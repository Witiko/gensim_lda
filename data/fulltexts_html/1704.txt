 

We gratefully acknowledge support from
the Simons Foundation
and member institutions 
arXiv.org > stat > arXiv:1704.02686
 
 
 
(Help | Advanced search)

Full-text links: 
Download:
    • PDF 
    • Other formats 
(license)
Current browse context:
stat.ML
< prev | next > 
new | recent | 1704
Change to browse by:
cs
cs.CL
cs.LG
stat 
References & Citations
    • NASA ADS 
Google Scholar
Bookmark
(what is this?) 
       
Statistics > Machine Learning
Title: Word Embeddings via Tensor Factorization
Authors: Eric Bailey, Shuchin Aeron
(Submitted on 10 Apr 2017 (v1), last revised 15 Sep 2017 (this version, v2))
Abstract: Most popular word embedding techniques involve implicit or explicit factorization of a word co-occurrence based matrix into low rank factors. In this paper, we aim to generalize this trend by using numerical methods to factor higher-order word co-occurrence based arrays, or \textit{tensors}. We present four word embeddings using tensor factorization and analyze their advantages and disadvantages. One of our main contributions is a novel joint symmetric tensor factorization technique related to the idea of coupled tensor factorization. We show that embeddings based on tensor factorization can be used to discern the various meanings of polysemous words without being explicitly trained to do so, and motivate the intuition behind why this works in a way that doesn't with existing methods. We also modify an existing word embedding evaluation metric known as Outlier Detection [Camacho-Collados and Navigli, 2016] to evaluate the quality of the order-$N$ relations that a word embedding captures, and show that tensor-based methods outperform existing matrix-based methods at this task. Experimentally, we show that all of our word embeddings either outperform or are competitive with state-of-the-art baselines commonly used today on a variety of recent datasets. Suggested applications of tensor factorization-based word embeddings are given, and all source code and pre-trained vectors are publicly available online. 
Comments: 
More simulation results added
Subjects: 
Machine Learning (stat.ML); Computation and Language (cs.CL); Machine Learning (cs.LG)
Cite as: 
arXiv:1704.02686 [stat.ML]
 
(or arXiv:1704.02686v2 [stat.ML] for this version)

Submission history
From: Shuchin Aeron [view email] 
[v1] Mon, 10 Apr 2017 02:24:37 GMT (429kb,D)
[v2] Fri, 15 Sep 2017 18:56:30 GMT (286kb,D)
Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) 
Link back to: arXiv, form interface, contact.

