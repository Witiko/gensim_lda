 
Skip to main content 
This service is more advanced with JavaScript available, learn more at http://activatejavascript.org 
Advertisement
Hide 

SpringerLink
Search SpringerLink 
  
Search 
    • Home 
    • Contact us 
    • Log in 
Analysis of Images, Social Networks and Texts  
International Conference on Analysis of Images, Social Networks and Texts 
AIST 2016: Analysis of Images, Social Networks and Texts pp 132-144 | Cite as
Parallel Non-blocking Deterministic Algorithm for Online Topic Modeling
    • Authors
    • Authors and affiliations
    • Oleksandr Frei
    • Murat Apishev
Conference paper
First Online: 17 February 2017
    • 2 Citations 
    • 3 Readers 
    • 621 Downloads 
Part of the Communications in Computer and Information Science book series (CCIS, volume 661)
Abstract
In this paper we present a new asynchronous algorithm for learning additively regularized topic models and discuss the main architectural details of our implementation. The key property of the new algorithm is that it behaves in a fully deterministic fashion, which is typically hard to achieve in a non-blocking parallel implementation. The algorithm had been recently implemented in the BigARTM library (http://bigartm.org). Our new algorithm is compatible with all features previously introduced in BigARTM library, including multimodality, regularizers and scores calculation. While the existing BigARTM implementation compares favorably with alternative packages such as Vowpal Wabbit or Gensim, the new algorithm brings further improvements in CPU utilization, memory usage, and spends even less time to achieve the same perplexity.
Keywords
Probabilistic topic modeling Additive regularization of topic models Stochastic matrix factorization EM-algorithm Online learning Asynchronous and parallel computing BigARTM 

This is a preview of subscription content, log in to check access.

Notes
Acknowledgements
The work was supported by Russian Science Foundation (grant 15-18-00091). Also we would like to thank Prof. K. V. Vorontsov for constant attention to our research and detailed feedback to this paper.
References
    1. 1.
       Blei, D.M.: Probabilistic topic models. Commun. ACM 55(4), 77–84 (2012)CrossRefGoogle Scholar
    2. 2.
       Daud, A., Li, J., Zhou, L., Muhammad, F.: Knowledge discovery through directed probabilistic topic models: a survey. Front. Comput. Sci. Chin 4(2), 280–301 (2010)CrossRefGoogle Scholar
    3. 3.
       Blei, D.M., Ng, A.Y., Jordan, M.I.: Latent Dirichlet allocation. J. Mach. Learn. Res. 3, 993–1022 (2003)zbMATHGoogle Scholar
    4. 4.
       Yuan, J., Gao, F., Ho, Q., Dai, W., Wei, J., Zheng, X., Xing, E.P., Liu, T.Y., Ma, W.Y.: LightLDA: big topic models on modest computer clusters. In: Proceedings of the 24th International Conference on World Wide Web, pp. 1351–1361 (2015)Google Scholar
    5. 5.
       Hofmann, T.: Probabilistic latent semantic indexing. In: Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 50–57 (1999)Google Scholar
    6. 6.
       Hoffman, M.D., Blei, D.M., Bach, F.R.: Online learning for latent Dirichlet allocation. In: NIPS, pp. 856–864. Curran Associates Inc. (2010)Google Scholar
    7. 7.
       Newman, D., Asuncion, A., Smyth, P., Welling, M.: Distributed algorithms for topic models. J. Mach. Learn. Res. 10, 1801–1828 (2009)MathSciNetzbMATHGoogle Scholar
    8. 8.
       Wang, Y., Bai, H., Stanton, M., Chen, W.-Y., Chang, E.Y.: PLDA: parallel latent Dirichlet allocation for large-scale applications. In: Goldberg, A.V., Zhou, Y. (eds.) AAIM 2009. LNCS, vol. 5564, pp. 301–314. Springer, Heidelberg (2009). doi: 10.1007/978-3-642-02158-9_26 CrossRefGoogle Scholar
    9. 9.
       Liu, Z., Zhang, Y., Chang, E.Y., Sun, M.: PLDA+: parallel latent Dirichlet allocation with data placement and pipeline processing. ACM Trans. Intell. Syst. Technol. 2(3), 26:1–26:18 (2011)CrossRefGoogle Scholar
    10. 10.
       Seide, F., Fu, H., Droppo, J., Li, G., Yu, D.: On parallelizability of stochastic gradient descent for speech DNNs. In: 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 235–239. IEEE (2014)Google Scholar
    11. 11.
       Dean, J., Corrado, G.S., Monga, R., Chen, K., Devin, M., Le, Q.V., Mao, M.Z., Ranzato, M.-A., Senior, A., Tucker, P., Yang, K., Ng, A.Y.: Large scale distributed deep networks. In: NIPS, pp. 1223–1231 (2012)Google Scholar
    12. 12.
       Řehůřek, R., Sojka, P.: Software framework for topic modelling with large corpora. In: Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pp. 45–50, Valletta, Malta, May 2010Google Scholar
    13. 13.
       Langford, J., Li, L., Strehl, A.: Vowpal wabbit open source project. Technical report. Yahoo! (2007)Google Scholar
    14. 14.
       McCallum, A.K.: A Machine Learning for Language Toolkit (2002). http://mallet.cs.umass.edu 
    15. 15.
       Smola, A., Narayanamurthy, S.: An architecture for parallel topic models. Proc. VLDB Endow. 3(1–2), 703–710 (2010)CrossRefGoogle Scholar
    16. 16.
       Vorontsov, K.V.: Additive regularization for topic models of text collections. Dokl. Math. 89(3), 301–304 (2014)MathSciNetCrossRefzbMATHGoogle Scholar
    17. 17.
       Vorontsov, K.V., Potapenko, A.A.: Additive regularization of topic models. Mach. Learn. Spec. Issue Data Anal. Intell. Optim. 101(1), 303–323 (2015)MathSciNetzbMATHGoogle Scholar
    18. 18.
       Vorontsov, K., Frei, O., Apishev, M., Romov, P., Dudarenko, M.: BigARTM: open source library for regularized multimodal topic modeling of large collections. In: Khachay, M.Y., Konstantinova, N., Panchenko, A., Ignatov, D.I., Labunets, V.G. (eds.) AIST 2015. CCIS, vol. 542, pp. 370–381. Springer, Heidelberg (2015). doi: 10.1007/978-3-319-26123-2_36 CrossRefGoogle Scholar
    19. 19.
       Vorontsov, K., Frei, O., Apishev, M., Romov, P., Suvorova, M., Yanina, A.: Non-Bayesian additive regularization for multimodal topic modeling of large collections. In: Proceedings of the 2015 Workshop on Topic Models: Post-Processing and Applications, pp. 29–37. ACM, New York (2015)Google Scholar
Copyright information
© Springer International Publishing AG 2017
Authors and Affiliations
    • Oleksandr Frei
        ◦ 1
      Email author
    • Murat Apishev
        ◦ 2
      Email author
    1. 1.Moscow Institute of Physics and TechnologyMoscowRussia
    2. 2.National Research University Higher School of EconomicsMoscowRussia
About this paper
Cite this paper as: 
Frei O., Apishev M. (2017) Parallel Non-blocking Deterministic Algorithm for Online Topic Modeling. In: Ignatov D. et al. (eds) Analysis of Images, Social Networks and Texts. AIST 2016. Communications in Computer and Information Science, vol 661. Springer, Cham 
    • First Online 17 February 2017 
    • DOI https://doi.org/10.1007/978-3-319-52920-2_13 
    • Publisher Name Springer, Cham 
    • Print ISBN 978-3-319-52919-6 
    • Online ISBN 978-3-319-52920-2 
    • eBook Packages Computer Science 
    • Buy this book on publisher's site 
    • Reprints and Permissions 
Personalised recommendations

Cite paper 
    • How to cite? 
    • .RIS Papers Reference Manager RefWorks Zotero 
    • .ENW EndNote 
    • .BIB BibTeX JabRef Mendeley 
Buy options 
Actions
Log in to check access 
Buy eBook 
EUR 63.06 
Buy paper (PDF) 
EUR 30.19 
    • Instant download 
    • Readable on all devices 
    • Own it forever 
    • Local sales tax included if applicable 
Learn about institutional subscriptions 
Cite paper 
    • How to cite? 
    • .RIS Papers Reference Manager RefWorks Zotero 
    • .ENW EndNote 
    • .BIB BibTeX JabRef Mendeley 
Advertisement
Hide 

Over 10 million scientific documents at your fingertips
Switch Edition
    • Academic Edition 
    • Corporate Edition 
    • Home 
    • Impressum 
    • Legal information 
    • Privacy statement 
    • How we use cookies 
    • Accessibility 
    • Contact us 
Springer Nature 
© 2017 Springer Nature Switzerland AG. Part of Springer Nature.
Not logged in Not affiliated 62.245.124.181 









    • Your Privacy
    • Strictly Necessary Cookies
    • Performance Cookies
    • Functional Cookies
    • Targeting Cookies
    • More Information
Privacy Preference Centre
Active
Always Active



Save Settings
Allow All
We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners in accordance with our Privacy Statement. You can manage your preferences in Manage Cookies.
Close
OK
Manage Cookies

