 Skip to main content 

Journals & BooksRegisterSign in
    • 
    • Journals & Books
    • Register
    • Sign InHelp
 
Outline

Get AccessGet Access


Export
Advanced
Outline
    1. Highlights
    2. Abstract
    3. Keywords
    4. MSC
    5. 1. Introduction
    6. 2. WANTED! Biometrics and forensics integration
    7. 3. Collaborative and context-aware visual question answering
    8. 4. Image representation using deep learning
    9. 5. Text generation and understanding using word vectors
    10. 6. Long term concept dependencies using feedback and temporal processing
    11. 7. Show and Tell
    12. 8. Biometric and forensic integration using Show and Tell
    13. 9. Conformal prediction
    14. 10. Show and Tell: Quo Vadis and C2VQA
    15. 11. Software
    16. 12. Conclusions
    17. Acknowledgment
    18. References
Show full outline
Figures (7)
    1. 
    2. 
    3. 
    4. 
    5. 
    6. 
Show all figures
JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page.

Pattern Recognition Letters
Available online 16 February 2017
In Press, Corrected ProofWhat are Corrected Proof articles?

Biometrics and forensics integration using deep multi-modal semantic alignment and joint embedding

Author links open overlay panelAndeep S.ToorHarryWechsler
Show more
https://doi.org/10.1016/j.patrec.2017.02.012Get rights and content

Highlights
•
Novel collaborative and context-aware visual query answering (C2VQA) methodology.
•
Novel approach for Integrating Biometrics and Forensics (IBF) using C2VQA.
•
Implements IBF using deep learning, joint embedding, and semantic alignment.
•
Handles misinformation, relevance, and uncertainty using conformal prediction.
Abstract
This paper proposes collaborative and context-aware visual question answering (C2VQA) for multi-modal information channels integration, and details its particular mapping and realization for biometrics forensic integration (BFI) using Show and Tell like architectures. C2VQA, which expands on Visual Query Answering (VQA) and the Visual Turing Test (VTT), engages deep semantic alignment and joint embedding using deep learning (DL) for image analysis, vector space as skip-grams and long-term dependencies as gated recurrent networks for context prediction, and multi-strategy learning including conformal prediction for control and meta-reasoning. C2VQA would engage in purposeful dialog to address and correct for misinformation and uncertainty and considers behavior to model realistic VQA problems characteristic of open rather than closed set VQA.
Keywords
Biometrics
Deep learning (DL)
Forensics
Joint embedding
meta-reasoning
Semantic alignment
Visual question answering (VQA)
Visual Turing Test (VTT)
Convolutional Neural Network (CNN)
MSC
41A05
41A10
65D05
65D17
Recommended articlesCiting articles (1)
© 2017 Elsevier B.V. All rights reserved.
Recommended articles
            ▪ Biometric surveillance using visual question answering
      Pattern Recognition Letters, 2018
      Purchase PDF
      View details
      
            ▪ Modern art challenges face detection
      Pattern Recognition Letters, 2018
      Purchase PDF
      View details
      
            ▪ Multi-modal uniform deep learning for RGB-D person re-identification
      Pattern Recognition, Volume 72, 2017, pp. 446-457
      Purchase PDF
      View details
      
12Next
Citing articles (1)
            ▪ Visual Question Authentication Protocol (VQAP)
      2018, Computers and Security
      Purchase PDF
      View details
      
Article Metrics
View article metrics
About ScienceDirectRemote accessShopping cartContact and supportTerms and conditionsPrivacy policy
We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies.
Copyright © 2018 Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V.

