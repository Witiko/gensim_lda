
diva-portal.org 

Please wait ...
Simple search 

Advanced search - 
Research publicationsAdvanced search - 
Student thesesStatistics 


EnglishSvenskaNorsk 
Change search
Search Only documents with full text in DiVA 
    • Topic discovery and document similarity via pre-trained word embedd...
CiteExportLink to record
Permanent link 
 
Direct link 

Cite
Citation style
Language
Output format
CreateClose

Topic discovery and document similarity via pre-trained word embeddings
Chen, Simin 
KTH, School of Electrical Engineering and Computer Science (EECS).

2018 (English)Independent thesis Advanced level (degree of Master (Two Years)), 20 credits / 30 HE creditsStudent thesis 
Abstract [en] 
Throughout the history, humans continue to generate an ever-growing volume of documents about a wide range of topics. We now rely on computer programs to automatically process these vast collections of documents in various applications. Many applications require a quantitative measure of the document similarity. Traditional methods first learn a vector representation for each document using a large corpus, and then compute the distance between two document vectors as the document similarity.In contrast to this corpus-based approach, we propose a straightforward model that directly discovers the topics of a document by clustering its words, without the need of a corpus. We define a vector representation called normalized bag-of-topic-embeddings (nBTE) to encapsulate these discovered topics and compute the soft cosine similarity between two nBTE vectors as the document similarity. In addition, we propose a logistic word importance function that assigns words different importance weights based on their relative discriminating power.Our model is efficient in terms of the average time complexity. The nBTE representation is also interpretable as it allows for topic discovery of the document. On three labeled public data sets, our model achieved comparable k-nearest neighbor classification accuracy with five stateof-art baseline models. Furthermore, from these three data sets, we derived four multi-topic data sets where each label refers to a set of topics. Our model consistently outperforms the state-of-art baseline models by a large margin on these four challenging multi-topic data sets. These works together provide answers to the research question of this thesis:Can we construct an interpretable document represen-tation by clustering the words in a document, and effectively and efficiently estimate the document similarity?
Abstract [sv] 
Under hela historien fortsätter människor att skapa en växande mängd dokument om ett brett spektrum av publikationer. Vi förlitar oss nu på dataprogram för att automatiskt bearbeta dessa stora samlingar av dokument i olika applikationer. Många applikationer kräver en kvantitativmått av dokumentets likhet. Traditionella metoder först lära en vektorrepresentation för varje dokument med hjälp av en stor corpus och beräkna sedan avståndet mellan two document vektorer som dokumentets likhet.Till skillnad från detta corpusbaserade tillvägagångssätt, föreslår vi en rak modell som direkt upptäcker ämnena i ett dokument genom att klustra sina ord , utan behov av en corpus. Vi definierar en vektorrepresentation som kallas normalized bag-of-topic-embeddings (nBTE) för att inkapsla de upptäckta ämnena och beräkna den mjuka cosinuslikheten mellan två nBTE-vektorer som dokumentets likhet. Dessutom föreslår vi en logistisk ordbetydelsefunktion som tilldelar ord olika viktvikter baserat på relativ diskriminerande kraft.Vår modell är effektiv när det gäller den genomsnittliga tidskomplexiteten. nBTE-representationen är också tolkbar som möjliggör ämnesidentifiering av dokumentet. På tremärkta offentliga dataset uppnådde vår modell jämförbar närmaste grannklassningsnoggrannhet med fem toppmoderna modeller. Vidare härledde vi från de tre dataseten fyra multi-ämnesdatasatser där varje etikett hänvisar till en uppsättning ämnen. Vår modell överensstämmer överens med de högteknologiska baslinjemodellerna med en stor marginal av fyra utmanande multi-ämnesdatasatser. Dessa arbetsstöd ger svar på forskningsproblemet av tisthesis:Kan vi konstruera en tolkbar dokumentrepresentation genom att klustra orden i ett dokument och effektivt och effektivt uppskatta dokumentets likhet?
Place, publisher, year, edition, pages
2018. , p. 85 
Series 
TRITA-EECS-EX ; 557 
Keywords [en] 
Document similarity; document representation; word embedding; natural language processing; topic modeling; 
National Category 
Computer and Information Sciences 
Identifiers
URN: urn:nbn:se:kth:diva-235537OAI: oai:DiVA.org:kth-235537DiVA, id: diva2:1251940 

Supervisors 
Girdzijauskas, Sarunas
KTH, School of Electrical Engineering and Computer Science (EECS).
Examiners 
Boström, Henrik
KTH, School of Electrical Engineering and Computer Science (EECS).
Available from: 2018-09-28 Created: 2018-09-28 Last updated: 2018-09-28Bibliographically approved 


Open Access in DiVA
fulltext(2614 kB)1 downloads

File information 
File name FULLTEXT01.pdfFile size 2614 kBChecksum SHA-512
cb115a830af99b93364eb7d1cc86f40ac77719d6faa0b332f93260ff40017d4e3809d946261024318f7987320452dba3c6b2f1fe71fd3b1aac32766eb8cec5bb
Type fulltextMimetype application/pdf
By organisation 
School of Electrical Engineering and Computer Science (EECS) 
On the subject 
Computer and Information Sciences 
Search outside of DiVA
GoogleGoogle Scholar

Total: 1 downloads
The number of downloads is the sum of all downloads of full texts. It may include eg previous versions that are now no longer available

urn-nbn

Total: 11 hits 
CiteExportLink to record
Permanent link 
 
Direct link 

Cite
Citation style
Language
Output format
CreateClose

v. 2.35.3
| 
About DiVA Portal 

    • BibTex
    • CSL-JSON
    • CSV 1
    • CSV 2
    • CSV 3
    • CSV 4
    • CSV 5
    • CSV all metadata
    • CSV all metadata version 2
    • RIS
    • Mods
    • MARC-XML
    • ETDMS
    • apa
    • ieee
    • modern-language-association-8th-edition
    • vancouver
    • Other style
    • de-DE
    • en-GB
    • en-US
    • fi-FI
    • nn-NO
    • nn-NB
    • sv-SE
    • Other locale
    • html
    • text
    • asciidoc
    • rtf
Altmetric score
urn-nbn
    • BibTex
    • CSL-JSON
    • CSV 1
    • CSV 2
    • CSV 3
    • CSV 4
    • CSV 5
    • CSV all metadata
    • CSV all metadata version 2
    • RIS
    • Mods
    • MARC-XML
    • ETDMS
    • apa
    • ieee
    • modern-language-association-8th-edition
    • vancouver
    • Other style
    • de-DE
    • en-GB
    • en-US
    • fi-FI
    • nn-NO
    • nn-NB
    • sv-SE
    • Other locale
    • html
    • text
    • asciidoc
    • rtf
