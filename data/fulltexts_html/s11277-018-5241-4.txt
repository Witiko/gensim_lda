 
Skip to main content 
This service is more advanced with JavaScript available, learn more at http://activatejavascript.org 
Advertisement
Hide 

SpringerLink
Search SpringerLink 
  
Search 
    • Home 
    • Contact us 
    • Log in 
Wireless Personal Communications  
Wireless Personal Communications
September 2018, Volume 102, Issue 2, pp 1853–1865 | Cite as
From Act to Utterance: A Research on Linguistic Act Convergence
    • Authors
    • Authors and affiliations
    • Mali Cai
    • Hui Liu
    • Wei Yu
Article
First Online: 12 January 2018
    • 28 Downloads 
Abstract
This paper presents an act–utterance convergence between children and their guardians (an umbrella term for the adults who serve as children’s interaction partner in this paper). Act and utterance are two different carriers of intention. Some convergence patterns exist in act–utterance interaction between young children and their guardians. Guardians tend to respond to their children by describing what the children are doing, reflecting this convergence. This research has built the A–U Assimilation Model to assimilate act and utterance and narrow the gap of expression between act and utterance while keeping their meanings unchanged. The unified expression framework in this model makes the act and utterance comparable. The research analyzed the convergence between act and utterance from children’s preverbal period to the age of 60 months by adopting a large-scale corpus. And the analysis of the convergence between act and utterance is conducted by the Doc2Vec in a neural network. The experiment results show that the degree of guardian-led act–utterance convergence increases rapidly during the period that children begin to learn to speak and decrease gradually as children become more proficient language learners and users.
Keywords
Act–utterance convergence A–U assimilation model Unified expression framework Doc2vec 

This is a preview of subscription content, log in to check access.

Notes
Acknowledgements
This work was financially supported by the National Natural Science Foundation of China (Grant: 61502350). Thanks are due to Wenfeng Z, Xianping Y et al., for participation in the A–U interaction experiments as undergraduate volunteers.
References
    1. 1.
       Mayor, J., & Plunkett, K. (2011). A statistical estimate of infant and toddler vocabulary size from cdi analysis. Developmental Science, 14(4), 769.CrossRefGoogle Scholar
    2. 2.
       Perani, D., Saccuman, M. C., Scifo, P., Anwander, A., Awander, A., Spada, D., et al. (2011). Neural language networks at birth. Proceedings of the National Academy of Sciences of the United States of America, 108(38), 16056–16061.CrossRefGoogle Scholar
    3. 3.
       Snow, C. E. (1972). Mothers’ speech to children learning language. Child Development, 43(2), 549–565.CrossRefGoogle Scholar
    4. 4.
       Yurovsky, D., Doyle, G., & Frank, M. C. (2016). Linguistic input is tuned to children’s developmental level. In Proceedings of the 38th annual meeting of the cognitive science society (pp. 2093–2098).Google Scholar
    5. 5.
       Giles, H., Coupland, J., & Coupland, N. (Eds.). (1991). Contexts of accommodation: Developments in applied sociolinguistics. Cambridge: Cambridge University Press.Google Scholar
    6. 6.
       Buresh, J. S., & Woodward, A. L. (2007). Infants track action goals within and across agents. Cognition, 104(2), 287–314.CrossRefGoogle Scholar
    7. 7.
       Rollins, P. R., & Greenwald, L. C. (2013). Affect attunement during mother-infant interaction: How specific intensities predict the stability of infants’ coordinated joint attention skills. Imagination, Cognition and Personality, 32(4), 339–366.CrossRefGoogle Scholar
    8. 8.
       MacWhinney, B. (2000). The CHILDES project: Tools for analyzing talk (3rd ed.). Mahwah: Lawrence Erlbaum Associates.Google Scholar
    9. 9.
       McCune, L. (1995). A normative study of representational play at the transition to language. Developmental Psychology, 31(2), 198–206.CrossRefGoogle Scholar
    10. 10.
       Bengio, Y., Vincent, P., & Janvin, C. (2006). A neural probabilistic language model. Journal of Machine Learning Research, 3(6), 1137–1155.Google Scholar
    11. 11.
       Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.
    12. 12.
       Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In International conference on neural information processing systems (Vol. 26, pp. 3111–3119). Curran Associates Inc.Google Scholar
    13. 13.
       Le, Q., & Mikolov, T. (2014). Distributed representations of sentences and documents. In Proceedings of the 31st international conference on machine learning (ICML-14) (pp. 1188–1196).Google Scholar
    14. 14.
       Zhang, Z., & Lan, M. (2016). Learning sentiment-inherent word embedding for word-level and sentence-level sentiment analysis. In International conference on asian language processing (pp. 94–97). IEEE.Google Scholar
    15. 15.
       Rehurek, R., & Sojka, P. (2010). Software framework for topic modelling with large corpora. In Proceedings of the LREC 2010 workshop on new challenges for NLP frameworks.Google Scholar
    16. 16.
       Chen, S., Soni, A., Pappu, A., & Mehdad, Y. (2017). Doctag2vec: An embedding based multi-label learning approach for document tagging, pp. 111–120.Google Scholar
    17. 17.
       Maslova, N., & Potapov, V. (2017). Neural network doc2vec in automated sentiment analysis for short informal texts. In International Conference on Speech and Computer (pp. 546–554). Springer, Cham.Google Scholar
    18. 18.
       Chan, W., Jaitly, N., Le, Q., & Vinyals, O. (2016). Listen, attend and spell: A neural network for large vocabulary conversational speech recognition. In IEEE international conference on acoustics, speech and signal processing (pp. 4960–4964). IEEE.Google Scholar
    19. 19.
       Pajankar, A. (2017). Introduction to NumPy. Raspberry Pi supercomputing and scientific programming. New York: Apress.CrossRefGoogle Scholar
Copyright information
© Springer Science+Business Media, LLC, part of Springer Nature 2018
Authors and Affiliations
    • Mali Cai
        ◦ 1
        ◦ 3
    • Hui Liu
        ◦ 2
      Email author
    • Wei Yu
        ◦ 3
    1. 1.Department of Applied EnglishWuhan College of Foreign Languages and Foreign AffairsWuhanChina
    2. 2.Department of ManagementWuhan Institute of BioengineeringWuhanChina
    3. 3.State Key Laboratory of Software Engineering, School of Computer ScienceWuhan UniversityWuhanChina
About this article
CrossMark 
Cite this article as: 
Cai, M., Liu, H. & Yu, W. Wireless Pers Commun (2018) 102: 1853. https://doi.org/10.1007/s11277-018-5241-4 
    • First Online 12 January 2018 
    • DOI https://doi.org/10.1007/s11277-018-5241-4 
    • Publisher Name Springer US 
    • Print ISSN 0929-6212 
    • Online ISSN 1572-834X 
    • About this journal 
    • Reprints and Permissions 
Personalised recommendations

Cite article 
    • How to cite? 
    • .RIS Papers Reference Manager RefWorks Zotero 
    • .ENW EndNote 
    • .BIB BibTeX JabRef Mendeley 
Buy options 
Actions
Log in to check access 
Buy (PDF) 
EUR 42.29 
    • Unlimited access to the full article 
    • Instant download 
    • Include local sales tax if applicable 
Subscribe to Journal 
Get Access to 
Wireless Personal Communications
for the whole of 2018 
Rent this article via DeepDyve 
Learn about institutional subscriptions 
Cite article 
    • How to cite? 
    • .RIS Papers Reference Manager RefWorks Zotero 
    • .ENW EndNote 
    • .BIB BibTeX JabRef Mendeley 
Advertisement
Hide 

Over 10 million scientific documents at your fingertips
Switch Edition
    • Academic Edition 
    • Corporate Edition 
    • Home 
    • Impressum 
    • Legal information 
    • Privacy statement 
    • How we use cookies 
    • Accessibility 
    • Contact us 
Springer Nature 
© 2017 Springer Nature Switzerland AG. Part of Springer Nature.
Not logged in Not affiliated 62.245.124.181 









    • Your Privacy
    • Strictly Necessary Cookies
    • Performance Cookies
    • Functional Cookies
    • Targeting Cookies
    • More Information
Privacy Preference Centre
Active
Always Active



Save Settings
Allow All
We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners in accordance with our Privacy Statement. You can manage your preferences in Manage Cookies.
Close
OK
Manage Cookies

