Open Directory Project based universal taxonomy for Personalization
of Online (Re)sources
Jurica Ševa
⇑
,
Markus Schatten,
Petra Grd
University of Zagreb,
Faculty of Organization and Informatics,
Pavlinska 2,
42 000 Varaz
ˇ
din,
Croatia
a r t i
c l e
i
n f o
Article history:
Available online 25 April 2015
Keywords:
Recommendation systems
Content personalization
Automatic content classiﬁcation
Automatic content labeling
Information extraction
Information retrieval
Open Directory Project
Vector Space Modeling
TF-IDF
a b s t r a c t
Content personalization reﬂects the ability of content classiﬁcation into (predeﬁned) thematic units or
information domains.
Content nodes in a single thematic unit are related to a greater or lesser extent.
An existing connection between two available content nodes assumes that the user will be interested
in both resources (but not necessarily to the same extent).
Such a connection (and its value) can be
established through the process of automatic content classiﬁcation and labeling.
One approach for the
classiﬁcation of content nodes is the use of a predeﬁned classiﬁcation taxonomy.
With the help of such
classiﬁcation taxonomy it is possible to automatically classify and label existing content nodes as well as
create additional descriptors for future use in content personalization and recommendation systems. For
these purposes existing web directories can be used in creating a universal, purely content based, classi-
ﬁcation taxonomy. This work analyzes Open Directory Project (ODP) web directory and proposes a novel
use of its structure and content as the basis for such a classiﬁcation taxonomy. The goal of a uniﬁed clas-
siﬁcation taxonomy is to allow for content personalization from heterogeneous sources. In this work we
focus on the overall quality of ODP as the basis for such a classiﬁcation taxonomy and the use of its hier-
archical structure for automatic labeling. Due to the structure of data in ODP different grouping schemes
are devised and tested to ﬁnd the optimal content and structure combination for a proposed classiﬁcation
taxonomy as well as automatic labeling processes.
The results provide an in-depth analysis of ODP and
ODP based content
classiﬁcation and automatic labeling models.
Although the use of
ODP is well
documented,
this question has not been answered to date.
Ó 2015 Elsevier Ltd.
All rights reserved.
1. Introduction
The beginning of the 21st century has witnessed a hyper pro-
duction of digitally available content.
One of the most important
processes was made in the redesign of newspapers for the digital
generation as they began to present
their
content
online.
The
downside of this evolution is deﬁned by the paradox of informa-
tion crisis: the problem of accessing needed information does not
lie in the fact that information is inaccessible, but just the opposite;
the vast
size of
digital
information users are surrounded with
makes it difﬁcult to access appropriate information. One approach
in reducing the effects of information crisis is the process of con-
tent personalization through recommendation systems.
This pro-
cess can be automated by using automatic content classiﬁcation
and labeling models which is the focus of
this work.
Automatic
content
classiﬁcation has been widely researched and is not
a
new research ﬁeld.
There are many approaches used in automatic
content classiﬁcation including but not limited to Bayesian classi-
ﬁers,
Support Vector Machines (SVM),
Artiﬁcial Neural Networks,
and clustering techniques (Borges & Lorena,
2010,
p.
130).
One of
the issues with automatic content
classiﬁcation from heteroge-
neous
sources
is
their
different
categorization
structure.
Additionally, there are no universally accepted experimental data-
set for large scale hierarchical classiﬁcation yet,
so related work is
based on different datasets for evaluation (e.g.
ODP,
the Yahoo!
Directory or some other domain-speciﬁc datasets) (He,
Jia,
Ding,
& Han,
2013).
Although different
datasets are used in different
research efforts we can give an overview of
weighting schemes
used,
classiﬁcation
approaches
and
their
results
for
recent
reviewed research efforts that
are comparable with this work.
We propose the use of ODP
1
Web directory as a uniﬁed classiﬁca-
tion taxonomy. As of time of writing this article an in-depth analysis
of ODP and its use as a uniﬁed classiﬁcation taxonomy is not present.
This paper is based on an approach that combines methods and
techniques of information extraction (IE) (Cowie & Lehnert,
1996),
http://dx.doi.org/10.1016/j.eswa.2015.04.033
0957-4174/Ó 2015 Elsevier Ltd.
All rights reserved.
⇑
Corresponding author.
Tel.: +385 42 390 873; fax: +385 42 213 413.
E-mail
addresses:
jseva@foi.hr (J.
Ševa),
markus.schatten@foi.hr (M.
Schatten),
petra.grd@foi.hr (P.
Grd).
1
Open Directory Project.
Expert Systems with Applications 42 (2015) 6306–6314
Contents lists available at ScienceDirect
Expert Systems with Applications
j o u r n a l
homepage:
w w w . e l s e v i e r . c o m / l o c a t e / e s w a
natural language processing (NLP),
information retrieval (IR) (Salton,
1983;
Van Rijsbergen,
1979)
and Vector
Space Modeling (VSM)
(Salton, Wong, & Yang, 1975) for creating machine understandable
classiﬁcation
models
used
for
automatic
content
classiﬁca-
tion/labeling. In order to prepare the content of digital textual doc-
uments for further processing IE and NLP techniques are used. NLP
is a part of
Artiﬁcial
Intelligence (AI) research that allows us to
process content presented in natural
language and extract tacit
knowledge from it.
NLP is
used to prepare input
documents
through removing parts of their content that are not useful for fur-
ther processing.
Prepared content is then represented with one of
possible weighting schemes.
Resulting models and their perfor-
mance are evaluated based on standard IR measures:
precision
(P), recall (R) and F1 (all deﬁned below). Python programming lan-
guage and its extensions NLTK
2
(Bird, Klein, & Loper, 2009), gensim
3
(R
ˇ
ehu
˚
r
ˇ
ek & Sojka,
2004)
and scikit-learn
4
(Pedregosa et al.,
2011)
have been selected as the implementation platform.
NLTK offers a
direct way for manipulating human written language and offers a
set of tools to prepare the data for further steps and VSM.
Genism
allows us to represent prepared documents in selected weighting
scheme,
with TF-IDF
5
weighting scheme used in this work.
TF-IDF
is the oldest and most used weighting scheme in VSM and was ini-
tially deﬁned in (Salton,
1975).
It is measure was later expanded
upon with idf measure reasoning for which is given in (Robertson,
2004). It is used primarily for VSM, which provides a basis for infor-
mation retrieval technique(s) used herein.
Scikit-learn provides the
basis
for
IR measures
implementation and classiﬁcation model
performance.
This paper focuses on testing if ODP presents a good classiﬁca-
tion scheme for both content-based node classiﬁcation as well as
labeling. We provide several grouping approaches and test optimal
number of documents for models in deﬁned grouping schemes for
best classiﬁcation and labeling results. This study aims to meet the
following objectives:
(G1) representing ODP content with a set of
key words that
describe individual
nodes
based on TF-IDF
weighting
scheme.
(G2) using ODP structure for automatic classiﬁcation and label-
ing based on the content representation deﬁned in G1.
The rest of
the paper is organized as follows: Section 2 pre-
sents an overview of related work and research efforts this work
is based on and compared to.
In Section 3 an overview of
used
research methodology is given whilst in Section 4 the research
results are presented and analyzed.
Section 5 concludes on the
obtained results,
explains the signiﬁcance of
achieved results in
the ﬁeld of intelligent information systems and gives an overview
of future work.
2. Related work
The use of folksonomies and/or taxonomies for enhancing infor-
mation retrieval results is well documented in relevant literature.
They are usually used as additional descriptors in various applica-
tion domains and annotate resources with a deﬁned set of possible
labels. In this context there are several web directories available for
use
in
creation
of
classiﬁcation
taxonomies
(AboutUs.org,
Biographicon,
LookSmart,
Google Directory,
Intute,
Lycos’
TOP 5%,
Yahoo! Directory,
Zeal
etc.).
From all
possible and available web
directories ODP has been identiﬁed as the most suitable for our
research agenda due to a number of reasons.
ODP itself was the
ﬁrst
organized effort
to classify Web domains
manually into
predeﬁned categories
and has,
from its
beginnings,
relied on
human editors and their manual
efforts in classifying submitted
Web
domains.
Therefore
it
represents
an
expert-based,
pre-labeled collection of documents.
The hierarchical structure is
presented through 17 root categories and has 0.7 million possible
categories (Zhu & Dreher, 2010) with the number of domains listed
in the directory exceeding 4.5 million entries. Besides the number
of
classiﬁed
web
domains,
it
also
presents
a
hierarchical
categorization scheme where each categorized domain belongs to
one or more categories that are organized in (maximum) 13 hier-
archical
levels.
All
categories are described with one or multiple
documents and they represent possible labels in automatic classi-
ﬁcation/labeling system.
One of
the main problems in using existing taxonomies (e.g.
ODP) is the structure of data presented in the taxonomy and its
combination in created classiﬁcation models.
The majority of
research efforts try to utilize preexisting connections and hierarchi-
cal structure from each speciﬁc data source used in automatic clas-
siﬁcation research efforts. In case of ODP, classiﬁcation models can
be created based on different grouping schemes as presented in this
work.
Documents used in classiﬁcation models can be grouped
based on parent–child relations or sibling relations.
Additionally,
an alternative way of grouping data is via symbolic links that are
present in most predeﬁned web directories.
A symbolic link is a
hyperlink which makes a directed connection from a webpage
along one path through a directory to a page along another path
(Perugini, 2008). As their results show, almost 97% of symbolic links
results
with multiclassiﬁcation and ‘‘majority of
symbolic
links
(>77%)
are multiclassiﬁcation links
which connect
two categories
which share at least the ﬁrst two levels of topic speciﬁcity’’ (Perugini,
2008,
p.
927).
The majority of
symbolic links
produce multi-
classiﬁcation this approach will not be used as their use generates
additional
noise
in
the
classiﬁcation
and
labeling
process.
Additionally, reviewed research efforts differ based on VSM weight-
ing scheme used (mostly TF-IDF) as well as the range of the taxon-
omy used (domain-speciﬁc branches or the entire taxonomy). The
majority of research efforts that use ODP for automatic classiﬁca-
tion are domain-speciﬁc,
use TF-IDF weighting scheme and limit
the number of ODP documents,
both in hierarchical
branches as
well as hierarchical depth, used in created classiﬁcation models.
Marath, Shepherd, Milios, and Duffy (2014) focus on the Yahoo!
Directory and present a uniﬁed classiﬁcation model or framework
for highly imbalanced hierarchical datasets. In their work ODP was
used as the validation data set. They focus on a subset of ODP and
use 17,217 categories and 130,594 web pages from ODP data
whilst we focus on the entire directory.
Additionally,
their work
uses standard machine learning algorithms for classiﬁcation whilst
we focus on VSM based models and IR.
Classiﬁcation results are
evaluated
using
F1
measure
and
as
reported
they
achieve
macro-averaged F1-measure of the DMOZ subset of value 84.85%.
ODP is used as the testing set again in (Rajalakshmi & Aravindan,
2013).
This approach uses just the URL of a document for its clas-
siﬁcation but
they use 3-gram notation for
feature extraction
whilst we use 1-gram notation. Classiﬁcation models are built with
SVM and Maximum Entropy classiﬁer.
Their testing set was again
limited, this time to 14 root categories, and Fl was used as the eval-
uation metric,
with classiﬁcation results around 80% for each of
selected root categories,
which is lower than our results.
Zubiaga
and Ji (2013) use ODP for the classiﬁcation of data available over
Twitter.
He et
al.
(2013)
focus on hierarchical
classiﬁcation of
rare categories in ODP.
They propose an approach based on LDA
6
2
Natural Language Toolkit,
http://www.nltk.org.
3
http://radimrehurek.com/gensim/index.html.
4
http://scikit-learn.org/stable/.
5
Term Frequency–Inverse Document Frequency.
6
Latent Dirichlet Allocation.
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
6307
(Blei,
Ng,
& Jordan,
2003).
Their classiﬁcation models are created by
SVM and use term frequency vectors for document representation.
Their experiments where performed on Chinese Simpliﬁed branch
of the DMOZ directory which has 13 root categories and a hierarchi-
cal depth of 6. Again,
we use a larger part of ODP data in our classi-
ﬁcation models.
As
evaluation measures
standard P,
R and F1
measures were used.
Their overall
classiﬁcation results based on
their approach is below 80% for all proposed classiﬁcation schemes.
Amini, Ibrahim, Othman, and Nematbakhsh (2015) use ODP in com-
bination with other web directories for a reference ontology in the
scope of scientiﬁc publishing.
From all available categories in ODP,
they focus on the Computer Science section of the directory leaving
them 8471 general entries.
Fathy,
Gharib,
Badr,
Mashat,
and Abraham (2014) use ODP for
improving search results based on user preferences.
ODP and its
concepts are used as additional descriptors for user search queries.
Reference taxonomy,
based on TF-IDF weighting scheme,
chooses
the ﬁrst 30 URLs for each concept based on the order in which
they are represented by ODP.
ODP is additionally used for con-
struction user proﬁles where search results clicked by the user
are
classiﬁed into concepts
from ODP which are
then used
together to build the proﬁle.
Duong,
Uddin,
and Nguyen (2013)
also focus their research efforts on enhancing search results by
using ODP as the basis for a reference ontology used to addition-
ally label visited documents. Again, documents in ODP were repre-
sented with TF-IDF weighting scheme based vectors. These vectors
are then used to search for similar ontological
concepts.
Their
research is focused on user searches in academic domain of com-
puter science and therefore their models only include that branch
of ODP.
Their experimental data set consists of 650 concepts and
15,326 documents
that
were indexed under
various
concepts.
Results were evaluated on P,
R and F1 measures although results
are only presented graphically.
In (Lee,
Ha,
Jung,
& Lee,
2013) ODP was used as an additional
descriptor in the domain of
contextual
advertising.
They prune
down ODP data used for training and testing down to 15 root cat-
egories,
95,259 domains,
5178 nodes and a maximum of
nine
levels that are used to create the taxonomy. Documents are repre-
sented based on TF-IDF weighting scheme values. Their results are
evaluated based on P, R and F1 with best P results at 0.863. Vargiu,
Giuliani,
and Armano (2013) also focus on contextual advertising
and use collaborative ﬁltering for classiﬁcation models creation.
It uses ODP and its data to classify the page content and to suggest
suitable ads accordingly.
The use TF-IDF weighting scheme to
transform prepared
documents
for
classiﬁcation.
They
use
Rocchio classiﬁer to created centroids and classify the document
into one or more ODP categories.
Two recent research efforts in were based on the entire ODP
dataset.
Yun,
Jing,
Yu,
and Huang (2012) focus on combining data
from ODP and Wikipedia where ODP is used to deﬁne a set of terms
that are then compared with Wikipedia concepts.
Their work is
combined in Two-level Representation Model (2RA) and uses syn-
tactic
information and
semantic
information extracted
from
Wikipedia data.
Term-based VSM and TF-IDF weighting scheme
are used in syntactic level
to record the syntactic information.
Semantic level consists of Wikipedia concepts related to the terms
in the syntactic level.
Their classiﬁcation approach,
deﬁned with
Multi-layer classiﬁcation (MLCLA) framework,
is designed to han-
dle
large
scale
data
with
complex
and
high
dimensions
layer-by-layer.
Their best achieved classiﬁcation results,
measure
with F-score measure,
differ for SVM classiﬁcation (0.9942) and
1NN classiﬁcation algorithms (0.8468).
Ha,
Lee,
Jang,
Lee,
and Lee
(2014)
focus on using various classiﬁcation algorithms for text
classiﬁcation and conclude that
training data expansion signiﬁ-
cantly improves the classiﬁcation performance.
They focus their
research efforts on the best
approach of
hierarchically pruning
the ODP tree while traversing available branches from root node
towards deeper hierarchical
levels.
They also remove two cate-
gories (Regional and World respectively) from training and testing
data which leaves them with 182,003 categories and 1,228,843
web pages.
As
the weighting scheme they also utilize TF-IDF
weights
and base
their
classiﬁcation approach on generated
merge-document and merge-centroid vectors.
They measured the
accuracy of a classiﬁer as the number of correctly classiﬁed test
data
divided
by
total
number
of
test
data,
based
on
two
F-measure
values
(macroaveraged (maF
1
)
and micro-averaged
(miF
1
) F-measure).
Although they give a comparison of different
classiﬁcation algorithms
used,
their
best
classiﬁcation results
yields at approximately 36%.
Compared to presented approaches in reviewed literature we
use ODP purely as the basis for a universal
classiﬁcation taxon-
omy.
The focus of
our approach is to enable personalization of
news articles from various
online news
portals.
Due to their
heterogeneous
classiﬁcation scheme a universal
classiﬁcation
scheme is needed to provide a general
classiﬁcation scheme.
For these purposes we analyze the entire ODP content and do
not exclude categories either based on their depth or the number
of documents describing the category.
Although ODP is used in
different application domains such an approach is not currently
presented in recent research efforts.
Our work also uses speciﬁc
steps in preparing ODP data for classiﬁcation models by utilizing
NLP
and IE
tools
and techniques
for
dimension reduction.
Additionally,
we
propose
a
two-step classiﬁcation approach
where the ﬁrst stage is focused on general classiﬁcation and sec-
ond stage attaches multiple labels to the classiﬁed resource.
For
these purposes we show different approaches in grouping ODP
content and compare their evaluation results.
Compared to pre-
sented relevant research efforts,
our approach performs as good
or better.
3. Methodology
IE was deﬁned and ﬁrst presented in (Cowie & Lehnert,
1996)
with its goal deﬁned as ‘‘creating a system that ﬁnds and links rele-
vant information while ignoring extraneous and irrelevant informa-
tion’’.
IR ‘‘deals with the representation,
storage,
organization of,
and
access to information items’’
(Baeza-Yates & Ribeiro-Neto,
1999).
It
was presented as a topic in the early 1950’s with the emergence
of
computers and its scope has increased in 1970’s through the
work of Van Rijsbergen (1979) and Salton (1983).
Salton also pre-
sented the foundations of VSM approach for document modeling in
(Salton et al.,
1975). VSM in general,
as a model for IR,
is ﬁrst pro-
posed in (Salton,
1979).
TF-IDF is a combination of two measures describing a document
compared to a document collection (classiﬁcation model): TF (term
frequency) and IDF (inverse document frequency).
The weighting
scheme is then deﬁned as
TF-IDFðt; d; NÞ ¼ tf ðt; dÞ  idf ðt; NÞ;
ð1Þ
with
tf ðt; dÞ ¼ t
d
=d
t
ð2Þ
and
idf
t
¼ logðN=df
t
Þ
ð3Þ
where t is the observed expression, d is a document from the collec-
tion of N documents,
t
d
is the number of times term t appears in a
single document,
d
t
is the total number of terms in the document
and df
t
is the number of
documents from N containing term t.
6308
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
This measure assigns a value to the observed expression t in docu-
ment d that is:
 greatest where t is common in a small number of documents,
 smaller when t is less common in d, or when it appears in many
documents,
 smallest when t appears in all documents in N.
As stated in (Yun et al., 2012) ‘‘VSM is the most popular document
representation model for text clustering, classiﬁcation and information
retrieval’’.
Set of measures for IR model evaluation,
with precision
(P),
recall (R) and F1 measures used in this work,
were ﬁrst pre-
sented in (Salton & Lesk, 1968). Precision (P) is deﬁned as the frac-
tion of retrieved documents that are relevant:
Precision ¼
#ðrele
v
ant items retrie
v
edÞ
#ðretrie
v
ed itemsÞ
¼ Pðrele
v
antjretrie
v
edÞ
ð4Þ
Recall (R) is deﬁned as the fraction of relevant documents that are
retrieved:
Recall ¼
#ðrele
v
ant items retrie
v
edÞ
#ðrele
v
ant itemsÞ
¼ Pðretrie
v
edjrele
v
antÞ
ð5Þ
F-measure is deﬁned as the weighted harmonic mean, known as F1,
of P and R:
F1 ¼ 2  P  R=ðP þ RÞ
ð6Þ
ODP and its content and structure data ﬁles are freely available on
the ODP Web page
7
in RDF
8
format.
For a detailed presentation of
the data available in ODP RDF dump ﬁles see (Kalinov,
Stantic,
&
Sattar,
2010).
Due to its structure ODP data has to be grouped
together in order to create useful classiﬁcation models. In this work
there are several grouping schemes devised,
as presented in 3.3.
The reason for different comparison models is to determine the
following:
(1) Overall quality of the proposed universal taxonomy for auto-
matic document
classiﬁcation via ODP-based comparison
models.
(2) Optimal
grouping scheme and model
size for future use,
both for classiﬁcation and automatic labeling.
NLTK framework is a platform that offers interfaces for corpora
9
and lexical
resources like WordNet (Miller,
1995) which makes it
easier to implement needed natural
language processing tasks as
explained in (Perkins, 2010). This framework, in this work, has been
used for data cleaning purposes and removing all textual data that
did not have any value for further analysis (e.g.
HTML tags,
stop
words,
ﬁrst/last
names,
grammatical
POS
10
parts
of
text).
Additionally NLTK was also used for stemming with Porters stem-
ming algorithm (Porter,
2006).
Stemming ‘‘is
designed to remove
and replace well
known sufﬁxes of
English words’’
(Perkins,
2010,
p.
26) thus giving us the root form of selected word.
This way docu-
ment content normalization can be achieved.
ODP data was extracted and stored in a MySQL database with
help of the open source tool suckdmoz
11
. The database scheme cre-
ated by this tool is presented in Fig.
1.
Two created database tables
are especially interesting for further analysis: ‘dmoz_categories’
and
‘dmoz_externalpages’. They offer a list of classiﬁed domains available
in ODP along with their respective descriptions.
These descriptions
are the basis for crated classiﬁcation and labeling models. The overall
process of web usage mining is presented in Fig. 2. Steps speciﬁc for
this
research,
with the
goal
of
creating
ODP-based
universal
classiﬁcation models which will be described in more detail in the
following subsections,
are as follows:
(1) Data preparation.
(2) Indexing.
(3) Similarity evaluation.
(4) Model evaluation.
3.1.
Data preparation
Raw data, available through ODP database dump, has been pre-
pared for further data analysis.
During the preprocessing phase
ﬁrstly two categories were removed from the ODP data dump.
ODP branches for root categories ‘Adult’ and ‘World’ were excluded
from further analysis due to their content either not being written
in English or being multimedial data (e.g. digital images). After that
15 root categories remained.
Afterwards,
hierarchical
depth levels were deﬁned based on
two approaches:
(1)
URL-based classiﬁcation scheme descriptor
with delimiter ‘/’,
and (2) bottom-up approach,
based on parent–
child relationship,
using the ‘fatherid’
column,
where each docu-
ment on level n is described with both ‘fatherid‘
and ‘catid’
values
Fig. 1.
Open Directory Project MySQL structure.
7
http://rdf.dmoz.org/.
8
Resource Description Framework.
9
Collection of ‘real word’
texts used in NLP analysis.
10
Part of speech.
11
http://sourceforge.net/projects/suckdmoz/.
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
6309
(as shown in Fig. 1). In this approach ‘fatherid’ on level n references
‘catid’
value on level n  1.
Depth information is stored in the col-
umn ‘depthCategory’.
Finally,
entries with an empty ‘Description’
column in tables
‘dmoz_categories’
as well
as ‘dmoz_externalpages’
were assigned a
special value ‘-1’
in column ‘ﬁlterOut’.
This value marked all data-
base rows that were excluded from both training and testing data.
Using the above mentioned ﬁltering steps available data in
tables ‘dmoz_categories’
and ‘dmoz_externalpages’
was reduced as
shown in Table 1.
3.2.
Indexing
Indexing is focused on extracting text features.
The algorithm
for this process,
which is a modiﬁed version from (Greenwood,
2001),
reads as follows:
(1) While there are documents load the next document
(2) Split the document into tokens in 1-gram notation (deﬁned
by a predeﬁned delimiter)
(3) Remove:
(a)
HTML element tags (e.g.
<HEAD>,
<BODY>,
<DIV> etc.)
and special formatting HTML tags (e.g.
<b>,
<i> etc.)
(b) punctuation signs
(c)
known male/female ﬁrst names
(d) single alphanumeric characters
(e)
stop words (two stop word lists were used; NLTK based
list as well as manually created list)
(4) Stem resulting tokens
(5) If there are more documents,
go to 1.
The overall reduction of the number of words is approximately
47%,
which shows that by using the steps in the presented algo-
rithm one can achieve a signiﬁcant dimension reduction for further
analysis.
3.3.
Similarity evaluation
The prepared data is represented with TF-IDF weighting scheme
and serves
as
input
for
the classiﬁcation models.
Two main
approaches for creation and testing of prepared models have been
devised. Each model is deﬁned through used ODP content grouping
scheme and number of documents in created model.
Results and
their evaluation are shown in the next section.
Available content for classiﬁed web domains is ﬁrst grouped
together based on either ‘catid’
or ‘fatherid’
column values and
are as follows:
 GENERAL grouping,
where a single document
in a category
model
is represented by a single document
from a speciﬁc
category.
 CATID grouping, where a single document in a category model is
represented by all documents with the same ‘catid’ value from a
speciﬁc category.
 FATHERID grouping,
where a single document
in a category
model is represented by all documents with the same ‘fatherid’
value from a speciﬁc category.
Next,
for each grouping scheme two main size model families
were created:
(1) Percentage models, where, for each of the main 15 categories,
ﬁrst 25%,
50%,
75% and 100% of
documents were used in
model creation.
(2) Limit models where,
for each of the main 15 categories,
ﬁrst
1000, 2500, 5000, 7500, 10,000 and 20,000 documents were
used in model creation.
The purpose of different grouping and model document number
schemes is to test:
(1) If ODP is a good source for the proposed universal classiﬁca-
tion taxonomy and
(2) if there are differences in evaluated IR measures for different
model
creation approaches
related to different
grouping
schemes and number of documents used.
The model creation process was as follows:
(1) Prepare input data,
following steps from Sections 3.1 and
3.2.
(2) Create dictionary,
with the list
of
all
tokens/words taken
from the database for each speciﬁc category.
(3) Create corpora.
(4) Create
VSM representation based
of
TF-IDF
weighting
values.
The difference between models is deﬁned in the ﬁrst step. Files,
created as the result of
this stage,
are then used in testing and
model evaluation.
3.4.
Model evaluation
The data available from ODP was divided in two distinct sets,
training
set
and
testing
set,
with
their
ratio
being
80/20.
Achieved results were evaluated with standard IR measures P,
R
and F1. Evaluation results answered two research question deﬁned
in Section 1. The results of the evaluations were stored in a MySQL
database for further analysis.
The overall steps for model evaluation where the same for both
research questions and re as follows:
1.
Get n sample documents from testing data set.
Fig. 2.
Generalized Web usage mining system (Hu,
Zong,
Lee,
& Yeh,
2003).
Table 1
Available data after ﬁltering.
Database table
Original rows
Prepared rows
% of rows left
‘dmoz_externalpages’
4,592,105
2,637,412
57%
‘dmoz_categories’
763,378
496,007
65%
6310
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
2.
For each sample document:
a.
Prepare the sampled documents
(following the steps
described in Sections 3.1 and 3.2).
b.
Load comparison model ﬁle
12
.
c.
Calculate
similarity
value
of
each sample
document
against
loaded comparison model
with the following
constraints:
(a)
Rank documents by similarity value (descending).
(b)
Filter out documents with similarity value below set
minimum similarity value
13
(limited to 1000 most
similar documents).
3.
Evaluate results.
4. Evaluation results
Results
evaluation is
focused on answering
two research
questions:
(1)
Overall classiﬁcation quality of ODP by comparing training set
models
from category X against
testing set
data for
all
categories.
(2)
Best
grouping scheme for automatic labeling by comparing
training set models from category X against testing set data
for category X for each grouping scheme.
The ﬁrst research question is focused on determining if ODP is a
suitable candidate for content classiﬁcation of unclassiﬁed docu-
ments.
The results of this process are of vital importance for the
rest of research agenda. Furthermore,
due to multiple possibilities
of combining ODP data multiple grouping schemes were devised.
Hence,
second research question was devised and tested to show
which grouping scheme yields best classiﬁcation results.
Data available in ODP, prepared as explained in Sections 3.1 and
3.2,
was divided in two document sets:
training document set,
used to create classiﬁcation models,
and testing document
set,
used to test classiﬁcation models.
A requirement was set for both
data sets: they should have at least one document each with the
same ‘catid’ and ‘fatherid’ values. In both approaches the evaluation
was done by comparing the classiﬁcation models on the document
training set
data and comparing ‘catid’
and/or ‘fatherid’’
values,
depending on the grouping scheme tested, of the input documents
and the returned documents sorted by descending similarity value.
The results were evaluated with standardized IR measures: P, R and
F1.
Next,
a detailed presentation and explanation of
evaluation
results is provided.
4.1.
Overall classiﬁcation quality of ODP
First we determined whether ODP can be used as a classiﬁcation
taxonomy at all.
For these purposes a simple testing scheme was
derived and implemented where, based on n documents form cat-
egory X,
a set of
documents from the testing set was evaluated
against every created model
for each of
the proposed grouping
schemes (GENERAL,
CATID and FATHERID).
Calculated similarities for tested documents against different
grouping scheme models where summed for each compared cate-
gory. Stored data tested which category,
based on the overall sum
of all returned similarity values,
had the highest cumulative simi-
larity value; that category was shown as the most similar one from
all 15 possible categories in comparison to testing data from cate-
gory X.
The overview results are shown in Fig. 3. When it comes to the
proposed grouping schemes, the grouping based on CATID (positive
with value 4.4/15 and negative with value 10.6/15) showed the
worst results based on cumulative similarity value.
This is to be
interpreted as
follows:
from all
testing data
document
only
approximately 30% were classiﬁed into their
original
category.
The devised classiﬁcation scheme performs better for other two
proposed grouping schemes as shown in Table 2.
Fig. 3.
Overall classiﬁcation quality of ODP.
Table 2
Overall classiﬁcation results of root categories.
Grouping scheme/classiﬁcation category
CATID
FATHERID
GENERAL
Positive
4.4
8.5
8.3
Negative
10.6
6.5
6.7
Number of categories
15
15
15
% positive classiﬁcation
30
56
55
12
Gensim generated TF-IDF weighting scheme ﬁle.
13
Documents in comparison model whose similarity to the analyzed document is
below set similarity value.
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
6311
This shows the potential of using ODP as a universal taxonomy
and suggests that
the classiﬁcation quality directly depends on
how the data is prepared and grouped together.
Although these results can be interpreted as not sufﬁcient when
we provide additional
constraints for each grouping scheme and
limit
the number of
documents included in testing models we
get a better overview of the nature of ODP and its data. This over-
view suggests that ODP based classiﬁcation models provide a good
basis for overall content classiﬁcation when limiting the number of
documents included in classiﬁcation models. For all three grouping
schemes several
model
size families have been devised to test
models with different document numbers.
The results are shown
in Fig.
4 and presented in detail in Table 3.
When it comes to number of documents used in generated clas-
siﬁcation models evaluation results show that
percentage-based
models are behaving subpar and actually, due to the different num-
ber of documents they are made of, increase the amount of noise in
the created models.
Limit based models provide far better results
and their use in future research is suggested by these results.
As
far as used grouping scheme is concerned, CATID grouping scheme
yields the worst results once again, but this time independently to
the number of documents used in classiﬁcation models. FATHERID
and GENERAL grouping schemes perform below par when used in
combination with percentage models but yield better results when
used in combination with limit
models.
Additionally,
as
the
number of documents used in classiﬁcation models increases clas-
siﬁcation results worsen.
It is easy to deduce that the grouping
scheme is not
the only factor
in achieving good classiﬁcation
results but is additionally improved when limiting number of doc-
uments used for classiﬁcation models.
Our evaluation results sug-
gest that smallest classiﬁcation models are to be used for overall
classiﬁcation as they include enough information for good overall
classiﬁcation with GENERAL grouping scheme models providing
best results (100%).
4.2.
Choosing best grouping scheme for automatic labeling
The goal of this process is to ﬁnely tune the classiﬁcation and to
apply automatic labels to the active document,
as well as to test
the quality of ODP as a possible labeling scheme.
In this step only
labels from the most similar category, as classiﬁed in previous sec-
tion,
are used.
Evaluation is based on the same steps and data as
used in previous section.
The IR measures used are calculated on
the ratio between tested document(s) (input value) and returned
most similar document (output value). Compared values are either
for database ﬁelds ‘catid’
or ‘fatherid’,
depending on the grouping
scheme used (CATID and FATHERID respectively). Evaluation results
are presented and discussed next.
First we determine which of the proposed grouping schemes is
best used in the process of
automatic labeling.
Overall
labeling
Fig. 4.
Overall classiﬁcation quality of ODP with different grouping schemes.
Table 3
Overall classiﬁcation results of root categories with different grouping schemes.
Grouping
CATID
FATHERID
GENERAL
Result
Positive
Negative
Positive
Negative
Positive
Negative
Percentage models
25
1
14
1
14
1
14
50
1
14
1
14
1
14
75
1
14
1
14
1
14
100
1
14
1
14
1
14
Limit models
1000
11
4
14
1
15
0
2500
5
10
15
0
13
2
5000
6
9
13
2
13
2
7500
8
7
13
2
12
3
10,000
6
9
13
2
12
3
20,000
4
11
13
2
14
1
6312
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
results,
for different grouping schemes,
are shown in Table 4.
The
results show that,
grouping scheme wise,
the differences between
different grouping schemes are small but only for the P value. The
results for other two measures,
Recall
and F1,
indicate that the
GENERAL grouping scheme based models are to be used for auto-
matic labeling. They are followed by CATID and FATHERID grouping
scheme based models.
A more detailed look gives us a better insight into the suggested
scheme.
As far as the number of model documents to be used for
automatic labeling is concerned,
as presented in Fig.
5 and shown
in detail in Table 5,
the proposed Percentage models are returning
poor results as far as R and F1 measures are concerned,
while P
measure results are satisfactory.
The results are conclusive across
all
three grouping schemes and the best performing percentage
model (100% percentage model) is performing worse than the worst
performing limit model (20,000 limit documents).
Limit models proved to yield better results for automatic label-
ing. Differences between different limit models ﬂuctuate. The best
limit model results,
as shown in Table 5,
are given for limit model
7500 and GENERAL grouping scheme with all
other limit models
performing better than percentage models. The results are promis-
ing as far as the process of automatic labeling is concerned. These
results will be used in future research dealing with ODP-based con-
tent labeling.
5. Result analysis and future work
The objectives of this study were to test ODP as the proposed
universal
taxonomy for
classiﬁcation and automatic
labeling.
Such a taxonomy is used in the domain of recommender systems
when dealing with multiple sources, each with its own information
structure.
Such a classiﬁcation can be achieved in two steps; ﬁrst,
unclassiﬁed document is classiﬁed in one of
15 root categories
identiﬁed in ODP and secondly additional
categorization labels
are attached to the analyzed document.
Due to the structure of
ODP there are several
possibilities for organizing its content for
classiﬁcation and labeling
models.
Our
research presents
an
in-depth look in to the best way of grouping ODP data together
and optimal number of documents in created classiﬁcation models.
For these purposes three grouping scheme and two model
size
families
have been devised.
Based on evaluation results,
best
Table 4
Best grouping scheme evaluation for automatic labeling (overall).
Grouping scheme/IR measures
CATID
FATHERID
GENERAL
Precision
0.92617
0.904447
0.92037
Recall
0.60799
0.21546
0.91859
F1
0.70016
0.31114
0.91651
Fig. 5.
Best grouping scheme evaluation.
Table 5
Best grouping scheme for automatic labeling detailed results.
Grouping
CATID
FATHERID
GENERAL
Model size
IR measure
P
R
F1
P
R
F1
P
R
F1
Percentage models
25
0.867
0.258
0.372
0.918
0.151
0.238
0.906
0.914
0.908
50
0.881
0.366
0.491
0.850
0.110
0.178
0.758
0.777
0.763
75
0.885
0.431
0.553
0.787
0.082
0.136
0.874
0.872
0.866
100
0.891
0.482
0.596
0.711
0.070
0.117
0.978
0.962
0.966
Limit models
1000
0.984
0.871
0.920
0.988
0.345
0.480
0.993
0.986
0.989
2500
0.973
0.817
0.883
0.988
0.239
0.365
0.995
0.988
0.990
5000
0.967
0.762
0.840
0.978
0.237
0.352
0.996
0.990
0.993
7500
0.956
0.732
0.815
0.966
0.283
0.395
0.997
0.991
0.993
10,000
0.944
0.718
0.799
0.942
0.331
0.440
0.996
0.988
0.991
20,000
0.915
0.643
0.733
0.918
0.305
0.411
0.987
0.968
0.973
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
6313
grouping and size models have been identiﬁed both for classiﬁca-
tion as well as labeling steps.
Such an extensive ODP analysis has
not been found in the reviewed literature.
When it comes to the classiﬁcation step ﬁrst the overall
ade-
quacy
of
ODP
as
the
proposed
taxonomy
was
evaluated.
Evaluation tested if an original document will be classiﬁed in the
originating category or if it will
be classiﬁed as a member of an
alternative category.
Possible categories were 15 root categories
left after ODP data preparation.
The results show that,
as far as
the overall
classiﬁcation quality of ODP is concerned,
evaluation
results depend on the used grouping scheme and additionally to
the number of documents used in classiﬁcation model. Best results
are achieved when using GENERAL grouping scheme model based
on 1000 documents from ODP.
When it comes to the second step,
automatic
labeling,
same
labeling models
regarding grouping
scheme and size limits are used.
The purpose of this evaluation is
to determine the best grouping scheme and size limitation combi-
nation for automatic labeling.
The results show that limit models
perform better than percentage models in all
cases and that the
best
performing model
is based on GENERAL grouping scheme
and 7500 documents.
This is expected as percentage models take
different
number of
documents in consideration while creating
labeling models.
Limit models on the other hand use the same
number of documents for labeling models.
When compared with
related and reviewed work, our classiﬁcation approach and created
models achieve better results both for overall classiﬁcation (with
our best performing classiﬁcation model achieving 100% precision)
as well
as automatic labeling (99,7).
We have to stress out that
these results are achieved when evaluating on ODP testing data.
Although current results are satisfactory for two of three pro-
posed grouping schemes there is room for improvement by using
additional
content preparation techniques (e.g.
n-gram notation
with n > 1). Additionally, we can, based on achieved results deduce
that frequency based analysis is not the best approach for this web
directory. Besides additional steps in preparing ODP’s content LDA
can be used as the basis for classiﬁcation models. Next to IR we can
also test different machine learning techniques as used in the sev-
eral
reviewed articles.
One analysis that is missing is algorithm
performance in terms of speed of execution.
Although our results
are satisfactory there are several
news taxonomies that one can
use in addition to ODP such as Wikidata
14
,
DBpedia
15
ontology
and other dictionaries to create better performing models when clas-
sifying actual
news items.
The results of
this research are imple-
mented as part of the system RecommendMe
16
.
References
Amini,
B.,
Ibrahim,
R.,
Othman,
M.
S.,
& Nematbakhsh,
M.
A.
(2015).
A reference
ontology
for
proﬁling
scholar’s
background knowledge
in recommender
systems.
Expert Systems with Applications,
42(2),
913–928.
Baeza-Yates,
R.,
& Ribeiro-Neto,
B.
(1999).
Modern information retrieval.
Addison
Wesley.
Bird, S., Klein, E., & Loper, E. (2009). Natural language processing with Python. O’Reilly
Media.
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. The Journal of
Machine Learning Research,
3,
993–1022.
Borges,
H.,
& Lorena,
A.
(2010).
A survey on recommender systems for news data.
Smart Information and Knowledge Management,
129–151.
Cowie, J., & Lehnert, W. (1996). Information extraction. Communications of the ACM,
39(1),
80–91.
Duong,
T.
H.,
Uddin,
M.
N.,
& Nguyen,
C.
D.
(2013).
Personalized semantic search
using ODP:
A study case in academic domain.
In:
Lecture notes in computer
science (including subseries lecture notes in artiﬁcial intelligence and lecture notes
in bioinformatics) (vol.
7975 LNCS (Part 5),
pp.
607–619).
Fathy, N., Gharib, T. F., Badr, N., Mashat, A. S., & Abraham, A. (2014). A personalized
approach for
re-ranking search results
using user
preferences.
Journal
of
Universal Computer Science,
20(9),
1232–1258.
Greenwood,
M.
(2001).
Implementing a vector space document retrieval
system.
Dcs.shef.ac.uk.
Ha,
J.,
Lee,
J.-H.,
Jang,
W.,
Lee,
Y.-K.,
& Lee,
S.
(2014).
Toward robust classiﬁcation
using the open directory project.
In:
2014 International
conference on data
science and advanced analytics (DSAA) (pp.
607–612).
He,
L.,
Jia,
Y.,
Ding,
Z.,
& Han,
W.
(2013).
Hierarchical
classiﬁcation with a topic
taxonomy via LDA.
International
Journal
of
Machine Learning and Cybernetics,
5(4),
491–497.
Hu, C., Zong, X., Lee, C., & Yeh, J. (2003). World wide web usage mining systems and
technologies.
Systemics,
Cybernetics and Informatics,
1(4),
53–59.
Kalinov, P., Stantic, B., & Sattar, A. (2010). Building a dynamic classiﬁer for large text
data collections. In H. T. Shen & A. Bouguettaya (Eds.). Proceedings of the twenty-
ﬁrst australasian conference on database technologies – Volume 104 (ADC ’10) (Vol.
104,
pp.
113–122).
Darlinghurst,
Australia: Australian Computer Society,
Inc..
Lee,
J.-H.,
Ha,
J.,
Jung,
J.-Y.,
& Lee,
S.
(2013).
Semantic contextual advertising based
on the open directory project.
ACM Transactions on the Web,
7(4),
24:1–24:22.
Marath,
S.
T.,
Shepherd,
M.,
Milios,
E.,
& Duffy,
J.
(2014).
Large-scale web page
classiﬁcation.
In: 2014 47th Hawaii
international
conference on system sciences
(pp.1813–1822).
Miller, G. a. (1995). WordNet: A lexical database for english. Communications of the
ACM,
38(11),
39–41.
Pedregosa,
F.,
Varoquaux,
G.,
Gramfort,
A.,
Michel,
V.,
Thirion,
B.,
Grisel,
O.,
et al.
(2011).
Scikit-learn: Machine learning in Python.
Journal
of
Machine Learning
Research,
12,
2825–2830.
Perkins,
J.
(2010).
Python text processing with NLTK 2.0 cookbook (First ed.).
Packt
Publishing.
Perugini,
S.
(2008).
Symbolic links
in the open directory project.
Information
Processing & Management,
44(2),
910–930.
Porter, M. F. (2006). An algorithm for sufﬁx stripping. Program: Electronic Library and
Information Systems,
40(3),
211–218.
Rajalakshmi, R., & Aravindan, C. (2013). Web page classiﬁcation using n-gram based
URL features.
2013 ﬁfth international conference on advanced computing (ICoAC)
(Vol.
263,
pp.
15–21).
IEEE.
R
ˇ
ehu
˚
r
ˇ
ek,
R.,
& Sojka,
P.
(2004).
Software framework for topic modelling with large
corpora. In Proceedings of LREC 2010 workshop new challenges (pp. 45–50). ELRA.
Robertson,
S.
(2004).
Understanding inverse document frequency: On theoretical
arguments for IDF.
J.
Doc.,
60(5),
503–520.
Salton,
G.
(1975).
A theory of
indexing.
Regional
conference
series
in applied
mathematics (Vol.
18).
Society for industrial and applied mathematics (SIAM).
Salton, G. (1979). Mathematics and information retrieval. Journal of Documentation,
35(1),
1–29.
Salton,
G. (1983). Introduction to modern information retrieval. Mcgraw-Hill College.
Salton,
G.,
& Lesk,
M.
E.
(1968).
Computer
evaluation of
indexing and text
processing.
Journal of the ACM,
15(1),
8–36.
Salton,
G.,
Wong,
A.,
& Yang,
C.-S.
(1975).
A vector space model
for automatic
indexing.
Communications of the ACM,
18(11),
613–620.
Van Rijsbergen, C. J. (1979). Information retrieval. MA, USA: Butterworth-Heinemann
Newton.
Vargiu,
E.,
Giuliani,
A.,
& Armano,
G.
(2013).
Improving contextual advertising by
adopting collaborative ﬁltering.
ACM Transactions
on the Web (TWEB),
7(3),
1–22.
Yun, J., Jing, L., Yu, J., & Huang, H. (2012). A multi-layer text classiﬁcation framework
based on two-level
representation model.
Expert
Systems
with Applications,
39(2),
2035–2046.
Zhu, D., & Dreher, H. (2010). Characteristics and uses of labeled datasets – ODP case
study.
In Proceedings – 6th international conference on semantics,
knowledge and
grid,
SKG 2010 (pp.
227–234).
IEEE.
Zubiaga,
A.,
& Ji,
H.
(2013).
Harnessing web page directories
for
large-scale
classiﬁcation of
tweets.
In WWW’13
companion proceedings
of
the
22nd
international conference on World Wide Web companion (pp.
225–226).
14
https://www.wikidata.org/.
15
http://dbpedia.org/.
16
http://rec.foi.hr:5000.
6314
J.
Ševa et al. / Expert Systems with Applications 42 (2015) 6306–6314
