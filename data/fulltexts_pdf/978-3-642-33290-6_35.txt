Evaluating the Use of Clustering
for Automatically Organising
Digital Library Collections
Mark Hall
1,2
, Paul Clough
2
, and Mark Stevenson
1
1
Department for Computer Science, Sheﬃeld University, Sheﬃeld, UK
(m.mhall,r.m.stevenson)@sheffield.ac.uk
2
Information School, Sheﬃeld University, Sheﬃeld, UK
p.d.clough@sheffield.ac.uk
Abstract.
Large digital
libraries have become available over the past
years through digitisation and aggregation projects.
These large collec-
tions present a challenge to the new user who wishes to discover what is
available in the collections.
Subject classiﬁcation can help in this task,
however in large collections it is frequently incomplete or inconsistent.
Automatic clustering algorithms provide a solution to this, however the
question remains whether they produce clusters that are suﬃciently co-
hesive and distinct for them to be used in supporting discovery and ex-
ploration in digital
libraries.
In this paper we present a novel approach
to investigating cluster cohesion that is based on identifying instruders
in a cluster.
The results from a human-subject experiment show that
clustering algorithms produce clusters that are suﬃciently cohesive to
be used where no (consistent) manual classiﬁcation exists.
1
Introduction
Large digital libraries have become available over the past years through digiti-
sation and aggregation projects. These large collections present two challenges to
the new user [22]. The ﬁrst is resource discovery: ﬁnding the collection in the ﬁrst
place.
The second is then discovering what items are present in the collection.
In current systems,
support for item discovery is mainly through the standard
search paradigm [27], which is well suited for professional (or expert) users who
are highly familiar with the collections,
subject areas,
and have speciﬁc search
goals.
However,
for the novice (or non-expert) user exploring,
investigating,
and
learning [16,21]
tend to be more useful
search modalities.
To support these
modalities the items in the collection must be classiﬁed according to a relatively
consistent schema, which is frequently not the case.
In many domains no standard classiﬁcation system exists and, even if it does,
collections are often classiﬁed inconsistently. Additionally, where collections have
been formed through aggregation (e.g. in large-scale digital libraries) the items
will
frequently be classiﬁed using diﬀerent and incompatible classiﬁcation sys-
tems.
Manual
(re-)classiﬁcation would be the ideal
solution,
however the time
P. Zaphiris et al. (Eds.): TPDL 2012, LNCS 7489, pp. 323–334, 2012.
c
 Springer-Verlag Berlin Heidelberg 2012
324
M. Hall, P. Clough, and M. Stevenson
and expense requirement when dealing with hundreds of thousands or millions
of items means that it is not a viable approach.
Automatic clustering techniques provide a potential solution that can be ap-
plied to large-scale collections where manual
classiﬁcation is not feasible.
The
advantage of these techniques is that they automatically derive the cluster struc-
ture from the digital library’s items. On the other hand the quality of the results
can be variable and thus the choice of which clustering technique to employ is
central to providing an improved exploration experience.
The research questions posed at the start of this work was: Do automatic clus-
tering techniques produce clusters that are cohesive enough to be used to support
the exploration of digital libraries? We deﬁne a cohesive cluster as one in which
the items in the cluster are similar, while at the same time clearly distinguishable
from items in other clusters. Our paper provides two major contributions in this
area. Firstly,
we propose a novel variant of the intruder detection task [6]
that
enables the measurement of
the cohesion of
automatically generated clusters.
Secondly, we apply this task to evaluate the cluster model
quality of a number
of automatic clustering and topic modelling algorithms.
Our results show that the clusters are suﬃciently good to be used in digital
libraries where manually assigned classiﬁcations are not available or not con-
sistent.
The remainder of
the paper is structured as follows:
The next section
provides background information on the use of
clustering in digital
libraries,
their evaluation, and the clustering techniques evaluated in this paper. Section 3
describes the methodology used in the evaluation experiment and section 4 the
experiment results. Section 5 concludes the paper.
2
Background
The issues large, aggregated digital libraries present to the user were ﬁrst high-
lighted in [22]
who suggested manual
classiﬁcation by the user and automated
clustering as approaches for dealing with the large amounts of information pro-
vided by these digital libraries. Since then a number of digital library exploration
interfaces based on clustering documents [26,9,8] and search results [11,28] have
been proposed. Most of these approaches were evaluated in task-based scenarios
and shown to improve task performance, however the cluster quality itself was
not evaluated.
2.1
Cluster Evaluation Metrics
Cluster evaluation has traditionally focused on automatic evaluation metrics.
They are frequently tested on synthetic or manually pre-classiﬁed data [17,1]
or using statistical
methods [29,13].
However,
these do not necessarily capture
whether the resulting clusters are cohesive from the user’s perspective.
There have been attempts at using human judgments to quantify the cohesion
of automatic clustering techniques. Mei et al. [18] evaluate the cohesion of Latent
Dirichlet Allocation topics in the context of automatically labelling these topics.
