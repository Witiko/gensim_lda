Incorporação de representação vetorial distribuída
de palavras e parágrafos na classificação de SMS
SPAM
Raul Freire Aguiar
∗
,
Ronaldo Cristiano Prati
∗
Centro de Matemática,
Computação e Cognição(CMCC)
Universidade Federal do ABC (UFABC)
Santo André,
SP,
Brasil
{f.raul,ronaldo.prati}@ufabc.edu.br
Resumo—A classificação automática de SMS spam é um pro-
blema desafiador,
pois ao contrário de outros documentos (como
e-mails,
por
exemplo),
esses
textos
são extremamente
curtos,
com no máximo 140 caracteres.
Além disso,
eles normalmente
são
escritos
utilizando
gírias,
abreviaturas
e
símbolos
como
emoticons.
Técnicas
de pré-processamento tem sido aplicadas
para contornar esse problema, como o uso de dicionários de gírias
e desambiguação de contexto.
Entretanto,
os benefícios advindos
de técnicas baseadas em dicionário são limitados,
uma vez que
apenas termos dicionarizados são pré-processados. Neste trabalho
investigamos o uso da combinação de técnicas tradicionais com
informação advinda de redes
neurais
recentemente propostas,
que criam uma representação vetorial
distribuídas de palavras
e parágrafos.
Essas
técnicas
são capazes
de capturar relações
semânticas não triviais,
e que podem ser usadas para melhorar
a classificação automática de SPAMS.
Resultados experimentais
mostram que a técnica é bastante competitiva com o uso de dici-
onários,
e que podem agregar informações adicionais relevantes
para a classificação de SMS spam.
I.
I
NTRODUÇÃO
Aplicações que lidam com envio de mensagens instantâneas,
do inglês Short
Message Service (SMS) e nacionalmente co-
nhecido como torpedos, tem aumentado significativamente nos
últimos anos principalmente em plataformas como celulares e
tablets, devido a sua simplicidade de utilização e baixo custo.
Esse tipo de mensagem é ideal
para pessoas que gostam de
se comunicar com outras pessoas ou em grupos de maneira
prática e rápida.
Elas também são adequadas para ambientes
barulhentos ou que requerem silêncio,
nos quais uma ligação
por voz não é confortável. O envio de mensagens instantâneas
através
de celulares
ou tablets
se tornou bastante popular
em alguns
países
por
permitir
envios
para
um ou vários
destinatários, e por serem mais baratas do que as ligações por
voz.
Nas últimas duas décadas, o serviço de envios de SMS vêm
se tornando um enorme negócio.
De acordo com o relatório
da empresa Portio Research
1
,
os
serviços
de comunicação
instantâneas estão se movendo em direção à plataforma móvel.
1
Mobile
Messaging
Futures
2014-2018.
Disponível
em
http://www.portioresearch.com/en/messaging-reports/mobile-messaging-
research/mobile-messaging-futures-2014-2018.aspx
(acessado
em
30/08/2015).
Em 2014 foram registrados 6,85 bilhões de assinaturas móveis
contra apenas 1,16 bilhões de telefonia fixa e entre 2011 a
2014 o mundo ganhou 983 milhões de assinaturas móveis e
perdeu 47 milhões de assinaturas de telefonia fixa. Enxerga-se
claramente que a telefonia fixa ainda não se tornou obsoleta,
mas certamente se tornou menos popular
com o passar
dos
anos.
Em 2014 o faturamento anual
com mensagens móveis
movimentou 173 bilhões
de
dólares,
sendo que
a
receita
estimada ao longo dos anos de 2014-2018 é de mais de 1,279
trilhões de dólares.
A popularidade do SMS atingiu também o meio comercial.
São diversas as empresas que se utilizam deste serviço como
meio de propaganda e soluções em mobilidade corporativa.
Segundo a empresa Zenvia
2
são mais
de 4.500 pequenas,
médias e grandes empresas de diversos setores no Brasil que
movimentam cerca de 3 bilhões de SMS ao ano,
com mais
de 100 milhões de brasileiros impactados por seus serviços.
Segundo dados fornecido pela mesma empresa,
mensalmente
são enviados 250 milhões de mensagens indesejáveis (spams)
via SMS.
Levando em consideração que o País possui
272
milhões de linhas ativas,
a maioria dos clientes de telefonia
móvel
são perturbados com mensagens fora de seu interesse.
SMS spam, também chamados de spam móvel ou SMS pirata,
é o nome atribuído a qualquer
mensagem de texto recebida
indesejadamente.
As mensagens de spam via SMS,
além de serem desagra-
dáveis,
podem causar uma série de problemas aos usuários e
às prestadoras de serviços móvel.
Segundo a empresa Zenvia,
estima-se que a proliferação de SMS pirata provoque prejuízos
anuais na ordem de 200 milhões de reais para as operadoras
móveis brasileiras.
A prática é de difícil
controle,
haja vista
que as operadoras podem bloquear
o número usado,
mas o
praticante da ilegalidade pode facilmente comprar
um novo
número e recomeçar
o ciclo.
Muitos
esforços
estão sendo
realizados no controle e combate ao spam via SMS.
Sabe-
se também que a filtragem automática de SMS spam ainda
está em seus
passos
iniciais
no cenário mundial,
pois
no
2
Zenvia Mobile Results.
Disponível
em http://www.zenvia.com.br/blog/,
acessado em 30/08/2015
mercado encontra-se poucas opções de software disponíveis.
Sendo assim, empresas recomendam que seus usuários sempre
denunciem o recebimento indesejado de mensagens de texto,
enquanto uma solução definitiva para diminuir o problema não
é encontrada.
Da mesma maneira que as empresas de telefonia,
no meio
acadêmico também há muitas
dificuldades
na pesquisa do
controle e prevenção de SMS spam.
Uma das preocupações
é
que
filtros
consolidados
para
bloquear
spam via
e-mail
vêm apresentando desempenho degradado quando aplicados
na filtragem de SMS spam.
Isso ocorre devido ao tamanho
limitado das mensagens,
que possuem apenas 140 bytes,
o
que representa 160 caracteres (para algumas línguas em que
é possível
codificar caracteres com 7 bits).
Além disso,
tais
mensagens
são geralmente
repletas
de
erros
de
digitação,
gírias,
símbolos,
emoticons,
e abreviações,
que tornam até
mesmo a tokenização uma tarefa difícil [1].
Devido a essas peculiaridades, diversas abordagens tem sido
utilizadas com o intuito de pré-processar as mensagens antes
de aplicar técnicas de classificação automática de SMS spam.
Essas abordagens incluem o uso de expansão de gírias por
meio de dicionários de gírias,
e desambiguação de contexto
de palavras.
Em [1],
por
exemplo,
esse pré-processamento
é feito com base em dicionários
de gírias
e de conceitos.
Apesar
da
melhora
de
desempenho reportada,
abordagens
baseadas em dicionários são pouco flexíveis, pois dependem de
atualizações dos dicionários utilizados.
Essas abordagens não
lidam bem com novas abreviaturas, jargões, termos específicos
e problemas de grafia, além de dependerem da disponibilidade
de dicionários para a língua na qual os SMS são escritos.
Neste contexto,
esta pesquisa tem como objetivo investigar
o uso de técnicas
de processamento de língua natural
que
não dependem de dicionário,
e que também são capazes de
tratar termos similares,
gírias e contexto diretamente a partir
do vocabulário (não necessariamente ortograficamente correto)
presente nas mensagens.
Mais especificamente,
investigamos
o uso de representação vetorial
distribuída de palavras e pa-
rágrafos recentemente proposta [2] para o pré-processamento
prévio de SMS para a classificação automática de SMS spams.
O restante deste artigo está organizado da seguinte maneira:
na Seção II
são apresentados alguns trabalhos que também
tratam da classificação de SMS spams.
Na Seção III
são
introduzidos os conceitos de representação vetorial distribuída
de palavras e parágrafos gerados pelos modelos Word2Vec e
Doc2Vec,
respectivamente.
Uma discussão qualitativa do uso
de técnicas baseadas em dicionários e representação vetorial
é feina na Seção IV.
Na Seção V é apresentado o desenho
experimental,
e na Seção VI
os resultados.
Finalmente,
na
Seção VII, são apresentadas as considerações finais e possíveis
desdobramentos deste trabalho.
II.
T
RABALHOS RELACIONADOS
A quantidade
de
SMS gerados
diariamente
é
impressi-
onante,
o que torna impossível
qualquer
tarefa manual
de
filtragem de spam.
Sendo assim,
abordagens de classificação
automáticas para detecção de spam móvel estão sendo desen-
volvidas entre os pesquisadores baseados nos bons resultados
obtidos pelas abordagens de classificação de spam via e-mails.
Entretanto, comparado à classificação de spam em mensagens
de correio eletrônico,
ainda existem poucos
trabalhos
para
filtragem de SMS spam.
A seguir,
são descritos alguns do
trabalhos mais recentes relacionados com este artigo.
Em [3] foi verificado que ao contrário do spam via e-mail,
a tarefa de classificar
spams móveis é bastante desafiadora
devido às mensagens serem mais curtas.
O trabalho é uma
extensão de [4] e envolve a tentativa de identificar o autor de
determinado texto afim de expandir os recursos para melhorar
a aprendizagem pelos classificadores.
Os autores propuseram
uma abordagem de aprendizado supervisionado para classifica-
ção de spam SMS utilizando o quadro de entropia máxima [5]
e consideraram que todas
as
mensagens
enviadas
possuem
apenas
dois
tipos:
spam ou não spam (ham).
Os
autores
concluem que existem diferenças no estilo de escrita de cada
tipo de mensagem, e através destas características foi possível
realizar inferências estatísticas e melhorar o desempenho dos
classificadores.
Em [6]
os
autores
propuseram um modelo simples
de
índices que calculam a pontuação de palavras baseadas em
uma função de frequência.
O modelo verifica a ocorrência
de diferentes características em ambos dados de treinamento,
spam e ham.
A abordagem usa índices
invertidos
para o
acesso e atualização rápida,
e concluem que o modelo de
índices derivado da análise léxica do conteúdo e cabeçalho
da mensagem fornece bom desempenho de filtragem.
Em [7] e [8] é apresentada uma nova base de dados pública
chamada de SMS Spam Collection,
criada a partir
de uma
comparação de desempenho entre 13 classificadores de apren-
dizagem supervisionada.
O corpus possui
5.574 mensagens,
sendo 747 spam e 4827 ham.
Dois métodos de tokenização
foram testados; um tokenizador que separa qualquer caractere
diferente de caracteres alfanuméricos e pontuações como vír-
gula, traço, ponto, etc, e uma combinação que tokeniza nomes
de domínios e endereços eletrônicos. Os autores concluem que
o SVM Linear é o classificador que apresenta melhor resultado
de desempenho para comparações futuras.
Entre os trabalhos mais recentes que envolveram a mesma
baseline proposta por
[7]
e [8]
encontram-se os
trabalhos
de [1],
[9]
e [10].
Em [9]
as
mensagens
não spam (ham)
correspondem a mensagens correntes e positivas e os autores
propõem uma filtragem de spam baseado na frequência do
conjunto de
itens
em uma
base
de
dados.
A filtragem é
realizada em 3 tipos de bases para captação de características
positivas sob certo suporte mínimo em conjunto de dados ham.
Após a expansão do conjunto de características positivas,
o
mesmo processo é feito em conjunto de dados sem rótulo afim
de encontrar a frequência de novos itens,
classificando-os em
positivos ou negativos utilizando os algoritmos multinominal
naïve Bayes [11],
Random Forest
[12]
e LibSVM [13].
A
principal
conclusão foi
que o método atinge melhor
estabi-
lidade em acurácia e F-scores quando o conjunto de dados
positivos é pequeno em comparação com os métodos Spy-
EM [14] e PEBL [15]. O uso de métodos semi-supervisionado
melhorou o desempenho dos classificadores,
entretanto para
conjuntos de itens maiores o método não apresentou resultados
relevantes. Em [10] os autores fazem um estudo do algoritmo
de aprendizagem de máquina naïve Bayes e propõem uma
pequena modificação na função de cálculo de frequência do
algoritmo Apriori.
Como resultado,
concluem que o modelo
modificado oferece melhor desempenho em acurácia,
compa-
rado à utilização corrente do algoritmo naïve Bayes.
Dentre os trabalhos analisados, é frequente a tentativa de es-
tender os recursos para oferecer maior quantidade de informa-
ção ao classificador.
Como mencionado anteriormente,
parte
se deve aos erros de digitação e tamanho reduzido de uma
mensagem SMS.
Dessa forma,
os autores em [1] propuseram
diversas maneiras de estender o conteúdo de uma mensagem
utilizando dicionário de gírias e técnicas de desambiguação
baseada em dicionários de conceitos. Apesar da melhora de de-
sempenho reportada, como descrito anteriormente, abordagens
baseadas em dicionários são pouco flexíveis.
Elas dependem
de atualizações dos dicionários utilizados, não lidam bem com
novas abreviaturas, jargões, termos específicos e problemas de
grafia,
e são limitados à língua daqueles dicionários.
Nesse contexto, seria interessante investigar o uso de ferra-
mentas que também agregam informações de similaridades se-
mânticas, mas que independem de dicionários. Nossa proposta
inclui investigar o uso de redes neurais capazes de criar repre-
sentações vetoriais distribuídas de termos e documentos [2],
pois como concluem [16], elas são um método computacional
eficiente para o aperfeiçoamento e aprendizagem de similari-
dades semânticas em documentos. Esse método computacional
é descrito na próxima seção.
III.
G
ERAÇÃO DE REPRESENTAÇÃO VETORIAL
DISTRIBUÍDA DE PALAVRAS E PARÁGRAFOS USANDO O
W
ORD
2V
EC E
D
OC
2V
EC
A representação vetorial de documentos textuais, conhecida
como modelo espaço-vetorial
(VSM,
do inglês Vector Space
Model
[17]),
cria representações vetoriais a partir
de docu-
mentos textuais. A representação é conhecida como sacola de
palavras (BOW, do inglês Bag of Words), em que a ordem das
palavras no documento é desconsiderada,
e a representação
vetorial é criada a partir da presença ou ausência de termos, ou
baseada na frequência absoluta ou relativa desses termos, como
a tf-idf
(term frequency–inverse document
frequency)
[18],
[19].
Esses vetores podem ser
usados como atributos em uma
grande quantidade de aplicações,
tais como recuperação de
informação [20],
classificação de documentos [21],
filtragem
de SMS spam [1],
entre outros.
Recentemente,
[2]
propuseram o modelo Word2Vec,
uma
maneira alternativa de representar palavras como um vetor de
valores reais.
Esse modelo tem atraído bastante atenção da
comunidade [22], [23]. O modelo consiste em criar representa-
ções vetoriais de palavras utilizando técnicas de redes neurais,
e fornece duas arquiteturas eficientes de implementação, sendo
elas uma baseada em Bag-of-Words,
cujo objetivo é prever a
probabilidade de um termo ocorrer,
baseado em uma janela
de
palavras
próximas
e
o Skip-Gram,
em que
procura-se
maximizar
a predição de quais termos ocorrem próximas a
um determinado termo.
Um aspecto interessante
dessa
abordagem é
que
ela
é
capaz de capturar aspectos semânticas e sintáticos com uma
granularidade fina,
por
meio de operações aritméticas veto-
riais simples.
Cada palavra é representada por
um vetor
n
-
dimensional
(
n
é um parâmetro definido pelo usuário,
ge-
ralmente entre 100 e 300).
Além disso,
palavras usadas em
contextos similares,
e que teriam um significado semântico
parecido,
tendem a se concentrarem em uma mesma região
do espaço. Outra característica e algumas relações semânticas
não triviais tendem a ter uma orientação e norma similares,
permitindo que se possa aplicar
algebra vetorial
na análise
desses termos.
Na Figura 1 é apresentado um exemplo,
adapatado de [2],
que
ilustra
esse
conceito.
Nessa
figura,
são representados
em um plano bi-dimensional
os
vetores
(linhas
pontilha-
das,
em cinza)
para
os
termos
homem
,
mulher
,
rei
e
rainha
.
Na Figura 1a,
em azul,
estão destacados
os
ve-
tores
homem
→
mulher
e
rei
→
rainha
.
Observe que os
dois tem uma interpretação semântica parecida (
homem
está
para
mulher
assim como
rei
está para
rainha
),
e que
os vetores tem uma orientação e normas parecidos.
Na Fi-
gura 1b é ilustrada a operação
rei
-
homem
+
mulher
.
O resultado dessa operação corresponde ao vetor
rainha
.
Exemplos na página web da ferramenta
1
e de uma técnica
similar
2
mostram que relações desse tipo emergem em vários
cenários quando treinados com dados suficientes,
como rela-
ções homem-mulher,
empresa-diretor,
cidade-CEP (código de
endereçamento postal),
comparativo-superlativo,
entre outros.
Entretanto,
de acordo com [24],
a utilização da representa-
ção vetorial de palavras ou termos para tarefas de aprendizado
de
máquina
sofre
com algumas
desvantagens,
pois
essas
representações não levam em conta o contexto semântico de
frase existente,
apenas o de palavras.
Nessas representações a
ordem dos vetores de palavras em uma frase é perdida. Dessa
maneira, frases com significados diferentes podem ter a mesma
representação se as mesmas palavras forem utilizadas. Apesar
de ser
possível
usar
a técnica de
n
-gramas para considerar
a ordem das palavras em pequenos contextos,
ela sofre de
dispersão de dados e alta dimensionalidade.
Em [24] é proposto o modelo Doc2Vec,
uma estrutura não
supervisionada que aprende representações vetoriais distribuí-
das em pedaços de textos.
Os textos podem ser de tamanhos
variados que vão desde sentenças e parágrafos à documentos.
O modelo Doc2Vec é complementar ao Word2vec.
Contudo,
ele leva em consideração o contexto semântico de frase no
qual uma palavra está inserida.
No modelo Doc2Vec, tanto termos quanto as frases também
são representados por um vetor
n
-dimensional.
Na etapa de
treinamento, ambos os tipos de vetores são atualizados. Os ve-
1
https://code.google.com/p/word2vec/
2
http://nlp.stanford.edu/projects/glove/
x
1
x
2
Homem
Mulher
Rei
Rainha
(a) Representação vetorial de termos gera-
dos pelo modelo word2vec
x
1
x
2
Homem
Mulher
Rei
Rainha
(b) Operações aritméticas vetoriais captu-
ram aspectos sintáticos e semânticos
Figura 1: Exemplo de representação vetorial criada pelo word2vec. Estão representados os vetores dos termos
homem
,
mulher
,
rei
e
rainha
.
Observe que em (a),
a orientação e norma do
homem
→
mulher
é a mesma de
rei
→
rainha
,
e em (b) a
operação vetorial rei-homem+mulher = rainha (adaptado de [2])
tores de palavras tem o mesmo papel no modelo Word2Vec, e
são compartilhados entre todas as frases/parágrafos. Já o vetor
de cada frase/parágrafo atua como uma memória, que captura
o que está faltando no contexto daquela frase/parágrafo.
Depois
de treinados,
os
vetores
de parágrafo podem ser
usadas como atributos daquele documento,
por exemplo,
em
substituição ou concatenado ao vetor
BoW.
Esses
vetores
podem então serem usados como entrada de algoritmos de
aprendizado de máquina para a construção de classificadores
ou agrupamentos,
por exemplo.
Uma importante vantagem de vetores de parágrafo é que
eles são gerados a partir de dados não rotulados,
e que por
esse motivo podem trabalhar bem em tarefas em que há poucos
dados rotulados.
Vetores de parágrafo também atenuam algu-
mas das desvantagens de modelos BoW.
Primeiramente,
eles
herdam uma propriedade importante dos vetores de palavras: a
semântica das palavras. Como descrito anteriormente, palavras
com semântica semelhantes tendem a ficarem próximas no
espaço de descrição de palavras.
Além disso,
eles capturam
alguns aspectos do contexto de frase da ordem das palavras, o
que é difícil de incorporar no modelo BoW. Apesar de ser pos-
sível usar um modelo de
n
-gramas para tentar capturar alguns
desses aspectos,
essa abordagem tende a criar representações
esparsas e com alta dimensionalidade.
Uma outra vantagem é que os vetores podem ser construídos
diretamente
a
partir
dos
tokens
que
aparecem nos
textos,
independentemente de estarem gramaticalmente corretos,
ou
serem palavras dicionarizadas.
Dessa maneira,
gírias,
siglas,
abreviações e emoticons são tratados diretamente como termos
válidos.
Além disso,
os modelos são independente da língua.
A desvantagem é que requerem uma grande quantidade de
dados para aumentar a convergência dos modelos.
IV.
T
RATAMENTO SEMÂNTICO BASEADO EM DICIONÁRIO
versus
REPRESENTAÇÃO VETORIAL DISTRIBUÍDA
O principal
objetivo desse trabalho é avaliar
se o uso da
representação vetorial
distribuída,
como discutido na seção
anterior,
é capaz de agregar
informação útil,
codificada nos
vetores de documentos,
para a classificação de SMS spams.
A hipótese
é
que
essa
informação pode
agregar
aspectos
semânticos não triviais,
não capturados pela abordagem bag
of words.
Trata-se,
portanto,
de um objetivo semelhante ao avaliada
em [1],
mas
utilizando uma estratégia diferente.
Em [1]
é
utilizado o dicionário de Lingo (gírias, abreviações, símbolos,
etc) para a língua inglesa noSlang
3
para traduzir termos Lingo.
A abordagem consiste em consultar um dicionário de palavras
gramaticalmente corretas da língua inglesa
4
se o termo está
presente no dicionário, e caso ele não seja encontrada, verificar
se está presente no dicionário de Lingo. Se estiver presente no
dicionário de Lingo,
é feita a substituição do termo pelo seu
sinônimo.
Para fazer uma normalização semântica,
os termos
após
a
tradução de
Lingo são consultados
no repositório
BabelNet, e o processo descrito em [25] é usado para encontrar
o conceito mais relevante associado àquele termo,
segundo o
método de desambiguação.
Esse método utiliza técnicas de
análise semântica e contextual para atribuir notas aos possíveis
conceitos retornados pelo repositório BabelNet,
e seleciona o
conceito com maior
nota.
A nota é baseada no calculo de
distâncias na rede semântica do BabelNet.
No exemplo dado no artigo,
os
autores
ilustram que o
termo plz,
que é uma abreviatura comum para “please”,
é
3
disponível em http://www.noslang.com/dictionary/
4
foi
utilizado o dicionário Freeling,
disponível
em http://nlp.lsi.upc.edu/
freeling/
Tabela I: Relações de similaridade encontradas pelo Doc2Vec
termo
termos similares
ok
okay,
okie,
blah,
yup
nigeria
tron,
mca,
england
year
goodmorning,
week,
day
tell
ask,
gave,
messaged,
bothering,
send
nice
delicious,
womderfull,
shame,
little,
silly
good
great,
gr8,
warm,
wonderful
love
promise,
miiiiiiissssssssss,
wish,
boytoy,
adore,
force,
dare
corretamente traduzida para o inglês padrão para please. Esse
termo corresponde a cinco diferente conceitos no dicionário
BabelNet
5
,
e na mensagem plz let
me know when you got
there,
sendo um deles selecionado de acordo com o método
de desambiguação.
Apesar
dos resultados reportados em [1]
mostrarem uma
vantagem dessa normalização e expansão semântica de termos
dentro do contexto de classificação de SMS spams,
ela é
baseada no uso de dicionários,
tanto na fase de detecção de
Lingo quando na normalização semântica.
Isso pode ser uma
desvantagem importante,
especialmente em um contexto de
SMS.
Somente palavras que efetivamente aparecem nos dici-
onários serão tratadas,
e geralmente somente apenas relações
de polissemia e sinonímia são tratadas.
O uso de métodos independentes de dicionários podem ame-
nizar algumas dessas limitações. Para ilustrar esse conceito, na
Tabela I são mostrados alguns exemplos de termos similares
que ocorrem entre os 10 mais próximos do termo na coluna da
esquerda no modelo gerado utilizando o Doc2Vec.
Como os
vetores de termos e parágrafos são tratados da mesma maneira,
vetores de parágrafos foram retirados da lista dos 10 similares.
Também foram retirados os termos que ocorrem uma única vez
na coleção,
pois eles representam ruído.
Devido a essas duas
remoções, não são mostrados os 10 termos mais similares, mas
apenas o subconjunto restante.
Analisando a tabela,
podemos
notar
diversas
ocorrências
que não seriam capturadas por abordagens baseadas em dici-
onários. Para o termo ok, por exemplo, somente o termo okay
seria considerado similar na abordagem baseada em dicionário,
pois somente ele aparece no dicionário de Lingo.
Okie é uma
gíria que aparece algumas vezes na base,
mas ela não está
dicionarizada.
Yup aparece no dicionário de Lingo como sim
(yes),
e blah aparece três
vezes
na mesma mensagem que
aparece uma ocorrência de okie. Para os termo nigeria e year,
os
termos
mais
similares
ocorrem na base com o sentido
de lugar e tempo,
respectivamente,
e as relações não seriam
capturadas por dicionários. Para os termo nice, vários adjetivos
foram encontrados como termos similares,
inclusive um com
a grafia incorreta (que não seria capturado por dicionários) e
uma gíria que aparece no dicionário de Lingo.
Para o termo
love,
aparecem vários termos correlacionados mas que não
seriam capturados por dicionários.
5
v. Give pleasure to or be pleasing to; v. Be the will of or have the will (to);
v.
Give satisfaction; v.
Make happy or satisfied; adj.
Used in polite request;
V.
D
ESENHO EXPERIMENTAL
Para avaliar a viabilidade do uso de representação vetorial
distribuída
na
classificação automática
de
SMS spam foi
utilizada a base de dados pública SMS Spam Collection [7],
[8].
Essa base também foi utilizada em [1],
e é composta por
5.574 mensagens escritas na língua inglesa,
sendo 747 spam
e 4827 ham.
As mensagens foram tokenizadas utilizando o mesmo toke-
nizador descrito em [7],
[8] o qual
separa qualquer caractere
diferente de caracteres alfanuméricos e pontuações como traço,
ponto,
vírgula,
etc..
Para a criação da representação vetorial
distribuída de termos e parágrafos foi
utilizada a implemen-
tação do Doc2Vec disponível
na biblioteca de modelagem
semântica de textos
gensim [26].
A dimensionalidade dos
vetores foi fixada em 300 (valor padrão). Como as mensagens
são curtas e o número de mensagens é relativamente pequeno,
a frequência mínima de poda de termos foi
fixada em um.
O parâmetro taxa
inicial
de
aprendizado (
α
)
foi
ajustada
empiricamente para 0.025.
Os demais parâmetros não foram
alterados,
e usados com valores padrão da ferramenta.
Para
a
realização dos
experimentos
com algoritmos
de
aprendizado de máquina foi utilizado o pacote de aprendizado
de máquina Scikit-learn [27].
Os algoritmos de aprendizado
utilizado para induzir os classificadores estão listados na Ta-
bela II. Os algoritmos marcados com um asterisco (*) também
foram utilizados em [1],
e são diretamente comparáveis.
Os
algoritmos marcados com dois asteriscos (**)
são similares
a algoritmos utilizados em [1]
mas não são os mesmos,
e
portanto não diretamente comparáveis. Em particular, CART-e
é similar ao algoritmo de árvore decisão J48 (reimplementação
do C4.5 dentro do WEKA), mas tem critérios de parada e poda
diferentes. CART também é um algoritmo baseado em árvore
de decisão,
mas usa o índice gini
ao invés da entropia como
critério de escolha de atributos para crescimento da árvore.
Como Bagging e Boosting usam como base o algoritmo de
árvore de decisão, eles também são similares e não diretamente
comparáveis.
BernoulliBN e GaussianNB são duas
versões
do naïve Bayes
que usam as
distribuições
de Bernoulli
e
Gaussiana para estimar
a distribuição de probabilidade para
atributos
contínuos.
A versão do WEKA,
usada
em [1],
discretiza atributos
contínuos.
PAC,
RF e SGD não foram
utilizados em [1]. O único algoritmo utilizado em [1] que não
foi
utilizado em nossos experimentos foi
o PART,
que não
tinha uma versão implementada ou similar no Scikit-learn.
Os experimentos foram realizados utilizando validação cru-
zada com cinco partições. Para comparar os resultados, utiliza-
mos o Coeficientede Correlação de Matthews (Matthews Cor-
relation Coefficient
-
MCC
),
que avalia a qualidade de uma
classificação binária.
O
MCC
leva em consideração as taxas
de verdadeiros e falsos positivos,
e é geralmente aceita como
uma medida balanceada,
e que pode ser
usada mesmo em
problemas com classes desbalanceadas.
O
MCC
retorna um
valor entre -1 e 1, no qual um coeficiente igual a 1 indica uma
classificação perfeita;
0 aleatória e -1 classificação inversa.
O
MCC
pode ser
calculado pela Equação 1,
em que
T P
,
Tabela II:
Algoritmos de aprendizado de máquina utilizados
nos experimentos
Nome
Descição
(*)1-NN
k
-vizinhos mais próximos,
com
k = 1
(*)3-NN
k
-vizinhos mais próximos,
com
k = 3
(*)5-NN
k
-vizinhos mais próximos,
com
k = 5
(**)Bagging
meta-classificador Bagging
(**)B.CART
meta-classificador
Boosting,
que usa árvore de de-
cisão e divisão por
índice Gini
como classificador
base
(**)B.CART-e
meta-classificador Boosting,
que usa o CART e di-
visão por entropia como classificador base
(**)BernoulliNB
Naïve Bayes
com kernel
Bernoulli
para atributos
contínuos
(**)CART
árvore de decisão e divisão por índice Gini
(**)CART-e
árvore de decisão e divisão por entropia
(**)GaussianNB
Naïve Bayes com kernel
Gaussiano para atributos
contínuos
(*)Logistic
Regressão Logística
PAC
Online Passive-Aggressive
RF
Florestas Aleatórias (Random Forests)
SGD
Stochastic gradient descent
(**)SVC
Support Vector Machines usando liblenar
(*)SVM
Support Vector Machines usando libSVM
F P
,
T N
e
FN
representam as taxas de verdadeiros/falsos
positivos/negativos,
respectivamente.
Esse número de folds e
métrica de avaliação foram escolhidas pois foram os mesmos
utilizados em [1].
MCC =
TP × TN − FP × FN
p
(T P + F P )(T P + F N)(T N + F P )(T N + F N)
(1)
Como entrada dos algoritmos de aprendizado foi
utilizada
a concatenação da contagem BoW tf-idf
com os vetores de
cada mensagem,
calculados pelo Doc2Vec.
Utilizamos duas
versões das mensagens: (a) sem nenhum tratamento e (b) com
a expansão de termos a partir
do dicionário de Lingo,
que
corresponde a primeira etapa utilizada em [1]. Não foi aplicada
a segunda etapa de expansão de conceitos
e normalização
pois em [1] esse processo não está bem detalhado (os autores
mencionam que
reportaram os
melhores
resultados
de
10
combinações possíveis,
mas nào é descrita qual
é a melhor
combinação).
VI.
R
ESULTADOS E DISCUSSÃO
Os métodos de classificação descritos na Tabela II
foram
aplicados
à
concatenação da
tabela
BoW com os
vetores
de
cada
mensagem obtidos
pelo Doc2Vec,
como descrito
na
Seção V.
Inicialmente
comparamos
com os
resultados
reportados em [1], que usa o pacote Weka [28] para a execução
dos algoritmos de aprendizado.
Na Tabela III são apresentados os valores médios de MCC
para as cinco execuções da validação cruzada para os algorit-
mos de aprendizado diretamente comparáveis — aqueles mar-
cados com (*) na Tabela II.
Para efeitos de comparação,
são
reproduzidos os resultados de [1] para os mesmos algoritmos,
que estão destacados em cinza tabela.
Analisando a tabela,
é
possível observar que os resultados obtidos pela concatenação
da tabela Bow com os vetores do Doc2Vec,
proposta neste
artigo, obtiveram os melhores resultados tanto na base original
quanto na base expandida.
Também é possível
observar que
no método proposto a diferença entre usar ou não a expansão
é pequena,
o que é um indicativo que,
ao se concatenar
os
vetores do Doc2Vec,
a expansão é menos efetiva.
Tabela III:
Comparação do MCC obtido pela concatenação
da tabela BoW com os vetores gerados pelo Doc2Vec com
os
resultados
reportados
em
[1]
-
algoritmos
diretamente
comparáveis.
Classificador
MCC
Dicionário [1]
Bow + Doc2Vec
Orig.
Exp.
Orig.
Exp.
1-NN
0,771
0,800
0,864
0,871
3-NN
0,572
0,707
0,853
0,851
5-NN
0,448
0,595
0,826
0,825
Logistic
0,638
0,715
0,890
0,888
SVM
0,929
0,927
0,930
0,933
Na Tabela IV é apresentada uma comparação da abordagem
proposta neste artigo com algoritmos similares usados em [1]
(esses
resultados
estão novamente destacados
em cinza na
tabela).
Apesar
de não diretamente comparáveis,
é possível
notar que a abordagem proposta apresenta resultados compa-
tíveis com os reportados em [1].
As abordagens baseadas em
árvores de decisão,
tanto puras quanto usadas conjuntamente
com boosting, tiveram um desempenho inferior. Uma possível
explicação é que os parâmetros padrão do Scikit-learn não são
adequados ao problema.
Já o bagging teve um desempenho
ligeiramente superior.
O naïve Bayes com kernel
Gaussiano
teve um resultado ruim,
mas a versão com o kernel Bernoulli
foi
superior ao naïve Bayes do Weka.
Observe também que,
novamente,
a
diferença
entre
os
resultados
com e
sem a
expansão é pequena, quando utilizamos a abordagem proposta.
Além das comparações com os resultados reportados em [1],
também analisamos outros aspectos da abordagem proposta.
A primeira delas
é se,
uma vez que a concatenação dos
vetores criados pelo Doc2Vec são capazes de capturar aspectos
semânticos,
se a expansão de Lingo é necessária.
Para isso,
aplicamos o teste estatístico de Mann-Whitney,
comparando
o
MCC
obtido pela abordagem proposta a partir
da base
original e da base com a expansão de Lingo. Esses resultados
estão listados
na
Tabela V,
com a
respectiva
diferença e
ranking entre os algoritmos.
Tabela IV: Comparação do MCC obtido pela concatenação da
tabela BoW com os vetores gerados pelo Doc2Vec com os
resultados reportados em [1] - algoritmos similares.
Dicionário [1]
Bow + Doc2Vec
Classificador
MCC
Classificador
MCC
Orig.
Exp.
Orig.
Exp.
Bagging
0,833
0,840
Bagging
0,857
0,859
B.C4.5
B.CART
0,842
0,842
0,915
0,922
B.CART-e
0,849
0,836
C4.5
CART
0,787
0,817
0,802
0,838
CART-e
0,711
0,756
SMO
0,929
0,927
SVC
0,929
0,929
NB
BernouliNB
0,901
0,889
0,864
0,870
GaussianNB
0,677
0,632
Tabela V: MCC médio obtido por cada um dos classificadores
nas
bases
original
e expandida.
Diferença entre resultados
obtidos usando as duas bases de dados e posição (rank)
do
algoritmo no teste Mann-Whitney.
(BoW + Doc2Vec)
Classificador
MCC
Diferença
Rank
Orig.
Exp.
GaussianNB
0,677
0,632
0,045
1.5
CART-e
0,711
0,756
-0,045
1.5
CART
0,787
0,817
-0,030
3
RF
0,689
0,673
0,016
4
B.CART-e
0,849
0,836
0,013
5
BernoulliNB
0,901
0,889
0,012
6
1-NN
0,864
0,871
-0,007
7
SGD
0,926
0,920
0,006
8
SVM
0,930
0,933
-0,003
9
Logistic
0,890
0,888
0,002
11
3-NN
0,853
0,851
0,002
11
Bagging
0,857
0,859
-0,002
11
5-NN
0,826
0,825
0,001
12
SVC
0,929
0,929
0,000
14
PAC
0,919
0,919
0,000
14
B.CART
0,842
0,842
0,000
14
Como pode ser observado, na maioria dos casos, a diferença
é positiva (isto é,
não realizar
a expansão de Lingo é me-
lhor).
Para a aplicação do teste de Mann-Whitney [29],
essas
diferenças devem ser
ordenadas (em módulo)
e ranqueadas.
Para a realização do teste,
compara-se a soma das posiçoes
com diferenças positivas (
R
+
), com a soma das posições com
diferenças negativas (
R
−
), que é 58,5 e 31,5, respectivamente.
Com esses valores,
no entanto,
não é possível afirmar que há
uma diferença estatisticamente significativa entre usar ou não
o dicionário Lingo. Além disso, o melhor resultado médio foi
obtido pelo SVM na base de dados com a expansão Lingo.
Como nem todos os algoritmos utilizados neste trabalho
são diretamente comparáveis aos resultados de [1], realizamos
também uma comparação dos classificadores disponíveis no
Scikit-learn utilizando apenas o a contagem tf-idf
da aborda-
gem BoW com a concatenação do BoW e os vetores gerados
pelo Word2Vec. Esses resultados são mostrados na Tabela VI.
Um ponto a ser destacado é que os resultados obtidos utili-
zando apenas a abordagem BoW para 1-NN,
3-NN,
5-NN e
a regressão logística são consideravelmente melhores que os
reportados em [1]. Realizamos também uma checagem dupla,
exportando nossa base de dados para o formato de entrada do
Weka e utilizando os mesmos algoritmos disponíveis naquela
biblioteca para comparação, e os resultados foram comparáveis
aos
reportados
em [1].
Isso indica que,
mesmo sendo os
mesmos algoritmos, há diferenças entre as implementações do
Weka e do Scikit-learn que estão influenciando nos resultados.
Essa diferença precisa ser melhor estudada no futuro.
Também aplicamos o teste de Friedman [29] para verificar
se existem diferenças
significativas
entre a base original
e
a base expandida com o dicionário de Lingo,
bem como
a abordagem BoW e Bow concatenado com os vetores do
Word2Vec.
O teste de Friedman foi
escolhido pois é reco-
mendado para a avaliação de multiplos classificadores com
multiplas bases [29].
Os resultados do teste estão mostrados
Tabela VI:
MCC médio na base original
e com expansão
de Lingo para a abordagem BoW e BoW concatenada com
Word2Vec
Original
Expandido
Classificador
Bow+W2V
Bow
Bow+W2V
Bow
1-NN
0,864
0,895
0,871
0,895
3-NN
0,853
0,878
0,851
0,874
5-NN
0,826
0,863
0,825
0,856
Baggging
0,857
0,862
0,859
0,865
B.CART
0,842
0,883
0,842
0,884
B.CART-e
0,849
0,894
0,836
0,879
BernouliNB
0,901
0,901
0,889
0,889
CART
0,787
0,841
0,817
0,846
CART-e
0,711
0,829
0,756
0,831
GaussianNB
0,677
0,677
0,632
0,632
Logistic
0,890
0,803
0,888
0,805
PAC
0,919
0,923
0,919
0,916
RF
0,689
0,844
0,673
0,852
SGD
0,926
0,923
0,920
0,910
SVC
0,929
0,916
0,929
0,909
SVM
0,930
0,919
0,933
0,915
no diagrama de diferenças críticas, representado pela Figura 2.
Nesse diagrama,
os algoritmos estão ordenados,
e uma linha
une valores estatisticamente semelhantes.
Os resultados indi-
cam que não há diferenças significativas entre as abordagens,
mas a abordagem BoW concatenada com Word2Vec tem uma
ligeira vantagem sobre a BoW sozinha.
Figura 2: Diagrama de diferenças críticas comparando o MCC
obtido a partir
da base original
e da base com expansão
de Lingo para a abordagem BoW e BoW concatenada com
Word2Vec
VII.
C
ONCLUSÃO
Neste artigo analisamos
o uso de representação vetorial
distribuída baseado em redes
neurais
e para problemas
de
classificação conhecido como filtragem de SMS spam que
tem como principal desafio,
incorporar informações úteis aos
classificadores em situações com poucos atributos,
curtas,
e
repletas de gírias e erros ortográficos.
Para este desafio,
propomos a utilização do Doc2Vec que
além de capturar similaridades semânticas e sintáticas, é capaz
de agregar informações úteis codificadas em vetores de docu-
mentos.
Nossa abordagem apresentou resultados comparáveis
e superiores nos principais classificadores em comparação com
estudos
recentes
de problemas
de filtragem de SMS spam
utilizando uma baseline pública e real e abordagem semelhante
que a utilizada em [1].
No entanto,
é importante ressaltar que
o método utilizado tem melhor desempenho quando o corpus
é grande.
Foram analisados os desempenhos obtidos pelos principais
classificadores e comparados com os resultados de [1].
Fi-
nalmente,
a análise estatística e comparativa indicou que a
utilização do Doc2Vec pode dispensar
esforços
computaci-
onais
em expandir
o conjunto de sentenças
que dependem
diretamente da atualização frequente dos dicionários utilizados
que além de serem poucos flexíveis e de não lidar bem com
novas abreviaturas, jargões, termos específicos e problemas de
grafia, são totalmente limitados à língua daqueles dicionários.
Trabalhos
futuros
pretende-se estudar
o desempenho do
Doc2Vec em outros problemas de classificação de textos, bem
como outras maneiras de combinar a abordagem BoW com os
vetores obtidos a partir do Doc2Vec.
A
GRADECIMENTOS
Este trabalho foi
desenvolvido com o apoio financeiro da
CAPES.
R
EFERÊNCIAS
[1]
T.
P.
Silva,
I.
Santos,
T.
A.
Almeida,
and J.
M.
GomezHidalgo,
“Normalização textual e indexação semântica aplicadas na filtragem de
sms spam,” in Anais do XI Encontro Nacional de Inteligência Artificial
e Computacional (ENIAC’14),
2014.
[2]
T.
Mikolov,
K.
Chen,
G.
Corrado,
and J.
Dean,
“Efficient estimation of
word representation in vector space,” 2013.
[3]
D.-N. Sohn, J.-T. Lee, K.-S. Han, and H.-C. Rim, “Content-based mobile
spam classification using stylistically motivated features,” in Pattern
Recognition Letters,
vol.
33,
no.
3,
2012,
pp.
364–369.
[4]
D.-N.
Sohn,
J.-T.
Lee,
and H.-C.
Rim,
“The contribution of
stylistic
information
to
content-based
mobile
spam filtering,”
in
ACLShort
’09 Proceedings of
the ACL-IJCNLP 2009 Conference Short
Papers,
2009,
pp.
321–324.
[Online].
Available:
http://dl.acm.org/citation.cfm?
id=1667682
[5]
A.
L.
Berger,
V.
J.
D.
Pietra,
and S.
A.
D.
Pietra,
“A maximum
entropy
approach
to
natural
language
processing,”
Computational
Linguistics,
vol.
22,
no.
1,
pp.
39–71,
1996.
[Online].
Available:
http://dl.acm.org/citation.cfm?id=234289
[6]
W.
Liu and T.
Wang,
“Index-based online text
classification for
sms
spam filtering,” Journal of Computers, vol. 5, no. 6, pp. 844–851, 2010.
[7]
T.
A.
Almeida,
J.
M.
G.
Hidalgo,
and A.
Yamakami,
“Contributions
to the study of
sms
spam filtering:
new collection and results,” in
Proceedings of
the 11th ACM symposium on Document
engineering.
Mountain View,
California,
USA:
ACM,
2011,
pp.
259–262.
[Online].
Available: http://dx.doi.org/10.1145/2034691.2034742
[8]
J.
M.
G.
Hidalgo,
T.
A.
Almeida,
and A.
Yamakami,
“On the validity
of a new sms spam collection,” in Machine Learning and Applications
(ICMLA).
Boca Raton,
FL,
USA: IEEE,
2012,
pp.
240–245.
[Online].
Available: http://dx.doi.org/10.1109/ICMLA.2012.211
[9]
I.
Ahmed,
R.
Ali,
D.
Guan,
Y.-K.
Lee,
S.
Lee,
and T.
Chung,
“Semi-
supervised learning using frequent
itemset
and ensemble learning for
sms classification,” Expert Systems with Applications,
vol.
42,
no.
3,
p.
1065–1073,
2014.
[10]
I. Ahmed, D. Guan, and T. C. Chung, “Sms classification based on naive
bayes classifier
and apriori
algorithm frequent
itemset,” International
Journal of machine Learning and computing, vol. 4, no. 2, p. 183, 2014.
[11]
F.
Peng,
D.
Schuurmans,
and S.
Wang,
“Augmenting naive bayes clas-
sifiers with statistical
language models,” Information Retrieval,
vol.
7,
no.
3–4,
pp.
317–345,
2004.
[12]
L.
Breiman,
“Random forests,” Machine Learning,
vol.
45,
no.
1,
pp.
5–32,
2001.
[13]
C.-C.
Chang
and
C.-J.
Lin,
“Libsvm:
A library
for
support
vector
machines,”
ACM Transactions
on
Intelligent
Systems
and
Technology
(TIST),
vol.
2,
no.
27,
2011.
[Online].
Available:
http://dl.acm.org/citation.cfm?doid=1961189.1961199
[14]
B. Liu, W. S. Lee, P. S. Yu, and X. Li, “Partially supervised classification
of text documents,” in Proceedings of the 19th ICMLC.
San Francisco,
CA,
USA: Morgan Kaufmann Publishers Inc,
2002,
pp.
8–12.
[15]
H.
Yu,
J.
Han,
and K.-C.
Chang,
“Pebl:
Web page
classification
without negative examples,” in Knowledge and Data Engineering, IEEE
Transactions on,
vol.
16.
IEEE,
2004,
pp.
70–81.
[16]
A.
Sanborn and J.
Skryzalin,
“Deep learning for semantic similarity,”
in
CS224d:
Deep
Learning
for
Natural
Language
Processing.
Stanford,
CA,
USA:
Stanford University,
2015.
[Online].
Available:
http://cs224d.stanford.edu/reports.html
[17]
G.
Salton,
A.
Wong,
and C.
S.
Yang,
“A vector
space model
for
automatic indexing,” Commun.
ACM,
vol.
18,
no.
11,
pp.
613–620,
1975.
[Online].
Available: http://doi.acm.org/10.1145/361219.361220
[18]
S.
Robertson,
“Understanding
inverse
document
frequency:
on
theoretical
arguments
for
IDF,” Journal
of
Documentation,
vol.
60,
no.
5,
pp.
503–520,
2004.
[Online].
Available:
http://dx.doi.org/10.
1108/00220410410560582
[19]
M.
Soares,
R.
Prati,
and M.
Monard,
“Improvement
on the porter
´
s
stemming algorithm for portuguese,” Latin America Transactions, IEEE
(Revista IEEE America Latina),
vol.
7,
no.
4,
pp.
472–477,
Aug 2009.
[20]
C.
D.
Manning,
P.
Raghavan,
and H.
Schütze,
Introduction to informa-
tion retrieval.
Cambridge University Press,
2008.
[21]
F.
Sebastiani,
“Machine
learning in automated text
categorization,”
ACM Comput. Surv., vol. 34, no. 1, pp. 1–47, 2002. [Online]. Available:
http://doi.acm.org/10.1145/505282.505283
[22]
J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors for
word representation,” Proceedings of the Empiricial Methods in Natural
Language Processing (EMNLP 2014),
vol.
12,
pp.
1532–1543,
2014.
[23]
L.
Wolf,
Y.
Hanani,
K.
Bar,
and N.
Dershowitz,
“Joint
word2vec
networks for bilingual
semantic representations,” International
Journal
of Computational Linguistics and Applications, vol. 5, no. 1, pp. 27–44,
2014.
[24]
Q.
V.
Le and T.
Mikolov,
“Distributed representations
of
sentences
and documents,” in Proceedings of
the 31th International
Conference
on Machine Learning,
ICML 2014,
Beijing,
China,
21-26 June 2014,
ser.
JMLR Proceedings,
vol.
32.
JMLR.org,
2014,
pp.
1188–1196.
[Online].
Available: http://jmlr.org/proceedings/papers/v32/le14.html
[25]
R.
Navigli
and S.
P.
Ponzetto,
“Multilingual
WSD with just
a few
lines of
code:
the babelnet
API,” in The 50th Annual
Meeting of
the
Association for Computational
Linguistics Proceedings of
the System
Demonstrations,
July 10,
2012,
Jeju Island,
Korea,
2012,
pp.
67–72.
[Online].
Available: http://www.aclweb.org/anthology/P12-3012
[26]
R.
ˇ
Reh˚
u
ˇ
rek and P.
Sojka,
“Software Framework for
Topic Modelling
with Large Corpora,” in Proceedings of
the LREC 2010 Workshop on
New Challenges for NLP Frameworks.
Valletta,
Malta:
ELRA,
May
2010,
pp.
45–50,
http://is.muni.cz/publication/884893/en.
[27]
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Gri-
sel,
M.
Blondel,
P.
Prettenhofer,
R.
Weiss,
V.
Dubourg,
J.
Vanderplas,
A.
Passos,
D.
Cournapeau,
M.
Brucher,
M.
Perrot,
and E.
Duchesnay,
“Scikit-learn:
Machine learning in Python,” Journal
of
Machine Lear-
ning Research,
vol.
12,
pp.
2825–2830,
2011.
[28]
R.
R.
Bouckaert,
E.
Frank,
M.
A.
Hall,
G.
Holmes,
B.
Pfahringer,
P.
Reutemann,
and I.
H.
Witten,
“WEKA -
experiences with a java
open-source project,” Journal
of
Machine Learning Research,
vol.
11,
pp. 2533–2541, 2010. [Online]. Available: http://portal.acm.org/citation.
cfm?id=1953016
[29]
J.
Demsar,
“Statistical
comparisons
of
classifiers
over
multiple data
sets,” Journal
of
Machine Learning Research,
vol.
7,
pp.
1–30,
2006.
[Online].
Available: http://www.jmlr.org/papers/v7/demsar06a.html
