Bann, E. Y. (2013) Undergraduate Dissertation: Semantic 
Clustering of Basic Emotion Sets. Other. Department of 
Computer Science, University of Bath, Bath.
Link to official URL (if available): 
Opus: University of Bath Online Publication Store
http://opus.bath.ac.uk/
This version is made available in accordance with publisher policies. 
Please cite only the published version using the reference above.
See http://opus.bath.ac.uk/ for usage policies. 
Please scroll down to view the document.
Department of
Computer Science
Technical Report
Undergraduate Dissertation: Semantic Clustering of Basic
Emotion Sets
Eugene Yuta Bann
Technical Report 2013-01
January 2013
ISSN 1740-9497
Copyright
c
January 2013 by the authors.
Contact Address:
Department of Computer Science
University of Bath
Bath, BA2 7AY
United Kingdom
URL: http://www.cs.bath.ac.uk
ISSN 1740-9497
Discovering Basic Emotion Sets via
Semantic Clustering on a Twitter Corpus
Eugene Yuta Bann
eugene@aeir.co.uk
Bachelor of Science in Computer Science with Honours
The University of Bath
May 2012
This dissertation may be made available for consultation within the Uni-
versity Library and may be photocopied or lent to other libraries for the
purposes of consultation.
Signed:
Eugene Yuta Bann
Discovering Basic Emotion Sets via
Semantic Clustering on a Twitter Corpus
Submitted by:
Eugene Yuta Bann
COPYRIGHT
Attention is drawn to the fact that copyright of this dissertation rests with its author.
The
Intellectual Property Rights of the products produced as part of the project belong to the
author unless otherwise specified below, in accordance with the University of Bath’s policy
on intellectual property (see http://www.bath.ac.uk/ordinances/22.pdf).
This copy of the dissertation has been supplied on condition that anyone who consults it
is understood to recognise that its copyright rests with its author and that no quotation
from the dissertation and no information derived from it may be published without the
prior written consent of the author.
Declaration
This dissertation is submitted to the University of Bath in accordance with the requirements
of the degree of Bachelor of Science in the Department of Computer Science.
No portion of
the work in this dissertation has been submitted in support of an application for any other
degree or qualification of
this or any other university or institution of
learning.
Except
where specifically acknowledged, it is the work of the author.
Signed:
Eugene Yuta Bann
Abstract
A plethora of words are used to describe the spectrum of human emotions, but how many
emotions are there really,
and how do they interact?
Over the past few decades,
several
theories of
emotion have been proposed,
each based around the existence of
a set of
ba-
sic emotions,
and each supported by an extensive variety of research including studies in
facial
expression,
ethology,
neurology and physiology.
Here we present research based on
a theory that people transmit their understanding of emotions through the language they
use surrounding emotion keywords.
Using a labelled corpus of over 21,000 tweets,
six of
the basic emotion sets proposed in existing literature were analysed using Latent Semantic
Clustering (LSC),
evaluating the distinctiveness of the semantic meaning attached to the
emotional
label.
We hypothesise that the more distinct the language is used to express a
certain emotion,
then the more distinct the perception (including proprioception) of that
emotion is, and thus more basic. This allows us to select the dimensions best representing
the entire spectrum of emotion.
We find that Ekman’s set,
arguably the most frequently
used for classifying emotions, is in fact the most semantically distinct overall.
Next, taking
all
analysed (that is,
previously proposed) emotion terms into account,
we determine the
optimal semantically irreducible basic emotion set using an iterative LSC algorithm.
Our
newly-derived set (Accepting, Ashamed, Contempt, Interested, Joyful, Pleased,
Sleepy, Stressed) generates a 6.1% increase in distinctiveness over Ekman’s set (Angry,
Disgusted, Joyful, Sad, Scared).
We also demonstrate how using LSC data can help
visualise emotions.
We introduce the concept of
an Emotion Profile and briefly analyse
compound emotions both visually and mathematically.
Contents
1
Introduction
1
1.1
Emotion Theories .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
1.2
Project Objectives
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
2
The Psychology of Emotion
4
2.1
Basic Emotions
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
5
2.1.1
Biologically Primitive Emotions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
5
2.1.2
Psychologically Irreducible Emotions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
6
2.2
Core Affect
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
6
2.3
The Conceptualisation of Emotion
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11
2.4
The Negativity Bias
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11
2.5
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
12
3
Lexical Emotion Extraction
14
3.1
Twitter
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
14
3.2
Sentiment Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
3.3
Emotion Recognition .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16
3.3.1
Mood Analysis
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
3.3.2
Comparison with Sentiment Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
3.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
4
Semantic Analysis
20
4.1
Semantic Space Theory
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
4.2
Latent Semantic Analysis
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
ii
CONTENTS
iii
4.2.1
Partial Singular Value Decomposition
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
4.2.2
Comparison to Non-negative Matrix Factorisation
.
.
.
.
.
.
.
.
.
.
23
4.3
Algorithm Complexity and Human Cognition .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
4.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
5
The Emotional Twitter Corpus
25
5.1
Basic Emotion Sets .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
25
5.2
Emotion Keywords
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
25
5.3
Emotion Streaming .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
5.3.1
Emotion Stream Rate
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
5.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
6
Semantic Emotion Analysis
31
6.1
DELSAR .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
31
6.1.1
Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
6.2
ELSA .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
6.2.1
Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
35
6.3
Testing Geographical Relativity .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
6.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
40
6.4.1
Fear
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
6.4.2
Applications of LSC .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
7
Visualising Emotion
43
7.1
Emotion Space
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
7.2
Emotion Profiling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
47
7.2.1
Emotion Wave
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
7.3
Emotion Equations .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
7.3.1
Method
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
7.3.2
Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
53
7.3.2.1
Depressed .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
7.3.2.2
Disgusted .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
7.3.2.3
Guilty .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
CONTENTS
iv
7.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
7.4.1
Emotion Classification and Discovery
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
58
7.4.2
Psychological Applications .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
58
7.4.2.1
Identification of Underlying Emotional Conditions
.
.
.
.
.
59
7.4.2.2
Emotional Engineering
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
59
7.4.2.3
Detecting Unconscious Stress Factors
.
.
.
.
.
.
.
.
.
.
.
.
59
7.4.2.4
Clinical Assessments .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
60
8
Conclusion
61
8.1
Summary of Contributions .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
62
9
Future Research
65
9.1
Current Project Extensions
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
65
9.2
Economic Prediction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
66
9.3
General Principle of Emotion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
66
9.4
Machine Consciousness .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
66
9.5
Epilogue .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
67
A EARL Emotion WordNet Synonyms
75
B Raw results output
77
C Code
88
C.1
Database Schema (MySQL)
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
89
C.2
Twitter Stream (PHP) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
90
C.3
DELSAR/ELSA (Python) .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95
D Appended Figures
104
List of Figures
2.1
Plutchik’s Wheel of Emotions
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7
2.2
Russell’s Circumplex Model of Affect .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
8
2.3
Watson and Tellegen’s Circumplex Theory of Affect
.
.
.
.
.
.
.
.
.
.
.
.
.
9
3.1
Discrete Emotional Response Matrix .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
5.1
Emotion Stream Rates for selected Emotion Keywords
.
.
.
.
.
.
.
.
.
.
.
.
29
6.1
Standard deviation correlated with maximum cosine values using ELSA .
.
38
7.1
Multidimensional
Scaling of DELSAR1100 Clustering Emotion Vector Co-
sine Similarities .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
7.2
Multidimensional
Scaling of DELSAR1100 Clustering Emotion Vector Co-
sine Similarities — 3D Visualisation
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48
7.3
Emotion Profile Space
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
49
7.4
Emotion Profile of Depressed, Anxious, Relaxed and Stressed .
.
.
.
.
.
.
.
50
7.5
Emotion Profile of Guilty
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
51
7.6
Similarity of primary emotion combinations to depressed .
.
.
.
.
.
.
.
.
.
.
54
7.7
Similarity of primary emotion combinations to disgusted .
.
.
.
.
.
.
.
.
.
.
55
7.8
Similarity of primary emotion combinations to guilty .
.
.
.
.
.
.
.
.
.
.
.
.
56
D.1
Similarity of primary emotion combinations to happy .
.
.
.
.
.
.
.
.
.
.
.
.
105
v
List of Tables
3.1
Comparison of Twitter Sentiment and Emotion Keyword Extraction .
.
.
.
18
5.1
Basic Emotion Sets to be analysed .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
5.2
Tracked Emotion Keywords and Filtered Phrases
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27
6.1
DELSAR1000 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
33
6.2
DELSAR Subset Analysis
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
6.3
ELSA1000 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
6.4
ELSA Subset Analysis
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
6.5
ELSA Geographical Analysis
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
6.6
Optimal ELSA Emotion Sets
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
7.1
DELSAR1100 Clustering Matrix
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
44
7.2
Symmetrical
Matrix of
DELSAR1100 Clustering Emotion Vector
Cosine
Similarities
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45
vi
List of Algorithms
1
DELSAR .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
2
ELSA .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
35
vii
Acknowledgements
I would like to thank Mr Alan Hayes and Professor James Davenport for their commitment
during my studies.
It has certainly been a roller-coaster ride!
Also thanks to Dr Radim
ˇ
Reh˚uˇrek for his helpful
comments on using Gensim,
and Professor Philip Johnson-Laird,
Professor Keith Oatley and Professor James Russell for their encouraging comments on the
project.
I am especially grateful
to Miss Stela Pashankova for her insightful
discussions,
Miss Vici Williamson for her rigorous proof reading and advice, and Miss Sarah Beckett for
planting the seed to start this research.
An extra special thanks to Dr Joanna Bryson for
her help, hard work and dedication to this project — her extensive and diverse experience in
technical writing, coupled with her interests aligned with this project has proved invaluable.
viii
Chapter 1
Introduction
There are a plethora of words to describe the spectrum of human emotion.
Many theories
are based on the existence of a set of ‘basic emotions’
that are seemingly hardwired into
our brain as individual
neurological
circuits (Watson,
1930;
Izard,
1971;
Plutchik,
1980;
Panksepp,
1982;
Gray and McNaughton,
1996),
and that all
other emotions are derived
from these ‘biological
primitives’
as either a combination or specific valence of these neu-
ral
circuits (Ortony and Turner,
1990).
Recently,
however,
the notion that emotion is a
conceptualised act has been proposed (Barrett, 2006), and experimental results have been
shown to support this hypothesis (Lindquist and Barrett, 2008).
Emotion in this sense can
be regarded in the same way as colour,
insofar we categorise and communicate discrete
colours within the confines of language,
even though colour itself is in fact a spectrum of
visible light.
Thus, discerning the psychological primaries of emotion is as fundamental as
discerning the unique hues of
red,
blue,
green and yellow in Hering’s Opponent Process
Theory of Color (Hering, 1964).
There is a long-standing view that language intrinsically shapes how people perceive and
categorise their world known as the Linguistic Relativity Hypothesis (Whorf, 1956).
How
one categorises certain concepts can be captured by the language used; findings show that
language drives the acquisition of colour categories, consistent with newer evidence showing
that emotion language influences the acquisition of emotion concepts (Lindquist, Barrett,
Bliss-Moreau and Russell, 2006).
While linguistic determinism is ubiquitously thought to
have been disproven, empirical evidence appears to be consistent with the idea that there is
indeed linguistic relativity in the perception of emotion in others (i.e.
language influences
thought and behaviour as opposed to determining it).
Specifically, it has been shown that
people of different cultures divide the affective world into different basic emotion categories
such that emotion concepts differ across cultures (Russell, 1991).
1
CHAPTER 1.
INTRODUCTION
2
1.1
Emotion Theories
In contrast to the basic emotions model,
the dimensional
model,
or core affect
(Russell,
2003) represents the entire emotion spectrum by mapping discrete emotion terms in a
multi-dimensional
space,
typically using the dimensions of
valence (the polarity of
the
emotion) and activation (the level of engagement) (for example Russell, 1980; Watson and
Tellegen, 1985).
Core affect, however, assumes that each person’s conceptualisation of each
emotion is universal.
Conceptualisation does not refer to the individual cognitive differences
of what makes one feel a particular emotion, but instead refers to individual thresholds for
labelling specific emotion qualia as a certain emotion term, and thus its relative placement
in the space.
There are several other alternative models of emotion.
Roseman, Spindel and Jose (1990)
specified event appraisals that elicit 16 discrete emotions,
dependent on cognition.
It has
been long thought that emotions follow a cognitive structure, specifically that an emotion is
elicited as a result of a valenced action, event or object (see for example Ortony, Clore and
Collins, 1988; Steunebrink, Dastani and Meyer, 2009; Turkia, 2009).
Ortony et al. (1988)
distinguishes between emotional and affective-not-emotional words, i.e.
words referring to
an affective state that are not explicit emotions,
for example,
moods (‘animosity’),
traits
(‘competitiveness’),
sensations (‘coldness’),
cognitive states (‘dazed’),
and attitude (‘de-
fensive’), building up an ontology, or a cognition-based hierarchical structure, of emotion.
Recent work in this area involves Mutual Action Histograms (MAH) (Lu, Lin, Liu, Cruz-
Lara and Hong,
2010),
in which knowing the MAH between a subject and an object in a
specific event would allow a system to reasonably estimate the emotion evoked.
However,
these models do not attempt to understand the meaning of individual
emotions,
and are
used according to their theoretical definitions within the literature.
1.2
Project Objectives
The primary objective of this project is to evaluate existing basic emotion sets to find out
which contain the most emotions expressed in the most distinct language,
testing the hy-
pothesis that the more distinct an emotion is (that is, unlike any other emotion), the more
distinct the language is used to express the experience of that emotion.
Semantics refers
to the meaning of an expression; in particular, we consider co-occurring words to measure
similarities of meaning.
We attempt to show such semantic changes in emotion language
from a corpus of explicitly expressed emotions extracted from the micro-blogging website
Twitter,
and evaluate six basic emotion sets on a scale of semantic distinctiveness,
based
on the theory that the more distinct the language is used to express a certain emotion,
then conceptually (i.e.
what we understand that emotion keyword to mean), the more psy-
chologically irreducible that emotion is.
The less semantically accurate a set of emotions
is,
the more similar these emotions are to each other,
or in other words,
if similar words
are used when expressing two different emotions, then these emotions are, in theory, con-
ceptually,
and thus psychologically,
similar.
A large majority of computer scientists tend
CHAPTER 1.
INTRODUCTION
3
to use Ekman’s basic emotion set for emotion categorisation, and it appears that, seman-
tically,
it is the most distinct set.
The secondary objective of this project is to identify a
set of basic emotions by clustering underlying semantic features of each expression within
the corpus.
We also aim to discover to what extent do the semantics of emotion language
vary according to geographical regions, thus providing empirical support for the Linguistic
Relativity Hypothesis.
Chapter 2
The Psychology of Emotion
Emotion is that which leads the subject’s condition to become so transformed that their
judgement is affected (Aristotle,
350BC),
triggered by a subconscious appraisal
process
about something that matters to the person experiencing it (Ekman,
2004).
It is char-
acterised by behavioral, expressive, cognitive, and physiological changes (Panksepp, 2000)
and can be started and executed unconsciously (Damasio, 1999).
The desire to experience
or not experience an emotion largely determines the contents and focus of consciousness
throughout the life span (Izard, 2009).
The above definition of emotion is not in the least a conclusive definition of emotion, but
takes the most important aspects from notable theorists’ definitions.
Attention is drawn to
Aristotle’s wording, stating that emotion “is that which...”, implying that emotion is in fact
a type of quale,
that is,
a subjective conscious experience that cannot be communicated,
or apprehended by any other means other than direct experience (Dennett, 1988).
Qualia
refers to subjective ‘raw feels’,
for example,
the taste of
red wine,
or the experience of
seeing the colour red.
Emotion qualia thus refers to the raw feel of an emotion; the actual
phenomenon of
a particular emotion experienced may actually differ according to each
person’s perception of
that emotion,
with perception being the result of
the individual’s
past and hypothesised responses, unique to each human being.
A useful representation of
particular emotion qualia involves the use of scripts (Russell, 1991), in which prototypical
features of each emotion are described as a list of sub-events,
or in other words using an
example-based definition,
although this too is subject to individualisation based on past
experiences.
Emotion could be thought of as a form of internal communication between organisms within
an environment.
Indeed,
Jarvilehto (2000) has proposed the theory that emotions are a
reorganisation of the organism-environment system, and that emotion and knowledge are in
fact only different aspects of the same process.
Emotion as an explicit language is different
to communicative languages as it is arguably difficult to explicitly transfer an exact emo-
tion to another person without any language taking place (i.e.
remote transfer of feelings),
although awareness of
emotional
contagion allows for it to be explicitly transferred via
4
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
5
body language, tone of language, facial expressions and so on.
Consequently, in addition to
gestures, expressions and the like, people use labels, or emotion keywords, to approximate
the combination of qualitative sensations that best describe emotion qualia to communicate
their feelings, limited to the complexity of language.
Language enables people to commu-
nicate with each other without
the need for emotion,
which,
although enabling people to
explicitly hide their true emotion, has enabled the evolution of cognitive thinking.
2.1
Basic Emotions
The dominant theory of emotion postulates the existence of a small
set of hardwired,
or
‘basic’,
emotions,
and consequently the majority of
textual
emotion recognition research
has been based on such, with Ekman, Friesen and Ellsworth’s (1972) set:
anger disgust fear joy sadness surprise
arguably being the most popular within the field of computer science for emotion mining
and classification.
However,
not only do the emotions comprising each basic emotion set
vary amongst theorists,
they do not always agree about what emotions are,
thus adding
to the confusion of what exactly are the basic emotions,
or whether they exist at all.
To
illustrate this point,
consider the emotion of
surprise:
can it be considered an emotion
if it can take the form of a negative,
neutral
or positive valence? Moreover,
consider the
emotion disgust :
the same label
is used to describe both the feeling of moral
disgust and
visceral
disgust.
This can be viewed as a problem regarding the vagueness of
language,
suggesting that there is a general
problem about how to talk about the objects (emotion
qualia) one wishes to study (Ortony and Turner,
1990).
Language is the most readily
available non-phenomenal
access we have to emotions,
although it must be noted that a
theory of emotion must not be confused with a theory of the language of emotion (Ortony
et al., 1988).
There are two viewpoints concerning the advocation of basic emotions:
they
are either biologically primitive or psychologically irreducible.
2.1.1
Biologically Primitive Emotions
Biologically primitive emotions have arisen largely from affective research with animals
(for example,
Panksepp,
1998).
Animal
researchers have created taxonomies of the basic
emotions and proposed specific neural pathways associated with each one, although human
studies confirming these findings have proved elusive.
It is argued that encephalization of
the brain during human evolution has not relocated emotional
core processes from sub-
cortical
to cortical
structures,
but has in fact expanded the penumbra of
emotional
core
processing circuitry into the upper layers of the brain, thus not replacing the basic emotional
brain that we share with other animals (Berridge,
2003).
In other words,
our emotional
brains are greater in size, but not structurally different to similar animals.
Developmental
studies assume a similar empirical
perspective to the study of
emotion as that taken by
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
6
animal models of affect insofar the behaviors of nonverbal subjects are observed and inter-
preted by researchers into specific emotional categories.
These affective behaviors, however,
are not identical
to subjective feelings,
or in other words,
eliciting an emotional
response
is not equivalent to experiencing an emotion (Posner, Russell and Peterson, 2005).
Biologically primitive emotions are also referred to as universal
emotions,
as one would
expect to find neurophysiological
or anatomical
evidence of
these hardwired emotions in
all
members of
the species (Ortony and Turner,
1990).
The most widely used method-
ology in this field establishes basic emotions by identifying their associated characteristic
facial
expressions (Darwin,
1872;
Ekman et al.,
1972).
This proposal,
however,
has been
largely discredited due to the overlap of expressive characteristics amongst seemingly basic
emotions,
resulting in the taxonomy of
facial
expressions not adequately describing the
taxonomy of emotions.
Recently,
Barrett,
Lindquist and Gendron (2007) suggest that fa-
cial
expressions are perceived relatively to the context they appear in,
such as language.
Highlighting Barrett et al.’s (2007) example,
an identical
facial
expression expressing ex-
citement could be mistaken for an expression of anger when taken out of context.
This lack
of
a universal
signature could have consequences for how clinicians are trained and also
for the security industry (for example,
classification of behaviours that determine who to
‘spot-check’).
Moreover,
it could be argued that many people can experience an emotion
without the need to express the associated facial expression, so while these people register
their feelings,
they do not necessarily or identifiably alter their facial
expression.
Facial
expressions can help identify an emotion, but an emotion cannot be classified or explained
by facial
expressions — Breazeal
(2003) calls this a perceptual
stance;
we shouldn’t be
concerned with how emotions create facial expressions,
but what information an observer
can determine from a facial expression.
2.1.2
Psychologically Irreducible Emotions
Theories of psychologically irreducible emotions postulate that all
other ‘non-basic’
emo-
tions can be created by fusing,
blending,
mixing or compounding basic emotions,
or in
other
words,
basic emotions
do not
have other
emotions
as
constituents
(Ortony and
Turner, 1990).
The most notable model in this field is Plutchik’s (1980) Wheel of Emotions
(see Figure 2.1) in which eight primary emotions, each with three levels of activation, and
eight secondary emotions that are the fusion of their two adjacent primary emotions are
defined and mapped.
While this is a popular model, no general principles of combination
are presented,
and no details are offered about the kinds of
mechanisms that might be
involved in the creation of such combinations (Ortony and Turner, 1990).
2.2
Core Affect
In contrast to the basic emotions model which treats emotions as discrete, labelled phenom-
ena, core affect — an emerging paradigm in affective neuroscience — considers a continuous
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
7
Figure 2.1:
Plutchik’s (1980) Wheel of Emotions.
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
8
Figure 2.2:
Russell’s (1980) Circumplex Model of Affect.
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
9
Figure 2.3:
Watson and Tellegen’s (1985) Circumplex Theory of Affect.
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
10
approach to defining emotions.
One of the very first empirical models of core affect is Rus-
sell’s (1980) Circumplex Model
of
Affect (CMA) (see Figure 2.2),
in which 28 discrete
emotions are mapped around a circumplex according to a study that involved each of the
emotions being classified as one of eight emotion categories, each constituting an octant of
a circumplex.
The eight categories were chosen theoretically according to two dimensions
— arousal and pleasure — and emotions were scaled around the circumplex using Princi-
pal
Component Analysis.
Another popular model
of core affect is Watson and Tellegen’s
(1985) Circumplex Theory of Affect (CTA) (see Figure 2.3), in which 38 emotions are dis-
tributed amongst four bipolar dimensions:
positive affect, negative affect, pleasantness and
engagement.
Another is Cacioppo and Berntson’s (1994) Evaluative Space Model,
which
is similar to CTA but posits that co-activation can occur, that is, that bipolar dimensions
are not negatively correlated.
All
models of core affect have one thing in common:
they represent emotion qualia as a
single integral
blend of two dimensions,
represented as a single point in the space.
Core
affect is universal,
primitive,
and irreducible to anything else psychological
— similar to
the subjective experience of temperature (Russell, 2003).
Core affect can, to some extent,
be represented in a three dimensional
space of
pleasure,
arousal,
and dominance (PAD),
typically using the Self Assessment Manikin (SAM) which asks people to rate an item (for
example, text) with respect to pleasure, arousal and dominance using an intuitive interface
(see for example Bradley, 1994).
Russell’s (1980) work also presents the three properties of the cognitive representation for
affect:
I
The pleasentness-unpleasentness and arousal-sleep dimensions account for the major
proportion of varience;
II
The dimensions descriptive of affect are bipolar;
III
Any affect word could be described as some combination of the pleasure and arousal
components.
If basic emotions are meant to be as distinct from each other as possible,
then we could
understand basic emotions to be the emotion keywords used to describe the dimensions of
the emotion spectrum.
We can modify the properties above to generate the three laws of
basic emotion sets:
I
Both positive and negative emotion subsets must cover a range of arousal levels;
II
Emotions must be able to be paired in such a way that each pair is bipolar;
III
An emotion that can be described as a combination of two or more emotions within
the set cannot be considered a basic emotion.
Armed with these laws, we are better able to evaluate potential basic emotion sets, although
we still face the problem of assuming a universal conceptualisation of emotions.
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
11
2.3
The Conceptualisation of Emotion
Barrett’s (2006) work studies the act of conceptualising core affect, or in other words, why
people attach emotion labels to the experience of
emotion qualia.
Barrett proposes the
hypothesis that emotion is a psychological event constructed from the more basic elements
of core affect and conceptual
knowledge.
In a study focusing on the conceptualisation of
fear,
it was found that neither the presence of accessible emotion concept knowledge nor
core affect alone was sufficient to produce the world-focused experience of fear (Lindquist
and Barrett,
2008).
As emotions are constructed from conceptual
knowledge about the
world, we can see that emotions themselves are in fact concepts that humans begin learning
in infancy and continuously extended and revised throughout life (Lindquist and Barrett,
2008).
This repeated experience of labelling a combination of core affect and the context
in which it occurs as an emotion provides “training” in how to recognise and respond to
that emotion — in this sense, Barrett describes emotions as “simulations”.
This “skill” of
conceptualising core affect as an emotion could be a core aspect of emotional
intelligence
— in much the same way as conceptual thinking is core to cognitive intelligence — defining
how humans deal
with their internal
state,
but more importantly,
defining the emotion
labels used as a combination of
specific experiences.
Each person’s conceptualisation of
their emotion spectrum is thus unique;
it is this conceptualisation that we attempt to
aggregate and analyse in this research.
2.4
The Negativity Bias
By mapping discrete emotion terms around a circumplex, Russell (1980) shows that basic
emotion sets are in fact a skewed representation of the entire emotion spectrum, in favour
of negatively-valanced emotions.
This implicitly supports the negativity bias in psychology
(Wason,
1959):
the tendency to use negative emotions much more than positive emo-
tions.
Particularly, it has been indicated that negative events elicit a more rapid and more
prominent response than positive events (Carreti,
Mercado,
Tapia and Hinojosa,
2001).
Recently,
it has been shown that expressed negative emotions “boosts activity” on BBC
forums (Chmiel,
Sobkowicz,
Sienkiewicz,
Paltoglou,
Buckley,
Thelwall
and Holyst,
2011),
suggesting that perhaps people’s individual
emotion circumplexes are negatively skewed.
It is thought that experiencing negative emotion serves as a call
for mental
or behavioral
adjustment (Wason, 1959), and as a result is more likely to be communicated as a way of
searching for a solution.
In contrast,
positive emotion serves as a cue to stay on course
or as a cue to explore the environment (Wason, 1959) and consequently is communicated
less.
The communication of
emotion does appear to be most beneficial
when expressing
negative emotions.
However, the negativity bias will have a negligible effect on this study
due to our focus towards the words surrounding a specific emotion keyword.
The English
language as a whole has in fact a positive bias,
with a recent study showing that 72%,
79% and 78% of words used in Twitter (which we form our corpus from),
Google Books
and New York Times articles respectively are positive words (Kloumann, Danforth, Harris,
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
12
Bliss and Dodds, 2011).
2.5
Discussion
There exist many models that have been devised over the years that aim to explain why hu-
mans experience emotions.
Emotions play a key part in human consciousness, influencing
the thoughts and actions of every human being.
Antonio Damasio points out that “people
who lack emotions because of brain injuries often have difficulty making decisions at all”
1
;
indeed,
it could be said that the combination of emotional
and cognitive information un-
derpins “rational” behaviour (De Martino, Kumaran, Seymour and Dolan, 2006).
Rational
decisions are dependent on the amount of knowledge that is available, altering perceptions
that could significantly change the decision process.
However, the actual process of making
a decision with a given amount of
knowledge is not unemotional:
making a completely
rational
decision is ultimately a positive emotion determining the course taken,
be it,
for
example,
interest,
assurance,
certainty,
the absence of negative emotions or the ‘lesser of
two evils’ (a ‘more positive’ negative emotion).
Basic emotion theorists suppose that a small
set of basic emotions are in fact inherently
within all humans regardless of individualisation.
A theory of basic emotions is a discrete
theory in which each basic emotion maps to one neural
system.
Taken individually,
bi-
ologically primitive emotion models have a strong grounding for inclusion of
constituent
emotion terms.
However, there is no consensus on the constituents of universal basic sets.
One way to define a basic emotion set could be to populate it with labels of emotion that are
present within an array of languages spanning several cultures, with the premise that the
emotions omitted are specific to culture, and thus could be ‘created’ from other, more basic
emotions.
Psychologically irreducible models of emotion describe the interplay of basic and
non-basic emotions,
but although making psychological
sense,
no empirical
evidence has
been provided to confirm the composition of these models.
The act of
conceptualising emotion treats emotions as a combination of
core affect and
conceptual knowledge, built using the same mechanisms as in cognitive learning.
Thus, we
can only understand and label emotions that we are aware of, although when we experience
new emotions in varying contexts,
we update our emotion knowledge by extrapolating to
our past experience of
a similar emotion.
With language,
we have conceptualised our
view of
emotion by the use of
discrete emotion labels that represent easy to understand
definitions of emotion qualia.
This enables humans to talk about emotions in order to share
and understand them to the extent of linguistic limitations imposed by the language used.
Emotions can be expressed in a variety of ways including facial expressions, body language,
tone of voice, and the language used in speech and text.
This project focuses on the most
explicit of these examples — the language used in communication — with the proposition
that how humans communicate to one another can reveal individual conceptualisations of
specific emotions, given that the specific emotion keyword is used within the communica-
1
http://www.usatoday.com/tech/science/discoveries/2006-08-06-brain-study x.htm
CHAPTER 2.
THE PSYCHOLOGY OF EMOTION
13
tion.
Defining basic emotions as emotions that are conceptually distinct from any other
emotion,
we explore the hypothesis that the language used in communicating basic emo-
tions should be significantly different for each one, as each basic emotion should describe a
sufficiently distinct concept.
In order to test this hypothesis, we must first collect a sample
of ‘real’ emotion data — expressions of basic emotions — by conducting Lexical Emotion
Extraction on the Internet.
Chapter 3
Lexical Emotion Extraction
Plato,
Aristotle,
Darwin,
James,
and even Ekman did not have access to the wealth of
emotional data being constantly published all over the Internet, in particular within social
networking sites.
We tap into this emotionally rich source of
information to create a
relatively large corpus of
emotional
experiences to perform our analysis on.
As we will
discuss at greater depth in section 4.3, an increase in data quantity leads to an increase in
the accuracy of results so, in theory, a corpus of over 21,000 tweets should produce a much
more accurate overall
result compared to experimental
studies using a sample of,
say 50
people.
Lexical
Emotion Extraction,
or Emotion Mining,
is a subfield of
data mining that aims
to extract emotions from text using an array of techniques.
There are numerous systems
that automatically or semi-automatically extract emotions from text for analysis, enabling
researchers to track how people are feeling with respect to a variety of indicators.
Emo-
tional
indicators have recently been demonstrated to perform more accurately than some
existing market-based predictors (Bollen, Mao and Zeng, 2011), suggesting a strong indica-
tion that emotion greatly influences the decisions people will make in the future, whether
as a consequence of self-experience or the experiences of others.
Many corpora have been
analysed including customer reviews (Turney, 2002), news headlines (Strapparava and Mi-
halcea,
2007;
Strapparava and Mihalcea,
2008),
speech samples (Tao,
2004),
literature
(Alm, 2008) and emails (Liu, Lieberman and Selker, 2003).
Online data is increasingly be-
ing used; indeed, people’s emotional and cognitive mechanisms are being revealed through
what they type online on social networking sites.
One such social networking site that has
received notable attention in the domain of emotion mining is Twitter.
3.1
Twitter
Twitter is a public micro-blogging system that allows users to share short messages of up
to 140 characters.
Its user base has grown exponentially since its conception in 2006 and
14
CHAPTER 3.
LEXICAL EMOTION EXTRACTION
15
currently has around about 100 million active users
1
with 200 million micro-blogs, or tweets,
posted each day
2
.
Tweets can be posted ‘at home’ via a computer or ‘on the go’ via a mobile
device,
and,
as they are publicly available,
provides us with an ethical
way of
collecting
a diverse range of
public expressions.
Coupled with the fact that a good proportion of
tweets project the user’s emotion,
we are able to assume that Twitter is a valid sample
of human emotive expression and thus a suitable corpus for this project.
Matthis (2000)
sees emotions as preconscious (Ekman and Davidson, 1994); due to their limited character
size of 140 characters, tweets could be seen as a form of, albeit weak, automatic appraisal,
insofar a large majority of users take a considerably less amount time of time or thought
in publishing a tweet compared to forum posts,
descriptions of in-depth experiences and
emails.
Although we cannot assume that Twitter is a measure of preconscious expressions,
there is somewhat of an explicit impulse to communicate emotions on Twitter and although
the underlying cause is not always explicitly mentioned,
it is this factor that we attempt
to capture.
For the purpose of this project,
we neglect the suggestion that there may be
some bias in expressions due to public image considerations, the widely fluctuating level of
which should be further investigated (see Chapter 9).
Although a few systems have mined
emotion from Twitter (see section 3.3) the majority of systems have focused on sentiment
analysis.
3.2
Sentiment Analysis
Twitter has been used extensively to measure and classify sentiment (e.g. Go, Bhayani and
Huang,
2009;
Bifet and Frank,
2010;
Pak and Paroubek,
2010;
Jiang,
Yu,
Zhou,
Liu and
Zhao,
2011).
Sentiment,
at least in the computer science sense,
refers to the opinions of
individuals, specifically regarding the emotional polarity of a document, labelling it either
positive, negative or neutral.
It is essentially a uni-dimensional, valence-focused variation
of the core affect model.
The majority of
sentiment mining from the web is based on the extraction of
emoticons
(for example :-) for happy and :-( for sad) and then training a classifier from these results
(see for example Go et al., 2009; Bifet and Frank, 2010; Pak and Paroubek, 2010).
Using
this technique assumes that (a) emoticons are an indication of an elicited emotion, (b) the
polarity of the emotion is defined by the type of emoticon, and (c) that the emotional po-
larity applies to all words within the document.
Traditionally, machine learning techniques
only work well when there is a good match between training and test data with respect to
topic,
however,
emoticon labels have the potential
of being independent of domain,
topic
and time (Read,
2005).
Emoticons are also a more intuitive representation of an elicited
emotion,
being pictorial
rather than lexical,
although they are not very specific and thus
can only effectively be applied to sentiment analysis,
or to augment emotion extraction.
Other methods to extract sentiment have been used,
including using Amazon’s Mechani-
cal
Turk to manually label
a Twitter corpus (Asur and Huberman,
2010) before training
1
http://blog.twitter.com/2011/09/one-hundred-million-voices.html
2
http://blog.twitter.com/2011/06/200-million-tweets-per-day.html
CHAPTER 3.
LEXICAL EMOTION EXTRACTION
16
classifiers.
Jiang et al.
(2011),
to discern target-dependent features,
used a combination
of
emoticons,
related tweets and General Inquirer to build up a more complex and
accurate sentiment score for a tweet.
Emotion lexicons, such as SentiWordNet have also
been used to generate sentiment scores based on individual emotional scores of each word
(Ruben Van Wanzeele and Tsiporkova, 2011).
LingPipe (Java) and Natural Language Toolkit (NLTK) (Python) integrate machine learn-
ing techniques which can be used to train a sentiment classifier.
In terms of the performance
of classifiers, Read (2005) has shown that neither Support Vector Machines (SVM) or Na¨ıve
Bayes classifiers outperforms the other.
A Na¨ıve Bayes classifier is less complicated to set
up and works best for unigrams (single keywords) although when taking both unigrams and
bigrams (two-word phrases) into account, a Maximum Entropy classifier has been found to
produce slightly better results (Go et al., 2009).
There are many online tools available that aim to measure sentiment by incorporating
these various methods of
classification,
including Lexalytics,
Tweetfeel,
Twitter
Sentiment (Go et al.,
2009),
twitrratr,
Linguistic Inquiry and Word Count (LIWC),
OpinionFinder and General Inquirer.
However,
these systems only measure textual
sentiment and do not provide a detailed insight into the emotional nature of each context.
Emotions are much more specific than sentiment,
so while emotions can infer sentiment
based on the theoretical
polarity of
emotional
keywords,
it is harder to classify due to
increased constraints, such as engagement and dominance.
As a result, different techniques
are required to extract emotion, rather than sentiment, from text.
3.3
Emotion Recognition
The past five to ten years has seen a rapid increase in emotion-recognition research.
The
most common method is identifying text as one of the basic emotions, treating basic emo-
tions as emotion types
(see for example Tao,
2004;
Lee,
Chen and Huang,
2010).
The
predominant technique is to use some sort of ontology or dataset to seed each basic emo-
tion type with synonyms and related words to produce a hierarchical
emotion lexicon,
and then to categorise text using these classifications.
Several
ontologies and lexicons
have been used including WordNet (Keshtkar and Inkpen,
2010),
WordNet-Affect
(Strapparava and Mihalcea, 2008), SentiWordNet (the UPAR7 system in Strapparava
and Mihalcea, 2007) and the Open Mind Common Sense (OPCS) database (Liu et al., 2003).
Additional
methods such as part of
speech tagging,
named entity extraction,
head noun
extraction,
Porter stemming and word stopping are also used to categorise and normalise
the data.
Another popular method is to assign the emotion to the word with the high-
est affective weight.
A Vector Space Model
has been used to classify emotions based on
the International Survey on Emotion Antecedents and Reactions (ISEAR) dataset labelled
with basic emotions, which performed significantly better than Na¨ıve Bayes and SVM clas-
sifiers and also the ConceptNet lexicon (Danisman and Alpkocak,
2008).
However,
the
underlying assumption remains that the emotions being seeded are in fact universal basic
CHAPTER 3.
LEXICAL EMOTION EXTRACTION
17
emotion types that best represent the entirety of the emotion spectrum.
As previously mentioned, Ruben Van Wanzeele and Tsiporkova (2011) used the emotions
ontology SentiWordNet to create a sentiment score based on the emotional score of each
word.
Strapparava and Mihalcea’s (2007) CLaC system used the reverse of this technique
by using General Inquirer,
similar to Jiang et al.
(2011),
to define each emotion and
seeded term as a ratio of valence.
CLaC took a more dimensional (indeed, fuzzy) approach
to the nature of emotion recognition and consequently had better accuracy and precision
over UPAR7.
This is similar to Kim,
Valitutti
and Calvo’s (2010) work who used the
Affective Norms for English Words (ANEW) dataset to define words in terms of valence,
arousal
and dominance (VAD — akin to PAD,
see Section 2.2),
mapping documents in a
3D emotional space, which proved most effective on the ISEAR dataset.
This 3D mapping
technique was also used to map basic emotions to calculate reactions of the sociable robot
Kismet (Breazeal, 2003).
3.3.1
Mood Analysis
The work of Pepe and Bollen (2008) involved creating an extended version of the psycho-
metric instrument Profile Of Mood States (POMS) (McNair, Lorr and Droppleman, 1992),
labelled POMS-ex,
by seeding the original
emotion adjectives describing aspects of mood
using WordNet,
extending the original
65 terms to nearly 800 terms.
This was used for
data mining on Twitter,
only retaining tweets that match the regular expressions ‘feel’,
‘I’m’,
‘Im’,
‘am’,
‘being’,
and ‘be’,
since the only tweets of interest where those that rep-
resent an explicit expression of individual
sentiment,
or those that reflect an individual’s
present status (Bollen,
Pepe and Mao,
2009).
This was improved two years later by ex-
tending the original 65 terms to a lexicon of over 950 associated terms by analyzing word
co-occurrences in Google’s Web 1T 5-Grams (Web1T5) database,
creating Google Profile
of
Mood States (GPOMS) (Bollen et al.,
2011).
Initial
findings show that the “happy”
dimension of GPOMS best approximates OpinionFinder’s trend, and the use of 4- and 5-
grams observed in publicly accessible web pages makes the lexicon more organic compared
to seeding using individual terms.
3.3.2
Comparison with Sentiment Analysis
Although sentiment is easier to classify — indeed it is just polarity — using specific emo-
tions rather than a valence ratio of words provides a greater insight into the dimensions,
and thus nature,
of
an expressed feeling.
We conduct a brief
preliminary comparison of
basic emotion extraction using keyword spotting and sentiment extraction using Twitter
Sentiment to reveal
any similarities and discrepancies as a result of using the increased
dimensionality of emotion.
As our emotion keywords we use Humaine’s Emotion Annota-
tion and Representation Language (EARL) (2006)
3
which classifies 48 emotions in eight
categories and correlates nicely with Watson and Tellegen’s CTA in terms of
matching
3
http://emotion-research.net/projects/humaine/earl
CHAPTER 3.
LEXICAL EMOTION EXTRACTION
18
Figure 3.1:
Discrete emotional response matrix.
Term
Ave(TS)Pos% Ave(EK)Pos% Diff%
Chocolate
71
63
8
Movie
66
64
2
Dentist
33
55
22
Crying
21
32
11
School
35
56
21
Table 3.1:
Mean average percentage of positive tweets using Twitter Sentiment (TS)
and Emotion Keyword Extraction (EK) of five example keywords over a three day period.
descriptions of octants, illustrated in Figure 3.1.
Using these emotion keywords as a basis,
we use WordNet (Fellbaum, 1998) to find synonyms for each keyword, arriving at a set of
60 positive and 60 negative emotional keywords distributed among each of the tithes in our
emotional space, as shown in Appendix A. Using this set of emotion keywords, we created a
database of 1.5 million tweets in three days using the Twitter streaming API. Five random
terms were chosen and results are shown in Table 3.1.
Comparing polarity results from emotion keyword spotting and the software Twitter
Sentiment (recall this uses a Maximum Entropy Classifier and considers all tweets as op-
posed to ‘explicitly emotional’ tweets), it is safe to say that there is a significant correlation
between the two.
We look at two cases where the difference was significant:
dentist
and
school.
When the top two emotion keywords were analysed for dentist, we found that our
emotion keyword spotting method treated brave as a positive emotion keyword,
and 19%
hit this term, contrasted with 11% for the term nervous.
Twitter Sentiment was unable
to identify brave as a positive.
For school, it treated glad as a positive, which accounted for
15%, whereas Twitter Sentiment would classify a tweet such as “I am glad that’s over”
as a negative.
In this example, the emotion elicited is indeed gladness, however Twitter
Sentiment fails to detect this.
We conclude,
albeit crudely,
that a ‘na¨ıve’
emotion keyword spotting system to measure
sentiment performs somewhat comparably with a trained classifier.
Performance is depen-
dent on the emotion keywords that are used and which are considered to be classified as
positive and negative,
but ultimately an increase in data granularity is achieved,
concen-
trating on specific emotions.
We hence presume that trained emotion classifiers implicitly
trump trained sentiment classifiers, although this statement should be further investigated
CHAPTER 3.
LEXICAL EMOTION EXTRACTION
19
(see Chapter 9).
3.4
Discussion
Many methods have been devised in attempt to capture emotion from text.
Although a lot
work has been done in the field of emotion extraction from arbitrary text,
less focus has
been drawn to analysing the nature of the emotions themselves.
Basic emotions sets are
used within emotion extraction as an attempt to define distinct clusters of discrete emotion
terms with the aim of
representing the entire emotion spectrum.
Thus it is important
to analyse existing basic emotion sets with the view to discern improved versions so that
clusters are correctly labelled to mitigate any neglect of regions of the emotion spectrum,
instigating an equally distributed seeding of synonyms for emotion classification.
With regards to our selection of mechanism for emotion mining, since we are only interested
in the words surrounding a specific emotion keyword, we need only use keyword spotting to
extract tweets containing each specific emotion keyword.
While simple statistical methods
are often used with extracted emotion to infer trends and psychological analytics (for exam-
ple the We Feel Fine emotion crawler and database, Kamvar and Harris, 2011), we require
a more powerful form of statistics to analyse the meaning, or semantics, of expressions at
a more deeper level.
We thus draw our attention to semantic analysis techniques.
Chapter 4
Semantic Analysis
Over the past few decades there has been significant evidence that people’s psychological
aspects can be predicted through analysis of language style.
One of the most notable exam-
ples of this is Rosenberg and Tucker’s (1979) work on verbal
behavior and schizophrenia.
They found that,
while the speech of
those diagnosed with schizophrenia did not differ
with unaffected people on the structural level, it did differ on the semantic level, i.e.
with
regard to thematic concerns that were being addressed.
It is this deviation from expected
thematic concerns,
which are linked to general
and sex-specific social
role expectations,
that is associated with the diagnosis of schizophrenia (Rosenberg and Tucker, 1979).
Anal-
ysis of
language semantics has been used extensively in research,
including discovering
individual differences in personality (Pennebaker and King, 1999), lie detection (Newman,
Pennebaker,
Berry and Richards,
2003) and discovering individual
differences in beliefs
(Bilovich and Bryson, 2008).
By analysing the semantics, specifically, co-occurrence statistics, of the language expressing
individual emotion keywords, we can discern those emotions that are similar and those that
are more distinct.
We postulate that similar emotions are represented by similar semantics,
and propose to cluster emotional
documents based on the underlying meanings of
each
document.
In order to analyse a corpus, we first require all target documents to be in the
same Euclidean space, and thus introduce the concept of a semantic space.
4.1
Semantic Space Theory
The central assumption when creating a semantic space is that the context surrounding a
given word provides important information about its meaning (Harris, 1968).
The semantic
properties of words are represented by capturing statistical
distributions of co-occurrence
with neighboring words which is then projected into a multi-dimensional Euclidean space
where each axis represents a context word.
The semantic similarity of any two words can
then be calculated,
typically using the Euclidean distance between the two points or the
20
CHAPTER 4.
SEMANTIC ANALYSIS
21
cosine of the angles between them.
Formally, a semantic space is a quadruple <A, B, S,
M>, where A is the Lexical Association Function, B is the Basis, S is the Similarity Measure
in <
|B|
× <
|B|
and M is an optional transformational Model (Lowe, 2001).
Zipf’s law states that in a (syntactically and semantically correct) textual
corpus,
the
frequency of any word is roughly inversely proportional to its frequency rank (Zipf, 1949).
The lexical
association function A is a normalising weighting scheme that is applied to
the raw co-occurrence count matrix to mitigate resulting data sparsity and chance co-
occurrences of words.
Perhaps the most effective weighting function is the Pointwise Mutual
Information method (PMI) (Church and Hanks, 1990).
Indeed it has recently been proven
to be more accurate than using idf
(inverse document frequency) or tf-idf
(term frequency-
inverse document frequency) normalisation techniques for contextual similarity and feature
selection (Qiu,
Wu and Shao,
2011),
and Jiang et al.
(2011) uses PMI
to successfully
measure the association of an elicited emotion with a target-dependent features.
Another
weighting function, referred to as log-entropy, is defined as:
G(i) =
1 + (
P
j
p(i, j)log(p(i, j)))
log(ndocs)
(4.1)
for term i and document j (Nakov,
Popova and Mateev, 2001).
This is both the de facto
normalisation function for Latent Semantic Analysis (see section 4.2) and found to be much
more accurate than idf
or gf-idf
by Nakov et al. (2001).
The similarity measure S, as previously mentioned, is usually the Euclidean distance or the
cosine of angles between two vectors in the semantic space.
The cosine of the angle θ be-
tween the vectors x and y with n elements, where x = hx
1
, x
2
, ..., x
n
i and y = hy
1
, y
2
, ..., y
n
i
can be calculated as follows:
cos(x, y) =
P
n
i=1
x
i
· y
i
q
P
n
i=1
x
2
i
·
P
n
i=1
y
2
i
(4.2)
It has been shown that the inner product is a more appropriate method for measuring the
syntagmatic (‘chunk-level’) similarity,
whereas the cosine was a better method for mea-
suring the paradigmatic (‘collection-level’) similarity (Utsumi,
2010).
It has also been
shown that the cosine of PMI vectors outperformed both the Euclidean distance of PMI
vectors and the cosine of
ratio vectors (Bullinaria and Levy,
2007).
Kullback-Leibler di-
vergence has also been shown to be less accurate than calculating the cosine (Bullinaria
and Levy, 2007; Utsumi, 2010).
Topic synsets can be represented by summing up the vec-
tors of individual
terms contained within each topic,
and then compared with individual
documents or other synsets.
The basis of
the semantic space,
B,
defines the dimensions of
the semantic space,
and is
usually the vocabulary.
The main issue with using a vector space model is its high dimen-
sionality, resulting in difficulties in capturing the latent semantic information.
Therefore B
is usually truncated to the k most frequent words.
Other techniques such as porter stem-
ming and word-stopping can be applied to B in an attempt to reduce the dimensionality
CHAPTER 4.
SEMANTIC ANALYSIS
22
of the semantic subspace, although by doing so a certain degree of semantic information is
unrepresented in the semantic space.
A semantic space is fully functional when A, B and S have been specified.
Indeed, Bilovich
and Bryson (2008) did not include M,
instead truncating low frequency words directly.
However it is possible to build a more structured mathematical
or statistical
model
with
the addition of
M (Lowe,
2001) to increase the accuracy of the analysis.
Latent Semantic
Analysis overcomes the issues of data sparseness and high dimensionality through the use
of dimensionality reduction methods.
4.2
Latent Semantic Analysis
Latent Semantic Analysis (LSA) (Landauer and Dumais,
1997) is a variant of the vector
space model
that aims to create a semantic space by means of
dimensionality reduction
techniques and has been widely used in a variety of domains,
from document indexing to
essay grading.
It has also been used in emotion classification of news headlines, performing
better than Na¨ıve Bayes for recall but not as good as WordNet for precision (Strapparava
and Mihalcea, 2008).
Given a raw co-occurrence matrix M using the entire vocabulary as B, this is transformed
by A (recall the documented function for LSA is log-entropy normalisation), and M is applied
to reduce dimensionality.
There are several techniques for M that reduce the dimensionality
of words constituting the semantic space, the original method documented for LSA being
Partial Singular Value Decomposition.
4.2.1
Partial Singular Value Decomposition
Partial
Singular Value Decomposition (PSVD) is the de facto method for dimensionality
reduction in LSA.
It uses Singular Value Decomposition (SVD) to decompose the data
matrix M into the product of three matrices:
M = TΣD
T
(4.3)
where T is the term matrix,
D is the document matrix and Σ is a diagonal
matrix with
singular values sorted in decreasing order that act as scaling factors that identify the vari-
ence with each dimension.
LSA uses a truncated SVD, keeping only the k largest singular
values in Σ and their associated vectors:
M ≈ M
k
= T
k
Σ
k
D
T
k
(4.4)
This reduced-dimension SVD,
or PSVD,
M
k
,
is the best approximation to M with k pa-
rameters, and is what LSA uses for its semantic space.
The rows in D
k
are the document
vectors and the rows in T
k
are the term vectors in LSA space.
As T and D have orthogonal
columns, the derived latent semantic space is orthogonal, and, combined with the fact that
CHAPTER 4.
SEMANTIC ANALYSIS
23
documents can take negative values in this space,
makes the derived semantic space less
likely to correspond to clusters that overlap (Xu,
Liu and Gong,
2003).
Additionally,
the
complexity of SVD is O(D
3
) and so makes it unsuitable for very large datasets,
although
methods have been developed to append data without having to recompute, most notably
folding-up (Tougas,
2005).
PSVD has recently been successfully used to identify latent
factors of political
alignment using hashtags on Twitter (M.
Conover,
2011).
Traditional
clustering techniques,
such as K-means,
can be applied in this space to derive semantic
clusters.
4.2.2
Comparison to Non-negative Matrix Factorisation
Non-Negative Matrix Factorisation (NMF) (Lee and Seung, 1999) is a multivariate analysis
method originally developed for computer vision purposes,
and increasingly being used
within the field of dimensionality reduction,
distinguished from other methods by its use
of non-negativity constraints and a parts-based representation.
With regard to document
clustering, it treats documents as an additive combination of the base latent semantics and
as a result, produces a semantic space that provides a direct indication of data partitions
without the need for additional
data clustering techniques (Xu et al.,
2003).
Terms and
documents are treated in an integrated fashion without the requirement of
a diagonal
matrix enabling natural soft clustering, i.e.
combining the term and document matrix for
clustering.
NMF finds the positive factorisation of the data matrix, M, such that
M ≈ WH
T
(4.5)
NMF is typically faster than SVD; SVD is computationally expensive and does not produce
intermediary results as it is not an optimisation procedure unlike NMF (Andrews and
Fox, 2007).
Xu et al. (2003) found NMF weighted by the normalised cut weighting scheme
to be more accurate than SVD for document clustering although Peter, Shivapratap, Divya
and Kp (2009) found negligible improvements over SVD when applied specifically for LSA.
Recently,
Utsumi
(2010) found that SVD yielded better performance in both synonym
judgement and word association over NMF.
NMF is an example of a latent topic model,
where a topic is represented by a distribution of words,
and is equivalent to several other
models in this field through parameter selection.
NMF via KL divergence is equivalent
to Probabilistic Latent Semantic Analysis (pLSA) (Gaussier and Goutte, 2005), and pLSA
using a uniform dirichlet prior distribution is equivalent to Latent Dirichlet Analysis (LDA)
(Girolami
and Kaban,
2003),
although these are generally regarded as topic modelling
techniques.
Latent Periodic Topic Analysis (LPTA) is a recent model that aims to represent
periodic topics,
ideal
for use with temporal
data to distinguish between periodic,
bursty
and background topics (Zhijun Yin and Huang, 2011).
CHAPTER 4.
SEMANTIC ANALYSIS
24
4.3
Algorithm Complexity and Human Cognition
Although dimension reduction techniques such as LSA and NMF are effective, the question
whether the assumed complexity of
these algorithms best models human cognition must
not be ignored.
In a recent study, Recchia and Jones (2009) demonstrated that, although
LSA was marginally more effective than PMI when using the same amount of data,
PMI
trained on large amounts of
data far surpassed the effectiveness of
LSA trained on less
data.
Recchia and Jones (2009) pose the theory that the requisite complexity of human
behavior may already be present in the structure of
language without the need to build
this complexity into models such as LSA, if a realistic sample is taken.
PMI-IR, a version of PMI that uses Information Retrieval from the Internet, has also shown
the effectiveness of PMI trained on more data over LSA, with just under a 10% increase in
precision in the Test of English as a Foreign Language (TOEFL) experiment, and a similar
gain in the English as a Second Language (ESL) experiment (Turney,
2001).
Another
approach that utilities massive amounts of world knowledge is Explicit Semantic Analysis
(ESA), which uses Wikipedia to create a semantic space, resulting in an almost 20% increase
in recall for individual words, and just over a 10% increase in recall for texts compared to
LSA (Gabrilovich and Markovitch, 2007).
In an age where million-scale datasets are more
frequently created and used, and until we have the processing power to use more complex
algorithms such as LSA on these massive datasets, less complex algorithms such as PMI-IR
and ESA may provide a viable alternative to approaching the human judgment problem,
being relatively simple, scalable and easily incremental.
4.4
Discussion
There exist many algorithms that create and analyse high-dimensional
linguistic spaces.
The most widely used algorithms, LSA and NMF, focus on transforming word co-occurrence
and document matrices in order to infer the underlying semantics of a particular corpus.
Other techniques,
such as PMI
and ESA,
use simpler mechanisms but compensate by
throwing more data at the problem.
For this study, however, we only need concentrate on
clustering documents that do not exceed the computational limitations of LSA. Given that
LSA is ultimately more accurate than other methods for inferring latent semantics, we select
LSA as our method of semantic analysis,
and install
the Enthought Python Distribution
(EPD) 7.2 on an x86 architecture to use the gensim framework (
ˇ
Reh˚uˇrek and Sojka, 2010)
to create latent semantic clusters of an emotion corpus harvested from Twitter.
Chapter 5
The Emotional Twitter Corpus
We are now in a position to discuss our data collection process.
As previously mentioned,
there are many basic emotion theories,
each defining a distinct set of emotion keywords.
We explain our selection of basic emotion sets and thus the emotion keywords used in this
study, and the mechanisms we used to create a corpus of emotion expressions from Twitter.
5.1
Basic Emotion Sets
Our first task was to decide on the emotion sets we would evaluate.
Originally starting with
the list of basic emotion sets tabulated in Ortony and Turner’s (1990) study,
we removed
sets that have four or less emotion keywords,
as these sets were regarded as not being
detailed enough for significant analysis,
more akin to a uni-dimensional
valence-focused
model.
Sets that contain emotion keywords that have an unfeasibly low stream rate (see
section 5.3.1) were also removed,
as these were considered impractical
to fully evaluate
within the timescale and resources of
this project.
We additionally included Russell’s
dimensional categories from his CTA as a basic emotion set, resulting in a collection of six
basic emotion theories as described in Table 5.1.
5.2
Emotion Keywords
The extraction mechanism and the selection of keywords to be mined from Twitter would
form the structure of our eventual emotion corpus.
Taking the union of all the emotion sets
identified for analysis,
we obtained a set of 21 unique emotion keywords,
which,
theoreti-
cally,
constitute the most distinct emotions.
We extract unigrams created using the first
person grammatical
inflection of each keyword,
similar to Russell
(1980),
as most tweets
will
contain this type of inflection:
“I am very excited today” as opposed to “I am feel-
ing excitement today”.
This was chosen as opposed to mining for bigrams,
for example
“feeling excited”, “feel excited” and “felt excited”, as this resulted in far fewer tweets being
25
CHAPTER 5.
THE EMOTIONAL TWITTER CORPUS
26
Basic Emotion Theory
Identified Basic Emotions
Izard (1971)
Anger, Contempt, Disgust, Distress, Fear,
Guilt, Interest, Joy, Shame, Surprise
Russell’s (1980) Categories
Angry,
Depressed,
Distressed,
Excited,
Miserable, Pleased, Relaxed, Sleepy
Plutchik (1980)
Acceptance, Anger, Anticipation, Disgust,
Joy, Fear, Sadness, Surprise
Ekman et al. (1972)
Anger,
Disgust,
Fear,
Joy,
Sadness,
Sur-
prise
Tomkins (1984)
Anger,
Interest,
Contempt,
Disgust,
Dis-
tress, Fear, Joy, Shame, Surprise
Oatley and Johnson-Laird (1987)
Anger, Disgust, Anxiety, Happiness, Sad-
ness
Table 5.1:
Basic Emotion sets from the most notable Basic Emotion theories that were
analysed.
returned due to Twitter’s indexing focusing on single keywords.
Moreover, tweets contain-
ing quantifiers would have been ignored if we chose to extract bigrams, for example “feeling
very excited”.
Contrary to Bollen et al.’s (2009) work, we did not require tweets to contain the words ‘feel’,
‘I’m’, ‘Im’, ‘am’, ‘being’, and ‘be’, as an explicit mention of an emotion keyword would be
sufficient to describe an experience of
that emotion,
reinforced by the fact that we will
only be mining for the first person grammatical inflection of each keyword.
We filtered out
re-tweets — minimising duplicates — and negative tweets,
because,
for example,
‘happy’
6
= ‘not happy’ ;
nor can we assume that ‘not sad’
= ‘happy’.
tweets that include popular
phrases including an emotion keyword such as “Happy Birthday” and “Angry Birds” were
also filtered out from being written to the database.
Initially,
@ tags were not filtered,
but we quickly realised that these tweets refer to messages either closely relating to other
people or as part of a thread of messages; thus we filtered them out as the emotion expressed
within such tweets did not describe an atomic emotional
experience.
Table 5.2 tabulates
the complete set of emotion keywords and filtered phrases used for emotion extraction from
Twitter.
We did not Porter stem collected words as Kim et al. (2010) notes that this might hide im-
portant semantic differences, for example, conceptual differences between loved and loving.
To optimally harvest emotions, we substituted fear with scared as it was proven to be the
most popular keyword out of scared, frightened and afraid.
We also substituted distressed
with stressed, due to an extremely low stream rate for this keyword (see section 5.3.1).
CHAPTER 5.
THE EMOTIONAL TWITTER CORPUS
27
Term
Filtered Phrases
Total tweets
accepting
not accepting, unaccepting
1847
angry
not angry, angry birds
7540
anticipating
not anticipating
1493
anxious
not anxious
1964
ashamed
not ashamed, unashamed
2871
contempt
not contempt, in contempt, contempt of
1287
depressed
not depressed
4347
disgusted
not disgusted
1607
excited
not excited, unexcited
20629
guilty
not guilty, found guilty
3450
happy
not happy, unhappy, happy birthday
57631
interested
not interested, uninterested, disinterested
4394
joyful
not joyful, unjoyful
1249
miserable
not miserable
3164
pleased
not pleased, displeased
1872
relaxed
not relaxed, unrelaxed
1817
sad
not sad
26721
scared
not scared
15273
sleepy
not sleepy
9786
stressed
not stressed, unstressed
4237
surprised
not surprised, unsurprised
5625
ALL
http://, RT, < 10 words
178804
Table 5.2:
Emotion Keywords that were tracked on Twitter, with any tweets containing a
filtered phrase not stored in the database.
Total
number of tweets are correct as of 28th
April 2012 and reflects additional extraction carried out after the analysis for the current
project was conducted.
CHAPTER 5.
THE EMOTIONAL TWITTER CORPUS
28
5.3
Emotion Streaming
The next stage involved mining and storing tweets.
A PHP script was created that used the
Gardenhose Level Twitter Streaming API — a streaming sample of about 10% of all public
status updates on Twitter — that allows tracking of
up to 400 keywords.
We collected
tweets that contained each of the emotion keywords in Table 5.2,
storing those which do
not include a filtered phrase into a MySQL database.
We programmed the PHP script to
be cyclical in the sense that it streamed individual tweets, but changed emotion keywords
every 5 minutes in order to collect the whole range of emotions without having to restart
the script each time.
Ten days of data collection resulted in a labelled Temporal Emotion
Database containing six emotion theories totaling to 21 unique emotion keywords each
with at least 1100 documents to base our analysis on.
The PHP script can be found in
Appendix C.2.
5.3.1
Emotion Stream Rate
We originally tracked emotions within each emotion set at the same time,
however this
produced biased results as the Emotion Stream Rate (ESR) deviated the number of tweets
proportionately to each emotion, and thus results were skewed in favour of more ‘popular’
emotions.
Figure 5.1 illustrates this problem.
A notable example was the keyword dis-
tressed,
with an ESR of less than 1 tweet per hour,
so to collect 1000 tweets would take
over 40 days.
Seeing as we could only stream one emotion at a time due to Twitter API
limitations, this was deemed unfeasible and so distressed was substituted with stressed.
CHAPTER 5.
THE EMOTIONAL TWITTER CORPUS
29
Figure 5.1:
Emotion Stream Rates for selected Emotion Keywords.
CHAPTER 5.
THE EMOTIONAL TWITTER CORPUS
30
We thus tracked each emotion keyword individually,
which also created the advantage of
being able to label tweets with their respective emotion in the database for efficient retrieval,
in addition to the ability to measure each emotion’s stream rate.
It should be noted that by
using WordNet (Fellbaum, 1998) we could have expanded our initial list of 21 keywords
by taking synonyms of each keyword and testing the ESR for each emotion,
selecting the
most popular keyword;
however in order to fairly test each theory,
we opted against this
as the selected emotion keywords had been carefully chosen by each theorist.
5.4
Discussion
We have created a PHP script that streams a large number of emotional expressions from
Twitter that can be executed from a UNIX terminal
and run in the background.
Using
this script, we have created a corpus of emotional tweets, stored in a database, with each
expression emotion-tagged and linked to additional
information such as time (useful
for
temporal
analysis) and nationality (useful
for cultural
analysis).
In the process,
we have
discovered that the stream rates of
emotions are highly irregular,
ranging from 2 to 200
tweets per minute for the emotions analysed,
including any word filters that were used.
Using consistent quantities of tweets for each emotion was key to this research, so a natural
limit of the number of documents we could analyse was imposed, this being the number of
documents harvested from the emotion with the lowest stream rate.
The primary limitation of this generated corpus is that it collects expressions that mention
an emotion keyword without regard to whether the user actually felt the expressed emotion.
However, we assume that the mere use of an emotion keyword still attributes to how people
understand each emotion to be.
Although we could have used many more popular emotion
keywords and synonyms,
we decided against this as the current study focuses on specific
basic emotion sets, however this should be explored in further research (see Chapter 9).
Our generated Twitter corpus is useful for those wanting to obtain raw explicit expressions
of
emotion.
Each expression is labelled,
rendering it especially useful
for classification
projects, although the data as it stands remains unparsed for duplicates or identified ‘junk’
data.
We can query our database to retrieve up to 1100 expressions for each of
the 21
emotions tracked, which we incorporate into our Python code to perform semantic analysis.
Chapter 6
Semantic Emotion Analysis
Having created an emotional
Twitter corpus,
we analyse this data in order to evaluate
the semantic distinctiveness of
existing basic emotion sets.
We also develop an iterative
latent semantic clustering algorithm to discern the optimal
semantically irreducible basic
emotion set from all 21 emotions collected.
Latent Semantic Clustering (LSC) is a simple
modification of
the LSA algorithm which we base our DELSAR algorithm on.
Given a
labelled corpus C with label set K, it calculates, using LSA, the semantic accuracy for each
label ∈ K,
thus providing an analysis of how distinct the labelling of C and the selection
of K is.
All analysis was performed on an Intel Core 2 U7700 CPU 2x1.33GHz with 2GB
RAM.
Unless specified,
we tested dimensions of
the LSA space in increments of
10 and
selected the dimensionality that performed optimally for each task, similar to Recchia and
Jones (2009).
For all tasks, we use Log-Entropy normalisation as our Association Function,
found to generate optimal
results by Nakov et al.
(2001) and recommended by Landauer
and Dumais (1997).
6.1
DELSAR
Document-Emotion Latent Semantic Algorithmic Reducer (DELSAR) takes an emotion
set and clusters each document’s emotion to the emotion of
its closest document vector
(excluding itself), calculating a clustering accuracy for each emotion.
The closest document
vector is calculated as the maximum cosine value of the angle between the current document
and each other document in the subcorpus.
The emotion keyword in each document is
removed before the closest document vector is calculated, so we focus purely on the words
surrounding the emotion keyword for each document.
DELSAR operates in the LSA space
created from the subcorpus of
all
documents matching all
emotion keywords in the set
being analysed, in which there are (doc limit × number of emotions) documents.
If a document expressing a certain emotion, e, is not clustered with a document of the same
emotion,
then the words surrounding e is more similar to the words surrounding another
31
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
32
emotion.
Thus the clustering accuracy of an emotion set corresponds to how distinct that
emotion set is;
the more semantically accurate an emotion set is,
the more distinct the
language surrounding each emotion within the set is.
The reduction aspect of
DELSAR initially starts with the set of
all
21 emotions.
After
calculating the clustering accuracies for each emotion, it removes the least accurate emotion
from the set and iterates until there are n emotions remaining in the initial set, resulting in
the optimal semantically distinct basic emotion set.
The DELSAR algorithm is described
in Algorithm 1 and the Python code can be found in Appendix C.3.
The raw Python
output of the DELSAR algorithm can be found in Appendix B.
Algorithm 1 DELSAR
Require:
Final
keyword set
size
reduceT o,
Corpus
C and Keyword Set
K,
where
∀document ∈ C ∃document → emotion ∈ K
calculate cosine document similarity matrix of LSC(C, K)
for each document ∈ C do
delete emotion in document
Find closest document vector nearest where nearest 6= document
if
nearest(K) == document(K)
then
document is a hit
else
document is a miss
end if
end for each
for each emotion ∈ K do
calculate accuracy of
emotion using (total
document
hits where emotion in docu-
ment/total document where emotion in document)
end for each
if
length(K) > reduceT o
then
delete least accurate word in K
DELSAR(reduced K)
else
return K
end if
6.1.1
Analysis
We performed DELSAR1000 on the corpus and various subcorpora and report the results
in Table 6.1.
Recall
that DELSAR creates an LSA space of
all
documents within each
emotion set;
for each basic emotion set an LSA space of
(1000 × number of emotions)
documents is created.
Evaluating all sets, our results show the accuracy of clustering each
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
33
Model
Izard
Russell
Plutchik
Ekman
Tomkins
Oatley
All
DELSAR
Dimension
40
30
30
30
30
30
60
40
accepting
0.583
0.452
0.553
angry
0.390
0.409
0.400
0.429
0.391
0.468
0.248
anticipating
0.455
0.312
anxious
0.535
0.272
ashamed
0.452
0.467
0.366
0.534
contempt
0.550
0.575
0.356
0.574
depressed
0.292
0.193
disgusted
0.364
0.417
0.484
0.422
0.527
0.251
excited
0.407
0.227
guilty
0.426
0.339
happy
0.411
0.255
interested
0.561
0.560
0.460
0.603
joyful
0.482
0.518
0.565
0.507
0.397
0.519
miserable
0.413
0.272
pleased
0.548
0.359
0.506
relaxed
0.383
0.245
sad
0.388
0.442
0.424
0.259
scared
0.377
0.456
0.498
0.396
0.249
sleepy
0.445
0.332
0.591
stressed
0.454
0.376
0.481
0.295
0.502
surprised
0.416
0.491
0.505
0.414
0.295
MEAN
0.447
0.409
0.464
0.487
0.468
0.473
0.306
0.548
STDEV
0.068
0.072
0.065
0.049
0.069
0.057
0.072
0.039
Table 6.1:
DELSAR clustering accuracy of each basic emotion set using a corpus comprised
of 1000 documents for each emotion within each set.
Standard Deviation of all
models is
σ = 0.027.
document to its nearest document, whether it is the same or another emotion.
Out of the
theories analysed,
Ekman’s set proved to be the most semantically distinct,
with a 2.9%
increase in accuracy compared to the average of
the remaining sets.
Russell’s categories
performed worst,
which is surprising seeing as these emotions were taken as the basis for
representing the entire emotion spectrum as a whole.
We performed DELSAR on the set of all
21 emotions,
reducing the set to the eight most
semantically distinct dimensions of emotion, these being:
accepting ashamed contempt interested joyful pleased sleepy stressed
This set achieved a significant increase in accuracy over Ekman’s set of 6.1%.
We could
say that these emotions best represent the emotion spectrum in its entirety,
or in other
words, the remaining emotions could be expressed as a combination or a particular degree
of intensity of these emotions.
In addition to performing DELSAR1000,
we tested four subcorpora of varying document
sizes to observe any temporal
effects.
We took document sizes of
500,
360,
280 and 100
and distributed equally across the whole corpus using a modulus function on the index.
We found negligible temporal variance within our results, with a 0.7% standard deviation
of
standard deviations for each test,
illustrated in Table 6.2.
Ekman’s set proved to be
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
34
Model
Izard
Russell
Plutchik
Ekman
Tomkins
Oatley
STDEV
DELSAR
D500 MOD2=0
0.444
0.411
0.461
0.475
0.463
0.472
0.024
0.563
D360 MOD3=0
0.416
0.405
0.440
0.456
0.427
0.449
0.020
0.532
D280 MOD4=0
0.427
0.403
0.414
0.430
0.431
0.434
0.012
0.494
D100 MOD10=0
0.376
0.345
0.396
0.418
0.382
0.422
0.029
0.470
MEAN
0.416
0.391
0.428
0.445
0.426
0.444
0.020
0.515
STDEV
0.029
0.031
0.029
0.025
0.033
0.022
0.007
0.041
Table 6.2:
DELSAR clustering accuracy using a dimension of 36.
Each set uses a subcorpus
comprised of 500, 360, 280 and 100 documents of each emotion in the set, selected using a
modulus function on the index.
the best overall, in line with DELSAR1000, although it was outperformed by Oatley’s set
when lower amounts of documents were used.
Again, in all cases, Russell’s categories were
outperformed by all other sets, and our DELSAR set outperformed each optimal set by as
much as 8.8%.
6.2
ELSA
While DELSAR is highly effective,
its analysis is relative to a subcorpus of
documents
that express all the emotions contained within a particular basic emotion set, so although
it is a good measure of
showing how distinct a particular emotion set is overall,
it does
not allow for each emotion to be mutually independent.
This is important to take into
consideration as it allows us to compare emotions without the constraint of it being in a
set with other emotions — for example an emotion within a set may be considered distinct
only because other emotions within the set are not.
Emotional Latent Semantic Analysis
(ELSA) is a modified version of DELSAR, in which emotions are treated separately from
one another.
ELSA takes the set of
all
21 emotions and,
for each emotion,
creates an
LSA space using documents matching only that particular emotion,
in which there are
(doc limit) documents.
For each ELSA space,
the cosine value for the closest document
vector to each document is determined, and an average of these is calculated.
The higher
this average value is for a specific emotion,
the more similar the documents are for that
emotion,
in other words,
the emotion cluster is tightly packed.
Lower values mean less
similar words being used in the expression of the same emotion — the emotion cluster is
more dispersed — signifying a decrease in distinctiveness.
The difference between ELSA
and DELSAR, is that the latter evaluates whether a particular emotion set is representative
of the entire emotion spectrum, as opposed to seeing which emotions are distinct.
Evaluating each basic emotion set according to ELSA is simply a matter of averaging the
corresponding values of
the constituent emotions,
and discerning the most semantically
distinct emotions is merely a case of selecting the emotions with maximum average values.
The ELSA algorithm is described in Algorithm 2.
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
35
Algorithm 2 ELSA
Require:
Corpus C and Keyword Set K, where ∀document ∈ C ∃document → emotion ∈
K
for each emotion ∈ K do
for each document ∈ C do
if
document(K) == emotion then
delete emotion in document
calculate cosine document similarity matrix of LSA(document, C)
Find closest document vector nearest where nearest 6= document
end if
end for each
return average(nearest)
end for each
6.2.1
Analysis
We performed ELSA in a similar fashion to DELSAR — testing the same copora — and
report the results in Table 6.3.
Out of
all
the basic emotion sets analysed,
Tomkin’s
set proved to contain the most semantically concentrated emotions,
although it must be
pointed out that Tomkin’s set is identical to Ekman’s set without the emotion sad and four
other emotions added;
by swapping disgusted for contempt, Ekman’s set would have been
optimal at 0.747.
We obtained a slightly different optimal set consisting of the eight most semantically distinct
emotions compared to DELSAR, taking away interested and sleepy and adding anxious and
miserable:
accepting anxious ashamed contempt joyful miserable pleased stressed
This set achieved a 1.9% increase in accuracy compared to Tomkin’s set.
We could say
that these emotions are the most atomic in the sense that the words surrounding these
emotions are semantically concentrated; people using these emotions are more likely to be
actually referring to these emotions due to the similarity of language across all documents.
Take happy as an example, which is the least atomic emotion:
being the least semantically
concentrated means that the language that people use when using the word happy varies
the most,
either due to describing a great variety of things,
being used in a great variety
of contexts,
or varying perceptions of what the emotion happy actually means.
The raw
Python output of the ELSA1000 algorithm can be found in Appendix B.
Similarly to DELSAR, we tested the same four subcorpora to observe any temporal effects,
and report the results in Table 6.4.
A standard deviation of 0.1% suggests that there is
negligible temporal effects on the corpus, with Tomkin’s set again outperforming all other
sets,
in line with our results from ELSA1000,
and our ELSA set outperforming Tomkin’s
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
36
Model
Izard
Russell
Plutchik
Ekman
Tomkins
Oatley
All
ELSA
accepting
0.781
0.781
0.781
angry
0.727
0.727
0.727
0.727
0.727
0.727
0.727
anticipating
0.717
0.717
anxious
0.744
0.744
0.744
ashamed
0.743
0.743
0.743
0.743
contempt
0.838
0.838
0.838
0.838
depressed
0.695
0.695
disgusted
0.708
0.708
0.708
0.708
0.708
0.708
excited
0.708
0.708
guilty
0.713
0.713
happy
0.694
0.694
interested
0.724
0.724
0.724
joyful
0.761
0.761
0.761
0.761
0.761
0.761
miserable
0.744
0.744
0.744
pleased
0.742
0.742
0.742
relaxed
0.707
0.707
sad
0.713
0.713
0.713
0.713
scared
0.719
0.719
0.719
0.719
0.719
sleepy
0.704
0.704
stressed
0.736
0.736
0.736
0.736
0.736
surprised
0.723
0.723
0.723
0.723
0.723
MEAN
0.739
0.720
0.731
0.725
0.742
0.717
0.731
0.761
STDEV
0.038
0.019
0.026
0.019
0.039
0.019
0.033
0.034
Table 6.3:
ELSA average cosine values using dimensions 10,
20,
30,
40,
50,
60,
70,
80,
90
and 100.
Each emotion uses a corpus of 1000 documents.
Standard Deviation of all models
is σ = 0.010.
set in each case.
For each set we calculated the optimal
ELSA set,
and found that in E280 the set does
not change, in E500 stressed is replaced with surprised, in E360 ashamed is replaced with
surprised and in E100 stressed is replaced with excited ;
negligible changes are observed
with the optimal
increasing accuracy by only 0.2% for E360 and E100 and 0% for E500
and E280.
Plotting the standard deviation of ELSA1000 performances using a variety of dimensions
against the average maximum cosine values creates an interesting correlation.
By increasing
the dimensionality,
we increase the number of words that are included in the LSA space.
Model
Izard
Russell
Plutchik
Ekman
Tomkins
Oatley
STDEV
ELSA
E500 MOD2=0
0.688
0.675
0.685
0.678
0.690
0.672
0.007
0.715
E360 MOD3=0
0.667
0.653
0.660
0.654
0.669
0.651
0.008
0.690
E280 MOD4=0
0.645
0.641
0.640
0.633
0.648
0.632
0.006
0.675
E100 MOD10=0
0.549
0.539
0.537
0.536
0.553
0.527
0.009
0.571
MEAN
0.637
0.627
0.631
0.625
0.640
0.620
0.008
0.663
STDEV
0.061
0.060
0.065
0.063
0.061
0.064
0.001
0.063
Table 6.4:
ELSA average cosine values using a dimension of
50.
Each emotion uses a
subcorpus comprised of 500, 360, 280 and 100 documents, selected using a modulus function
on the index.
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
37
Figure 6.1 shows that the lower the standard deviation of data across all dimensions is, the
more distinct the emotion is.
This is actually intuitive as one would expect that the more
variance an emotion has relative to the number of words that is used, the less accurate it
would be in clustering.
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
38
Figure 6.1:
Standard deviation plotted against the average maximum cosine value for each emotion of dimensions 10, 20, 30,
40, 50, 60, 70, 80, 90 and 100 using ELSA.
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
39
Model
Izard
Russell
Plutchik
Ekman
Tomkins
Oatley
ELSA
Optimal
USP77
0.605
0.569
0.589
0.594
0.603
0.590
0.605
0.621
USE91
0.619
0.601
0.616
0.615
0.622
0.596
0.631
0.636
USC92
0.618
0.610
0.595
0.599
0.624
0.583
0.627
0.637
UK49
0.478
0.476
0.484
0.480
0.480
0.459
0.475
0.501
RAND77
0.593
0.577
0.584
0.581
0.593
0.585
0.601
0.613
MEAN
0.582
0.567
0.574
0.574
0.584
0.563
0.588
0.602
STDEV
0.060
0.053
0.052
0.054
0.060
0.058
0.065
0.057
Table 6.5:
ELSA values for geographical subcorpora, using a dimension of 50.
6.3
Testing Geographical Relativity
We analysed subcorpora consisting of tweets originating from specific timezones in order
to briefly assess whether there is any difference in the perception of
emotion dimensions
latent within the language of emotion expression across cultures.
We select the following
geographical areas (document limits in brackets):
Pacific Time (US & Canada) (77), East-
ern Time (US & Canada) (91), Central Time (US & Canada) (92) and London, Edinburgh,
Dublin (49).
We designate these subcorpora the codes USP77, USE91, USC92 and UK49
receptively.
The limits we tested each of these sets with were chosen as the minimum num-
ber of tweets any one emotion had for each timezone, in order for a fair test to be carried
out; each timezone had consistent quantities of tweets for each emotion.
One concern was that such a small limit would render the analysis statistically irrelevant;
however,
we have mitigated this by showing a random ELSA calculation using a limit of
77, generated using a MOD 12 = 1 function on the index, which correlated to ELSA1000.
We also recreated each ELSA set to the optimal.
The results are shown in Table 6.5.
Of
all
the current basic emotion theories Tomkin’s set performs best,
and Oatley’s and
Russell’s sets perform worst overall, corresponding to ELSA1000.
In most cases the ELSA
set outperforms current basic emotion sets,
although if the optimum is found an increase
of
up to 2.6% is observed.
While this alone somewhat diminishes the case for linguistic
relativity,
we found that in all
cases the optimal
set to be not only different to the best
performing set, but in as much disarray as the original basic emotion sets as tabulated by
Ortony and Turner (1990) — see Table 6.6.
As we have observed negligible changes in
the optimal set when testing subcorpora of the same size,
we must conclude that there is
indeed linguistic relativity, at least with regards to emotion and geographical areas.
What we have determined is that the emotion disgusted cannot be regarded as a seman-
tically distinct emotion, as it does not appear in any emotion set derived in this research.
This may come across as surprising,
since all
basic emotion theories analysed have in-
cluded disgust (with the exception of it not being one of Russell’s categories of dimension),
although recall
in section 2.1 we mentioned that disgust
is a ‘vague’
emotion,
with the
possibility of explaining differing emotion qualia.
In this sense, it is no surprise that is has
been identified as an indistinct emotion.
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
40
6.4
Discussion
A large majority of computer scientists tend to use Ekman’s basic emotion set for emotion
categorisation,
and it appears that,
semantically,
it is the most distinct set.
Using an
iterative algorithm based on LSC, we have discerned a set of eight basic emotion keywords
that have been calculated to be the most semantically distinct.
This set performed better
in all semantic tests than all of the basic emotion models analysed, with a 6.1% increase in
accuracy over Ekman’s basic emotion set.
Furthermore, the derived set satisfies the three
laws of basic emotions (see Section 2.2).
Emotions must be seen as relative to a specific domain.
This research has not focused on
any particular domain as it attempts to generalise the nature of emotions, however, as we
have seen with the geographical testing, the composition of optimal sets are dynamic and
highly dependent on region, even though negligible alterations were observed when testing
a random sample — if there is an underlying domain, then its semantically distinct set of
emotion dimensions will differ to that of another corpus of a different domain.
If
we had to decide upon a universal
set of
basic emotions,
it would be those emotions
that appear thrice or greater in the derived basic emotion sets within the research thus far
(ELSA, DELSAR and the optimal ELSA sets derived from USP77, USE91, USC92, UK49,
RAND77):
accepting anxious ashamed contempt interested joyful pleased stressed
We do not recommended the use of these emotion dimensions universally,
although they
are a much more accurate and complete set of basic emotions to base emotion classification
with than existing basic emotion sets, and certainly more distinct than Ekman’s set, at least
in terms of the language used for each expression of emotion.
Similar to Kim et al.’s (2010)
point of view, we recommend that a different basic emotion set should be chosen dependent
on the domain and corpus, suggesting that basic emotions are ultimately not universal and
correlated with underlying thematic concerns within the corpus under analysis.
We can define three more ‘categories’ of emotions, according to the frequency of their use
in derived basic emotion sets within the research thus far.
Having just identified category 1
emotions, the next category consists of emotions that appear in multiple sets:
anticipating excited scared sleepy
Category 2 emotions are also primary emotions, especially as some of them appear in our
ELSA and DELSAR sets, although they have not been as strongly identified and thus not
category 1 emotions.
The next category refers to those emotions that could be considered
as ‘secondary’ emotions, similar in sense to that of Plutchik’s definition:
angry depressed guilty happy miserable relaxed sad
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
41
Basic Emotion Set
USP77
USE91
USC92
UK49
RAND77
ELSA
DELSAR
Category
accepting
x
x
x
1
angry
x
3
anticipating
x
x
2
anxious
x
x
x
x
1
ashamed
x
x
x
x
x
1
contempt
x
x
x
x
x
x
1
depressed
x
3
disgusted
4
excited
x
x
2
guilty
x
3
happy
x
3
interested
x
x
x
x
x
1
joyful
x
x
x
x
x
x
x
1
miserable
x
3
pleased
x
x
x
x
x
1
relaxed
x
3
sad
x
3
scared
x
x
2
sleepy
x
x
2
stressed
x
x
x
x
x
1
surprised
x
3
Table 6.6:
Optimal ELSA emotion sets derived from various corpora.
Secondary emotions, or category 3 emotions, only appear in one of the emotion sets derived
in this research thus far and are the candidates for being the result of the fusion of multiple
emotions, in addition to the final category of emotions:
disgusted
Category 4 emotions are not basic emotions,
and have not been included in any derived
set thus far.
We will
be attempting to recreate secondary emotions as a result of fusing
together permutations of
the more distinct emotions identified in the next chapter.
It
should be noted that we have analysed a significantly smaller sample of
the corpus for
geographical
testing,
hence results are bound to be less accurate than if
a larger sample
was taken, as DELSAR and ELSA does.
6.4.1
Fear
Our basic set does not include fear as a basic emotion.
This will
be sure to create much
debate amongst researchers,
as the majority of
emotion research has identified fear as a
basic emotion; indeed, only five of the fourteen basic emotion sets as tabulated by Ortony
and Turner (1990) omitted fear.
There are two possible explanations as to why fear may not
be a basic emotion.
The first, and the most obvious of the two, is that not enough synonymic
emotion keywords, such as frightened, afraid and horrified, were used in creating our Twitter
corpus to be able to capture a complete signature of the emotion fear.
In our study,
we
have used the emotion keyword scared due to its popularity of
expression,
however,
this
may have hidden underlying conceptualisations of the emotion fear.
For example, perhaps
CHAPTER 6.
SEMANTIC EMOTION ANALYSIS
42
people use the word frightened to describe the type of fear experienced when, for example,
facing a hungry lion about to attack them, and the word scared to describe the type of fear
experienced when,
for example,
facing a break-up with their partner.
Moreover,
the vast
majority of people are aware that their tweets are able to be read by the public,
and we
mentioned in Section 3.1 that we neglect public image considerations — there may exist a
tendency to omit certain emotions from the public.
Would people really tweet true fear ?
The second explanation as to why fear may not be a basic emotion,
and arguably most
controversial, is the proposition that fear is in fact a compound emotion, comprised of an
anxiety component and a stress component,
both found to be more conceptually distinct
than fear.
Although similar, fear and anxiety are said to be significantly distinct in dura-
tion and focus,
specificity of the related threat and motivated direction of response.
Fear
is defined as short lived,
present focused,
geared towards a specific threat,
and facilitat-
ing escape from threat,
while anxiety is defined as long acting,
future focused,
broadly
focused towards a diffuse threat,
and promoting caution while approaching a potential
threat (Sylvers,
Lilienfeld and LaPrairie,
2011).
However,
we should attempt to distance
ourselves from learned ideas and past experience of actions in response to these emotions.
If we separate emotion from action, and focus on the expression, and thus the conceptuali-
sation of emotions, we could say that these two emotions are similar.
In this case, it is the
emotional response that is distinct, and not the emotion qualia.
Darwin (1872) found that fear had a characteristic facial expression, and coupled with its
evolutionary role in responding to an immediate threat,
posited fear as a basic emotion.
However,
Darwin required fear
to be atomic (that is,
as a single emotion as opposed
to several
mechanisms) in order to explain his theory,
so,
while the emotion that best
describes the mechanism in Darwin’s evolutionary theory may well
be fear,
he did not
need to consider the possibility that it could be a compound of
several
other emotional
components.
In Breazeal’s (2003) work,
an evaluation of the social
robot Kismet’s facial
expressions found that fear was the most ambiguous of all the basic emotions implemented,
again casting doubt over its perceived distinctiveness compared to other basic emotions.
Moreover, Cannon (1922) says that a stress component, rather than fear, is triggered in a
‘fight or flight’ response.
If this is compounded with a high anxiety component, this could
result in the manifestation of fear.
Whilst fear may be facially distinct,
it may not be as
conceptually distinct as previously thought.
6.4.2
Applications of LSC
We have essentially ranked emotions and basic emotion sets using our algorithms according
to a metric of semantic distinctiveness of extracted expressions from Twitter.
Whilst this
is useful for discovering psychological similarities of emotion expression, the real power lies
in the application of
the resulting clustering data.
By visualising these matrices,
we are
able to compare the similarity of compound emotions, analyse the composite properties of
emotions and highlight how specific emotions interact with each other.
Chapter 7
Visualising Emotion
Until now, we have not analysed any relationships between specific emotions that contribute
to defining their similarity, such as the relative levels of polarity and engagement.
This is
important as it could highlight specifically how emotions interact with each other, and eas-
ily analyse, relative to the corpus, the composite properties of each emotion.
Traditionally,
this has been illustrated using core affect models (see Section 2.2) in which emotions are
positioned in an emotional
space as a single point (Russell’s Theory of Affect),
or desig-
nated a specific dimension (Watson’s Circumplex Theory of Affect).
Indeed Plutchik not
only assigns emotions to bipolar dimensions, but does so using each dimension as a scale of
intensity,
and also incorporating mixtures of dimensions into his model.
The key to illus-
trating emotions is, when calculating DELSAR clustering, instead of registering clustering
hits and misses to obtain a final accuracy, we actually record the specific cluster labels of
each miss,
resulting in each emotion being a combination of
all
emotions.
We visualise
these semantic vectors of emotion in this chapter using two techniques:
Multidimensional
Scaling and Emotion Profiling.
7.1
Emotion Space
Firstly, we visualise what a two and three-dimensional emotion space looks like.
We create
an emotion matrix of DELSAR1100 clustering, shown in Table 7.1, using 1100 documents
for each emotion.
We can see that this matrix illustrates the notion that each emotion is
in fact a combination of all other emotions.
This property has also been shown in Russell’s
(1980) and more recently Breazeal’s (2003) work.
The Cosine Similarity is then calculated
for each pairwise semantic emotion vector using Equation 4.2, creating a symmetrical simi-
larity matrix of cosine similarities for all emotions, shown in Table 7.2.
We use the XLSTAT
Excel
plug-in to perform multidimensional
scaling of these cosine similarities,
and plot a
two-dimensional representation of this space, shown in Figure 7.1, and a three-dimensional
representation, shown in Figure 7.2.
43
CHAPTER 7.
VISUALISING EMOTION
44
Emotion
accepting
angry
anticipating
anxious
ashamed
contempt
depressed
disgusted
excited
guilty
happy
accepting
471
19
21
13
19
62
14
20
11
24
28
angry
29
300
24
45
36
27
74
51
20
26
50
anticipating
24
18
325
31
13
16
21
11
33
8
13
anxious
32
57
64
262
42
55
56
56
110
34
60
ashamed
39
32
24
84
398
171
23
44
28
39
42
contempt
52
14
31
27
23
362
17
33
22
39
17
depressed
41
99
58
61
57
36
199
79
63
63
93
disgusted
46
67
44
39
59
44
64
241
43
60
50
excited
22
17
59
71
19
19
33
18
261
16
25
guilty
12
23
20
36
50
28
40
48
25
372
27
happy
24
40
27
31
34
16
70
19
32
26
246
interested
41
28
36
39
21
40
34
44
29
26
21
joyful
30
17
28
24
22
25
27
19
27
24
28
miserable
32
48
33
25
28
16
47
48
22
33
68
pleased
61
33
50
29
37
44
25
83
54
30
45
relaxed
30
52
57
57
40
38
65
52
69
79
51
sad
28
63
31
42
33
28
64
47
35
37
56
scared
18
40
26
25
32
13
23
29
29
36
30
sleepy
20
50
53
78
42
14
86
55
99
42
62
stressed
21
45
45
53
30
19
69
33
45
45
38
surprised
27
38
44
28
65
27
49
70
43
41
50
Theoretical Positivity
0.24
0.22
0.57
0.28
0.23
0.20
0.29
0.29
0.50
0.23
0.44
Vector Magnitude
494.38
361.34
373.51
333.17
432.38
425.29
299.13
320.71
340.64
412.33
323.15
Emotion
interested
joyful
miserable
pleased
relaxed
sad
scared
sleepy
stressed
surprised
accepting
10
43
25
23
21
20
24
7
9
9
angry
32
23
46
35
31
43
46
35
54
33
anticipating
11
11
18
26
33
22
17
12
24
21
anxious
41
30
49
60
52
54
44
66
60
36
ashamed
28
23
33
31
27
31
59
25
22
50
contempt
36
37
27
26
23
30
17
5
16
18
depressed
38
46
85
44
68
91
71
89
114
62
disgusted
54
32
50
77
63
59
59
33
38
80
excited
19
32
12
28
21
43
45
36
48
29
guilty
16
28
28
21
55
28
34
24
31
20
happy
18
60
61
36
43
57
29
33
39
35
interested
489
22
31
32
42
32
25
18
25
46
joyful
24
432
37
31
32
23
17
11
10
22
miserable
29
48
300
22
31
44
33
22
47
35
pleased
44
59
22
387
32
43
30
28
21
64
relaxed
52
61
62
54
280
52
49
71
77
48
sad
40
38
56
30
55
258
27
46
48
40
scared
28
11
35
25
24
21
269
36
28
30
sleepy
27
18
44
36
79
64
92
407
84
50
stressed
19
19
45
27
62
44
39
54
274
25
surprised
45
27
34
49
26
41
74
42
31
347
Theoretical Positivity
0.64
0.64
0.25
0.58
0.46
0.28
0.26
0.23
0.25
0.56
Vector Magnitude
510.87
461.99
357.48
423.27
343.36
328.50
339.24
445.97
350.18
393.32
Table 7.1:
DELSAR1100 Clustering Matrix.
CHAPTER 7.
VISUALISING EMOTION
45
Emotion
accepting
angry
anticipating
anxious
ashamed
contempt
depressed
disgusted
excited
guilty
happy
accepting
1
0.240
0.229
0.242
0.214
0.340
0.275
0.304
0.222
0.193
0.288
angry
0.240
1
0.345
0.514
0.347
0.273
0.716
0.582
0.401
0.332
0.549
anticipating
0.229
0.345
1
0.477
0.261
0.272
0.478
0.410
0.490
0.261
0.384
anxious
0.242
0.514
0.477
1
0.497
0.411
0.646
0.556
0.715
0.390
0.552
ashamed
0.214
0.347
0.261
0.497
1
0.529
0.410
0.456
0.326
0.340
0.408
contempt
0.340
0.273
0.272
0.411
0.529
1
0.326
0.399
0.296
0.294
0.306
depressed
0.275
0.716
0.478
0.646
0.410
0.326
1
0.707
0.607
0.490
0.761
disgusted
0.304
0.582
0.410
0.556
0.456
0.399
0.707
1
0.503
0.485
0.556
excited
0.222
0.401
0.490
0.715
0.326
0.296
0.607
0.503
1
0.335
0.496
guilty
0.193
0.332
0.261
0.390
0.340
0.294
0.490
0.485
0.335
1
0.379
happy
0.288
0.549
0.384
0.552
0.408
0.306
0.761
0.556
0.496
0.379
1
interested
0.178
0.269
0.242
0.319
0.201
0.251
0.340
0.377
0.270
0.206
0.261
joyful
0.238
0.253
0.244
0.290
0.211
0.243
0.361
0.308
0.302
0.242
0.371
miserable
0.259
0.497
0.356
0.453
0.331
0.284
0.633
0.533
0.384
0.354
0.615
pleased
0.268
0.353
0.355
0.394
0.290
0.291
0.410
0.580
0.419
0.272
0.420
relaxed
0.253
0.481
0.454
0.557
0.350
0.316
0.680
0.584
0.533
0.504
0.552
sad
0.267
0.557
0.410
0.558
0.368
0.337
0.736
0.604
0.531
0.389
0.631
scared
0.247
0.495
0.373
0.503
0.432
0.295
0.591
0.552
0.509
0.391
0.501
sleepy
0.149
0.398
0.332
0.523
0.278
0.172
0.625
0.439
0.541
0.297
0.464
stressed
0.204
0.535
0.424
0.579
0.322
0.257
0.760
0.512
0.552
0.396
0.546
surprised
0.202
0.399
0.357
0.399
0.405
0.274
0.535
0.601
0.422
0.316
0.474
Emotion
interested
joyful
miserable
pleased
relaxed
sad
scared
sleepy
stressed
surprised
accepting
0.178
0.238
0.259
0.268
0.253
0.267
0.247
0.149
0.204
0.202
angry
0.269
0.253
0.497
0.353
0.481
0.557
0.495
0.398
0.535
0.399
anticipating
0.242
0.244
0.356
0.355
0.454
0.410
0.373
0.332
0.424
0.357
anxious
0.319
0.290
0.453
0.394
0.557
0.558
0.503
0.523
0.579
0.399
ashamed
0.201
0.211
0.331
0.290
0.350
0.368
0.432
0.278
0.322
0.405
contempt
0.251
0.243
0.284
0.291
0.316
0.337
0.295
0.172
0.257
0.274
depressed
0.340
0.361
0.633
0.410
0.680
0.736
0.591
0.625
0.760
0.535
disgusted
0.377
0.308
0.533
0.580
0.584
0.604
0.552
0.439
0.512
0.601
excited
0.270
0.302
0.384
0.419
0.533
0.531
0.509
0.541
0.552
0.422
guilty
0.206
0.242
0.354
0.272
0.504
0.389
0.391
0.297
0.396
0.316
happy
0.261
0.371
0.615
0.420
0.552
0.631
0.501
0.464
0.546
0.474
interested
1
0.179
0.270
0.258
0.335
0.312
0.268
0.189
0.249
0.310
joyful
0.179
1
0.346
0.301
0.352
0.321
0.239
0.178
0.239
0.246
miserable
0.270
0.346
1
0.302
0.496
0.540
0.446
0.356
0.510
0.383
pleased
0.258
0.301
0.302
1
0.390
0.402
0.348
0.277
0.319
0.416
relaxed
0.335
0.352
0.496
0.390
1
0.572
0.483
0.523
0.616
0.405
sad
0.312
0.321
0.540
0.402
0.572
1
0.464
0.478
0.564
0.453
scared
0.268
0.239
0.446
0.348
0.483
0.464
1
0.511
0.491
0.498
sleepy
0.189
0.178
0.356
0.277
0.523
0.478
0.511
1
0.532
0.355
stressed
0.249
0.239
0.510
0.319
0.616
0.564
0.491
0.532
1
0.378
surprised
0.310
0.246
0.383
0.416
0.405
0.453
0.498
0.355
0.378
1
Table 7.2:
Symmetrical Matrix of DELSAR1100 Clustering Emotion Vector Cosine Similarities.
CHAPTER 7.
VISUALISING EMOTION
46
Figure 7.1:
Multidimensional
Scaling of
DELSAR1100 Clustering Emotion Vector Cosine Similarities — red denotes our
identified primary emotions; bold denotes our DELSAR set and italics denotes our ELSA set.
CHAPTER 7.
VISUALISING EMOTION
47
We can clearly see that our identified basic emotions are in fact distributed nicely around
the outside of the space, while other emotions are located in the middle of the space, which
correlates to our basic emotion set being the most representative of
distinct dimensions
of
emotion space.
The three-dimensional
plot shows the same space with a reduction of
stress, or in other words, a more accurate representation of the similarity distance between
emotions; clusters such as [surprised, scared, disgusted], [accepting, ashamed, con-
tempt] and [happy, joyful, miserable] are clearly identified.
Whilst visualising emotion
space can be beneficial
to illustrate the relationship between a set of
emotions and help
identify such clusters,
these models do not illustrate the nature of
individual
emotions,
but rather their relativity to other emotions.
Having derived the dimensions of
the spe-
cific emotion spectrum of
the corpus we have analysed,
we propose a novel
technique to
visualising emotions called an Emotion Profile,
in which an emotion is plotted as an area
contained within a radar diagram, similar to circumplex models of affect.
7.2
Emotion Profiling
Typically,
emotions are represented as single points within some space,
as shown in the
previous section.
We can illustrate the nature of emotions by using an Emotion Profile:
a
plot modelling each emotion’s semantic ratio using a radar diagram.
Circumplex properties
are defined by the areas of
the profile in specific segments of
the diagram;
each octant,
quadrant and half has a specific property.
To effectively represent core affect properties,
we need to create the space theoretically based on Russell’s circular scaling of
emotions
to position all 21 emotions, with the exception of disgusted to preserve octal segmentation
(chosen for being the least distinct emotion), in order around a circumplex, according to the
two dimensional axis of polarity (valence) and engagement (arousal).
Figure 7.3 shows the
properties of specific regions of this emotion space according to each emotion’s theoretical
position around the circumplex, adapted from Russell’s CMA.
Generally speaking,
the primary benefit of a graph is to quickly identify correlations and
anomalies.
Plotting emotion profiles provides us with a graphic visualisation of emotion, so
we can easily identify key differences in the composition of emotions.
We could represent
this information numerically of course; the theoretical positivity of each emotion is calcu-
lated and appended to Table 7.1 to illustrate this, and a similar measure can be obtained
for arousal
levels.
Where the emotion element is equal
to the emotion being profiled,
the
average of adjacent cells is plotted to avoid skewing.
Figure 7.4 shows the emotion profiles of
the emotions depressed,
anxious,
relaxed and
stressed.
We can see that all
four emotions are more negative than positive (even with
sleepy as a positive emotion) and that relaxed is clearly a disengaged emotion.
They are
all
have a similar shape of profile,
or in other words,
people talk about these emotions in
much the same way.
This is also highlighted by their closeness in Figure 7.2.
What can these profiles tell
us about these emotions?
The key to interpreting emotion
profiles,
apart from the similarity of
profile shape,
is identifying anomalous spikes.
We
CHAPTER 7.
VISUALISING EMOTION
48
Figure 7.2:
Multidimensional
Scaling of DELSAR1100 Clustering Emotion Vector Cosine
Similarities — 3D Visualisation.
Yellow to Green indicates the depth of dimension 2.
CHAPTER 7.
VISUALISING EMOTION
49
Figure 7.3:
Emotion Profile Space — red (left half) denotes negative emotions, green (right
half) denotes positive emotions, dark denotes high arousal and light denotes low arousal.
can see that the profile of anxious has a spike in the dimension of ashamed ; if one is uses
similar language as used by people talking about the emotion ashamed then they are more
likely to feel anxious as opposed to any of the other three emotions.
It could also be said
that depressed people are more likely than those who are anxious or stressed to ‘hide’ their
emotion by using language similar to those expressing happiness.
We can also see that
stressed people talk similarly to those speaking about depression; based on their language,
this is possibly an indication that these people are more likely to become depressed.
CHAPTER 7.
VISUALISING EMOTION
50
Figure 7.4:
Emotion Profile of Depressed, Anxious, Relaxed and Stressed.
CHAPTER 7.
VISUALISING EMOTION
51
Figure 7.5:
Emotion Profile of Guilty.
CHAPTER 7.
VISUALISING EMOTION
52
We also show the emotion profile of guilty in Figure 7.5.
We can see that this is a more
disengaged emotion, and more negative than positive, based on the properties of the emo-
tion profile’s area as determined by Figure 7.3.
The spike in the relaxed dimension means
that people are more likely to use similar language to those expressing the emotion relaxed
when talking about guilt, possibly because it is a disengaged feeling, or due to a self-defence
mechanism that reduces the impact of feeling guilty.
This implies that, compared to other
emotions, guilt is somewhat harder to identify through latent semantics.
It also seems that
depression and guilt are linked.
It must be remembered that all the documents of expressed emotions used for our analysis
do not describe what people understand each emotion to mean;
it merely represents the
natural usage of these emotion keywords in language.
7.2.1
Emotion Wave
Specifically for temporal
data visualisation,
using an array of
emotion profiles to model
temporal
data generates a signal,
or wave form,
of emotion that can be used to measure
the conceptualisation of emotions over time.
Instead of a graph that shows the peak and
troughs of a variable in a single dimension,
using a time-lapse of emotion profiles enables
us to visualise how the spikes of
emotion profiles morph over time,
identifying volatility
and trends in the properties of each dimension and area covered by the profile.
7.3
Emotion Equations
In this section we briefly introduce the concept of
emotion equations.
The objective is
to see if
we can create a selection of
the secondary emotions identified in Chapter 6 by
combining particular primary emotions.
For this,
we again use DELSAR1100 clustering
data (see Table 7.1) as our emotion vectors.
While Plutchik theorises on which combinations
of emotions create another emotion,
we attempt to provide the first significant empirical
evidence that emotions can in fact be combined to create other emotions, to some extent.
7.3.1
Method
Each primary emotion vector is firstly zero-weighted — we set the element V
e
in the vector
of
emotion e to 0 — and then normalised by dividing each element by the sum of
the
vector’s elements.
We then combine each of the emotions by adding together their vectors
to create 78 pairwise emotion combination vectors.
For each emotion combination vector
we calculate the cosine similarity between it and each of
the secondary emotion vectors,
zero-weighted and normalised in the same way, using Equation 4.2.
CHAPTER 7.
VISUALISING EMOTION
53
7.3.2
Analysis
Preliminary results show that some emotions are more accurately represented as a combi-
nation of two emotions rather than the most similar emotion.
We present graphs for three
of the most interesting secondary emotions:
depressed, disgusted and guilty.
CHAPTER 7.
VISUALISING EMOTION
54
Figure 7.6:
Cosine similarity of primary emotion combinations to depressed.
CHAPTER 7.
VISUALISING EMOTION
55
Figure 7.7:
Cosine similarity of primary emotion combinations to disgusted.
CHAPTER 7.
VISUALISING EMOTION
56
Figure 7.8:
Cosine similarity of primary emotion combinations to guilty.
CHAPTER 7.
VISUALISING EMOTION
57
7.3.2.1
Depressed
The similarity of emotion combination vectors to the emotion vector of depressed is shown
in Figure 7.6.
We can see that overall,
emotion combinations that include the emotion
stressed are most similar to depressed.
Indeed, the emotion vector for stressed is the most
similar to depressed out of all the secondary emotions; however, by combining it with the
second most similar emotion sleepy,
we increase the similarity from an average of 88% to
94%.
This is important to consider, as we identify other emotional factors contributing to
depression other than the primary ‘cause’ of the emotion, this being stress.
7.3.2.2
Disgusted
The similarity of emotion combination vectors to the emotion vector of disgusted is shown
in Figure 7.7.
Again,
we can see the most similar emotion (this time being surprised ) is
dominant in all
the most similar emotion combination vectors,
and by combining it with
the emotion ashamed we increase the similarity from an average of 79% to 89%.
We should
note that the emotions pleased and interested are also similar,
however not only do their
combinations score fractionally less than ashamed, it doesn’t seem psychologically correct
to use them as part of the emotion disgust.
Their similarity is due to the similarity of the
language people use, so we could say that people using similar language as those expressing
the emotions pleased and interested are, statistically speaking, more likely to feel disgusted.
7.3.2.3
Guilty
The similarity of emotion combination vectors to the emotion vector of guilty is shown in
Figure 7.8.
This is an example where the most similar emotion of a particular emotion is
a single emotion rather than a combination of
emotions,
namely ashamed,
which is 11%
more similar to guilty than the most similar emotion combination vector.
This provides
evidence that guilty is more likely to be a basic emotion than other secondary emotions we
have analysed.
The similarity of emotion combination vectors to the emotion vector of happy can be seen
in Chapter D.
7.4
Discussion
Emotions are notoriously difficult to visualise.
The predominant method for showing how
emotions change over time is by measuring the quantity of expressions at each time point
without any regard for dimensionality, possibly due to a lack of post-processing of collected
emotion data.
Sentiment is usually visualised in this way, however, when applied to emo-
tions,
each emotion is determined as being either positive or negative.
In our model,
we
propose that emotions are a ratio of both positive and negative, and both engaged and dis-
CHAPTER 7.
VISUALISING EMOTION
58
engaged properties that morph according to time, relative to the particular topic or corpus
being analysed.
Emotion waves and profiles can be used as signatures in which pattern
matching techniques can be applied for predictive analysis over a time series.
Using these
signatures as definitions of emotions can generate a more accurate analysis of emotion or
mood (for example, calmness) compared to more theoretical definitions.
Emotion equations is an area which we will
be studying at greater depth.
We have only
taken combinations of secondary emotions and a more concentrated study will involve com-
bining a much greater number of both primary and secondary emotions to create axiomatic
equations of emotions.
Other basic operators will also be investigated, such as taking away
emotions and adding varying intensities of emotions, for example adding a fraction of one
emotion to another emotion.
Having said that, we have demonstrated that both our clus-
tering algorithm and method of
combining emotions provide a fairly accurate meaning
to certain emotions,
which is somewhat impressive seeing as we have only analysed 1100
documents extracted from a micro-blogging site with little parsing of the data nor strict
constraints to data collection.
Ideally,
we would have liked to test Plutchik’s theory of
emotion combinations, however we do not currently hold the data for his specific emotion
keywords,
and therefore have presented our method and analysis for a few other basic
emotions.
7.4.1
Emotion Classification and Discovery
The most obvious application of
this research is to the mining,
classification and identi-
fication of emotions in text.
As we have discussed in Chapter 3,
many computer science
studies of
emotion include the use of
a set of
basic emotions,
and Ekman’s set is most
commonly used.
However,
we should not assume that Ekman’s basic set of
emotions is
the most ideal
to use in all
situations.
Any studies involving seeding terms from a set of
emotions should consider the dimensions of emotion relative to the topic before seeding to
ensure a representative spectrum of emotion is taken into account.
In fact,
the keywords
may not even be traditional
emotions at all.
Emotions mean different things dependent
on the thematic concerns of a corpus.
For example,
the emotion spectrum will
look very
different when classifying political
news headlines compared to classifying fairy tales —
the same emotion words can be used differently in these contexts due to the variance of
representative emotion spectrums.
We have highlighted the fact that emotions should not be considered as strictly positive or
negative, but as a ratio of these.
This affects sentiment research, which has mainly focused
on mining emoticons — future research could involve the use of emotion keywords instead,
increasing data granularity, and perhaps accuracy.
7.4.2
Psychological Applications
Arguably, the most interesting aspect of this research, at least with regard to the emotion
domain, is its direct psychological applications.
An interesting idea arising from accessibil-
CHAPTER 7.
VISUALISING EMOTION
59
ity to co-occurrence data is the potential ability to subliminally infer specific emotions by
carefully constructing sentences that convey an arbitrary point across using specific words
and phrases that are more commonly expressed when feeling a particular emotion.
In other
words, we could create ‘emotional dialects’, which could prove to be an interesting tool for
reassurance or, on the other end of the scale, manipulation.
7.4.2.1
Identification of Underlying Emotional Conditions
Emotion Profiles can be generated using any form of
natural
text,
from emails to tran-
scripts of interrogations.
It is particularly useful
to find links between specific emotions,
for example,
depression,
to other underlying emotions that may not have been directly
targeted,
in this case,
sleepiness.
The important aspect to take into consideration when
analysing emotion profiles is that fact that it is a visualisation of LSC data, as opposed to
a general view of the emotion spectrum, so it defines individual emotions as a combination
of other emotions.
7.4.2.2
Emotional Engineering
Deriving psychological emotion equations, specifically relative to a particular domain, will
enable psychological
researchers to be able to break down feelings to their constituent
emotions.
This will
be useful
to understand which emotions to add or take away from
an existing emotional
condition to create another,
more preferable emotion.
This could
lead to the creation of ‘new emotions’; existing emotions could be manipulated, combined
and ‘re-packaged’
in order to explain types of behaviour,
not traditionally thought to be
a particular emotion.
This mechanism is not dissimilar to how people of different cultures
divide the affective world into different basic emotion categories.
Russell (1991) describes
several emotion words in other languages for which no word exists in English.
An example
from German is the word schadenfreude,
which refers to pleasure derived from another’s
displeasure.
An example from Japanese is itoshii,
which refers to longing for an absent
loved one;
another is ijirashii,
which refers to a feeling associated with seeing someone
praiseworthy overcoming an obstacle.
There may be many more different types of emotions
to those we are conceptually aware of,
and if
this is the case,
we may need to approach
them in different ways.
7.4.2.3
Detecting Unconscious Stress Factors
We have seen that emotion conceptualisation is dependent on geographical region — sim-
ilar to dialects of
a language — but why could this be?
We have shown,
using emotion
combinations, that stress is highly correlated with depression, and it is also correlated with
anxiety.
We could use our data to identify correlations between properties of geographical
regions, such as density of roads, number of factories and variety of entertainment venues.
Instead of assuming that specific properties contribute to stress, we can actually determine
CHAPTER 7.
VISUALISING EMOTION
60
what factors are indeed contributing;
it could be the case that seemingly negative prop-
erties could in fact have a negligible role in causing stress, and the opposite could also be
true.
7.4.2.4
Clinical Assessments
The disadvantage with our current emotion extraction method is that not everyone will de-
scribe experiences using emotion keywords — we have aggregated many people’s responses
in the present study.
A more powerful method of identifying emotions is by using self-report
psychometric instruments that involve participants completing a written or oral question-
naire regarding their emotional experiences in order to analyse their responses taking into
account a number of factors.
Examples of such instruments include the Depression Anx-
iety Stress Scale (Lovibond and Lovibond,
1995),
the Beck Hopelessness Scale (Beck and
Lester,
1974) and Profile Of Mood States (McNair et al.,
1992).
Indeed Pepe and Bollen
(2008) modified Profile Of
Mood States to infer the current global
mood on Twitter,
as
opposed to mining for phrases such as “I feel calm”.
Using LSC data, however, we are able
to identify otherwise unknown unconscious factors that contribute to specific emotions,
which could lead to more accurate questionnaires being devised.
Chapter 8
Conclusion
A vast majority of computer scientists tend to use Ekman’s basic emotion set for emotion
categorisation,
and it appears that,
semantically,
it is the most distinct set,
with a 2.9%
increase in accuracy compared to the average of
the remaining sets.
Using an iterative
algorithm based on LSC, we have discerned a set of eight (rather than Ekman’s six) basic
emotion keywords that have been calculated to be the most semantically distinct.
This set
performed better in all semantic tests than all of the basic emotion models analysed, with
a 6.1% increase in accuracy over Ekman’s basic emotion set,
providing evidence that by
carefully selecting emotion keywords, more of the emotion spectrum can be accounted for.
Emotions must be seen as relative to a specific domain.
This research has not focused
on any particular domain as it attempts to generalise the nature of emotions, however, as
we have seen with the geographical
testing,
the composition of
optimal
sets were highly
dynamic and dependent on region, even though negligible alterations were observed when
testing a random sample — if there is an underlying domain, then its semantically distinct
set of emotion dimensions will differ to those of another corpus of a different domain.
If we
had to decide upon a universal set of basic emotions, it would be those emotions that appear
thrice or greater in the derived basic emotion sets within the analysis (ELSA,
DELSAR
and the optimal ELSA sets derived from USP77, USE91, USC92, UK49, RAND77):
accepting anxious ashamed contempt interested joyful pleased stressed
We do not recommended the use of these emotion dimensions universally,
although they
are a much more accurate and complete set of basic emotions to base emotion classification
with than existing basic emotion sets, and certainly more distinct than Ekman’s set, at least
in terms of the language used for each expression of emotion.
Similar to Kim et al.’s (2010)
point of view, we recommend that a different basic emotion set should be chosen dependent
on the domain and corpus,
suggesting that basic emotions are ultimately not universal
and correlated with underlying thematic concerns within the corpus under analysis.
The
semantic nature of our analysis means that our algorithms can achieve similar results in
any language, so long as the language within the corpus under analysis is consistent.
61
CHAPTER 8.
CONCLUSION
62
This research has been limited to the corpus used; while extremely relevant, the extent in
which temporal
effects were mitigated may not have been sufficient.
We have based our
research on 21 thousand tweets collected over ten days, and the same amount of data over
several
months may or may not produce different results.
The primary limitation of our
emotional Twitter corpus is that it consists of expressions that mention an emotion keyword
without regard to whether the user actually felt the expressed emotion.
However, we assume
that the mere use of an emotion keyword still
attributes to how people understand each
emotion to be.
Additionally, adding more emotion keywords may change derived sets, but
although we could have used many more popular emotion keywords and synonyms,
we
decided against this as the current study focuses on specific basic emotion sets.
We also
noted that adding an additional
six basic emotions from Russel’s set negligibly altered
our results.
The Emotional
Twitter Corpus is useful
for those wanting to obtain raw
explicit expressions of emotion.
Each expression is labelled,
rendering it especially useful
for classification projects,
although the data as it stands remains unparsed for duplicates
or identified ‘junk’ data.
We have essentially ranked emotions and basic emotion sets using our algorithms according
to a metric of semantic distinctiveness of extracted expressions from Twitter.
Whilst this
is useful for discovering psychological similarities of emotion expression, the real power lies
in the application of the resulting clustering data.
By visualising LSC data matrices,
we
are able to compare the similarity of compound emotions, analyse the composite properties
of emotions and highlight how specific emotions interact with each other, with applications
ranging from clinical assessments to applied psychological research.
Emotion may contribute to evolution on a much grander scale than previously thought.
Indeed,
Izard (2009) suggests that the main component in evolution could be Emotion
Schemas, that is, evolution of actions through imitative learning of specific emotions.
Map-
ping such processes could shed light on an updated and, combined with genetic algorithms,
a more complete model of human evolution.
8.1
Summary of Contributions
An Emotional
Twitter Corpus.
We have created a PHP script that streams a large
number of emotional expressions from Twitter that can be executed from a UNIX terminal
and run in the background.
Using this script,
we have created a corpus of
emotional
tweets, stored in a database, with each expression emotion-tagged and linked to additional
information such as time (useful for temporal analysis) and nationality (useful for cultural
analysis).
In the process, we have discovered that the stream rates of emotions are highly
irregular,
ranging from 2 to 200 tweets per minute for the emotions analysed,
including
any word filters that were used.
Using consistent quantities of tweets for each emotion was
key to this research,
so a natural limit of the number of documents we could analyse was
imposed, this being the number of documents harvested from the emotion with the lowest
stream rate.
CHAPTER 8.
CONCLUSION
63
Semantic Distinctiveness Evaluation of Basic Emotion Sets.
We evaluate six basic
emotion sets on a scale of
semantic distinctiveness,
based on the theory that the more
distinct the language is used to express a certain emotion,
then conceptually,
i.e.
what
we understand that emotion keyword to mean,
the more psychologically irreducible that
emotion is.
The less semantically accurate a set of emotions is, then the more similar these
emotions are to each other, or in other words, if similar words are used when expressing two
different emotions,
then these emotions are,
in theory,
conceptually,
and thus psychologi-
cally, similar.
A large majority of computer scientists tend to use Ekman’s basic emotion
set for emotion categorisation, and it appears that, semantically, it is the most distinct set.
A Semantically Irreducible Emotion Set.
Using DELSAR,
an iterative algorithm
based on LSC,
we derive an optimal
basic emotion set consisting of
eight,
rather than
six,
emotions.
This set performed better in all
semantic tests than all
of the basic emo-
tion models analysed, with a 6.1% increase in distinctiveness over Ekman’s basic emotion
set.
Furthermore,
the derived set satisfies the three laws of
basic emotions.
We also use
our ELSA algorithm to derive optimal
basic emotion sets using a variety of
geographi-
cally specific subcorpora, and present a Semantically Irreducible Emotion Set based on the
combination of these derived basic emotion sets and the derived sets using DELSAR and
ELSA.
The Theory of Emotional Relativity.
The Theory of Emotional Relativity is a fusion
of the Linguistic Relativity Hypothesis and Russell’s (1991) Cultural Relativity proposition.
We propose the theory that each person’s conceptualisation of their emotion spectrum is
unique;
throughout this project,
we have aggregated these individualised emotion spaces,
although we began to test this theory by analysing subsets of the corpus containing tweets
from specific geographical
areas.
We find that,
while the majority of
areas are still
best
modeled by the optimal basic emotion set, this is not true for all areas; in some cases we find
that a different set best models the dimensions of their emotion space.
Furthermore,
we
discern the optimal basic emotion set for each geographical area, and find that constituent
emotions are as disorderly as the original collection of basic emotion sets.
Emotion Visualisation Techniques.
We have demonstrated four key techniques of
visualising emotions that illustrate specific properties of emotions,
making the LSC data
more accessible and easier to navigate:
Multi-Dimensional Scaling that highlights properties
of emotions relative to each other, Emotion Profiling that highlights individual properties of
specific emotions, Emotion Waves that aim to highlight emotional trends and correlations
over time by visualising a time-lapse of emotion profiles, and Emotion Equations that aim
to illustrate compounded emotions and their similarity to individual emotions.
Applications of Emotion Data. We have discussed a variety of important applications of
LSC data, including determining unconscious factors contributing to experienced emotions
and improvement and enhancement of clinical
assessments.
We have also introduced the
notion of Emotional Engineering.
This could lead to the creation of ‘new emotions’; existing
emotions could be manipulated,
combined and ‘re-packaged’
in order to explain types of
behaviour,
not traditionally thought to be a particular emotion.
There may be different
types of emotions to those we are conceptually aware of,
and if this is the case,
we may
CHAPTER 8.
CONCLUSION
64
need to approach them in different ways.
Focusing on expressions in text allows our methods to be applied to the wealth of data on
the Internet,
and text in general.
We are slowing beginning acquire a full
understanding
of the mechanisms of emotion,
increasing our awareness of originally unconscious factors,
potentially up to a point in which we will
be able to predict both individual
and global
emotions in response to arbitrary scenarios.
Emotion theory remains an area of
active
Computer Science research, and there are several matters yet to be thoroughly researched.
Chapter 9
Future Research
Apart from expanding on the applications as discussed in Chapter 7, there are many areas
that require extensive research to fully understand the nature of emotion.
Does anonymity
increase negativity?
Does the negation of
an emotion equate to its psychological
oppo-
nent?
How closely linked are emotion and sentiment?
How does the time of
day affect
our emotions?
In addition to these questions,
a number of
research projects have been
conceptualised by the author.
9.1
Current Project Extensions
The accuracy of
our data collection could be improved.
We would like to extend our
streaming script to a list of all emotions by using an extensive list of keywords seeded with
synonyms from WordNet,
and also taking into consideration colloquialisms of
emotion
keywords,
such as jeals (meaning jealous).
Another method we would like to integrate
is using LDA to populate the initial
list of keywords from a corpus,
thus automating the
keyword selection process and identifying underlying thematic concerns for a more accurate
seeding of keywords.
Applying our algorithms to Facebook profile data,
we could be able to detect the indi-
vidualisation of
emotion by discerning emotional
spaces right down to individual
people
(in other words, attitudes), which could have applications in consumer profiling and online
dating.
It may be the case that using Facebook data would produce significantly different
results to our Twitter-based analysis, possibly due to both the increase in blog space and
the privatised nature of posting.
Since the majority of profiles are limited to friends, there
may be a considerable lack of public image concerns, and analysing this data could prove
to create a more accurate representation of emotional mechanisms.
There could, however,
be social
image concerns.
We would also like to find some sort of
measurement for determining the level
of
bias
resulting from public image considerations.
By comparing public emotions,
for example
65
CHAPTER 9.
FUTURE RESEARCH
66
from Twitter,
with emotions thought to have been expressed in private,
for example the
Enron internal
email
data set,
we could be able to detect a semantic measurement of
publicity bias.
9.2
Economic Prediction
There has been a growing amount of research involving stock market prediction techniques
by analysing social
network data,
specifically Twitter.
As we have previously discussed,
Bollen et al.
(2011) used a modified version of
Profile Of
Mood States to analyse the
current mood on Twitter, and found that the calmness dimension predicted the movement
of
the Dow Jones Industrial
Average Index four days in advance,
with an accuracy of
87%.
More recently,
Ruiz,
Hristidis,
Castillo,
Gionis and Jaimes (2012) created trading
strategies that outperformed baseline strategies by extracting connected components and
interaction nodes from tweets.
By extending such research to cover a wide range of sources
and combining it with our mechanisms of
emotion analysis,
we would be able to more
accurately predict the economy,
possibly right down to individual stock.
As decisions are
heavily influenced by emotions,
the use of
real-time emotion semantic analysis could be
considered for outperforming more traditional trading strategies.
9.3
General Principle of Emotion
We present the General
Principle of Emotion:
the theory that differential emotion values
may prove to be more accurate in defining emotion qualia than the experience of emotion
qualia at each point in time.
These ‘Delta Emotion’
values infer the emotional
response
of
a given time point (i.e.
event) by capturing and analysing the emotional
responses
at either side of
the time point,
and could provide a more genuine emotion signal
for
predictive analysis.
Delta emotions are geared towards long-term analysis;
specifically,
it
could be thought of as measuring shifts in perception.
Using this data, we could be able to
measure what we call Emotion Injection, or in other words, measuring to what extent does
perception change according to which, why, how and when emotions are experienced.
If we
can understand someone else’s emotional perception, we will better be able to manipulate
their emotions using language,
a position not to be taken lightly without a vast array of
opportunities and consequences.
9.4
Machine Consciousness
There is a strong link between emotion conceptualisation and memetics.
The term meme
was introduced and defined by Dawkins (1990) as “the basic unit of cultural transmission,
or imitation”, and in the English Oxford Dictionary as “an element of culture that may be
considered to be passed on by non-genetic means”.
Emotion may contribute to evolution
CHAPTER 9.
FUTURE RESEARCH
67
on a much grander scale than previously thought.
Indeed,
Izard (2009) suggests that the
main component in evolution could be Emotion Schemas,
that is,
evolution of
actions
through imitative learning of specific emotions.
Mapping such processes could shed light
on an updated and,
combined with genetic algorithms,
a more complete model
of human
evolution.
Memetic theory states that the ability to imitate is the only requirement for
language to occur in evolution,
and it has been shown in several
studies that syntax and
semantics emerge spontaneously (for a discussion, see Blackmore, 2003).
Thus, by analysing
language we should be able to reverse-engineer the imitative mechanisms of
humans.
It
may be the case that we cannot simply build the most accurate ‘emotion brain’ and hard
code it into a machine;
an emotional
brain would need to experience and evolve using
emotion-based memetic algorithms.
Using such a process would enable us to create an
emotional
projection of
ourself
with the potential
for acquiring a human-like illusion of
consciousness;
indeed,
it may hold key to simulating minds,
and could provide the first
step towards testing Bostrom’s (2003) simulation hypothesis.
9.5
Epilogue
We have conducted thorough research and discovered emotional mechanisms that advance
our understanding of the individual
conceptualisation of emotion qualia through analysis
of social language.
We have explored what emotional semantic analysis data could reveal
about the nature of emotions and have discussed its potential applications to both clinical
and general psychological research.
We have not, however, spoken of the emotion love.
It
could be argued that no amount of language could describe what true love is.
Or, equally
as plausible, that true love is in fact an illusion, which is not hard to believe if consciousness
itself is an illusion.
Perhaps an emotional simulation of ourselves could tell us the answer.
Whichever direction our research into emotions take us, there is still much to be learned.
Bibliography
Alm,
E.
C.
O.
(2008),
Affect in Text and Speech,
PhD thesis,
University of
Illinois at
Urbana-Champaign.
Andrews, N. O. and Fox, E. A. (2007), Recent developments in document clustering, Tech-
nical report, Computer Science, Virginia Tech.
Aristotle (350BC), Rhetoric.
Asur, S. and Huberman, B. A. (2010), ‘Predicting the future with social media’.
Barrett, L. F. (2006), ‘Solving the emotion paradox:
Categorization and the experience of
emotion’, Personality and Social
Psychology Review 10(1), 20–46.
Barrett,
L.
F.,
Lindquist,
K.
A.
and Gendron,
M.
(2007),
‘Language as context for the
perception of emotion’, Trends in Cognitive Sciences 11(8), 327–332.
Beck, A. and Lester, D. (1974), ‘Scoring algorithm :
Beck hopelessness scale (bhs)’, Journal
of Consulting and Clinical
Psychology .
Berridge, K. C. (2003), Comparing the emotional brains of humans and other animals, in
‘Handbook of Affective Sciences’, Oxford University Press US, chapter 3, pp. 25–51.
Bifet, A. and Frank, E. (2010), ‘Sentiment knowledge discovery in twitter streaming data’,
Discovery Science 6332, 1–15.
Bilovich, A. and Bryson, J. J. (2008), Detecting the evolution of semantics and individual
beliefs through statistical
analysis of
language use,
in ‘Naturally-Inspired Artificial
Intelligence - Papers from the AAAI Fall Symposium’, AAAI, pp. 21–26.
Blackmore, S. (2003), ‘Consciousness in meme machines’, Journal of Consciousness Studies
10(4), 19–30.
Bollen, J., Mao, H. and Zeng, X. (2011), ‘Twitter mood predicts the stock market’, Journal
of Computational
Science .
Bollen,
J.,
Pepe,
A.
and Mao,
H.
(2009),
‘Modeling public mood and emotion:
Twitter
sentiment and socio-economic phenomena’, CoRR abs/0911.1583.
informal publica-
tion.
68
BIBLIOGRAPHY
69
Bostrom,
N.
(2003),
‘Are you living in a computer simulation?’,
Philological
Quarterly
53(211), 243–255.
Bradley,
M.
(1994),
‘Measuring emotion:
The self-assessment manikin and the semantic
differential’, Journal
of Behavior Therapy and Experimental
Psychiatry 25(1), 49–59.
Breazeal, C. (2003), ‘Emotion and sociable humanoid robots’, Int. J. Hum.-Comput. Stud.
59(1-2), 119–155.
Bullinaria, J. A. and Levy, J. P. (2007), ‘Extracting semantic representations from word co-
occurrence statistics:
a computational study.’, Behavior Research Methods 39(3), 510–
526.
Cacioppo, J. T. and Berntson, G. G. (1994), ‘Relationship between attitudes and evaluative
space:
A critical
review,
with emphasis on the separability of
positive and negative
substrates’, Psychological
Bulletin 115(3), 401–423.
Cannon,
W.
(1922),
Bodily changes in pain,
hunger,
fear and rage:
an account of
recent
researches into the function of emotional
excitement, D. Appleton and Company.
Carreti,
L.,
Mercado,
F.,
Tapia,
M.
and Hinojosa,
J.
A.
(2001),
‘Emotion,
attention,
and
the negativity bias,
studied through event-related potentials.’,
International
Journal
of Psychophysiology 41(1), 75–85.
Chmiel,
A.,
Sobkowicz,
P.,
Sienkiewicz,
J.,
Paltoglou,
G.,
Buckley,
K.,
Thelwall,
M.
and
Holyst, J. A. (2011), ‘Negative emotions boost user activity at bbc forum’, Physica A:
Statistical
Mechanics and its Applications 390(16), 2936–2944.
Church,
K.
W.
and Hanks,
P.
(1990),
‘Word association norms,
mutual
information,
and
lexicography’, Comput. Linguist. 16, 22–29.
Damasio,
A.
(1999),
The Feeling of
What
Happens:
Body Emotion and the Making of
Consciousness., Vintage.
Danisman,
T.
and Alpkocak,
A.
(2008),
Feeler:
Emotion classification of
text using vec-
tor space model,
in ‘AISB 2008 Convention,
Communication,
Interaction and Social
Intelligence’, Vol. vol. 2.
Darwin, C. (1872), The expression of the emotions in man and animals, John Murray.
Dawkins, R. (1990), The Selfish Gene, Oxford University Press.
De Martino,
B.,
Kumaran,
D.,
Seymour,
B.
and Dolan,
R.
(2006),
‘Frames,
biases,
and
rational decision-making in the human brain’, Science 313(5787), 684–7.
Dennett, D. (1988), Quining qualia, in A. J. Marcel and E. Bisiach, eds, ‘Consciousness in
Contemporary Science’, Oxford University Press, Oxford, pp. 42–77.
Ekman, P. (2004), Emotions Revealed:
Understanding Faces and Feelings, Phoenix.
BIBLIOGRAPHY
70
Ekman, P. and Davidson, R. (1994), The Nature of Emotion, Antecedent Events and Emo-
tion Metaphors, Oxford University Press, United Kingdom.
Ekman, P., Friesen, W. V. and Ellsworth, P. (1972), Emotion in the Human Face, Oxford
University Press.
Fellbaum,
C.,
ed.
(1998),
WordNet:
An Electronic Lexical
Database (Language,
Speech,
and Communication), The MIT Press.
Gabrilovich,
E.
and Markovitch,
S.
(2007),
Computing
semantic
relatedness
using
wikipedia-based explicit semantic analysis,
in ‘Proceedings of the 20th international
joint conference on Artifical
intelligence’,
IJCAI’07,
Morgan Kaufmann Publishers
Inc., San Francisco, CA, USA, pp. 1606–611.
Gaussier,
E.
and Goutte,
C.
(2005),
‘Relation between plsa and nmf
and implications’,
Learning pp. 601–602.
Girolami,
M.
and Kaban,
A.
(2003),
On an equivalence between plsi
and lda,
in ‘SIGIR
’03:
Proceedings of the 26th annual international ACM SIGIR conference on Research
and development in informaion retrieval’, ACM, pp. 433–434.
Go, A., Bhayani, R. and Huang, L. (2009), ‘Twitter sentiment classification using distant
supervision’, Processing pp. 1–6.
Gray, J. and McNaughton, N. (1996), ‘The neuropsychology of anxiety; reprise’, Nebraska
Symposium on Motivation 43, 61–134.
Harris, Z. S. (1968), Mathematical
Structures of Language, Wiley, New York, NY, USA.
Hering, E. (1964), Outlines Of A Theory Of The Light Sense, Harvard University Press.
Izard, C. E. (1971), The Face of Emotion, Appleton-Century-Crofts, New York :.
Izard, C. E. (2009), ‘Emotion theory and research:
highlights, unanswered questions, and
emerging issues’, Annual
review of psychology 60(1), 1–25.
Jarvilehto, T. (2000), ‘Feeling as knowing part i:
Emotion as reorganization of the organism-
environment system’, Consciousness and Emotion 2(1), 245–257.
Jiang,
L.,
Yu,
M.,
Zhou,
M.,
Liu,
X.
and Zhao,
T.
(2011),
Target-dependent twitter sen-
timent classification,
in ‘Proceedings of the 49th Annual
Meeting of the Association
for Computational Linguistics:
Human Language Technologies - Volume 1’, HLT ’11,
Association for Computational Linguistics, pp. 151–160.
Kamvar,
S.
D.
and Harris,
J.
(2011),
We feel
fine and searching the emotional
web,
in
‘Proceedings of
the fourth ACM international
conference on Web search and data
mining’, WSDM ’11, ACM, pp. 117–126.
Keshtkar, F. and Inkpen, D. (2010), A Corpus-based Method for Extracting Paraphrases of
Emotion Terms, number June, Association for Computational Linguistics, pp. 35–44.
BIBLIOGRAPHY
71
Kim,
S.
M.,
Valitutti,
A.
and Calvo,
R.
A.
(2010),
Evaluation of
unsupervised emotion
models to textual affect recognition, in ‘Proceedings of the NAACL HLT 2010 Work-
shop on Computational Approaches to Analysis and Generation of Emotion in Text’,
Association for Computational Linguistics, Los Angeles, CA, pp. 62–70.
Kloumann,
I.
M.,
Danforth,
C.
M.,
Harris,
K.
D.,
Bliss,
C.
A.
and Dodds,
P.
S.
(2011),
‘Positivity of the english language’, CoRR abs/1108.5192.
Landauer, T. K. and Dumais, S. T. (1997), ‘Solution to Plato’s Problem:
The Latent Se-
mantic Analysis Theory of Acquisition, Induction and Representation of Knowledge’,
Psychological
Review (104).
Lee, D. D. and Seung, H. S. (1999), ‘Learning the parts of objects by non-negative matrix
factorization’, Nature 401, 788–791.
Lee, S., Chen, Y. and Huang, C. (2010), Text-driven rule-based system for emotion cause
detection,
in ‘Proceedings of
the NAACL HLT 2010 Workshop on Computational
Approaches to Analysis and Generation of Emotion in Text’, pp. 45–53.
Lindquist, K. A. and Barrett, L. F. (2008), ‘Constructing emotion:
The experience of fear
as a conceptual act’, Psychological
Science 19(9), 898–903.
Lindquist, K. A., Barrett, L. F., Bliss-Moreau, E. and Russell, J. A. (2006), ‘Language and
the perception of emotion.’, Emotion 6(1), 125–138.
Liu, H., Lieberman, H. and Selker, T. (2003), A model of textual affect sensing using real-
world knowledge,
in ‘Proceedings of
the 8th international
conference on Intelligent
user interfaces’, IUI ’03, ACM, pp. 125–132.
Lovibond,
S.
H.
and Lovibond,
P.
F.
(1995),
Manual
for the Depression Anxiety Stress
Scales, Psychology Foundation.
Lowe, W. (2001), Towards a theory of semantic space, in ‘Proceedings of the 23rd Annual
Meeting of the Cognitive Science Society’, pp. 576–581.
Lu, C.-Y., Lin, S.-H., Liu, J.-C., Cruz-Lara, S. and Hong, J.-S. (2010), ‘Automatic event-
level textual emotion sensing using mutual action histogram between entities’, Expert
Systems with Applications:
An International
Journal
archive 37(5).
M.
Conover,
B.
Gonalves,
J.
R.
A.
F.
F.
M.
(2011),
Predicting the political
alignment of
twitter users, in ‘Third IEEE International Conference on Social Computing’.
Matthis,
I.
(2000),
‘Sketch for a metapsychology of affect’,
International
Journal
of
Psy-
choanalysis 81, 215–227.
McNair, D., Lorr, M. and Droppleman, L. (1992), Profile of mood states, EdITS.
Nakov, P., Popova, A. and Mateev, P. (2001), Weight functions impact on lsa performance,
in ‘EuroConference RANLP’2001 (Recent Advances in NLP’, pp. 187–193.
BIBLIOGRAPHY
72
Newman, M. L., Pennebaker, J. W., Berry, D. S. and Richards, J. M. (2003), ‘Lying words:
Predicting deception from linguistic styles’, Personality and Social Psychology Bulletin
29(1901), 665–675.
Oatley,
K.
and Johnson-Laird,
P.
N.
(1987),
‘Towards a cognitive theory of
emotions’,
Cognition & Emotion 1(1), 29–50.
Ortony,
A.,
Clore,
G.
and Collins,
A.
(1988),
The cognitive structure of
emotions,
Cam-
bridge University Press, United Kingdom.
Ortony,
A.
and Turner,
T.
J.
(1990),
‘What’s basic about basic emotions?’,
Psychological
Review 97(3), 315–331.
Pak,
A.
and Paroubek,
P.
(2010),
Twitter as a corpus for sentiment analysis and opinion
mining, in ‘Proceedings of the Seventh conference on International Language Resources
and Evaluation (LREC’10)’, European Language Resources Association (ELRA), Val-
letta, Malta.
Panksepp,
J.
(1982),
‘Toward a general
psychobiological
theory of
emotions’,
Behavioral
and Brain Sciences 5(3), 407–467.
Panksepp,
J.
(1998),
Affective neuroscience:
the foundations of
human and animal
emo-
tions, Oxford University Press.
Panksepp,
J.
(2000),
The
Caldron of
Consciousness:
Motivation,
affect
and
self-
organization - An anthology (Advances in Consciousness Research).
Pennebaker, J. W. and King, L. A. (1999), ‘Linguistic styles:
language use as an individual
difference’, Journal
of personality and social
psychology 77(6), 1296–1312.
Pepe,
A.
and Bollen,
J.
(2008),
‘Between conjecture and memento:
shaping a collective
emotional perception of the future’, Artificial
Intelligence .
Peter,
R.,
Shivapratap,
G.,
Divya,
G.
and Kp,
S.
(2009),
‘Evaluation of
svd and nmf
methods for latent semantic analysis’, International
Journal
of Recent Trends in En-
gineering 1(3), 308–310.
Plutchik, R. (1980), A general psychoevolutionary theory of emotion, Academic press, New
York, pp. 3–33.
Posner,
J.,
Russell,
J.
A.
and Peterson,
B.
S.
(2005),
‘The circumplex model
of
affect:
an integrative approach to affective neuroscience,
cognitive development,
and psy-
chopathology.’, Development and Psychopathology 17(3), 715–734.
Qiu, L., Wu, Y. and Shao, Y. (2011), Combining contextual and structural information for
supersense tagging of chinese unknown words, in ‘Proceedings of the 12th international
conference on Computational linguistics and intelligent text processing - Volume Part
I’, CICLing’11, Springer-Verlag, pp. 15–28.
BIBLIOGRAPHY
73
Read,
J.
(2005),
Using emoticons to reduce dependency in machine learning techniques
for sentiment classification, in ‘Proceedings of the ACL Student Research Workshop’,
pp. 43–48.
Recchia,
G.
and Jones,
M.
N.
(2009),
‘More data trumps smarter algorithms:
Compar-
ing pointwise mutual
information with latent semantic analysis’,
Behavior Research
Methods 41(3), 647.
ˇ
Reh˚uˇrek,
R.
and Sojka,
P.
(2010),
Software Framework for Topic Modelling with Large
Corpora,
in ‘Proceedings of
the LREC 2010 Workshop on New Challenges for NLP
Frameworks’, ELRA, Valletta, Malta, pp. 45–50.
Roseman, I. J., Spindel, M. S. and Jose, P. E. (1990), ‘Appraisals of emotion-eliciting events:
Testing a theory of discrete emotions’,
Journal
of Personality and Social
Psychology
59(5), 899–915.
Rosenberg,
S.
D.
and Tucker,
G.
J.
(1979),
‘Verbal
behavior and schizophrenia:
The se-
mantic dimension’, Archives of General
Psychiatry 38, 1331–1337.
Ruben Van Wanzeele, Katja Verbeeck, A. V. T. T. and Tsiporkova, E. (2011), Extracting
emotions out of twitter’s microblogs, in ‘Proceedings of the 23rd Benelux Conference
on Artificial Intelligence (BNAIC 2011)’.
Ruiz,
E.
J.,
Hristidis,
V.,
Castillo,
C.,
Gionis,
A.
and Jaimes,
A.
(2012),
Correlating fi-
nancial
time series with micro-blogging activity,
in ‘Proceedings of
the fifth ACM
international conference on Web search and data mining’, WSDM ’12, pp. 513–522.
Russell,
J.
A.
(1980),
‘A circumplex model
of
affect’,
Journal
of
Personality and Social
Psychology 39(6), 1161–1178.
Russell, J. A. (1991), ‘Culture and the categorization of emotions.’, Psychological
Bulletin
110(3), 426–450.
Russell, J. A. (2003), ‘Core affect and the psychological construction of emotion’, Psycho-
logical
Review 110(1), 145–172.
Steunebrink, B. R., Dastani, M. and Meyer, J.-J. C. (2009), ‘The occ model revisited’, 4th
Workshop on Emotion and Computing Paderborn Germany 2009 .
Strapparava,
C.
and Mihalcea,
R.
(2007),
Semeval-2007 task 14:
affective text,
in ‘Pro-
ceedings of the 4th International Workshop on Semantic Evaluations’, SemEval.
Strapparava,
C.
and Mihalcea,
R.
(2008),
Learning to identify emotions in text,
in ‘Pro-
ceedings of the ACM Conference on Applied Computing’, ACM-SAC.
Sylvers,
P.,
Lilienfeld,
S.
O.
and LaPrairie,
J.
L.
(2011),
‘Differences between trait fear
and trait
anxiety:
implications
for
psychopathology.’,
Clinical
Psychology Review
31(1), 122–137.
BIBLIOGRAPHY
74
Tao,
J.
(2004),
Context based emotion detection from text input,
in ‘8th International
Conference on Spoken Language Processing’, ICSLP, pp. 1337–1340.
Tomkins, S. S. (1984), Affect theory, in ‘Approaches to emotion’, pp. 163–195.
Tougas, J. E. B. (2005), Folding-up:
A Hybrid Method for Updating the Partial Singular
Value Decomposition in Latent Semantic Indexing, Master’s thesis, Dalhousie Univer-
sity.
Turkia, M. (2009), ‘A computational model of affects’, pp. 277–290.
Turney, P. (2001), Mining the web for synonyms:
Pmi-ir versus lsa on toefl, in L. D. Raedt
and P.
Flach,
eds,
‘Machine Learning:
ECML 2001’,
Vol.
2167 of
Lecture Notes in
Computer Science, pp. 491–502.
Turney,
P.
D.
(2002),
Thumbs up or thumbs down?:
semantic orientation applied to un-
supervised classification of
reviews,
in ‘Proceedings of
the 40th Annual
Meeting on
Association for Computational Linguistics’, ACL ’02, pp. 417–424.
Utsumi,
A.
(2010),
Evaluating the performance of
nonnegative matrix factorization for
constructing semantic spaces:
Comparison to latent semantic analysis.,
in ‘SMC’,
IEEE, pp. 2893–2900.
Wason,
P.
C.
(1959),
‘The processing of
positive and negative information’,
Quarterly
Journal
on Experimental
Psychology 11(2), 92–107.
Watson, D. and Tellegen, A. (1985), ‘Toward a consensual structure of mood’, Psychological
bulletin 98(2), 219–235.
Watson, J. (1930), Behaviourism, University of Chicago Press.
Whorf, B. L. (1956), Language, Thought, and Reality:
Selected Writings of Benjamin Lee
Whorf, MIT Press.
Xu, W., Liu, X. and Gong, Y. (2003), Document clustering based on non-negative matrix
factorization, in ‘Proceedings of the 26th annual international ACM SIGIR conference
on Research and development in informaion retrieval’, SIGIR ’03, ACM, pp. 267–273.
Zhijun Yin, Liangliang Cao, J. H. C. Z. and Huang, T. (2011), Lpta:
A probabilistic model
for latent periodic topic analysis,
in ‘The IEEE International
Conference on Data
Mining series’.
Zipf, G. K. (1949), Human Behavior and the Principle of Least Effort.
Appendix A
EARL Emotion WordNet
Synonyms
75
EARL Emotion WordNet Synonyms
POSITIVE EARL SYNONYMS
courageous
hopeful
proud
satisfied
trustful
brave
aspirant
gallant
slaked
trusting
promising
lofty
calm
content
relaxed
relieved
serene
unagitated
placid
alleviated
tranquil
lull
eased
quiescent
affectionate
empathetic
friendly
love
fond
empathic
favorable
enjoy
lovesome
warmhearted
interested
polite
surprised
amazed
astonied
astounded
astonished
amused
delighted
elated
excited
happy
joyful
pleased
beguiled
gleeful
frantic
felicitous
captivated
jubilant
delirious
glad
charmed
unrestrained
enthralled
entranced
NEGATIVE EARL SYNONYMS
doubtful
envious
frustrated
guilty
ashamed
dubious
covetous
shamed
tentative
jealous
bored
despair
disappointed
hurt
sad
blase
defeated
pitiful
unhappy
anxious
embarrassed
fearful
helpless
powerless
worried
nervous
humiliated
frightful
incapacitated
apprehensive
queasy
mortified
disquieted
uneasy
upset
unquiet
angry
annoyed
contempt
disgusted
irritated
furious
vexed
disrespected
fed up
peeved
raging
scornful
pissed off
tempestuous
stressed
shocked
tense
distressed
aghast
strained
appalled
hostile
dismayed
jittery
Appendix B
Raw results output
DELSAR1000 Algorithm
>>>
DELSAR1000
t e s t i n g
ALL with
60
d i m e n s i o n s .
21
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 3 5 3 2
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0373B1B0>
I n d e x i n g
LSA Space . . .
Warning
( from w a r n i n g s
module ) :
F i l e
”C: \ Python27 \ l i b \ s i t e −p a c k a g e s \ s c i p y \ s p a r s e \ c om p r es s e d . py ” ,
l i n e
122
% s e l f . i n d i c e s . dtype . name
)
UserWarning :
i n d i c e s
a r r a y
has
non−i n t e g e r
dtype
( f l o a t 6 4 )
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ a c c e p t i n g ’ ,
0 . 4 5 2 ]
[ ’ angry ’ ,
0 . 2 4 8 ]
[ ’ a n t i c i p a t i n g ’ ,
0 . 3 1 2 ]
[ ’ a n x i o u s ’ ,
0 . 2 7 2 ]
[ ’ ashamed ’ ,
0 . 3 6 6 ]
[ ’ contempt ’ ,
0 . 3 5 6 ]
[ ’ d e p r e s s e d ’ ,
0 . 1 9 3 ]
[ ’ d i s g u s t e d ’ ,
0 . 2 5 1 ]
[ ’ e x c i t e d ’ ,
0 . 2 2 7 ]
[ ’ g u i l t y ’ ,
0 . 3 3 9 ]
[ ’ happy ’ ,
0 . 2 5 5 ]
[ ’ i n t e r e s t e d ’ ,
0 . 4 6 ]
[ ’ j o y f u l
’ ,
0 . 3 9 7 ]
77
APPENDIX B.
RAW RESULTS OUTPUT
78
[ ’ m i s e r a b l e ’ ,
0 . 2 7 2 ]
[ ’ p l e a s e d ’ ,
0 . 3 5 9 ]
[ ’ r e l a x e d ’ ,
0 . 2 4 5 ]
[ ’ sad ’ ,
0 . 2 5 9 ]
[ ’ s c a r e d ’ ,
0 . 2 4 9 ]
[ ’ s l e e p y ’ ,
0 . 3 3 2 ]
[ ’ s t r e s s e d ’ ,
0 . 2 9 5 ]
[ ’ s u r p r i s e d ’ ,
0 . 2 9 5 ]
TOTAL ACCURACY:
0 . 3 0 6 3 8 1
Time
Taken :
2 7 . 1 1 1 2 8 8 3 8 6 6
>>>
DELSAR1000
t e s t i n g
ALL with
40
d i m e n s i o n s .
21
emotions ,
13
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 3 5 3 2
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x038011B0>
I n d e x i n g
LSA Space . . .
Warning
( from w a r n i n g s
module ) :
F i l e
”C: \ Python27 \ l i b \ s i t e −p a c k a g e s \ s c i p y \ s p a r s e \ c om p r es s e d . py ” ,
l i n e
122
% s e l f . i n d i c e s . dtype . name
)
UserWarning :
i n d i c e s
a r r a y
has
non−i n t e g e r
dtype
( f l o a t 6 4 )
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
d e p r e s s e d
( 0 . 1 8 7 0 0 0 )
20
emotions ,
12
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 3 1 7 0
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x03A3FD10>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
d i s g u s t e d
( 0 . 2 1 7 0 0 0 )
19
emotions ,
11
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 6 6 6
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
APPENDIX B.
RAW RESULTS OUTPUT
79
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x038BB370>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed sad
( 0 . 2 3 5 0 0 0 )
18
emotions ,
10
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 1 7 8
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x038CC090>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed happy
( 0 . 2 4 6 0 0 0 )
17
emotions ,
9
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 1 6 9 8
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x0393B430>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
e x c i t e d
( 0 . 2 7 4 0 0 0 )
16
emotions ,
8
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 1 2 3 0
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x03A87D90>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
s c a r e d
( 0 . 2 9 0 0 0 0 )
15
emotions ,
7
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 0 7 7 4
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x03A8FA10>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
APPENDIX B.
RAW RESULTS OUTPUT
80
Removed
r e l a x e d
( 0 . 3 1 4 0 0 0 )
14
emotions ,
6
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 0 2 4 1
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039DFA90>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
a n x i o u s
( 0 . 3 3 7 0 0 0 )
13
emotions ,
5
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 9 7 5 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x05E7BD70>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed angry
( 0 . 3 6 2 0 0 0 )
12
emotions ,
4
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 9 2 4 1
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x074DBB30>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
a n t i c i p a t i n g
( 0 . 3 7 5 0 0 0 )
11
emotions ,
3
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 8 6 5 2
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x06D4E590>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
m i s e r a b l e
( 0 . 3 9 2 0 0 0 )
10
emotions ,
2
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 8 0 5 8
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
APPENDIX B.
RAW RESULTS OUTPUT
81
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0B154B70>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
s u r p r i s e d
( 0 . 4 1 7 0 0 0 )
9
emotions ,
1
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 7 4 7 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x039731B0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
Removed
g u i l t y
( 0 . 4 4 4 0 0 0 )
8
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 6 8 1 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0BBDF0D0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ a c c e p t i n g ’ ,
0 . 5 5 3 ]
[ ’ ashamed ’ ,
0 . 5 3 4 ]
[ ’ contempt ’ ,
0 . 5 7 4 ]
[ ’ i n t e r e s t e d ’ ,
0 . 6 0 3 ]
[ ’ j o y f u l
’ ,
0 . 5 1 9 ]
[ ’ p l e a s e d ’ ,
0 . 5 0 6 ]
[ ’ s l e e p y ’ ,
0 . 5 9 1 ]
[ ’ s t r e s s e d ’ ,
0 . 5 0 2 ]
TOTAL ACCURACY:
0 . 5 4 7 7 5 0
Time
Taken :
2 5 8 . 6 9 5 9 5 0 8 6 3
>>>
ELSA1000 Algorithm (10 Dimensions)
>>>
ELSA1000
t e s t i n g
a c c e p t i n g
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 4 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
APPENDIX B.
RAW RESULTS OUTPUT
82
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x03990E10>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ a c c e p t i n g ’ ,
0 . 9 6 7 5 6 7 8 0 5 2 3 0 6 1 7 5 ]
ELSA1000
t e s t i n g
angry
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 0 3
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x039904B0>
I n d e x i n g
LSA Space . . .
Warning
( from w a r n i n g s
module ) :
F i l e
”C: \ Python27 \ l i b \ s i t e −p a c k a g e s \ s c i p y \ s p a r s e \ c om p r es s e d . py ” ,
l i n e
122
% s e l f . i n d i c e s . dtype . name
)
UserWarning :
i n d i c e s
a r r a y
has
non−i n t e g e r
dtype
( f l o a t 6 4 )
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ angry ’ ,
0 . 9 5 1 1 2 1 8 0 9 6 6 1 3 8 8 4 ]
ELSA1000
t e s t i n g
a n t i c i p a t i n g
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 3 3
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x03992310>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ a n t i c i p a t i n g ’ ,
0 . 9 2 9 5 8 4 0 6 5 7 9 4 9 4 4 8 ]
ELSA1000
t e s t i n g
a n x i o u s
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 8 2 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0 x0392F870>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ a n x i o u s ’ ,
0 . 9 8 8 6 9 1 6 7 8 3 4 5 2 0 3 4 ]
APPENDIX B.
RAW RESULTS OUTPUT
83
ELSA1000
t e s t i n g
ashamed
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 7 1
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0392FC70>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ ashamed ’ ,
0 . 9 4 7 1 8 4 9 9 4 2 2 0 7 3 3 7 ]
ELSA1000
t e s t i n g
contempt
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 4 6 8
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x038CEDD0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ contempt ’ ,
0 . 9 7 7 7 3 4 0 4 8 4 8 5 7 5 6 ]
ELSA1000
t e s t i n g
d e p r e s s e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 1 5 8
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039A5CF0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ d e p r e s s e d ’ ,
0 . 9 5 0 2 7 9 8 5 8 8 2 7 5 9 0 9 ]
ELSA1000
t e s t i n g
d i s g u s t e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 7 0
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x038CEDD0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ d i s g u s t e d ’ ,
0 . 9 3 2 6 0 5 5 7 8 3 0 3 3 3 7 1 ]
ELSA1000
t e s t i n g
e x c i t e d
with
10
d i m e n s i o n s .
APPENDIX B.
RAW RESULTS OUTPUT
84
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 1 2 1
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0399E5D0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ e x c i t e d ’ ,
0 . 9 4 2 4 4 6 4 8 6 1 1 5 4 5 5 7 ]
ELSA1000
t e s t i n g
g u i l t y
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 3 0 6
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x038CEC10>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ g u i l t y ’ ,
0 . 9 2 5 5 6 8 9 1 0 2 4 1 1 2 7 ]
ELSA1000
t e s t i n g
happy
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 1 6
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039A7F90>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ happy ’ ,
0 . 9 4 8 6 1 6 8 2 0 9 3 1 4 3 4 6 ]
ELSA1000
t e s t i n g
i n t e r e s t e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 3 9 8
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039A64F0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ i n t e r e s t e d ’ ,
0 . 9 5 6 3 5 9 6 8 1 6 6 5 8 9 7 4 ]
ELSA1000
t e s t i n g
j o y f u l
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
APPENDIX B.
RAW RESULTS OUTPUT
85
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 3 2 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0398DC70>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ j o y f u l
’ ,
0 . 9 4 0 8 1 3 8 2 7 0 3 7 8 1 1 2 ]
ELSA1000
t e s t i n g
m i s e r a b l e
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 6 3
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039AC3F0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ m i s e r a b l e ’ ,
0 . 9 5 4 3 2 6 7 2 9 3 5 7 2 4 2 6 ]
ELSA1000
t e s t i n g
p l e a s e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 2 0
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039AC8B0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ p l e a s e d ’ ,
0 . 9 4 9 1 5 4 9 9 8 0 0 4 4 3 6 5 ]
ELSA1000
t e s t i n g
r e l a x e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 6 7
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039AC630>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ r e l a x e d ’ ,
0 . 9 3 8 9 9 8 9 3 9 2 1 6 1 3 7 ]
ELSA1000
t e s t i n g
sad
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
APPENDIX B.
RAW RESULTS OUTPUT
86
D i c t i o n a r y ( 1 3 6 7
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039A4AD0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ sad ’ ,
0 . 9 4 0 6 8 3 2 0 3 1 6 0 7 6 2 8 ]
ELSA1000
t e s t i n g
s c a r e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 2 7
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x039A4930>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ s c a r e d ’ ,
0 . 9 3 5 4 9 4 3 0 9 3 6 5 7 4 9 4 ]
ELSA1000
t e s t i n g
s l e e p y
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 0 1 9
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0399D230>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ s l e e p y ’ ,
0 . 9 3 9 1 7 4 0 3 7 1 5 8 4 8 9 2 ]
ELSA1000
t e s t i n g
s t r e s s e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 1 2 4
u ni q ue
t o k e n s )
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0399EDD0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ s t r e s s e d ’ ,
0 . 9 5 0 1 2 9 5 5 4 2 1 2 0 9 3 3 ]
ELSA1000
t e s t i n g
s u r p r i s e d
with
10
d i m e n s i o n s .
1
emotions ,
0
r e d u c t i o n s
r e m a i n i n g .
C r e a t i n g
d i c t i o n a r y . . .
D i c t i o n a r y ( 1 2 2 8
u ni q ue
t o k e n s )
APPENDIX B.
RAW RESULTS OUTPUT
87
C r e a t i n g
c o r p u s
o b j e c t . . .
Done .
G e n e r a t i n g
LSA Space . . .
<gensim . i n t e r f a c e s . TransformedCorpus
o b j e c t
a t
0x0392FAB0>
I n d e x i n g
LSA Space . . .
Done .
G e n e r a t i n g
document
s i m i l a r i t y
m a t r i x . . .
[ ’ s u r p r i s e d ’ ,
0 . 9 3 7 2 7 0 7 6 9 6 5 5 7 0 4 5 ]
0 . 9 6 7 5 6 7 8 0 5 2 3 1
0 . 9 5 1 1 2 1 8 0 9 6 6 1
0 . 9 2 9 5 8 4 0 6 5 7 9 5
0 . 9 8 8 6 9 1 6 7 8 3 4 5
0 . 9 4 7 1 8 4 9 9 4 2 2 1
0 . 9 7 7 7 3 4 0 4 8 4 8 6
0 . 9 5 0 2 7 9 8 5 8 8 2 8
0 . 9 3 2 6 0 5 5 7 8 3 0 3
0 . 9 4 2 4 4 6 4 8 6 1 1 5
0 . 9 2 5 5 6 8 9 1 0 2 4 1
0 . 9 4 8 6 1 6 8 2 0 9 3 1
0 . 9 5 6 3 5 9 6 8 1 6 6 6
0 . 9 4 0 8 1 3 8 2 7 0 3 8
0 . 9 5 4 3 2 6 7 2 9 3 5 7
0 . 9 4 9 1 5 4 9 9 8 0 0 4
0 . 9 3 8 9 9 8 9 3 9 2 1 6
0 . 9 4 0 6 8 3 2 0 3 1 6 1
0 . 9 3 5 4 9 4 3 0 9 3 6 6
0 . 9 3 9 1 7 4 0 3 7 1 5 8
0 . 9 5 0 1 2 9 5 5 4 2 1 2
0 . 9 3 7 2 7 0 7 6 9 6 5 6
Time
Taken :
5 . 4 5 3 3 5 9 1 4 7 9 6
Appendix C
Code
Up-to-date code is available at http://www.aeir.co.uk;
the following provides a reference
for the text.
88
APPENDIX C.
CODE
89
C.1
Database Schema (MySQL)
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
−− TWEETS. s q l
−−
−−
−−
−− C r e a t e s
t h e
TWEETS t a b l e
−−
−−
−−
−− C o m p a t i b i l i t y :
MySQL
−−
−−
−−
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
−− Host :
m y s q l 5 h o s t . b a t h . ac . uk
−−
−− Database :
‘ PROJtwitterEDB ‘
−−
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
−−
−− Table
s t r u c t u r e
f o r
t a b l e
‘TWEETS‘
−−
CREATE TABLE ‘TWEETS‘
(
‘ i d ‘
i n t ( 2 0 )
UNSIGNED NOT NULL AUTO
INCREMENT COMMENT ’ Table
key ’ ,
‘ t w e e t
i d ‘
b i g i n t ( 2 0 )
UNSIGNED NOT NULL COMMENT ’ Twitter
t w e e t
ID f o r
l o o k u p ’ ,
‘ t e x t ‘
varchar ( 1 5 0 )
NOT NULL,
‘ emotion ‘
varchar ( 1 5 0 )
NOT NULL,
‘ s c r e e n n a m e ‘
varchar ( 2 5 5 )
NOT NULL,
‘ r e t w e e t
c o u n t ‘
i n t ( 1 1 )
NOT NULL,
‘ c r e a t e d a t ‘
datetime NOT NULL COMMENT ’ Timestamp
o f
d a t a b a s e
i n s e r t ’ ,
‘ t i m e z o n e ‘
varchar ( 2 5 5 )
NOT NULL COMMENT ’ Twitter−defined ,
s e e
s e p e r a t e
SQL f i l e
f o r
d a t e t i m e
c o n v e r s i o n ’ ,
‘ f l a g ‘
t i n y i n t ( 4 )
NOT NULL COMMENT ’ Generic
F l a g ’ ,
PRIMARY KEY ( ‘ id ‘ )
)
ENGINE=InnoDB
DEFAULT CHARSET=utf8 ;
APPENDIX C.
CODE
90
C.2
Twitter Stream (PHP)
<?php
/∗
streamword . php
∗
∗
C r e a t e s
a
t w i t t e r
stream f o r
a
s i n g l e
keyword
∗
∗
F i l t e r s
o u t
t w e e t s
t h a t
c o n t a i n
s p e c i f i c
p h r a s e s
∗
∗
S a v e s
matching
t w e e t s
i n t o
t h e
d a t a b a s e
∗
∗
Changes
emotion
e v e r y
5
minutes
∗
∗/
s e t
t i m e l i m i t ( 0 ) ;
include ( ”JSON . php” ) ;
include ( ” t i m e r . php” ) ;
$currentEmotionCode
= 0 ;
$ f i l t e r
= array ( ) ;
$ f i l t e r [ 0 ]
= array (0 => ’RT ’ , ’ not
a c c e p t i n g ’ ,
’ n o t
r e a l l y
a c c e p t i n g ’ ,
’ n o t
t h a t
a c c e p t i n g ’ ,
’ wasn \ ’ t
t h a t
a c c e p t i n g ’ ,
’ wasn \ ’ t
v e r y
a c c e p t i n g ’ ,
’ u n a c c e p t i n g ’ ,
’ d i s a c c e p t i n g ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 ]
= array (0 => ’RT ’ , ’ not
a n g r y ’ ,
’ n o t
r e a l l y
a n g r y ’ ,
’ n o t
t h a t
a n g r y ’ ,
’ wasn \ ’ t
t h a t
a n g r y ’ ,
’ wasn \ ’ t
v e r y
a n g r y ’ ,
’ unangry ’ ,
’ angry
b i r d s ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 2 ]
= array (0 => ’RT ’ , ’ not
a n t i c i p a t i n g ’ ,
’ n o t
r e a l l y
a n t i c i p a t i n g ’ ,
’ n o t
t h a t
a n t i c i p a t i n g ’ ,
’ wasn \ ’ t
t h a t
a n t i c i p a t i n g ’ ,
’ wasn \ ’ t
v e r y
a n t i c i p a t i n g ’ ,
’ u n a n t i c i p a t i n g ’ ,
’ d i s a n t i c i p a t i n g ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 3 ]
= array (0 => ’RT ’ , ’ not
a n x i o u s ’ ,
’ n o t
r e a l l y
a n x i o u s ’ ,
’ n o t
t h a t
a n x i o u s ’ ,
’ wasn \ ’ t
t h a t
a n x i o u s ’ ,
’ wasn \ ’ t
v e r y
a n x i o u s ’ ,
’ u n a n x i o u s ’ ,
’ d i s a n x i o u s ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 4 ]
= array (0 => ’RT ’ , ’ not
ashamed ’ ,
’ n o t
r e a l l y
ashamed ’ ,
’ n o t
t h a t
ashamed ’ ,
’ wasn \ ’ t
t h a t
ashamed ’ ,
’ wasn \ ’ t
v e r y
ashamed ’ ,
’ unashamed ’ ,
’ d i s a s h a m e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 5 ]
= array (0 => ’RT ’ , ’ not
contempt ’ ,
’ n o t
r e a l l y
contempt ’ ,
’ n o t
t h a t
contempt ’ ,
’ wasn \ ’ t
t h a t
contempt ’ ,
’ wasn \ ’ t
v e r y
contempt ’ ,
’ uncontempt ’ ,
’ d i s c o n t e m p t ’ ,
’ i n
contempt ’ ,
’ contempt
o f ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
APPENDIX C.
CODE
91
$ f i l t e r [ 6 ]
= array (0 => ’RT ’ , ’ not
d e p r e s s e d ’ ,
’ n o t
r e a l l y
d e p r e s s e d ’ ,
’ n o t
t h a t
d e p r e s s e d ’ ,
’ wasn \ ’ t
t h a t
d e p r e s s e d ’ ,
’ wasn \ ’ t
v e r y
d e p r e s s e d ’ ,
’ u n d e p r e s s e d ’ ,
’ d i s d e p r e s s e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 7 ]
= array (0 => ’RT ’ , ’ not
d i s g u s t e d ’ ,
’ n o t
r e a l l y
d i s g u s t e d ’ ,
’ n o t
t h a t
d i s g u s t e d ’ ,
’ wasn \ ’ t
t h a t
d i s g u s t e d ’ ,
’ wasn \ ’ t
v e r y
d i s g u s t e d ’ ,
’ u n d i s g u s t e d ’ ,
’ d i s d i s g u s t e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 8 ]
= array (0 => ’RT ’ , ’ not
e x c i t e d ’ ,
’ n o t
r e a l l y
e x c i t e d ’ ,
’ n o t
t h a t
e x c i t e d ’ ,
’ wasn \ ’ t
t h a t
e x c i t e d ’ ,
’ wasn \ ’ t
v e r y
e x c i t e d ’ ,
’ u n e x c i t e d ’ ,
’ d i s e x c i t e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 9 ]
= array (0 => ’RT ’ , ’ not
g u i l t y ’ ,
’ n o t
r e a l l y
g u i l t y ’ ,
’ n o t
t h a t
g u i l t y ’ ,
’ wasn \ ’ t
t h a t
g u i l t y ’ ,
’ wasn \ ’ t
v e r y
g u i l t y ’ ,
’ u n g u i l t y ’ ,
’ found
g u i l t y ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 0 ]
= array (0 => ’RT ’ , ’ not
happy ’ ,
’ n o t
r e a l l y
happy ’ ,
’ n o t
t h a t
happy ’ ,
’ wasn \ ’ t
t h a t
happy ’ ,
’ wasn \ ’ t
v e r y
happy ’ ,
’ unhappy ’ ,
’ happy
b i r t h d a y ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 1 ]
= array (0 => ’RT ’ , ’ not
i n t e r e s t e d ’ ,
’ n o t
r e a l l y
i n t e r e s t e d ’ ,
’ n o t
t h a t
i n t e r e s t e d ’ ,
’ wasn \ ’ t
t h a t
i n t e r e s t e d ’ ,
’ wasn \ ’ t
v e r y
i n t e r e s t e d ’ ,
’ u n i n t e r e s t e d ’ ,
’ d i s i n t e r e s t e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 2 ]
= array (0 => ’RT ’ , ’ not
j o y f u l
’ ,
’ n o t
r e a l l y
j o y f u l
’ ,
’ n o t
t h a t
j o y f u l
’ ,
’ wasn \ ’ t
t h a t
j o y f u l
’ ,
’ wasn \ ’ t
v e r y
j o y f u l
’ ,
’ u n j o y f u l ’ ,
’ d i s j o y f u l
’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 3 ]
= array (0 => ’RT ’ , ’ not
m i s e r a b l e ’ ,
’ n o t
r e a l l y
m i s e r a b l e ’ ,
’ n o t
t h a t
m i s e r a b l e ’ ,
’ wasn \ ’ t
t h a t
m i s e r a b l e ’ ,
’ wasn \ ’ t
v e r y
m i s e r a b l e ’ ,
’ u n m i s e r a b l e ’ ,
’ d i s m i s e r a b l e ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 4 ]
= array (0 => ’RT ’ , ’ not
p l e a s e d ’ ,
’ n o t
r e a l l y
p l e a s e d ’ ,
’ n o t
t h a t
p l e a s e d ’ ,
’ wasn \ ’ t
t h a t
p l e a s e d ’ ,
’ wasn \ ’ t
v e r y
p l e a s e d ’ ,
’ u n p l e a s e d ’ ,
’ d i s p l e a s e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 5 ]
= array (0 => ’RT ’ , ’ not
r e l a x e d ’ ,
’ n o t
r e a l l y
r e l a x e d ’ ,
’ n o t
t h a t
r e l a x e d ’ ,
’ wasn \ ’ t
t h a t
r e l a x e d ’ ,
’ wasn \ ’ t
v e r y
r e l a x e d ’ ,
’ u n r e l a x e d ’ ,
’ d i s r e l a x e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 6 ]
= array (0 => ’RT ’ , ’ not
s a d ’ ,
’ n o t
r e a l l y
s a d ’ ,
’ n o t
t h a t
s a d ’ ,
’ wasn \ ’ t
t h a t
s a d ’ ,
’ wasn \ ’ t
v e r y
s a d ’ ,
’ unsad ’ ,
’ d i s s a d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 7 ]
= array (0 => ’RT ’ , ’ not
s c a r e d ’ ,
’ n o t
r e a l l y
s c a r e d ’ ,
’ n o t
t h a t
s c a r e d ’ ,
’ wasn \ ’ t
t h a t
s c a r e d ’ ,
’ wasn \ ’ t
v e r y
s c a r e d ’ ,
’ u n s c a r e d ’ ,
’ d i s s c a r e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 8 ]
= array (0 => ’RT ’ , ’ not
s l e e p y ’ ,
’ n o t
r e a l l y
s l e e p y ’ ,
’ n o t
t h a t
s l e e p y ’ ,
’ wasn \ ’ t
t h a t
s l e e p y ’ ,
’ wasn \ ’ t
v e r y
s l e e p y ’ ,
’ u n s l e e p y ’ ,
’ d i s s l e e p y ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 1 9 ]
= array (0 => ’RT ’ , ’ not
s t r e s s e d ’ ,
’ n o t
r e a l l y
s t r e s s e d ’ ,
’ n o t
t h a t
s t r e s s e d ’ ,
’ wasn \ ’ t
t h a t
s t r e s s e d ’ ,
’ wasn \ ’ t
v e r y
s t r e s s e d ’ ,
’ u n s t r e s s e d ’ ,
’ d i s s t r e s s e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
$ f i l t e r [ 2 0 ]
= array (0 => ’RT ’ , ’ not
s u r p r i s e d ’ ,
’ n o t
r e a l l y
s u r p r i s e d ’ ,
’ n o t
t h a t
s u r p r i s e d ’ ,
’ wasn \ ’ t
t h a t
s u r p r i s e d ’ ,
’ wasn \ ’ t
v e r y
s u r p r i s e d ’ ,
’ u n s u r p r i s e d ’ ,
’ d i s s u r p r i s e d ’ ,
’ h t t p : / / ’ ,
’
RT ’ ,
’@ ’ ) ;
APPENDIX C.
CODE
92
$ s e a r c h w o r d = array ( ) ;
$ s e a r c h w o r d [ 0 ]
= ” a c c e p t i n g ” ;
$ s e a r c h w o r d [ 1 ]
= ” angry ” ;
$ s e a r c h w o r d [ 2 ]
= ” a n t i c i p a t i n g ” ;
$ s e a r c h w o r d [ 3 ]
= ” a n x i o u s ” ;
$ s e a r c h w o r d [ 4 ]
= ”ashamed” ;
$ s e a r c h w o r d [ 5 ]
= ” contempt ” ;
$ s e a r c h w o r d [ 6 ]
= ” d e p r e s s e d ” ;
$ s e a r c h w o r d [ 7 ]
= ” d i s g u s t e d ” ;
$ s e a r c h w o r d [ 8 ]
= ” e x c i t e d ” ;
$ s e a r c h w o r d [ 9 ]
= ” g u i l t y ” ;
$ s e a r c h w o r d [ 1 0 ]
= ”happy” ;
$ s e a r c h w o r d [ 1 1 ]
= ” i n t e r e s t e d ” ;
$ s e a r c h w o r d [ 1 2 ]
= ” j o y f u l ” ;
$ s e a r c h w o r d [ 1 3 ]
= ” m i s e r a b l e ” ;
$ s e a r c h w o r d [ 1 4 ]
= ” p l e a s e d ” ;
$ s e a r c h w o r d [ 1 5 ]
= ” r e l a x e d ” ;
$ s e a r c h w o r d [ 1 6 ]
= ” sad ” ;
$ s e a r c h w o r d [ 1 7 ]
= ” s c a r e d ” ;
$ s e a r c h w o r d [ 1 8 ]
= ” s l e e p y ” ;
$ s e a r c h w o r d [ 1 9 ]
= ” s t r e s s e d ” ;
$ s e a r c h w o r d [ 2 0 ]
= ” s u r p r i s e d ” ;
f u n c t i o n
h a r v e s t ( )
{
g l o b a l
$currentEmotionCode ;
g l o b a l
$ f i l t e r ;
g l o b a l
$ s e a r c h w o r d ;
$ q u e r y
d a t a = array ( ’ t r a c k ’
=> $ s e a r c h w o r d [ $currentEmotionCode ] ) ;
$ u s e r
= ’USERNAME’ ;
$ p a s s
= ’PASSWORD’ ;
$ f p = fsockopen ( ” s s l : / / stream . t w i t t e r . com” ,
4 4 3 ,
$ e r r n o ,
$ e r r s t r ,
7 2 0 ) ;
i f ( ! $ f p ) {
echo ” $ e r r s t r
( $ e r r n o ) \n” ;
}
e l s e
{
$ m y s q l i
= new mysqli ( ’HOSTNAME’ ,
’USERNAME’ ,
’PASSWORD’ ,
’DATABASE ’ ) ;
APPENDIX C.
CODE
93
i f
( m y s q l i
c o n n e c t
e r r n o ( ) )
{
p r i n t f ( ”Can ’ t
c o n n e c t
to MySQL S e r v e r .
E r r o r c o d e :
%s \n” ,
m y s q l i
c o n n e c t
e r r o r ( ) ) ;
}
$ r e q u e s t
= ”GET /1/ s t a t u s e s / f i l t e r . j s o n ? ” . h t t p b u i l d q u e r y ( $ q u e r y d a t a ) . ” HTTP/ 1 . 1 \ r \n” ;
$ r e q u e s t
.= ” Host :
s t r e a m . t w i t t e r . com\ r \n” ;
$ r e q u e s t
.= ” A u t h o r i z a t i o n :
B a s i c
” . base64 encode ( $ u s e r . ” : ” . $ p a s s ) . ” \ r \n\ r \n” ;
f w r i t e ( $ f p ,
$ r e q u e s t ) ;
//
S t a r t
a
t i m e r ,
end
s t r e a m i n g
t h e
c u r r e n t
emotion
a f t e r
5
minutes
$ t i m e r
= new t i m e r ( 1 ) ;
//
c o n s t r u c t o r
s t a r t s
t h e
t i m e r
while ( ! f e o f ( $ f p )
&& $timer−>g e t ( )
< 300)
{
$ j s o n = f g e t s ( $ f p ) ;
$ t w e e t
= j s o n d e c o d e ( $ j s o n ,
true ) ;
i f ( $ t w e e t )
{
$ i n = true ;
foreach ( $ f i l t e r [ $currentEmotionCode ]
a s
$word )
{
i f ( s t r i p o s ( $ t w e e t [ ” t e x t ” ] , $word )
!== f a l s e )
{ $ i n = f a l s e ;
echo ”SKIPPED
” . $word . ” \n\n” ; }
}
i f ( s t r
w o r d c o u n t ( $ t w e e t [ ” t e x t ” ] )
< 10)
{ $ i n = f a l s e ;
echo ” L e s s
than
10
words
SKIPPED\n\n” ; }
// i f ( ! p r e g m a t c h ( ’ ˜ [ ˆA−Za−z0 −9
] ˜ ’ ,
$ t w e e t [ ” t e x t ” ] ) )
{ $ i n = f a l s e ;
echo
”Non
a l p h a n u m e r i c
SKIPPED\n\n ” ; }
i f ( $ i n )
{
$ t e x t
= $mysqli−>r e a l
e s c a p e
s t r i n g ( $ t w e e t [ ” t e x t ” ] ) ;
$ t w e e t
i d = $mysqli −>r e a l
e s c a p e
s t r i n g ( $ t w e e t [ ” i d s t r ” ] ) ;
$ s c r e e n n a m e
= $mysqli−>r e a l
e s c a p e
s t r i n g ( $ t w e e t [ ” u s e r ” ] [ ” s c r e e n n a m e ” ] ) ;
$ r e t w e e t
c o u n t
= $mysqli−>r e a l
e s c a p e
s t r i n g ( $ t w e e t [ ” r e t w e e t
c o u n t ” ] ) ;
$ t i m e
z o n e
= $mysqli−>r e a l
e s c a p e
s t r i n g ( $ t w e e t [ ” u s e r ” ] [ ” t i m e
z o n e ” ] ) ;
i f ( $ r e s u l t
= $mysqli−>query ( ”INSERT INTO
‘ PROJtwitterEDB ‘ .
‘ETWEETS‘ ( ‘ t w e e t
i d ‘ , ‘ t e x t ‘ , ‘ emotion ‘ , ‘ s c r e e n n a m e ‘ , ‘ r e t w e e t
c o u n t ‘ ,
‘ c r e a t e d a t ‘ , ‘ t i m e z o n e ‘ )
VALUES( $ t w e e t
i d , ’ $ t e x t ’ , ’ $ s e a r c h w o r d [ $currentEmotionCode ] ’ , ’ $ s c r e e n n a m e ’ , $ r e t w e e t
c o u n t ,NOW( ) ,
’ $ t i m e
z o n e ’ ) ” ) )
{
echo $ t w e e t [ ” t e x t ” ] . ” FROM ” . $ t w e e t [ ” u s e r ” ] [ ” t i m e
zone ” ] . ” SAVED TO DATABASE AT
” . date ( ”Y−m−d H: i : s ” ) . ”\n” ;
}
APPENDIX C.
CODE
94
e l s e
{
echo $mysqli −>e r r o r ;
}
}
}
}
$ m y s q l i −>c l o s e ( ) ;
f c l o s e ( $ f p ) ;
}
//
Increment
up
t o
21
t h e
l o o p
round
t o
1
i f ( $currentEmotionCode
+ 1 == 21)
{
$currentEmotionCode
= 0 ;
}
e l s e
{
$currentEmotionCode += 1 ;
}
h a r v e s t ( ) ;
}
h a r v e s t ( ) ;
?>
APPENDIX C.
CODE
95
C.3
DELSAR/ELSA (Python)
###################################################################
# DELSAR. py
#
#
#
# A l g o r i t h m s :
#
#
#
# DELSAR
#
# Documented−Emotion
L a t e n t
Semantic
A l g o r i t h m i c
Reducer
#
# C a l c u l a t e s
s e m a n t i c
d i s t i n c t i v e n e s s
o f
a
c o r p u s ,
g i v e n
each
#
# document
i s
l a b e l e d
u s i n g
LSC
#
# Reduces
an
i n i t i a l
keyword
( l a b e l )
s e t
u s i n g
LSC
#
#
#
# ELSA
#
# Emotional
L a t e n t
Semantic
A n a l y s i s
#
# C a l c u l a t e s
t h e
a c c u r a c y
o f
emotion−s p e c i f i c
sub−corpora ,
u s i n g
#
# t h e
a v e r a g e
o f
maximum c o s i n e
s i m i l a r i t y
b e t w e e n
documents
#
#
#
# @ r e q u i r e s
MySQLdb ,
gensim
#
# @author
Eugene
Yuta
Bann
#
# @version
28/03/12
#
#
#
###################################################################
from gensim import
c o r p o r a ,
models ,
s i m i l a r i t i e s
import
MySQLdb,
time ,
i t e r t o o l s
from c o l l e c t i o n s
import
Counter
########## VARIABLES ##############################################
ELSA = F a l s e
printDELSAR = True # p r i n t
a r r a y
f o r
E x c e l
m a t r i x
i n p u t
# Uncomment
emotion
s e t
t o
t e s t :
APPENDIX C.
CODE
96
#emotionTest
= ”IZARD”
#emotionTest
= ”RUSSELL”
#emotionTest
= ”PLUTCHIK”
emotionTest
= ”EKMAN”
#emotionTest
= ”TOMKINS”
#emotionTest
= ”JOHNSON” #OATLEY
#emotionTest
= ”ALL”
#emotionTest
= ”DELSAR”
#emotionTest
= ”BANN”
l i m i t
= 100 # Document
l i m i t
p e r
emotion
dimension = 40 # LSA number
o f
d i m e n s i o n s
# Uncomment
a d d i t i o n a l
p a r a m e t e r s
f o r
MySQL query :
s q l H a v i n g = ””
#s q l H a v i n g
= ”HAVING i d x MOD 4 = 0”
#s q l H a v i n g
= ”HAVING i d x MOD 13 = 1”
#s q l H a v i n g
= ”HAVING i d x MOD 3 = 2”
#s q l H a v i n g
= ”HAVING ( i d x MOD 11 = 7 AND i d x
> 280) ”
#s q l H a v i n g
= ”AND timezone
= ’ London ’”
#s q l H a v i n g
= ”AND NOT timezone
= ’ Mountain Time
(US & Canada ) ’
AND NOT timezone
= ’ P a c i f i c
Time
(US & Canada ) ’
AND NOT timezone
= ’ Easte rn Time
(US & Canada ) ’
AND NOT timezone
= ’ C e n t r a l
Time
(US & Canada ) ’
AND NOT timezone
= ’ ’
AND NOT timezone
= ’ Quito ’
AND NOT timezone
=
’ A t l a n t i c
Time
( Canada ) ’”
#s q l H a v i n g
= ”AND ( timezone
= ’ London ’
OR timezone
= ’ Edinburgh ’
OR timezone
= ’ D u b l i n ’ ) ”
#s q l H a v i n g
= ”AND ( timezone
= ’ Mountain Time
(US & Canada ) ’
OR timezone
= ’ P a c i f i c
Time
(US &
Canada ) ’
OR timezone
= ’ Easte rn Time
(US & Canada ) ’
OR timezone
= ’ C e n t r a l
Time
(US &
Canada ) ’ ) ”
#s q l H a v i n g
= ”AND timezone
= ’ P a c i f i c
Time
(US & Canada ) ’”
#s q l H a v i n g
= ”AND timezone
= ’ East ern Time
(US & Canada ) ’”
#s q l H a v i n g
= ”AND timezone
= ’ C e n t r a l
Time
(US & Canada ) ’”
#s q l H a v i n g
= ”AND timezone
= ’ Quito ’”
# P o s s i b l e
Asia
g r o u p :
B e i j i n g
Tokyo
Hong
Kong
J a k a r t a
Kuala
Lumpur
S i n g a p o r e
APPENDIX C.
CODE
97
##################################################################
# Create
emotion
term a r r a y s
# Change
b e l o w f o r
where
t h e
emotion
l i s t s
a r e
s t o r e d
# . e
f i l e s
a r e
t e x t
f i l e s ,
each
emotion on a
new l i n e
e m o t i o n F i l e
= ” e L i s t s /” + emotionTest
+ ” . e ”
emotionTerms
= [ emotion . l o w e r ( ) . s t r i p ( )
f o r
emotion
in open ( e m o t i o n F i l e ) ]
# Database
v a r i a b l e s
db = MySQLdb . connect ( ”HOSTNAME” ,
”USERNAME” ,
”PASSWORD” ,
”DATABASE” )
c u r s o r
= db . c u r s o r ( )
###################################################################
## For
DELSA ( w i t h o u t
r e d u c t i o n ) :
## s e t
reduceTo
t o
a
number
h i g h e r
t h a n
t h e
i n i t i a l
s e t
def
DELSAR( i n i t i a l
,
reduceTo ) :
# Corpus
c l a s s
t o
l o a d
each
document
i t e r a t i v e l y
from d a t a b a s e
c l a s s
MyCorpus ( o b j e c t ) :
def
i t e r
( s e l f ) :
f o r
emotion
in r a n g e ( l e n ( emotionTerms ) ) :
try :
s q l
= ”SELECT text ,
@idx:=@idx+1 AS idx FROM ETWEETS WHERE emotion = ’% s ’
%s
LIMIT %d” % ( emotionTerms [ emotion ] ,
s q l H a v i n g ,
l i m i t )
c u r s o r . e x e c u t e ( ”SELECT @idx : = 0 ; ” )
c u r s o r . e x e c u t e ( s q l )
r e s u l t s
= c u r s o r . f e t c h a l l ( )
f o r
row in
r e s u l t s :
y i e l d
d i c t i o n a r y . doc2bow ( row [ 0 ] . l o w e r ( ) . s p l i t ( ) )
except :
print
” E r r o r :
u n a b l e
t o
f e t c h
data ”
emotionTerms
= i n i t i a l
i f
( l e n ( i n i t i a l )
> reduceTo
and not
ELSA) :
print
s t r ( l e n ( i n i t i a l ) )
+ ”
emotions ,
” + s t r ( l e n ( i n i t i a l )−reduceTo )
+ ”
r e d u c t i o n s
r e m a i n i n g . ”
e l s e :
APPENDIX C.
CODE
98
print
s t r ( l e n ( i n i t i a l ) )
+ ”
emotions ,
0
r e d u c t i o n s
r e m a i n i n g . ”
print
” C r e a t i n g
d i c t i o n a r y . . . ”
# Create
a
d i c t i o n a r y
d i c t i o n a r y = c o r p o r a . D i c t i o n a r y ( )
f o r
emotion
in r a n g e ( l e n ( emotionTerms ) ) :
try :
s q l
= ”SELECT text ,
@idx:=@idx+1 AS idx FROM ETWEETS WHERE emotion = ’% s ’
%s
LIMIT
%d” % ( emotionTerms [ emotion ] ,
s q l H a v i n g ,
l i m i t )
c u r s o r . e x e c u t e ( ”SELECT @idx : = 0 ; ” )
c u r s o r . e x e c u t e ( s q l )
r e s u l t s
= c u r s o r . f e t c h a l l ( )
d i c t i o n a r y . add documents ( row [ 0 ] . l o w e r ( ) . s p l i t ( )
f o r
row in
r e s u l t s )
except
MySQLdb . Error ,
e :
print
” E r r o r
%d :
%s ” % ( e . a r g s [ 0 ] ,
e . a r g s [ 1 ] )
# We don ’ t
u s e
a
s t o p l i s t
s t o p l i s t
= s e t ( ” a ” . s p l i t ( ) )
s t o p i d s
= [ d i c t i o n a r y . t o k e n 2 i d [ stopword ]
f o r
stopword
in
s t o p l i s t
i f
stopword
in d i c t i o n a r y . t o k e n 2 i d ]
# We
g e t
r i d
o f
words
t h a t
o n l y
o c c u r
once
i n
t h e
e n t i r e
c o r p u s
o n c e
i d s
= [ t o k e n i d
f o r
t o k e n i d ,
d o c f r e q
in d i c t i o n a r y . d f s . i t e r i t e m s ( )
i f
d o c f r e q == 1 ]
d i c t i o n a r y . f i l t e r
t o k e n s ( s t o p i d s
+ o n c e
i d s )
# Remove
g a p s
i n
i d
s e q u e n c e
a f t e r
words
t h a t
were
removed
d i c t i o n a r y . c o m p a c t i f y ( )
# P r i n t
d i c t i o n a r y
i n f o r m a t i o n
print
d i c t i o n a r y
###############################################################
print
” C r e a t i n g
c o r p u s
o b j e c t . . . ”
# Create
c o r p u s
o b j e c t
from d a t a b a s e
i t e r a t i v e l y ,
d o e s n ’ t
l o a d
i n t o
memory
c o r p u s
m e m o r y f r i e n d l y = MyCorpus ( )
print
”Done . ”
###############################################################
print
” G e n e r a t i n g
LSA Space . . . ”
APPENDIX C.
CODE
99
# use
a
l o g −e n t r o p y
model
t o
w e i g h t
terms
l o g e n t
= models . LogEntropyModel ( c o r p u s
m e m o r y f r i e n d l y )
# i n i t i a l i z e
an LSI
t r a n s f o r m a t i o n
c o r p u s
l o g e n t
= l o g e n t [ c o r p u s
m e m o r y f r i e n d l y ]
l s i
= models . LsiModel ( c o r p u s
l o g e n t ,
id2word=d i c t i o n a r y ,
n u m t o p i c s=di me ns i on )
# c r e a t e
a
d o u b l e
wrapper
o v e r
t h e
o r i g i n a l
c o r p u s :
bow−>l o g e n t −>f o l d −in− l s i
c o r p u s
l s i
= l s i
[ c o r p u s
l o g e n t ]
print
c o r p u s
l s i
print
” I n d e x i n g
LSA Space . . . ”
i n d e x = s i m i l a r i t i e s . S i m i l a r i t y ( ” i n d e x . e ” ,
c o r p u s
l s i
,
n u m f e a t u r e s=d i m e n s i o n )
print
”Done . ”
# Save
Emotive
Brain
Model
( f o r
f u t u r e
work )
# We can
have
a
new b r a i n
model
each
month
f o r
example
#i n d e x . s a v e (”EB0”)
# Load
Emotive
Brain
Model
#i n d e x
= s i m i l a r i t i e s . M a t r i x S i m i l a r i t y . l o a d ( ”EB0” )
###############################################################
print
” C l u s t e r i n g
Documents . . . ”
mapEmotion = [ ]
# i n d e x ,
word
queryMatch = [ ]
# word ,
max
c o s i n e
(ELSA) / i n d e x
(DELSAR)
s e q u e n t i a l C o u n t
= 0 # We need
t h i s
t o
k e e p
t r a c k
o f
s t r e a m i n g
# Stream back
a l l
documents
i n
o r d e r
f o r
emotion
in r a n g e ( l e n ( emotionTerms ) ) :
try :
s q l
= ”SELECT text ,
@idx:=@idx+1 AS idx FROM ETWEETS WHERE emotion = ’% s ’
%s
LIMIT
%d” % ( emotionTerms [ emotion ] ,
s q l H a v i n g ,
l i m i t )
c u r s o r . e x e c u t e ( ”SELECT @idx : = 0 ; ” )
c u r s o r . e x e c u t e ( s q l )
r e s u l t s
= c u r s o r . f e t c h a l l ( )
f o r
row in
r e s u l t s :
# For
each
document ,
a
i s
a c t u a l
term ,
b
i s
most
s i m i l a r
term u s i n g
LSA
a = emotionTerms [ emotion ]
APPENDIX C.
CODE
100
# D e l e t e
t h e
emotion
keyword
from t h e
document
t w e e t
= row [ 0 ] . r e p l a c e ( emotionTerms [ emotion ] ,
” ” )
# Convert
t h e
document
t o
l o g e n t
LSA s p a c e
vec bow = d i c t i o n a r y . doc2bow ( t w e e t . l o w e r ( ) . s p l i t ( ) )
q u e r y
l s i
= l s i
[ l o g e n t [ vec bow ] ]
# Compute
document
s i m i l a r i t y
s i m s
= i n d e x [ q u e r y
l s i ]
s i m s
= s o r t e d ( enumerate ( s i m s ) ,
key=lambda item :
i t e m [ 0 ] )
# D e l e t e
t h e
c u r r e n t
document
from t h e
a r r a y
del
s i m s [ s e q u e n t i a l C o u n t ]
i f (ELSA) :
# ELSA u s e s
maximum c o s i n e
v a l u e
b = max( sims ,
key=lambda x :
x [ 1 ] )
e l s e :
# DELSAR j u s t
wants
t o
know what
emotion
i s
t h e
most
s i m i l a r
document
b = s i m s . i n d e x (max( sims ,
key=lambda x :
x [ 1 ] ) )
queryMatch . append ( [ a , b ] )
mapEmotion . append ( emotionTerms [ emotion ] )
s e q u e n t i a l C o u n t
+= 1
except
MySQLdb . Error ,
e :
print
” E r r o r
%d :
%s ” % ( e . a r g s [ 0 ] ,
e . a r g s [ 1 ] )
a c c u r a c y = [ ]
t o t a l H i t
= 0
t o t a l M i s s
= 0
i f ( printDELSAR ) :
c l u s t e r s
= [ ]
i f (ELSA) :
# For
each
emotion we
g e t
an
a v e r a g e
maximum c o s i n e
v a l u e
floatNums
= [ f l o a t ( v e c [ 1 ] [ 1 ] )
f o r
v e c
in queryMatch ]
a v e r a g e
= sum ( floatNums )
/
l e n ( queryMatch )
a c c u r a c y . append ( [ emotionTerms [ 0 ] ,
a v e r a g e ] )
f o r
v e c
in a c c u r a c y :
numbers . append ( v e c [ 1 ] )
print
v e c
e l s e :
# DELSAR
APPENDIX C.
CODE
101
# This
b i t
d e t e r m i n e s
a c c u r a c y
o f
c l u s t e r i n g
( l a b e l l i n g )
# I f
t h e
n e a r e s t
document
i s
t h e
same
emotion ,
i t
i s
a
h i t ,
# o t h e r w i s e
i t
i s
a
m i s s .
In
b o t h
o c c a s s i o n s ,
we
r e c o r d
# t h e
a c t u a l
emotion
i n
t h e
c l u s t e r s
a r r a y
i f
r e q u i r e d
# f o r
p r i n t i n g
t o
E x c e l
f o r
a
in r a n g e ( l e n ( emotionTerms ) ) :
h i t R a t e
= 0
h i t
= 0
m i s s
= 0
f o r
v e c
in queryMatch :
i f
v e c [ 0 ]
== emotionTerms [ a ] :
i f
v e c [ 0 ]
== mapEmotion [ vec [ 1 ] ] :
h i t
+= 1
t o t a l H i t
+= 1
i f ( printDELSAR ) :
c l u s t e r s . append ( ( v e c [ 0 ] , mapEmotion [ v e c [ 1 ] ] ) )
e l s e :
m i s s
+= 1
t o t a l M i s s
+= 1
i f ( printDELSAR ) :
c l u s t e r s . append ( ( v e c [ 0 ] , mapEmotion [ v e c [ 1 ] ] ) )
c
= f l o a t ( h i t )
d = f l o a t ( m i s s )
i f
c+d > 0 :
h i t R a t e
= c /( c+d )
# Accuracy
o f
h i t
r a t e
f o r
each
emotion
g e t s
appended
t o
t h i s
a r r a y
a c c u r a c y . append ( [ emotionTerms [ a ] ,
h i t R a t e ] )
t o t a l H i t
= f l o a t ( t o t a l H i t )
t o t a l M i s s
= f l o a t ( t o t a l M i s s )
i f ( ( t o t a l H i t+t o t a l M i s s )
> 0 ) :
t o t a l
= ( t o t a l H i t / ( t o t a l H i t+t o t a l M i s s ) )
e l s e :
t o t a l
= 0
# Reduce
emotion
s e t
and
rerun DELSAR i f
we
need
t o
r e d u c e
more
e m o t i o n s
i f ( l e n ( i n i t i a l )
> reduceTo ) :
APPENDIX C.
CODE
102
print
”Removed %s
(% f ) ” % ( min ( a c c u r a c y ,
key=lambda x :
x [ 1 ] ) [ 0 ] ,
min ( a c c u r a c y ,
key=lambda x :
x [ 1 ] ) [ 1 ] )
del
i n i t i a l
[
i n i t i a l
. i n d e x ( min ( a c c u r a c y ,
key=lambda x :
x [ 1 ] ) [ 0 ] ) ]
DELSAR( i n i t i a l
,
reduceTo )
# O t h e r w i s e
we ’ r e
done
e l s e :
f o r
v e c
in a c c u r a c y :
print
v e c
print
”TOTAL ACCURACY:
%f ” % t o t a l
i f ( printDELSAR ) :
# P r i n t
DELSAR c l u s t e r i n g
v a l u e s
i n
o r d e r
f o r
copy&p a s t e
i n t o
E x c e l
c
= Counter ( c l u s t e r s )
f o r
i
in r a n g e ( l e n ( emotionTerms ) ) :
f o r
j
in r a n g e ( l e n ( emotionTerms ) ) :
f o r
v e c
in c :
i f
v e c [ 0 ]
== emotionTerms [ i
] :
i f
v e c [ 1 ]
== emotionTerms [ j ] :
print
c [ v e c ]
###############################################################
# START PROGRAM HERE:
###############################################################
# S t a r t
t h e
t i m e r
t 0 = time . c l o c k ( )
i f (ELSA) :
numbers
= [ ]
f o r
a
in emotionTerms :
print
”ELSA” + s t r ( l i m i t )
+ ”
t e s t i n g
” + a + ”
with
” + s t r ( d i m e n s i o n )
+ ”
d i m e n s i o n s . ”
print
s q l H a v i n g
DELSAR( [ a ] ,
8 8 )
# Make
s u r e
t h e
number
h e r e
i s
g r e a t e r
t h a n
t h e
emotion
s e t
s i z e
f o r
v e c
in numbers :
print
v e c
APPENDIX C.
CODE
103
e l s e :
# DELSAR
print
”DELSAR” + s t r ( l i m i t )
+ ”
t e s t i n g
” + emotionTest
+ ”
with
” + s t r ( d i m e n s i o n )
+ ”
d i m e n s i o n s . ”
print
s q l H a v i n g
DELSAR( emotionTerms ,
8 8 )
# Change
t h e
number
h e r e
t o
t h e
f i n a l
r e d u c e d
keyword
s e t
s i z e
# C l o s e
d a t a b a s e
and
p r i n t
t o t a l
t i m e
t a k e n
db . c l o s e ( )
print
”Time
Taken : ”
print
s t r ( ( t i m e . c l o c k ( )
− t 0 ) / 6 0 )
# # # # # # # # −−−−−−−− END PYTHON −−−−−−−− # # # # # # # #
Appendix D
Appended Figures
104
APPENDIX D.
APPENDED FIGURES
105
Figure D.1:
Cosine similarity of primary emotion combinations to happy.
