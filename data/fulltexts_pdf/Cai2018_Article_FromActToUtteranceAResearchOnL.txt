From Act to Utterance: A Research on Linguistic Act
Convergence
Mali Cai
1,3
•
Hui Liu
2
•
Wei Yu
3
Published online: 12 January 2018
 Springer Science+Business Media,
LLC, part of Springer Nature 2018
Abstract
This paper presents an act–utterance convergence between children and their
guardians (an umbrella term for the adults who serve as children’s interaction partner in
this paper).
Act
and utterance are two different
carriers of intention.
Some convergence
patterns exist
in act–utterance interaction between young children and their
guardians.
Guardians tend to respond to their children by describing what
the children are doing,
reflecting this
convergence.
This
research has
built
the A–U Assimilation Model
to
assimilate act and utterance and narrow the gap of expression between act and utterance
while keeping their meanings unchanged. The unified expression framework in this model
makes the act and utterance comparable. The research analyzed the convergence between
act and utterance from children’s preverbal period to the age of 60 months by adopting a
large-scale corpus.
And the analysis of
the convergence between act
and utterance is
conducted by the Doc2Vec in a neural
network.
The experiment
results show that
the
degree of guardian-led act–utterance convergence increases rapidly during the period that
children begin to learn to speak and decrease gradually as children become more proficient
language learners and users.
Keywords Act–utterance convergence  A–U assimilation model  Unified
expression framework  Doc2vec
& Hui Liu
rx_78_ii@163.com
Mali Cai
mary_whu@outlook.com
Wei Yu
3341883515@qq.com
1
Department of Applied English,
Wuhan College of Foreign Languages and Foreign Affairs,
Wuhan 430083, China
2
Department of Management,
Wuhan Institute of Bioengineering,
Wuhan 430415,
China
3
State Key Laboratory of Software Engineering, School of Computer Science,
Wuhan University,
Wuhan 430072, China
123
Wireless Pers Commun (2018) 102:1853–1865
https://doi.org/10.1007/s11277-018-5241-4
1 Introduction
The mechanism of language learning of children is complicated,
especially because chil-
dren learn a lot of words and expressions in the first few years [1]. Studies have shown that
newborns can process mother’s speech as early as 2 days after the birth [2].
Linguistic
tuning theory predicts that
parents should tune the complexity of their speech for their
young children to make them learn languages more effectively [3].
A recent
study on
conversation between children and parents by Hierarchical Alignment Model shows that
parents indeed provide linguistic input that calibrates to children’s development [4].
The
theory of speech accommodation can explain such linguistic convergence, and the affect it
has on children’s language learning [5]. However, there is always a natural obstacle in the
research of linguistic convergence between children and parents: the exclusion of preverbal
children. In order to involve preverbal children in the convergence analysis, we analyze the
interaction from another perspective: the linguistic act convergence.
Humans use language to communicate with each other, the words we say, the message
we intend to convey.
But language is not the only message carrier for human communi-
cation;
act
is
another
carrier.
Preverbal
children can produce a variety of
nonverbal
behavior (eating, looking and pointing, etc.) to convey their intentions [6]. We predict that
in addition to certain convergence patterns in linguistic interaction [5],
there also exist
some convergence patterns in act–utterance interaction between children and their guar-
dians.
Act
and utterance are two different
carriers of intention.
In order to compare the
extent
of
convergence between them,
it
is essential
to unify them into a standardized
platform.
More generally,
we not
only examine the act–utterance interaction in the pre-
verbal period but try to analyze it in large-scale corpora analysis from the preverbal period
to the age of 60 months as a continuous process.
2 Empirical Analysis of Act–Utterance Interaction Between Children
and Guardians
Consider the Table 1,
a snippet of interaction between a preverbal child and her mother
with act tags in a text form,
taken from the Rollins Corpus [7].
This
is an act–utterance (or
A–U for
short)
interactions between target
child (12-
months) and her mom. Lines in Table 1 that start with ‘‘ %act’’ are act tags [8]; these lines
record the acts of the upstairs child.
Lines start
with tags ‘‘*CHI’’ or ‘‘*MOT’’ are the
utterance of child or mother.
Lines with content of number 0 indicate that
there was no
Table 1
A case of act–utterance
interactions between a preverbal
child(12-months) and his mom
Tag
Content
1
2
3
4
5
6
7
8
9
10
*CHI
%act
*MOT
*CHI
%act
*MOT
*CHI
%act
*MOT
*MOT
0
Reaches toward phone
Wanna push that
0
Takes phone from MOT
What is that
0
Looking at phone
Oh
Is that a phone
1854
M.
Cai et al.
123
talking. In this case, the target child (12-months) was in the preverbal period and was not
able to interact with his mother in a normal language. However, as an interaction partner,
the mother’s utterance reply depends on the child’s nonverbal acts input. For the boy’s act
‘‘reaches
toward phone’’,
the mother
responds
with a similar
utterance ‘‘wanna push
that(phone)’’ in semantic level.
The lexical correspondence between line 2 and line 3 is as Fig.
1. It can be found that
the corresponding parts of text are similar in meaning. It should be noted that the acts were
recorded by independent
coders [8],
and the description of
the act
is as objective as
possible. Consider the Table 2, taken from the McCune Corpus [9]. In line 1 and line 3, the
word ‘‘hammer’’ appeared in the child’s act record. In response, her mom re-used the same
word ‘‘hammer’’ (presented in the line 5 and 6) in line with child’s act. In fact, as an adult,
the mother did not really care about the purpose of her child picking up a toy hammer and
could even know that the child was going to hammer the wall because the child had done it
many times before (the last five documents before the child was 2 years old in this corpus
show that, each time the child would hammer the wall when she picked up the toy hammer
under the supervision of her mother). It indicates that mother tends to respond to the child
by describing the child’s act
that
just
happened.
We can also find other
act–utterance
convergence in the rest
part
of
Tables 1 and
2.
In fact,
this kind of
convergence is
common in other documents of interaction between children and guardians in the corpus.
3 The A-U assimilation model
In most cases, act text contains at least one verb and one noun, it rarely contains pronoun
and modifier. However, a large proportion of pronouns exist in the guardian’s utterances,
posing a challenge to the meaning differentiation between act
and language.
The A–U
Assimilation model is designed to eliminate the differences in the form between act and
utterance, and makes them comparable. The model is implemented in three steps, namely,
the division of A–U interaction,
the pronoun anaphora in A–U interaction and the sym-
bolization of the verb and noun.
Fig.
1
Lexical correspondence
between line 2 and line 3 in
Table 1
From Act to Utterance: A Research on Linguistic Act…
1855
123
3.1 The Division of A–U Interaction
Definition 1
The division of A–U interaction
S ¼ Uc
1
; Ac
1
ð
Þ; Ug
1
;
Uc
2
; Ac
2
ð
Þ; Ug
2
; . . .;
Uc
n
; Ac
n
ð
Þ; Ug
n
½

ð1Þ
where S is a list of act–utterance interaction in the corpus, the raw text in the list is divided
into three categories, Uc
i
for child’s utterances, Ac
i
for child’s acts and Ug
i
for guardian’s
utterances.
These elements are arranged in chronological sequence with the integer sub-
script i; i 2 1; n
½
 that represents the sequence of the interaction. The Uc
i
and Ac
i
that are
attributed to the bracket refer that they occur almost simultaneously. In order to study the
A–U interaction, we focus on the structure of segment
Uc
i
; Ac
i
ð
Þ; Ug
i
½
 in S, which contains
the contact point between child’s acts and guardian’s utterance. In the syntactic structure of
the act text Ac
i
, the act description contains verbs and nouns that primarily reflect the core
meanings of
the child’s acts,
and pronouns are rare in the act
sentence.
However,
the
guardian’s utterance Ug
i
presents a more vague structure of syntax and contains uncertain
proportion of irregular dialog. In order to reduce impact from the subjectivity of act coders
and the arbitrariness of spoken language,
the raw text in Ac
i
and Ug
i
needs to be unified
into a comparable framework.
3.2 Pronoun Anaphora in A–U Interaction
Act
text
contains a verb and a noun in most
cases.
However,
it
rarely contains any
pronouns or modifiers.
On the contrary,
a large proportion of pronouns exist in the guar-
dian’s reply for child, which makes it crucial to determine whether the pronoun in the Ug
i
points to the previous
content
in Ac
i
.
It
is essential
to complete anaphora resolution
automatically and rapidly when there is a huge amount of texts in the corpora.
Thus,
the
Back-Trace Probability is designed to tackle the anaphora resolution in the huge amount of
texts.
And its main principle is to predict the probabilities of the pronouns in guardians’
utterance referring to specific nouns in children’s act. The prediction is completed through
two aspects. One is the occurrence of specific words that are embodied in the children’s act
and utterance; another is the text’s chronological sequential distance between these specific
words and their pronouns. The result of the prediction is to substitute the original pronouns
according to the Back-Trace Probability.
Table 2
A snippet of act–utter-
ance interactions between a child
(24-months) and her mom
Tag
Content
1
2
3
4
5
6
7
8
9
10
11
%act
*CHI
%act
*MOT
*MOT
*CHI
%act
*MOT
%act
*MOT
*MOT
Takes hammer, gets up
0
Walks toward wall with hammer
You gonna hammer?
What are you gonna hammer?
I,
got,
that um,
wood
Hammers wall.
Okay
Reaches toward child
That’s good
Don’t hammer too hard
1856
M.
Cai et al.
123
Definition 2
Back-Trace Probability
P Ac
i
w
j


Ug
i
pro
ð
Þ


¼
arg max
j2Z
þ
u
i!i
w
j


a
i
w
j
; k




;
if
w
j
2 Uc
i
arg max
j2Z
þ
u
i!h
w
j


a
i
w
j
; k




;
if
w
j
6
2 Uc
i
8
>
<
>
:
0\h\i;
h 2 Z
a
i
w
j
; k


¼
count
w
j


P
n
k¼1
count
w
k
ð
Þ
;
if count
w
j


[k
i; j ¼ 1; 2; . . .
k;
if
count
w
j


k
0\k\1
8
>
<
>
:
ð2Þ
where P Ac
i
w
j


Ug
i
pro
ð
Þ


is a back-trace probability, it represents the probability that
a pronoun pro(if one exists) in guardian’s utterance Ug
i
points to the noun w
j
appeared in
previous act and utterance text of child. If count
w
j


[ k, the act factor a
i
w
j
; k


is the ratio
of count
w
j


to the number of all nouns appeared in the Ac
i
, if count
w
j


 k, the a
i
w
j
; k


equals k. count
w
j


is a counting function that records the number of w
j
occurrences. The
parameter k is a threshold that is used to prevent the probability value from being too small
or
equaling zero.
A small
value or
zero in act
factor
would make the Eq.
(2)
lose its
probability generating function.
The utterance factors,
u
i!i
w
j


and u
i!h
w
j


,
that
are used to exert
this kind of lin-
guistic effect. The u
i!i
w
j


represents the influence of child’s current utterance Uc
i
on his
current
act
Ac
i
,
when the w
j
appears in Uc
i
.
The u
i!h
w
j


represents the influence of
child’s previous utterance Uc
h
on his current act Ac
i
, when the w
j
appears in Uc
h
,
h\i
ð
Þ.
The back-trace probability measures the extent of how likely the pronoun in Ug
i
to point
the noun in Ac
i
. If Ac
i
has the same noun as in child’s utterance Uc
i
, the u
i
w
j


is given as
the value by Uc
i
otherwise the nouns in the previous text Uc
h
need to be examined.
Definition 3
Utterance Factor
u
i!v
w
j
; v


¼
1
1 þ e
r
1þiv
ð
Þcountðw
j
;vÞ
0\v  i ;
g 2 Z
ð3Þ
Equation 3 defines a specific mathematical expressions of the utterance factor u
i!v
w
j


, it
maps the times of w
j
occurrences into a probability value and unifies the mathematical
form of factor u
i!i
w
j


and u
i!h
w
j


into u
i!v
w
j
; v


. The function count
w
j
; v


in Eq.
(3)
refers to the number of noun w
j
appears in the child’s utterance Uc
v
. The Eq.
(3) is actually
a deformation of
sigmoid function with a span parameter
(i ! v)
and a regulation
parameter r. The span parameter uses the span between Uc
i
and Uc
v
to weaken the effect of
count
w
j
; v


on the utterance factor
u
i!v
w
j
; v


.
The regulation parameter
r is used to
adjust the effect of the span parameter and count
w
j
; v


on the factor value. It can be found
that when the parameter (i ! v) is fixed,
the more the number of w
j
appears in Uc
i
,
the
greater the value of utterance factor will be.
Definition 4
Back-trace probability in a unified structure
P Ac
i
w
j


Ug
i
pro
ð
Þ


¼ arg max
j2Z
þ
u
i!v
w
j
; v


a
i
w
j
; k




;
0\v  i ; v 2 Z
ð4Þ
From Act to Utterance: A Research on Linguistic Act…
1857
123
Replacing u
i!i
w
j


and u
i!h
w
j


with u
i!v
w
j
; v


,
Definition 2 can be converted to the
unified form as Definition 4.
The back-trace probability P Ac
i
w
j


Ug
i
pro
ð
Þ


deter-
mines the probability that the pronoun in Ug
i
would be replaced by noun w
i
in previous
text. In order to improve the computational performance, a threshold can be set for the span
of the forward traversal.
The traversal will stop if w
i
is not detected within the length of
threshold, in which case, let the threshold be d;
d \i
ð
Þ, then the span parameter could be
(i  d  1).
If there is no w
i
in both Ac
i
and Uc
v
,
the pro in Ug
i
will be retained.
Figure 2 shows how the back-trace probability is generated in the A–U assimilation
model.
The solid lines represent
the sequence of A–U interactions,
the dotted lines rep-
resent the functional routes of the utterance and act factors to the back-trace probability, all
of them determine the probability of pronouns in Ug
i
pointing to nouns in previous Ac
i
and
Uc
i
.
Definition 5
Characterization
Ug
i
!
P Ac
i
w
j
ð
Þ
Ug
i
pro
ð
Þ
ð
Þ
U
0
g
i
ð5Þ
where the U
0
g
i
is a Characterization of Ug
i
, it represents the text in which the pronouns in
the
Ug
i
are
replaced
by
the
nouns
according
to
the
back-trace
probability
P Ac
i
w
j


Ug
i
pro
ð
Þ


.
3.3 Symbolization of Verb and Noun
Verbs in English have different tenses and voices. They can be transformed to the original
form by means of dictionary mappings. However, unlike dialogues between two adults, the
interaction between children and adults can frequently contain a significant
amount
of
spoken language and informal expressions, which do not exist in the dictionary. Due to this
specific characteristic in the guardian-to-child conversation,
the A–U assimilation model
cannot rely on external dictionary mapping. Instead, the symbolization of the verb and the
noun has been adopted because it
can easily identify the informal
expressions in the
utterance between children and guardians. Firstly, the A–U assimilation model extracts the
same and continuous letters in the two left aligned verb in segment
Uc
i
; Ac
i
ð
Þ; Ug
i
½
, which
are considered a uniform semantic identity of the verbs. Secondly, these identities will be
i
j
a
w
i
Ug
i
Ac
v
Uc
v
Ac
v
Ug
i
Uc
i
Ug
i
Ac
i
Uc
i
v
j
u
w v
pro
Fig.
2
Pronominal anaphora and back-trace probability
1858
M.
Cai et al.
123
delivered into a unified expression framework.
In the similar fashion,
the singular and
plural of nouns can be also unified and delivered as semantic identities.
3.4 Unified Expression Framework
The unified expression framework is a list that contains expressions in a unified form, which is
divided into two sub-frameworks. One is utterance expression framework (U-EF), which can
be obtained by replacing the verbs and nouns in U
0
g
i
with their semantic identities. The other
is act expression framework (A-EF) that can be obtained by replacing the verbs and nouns in
Ac
i
with their semantic identities.
In unified expression framework,
each sub-framework
contains at least one noun identity and one verb identity with maximum possibility by the
drive of back-trace probability. The structure of ‘‘noun ID ? verb ID’’ in sub-framework is
the key to describe an act, since this kind of structure exists in both Ac
i
and U
0
g
i
, it makes them
comparable. In this way, during the convergence calculation of text, the expressions which
have different forms but the same semantics will not be excluded by the algorithm.
Consider
the mechanism of
unified expression framework in Fig.
3.
The solid lines
represent
the delivery path of the symbolized words,
and the dotted line represents the
delivery path of the pronominal anaphora that are implemented by back-trace probability.
The pronoun in Ug
i
is referring to the noun in Ac
i
and Uc
v
and then delivering it into U-EF.
In this way, we turn the comparison of A–U interactions convergence into a comparison of
their
similarities
between act
the expression framework and the utterance expression
framework.
We use the deep learning technique to calculate convergence.
4 Doc2vec in Convergence Analysis
The statistical language model has gone through a long period of development, based on it,
the neural network language model(or NNLM for short) [10] became a classic technique
that using neural network for natural language processing. Subsequent development work
is carried out with reference to this model. Now, there are word2vec that contains CBOW
model
and Continuous Skip-gram model
that
simpler than NNLM in model architecture
Fig.
3
Mechanism of unified expression framework
From Act to Utterance: A Research on Linguistic Act…
1859
123
[11, 12], and the doc2vec, which contains Distributed Memory model and Distributed Bag
of Words model [13], as an extension of word2vec, can be used in the training of phrases
vectors.
In Continuous Skip-gram model, as shown in Fig.
4, the current word is related to the
surrounding words [14, 15], the neural network input is a word vector [16], the skip-gram
model needs to predict the relative words within a certain range before and after the current
word. The second layer is a log-linear classifier with continuous projection layer, thus the
computation complexity in this model is C  D þ C  D  log
2
V
ð
Þ,
where C is the max
word distance in certain rang,
D is the dimension of the input vector and where V is the
number of different words in training corpus.
Theoretically, as the range increases, the quality of the resulting word vectors will also
improve, because the current words will associate with more words in context. Meanwhile,
this will result in an increase of computation complexity. The specific training process is as
follows:
1.
Build a glossary of words according to corpus,
with each word in the glossary being
initialized to a high dimensional vector.
2.
Train the text in the corpus in turn, plug in the vector of current word into the model,
3.
According to the Huffman Coding of context
word of current
word,
the model
can
determine the correct path from the root node to the leaf node, which also determines
the predictions that
should be made by classifiers (non-leaf nodes) on the path.
The
current word vector is placed to the root node of the Huffman tree and then transferred
into a leaf node, by which process the model completes a prediction. The parameters
of the non-leaf node and the current
word vector are updated by using the gradient
descent algorithm.
4.
Repeat steps 3 until all the words in the glossary are predicted.
Word2vec was opened in 2013 by google Inc. to train word vectors. Its core architecture
includes skip-gram.
The distributed Bag of Words model
in doc2vec is an extension of
skip-gram,
its principle is basically the same as the former but
each input
should be a
sentence with a unique ID. We implement the training by doc2vec in Gensim [17, 18]. The
text
is processed into a list
in unified expression framework by the A–U assimilation
model.
Definition 6
Unified act–utterance list in expression framework
Fig.
4
Continuous skip-gram architecture
1860
M.
Cai et al.
123
S
0
¼ Uc
1
; A  EF
1
ð
Þ; U  EF
1
;
Uc
2
; A  EF
2
ð
Þ; U  EF
2
; . . .;
Uc
n
; A  EF
n
ð
Þ; U  EF
n
½

ð6Þ
where S
0
is the unified act–utterance list in expression framework,
compare to the list of
raw text, the items of child’s act Ac
i
and guardian’s utterance Ug
i
are replaced by A  EF
i
and U  EF
i
respectively.
Sentences in S
0
are given as doc2vec inputs.
5 Convergence Analysis
To achieve a larger data size, we merged eight corpora. Children aged 0–6 years old were
distributed in corpora with act description. For a corpus that covers a small amount of age,
we appropriately repeat
the corpus of this age group to make the whole corpus evenly
distributed in the age of examination.
In fact,
each interaction is recorded at
a point
of
child’s age rather than a range of ages.
In order to analyze convergence in a continuous
way, we use the child’s age point as the center of time interval evenly dispersed with time
in interaction sequence. For example, in an A–U interaction record, the children here are 2,
2.3 and 2.5 years old, while the record of child who is 2 years old can be evenly scattered
as 1.85–2.15 years old,
and the records of rest children can be evenly scattered as 2.15–
2.45 and 2.35–2.65 years old.
The training environment is Python 3.6 with gensim 2.3.0
and numpy [19] It runs on Windows 10 64-bit operating system.
The hardware configu-
rations are Intel i7 7700 K CPU ,DDR4 2133 32 GB RAM. The span threshold d in the A–
U assimilation model
is set
to 3 and k = 2.
By performing similarity calculations in
doc2vec for each
A  EF
i
; U  EF
i
f
g
by using the trained model.
As shown in Fig.
5,
the blue dots represent the convergence values of each A–U pair;
the red curve is the result of polynomial fitting (deg = 4) for convergence value. When the
children are 0–10 months old,
the guardians’ convergence is rising rapidly from a lower
starting point. According to the corpora, maybe due to the preverbal stage, it can be found
that the guardian has no special reaction to the child’s act, which can explain the initial low
point of convergence. When the children are 10–20 months old, which is the key stage of
Fig.
5
Act–utterance convergence
From Act to Utterance: A Research on Linguistic Act…
1861
123
children learning the language,
the guardian’s utterance convergence stay at
a relatively
high level. The high convergence indicates that the guardians respond to the children with
similar descriptions of children’s acts, but whether the descriptions are for the children to
learn language needs further research.
After 20 months,
there was a long slow decline in
convergence. In this period, children have been able to speak and become more proficient.
At the end of the curve,
convergence tends to rise slightly,
it may be due to the fact that
some of the interactions in the later age are taken place in the classroom, where the act and
utterance of
children are highly guided by teachers(the guardians
in kindergarten or
school).
In order to find out whether this kind of convergence trend is universal or not, we also
study the act–utterance interactions between adults.
Because there is no text
of act–ut-
terance interaction between adults in existing corpus, we organized nineteen undergraduate
volunteers to participate in the A–U corpus production project, in the project, we recorded
the volunteers’ ages, conversations and acts at the time of recording(when the same person
records multiple times,
the age will
change).
The age of volunteers ranged from 212 to
247 months old.
Same as before,
as the center of time interval,
the undergraduate’s age
point evenly dispersed with time in interaction sequence. The recording locations include
street,
cafeteria,
lab,
McDonald’s,
and indoor stadium.
As shown in Fig.
6,
the blue dots
represent
the convergence values of
each A-U pair,
the yellow curve is the result
of
polynomial fitting(deg=4) for convergence value.
In order to understand the effect of the A–U assimilation model for the the calculation
of convergence, we also calculate the convergence of raw text in previous eight corpora in
Fig.
5 (the training process is also use raw text without conversion of A–U assimilation).
As shown in Fig.
7,
the red curve is the result
of polynomial
fitting (deg = 4) for con-
vergences in unified expression framework,
the default
input
lists are the text
that
con-
verted by A–U assimilation.
The green curve is the result of polynomial fitting(deg = 4)
for convergences of raw text between act and utterance.
Compare to the convergences in
expression framework, the convergences between raw text shows a steady trend with slight
fluctuations, it indicates that the A–U assimilation model does reinforce the features of A–
U interaction.
At the beginning, the green curve is higher than the red curve.
We believe
Fig.
6
Act–utterance convergence between adults
1862
M.
Cai et al.
123
that this is due to too many pronouns in Ug
i
misleading the comparison, they are treated as
an identical or similar object. After that, the red line is higher than the green line and shows
that in the stages of preverbal and learning language,
the features of A–U interaction are
properly extracted by A–U assimilation model.
6 Conclusions
The research analyzed the convergence between act
and utterance from children’s pre-
verbal period to the age of 60 months by adopting A–U assimilation model and Doc2vec.
This research has built
the A–U assimilation model
to assimilate act
and utterance and
narrow the gap of expression between act
and utterance while keeping their
meanings
unchanged.
The unified expression framework in this model makes the act and utterance
comparable. The text is processed into a list in unified expression framework by the A–U
assimilation
model.
Three
experiments
were
conducted:
act–utterance
convergence
between children and guardians,
act–utterance convergence between adults and act–ut-
terance convergences of raw text between children and guardians. The experiment results
show that the degree of guardian-led act–utterance convergence increases rapidly during
the period that children begin to learn to speak and decrease gradually as children become
more proficient language learners and users, on the contrary,
there is no obvious trend in
convergence between adults.
Compare to the convergences in expression framework,
the
convergences between raw text shows a steady trend with slight fluctuations,
it indicates
that the A–U assimilation model does reinforce the features of A–U interaction.
Acknowledgements This work was financially supported by the National Natural Science Foundation of
China (Grant: 61502350).
Thanks are due to Wenfeng Z,
Xianping Y et al.,
for participation in the A–U
interaction experiments as undergraduate volunteers.
Fig.
7
Act–utterance convergences of raw text between children and guardians
From Act to Utterance: A Research on Linguistic Act…
1863
123
References
1.
Mayor, J., & Plunkett, K. (2011). A statistical estimate of infant and toddler vocabulary size from cdi
analysis.
Developmental Science,
14(4),
769.
2.
Perani,
D.,
Saccuman,
M.
C.,
Scifo,
P.,
Anwander,
A.,
Awander,
A.,
Spada,
D.,
et al.
(2011).
Neural
language networks at birth.
Proceedings of the National Academy of Sciences of the United States of
America,
108(38),
16056–16061.
3.
Snow, C. E. (1972). Mothers’ speech to children learning language. Child Development, 43(2), 549–565.
4.
Yurovsky, D., Doyle, G., & Frank, M. C. (2016). Linguistic input is tuned to children’s developmental
level.
In Proceedings of the 38th annual meeting of the cognitive science society (pp.
2093–2098).
5.
Giles, H., Coupland, J., & Coupland, N. (Eds.). (1991). Contexts of accommodation: Developments in
applied sociolinguistics.
Cambridge: Cambridge University Press.
6.
Buresh, J. S., & Woodward, A. L. (2007). Infants track action goals within and across agents. Cognition,
104(2),
287–314.
7.
Rollins,
P.
R.,
& Greenwald,
L.
C.
(2013).
Affect attunement during mother-infant
interaction: How
specific intensities
predict
the stability of
infants’
coordinated joint
attention skills.
Imagination,
Cognition and Personality,
32(4),
339–366.
8.
MacWhinney, B. (2000). The CHILDES project: Tools for analyzing talk (3rd ed.). Mahwah: Lawrence
Erlbaum Associates.
9.
McCune,
L.
(1995).
A normative study of representational
play at
the transition to language.
Devel-
opmental Psychology,
31(2),
198–206.
10.
Bengio,
Y.,
Vincent,
P.,
& Janvin,
C.
(2006).
A neural
probabilistic language model.
Journal
of
Machine Learning Research, 3(6),
1137–1155.
11.
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in
vector space.
arXiv preprint arXiv:1301.3781.
12.
Mikolov,
T.,
Sutskever,
I.,
Chen,
K.,
Corrado,
G.,
& Dean,
J.
(2013).
Distributed representations of
words
and phrases
and their
compositionality.
In International
conference on neural
information
processing systems (Vol.
26,
pp.
3111–3119). Curran Associates Inc.
13.
Le, Q., & Mikolov, T. (2014). Distributed representations of sentences and documents. In Proceedings
of the 31st international conference on machine learning (ICML-14) (pp.
1188–1196).
14.
Zhang, Z., & Lan, M. (2016). Learning sentiment-inherent word embedding for word-level and sentence-
level sentiment analysis. In International conference on asian language processing (pp. 94–97). IEEE.
15.
Rehurek,
R.,
& Sojka,
P.
(2010).
Software framework for
topic modelling with large corpora.
In
Proceedings of the LREC 2010 workshop on new challenges for NLP frameworks.
16.
Chen,
S.,
Soni,
A.,
Pappu,
A.,
& Mehdad,
Y.
(2017).
Doctag2vec: An embedding based multi-label
learning approach for document tagging,
pp.
111–120.
17.
Maslova, N., & Potapov, V. (2017). Neural network doc2vec in automated sentiment analysis for short
informal texts. In International Conference on Speech and Computer (pp.
546–554).
Springer, Cham.
18.
Chan, W., Jaitly, N., Le, Q., & Vinyals, O. (2016). Listen, attend and spell: A neural network for large
vocabulary conversational speech recognition.
In IEEE international conference on acoustics,
speech
and signal processing (pp.
4960–4964). IEEE.
19.
Pajankar, A. (2017). Introduction to NumPy. Raspberry Pi supercomputing and scientific programming.
New York: Apress.
1864
M.
Cai et al.
123
Mali
Cai
received the M.A.
degree in School of Foreign Languages
from Wuhan University of Technology,
China,
in 2016.
She is cur-
rently a full time lecturer of Wuhan College of Foreign Languages and
Foreign Affairs.
She is primarily involved in applied linguistics pro-
jects.
His current
field of research is network dialogue analysis and
multimedia text analysis.
Hui Liu received the Ph.D.
degree in Chinese Modern and Contem-
porary Literature from Wuhan University,
China,
in 2014.
She is
currently a full time lecturer in Wuhan Bioengineering Institute,China.
Her current field is Chinese Modern and Contemporary Literature and
protection of intangible cultural heritage.
Wei Yu born in 1987. Ph.D. Now he is working in Computer School of
Wuhan University as Lecturer. His research interests are in the areas of
Web Data Ming and Natural Language Processing.
He is member of
China Computer Federation.
From Act to Utterance: A Research on Linguistic Act…
1865
123
