HAL Id:
hal-01226551
https://hal.archives-ouvertes.fr/hal-01226551
Submitted on 27 Nov 2015
HAL is
a
multi-disciplinary
open
access
archive for the deposit and dissemination of
sci-
entific research documents, whether they are pub-
lished or not.
The documents may come from
teaching and research institutions
in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL,
est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche,
publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers,
des laboratoires
publics ou privés.
Thésaurus distributionnels pour la recherche
d’information et vice-versa
Vincent Claveau, Ewa Kijak
To cite this version:
Vincent Claveau, Ewa Kijak.
Thésaurus distributionnels pour la recherche d’information et vice-versa.
Revue des Sciences et Technologies de l’Information - Série Document Numérique, Lavoisier, 2015, 18
(2-3), <10.3166/DN.18.2-3.101-121>.
<hal-01226551>
Thésaurus distributionnels pour
la recherche d’information et vice-versa
Vincent Claveau
1
, Ewa Kijak
2
1. IRISA-CNRS, Campus de Beaulieu, 35042 Rennes, France
vincent.claveau@irisa.fr
2. IRISA-Univ. Rennes 1, Campus de Beaulieu, 35042 Rennes, France
ewa.kijak@irisa.fr
RÉSUMÉ.
Les
thésaurus
distributionnels
sont
utiles
à de nombreuses
tâches
du traitement
automatique des langues. Dans cet article, nous abordons les problèmes de leur construction
et
de leur évaluation sous l’angle de la recherche d’information.
Deux contributions sont
proposées. D’une part, en poursuite des travaux initiés par Claveau et al., 2014, nous montrons
comment les techniques de RI peuvent être utilisées avec succès pour construire ces thésaurus.
Au moyen d’une évaluation directe par comparaison avec des lexiques de référence et
au
travers de plusieurs expérimentations, nous montrons que les résultats obtenus par des modèles
de RI dépassent
les performances des systèmes état
de l’art.
D’autre part,
nous utilisons la
RI comme cadre applicatif pour proposer une évaluation indirecte des thésaurus produits. Là
encore,
cette évaluation valide l’approche.
Mais surtout,
elle permet de mettre en regard les
performances obtenues sur cette tâche avec celles des évaluations directes utilisées dans la
littérature. Les différences constatées remettent en cause en partie ces pratiques d’évaluation.
ABSTRACT.
Distributional
thesauri
are useful
in many tasks of
Natural
Language Processing.
In this paper,
we address the problem of
building and evaluating such thesauri
with the
help of
Information Retrieval
concepts.
Two main contributions are proposed.
First,
in the
continuation of the work of Claveau et al., 2014, we show how IR tools and concepts can be
used with success to build thesaurus. Through several experiments and by evaluating directly
the results with reference lexicons,
we show that some IR models outperform state-of-the-art
systems. Secondly, we use IR as an application framework to indirectly evaluate the generated
thesaurus.
Here again,
this task-based evaluation validate the IR approach used to build the
thesaurus. Moreover, it allows us to compare these results with those from the direct evaluation
framework used in the literature. The observed differences question these evaluation habits.
MOTS-CLÉS :
thésaurus distributionnels,
sémantique distributionnelle,
construction de lexique,
modèles de RI, évaluation directe, évaluation par tâche, extension de requêtes.
KEYWORDS:
distributional
thesaurus,
distributional
semantics,
lexicon generation,
IR models,
direct evaluation, task-based evaluation, query expansion.
1.
Introduction
La sémantique distributionnelle a pour
objet
de construire des thésaurus (ou
lexiques) automatiquement à partir de corpus de textes. Pour une entrée donnée (ie.
un mot donné),
ces thésaurus recensent des mots sémantiquement proches en s’ap-
puyant sur l’hypothèse qu’ils partagent une distribution similaire au mot d’entrée. En
pratique, cette hypothèse distributionnelle est mise en œuvre simplement : deux mots
seront considérés proches s’ils partagent des contextes similaires. Ces contextes sont
typiquement les mots cooccurrant dans une fenêtre restreinte autour du mot examiné,
ou les mots liés syntaxiquement à celui-ci.
L’évaluation de ces thésaurus reste un point crucial pour juger de la qualité des mé-
thodes de construction employées. Une approche communément utilisée est de com-
parer le thésaurus produit à un ou plusieurs lexiques de référence.
Cette évaluation,
qualifiée d’intrinsèque,
a pour avantage d’être directe et
simple puisqu’elle permet
d’estimer la qualité et la complétude du thésaurus produit. Cependant, elle repose sur
des lexiques de référence dont la complétude, la qualité, ou tout simplement la dispo-
nibilité pour le domaine traité ne sont pas assurés.
Dans cet article, nous proposons d’examiner ces deux aspects – la construction et
l’évaluation des thésaurus distributionnels – sous l’angle de la recherche d’informa-
tion, utilisée à la fois comme technique et comme usage.
Concernant la construction,
des travaux récents (Claveau et al.,
2014) ont mon-
tré que des systèmes de RI pouvaient avantageusement être utilisés pour mettre en
œuvre cette analyse distributionnelle. Nous proposons dans cet article d’explorer cette
approche RI de la construction des thésaurus en examinant l’intérêt de différents mo-
dèles classiques de RI, en les comparant à l’état de l’art. Nous testons également les
modèles de type
WORD
2
VEC
(Mikolov et al., 2013) qui ont fait l’objet de beaucoup
de recherches ces dernières années.
Concernant l’évaluation, nous proposons une évaluation extrinsèque des thésaurus
produits dans une tâche de RI classique.
Cela nous permet de mettre en regard ces
résultats avec ceux obtenus par évaluation intrinsèque et donc de juger de la pertinence
de ces scénarios d’évaluation.
Après un état de l’art (section suivante),
l’article aborde ces deux contributions
successivement : les aspects relatifs à la construction des thésaurus sont présentés en
section 3, ceux portant sur l’évaluation par RI sont en section 4. Nous présentons enfin
quelques conclusions et perspectives sur ce travail dans la dernière section.
2.
État de l’art
2.1.
Construction de thésaurus distributionnels
La construction de thésaurus distributionnels a fait l’objet de nombreuses études
depuis les travaux pionniers de Grefenstette, 1994 et Lin, 1998. Toutes reposent sur
Thésaurus distributionnels et RI
l’hypothèse distributionnelle de Firth, 1957 que l’on résume par sa formule célèbre :
You should know a word by the company it keeps. On considère que chaque mot est ca-
ractérisé sémantiquement par l’ensemble des contextes dans lesquels il apparaît. Pour
un mot en entrée d’un thésaurus, des mots partageant des similarités de contextes sont
proposés ; on les appelle voisins sémantiques par la suite. La nature du lien sémantique
entre une entrée et ses voisins est variable ; ils peuvent être des synonymes de l’entrée,
des hyperonymes, des hyponymes ou d’autres types de liens sémantiques (Budanitsky,
Hirst, 2006 ; Adam et al., 2013, pour une discussion). Ces liens sémantiques, même
s’ils sont très divers, sont néanmoins utiles pour de nombreuses applications liées au
Traitement Automatique des Langues. Cela explique que ce champ de recherche soit
encore très actif, avec des contributions portant sur différents aspects liés à la construc-
tion de ces thésaurus.
Tout
d’abord,
différentes pistes sur ce qui
peut
être considéré comme contexte
distributionnel
ont
été explorées.
On distingue ainsi
les contextes graphiques des
contextes syntaxiques.
Les premiers sont
simplement
les mots apparaissant
autour
du mot étudié. Les seconds sont les mots recteurs ou dépendants syntaxiques du mot
examiné. La seconde approche est souvent considérée comme plus précise, mais elle
repose bien sûr sur une analyse syntaxique préalable qui n’est pas toujours disponible
et peut même être source d’erreurs.
Les connexions entre sémantique distributionnelle et
RI sont
nombreuses.
Plu-
sieurs chercheurs ont,
par exemple,
utilisé des moteurs de recherche pour collecter
des informations de co-occurrences ou des contextes sur le web (Turney, 2001 ; Bol-
legala et
al.,
2007 ;
Sahami,
Heilman,
2006 ;
Ruiz-Casado et
al.,
2005).
Les repré-
sentations vectorielles des contextes sont également souvent utilisées de différentes
manières (Turney, Pantel, 2010), mais sans lien avec les systèmes de pondérations et
les fonctions de pertinence classiques de la RI (à l’exception de (Vechtomova, Robert-
son, 2012) dans un cadre un peu différent de similarité entre entités nommées). Plu-
sieurs travaux se sont pourtant penchés sur la pondération des contextes pour obtenir
de meilleurs voisins.
Par exemple,
Broda et al.,
2009 a proposé de ne pas considé-
rer directement les poids des contextes, mais les rangs pour s’affranchir de l’influence
des fonctions de pondérations. D’autres ont proposé des méthodes d’amorçage (boots-
trap) pour modifier les poids des contextes d’un mot en prenant déjà en compte ses
voisins sémantiques (Zhitomirsky-Geffet, Dagan, 2009 ; Yamamoto, Asakura, 2010).
Par ailleurs, beaucoup de travaux se sont basés sur le fait que la représentation "tra-
ditionnelle" des contextes distributionnels est
très creuse et
redondante,
comme l’a
illustré Hagiwara et al., 2006. Dans ce contexte, plusieurs méthodes de réduction de
la dimension ont été testées : depuis l’analyse sémantique latente (T.
K.
Landauer,
Dumais,
1997 ;
Padó,
Lapata,
2007 ;
Van de Cruys et
al.,
2011),
jusqu’au Random
Indexing (Sahlgren, 2001), en passant par la factorisation par matrices non négatives
(Van de Cruys, 2010).
Récemment,
Claveau et al.,
2014 ont proposé d’identifier plus complètement le
processus de recherche de voisins distributionnels comme un problème de recherche
documentaire classique. L’ensemble des contextes d’un mot peut en effet être repré-
senté comme un document ou une requête,
ce qui permet de trouver facilement les
mots proches, ou plus exactement les ensembles de contextes proches. Bien que par-
tageant de nombreux points communs avec des travaux de l’état de l’art, cette façon
simple de poser le problème de la construction des thésaurus distributionnels offre
des pistes intéressantes et un outillage facilement accessible. C’est cette approche que
nous reprenons dans le cadre de cet article ; nous la décrivons plus en détail dans la
section 3.1.
2.2.
Évaluation des thésaurus distributionnels
Comme nous l’avons dit précédemment, l’évaluation des thésaurus produits se fait
soit de manière intrinsèque,
en les comparant à une ressource de référence,
soit de
manière extrinsèque, au travers de leur utilisation dans une tâche précise.
Dans le cas de l’évaluation intrinsèque, il faut disposer de lexiques de référence.
Il est alors simple de calculer rappel,
précision ou toute autre mesure de qualité du
lexique produit. Cette approche a été utilisée pour évaluer de nombreux travaux. Parmi
les lexiques régulièrement
utilisés comme références,
on peut
citer WordSim 353
(Gabrilovich, Markovitch, 2007), ou ceux utilisés par Ferret, 2013 qui exploitent des
ressources plus larges,
à savoir les synonymes de WordNet 3.0 (Miller,
1990) et le
thésaurus Moby (Ward, 1996). Ce sont ces deux derniers lexiques que nous utilisons
nous aussi pour l’évaluation intrinsèque ; voir ci-après pour une présentation. D’autres
ressources ne sont pas directement des lexiques, mais des jeux de données permettant
une évaluation directe, comme le jeu de synonymes du TOEFL (T. Landauer, Dumais,
1997) ou l’ensemble de relations sémantiques BLESS (Baroni, Lenci, 2011).
L’évaluation directe séduit par sa simplicité,
mais pose la question de l’adéqua-
tion des lexiques utilisés comme références.
Plusieurs recherches ont donc proposé
des évaluations indirectes au travers d’une tâche. La plus connue est la tâche de sub-
stitution lexicale mise en œuvre à SemEval 2007 (McCarthy,
Navigli,
2009).
Étant
donné un mot dans une phrase, le but est de remplacer ce mot par un de ses voisins
supposés et de vérifier que cela n’altère pas le sens de la phrase. Les résultats obte-
nus sont ensuite comparés aux substitutions proposées par des humains. Cette tâche
va donc privilégier les synonymes exacts au détriment des autres types de relations
sémantiques. L’évaluation de thésaurus distributionnels par des tâches de RI n’a pas,
à notre connaissance, été explorée. Bien sûr, l’utilisation d’informations que l’on peut
qualifier de distributionnelles dans un cadre de RI a fait l’objet de plusieurs travaux
(Besançon et al., 1999 ; Billhardt et al., 2002) qui se prolongent de nos jours par les
travaux sur les représentations lexicales apprises par réseaux de neurones (Huang et
al., 2012 ; Mikolov et al., 2013). Il s’agit dans tous les cas de tirer parti des simila-
rités de contextes entre mots pour améliorer la représentation des documents et/ou la
fonction de pertinence RSV. Cependant, ces travaux ne dissocient pas le processus de
création du thésaurus distributionnel du processus de RI, ce qui rend impossible l’éva-
luation de l’apport des informations distributionnelles seules. Dans notre cas, l’éva-
luation extrinsèque par RI que nous proposons (cf. section 4) repose simplement sur
Thésaurus distributionnels et RI
l’utilisation des voisins sémantiques pour étendre des requêtes ; le reste du système de
recherche d’information est standard. Cela doit nous permettre de juger au mieux de
la qualité des thésaurus produits.
3.
Modèles de RI pour l’analyse distributionnelle
3.1.
Principes et matériel
Comme nous l’avons expliqué en introduction, le problème de la construction d’un
lexique distributionnel peut être vu comme un problème de recherche de documents
similaires et peut donc être mis en œuvre avec des techniques de RI. Dans ce cadre,
pour un mot donné, ses contextes dans un corpus sont collectés et rassemblés. C’est
cet ensemble de contextes qui forme un document. Construire une entrée du lexique,
c’est-à-dire trouver les mots proches au sens distributionnel d’un mot
w
i
, revient alors
à trouver les documents (contextes) proches du document représentant les contextes
de
w
i
.
Les données que nous utilisons pour nos expériences de construction sont celles
utilisées dans plusieurs travaux. Cela va nous permettre de comparer nos résultats à
ceux publiés. Le corpus utilisé pour collecter les contextes est le corpus AQUAINT-
2 ; il est composé de d’articles de presse en anglais et compte 380 millions de mots.
Parmi eux, les mots que nous considérons pour entrées de notre lexique sont les noms
communs apparaissant au moins 10 fois dans le corpus, soit 25 000 noms différents.
Les contextes de toutes les occurrences de ces mots sont
donc collectés ;
dans les
expériences rapportées ci-dessous, le contexte d’un mot est composé des deux mots
à droite et deux mots à gauche du nom visé,
en gardant leur position.
Par exemple,
dans l’extrait : "
...
all
forms of
restriction on freedom of
expression,
threats ...
",
les
mots
restriction-2
,
on-1
,
of+1
,
expression+2
sont ajoutés à l’ensemble des contextes
freedom
. La figure 1 illustre l’ensemble de cette démarche.
Comme nous l’avons évoqué précédemment, nous utilisons conjointement Word-
Net
(WN) et
Moby pour l’évaluation intrinsèque des thésaurus produits.
Ces deux
ressources offrent des caractéristiques complémentaires : WN recense des liens sé-
mantiques forts (synonymes ou quasi-synonymes) alors que Moby recense une plus
grande variété de liens (hyperonymes,
méronymes,
co-hyponymie...).
Une descrip-
tion détaillée des liens considérés par ces ressources est donnée par Ferret, 2013 ou
Claveau et al., 2014. Ainsi, WN propose en moyenne 3 voisins pour 10 473 des noms
du corpus AQUAINT-2 et Moby 50 voisins en moyenne pour 9 216 noms. Combinées,
ces deux ressources couvrent 12 243 noms du corpus avec 38 voisins en moyenne. Le
nombre de noms dans les listes de référence et la variété des relations sémantiques
considérées font de ces données un jeu d’évaluation très complet par rapport à d’autres
benchmarks parfois utilisés tels que WordSim 353 (Gabrilovich, Markovitch, 2007).
Figure 1. Illustration de la collecte des contextes des mots (ici, freedom) et de leur
représentation comme des documents en RI (sacs de mots, ou sacs de contextes)
3.2.
Test des modèles de RI
Le tableau 1 présente les résultats obtenus par différents systèmes de construction
de thésaurus, appliqués au corpus AQUAINT-2. Les mesures de performances utilisées
pour comparer les thésaurus produits à la référence WordNet+Moby sont classique-
ment la précision à différents seuils (P@x), la MAP et la R-précision, moyennés sur
les 12 243 noms de la référence WN+Moby et exprimés en pourcentage.
Nous testons notamment des systèmes probabilistes par modèles de langues (notés
LM) dans lesquels la pertinence d’une requête est évaluée en fonction de la probabilité
d’apparition des mots selon un modèle appris pour chaque document ; voir équation 1.
RSV
LM
(Q, D) =
Y
t∈Q
P (t|M
D
)
qtf
(1)
Les notations sont les suivantes :
Q
est une requête,
D
un document,
t
un terme
d’indexation,
M
D
un modèle de langue du document, et
qtf
est le nombre d’occur-
rences de
t
dans
Q
.
Pour estimer la probabilité d’apparition d’un terme,
deux variantes très usuelles
sont testées correspondant à deux techniques de lissage, toutes deux utilisant les pro-
Thésaurus distributionnels et RI
Tableau 1. Performances des modèles de RI pour la construction des thésaurus
distributionnels sur la référence WN+Moby
Méthode
MAP
R-Prec
P@1
P@5
P@10
P@50
P@100
Ferret 2013 base
5,6
7,7
22,5
14,1
10,8
5,3
3,8
Ferret 2013 best rerank
6,1
8,4
24,8
15,4
11,7
5,7
3,8
Ferret 2014 synt
7,9
10,7
29,4
18,9
14,6
7,3
5,2
Hellinger
2,45
2,89
9,73
6,28
5,31
4,12
3,30
TF-IDF
5,40
7,28
21,73
13,74
9,59
5,17
3,49
TF-IDF ajusté
7,09
9,02
24,68
15,13
11,55
5,96
4,31
Okapi-BM25
6,72
8,41
24,82
14,65
10,85
5,16
3,66
Okapi-BM25 ajusté
8,97
10,94
31,05
18,44
13,76
6,46
4,54
LM Dirichlet
µ = 25
6,52
7,56
23,46
11,88
8,16
2,99
1,89
LM Dirichlet
µ = 250
6,56
7,43
23,08
12,31
8,17
2,77
1,73
LM Dirichlet
µ = 2500
5,83
6,77
23,28
12,06
8,00
2,98
1,81
LM Hiemstra
λ = 0, 45
5,41
6,79
25,09
12,07
8,17
3,05
1,90
LM Hiemstra
λ = 0, 65
8,10
8,98
27,06
13,35
9,25
3,41
2,13
LM Hiemstra
λ = 0, 85
7,06
7,88
25,28
12,44
8,41
3,04
1,89
LM Hiemstra
λ = 0, 95
6,49
7,64
27,21
13,62
9,17
3,28
2,06
babilités d’apparition des mots dans toute la collection pour mieux estimer celles des
documents. Il s’agit d’une part du lissage de Dirichlet que nous testons avec différentes
valeurs du paramètre
µ
; voir équation 2.
P (t|M
D
) =
tf + µ ∗ P (t, C)
dl(D) + µ
(2)
dl(D)
est la longueur du document
D
et
P (t, C)
la probabilité d’apparition de
t
dans l’ensemble de la collection (typiquement sa fréquence dans la collection),
tf
est le nombre d’occurrences de
t
dans
D
. Et d’autre part, nous testons le lissage à la
Hiemstra (ou lissage de Jelinek-Mercer) avec différentes valeurs de
λ
; voir équation 3.
P (t|M
D
) = (1 − λ)
tf
dl(D)
+ λP (t|C)
(3)
Ces modèles sont mis en œuvre en utilisant le système de RI Indri
1
.
Nous rapportons également les résultats des systèmes déjà présentés dans (Claveau
et al., 2014), qui reposent sur la similarité d’Hellinger (Escoffier, 1978 ; Domengès,
Volle, 1979), un TF-IDF/cosinus, et Okapi-BM25 (Robertson et al., 1998) ; voir équa-
tion 4.
RSV
Okapi
(Q, D)
=
X
t∈Q
qT F (t) ∗ T F (t, D) ∗ IDF (t)
(4)
1.
Indri est disponible à http://www.lemurproject.org/ .
qT F (t) =
(k
3
+ 1) ∗ qtf
k
3
+ qtf
T F (t, D) =
tf ∗ (k
1
+ 1)
tf + k
1
∗ (1 − b + b ∗
dl(D)
dl
avg
)
IDF (t) = log
n − df (t) + 0.5
df (t) + 0.5
avec
dl
avg
la taille moyenne des documents,
n
le nombre de documents dans la col-
lection, et
df (t)
le nombre de documents contenant
t
. Les paramètres
k
1
,
k
3
et
b
sont
des constantes, avec des valeurs par défaut
k
1
= 2
,
k
3
= 1000
et
b = 0, 75
.
Nous proposons une version dite ajustée de la similarité Okapi-BM25,
dans la-
quelle l’influence de la taille du document
est
renforcée,
en prenant
b = 1
,
et
en
mettant l’IDF au carré pour donner plus d’importance aux mots de contexte plus dis-
criminants. Nous appliquons également cette stratégie pour obtenir une version ajustée
du TF-IDF/cosinus en prenant l’IDF au carré.
Ces modèles de RI, très classiques, ne sont pas détaillés plus avant ici ; le lecteur
intéressé trouvera les notions et détails utiles dans les références citées ou des ouvrages
généralistes (Manning et al., 2008 ; Boughanem, Savoy, 2008, par exemple).
À des fins de comparaison, nous rapportons les résultats obtenus dans les mêmes
conditions expérimentales avec une approche état de l’art notée base exploitant une
similarité cosinus avec une pondération par information mutuelle (Ferret, 2013), une
version avec apprentissage (rerank) pour réordonnancer les voisins (Ferret, 2013), et
une version (synt) reposant non plus sur des contextes graphiques, mais syntaxiques
(Ferret, 2014).
On observe tout
d’abord la difficulté de la tâche puisque dans tous les cas,
les
précisions relevées sont très faibles selon cette évaluation intrinsèque. La comparai-
son avec les lexiques de référence conduit donc à une conclusion très sévère quant à
la qualité supposée des thésaurus produits.
On note tout de même que certains mo-
dèles de RI fonctionnent particulièrement bien par rapport à l’état de l’art, comme les
modèles basés sur Okapi, ou les modèles de langues.
3.3.
Test des modèles de réduction de dimension et d’embedding
Les plongements de mots (word embedding) dans des espaces vectoriels ont connu
un regain d’activité ces dernières années avec l’avènement de nouveaux modèles neu-
ronaux.
Parmi
les différentes approches proposées,
les travaux de (Mikolov et
al.,
2013) reposant sur le concept de skip-gram pour représenter le contexte font référence.
Ces travaux ont donné naissance à
WORD
2
VEC
, un outil permettant de représenter les
mots comme des vecteurs denses dans un espace de faible dimension (typiquement
R
200
). Nous rapportons dans le tableau 2 le résultat de tels modèles (notés W2V) sur
notre tâche dans les mêmes conditions expérimentales que précédemment, avec diffé-
rents paramètres (nombre de dimension et taille de la fenêtre de contexte considérée).
Thésaurus distributionnels et RI
Nous indiquons également le résultat d’un modèle fourni par Google
2
appris sur un
corpus d’actualités (Google News) de 100 milliards de mots. Même si ce corpus est
différent, la comparaison est néanmoins intéressante, puisqu’il s’agit d’un modèle uti-
lisé directement dans de nombreuses applications,
entraîné sur un corpus de même
genre mais de taille bien plus conséquente.
Nous testons également des techniques de réduction de dimensions plus classiques,
à savoir Latent Semantic Indexing (LSI) (Deerwester et al., 1990), Latent Dirichlet Al-
location (LDA) (Hoffman et al., 2010) et Random Projections (RP) (Bingham, Man-
nila, 2001), avec différents nombres de dimensions. Toutes ces approches (W2V, LSI,
LDA, RP) sont implémentées en utilisant la bibliothèque Python GenSim
3
(
ˇ
Reh˚
u
ˇ
rek,
Sojka, 2010).
Tableau 2. Performances des modèles de RI pour la construction des thésaurus
distributionnels sur la référence WN+Moby
Méthode
MAP
R-Prec
P@1
P@5
P@10
P@50
P@100
Ferret 2013 base
5,6
7,7
22,5
14,1
10,8
5,3
3,8
Ferret 2013 best rerank
6,1
8,4
24,8
15,4
11,7
5,7
3,8
Ferret 2014 synt
7,9
10,7
29,4
18,9
14,6
7,3
5,2
LSI dim=50
1,62
2,86
5,00
4,12
3,76
2,78
2,35
LSI dim=500
4,37
6,27
16,00
10,76
8,78
4,61
3,45
LSI dim=1000
5,06
6,87
21,09
13,20
9,96
5,39
4,02
LSI dim=2000
5,11
6,86
23,11
14,34
10,78
5,12
3,72
LDA dim=500
0,60
1,25
2,17
2,21
1,90
1,29
1,13
RP dim=500
5,66
6,48
27,3
12,85
8,67
3,04
1,86
RP dim=2000
5,90
7,04
27,13
13,71
8,94
3,21
1,96
W2V dim=50 w=5
2,89
3,89
13,48
7,36
5,44
2,58
1,82
W2V dim=100 w=5
3,65
4,84
18,49
9,62
7,04
3,16
2,17
W2V dim=200 w=5
3,92
5,44
22,18
11,39
8,32
3,61
2,59
W2V dim=300 w=5
5,25
6,25
18,67
10,72
7,73
3,49
2,38
W2V dim=400 w=5
5,06
6,43
20,37
11,44
8,29
3,66
2,50
W2V dim=50 w=9
3,12
4,11
13,11
7,80
5,68
2,59
1,87
W2V dim=100 w=9
4,14
5,55
17,18
9,25
6,79
3,21
2,21
W2V dim=200 w=9
4,42
5,60
17,69
10,71
7,47
3,40
2,32
W2V dim=300 w=9
4,07
5,53
20,50
11,13
8,02
3,62
2,52
W2V dim=400 w=9
4,39
5,51
17,81
9,95
7,43
3,24
2,21
W2V Google news
5,82
7,51
13,28
11,60
8,94
3,93
2,54
Les résultats obtenus pour l’ensemble de ces méthodes apparaissent comme faibles
au regard de ceux vus en sous-section précédente.
Les modèles W2V,
très utilisés,
sont notamment inférieurs à l’état de l’art et même à certaines méthodes de réduction
classiques (LSI).
Une piste d’explication pourrait être la difficulté de la tâche d’ap-
prentissage rapportée aux nombre de mots,
comme le suggèrent
les résultats W2V
légèrement meilleurs obtenus avec le corpus Google News, qui est 250 fois plus gros
2.
Ce modèle est disponible à l’URL suivante : https://code.google.com/p/word2vec/ .
3.
GenSim est disponible à https://radimrehurek.com/gensim/ .
qu’AQUAINT-2. Il faut cependant noter que même avec cette quantité de mots, les ré-
sultats obtenus sont à peine du niveau de l’état de l’art et restent largement inférieurs
aux modèles RI vus précédemment.
Les autres techniques de réduction de dimension donnent
des résultats d’autant
plus limités que le nombre de dimensions considérées est petit. Ce résultat faible est
en ligne avec certaines conclusions de travaux précédents (Van de Cruys, 2010). Le
fait d’agréger en une seule dimension des mots différents est donc préjudiciable pour
bien distinguer les voisins sémantiques. Autrement dit, l’apparition de certains mots
de contexte bien précis est un indicateur fort pour juger de la proximité sémantique des
mots. Cela est d’ailleurs confirmé par le fait qu’au sein d’une même famille de modèle
de RI (sous-section précédente), les paramétrages menant aux meilleurs résultats sont
ceux qui donnent plus de poids aux mots discriminants : IDF au carré pour Okapi,
faible lissage pour les modèles de langue (
µ
et
λ
relativement petits).
3.4.
Analyse par fréquence
Certains auteurs ont remarqué que la fréquence des mots dont on essaie de trouver
les voisins a une grande influence sur la qualité finale (Ferret, 2013). Plus ils sont fré-
quents, plus on a de contextes pour les décrire et meilleurs sont les résultats avec les
méthodes « état de l’art ». On se propose donc de vérifier si l’emploi de méthodes is-
sues de la RI amène la même observation. Pour cela, on reprend le cadre expérimental
précédent et le modèle Okapi ajusté, mais on distingue les résultats selon la fréquence
des mots-entrées : les mots ayant les plus hautes fréquences (>1000),
ceux avec les
fréquence les plus basses (<100) et le tiers restant avec des fréquences moyennes. Ces
résultats sont présentés dans les figures 2 à 4. Là encore, nous indiquons les résultats
état de l’art de (Ferret, 2013) pour comparaison.
Figure 2. Performances pour la construction des thésaurus distributionnels sur la
référence WN+Moby pour les mots de fréquence élevée (> 1 000)
Thésaurus distributionnels et RI
Figure 3. Performances pour la construction des thésaurus distributionnels sur la
référence WN+Moby pour les mots de fréquence moyenne (< 1 000 et > 100)
Figure 4. Performances pour la construction des thésaurus distributionnels sur la
référence WN+Moby pour les mots de fréquence faible (< 100)
Il
apparaît
que l’approche par RI a un comportement
bien plus stable selon les
fréquences que le système état de l’art de (Ferret,
2013).
En particulier,
l’approche
RI assure des résultats de bonne qualité pour les mots faiblement fréquents.
La fré-
quence des mots étant directement liée à la taille des ensembles de contextes,
cela
indique l’importance de la normalisation en fonction de la taille des documents dans
l’approche RI.
3.5.
Limites de l’analogie avec la RI
L’analogie entre recherche de document similaire et recherche de voisins distribu-
tionnels apporte de très bons résultats, mais il convient cependant de pointer certaines
limites de cette analogie.
En effet,
les ensembles de contextes,
qui
sont
considérés
comme des documents,
ont
des propriétés sensiblement
différentes des documents
réels. Pour illustrer cela, nous produisons respectivement en figures 5 et 6 la distribu-
tion des tailles de documents standard (ce sont ceux du corpus AQUAINT-2, c’est-à-
dire des articles de journaux) et de celles des ensembles de contextes. On y observe un
éventail de taille beaucoup plus important dans le cas des ensembles de contextes. Il
semble donc important dans les fonctions de similarités utilisées de prendre en compte
ce besoin de normalisation accrue selon la longueur des documents.
Figure 5. Distribution des tailles des documents dans le cadre standard ; échelle log.
Figure 6. Distribution des tailles des documents dans le cadre des ensembles de
contextes ; échelle log.
La distribution des mots est également assez différente de ce que l’on trouve dans
une vraie collection de documents. Cela est illustré en figures 7 et 8 dans lesquelles on
Thésaurus distributionnels et RI
donne la distribution des fréquences documentaires (DF), en se comparant là encore
avec le corpus AQUAINT-2 original. Les mots apparaissent en général dans beaucoup
plus de contextes que dans le cas de vrais documents. Par exemple, le nombre de mots
apparaissant dans 1 document sur 10 000 (DF=0.0001) est près de 100 fois plus élevé
que pour de vrais documents.
Comme nous l’avions vérifié expérimentalement,
ce
phénomène milite pour une prise en compte spécifique de cette distribution dans les
modèles (à travers les lissages dans les modèles de langue ou l’IDF dans les modèles
vectoriels par exemple, ou à travers de nouveaux schémas de pondérations).
Figure 7. Distribution des fréquences documentaires (DF) dans le cadre standard ;
échelle log.
Figure 8. Distribution des fréquences documentaires (DF) dans le cadre des
ensembles de contextes ; échelle log.
4.
Évaluation dans un cadre de RI
Pour évaluer l’apport des thésaurus distributionnels dans une tâche classique de RI,
nous nous plaçons dans un cadre d’extension de requêtes. Pour chaque nom de la re-
quête, les mots associés dans le thésaurus distributionnel sont ajoutés à celle-ci. Nous
décrivons ci-dessous notre contexte expérimental, puis les résultats obtenus. Nous pro-
posons ensuite de mettre en regard les résultats obtenus par cette évaluation indirecte
avec les résultats de l’évaluation intrinsèque que nous avons utilisée précédemment.
4.1.
Contexte expérimental
La collection de RI que nous utilisons est celle développée pour le projet Tipster et
utilisée dans le cadre de TREC. Elle contient plus de 170 000 documents et cinquante
requêtes. Ces requêtes sont composées de plusieurs champs (la requête à proprement
parler,
un champ narratif détaillant les critères de pertinence) ; dans les expériences
rapportées ci-dessous, nous n’utilisons que le champ requête. Cette collection est par-
ticulièrement
adaptée puisqu’elle est
composée de documents en anglais de même
nature que le corpus AQUAINT-2 (articles du Wall Street Journal) à partir duquel le
thésaurus distributionnel a été construit.
Le système de recherche d’information que nous utilisons est Indri (Metzler, Croft,
2004 ; Strohman et al.,
2005),
connu pour offrir des performances état de l’art.
Ce
système probabiliste implémente une combinaison de modèle de langue (Ponte, Croft,
1998), tel que vu précédemment, et de réseaux d’inférence (Turtle, Croft, 1991) per-
mettant d’utiliser des opérateurs tels que ET OU...
Dans les expériences rapportées
ci-dessous,
nous l’utilisons avec des réglages standard,
à savoir un lissage de Diri-
chlet (
µ = 2500
). Dans notre cas, ce système de RI offre l’avantage de disposer d’un
langage de requête complexe qui nous permet d’inclure les mots du thésaurus distribu-
tionnel en exploitant au mieux le modèle par réseau d’inférence à l’aide de l’opérateur
dédié ’
#syn
’ qui permet d’agréger les comptes des mots considérés comme syno-
nymes (voir la documentation d’Indri pour plus de détails). Pour supprimer les effets
de flexions (pluriel) sur les résultats,
les formes pluriel et singulier des noms de la
requêtes sont ajoutées, que ce soit dans les requêtes non étendues avec les synonymes
ou celles étendues par les voisins sémantiques.
Les performances pour cette tâche de RI sont également classiquement mesurées
en précision à différents seuils (P@x), R-prec, MAP. L’évaluation du lexique consiste
donc en la comparaison des résultats obtenus avec ou sans extension, que nous me-
surons en gain relatif de précision, de MAP... Nous indiquons également la moyenne
des gains d’AP par requête,
notée AvgGainAP (à ne pas confondre avec le gain de
MAP, qui est le gain calculé sur les moyennes des AP par requête). Les résultats non
statistiquement significatifs (Wilcoxon et t-test avec
p < 0, 05
) sont en italiques.
4.2.
Résultats d’extension
Le tableau 3 présente les gains de performance obtenus en étendant les requêtes
avec les mots collectés dans les thésaurus. Nous choisissons le lexique ayant obtenu les
meilleurs résultats : celui construit avec la méthode Okapi ajustée. Puisque ce lexique
ordonne les voisins par proximité avec le mot-entrée,
on teste différents scénarios :
Thésaurus distributionnels et RI
pour chaque mot (nom) de la requête, s’il apparaît dans le thésaurus, on ne garde que
ses 5,
10 ou 50 plus proches voisins.
Sur les cinquante requêtes,
cela concerne 136
noms. À des fins de comparaison, on indique aussi les résultats obtenus en étendant
avec les lexiques de référence WN seul et WN+Moby. Voici un exemple de requête,
avec sa forme non-étendue et sa forme étendue (Okapi ajusté top 5) utilisant les opé-
rateurs de réseau d’inférence d’Indri :
– requête :
coping with overcrowded prisons
– forme
normale
:
#combine( coping with overcrowded #syn(
prisons prison ) )
– forme
étendue
:
#combine( coping with overcrowded #syn(
prisons prison inmate inmates jail jails detention detentions
prisoner prisoners detainee detainees ) )
Tableau 3. Gains relatifs de performance (%) par extension de requête
selon le lexique utilisé
Extension
MAP
Avg
R-Prec
P@5
P@10
P@50
P@100
GainAP
Sans
21,78
-
30,93
92,80
89,40
79,60
70,48
avec WN
+12,44
+36,3
+7,01
+4,31
+7,16
+7,60
+10,87
avec WN+M
+11,00
+28,33
+7,78
+3,02
+5,37
+6,53
+9,17
avec Okapi-BM25 ajusté top 5
+13,14
+29,99
+11,17
+3,45
+5,15
+9,40
+12,43
avec Okapi-BM25 ajusté top 10
+13,80
+24,36
+9,58
+2,16
+4,03
+5,58
+8,26
avec Okapi-BM25 ajusté top 50
+10,02
+17,99
+8,82
+3,45
+3,36
+3,72
+5,36
On note tout d’abord que quel que soit le lexique utilisé,
l’extension de requête
apporte un gain significatif de performance. Comme beaucoup de travaux depuis, cela
contredit
au passage les conclusions de (Voorhees,
1994) sur l’absence d’intérêt
à
utiliser WN pour étendre des requêtes.
Le fait le plus notable est cependant les ex-
cellentes performances (MAP) du lexique construit automatiquement, qui dépassent
même celles des lexiques de référence.
Alors que sa précision sur les 10 premiers
voisins a été évaluée à moins de 14 % en section 3, ce lexique produit des extensions
obtenant le meilleur gain en MAP. La moyenne des gains d’AP (AvgGainAP) apporte
également des informations intéressantes : celle-ci est maximale avec WN, qui offre
donc une amélioration stable (c’est-à-dire une amélioration concernant beaucoup de
requêtes) grâce au fait qu’il ajoute à la requête principalement des voisins très proches
sémantiquement (synonymes exacts), sans « prise de risque ». Cette stabilité diminue
avec les autres lexiques, et est la plus basse avec les extensions par les 50 plus proches
voisins du lexique généré par le modèle Okapi ajusté. Comme la MAP reste globale-
ment bonne, cela indique que seules certaines requêtes bénéficient d’un gain absolu
important.
5.
Évaluation intrinsèque vs. évaluation extrinsèque
Les résultats de l’expérience précédente soulèvent des questions sur la cohérence
entre les résultats de l’évaluation intrinsèque et ceux de l’évaluation extrinsèque. Le
gain de précision entre deux méthodes de construction de thésaurus, même s’il est jugé
statistiquement significatif, est-il sensible en RI ? Dans cette section, nous tentons de
répondre à cette question en examinant les différences entre évaluation intrinsèque et
extrinsèque au travers de quelques expériences complémentaires.
5.1.
Mise en regard des précisions intrinsèque et extrinsèque
Pour cela on complète les résultats précédents avec la figure 9 qui
rapporte les
résultats de différents modèles de RI sur la tâche d’extension (avec les 10 premiers
voisins) selon leur P@10 de l’évaluation directe. Il en ressort que la précision mesu-
Figure 9. Gain en MAP et AvgGainAP de différents modèles selon leur précision
@10 lors de l’évaluation intrinsèque
rée avec l’évaluation directe est liée aux gains mesurés dans la mesure où l’ordre est
bien respecté : la meilleure P@10 à l’évaluation directe obtient le meilleur gain de
MAP à la tâche de RI, etc. Mais la corrélation n’est pas linéaire comme on pourrait
s’y attendre. En outre, des différences statistiquement significatives lors de l’évalua-
tion directe (comme entre TF-IDF ajusté et Okapi ajusté) ne se traduisent pas forcé-
ment par des différences statistiquement significatives à la tâche d’extension.
Parmi
les faux positifs de l’évaluation directe (mots détectés comme proches mais absents
dans les lexiques de référence), certains semblent plus ou moins néfastes pour étendre
les requêtes.
5.2.
Faux positifs et bonnes extensions
Il est alors intéressant d’examiner plus précisément l’effet de ces faux positifs. On
examine de nouveau l’évolution des performances sur la tâche de RI en fonction de
la qualité des listes de voisins utilisées pour étendre les requêtes,
mais cette fois-ci,
des listes de voisins plus ou moins bruitées sont générées à partir des thésaurus de
Thésaurus distributionnels et RI
référence en remplaçant des voisins par des mots choisis aléatoirement dans le vo-
cabulaire. On peut ainsi produire des listes de voisins avec une précision variable et
contrôlée,
dont on évalue les performances pour étendre les requêtes comme précé-
demment. La figure 10 montre l’évolution de la MAP et de l’AvgGainAP en faisant
varier ainsi la précision des listes de voisins données par les références WN seul et
WN+Moby. Une précision du thésaurus de 20 % signifie donc que chaque requête est
étendue avec la liste de ses voisins fournie par WN seul ou WN+Moby, dans laquelle
20 % des vrais voisins sont
remplacés aléatoirement par d’autres mots.
On indique
pour comparaison les scores obtenus avec les top 5, 10 et 50 du lexique Okapi ajusté.
Figure 10. Gain en MAP (gauche) et AvgGainAP (droite) selon la précision
contrôlée artificiellement des thésaurus utilisés pour étendre les requêtes
Comme attendu, les deux mesures de performance chutent lorsque la précision des
listes diminue. Il faut une précision controlée (intrinsèque) des listes inférieure à 50 %
pour rendre les gains de performance nuls sur la tâche de RI, et en deçà, les extensions
de requête dégradent les résultats. Il y a donc bien une corrélation entre la précision
des listes mesurée par évaluation directe et les performances pour l’extension de re-
quête,
du moins lorsque que les faux positifs sont pris au hasard.
Mais dans le cas
du lexique que nous avons généré, les performances obtenues sont comparables à des
listes de précision intrinsèque entre 70 et 100 % selon les cas, alors que la précision
mesurée par évaluation intrinsèque variait entre 10 et 20 %.
Plus que la sévérité de
l’évaluation intrinsèque, cela souligne la faiblesse de la démarche qui repose sur des
références incomplètes : certains voisins, jugés comme faux positifs car non listés par
les références sont en réalité de bons candidats.
Pour illustrer ce dernier point, nous rapportons dans le tableau 4 les performances
obtenues par le lexique Okapi ajusté en étendant de nouveau les requêtes avec les 10
premiers voisins de chaque nom, mais en excluant ceux qui sont listés comme voisins
dans WN ou WN+Moby. Autrement dit, on ne garde que les voisins jugés comme faux
positifs par l’évaluation intrinsèque. Il apparaît clairement que ces faux positifs sont
bien liés sémantiquement à l’entrée.
Pour le mot
prison
de la requête précédente,
parmi les 10 premiers voisins, ceux absents de WN+Moby sont :
sentence, abuse,
detainee, guard, custody, defendant, inmate, prisoner
.
Ils semblent
effectivement bien liés sémantiquement à prison.
Tableau 4. Gains relatifs de performance (%) par extension de requête
avec les voisins jugés faux positifs
Extension avec
MAP
Avg
R-Prec
P@5
P@10
P@50
P@100
Okapi-BM25 ajusté
GainAP
top 10 sauf WN
+11,80
+21,60
+8,37
+2,16
+3,58
+5,08
+6,87
top 10 sauf WN+M
+9,36
+19,22
+6,41
+3,02
+3,36
+3,17
+5,73
6.
Conclusion
Dans cet article, nous avons exploré l’utilisation de la recherche d’information à la
fois pour construire et pour évaluer des thésaurus distributionnels. Nous avons d’une
part utilisé les modèles de similarités développés en RI sur les contextes des mots,
ce qui
nous permet,
pour un mot
donné,
de trouver ceux partageant
une similarité
contextuelle, et donc sémantique. D’autre part, la recherche d’information, à travers la
tâche classique de recherche de documents par requête, nous offre un cadre applicatif
permettant une évaluation indirecte des thésaurus.
De ces travaux, deux conclusions majeures se dégagent. En étendant nos travaux
précédents (Claveau et al.,
2014),
nous avons confirmé le bien-fondé de l’approche
RI pour la construction des thésaurus sémantiques. Nous avons en particulier montré
l’importance de la prise en compte des mots discriminants dans différents modèles
(au travers de pondérations spécifiques pour l’IDF ou par le lissage). Nous avons éga-
lement souligné l’avantage des modèles RI par rapport aux méthodes classiques en
particulier sur les mots avec peu d’occurrences,
mais aussi sur les modèles de type
WORD
2
VEC
qui font actuellement l’objet de beaucoup de travaux. Mais nous avons
également souligné les limites de l’analogie entre RI et sémantique distributionnelle :
les ensembles de contextes ont des propriétés statistiques (taille,
fréquence d’appa-
rition des mots...) très différentes de « vrais » documents. Cela milite pour l’établis-
sement de fonctions de pondération et de pertinence adaptées à cette réalité et ouvre
donc des voies d’amélioration possibles. D’autres perspectives sur ce point concernent
l’utilisation de techniques récentes de RI pour la construction des thésaurus (learning
to rank, représentations continues...).
L’autre conclusion majeure de cet article porte sur la fiabilité de l’évaluation intrin-
sèque. En montrant que les thésaurus obtenus offrent des résultats au moins aussi bons
que les listes de référence servant à l’évaluation intrinsèque, nous remettons en pers-
pective beaucoup de conclusions de travaux précédents. Les faibles résultats obtenus
aux évaluations intrinsèques ne se traduisent pas dans ce cadre applicatif d’extension
de requête. Il convient bien sûr de nuancer cette conclusion, qui ne porte que sur le
cadre applicatif testé : la tâche et la mise en œuvre que nous utilisons (avec les opéra-
teurs de croyances d’Indri) permet d’avoir des liens sémantiques relativement distants
dans les listes de voisins servant d’extensions sans que cela ne dégrade trop les ré-
sultats. D’autres tâches, comme la substitution lexicale, plus centrée sur la synonymie
exacte, pourraient donner d’autres résultats. Une perspective intéressante serait ainsi
de mesurer la corrélation entre les scores d’évaluation intrinsèque et extrinsèque dans
Thésaurus distributionnels et RI
différentes tâches pour mieux aider à choisir les méthodes de construction les plus
adaptées selon la tâche finale visée.
Bibliographie
Adam C.,
Fabre C.,
Muller P.
(2013).
Évaluer et améliorer une ressource distributionnelle :
protocole d’annotation de liens sémantiques en contexte.
TAL, vol. 54, n
o
1, p. 71-97.
Baroni M., Lenci A. (2011). How we BLESSed distributional semantic evaluation. In Workshop
on geometrical models of natural language semantics, p. 1-10.
Besançon R., Rajman M., Chappelier J.-C. (1999). Textual similarities based on a distributional
approach.
In in proceedings of the tenth international workshop on database and expert
systems applications (dexa’99), p. 180–184.
Billhardt H.,
Borrajo D.,
Maojo V.
(2002,
février).
A context vector model for information
retrieval.
J.
Am.
Soc.
Inf.
Sci.
Technol.,
vol.
53,
n
o
3,
p.
236–249.
Consulté sur http://
dx.doi.org/10.1002/asi.10032
Bingham E., Mannila H.
(2001).
Random projection in dimensionality reduction: Applications
to image and text
data.
In Proceedings of
the seventh acm sigkdd international
confe-
rence on knowledge discovery and data mining, p. 245–250.
New York, NY, USA, ACM.
Consulté sur http://doi.acm.org/10.1145/502512.502546
Bollegala D., Matsuo Y., Ishizuka M.
(2007).
Measuring semantic similarity between words
using web search engines.
In Proceedings of www’2007.
Boughanem M., Savoy J. (Eds.).
(2008).
Recherche d’information : états des lieux et perspec-
tives. Hermès Science.
Consulté sur http://www.editions-hermes.fr/
Broda B., Piasecki M., Szpakowicz S.
(2009).
Rank-Based Transformation in Measuring Se-
mantic Relatedness.
In 22
nd
canadian conference on artificial intelligence, p. 187-190.
Budanitsky A.,
Hirst
G.
(2006).
Evaluating WordNet-based measures of lexical
semantic
relatedness.
Computational Linguistics, vol. 32, n
o
1, p. 13-47.
Claveau V., Kijak E., Ferret O.
(2014, août).
Improving distributional thesauri by exploring the
graph of neighbors.
In International Conference on Computational Linguistics, COLING
2014.
Dublin, Irlande.
Consulté sur https://hal.archives-ouvertes.fr/hal-01027545
Deerwester S., Dumais S. T., Furnas G. W., Landauer T. K., Harshman R.
(1990).
Indexing by
latent semantic analysis.
Journal of the American Society for Information Science.
Domengès D., Volle M.
(1979).
Analyse factorielle sphérique : une exploration.
Annales de
l’INSEE, vol. 35, p. 3–83.
Escoffier B.
(1978).
Analyse factorielle et distances répondant au principe d’équivalence dis-
tributionnelle.
Revue de statistique appliquée, vol. 26, n
o
4, p. 29–37.
Ferret O.
(2013).
Identifying bad semantic neighbors for improving distributional thesauri.
In
51
st
annual meeting of the association for computational linguistics (acl 2013), p. 561–571.
Sofia, Bulgaria.
Ferret O. (2014). Typing relations in distributional thesauri. In N. Gala, R. Rapp, G. Bel (Eds.),
Advances in language production, cognition and the lexicon. Springer.
Firth J. R.
(1957).
Studies in linguistic analysis.
In, p. 1–32.
Oxford, Blackwell.
Gabrilovich E., Markovitch S.
(2007).
Computing semantic relatedness using wikipedia-based
explicit semantic analysis.
In 20
th
international joint conference on artificial intelligence
(ijcai 2007), p. 6–12.
Grefenstette G.
(1994).
Explorations in automatic thesaurus discovery.
Kluwer Academic
Publishers.
Hagiwara M.,
Ogawa Y.,
Toyama K.
(2006).
Selection of effective contextual
information
for automatic synonym acquisition.
In 21
st
international
conference on computational
linguistics and 44
th
annual meeting of the association for computational linguistics (coling-
acl 2006), p. 353–360.
Sydney, Australia.
Hoffman M., Bach F. R., Blei D. M.
(2010).
Online learning for latent dirichlet allocation.
In
J. Lafferty, C. Williams, J. Shawe-Taylor, R. Zemel, A. Culotta (Eds.), Advances in neural
information processing systems 23, p. 856–864. Curran Associates, Inc. Consulté sur http://
papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation.pdf
Huang E. H., Socher R., Manning C. D., Ng A. Y.
(2012).
Improving word representations via
global context and multiple word prototypes.
In 50th annual meeting of the association for
computational linguistics (acl’12), p. 873–882.
Landauer T., Dumais S.
(1997).
A solution to plato’s problem: The latent semantic analysis
theory of acquisition, induction, and representation of knowledge.
Psychological Review,
vol. 104, n
o
2, p. 211-240.
Landauer T.
K.,
Dumais S.
T.
(1997).
A solution to Plato’s problem:
the latent
semantic
analysis theory of acquisition, induction, and representation of knowledge.
Psychological
review, vol. 104, n
o
2, p. 211-240.
Lin D.
(1998).
Automatic retrieval
and clustering of similar words.
In 17
th
international
conference on computational
linguistics and 36
th
annual
meeting of
the association for
computational linguistics (acl-coling’98), p. 768–774.
Montréal, Canada.
Manning C. D., Raghavan P., Schütze H.
(2008).
Introduction to information retrieval. Cam-
bridge University Press.
McCarthy D., Navigli R.
(2009).
The english lexical substitution task.
Language Resources
and Evaluation, vol. 43, n
o
2, p. 139-159.
Metzler D., Croft W. (2004). Combining the language model and inference network approaches
to retrieval.
Information Processing and Management Special Issue on Bayesian Networks
and Information Retrieval, vol. 40, n
o
5, p. 735-750.
Mikolov T.,
Yih W.-t.,
Zweig G.
(2013).
Linguistic regularities in continuous space word
representations.
In 2013 conference of the north american chapter of the association for
computational linguistics: Human language technologies (naacl hlt 2013), p. 746–751.
At-
lanta, Georgia.
Miller G. A.
(1990).
WordNet: An On-Line Lexical Database.
International Journal of Lexi-
cography, vol. 3, n
o
4.
Padó S., Lapata M.
(2007).
Dependency-based construction of semantic space models.
Com-
putational Linguistics, vol. 33, n
o
2, p. 161–199.
Thésaurus distributionnels et RI
Ponte J. M., Croft W. B.
(1998).
A language modeling approach to information retrieval.
In
Proceedings of the 21st annual international acm sigir conference on research and deve-
lopment in information retrieval (sigir ’98), p. 275-281.
ˇ
Reh˚
u
ˇ
rek R., Sojka P. (2010, 22 mai). Software Framework for Topic Modelling with Large Cor-
pora. In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,
p. 45–50.
Valletta, Malta, ELRA.
(http://is.muni.cz/publication/884893/en)
Robertson S. E., Walker S., Hancock-Beaulieu M.
(1998).
Okapi at TREC-7: Automatic Ad
Hoc,
Filtering,
VLC and Interactive.
In Proc.
of the 7
th
text retrieval conference,
trec-7,
p. 199-210.
Ruiz-Casado M., Alfonseca E., Castells P.
(2005).
Using context-window overlapping in syno-
nym discovery and ontology extension.
In Proceedings of ranlp-2005.
Borovets, Bulgarie.
Sahami M., Heilman T.
(2006).
A web-based kernel function for measuring the similarity of
short text snippets.
In Proceedings of www’2006.
Sahlgren M.
(2001).
Vector-based semantic analysis: Representing word meanings based on
random labels.
In Esslli 2001 workshop on semantic knowledge acquisition and categori-
sation.
Helsinki, Finland.
Strohman T., Metzler D., Turtle H., Croft W.
(2005).
Indri: A language-model based search
engine for complex queries (extended version). Rapport technique. CIIR.
Turney P.
(2001).
Mining the web for synonyms: Pmiir versus lsa on toefl.
Lecture Notes in
Computer Science, vol. 2167, p. 491–502.
Turney P., Pantel P.
(2010).
From frequency to meaning : Vector space models of semantics.
Journal of Artificial Intelligence Research, vol. 37, n
o
1, p. 141-188.
Turtle H., Croft W.
(1991).
Evaluation of an inference network-based retrieval model.
ACM
Transactions on Information System, vol. 9, n
o
3, p. 187-222.
Van de Cruys T.
(2010).
Mining for Meaning. The Extraction of Lexico-semantic Knowledge
from Text.
Thèse de doctorat non publiée, University of Groningen, The Netherlands.
Van de Cruys T., Poibeau T., Korhonen A.
(2011).
Latent vector weighting for word meaning
in context.
In A.
for Computational Linguistics (Ed.),
Proceedings of the conference on
empirical methods in natural language processing, p. 1012-1022.
Vechtomova O., Robertson S. E.
(2012).
A domain-independent approach to finding related
entities.
Information Processing and Management, vol. 48, n
o
4, p. 654–670.
Voorhees E. M. (1994). Query expansion using lexical-semantic relations. In Proceedings of the
17th annual international acm sigir conference on research and development in information
retrieval,
p.
61–69.
New York,
NY,
USA,
Springer-Verlag New York,
Inc.
Consulté sur
http://dl.acm.org/citation.cfm?id=188490.188508
Ward G.
(1996).
Moby thesaurus.
Moby Project.
Yamamoto K., Asakura T. (2010). Even unassociated features can improve lexical distributional
similarity.
In Second workshop on nlp challenges in the information explosion era (nlpix
2010), p. 32–39.
Beijing, China.
Zhitomirsky-Geffet M., Dagan I.
(2009).
Bootstrapping Distributional Feature Vector Quality.
Computational Linguistics, vol. 35, n
o
3, p. 435–461.
