EmTaggeR: A Word Embedding Based Novel
Method for Hashtag Recommendation on Twitter
Kuntal Dey
∗†
,
Ritvik Shrivastava
‡
,
Saroj Kaushik
†
and L Venkata Subramaniam
†
∗
IBM Research India,
New Delhi,
India.
Email:
{
kuntadey,lvsubram
}
@in.ibm.com
†
Indian Institute of Technology,
New Delhi,
India.
Email
{
anz138579,saroj
}
@cse.iitd.ac.in
‡
Netaji Subhas Institute of Technology,
New Delhi,
India.
Email: ritviks.it@nsit.net.in
Abstract—The
hashtag recommendation problem addresses
recommending (suggesting)
one or more hashtags to explicitly
tag a post made on a given social network platform,
based upon
the content
and context
of
the post.
In this work,
we propose
a novel methodology for hashtag recommendation for microblog
posts,
specifically Twitter.
The methodology,
EmTaggeR,
is built
upon a training-testing framework that builds on the top of the
concept
of
word embedding.
The training phase comprises
of
learning word vectors associated with each hashtag, and deriving
a word embedding for each hashtag.
We provide two training
procedures, one in which each hashtag is trained with a separate
word embedding model applicable in the context of that hashtag,
and another in which each hashtag obtains its embedding from
a global context. The testing phase constitutes computing the av-
erage word embedding of the test post, and finding the similarity
of this embedding with the known embeddings of the hashtags.
The tweets that contain the most-similar hashtag are extracted,
and all
the hashtags that appear in these tweets are ranked in
terms of embedding similarity scores.
The top-
K
hashtags that
appear in this ranked list,
are recommended for the given test
post.
Our system produces F1 score of 50.83%,
improving over
the LDA baseline by around 6.53 times,
outperforming the best-
performing system known in the literature that provides a lift of
6.42 times.
EmTaggeR is a fast,
scalable and lightweight system,
which makes it practical
to deploy in real-life applications.
I.
I
NTRODUCTION
A.
Background and Motivation
The hashtag recommendation problem addresses
recom-
mending (suggesting) one or more hashtags to explicitly tag
a post
made on a given social
network platform,
based upon
the content
and context
of the post.
Practically,
the hashtags
that
users
tend to assign to a given social
network post,
depend upon their
perception of
one or
more key facets of
the message content.
A large number of social posts,
such as
tweets,
do not
contain hashtags,
as observed by Hong et
al.
[11]. And yet, hashtags provide significant value addition, and
act
as one of
the fundamental
information facets associated
with user-generated social network messages.
As noted in the
literature,
problems such as topic modeling [1],
information
diffusion [21] [20] and many other problems as observed by
the literature survey conducted by Dey et al. [5], can be solved
well
by using the information content
and context
of
usage
of hashtags.
An interesting observation made by [23] is that,
recommending hashtags “aim at
encouraging the user
to (i)
use hashtags at all, (ii) use more appropriate hashtags and (iii)
avoid the usage of synonymous hashtags”. All of these indicate
that the hashtag recommendation problem is important.
The problem of hashtag recommendation has emerged as a
mainstream area of research over time.
Works such as [23],
[7]
and [6]
mark some of
the early research efforts in this
space.
Later,
other
methods emerged,
such as tweet
content
hyperlink based ones [18], Dirichlet-based ones [9] and topic-
based ones [19] [24].
Deep learning based works also started
appearing in the literature,
such as the work by Weston et al.
[22]. The recent deep learning based work by Gong and Zhang
[8], with a convolutional neural network (CNN), has produced
the best-konwn results in the literature.
B.
Our Proposition
While Dirichlet based approaches that consider topic mod-
els,
as well
as deep CNN based learning approaches,
exist
in the literature,
we observe that
the textual
context
of
the
words (which in turn constitute the body of the tweets) leave
some scope for
exploration.
Specifically,
word embedding,
a recent
approach that
was proposed by Bengio et
al.
[2],
provides
a dense,
low-dimensional
vector
based approach,
which is
effective in storing contextual
information within
this
low-dimensional
vector.
The
emergence
of
Word2Vec
by Mikolov et
al.
[14]
has enabled the unsupervised word
embedding-based approach to be widely adopted by several
bodies of research, solving different problems. We hypothesize
that
applying word embedding to better
understand (learn)
the context
of
hashtag usage behavior
(with respect
to the
words used along with the hashtag), and using this learning to
recommend hashtags for test tweets, is likely to be an effective
approach.
Although prior works on hashtag recommendation,
namely Weston et
al.
[22]
and Gong and Zhang [8],
use
embedding as part
of
their
overall
solution design,
we use
embedding in a different
and novel
manner
that
integrates
more deeply with the user-generated content,
by deriving the
embeddings of
hashtags using the content
words appearing
with the hashtag.
We propose a model to train for learning word embeddings
and testing (assigning hashtags) with the trained embedding
model, for the task of recommending hashtags towards tweets.
We learn word embeddings from the given traiing data in the
training phase. We develop two different training models in the
current work.
In one model,
we globally train the embedding
for
the words
that
appear
across
the entire vocabulary.
In
the other model,
we create corpus for each specific hashtag,
and learn the embedding of
each word within the scope of
arXiv:1712.01562v1 [cs.CL] 5 Dec 2017
that
hashtag.
We use the skip-gram model
for
training the
embeddings.
In the testing phase, the embeddings are extracted from the
trained model,
for
all
words associated with the test
tweet.
The “embedding” of the test tweet is computed as the average
vector
of
the extracted embeddings.
The similarity of
these
embeddings are compared with the embeddings of the hashtags
learned during the training phase,
and the tweets containing
the best-matching hashtag are extracted. The hashtags of these
tweets are collected, and ranked using the embedding similar-
ity that
was already computed earlier in the testing process.
The top
K
hashtags with the highest
similarity measures are
recommended as the hashtags for
the given test
tweet.
For
the first model,
the word embedding vectors are chosen from
the global
occurrences of
the word.
For
the second model,
the word embedding vectors are chosen from the occurrences
of the word that
are local
with respect
to the hashtag under
consideration for recommendation.
We perform empirical
validation of
our
approach,
using
real-life Twitter data. In absence of any benchmark data in this
space,
we assess the goodness of
our
system,
and compare
it
with the literature,
using performance lift
values over the
well-adopted Latent
Dirichlet
Allocation (LDA) [3] baseline.
Performance lift of a method, captures the ratio of performance
given by that method (such as, our method EmTaggeR) to the
performance given by a baseline method (the LDA baseline,
in this case).
While the state of the art
[8] provides a lift
of
6.42
times over a LDA baseline,
our approach provides a lift
of
6.53
times.
Thus,
our work establishes a new benchmark.
II.
R
ELATED
W
ORK
Hashtag recommendation has been a key research problem
for long.
An early work by Davidov et
al.
[4],
that
focused
around sentiment classification, had touched upon the angle of
hashtags with sentiments.
One of the first works that focused
completely on hashtag prediction, was carried out by Zangerle
et al.
[23].
The work attempts to recommend hashtags by (a)
computing a tf-idf
based content
similarity of a target
tweet
with other
tweets
that
exist
in the database,
(b)
retrieving
the tweets of the most
similar messages and (c) ranking and
recommending the hashtags that
appear within these tweets.
Ding et
al.
[7] [6] propose an unsupervised learning method
using a latent
variable estimation based topical
translation
model.
They model
by treating hashtags and tweet
content
as a parallel occurrence of a target concept.
Sedhai
and Sun [18] recommend hashtags for tweets,
that
contain hyperlinks as part of their content. They propose a two-
phase solution. In the first phase, they select a set of candidate
hashtags
using several
attributes,
such as
consideration of
similar tweets, hyperlinked documents, named entities and the
domain of the content of the webpage that the hyperlink refers
to.
In the second phase,
they formulate as a learning-to-rank
problem,
and solve with RankSVM to aggregate and rank the
candidate hashtags selected in the first phase.
Gong et
al.
[9] proposed a Dirichlet
based mixture model,
incorporating types of hashtags as hidden variables. They pro-
pose their framework as a non-parametric Bayesian method,
and motivated by Liu et al.
[13] they base their model under
the assumption that
hashtags and tweet
content
are parallel
descriptions of the same content.
This is also similar to the
philosophy of [7] and [6].
Works such as [19] and [24] propose topic-based hashtag
recommendation models.
She and Chen [19] perform super-
vised topic model learning using the hashtags as topic labels,
to discover inter-word relationships. They infer the probability
that
a hashtag will
be contained in a new tweet,
by treating
words either as background words (that are prevalent in many
tweets)
or
local
topic words (that
are more specific to that
tweet),
and generate hashtags
for
recommendation using a
symmetric Dirichlet
distribution of the local
and background
words.
Zhang et
al.
[24] extend upon the widely used trans-
lation model for hashtag recommendation in the literature,
to
include the aspects of
temporal
and personal
factors.
They
draw from a multinomial
word-topic distribution and retain
(recommend) the hashtags with the maximum probabilities.
The concept of word embedding was introduced by Bengio
et al.
[2].
The concept was enriched by the work of Mikolov
et
al.
[14],
where they proposed the now-popular Word2Vec
model.
This has enabled the unsupervised word embedding-
based approach to be widely adopted by several bodies of re-
search, solving different problems. The concept of embedding
also acts as the foundation of
the hashtag recommendation
works by Weston et al. [22] and Gong and Zhang [8]. Amongst
other
related approaches,
GloVe [15]
based embedding has
also found research traction.
Deep neural
network based approaches have also emerged
in the literature.
Weston et al.
[22] model a deep CNN based
architecture that
learns semantic embeddings from hashtags.
Their model represents the words, as well as the entire textual
posts,
as embeddings in the intermediate layers of their deep-
CNN architecture.
The philosophy of this work is similar to
ours; however, there are significant differences such as, we use
a per-hashtag word embedding,
as well as,
we use skip-gram
embedding instead of a bag-of-words based one - all of these
factors play a major role in improving our performance.
In a
recent
work that
has established the current
state of the art,
Gong and Zhang [8] proposed the use of a deep CNN with
embedding and attention mapping.
While the recent works that use embedding, tend to perform
other
intelligent
actions
such as
adding the
entire
textual
post
also along with the embedding [22] and local
attention
maps [8],
our approach is different in having hashtag-specific
word embeddings.
These works compute the embeddings of
hashtags
as
a direct
derivation of
the word neighborhoods
of
the hashtags,
as opposed to our
approach where we use
the constituent
words’
embeddings to derive embeddings of
hashtags.
Our
approach adds
context,
by proposing a per-
hashtag word embedding structure
in one
of
the
models,
making it
unique and novel,
and outperforming the state of
the art.
We do not
perform any convolution operation,
and
rely upon the inherent recurrent neural network (RNN) based
contextualization that are used to find embeddings.
III.
O
UR
A
PPROACH
We present the details of our approach in this section. After
initial preprocessing of the input microblog (Twitter) data, we
perform a train-test
based approach.
Overall,
the training is
performed over two phases: (a) learning the embedding of each
word,
and,
(b) learning the embedding of each hashtag,
using
the embedding of
the constituent
words.
The embedding of
each word is learned using two different methods - one from a
global corpus that is constructed as a union of all the available
tweets,
and another from a hashtag-specific usage of words.
Below, we provide an introduction to word embedding, which
is already present
in the literature and is at
the core of our
model.
We subsequently provide the details of our approach.
A.
Data Cleaning and Preprocessing
1)
Data Cleaning:
We first perform data cleaning, in order
to make the provided tweets useful for our work.
•
Non-English tweet
removal:
We
eliminate
the
non-
English tweets from our dataset.
We detect
non-English
tweets using the language marker
meta-data,
that
is an
integral part of the raw Twitter data.
•
Non-ASCII character removal: We eliminate the non-
ASCII content that is present in any of the English tweets
(retained in the earlier step).
•
Removal
of
tweets
without
any hashtag:
Since the
objective of our work,
namely hashtag recommendation,
will
need tweets
that
have
at
least
one
hashtag for
training,
and the
hashtags
recommended for
the
test
tweets will need to be compared with a ground truth (real
hashtags that
were given by the users to those tweets),
it is necessary to retain only those tweets that contain at
least
one hashtag.
Hence,
we eliminate each tweet
that
does not have at least one hashtag associated with it.
2)
Preprocessing:
We perform text
stemming,
tweet
nor-
malization (including noise removal
to an extent),
and stop-
word removal,
as part of the preprocessing phase.
•
Stemming:
We stem the tokens
present
in the tweet
content. Since, hashtags typically do not tend to be char-
acterized by what
stemming eliminates (such as,
tenses,
numbers
etc.),
stemming does
not
lose the necessary
information in the context of hashtag recommendation.
•
Tweet normalization: We perform normalization of the
tweet
content,
by resolving many colloquial
on-the-net
expressions that
appear
on user-generated social
media
text,
but
do not
appear in any traditional
dictionary.
For
instance,
what
appears as aaf
on Twitter,
is expanded
to as a friend.
We use an online net
slang resolution
dictionary
1
,
along with Han-Baldwin dictionary [10],
for
tweet normalization.
•
Stopword removal: We use an online resource from the
Stanford NLP resources for stopword removal
2
.
1
http://www.noslang.com/dictionary
2
https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-
terms-stop-words-1.html
The content
generated as the output
of
preprocessing,
is
sent to the next phase of the system, to learn embeddings. We
propose two different (but similar) models for embedding.
B.
Model 1: Per Hashtag Word Embedding Based
In this model,
we create a per-hashtag word embedding
matrix, where, each word appearing along with a hashtag, has a
different embedding with respect to that hashtag. We derive the
embedding of a hashtag, as the average of all hashtag-specific
embeddings of all
the words appearing for that
hashtag.
The
architecture of the figure is illustrated in Figure 1. The training
process is carried out over the following steps.
1)
Training - Document
Creation:
A document
is created
for each hashtag, by first collecting all the tweets
t
h
where the
given hashtag
h
appears,
and then appending all
the tweets
thus obtained.
Note that,
all
the hashtags and mentions are
eliminated from the document.
Let
H
be the set
of
all
the
hashtags
that
appear
in the overall
dataset.
Thus
for
each
hashtag
h
,
we create a document
1
D
h
as
1
D
h
=
[
{t
h
} − (∀h ∈ H){h}
(1)
2)
Training - Word and Hashtag Embedding Determination:
Next,
a word embedding model is created for each document
(corresponding to a hashtag).
To create this,
each word is
assigned an embedding based upon its usage across only those
tweets that
contain this hashtag,
i.e.,
belong to the document
for
this
hashtag.
We
perform skip-gram based Word2Vec
embedding [14],
and do not use the bag-of-word embeddings
model at all. If
E
denotes the embedding learning operation on
a word from a given document
1
D
h
,
1
v
w,h
is the embedding
vector of a word
w
in the context of hashtag
h
,
s
is the skip
window size of the skip-gram,
c
w
is the minimum occurrence
count of a word in the document
1
D
h
for being considered at
all,
and
l
v
is the dimension of the embedding vector that will
be derived at
the output,
then the embedding of the word in
the hashtag (the corresponding document) is computed as:
1
v
w,h
= E(
1
D
h
, s, c
w
, l
v
)
(2)
Let
W
h
be the set of words appearing in
1
D
h
. The embed-
ding computation operation is repeated for all words
w ∈ W
h
,
to obtain the embedding
1
v
w,h
of all the words
w
that appear
within the hashtag.
Finally,
an embedding
1
V
h
is computed
for each given hashtag as a whole, using the embedding of the
words that appear in the tweets containing the hashtag. This is
simply computed as the average of all
the word embeddings
appearing in its document.
1
V
h
=
P
w∈
1
D
h
(
1
v
w,h
)
|
1
D
h
|
(3)
In the above,
|
1
D
h
|
denotes the total length of the document
1
D
h
in terms
of
number
of
words
(with repeated words
retained).
The above is repeated for all hashtags
h ∈ H
,
thus
creating a complete embedding map, for all the words
w
under
the context of all the hashtags
h
that they appear in. Note that,
words that
are repeated in the document,
are considered as
Fig.
1.
System Architecture Diagram with Model 1
Algorithm 1 E
M
T
AGGE
R: M
ODEL
1 T
RAINING
1:
function EmTaggeRTrainModel1():
2:
for hashtag
h
in
H
do
3:
1
D
0
h
←
Append all tweets where hashtag
h
appears
4:
1
D
h
←
1
D
0
h
− H
(H is the set of all hashtags)
5:
s ←
Skip window size
6:
c
w
←
Min.
required word occurrence count in
1
D
h
7:
l
v
←
Desired Word2Vec length
8:
Embedding of
word
w
in hashtag
h
:
1
v
w,h
←
E(
1
D
h
, s, c
w
, l
v
)
9:
Embedding of hashtag
h
:
1
V
h
←
Average embedding
P
w∈
1
D
h
(
1
v
w,h
)
|
1
D
h
|
of all words
w
10:
end for
11:
Output:
(∀h ∈ H)
1
V
h
many times as they appear;
that
is,
the repeating behavior is
retained,
as this inherently assigns the necessary weight
that
the embedding merits with respect
to how highly each word
is used with respect
to that
hashtag.
The training process for
Model 1 has been summarized in Algorithm 1.
3)
Testing the Model:
The aim of
the testing (hashtag
recommendation)
phase is
to align each test
tweet
to the
best
possible hashtag(s),
and assign the most
highly aligned
hashtag(s)
to the test
tweet.
We compute the alignment
of
each given hashtag to a given test
tweet
as follows.
Given a
test
hashtag
h
,
a set
of words
W
h
associated with hashtag
h
that
have their
embeddings as part
of
1
v
w,h
,
for
each word
w
t
in the test
tweet
t
t
,
we retrieve the embedding of
w
t
in
the word embedding
1
v
w,h
trained for that
hashtag.
That
is,
we retrieve
1
v
w
t
,h
,
an embedding for
word
w
t
trained with
respect to hashtag
h
,
as:
1
v
w
t
,h
=
1
v
w,h
, ∀w
t
∈ W
h
(4)
The embedding of the test
tweet
is derived by computing
the average of all
the word embeddings appearing in the test
tweet,
that are also present in the training vocabulary.
1
V
h
t
=
P
w
t
∈t
t
(
1
v
w
t
,h
)
|
1
v
w
t
,h
|
(5)
We compute the similarity of the hashtag’s embedding with
the test tweet’s embedding within that hashtag,
and select the
hashtag that
have the highest
value.
If
σ(h
t
, h)
denotes the
similarity (such as,
cosine similarity) of the embedding of a
test hashtag
h
t
with that of a given hashtag
h
, then, the hashtag
similarity scores with respect to the test tweet, are obtained as
h
sim
= ∀h
t
∈ Hσ(h,
1
V
h
t
)
(6)
The best-matching hashtag is selected as:
g = ∀h
t
∈ Hmax(h
sim
)
(7)
In one embodiment
of the problem where we recommend
the single-best hashtag, we terminate our testing process here,
and output
g
. However, in another embodiment where we need
to recommend top-
K
hashtags, we perform the following. We
go back to the training tweets, and pick all the training tweets
that
contain the hashtag
g
,
and form a set
union
g
t
of
all
the hashtags that
these hashtags together
contain.
We rank
the hashtags based upon the
h
sim
list,
and pick
G
,
the top-
K
hashtags that
appear also in
g
t
.
G
is the set
of hashtags
provided as the output of Model 1.
The testing process using
Model 1 has been summarized in Algorithm 2.
Fig.
2.
System Architecture Diagram with Model 2
C.
Model 2: Cross Hashtag Word Embedding Model
In this model,
we create a global
word embedding matrix,
where, each word has an embedding agnostic to hashtags. We
derive the embedding of a hashtag, as the average of all global
embeddings of all
the words appearing for that
hashtag.
The
architecture of the figure is illustrated in Figure 2. The training
for this model is performed as follows.
1)
Training -
Document
Creation:
A single global
docu-
ment is constructed by appending all the tweets irrespective of
the hashtags they contain.
In this model
too,
all
the hashtags
and mentions are eliminated from the document.
Let
H
be
the set
of all
the hashtags that
appear in the overall
dataset,
h(∈ H)
be the set of individual hashtags,
and let
t
be the set
of the tweets.
The document
2
D
H
is created as
2
D
H
=
[
{t} − (∀h ∈ H){h}
(8)
Further,
for each hashtag
h
,
we create a document
2
D
h
as
2
D
h
=
[
{t
h
} − (∀h ∈ H){h}
(9)
2)
Training - Word and Hashtag Embedding Determination:
Subsequently,
a word embedding model
is created across all
the hashtags, using the single global document created above.
For this,
each word is assigned an embedding based upon its
usage in the document.
Akin to Model
1,
we perform skip-
gram based Word2Vec embedding [14],
and do not
use the
bag-of-word embeddings model at all, in Model 2 (the current
model) as well. If
E
denotes the embedding learning operation
on a word from a given document
2
D
H
,
2
v
w
is the embedding
vector of a word
w
in the document,
s
is the skip window size
of the skip-gram,
c
w
is the minimum occurrence count
of a
word in the document
2
D
H
for being considered at all, and
l
v
is the dimension of the embedding vector that will be derived
at the output, then the embedding of the word
w
in the hashtag
(the corresponding document) is computed as:
2
v
w
= E(
2
D
H
, s, c
w
, l
v
)
(10)
Let
W
H
be
the
set
of
words
appearing in
2
D
H
.
The
embedding computation is performed for all words
w ∈ W
H
,
to obtain the embedding
2
v
w
of all
the words
w
.
Finally,
an
embedding
2
V
h
is computed for each given hashtag as a whole,
using the embedding of
the words appear
in the content
of
the tweets containing the hashtag,
as the average of
all
the
embeddings of these words.
Then,
the embedding of hashtag
h
is given as:
2
V
h
=
P
w∈
2
D
H
(
2
v
w
)
|
2
D
h
|
(11)
Here,
|
2
D
h
|
denotes the total
length of the document
2
D
h
in terms of number of words (with repeated words retained),
which is the per-hashtag occurrence of the words
w ∈
2
D
h
.
The above is repeated for all
hashtags
h ∈ H
,
thus creating
a complete embedding map,
for
all
the words
w
,
across all
the tweets
(ducoments).
Akin to Model
1,
repeated words
here too are retained, for the same reasons, for computing the
embedding of the hashtags.
The training process for Model 2
has been summarized in Algorithm 3.
3)
Testing the Model:
The testing (hashtag recommenda-
tion) process for Model 2 is similar to that of Model 1, except
that,
the hashtag embeddings are retrieved from the global
embeddings rather than hashtag-specific ones. Here, the testing
is performed as follows.
Given a test hashtag
h
,
a set of words
W
h
associated with
hashtag
h
that have their embeddings as part of
2
v
w
, for each
Algorithm 2 E
M
T
AGGE
R: M
ODEL
1 T
ESTING
1:
function EmTaggeRTestModel1():
2:
MaxAlignedHashtag
← φ
3:
MaxAlignmentScore
← 0
4:
Let
t
t
be a test tweet,
w
t
the words in
t
t
5:
for hashtag
h ∈ H
do
6:
W
h
←
Vocabulary (set
of words) across all
tweets
that contain
h
7:
for
∀w
t
∈ t
t
do
8:
Retrieve embedding
1
v
w
t
,h
for
word
w
t
in
h
:
1
v
w
t
,h
=
1
v
w,h
, (∀w
t
∈ W
h
)
9:
Find average embedding of test
tweet:
1
V
h
t
←
P
w
t
∈t
t
(
1
v
w
t
,h
)
|
1
v
w
t
,h
|
10:
Compute
similarity
of
t
t
and
h
t
:
h
sim
←
σ(h,
1
V
h
t
)
11:
if
h
sim
>
MaxAlignmentScore then
12:
MaxAlignedHashtag
← h
t
13:
MaxAlignmentScore
← h
sim
14:
end if
15:
end for
16:
end for
17:
g ←
MaxAlignedHashtag
18:
if only one hashtag needs to be recommended then
19:
G ← g
20:
else
21:
Pick all training tweets having hashtag
g
22:
Sort (rank)
h
sim
23:
G ←
The top-
K
hashtags as per
h
sim
values that
appear also in
g
t
24:
end if
25:
Output:
(∀h ∈ H)
1
V
h
word
w
t
in the test tweet
t
t
, we retrieve the embedding of
w
t
in the trained word embedding
2
v
w
.
That
is,
we retrieve an
embedding for
w
t
in
h
,
namely
2
v
w
t
,h
,
as:
2
v
w
t
,h
=
2
v
w
, ∀w
t
∈ W
h
(12)
The embedding of the test tweet is derived by computing the
average of all the word embeddings appearing in the test tweet,
that
are also present
in the training vocabulary (and thus has
an embedding trained for it
during the training phase,
using
the single global document).
2
V
h
t
=
P
w
t
∈t
t
(
2
v
w
t
,h
)
|
2
v
w
t
,h
|
(13)
The rest
of
the testing pipeline is precisely the same for
Model
1 and Model
2.
Akin to the testing phase of
Model
1,
for testing Model
2 also we compute the similarity of the
hashtag’s embedding with the test
tweet’s embedding within
that hashtag, and select the hashtag that have the highest value.
If
σ(h
t
, h)
denotes the similarity (such as,
cosine similarity)
of
the embedding of
a test
hashtag
h
t
with that
of
a given
Algorithm 3 E
M
T
AGGE
R: M
ODEL
2 T
RAINING
1:
function EmTaggeRTrainModel2():
2:
2
D
0
H
←
Append all tweets
3:
2
D
H
←
2
D
0
h
− H
(H is the set of all hashtags)
4:
s ←
Skip window size
5:
c
w
←
Min.
required word occurrence count in
2
D
h
6:
l
v
←
Desired Word2Vec length
7:
Embedding of word
w
:
2
v
w
= E(
2
D
H
, s, c
w
, l
v
)
8:
for hashtag
h
in
H
do
9:
2
D
0
h
←
Append all tweets where hashtag
h
appears
10:
2
D
h
←
2
D
0
h
− H
(H is the set of all hashtags)
11:
Embedding of hashtag
h
:
2
V
h
←
Average embedding
P
w∈
2
D
H
(
2
v
w
)
|
2
D
h
|
12:
end for
13:
Output:
(∀h ∈ H)
1
V
h
hashtag
h
,
then,
the hashtag similarity scores with respect
to
the test tweet,
are obtained as
h
sim
= ∀h
t
∈ Hσ(h,
2
V
h
t
)
(14)
The best-matching hashtag is selected as:
g = ∀h
t
∈ Hmax(h
sim
)
(15)
Akin to the other model, in one embodiment of the problem
where we recommend the single-best
hashtag,
we terminate
our testing process here,
and output
g
.
However,
in another
embodiment
where we need to recommend top-
K
hashtags,
we perform the following.
We go back to the training tweets,
and pick all the training tweets that contain the hashtag
g
, and
form a set
union
g
t
of
all
the hashtags that
these hashtags
together contain.
We rank the hashtags based upon the
h
sim
list,
and pick
G
,
the top-
K
hashtags that
also appear in
g
t
.
Akin to Model
1,
G
is the set
of
hashtags provided as the
output
of
Model
2.
The testing process using Model
2 has
been summarized in Algorithm 2.
IV.
E
XPERIMENTS
Tweet Selection Criteria
Count
Total number of tweets
34, 114, 982
Tweets in English
13, 410, 808
English Tweets containing at least one hashtag
2, 417, 163
Hashtag filtering (retain if 200-500 occurrences)
251, 649
Training tweet dataset size
175, 000
Validation tweet dataset size
25, 000
Testing tweet dataset size
51, 649
TABLE I
D
ATA DESCRIPTION
A.
Dataset Description
We collected
10%
of the entire Twitter data that was posted
on
31
st
January
2017
, using DecaHose
3
. Further, as described
in Section III, we retain only the English tweets, containing at
least one hashtag, eliminate non-ASCII characters, and remove
retweets and quoted tweets to retain only tweets with original
3
https://gnip.com/realtime/decahose/
Model
L = 25
L = 50
L = 100
L = 200
L = 400
L = 600
Model 1: At-Least-One Correct (ALOC)
0.4378
0.4395
0.4334
0.4270
0.4199
0.4183
Model 1: Multiple Correct (MuC)
0.3403
0.3411
0.3321
0.3264
0.3228
0.3189
Model 2: At-Least-One Correct (ALOC)
0.5743
0.5829
0.5809
0.5780
0.5700
0.5662
Model 2: Multiple Correct (MuC)
0.4993
0.5083
0.5059
0.5003
0.4958
0.493
TABLE II
F1-
SCORE
(
PERFORMANCE
)
OF THE DIFFERENT MODELS
,
FOR THE DIFFERENT PERFORMANCE MEASUREMENT METRICS USED IN THE PAPER
Algorithm 4 E
M
T
AGGE
R: M
ODEL
2 T
ESTING
1:
function EmTaggeRTestModel2():
2:
MaxAlignedHashtag
← φ
3:
MaxAlignmentScore
← 0
4:
Let
t
t
be a test tweet,
w
t
the words in
t
t
5:
for hashtag
h ∈ H
do
6:
W
h
←
Vocabulary (set
of words) across all
tweets
that contain
h
7:
for
∀w
t
∈ t
t
do
8:
Retrieve embedding
2
v
w
t
,h
for word
w
t
from the
global embedding:
2
v
w
t
,h
=
2
v
w
, (∀w
t
∈ W
h
)
9:
Find average embedding of test
tweet:
2
V
h
t
←
P
w
t
∈t
t
(
2
v
w
t
,h
)
|
2
v
w
t
,h
|
10:
Compute
similarity
of
t
t
and
h
t
:
h
sim
=
∀h
t
∈ Hσ(h,
2
V
h
t
)
11:
if
h
sim
>
MaxAlignmentScore then
12:
MaxAlignedHashtag
← h
t
13:
MaxAlignmentScore
← h
sim
14:
end if
15:
end for
16:
end for
17:
g ←
MaxAlignedHashtag
18:
if only one hashtag needs to be recommended then
19:
G ← g
20:
else
21:
Pick all training tweets having hashtag
g
22:
Sort (rank)
h
sim
23:
G ←
The top-
K
hashtags as per
h
sim
values that
appear also in
g
t
24:
end if
25:
Output:
(∀h ∈ H)
1
V
h
Method
Lift
Naive Bayes
3.27
IBM1 [12]
3.55
EmTaggeR (Model
1,
MuC)
4.38
TopicWA [7]
4.71
EmTaggeR (Model 1,
ALOC)
5.64
TTM [6]
5.87
CNN+Attention-5 [8]
6.42
EmTaggeR (Model
2,
MuC)
6.53
EmTaggeR (Model 2,
ALOC)
7.48
TABLE III
L
IFTS OVER THE
LDA
BASELINE
,
FOR THE DIFFERENT METHODS
content and original hashtags. We also remove the tweets that
comprise of
only hashtags that
are stopwords
4
;
however,
if
other hashtags are also present
in the tweet,
we retain it.
In
order to ensure sufficient data volume while avoiding overtly
4
Appears
in
https://nlp.stanford.edu/IR-book/html/htmledition/dropping-
common-terms-stop-words-1.html if the hash is removed from the tag
common tweets (e.g.,
#coke),
we empirically retain all
the
tweets containing at least one hashtag appearing in the range
of
200
-
500
times in the input
dataset.
We set
aside
70%
of
the data for training,
10%
for validation, and
20%
for the final
testing.
The dataset details are presented in Table I.
B.
Software/Tools Used
We have used the following tools,
for the experiments.
(a)
For stemming, we make use of the widely used Porter’s Snow-
ball Stemmer 2.0 [16]. (b) For tweet parsing and tokenization,
we have used the Python NLTK toolkit
5
.
(c) For embedding
train-test,
we used Gensim [17].
C.
Hyperparameter Tuning
Specifically,
we fix three hyperparameters.
1)
Setting minimum word occurrence frequency:
We in-
clude only the words that
occur more than a threshold
number
of
times in the document,
to avoid including
insignificant
words.
We empirically set
the minimum
frequency threshold as
3
,
and ignore all
the words that
appear less than these many times in the document.
2)
Skip-size:
Since
we
use
the
skip-gram algorithm of
embedding (and do not
use the bag-of-words model
at
all), we need to decide the maximum skip window size.
We empirically choose to keep a window size of
4
, that
is,
we have skip-
4
grams.
3)
Vector
dimensionality determination:
We
observe
by
studying several models that use embedding in the litera-
ture, that, typically Word2Vec embeddings between size
50
-
600
tend to be widely used and most
effective.
We
thus chose to perform our experiments with vector sizes
of
50
,
100
,
200
,
400
and
600
.
Since,
our experiments
obtained the best
results for vector-sizes of
50
,
which
is the lowest
in the range,
we also choose to perform
an additional
round of
experiment
with a vector
size
of
25
,
to avoid missing out
a possibly better result.
As
shown subsequently in Table II, EmTaggeR consistently
performs the best
with vectors of
size
50
across both
the
models
and both the
performance
measurement
frameworks (described below).
D.
Results
We measure performance using two different metrics.
1)
At-Least-One Correct
(ALOC):
In the ALOC model,
we recommend one hashtag for each given test
tweet.
We consider
the recommendation to be successful
if
the ground truth data indicates that
the recommended
5
http://www.nltk.org
hashtag was
indeed a part
of
the tweet
(before the
hashtag was removed for the purpose of testing).
2)
Multiple Correct
(MuC):
In the MuC model,
we sort
the
hashtags
using their
embedding score.
We
then
investigate the number
of
hashtags that
appear
in the
tweet in the ground truth data,
namely
K
,
and pick the
top-
K
hashtags from the sorted list.
Note that,
by the
very nature of
this process of
measurement,
accuracy
and F1-score measures here will be equivalent.
We present the details of our experimental results below.
1)
Performance of The Different Models:
Table II presents
the performance for
the two models
used by our
system,
observed for
both the At-Least-One Correct
as well
as the
Multiple Correct
performance metrics,
effectively producing
four different results.
Three factors here are noteworthy.
•
First,
the performances are consistently better for Model
1 as compared to Model
2,
across both the evaluation
metrics (ALOC and MuC).
•
Second,
the performances
peak at
vector
sizes
50
,
as
observed in our experiments that
covers the range from
25
at the low end to
600
at the high end.
•
Third,
the performances are always higher with ALOC
over MuC.
2)
Establishing an LDA Baseline: In absence of benchmark
datasets
for
comparison,
we
create
a
LDA-based baseline
score.
For
this,
we pick the top
3
LDA-based topics
that
the test
tweet
is
aligned to.
For
each topic,
we pick the
one representative tweet
that
has
the highest
likelihood of
belonging to that
topic (amongst
all
the tweets that
represent
the topic).
We use the
3
training tweets selected over the
3
topics,
to perform hashtag assignment
to the test
topic.
The
LDA baseline yields F1-score of
7.79%
. This baseline is used
subsequently to benchmark the performance of
EmTaggeR
(our system) with respect to the literature.
3)
Comparison with The Literature:
Table III
shows the
performance of
the different
models
under
the EmTaggeR
framework. Since our system yields best-case F1 performances
of
58.29% and 50.83% respectively for
ALOC and MuC
based measurements, the lift we obtain over the LDA baseline
is
58.29/7.79 ≈
7.48 and
50.83/7.79 ≈
6.53 times.
Both
of these are higher than the state-of-the-art,
where the lift
is
6.42 times. Note that, both the performances reported here are
obtained with Model
2.
The performances of Model
1 leave
much to be desired, with ALOC and MuC yielding lifts of 5.64
and 4.38 respectively (F1-score performances of 43.95% and
34.11% respectively),
significantly lesser than the literature.
V.
C
ONCLUSION
In this work, we proposed EmTaggeR, a novel hashtag rec-
ommendation framework for Twitter.
We develop a training-
testing model
centered around the concept
of
embedding.
In the training phase,
we learned word vectors
associated
with each hashtag,
which in turn was used to derive a word
embedding for
each hashtag.
The testing phase constituted
of computing the average word embedding of the given test
post,
and finding the similarity of
this embedding with the
known embeddings of the hashtags.
The tweets that
contain
the
most-similar
hashtag were
extracted.
All
the
hashtags
that
appear
in these tweets were ranked using their
hashtag
embedding score, and the top-
K
hashtags were recommended.
We empirically demonstrated the effectiveness of our system,
by recommending the top-
K
“most
likely” (most
similar)
hashtags for each given tweet, where
K
is user-given number
specifying the number
of
hashtags
that
a given tweet
will
have.
Our
work provides a lift
of
7.48 and 6.53 times for
recommending a single hashtag and multiple hashtags to a
given tweet respectively,
outperforming the literature.
R
EFERENCES
[1]
S.
Asur,
B.
A.
Huberman,
G.
Szabo,
and C.
Wang.
Trends in social
media: Persistence and decay.
In ICWSM,
2011.
[2]
Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin.
A neural probabilis-
tic language model. Journal of machine learning research, 3(Feb):1137–
1155,
2003.
[3]
D.
M.
Blei,
A.
Y.
Ng,
and M.
I.
Jordan.
Latent
dirichlet
allocation.
Journal of machine Learning research,
3(Jan):993–1022,
2003.
[4]
D.
Davidov,
O.
Tsur,
and A.
Rappoport.
Enhanced sentiment
learning
using twitter hashtags and smileys.
In ACL,
pages 241–249,
2010.
[5]
K.
Dey,
S.
Kaushik,
and L.
V.
Subramaniam.
Literature survey on
interplay of
topics,
information diffusion and connections
on social
networks.
arXiv preprint arXiv:1706.00921,
2017.
[6]
Z.
Ding,
X.
Qiu,
Q.
Zhang,
and X.
Huang.
Learning topical translation
model for microblog hashtag suggestion.
In IJCAI,
2013.
[7]
Z.
Ding,
Z.
Zhang,
and X.
Huang.
Automatic hashtag recommendation
for microblogs using topic-specific translation model.
In 24th Interna-
tional Conference on Computational Linguistics,
page 265,
2012.
[8]
Y. Gong and Q. Zhang.
Hashtag recommendation using attention-based
convolutional neural network.
In IJCAI,
pages 2782–2788,
2016.
[9]
Y.
Gong,
Q.
Zhang,
and X.
Huang.
Hashtag recommendation using
dirichlet
process mixture models incorporating types of
hashtags.
In
EMNLP,
pages 401–410,
2015.
[10]
B.
Han and T.
Baldwin.
Lexical
normalisation of short
text
messages:
Makn sens a# twitter.
In ACL-HLT,
Volume 1,
pages 368–378,
2011.
[11]
L. Hong, G. Convertino, and E. H. Chi.
Language matters in twitter: A
large scale study.
In ICWSM,
2011.
[12]
Z.
Liu,
X.
Chen,
and M.
Sun.
A simple word trigger method for social
tag suggestion.
In EMNLP,
pages 1577–1588,
2011.
[13]
Z. Liu, C. Liang, and M. Sun.
Topical word trigger model for keyphrase
extraction.
In In Proceedings of COLING.
Citeseer,
2012.
[14]
T.
Mikolov,
K.
Chen,
G.
Corrado,
and J.
Dean.
Efficient
estimation of
word representations in vector space.
arXiv preprint: 1301.3781,
2013.
[15]
J. Pennington, R. Socher, and C. D. Manning.
Glove: Global vectors for
word representation.
In EMNLP,
volume 14,
pages 1532–1543,
2014.
[16]
M.
F.
Porter.
Snowball: A language for stemming algorithms,
2001.
[17]
R.
Rehurek and P.
Sojka.
Software framework for
topic modelling
with large corpora.
In LREC Workshop on New Challenges for NLP
Frameworks,
2010.
[18]
S. Sedhai and A. Sun.
Hashtag recommendation for hyperlinked tweets.
In ACM SIGIR,
pages 831–834,
2014.
[19]
J. She and L. Chen.
Tomoha: Topic model-based hashtag recommenda-
tion on twitter.
In WWW,
pages 371–372.
ACM,
2014.
[20]
K.
Starbird and L.
Palen.
(how)
will
the revolution be retweeted?:
information diffusion and the 2011 egyptian uprising.
In CSCW,
pages
7–16.
ACM,
2012.
[21]
O.
Tsur
and A.
Rappoport.
What’s
in a
hashtag?:
content
based
prediction of
the spread of
ideas in microblogging communities.
In
WSDM,
pages 643–652.
ACM,
2012.
[22]
J. Weston, S. Chopra, and K. Adams.
# tagspace: Semantic embeddings
from hashtags.
2014.
[23]
E. Zangerle, W. Gassler, and G. Specht.
Recommending#-tags in twitter.
In Workshop on Semantic Adaptive Social Web (SASWeb 2011).
CEUR
Workshop Proceedings,
volume 730,
pages 67–78,
2011.
[24]
Q.
Zhang,
Y.
Gong,
X.
Sun,
and X.
Huang.
Time-aware personalized
hashtag recommendation on social media.
In COLING, pages 203–212,
2014.
