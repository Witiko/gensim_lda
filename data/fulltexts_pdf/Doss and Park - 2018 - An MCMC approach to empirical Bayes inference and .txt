arXiv:1807.02191v1 [stat.ME] 5 Jul 2018
Submitted to the Annals of Statistics
arXiv: arXiv:0000.0000
AN MCMC APPROACH TO EMPIRICAL BAYES INFERENCE AND
BAYESIAN SENSITIVITY ANALYSIS VIA EMPIRICAL PROCESSES
B
Y
H
ANI
D
OSS
∗
AND
Y
EONHEE
P
ARK
University of Florida and MD Anderson Cancer Center
Consider a Bayesian situation in which we observe Y
∼ p
θ
,
where
θ ∈ Θ, and we have a family {ν
h
, h ∈ H} of potential prior distributions
on Θ.
Let
g be a real-valued function of θ,
and let
I
g
(h) be the posterior
expectation of g(θ) when the prior is ν
h
. We are interested in two problems:
(i) selecting a particular value of h, and (ii) estimating the family of posterior
expectations {I
g
(h), h ∈ H}. Let m
y
(h) be the marginal likelihood of the
hyperparameter h: m
y
(h) =
R
p
θ
(y) ν
h
(dθ). The empirical Bayes estimate
of h is, by definition, the value of h that maximizes m
y
(h). It turns out that it
is typically possible to use Markov chain Monte Carlo to form point estimates
for m
y
(h) and I
g
(h) for each individual h in a continuum,
and also confi-
dence intervals for m
y
(h) and I
g
(h) that are valid pointwise. However, we
are interested in forming estimates, with confidence statements, of the entire
families of integrals {m
y
(h), h ∈ H} and {I
g
(h), h ∈ H}: we need esti-
mates of the first family in order to carry out empirical Bayes inference, and
we need estimates of the second family in order to do Bayesian sensitivity
analysis.
We establish strong consistency and functional central limit theo-
rems for estimates of these families by using tools from empirical process
theory.
We give two applications,
one to Latent Dirichlet Allocation,
which
is used in topic modelling, and the other is to a model for Bayesian variable
selection in linear regression.
1.
Introduction.
This paper is concerned with two related problems.
In the
first, there is a function
B
:
H →
R
, where
H
is a subset of some Euclidean space,
and we wish to obtain confidence sets for
arg max
h∈H
B
(
h
)
. For each
h
, the ex-
pression for
B
(
h
)
is analytically intractable;
however,
we have at our disposal
a
family of functions
{
f
h
, h
∈ H}
and a sequence of random variables
θ
1
, . . . , θ
n
(these are iid or the initial segment of an ergodic Markov chain) such that the ran-
dom function
B
n
(
h
)
:
= (1
/n
)
P
n
i=1
f
h
(
θ
i
)
satisfies
B
n
(
h
)
a.s.
−→
B
(
h
)
for each
h
.
We are interested in how we can use
B
n
to form both a point estimate and a
confidence set for
arg max
h∈H
B
(
h
)
.
This problem appears in empirical
Bayes analysis and under many forms in
likelihood inference. In empirical Bayes analysis, the application that is the focus
∗
Supported by NSF Grant DMS-11-06395 and NIH grant P30 AG028740
MSC 2010 subject classifications: Primary 62F15, 91-08; secondary 62F12
Keywords and phrases: Donsker class, geometric ergodicity, hyperparameter selection, regenera-
tive simulation, Latent Dirichlet Allocation model
1
2
H. DOSS AND Y. PARK
of this paper, it arises as follows. Suppose we are in a standard Bayesian situation
in which we observe a data vector
Y
whose distribution is
P
θ
(with density
p
θ
with respect to some dominating measure) for some
θ
∈
Θ
. We have a family of
potential prior densities
{
ν
h
, h
∈ H}
, and because the hyperparameter
h
can have
a great impact on subsequent inference,
we wish to choose it carefully.
Selection
of
h
is often guided by the marginal likelihood of the data under the prior
ν
h
, given
by
(1.1)
m
y
(
h
) =
Z
p
θ
(
y
)
ν
h
(
θ
)
dθ,
h
∈ H
.
By definition, the empirical Bayes choice of
h
is
arg max
h
m
y
(
h
)
. Unfortunately,
analytic calculation of
m
y
(
h
)
is not feasible except for a few textbook examples,
and estimation of
m
y
(
h
)
via Monte Carlo is notoriously difficult—for example,
the “harmonic mean estimator” introduced by Newton and Raftery (1994) typically
converges at a rate which is much slower than
n
1/2
(Wolpert and Schmidler, 2012).
It is very interesting to note that if
c
is a constant, then the information regarding
h
given by the two functions
m
y
(
h
)
and
cm
y
(
h
)
is the same: the same value of
h
maximizes both functions,
and the second derivative matrices of the logarithm
of these two functions are identical.
In particular,
the Hessians of the logarithm
of these two functions at the maximum (i.e. the observed Fisher information) are
the same and, therefore, the standard point estimates and confidence regions based
on
m
y
(
h
)
and
cm
y
(
h
)
are identical.
This is a very useful observation because it
turns out that
it is usually easy to estimate the entire family
{
cm
y
(
h
)
, h
∈ H}
for a suitable choice of
c
.
Indeed,
for any
h
∈ H
,
let
ν
h,y
denote the posterior
corresponding to
ν
h
, let
h
1
be fixed but arbitrary, and suppose that
θ
1
, . . . , θ
n
are
either independent and identically distributed according to the posterior
ν
h
1
,y
, or
are the initial segment an ergodic Markov chain with invariant distribution
ν
h
1
,y
.
Let
ℓ
y
(
θ
) =
p
θ
(
y
)
be the likelihood function. Note that
m
y
(
h
)
given by (1.1) is the
normalizing constant in the statement “the posterior is proportional to likelihood
times the prior,” i.e.
(1.2)
ν
h,y
(
θ
) =
ℓ
y
(
θ
)
ν
h
(
θ
)
/m
y
(
h
)
.
We have
1
n
n
X
i=1
ν
h
(
θ
i
)
ν
h
1
(
θ
i
)
a.s.
−→
Z
ν
h
(
θ
)
ν
h
1
(
θ
)
ν
h
1
,y
(
θ
)
dθ
=
m
y
(
h
)
m
y
(
h
1
)
Z
ν
h,y
(
θ
)
ν
h
1
,y
(
θ
)
ν
h
1
,y
(
θ
)
dθ
=
m
y
(
h
)
m
y
(
h
1
)
,
(1.3)
in which the first equality follows from (1.2) and cancellation of the likelihood.
Let
B
(
h
) =
m
y
(
h
)
/m
y
(
h
1
)
.
Since
m
y
(
h
1
)
is a fixed constant,
as noted above,
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
3
the two functions
m
y
(
h
)
and
B
(
h
)
give exactly the same information about
h
. If
we let
f
h
=
ν
h
/ν
h
1
,
then
B
n
(
h
) = (1
/n
)
P
n
i=1
(
ν
h
(
θ
i
)
/ν
h
1
(
θ
i
))
—this quantity
is computable, since it involves only the priors and not the posteriors—so we have
precisely the situation discussed in the first paragraph of this paper. Other examples
of this situation arising in frequentist inference,
and in particular in missing data
models, are given in Sung and Geyer (2007) and Doss and Tan (2014).
In Bayesian applications it is rare that Monte Carlo estimates of posterior quan-
tities can be based on iid samples; in the vast majority of cases they are based on
Markov chain samples, and that is the case that is the focus of this paper. We show
that under suitable regularity conditions,
(1.4)
arg max
h
B
n
(
h
)
a.s.
−→
arg max
h
B
(
h
)
and
(1.5)
n
1/2
arg max
h
B
n
(
h
)
−
arg max
h
B
(
h
)

d
→ N
(0
,
Σ)
,
where
Σ
can be estimated consistently. Now, in general, almost sure convergence of
B
n
(
h
)
to
B
(
h
)
pointwise is not enough to imply that
arg max
h
B
n
(
h
)
converges to
arg max
h
B
(
h
)
under any mode of convergence, and in fact it is trivial to construct
a counterexample in which
g
n
and
g
are deterministic functions defined on
[0
,
1]
,
g
n
(
h
)
n→∞
−→
g
(
h
)
for every
h
∈
[0
,
1]
,
but
arg max
h
g
n
(
h
)
does not converge to
arg max
h
g
(
h
)
.
To obtain results (1.4) and (1.5) above,
some uniformity in the
convergence is needed. We establish the necessary uniform convergence and show
that
(1.4) and (1.5) are true under certain regularity conditions on the sequence
θ
1
, θ
2
, . . .
, the functions
f
h
, and the function
B
. Result (1.5) enables us to obtain
confidence sets for
arg max
h
B
(
h
)
.
The second problem we are interested in pertains to the Bayesian framework
discussed earlier and is described as follows. Suppose that
g
is a real-valued func-
tion of
θ
, and consider
I
g
(
h
) =
R
g
(
θ
)
ν
h,y
(
θ
)
dθ
, the posterior expectation of
g
(
θ
)
given
Y
=
y
, when the prior is
ν
h
. Suppose that
h
1
∈ H
is fixed but arbitrary, and
that
θ
1
, θ
2
, . . .
is an ergodic Markov chain with invariant distribution
ν
h
1
,y
. A very
interesting and well-known fact,
which we review in Section 2.3,
is that for any
h
∈ H
, if we define
w
(h)
i
=
[
ν
h
(
θ
i
)
/ν
h
1
(
θ
i
)]
P
n
l=1
[
ν
h
(
θ
l
)
/ν
h
1
(
θ
l
)]
,
then
(1.6)
ˆ
I
g
(
h
) =
n
X
i=1
g
(
θ
i
)
w
(h)
i
is a consistent estimate of
I
g
(
h
)
. Clearly
ˆ
I
g
(
h
)
is a weighted average of the
g
(
θ
i
)
’s.
Under additional regularity conditions on the Markov chain and the function
g
, we
4
H. DOSS AND Y. PARK
even have a central limit theorem (CLT):
n
1/2
ˆ
I
g
(
h
)
−
I
g
(
h
)

d
→ N
(0
, σ
2
(
h
))
,
and we can consistently estimate the limiting variance. Thus, with a single Markov
chain run, using knowledge of only the priors and not the posteriors, we can esti-
mate and form confidence intervals for
I
g
(
h
)
for any particular value of
h
. Now in
Bayesian sensitivity analysis applications,
we will be interested in viewing
I
g
(
h
)
for many values of
h
.
For example,
in prior elicitation settings,
we may wish to
find those aspects of the prior that have the biggest impact on the posterior, so that
the focus of the effort is spent on those important aspects.
We may also want to
determine whether differences in the prior opinions of many experts have a signif-
icant impact on the conclusions. (For a discussion of Bayesian sensitivity analysis
see Berger (1994) and Kadane and Wolfson (1998).) In these cases we will be in-
terested in forming confidence bands for
I
g
(
·
)
that are valid globally,
as opposed
to pointwise.
A common feature of the two problems we study in this paper is the need for
uniformity in the convergence: to obtain confidence intervals for
arg max
h∈H
B
(
h
)
we need some uniformity in the convergence of
B
n
(
·
)
to
B
(
·
)
, and to obtain con-
fidence bands for
I
g
(
·
)
we need functional CLT’s for the stochastic process
ˆ
I
g
(
·
)
.
Empirical process theory is a body of results that can be used to establish uniform
almost sure convergence and functional CLT’s in very general settings.
However,
the results hold only under strong regularity conditions; and these conditions are
often hard to check in practical settings—indeed the results can easily be false if
the conditions are not met. Empirical process theory is fundamentally based on an
iid assumption, whereas in our setting, the sequence
θ
1
, θ
2
, . . .
is a Markov chain.
In this paper we show how empirical process methods can be applied to our two
problems when the sequence
θ
1
, θ
2
, . . .
is a Markov chain, and we also show how
the needed regularity conditions can be established.
The rest
of the paper is organized as follows.
In Section 2 we state our the-
oretical
results,
the main ones—those that
pertain to the Markov chain case—
being as follows.
Theorem 3 asserts uniform convergence of
B
n
to
B
when the
sequence
θ
1
, θ
2
, . . .
is a Harris ergodic Markov chain,
under
certain regularity
conditions on the family
{
f
h
, h
∈ H}
(the precise details are spelled out in the
statement
of the theorem),
and we show how these regularity conditions can be
checked with relative ease in standard settings. We then give a simple result which
says that under a mild regularity assumption on
B
, the condition
sup
h
|
B
n
(
h
)
−
B
(
h
)
|
a.s.
−→
0
entails
arg max
h
B
n
(
h
)
a.s.
−→
arg max
h
B
(
h
)
.
Theorem 4 estab-
lishes that
under certain regularity conditions,
we have asymptotic normality of
n
1/2
arg max
h
B
n
(
h
)
−
arg max
h
B
(
h
)

. Theorem 6 establishes almost sure uni-
form convergence of
ˆ
I
g
(
·
)
to
I
g
(
·
)
, and also functional weak convergence: the pro-
cess

n
1/2
ˆ
I
g
(
h
)
−
I
g
(
h
)

, h
∈ H
converges weakly to a mean
0
Gaussian
process indexed by
h
∈ H
. We also show how this result can be used to construct
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
5
confidence bands for
I
g
(
·
)
that are valid globally. A by-product is functional weak
convergence of

n
1/2
(
B
n
(
h
)
−
B
(
h
))
, h
∈ H
to a mean
0
Gaussian process
indexed by
h
∈ H
, and construction of corresponding globally valid confidence
bands for
B
(
·
)
. In Section 3 we give two illustrations on Bayesian models in which
serious consideration needs to be given to the effect of the hyperparameter and its
choice. The first is to the Latent Dirichlet Allocation topic model, where we show
how our methodology can be used to do sensitivity analysis, and the second is to a
model for Bayesian variable selection in linear regression, where we show how our
methodology can be used to select the hyperparameter. In the Appendix we provide
the proofs of all the theorems except for Theorem 3; additionally, we show how the
regularity conditions in Theorem 1 and Theorem 3 would typically be checked, and
we verify these conditions in a simple setting.
2.
Convergence of B
n
(·) as a Process and Convergence of the Empirical
Argmax.
This section consists of three parts. Section 2.1 deals with uniform con-
vergence of
B
n
for the iid case, and introduces the framework that will enable us to
obtain results for the Markov chain case; this framework will be used in Section 2.1
and in the rest of the paper. Section 2.2 deals with point estimates and confidence
sets for
arg max
h
B
(
h
)
, and Section 2.3 deals with uniform convergence and func-
tional CLT’s for estimates of posterior expectations. Throughout, uniformity refers
to a class of functions indexed by
h
∈ H
.
2.1.
Uniform Convergence of
B
n
(
·
)
.
Let
Θ
be a measurable subset of
R
d
for
some
d
≥
1
, and let
P
be a probability measure on
(Θ
,
B
)
, where
B
is the Borel
sigma-field on
Θ
. We assume that
θ
1
, . . . , θ
n
are independent and identically dis-
tributed according to
P
, and we let
P
n
be the empirical measure that they induce.
We assume that
H
is a convex compact subset of
R
k
for some
k
≥
1
, and that for
each
h
∈ H
,
f
h
: Θ
→
R
is measurable. The strong law of large numbers (SLLN)
states that
(2.1)
1
n
n
X
i=1
f
h
(
θ
i
)
a.s.
−→
Z
f
h
dP
if
Z
|
f
h
|
dP <
∞
.
Since we will be interested in versions of (2.1) that are uniform in
h
, there will exist
measurability difficulties,
so we have to be careful in dealing with measurability
issues. Before proceeding, we review some terminology and standard facts from the
theory of empirical processes. We will use the following standard empirical process
notation:
for a signed measure
µ
on
Θ
and a
µ
-integrable function
f
:
Θ
→
R
,
µ
(
f
)
denotes
R
f dµ
. Let
Q
be an arbitrary probability measure on
Θ
, suppose that
ξ
1
, ξ
2
, . . .
are independent and identically distributed according to
Q
, and let
Q
n
be
the empirical measure induced by
ξ
1
, . . . , ξ
n
. If
V
is a class of functions mapping
Θ
6
H. DOSS AND Y. PARK
to
R
, and
µ
is a signed measure on
Θ
, we use the notation
k
µ
k
V
= sup
v∈V
|
µ
(
v
)
|
.
We say that
V
is
Glivenko-Cantelli
if
k
Q
n
−
Q
k
V
converges to
0
almost surely;
sometimes we will say
V
is
Q
-
Glivenko-Cantelli
, to emphasize the dependence on
Q
. Let
F
=
{
f
h
, h
∈ H}
. Our goal is to establish that
F
is
P
-Glivenko-Cantelli,
which is exactly equivalent
to the statement
that
the convergence in (2.1) holds
uniformly in
h
.
The IID Case.
T
HEOREM
1 (Theorem 6.1 and Lemma 6.1 in Wellner
(2005))
Suppose that
θ
1
, θ
2
, . . .
are independent and identically distributed according to
P
. Suppose that
f
·
(
·
) :
H×
Θ
→
R
is continuous in
h
for
P
-almost all
θ
. If
sup
h
|
f
h
|
is measurable
and satisfies
R
sup
h
|
f
h
|
dP <
∞
, then the class
F
is
P
-Glivenko-Cantelli.
Let
B
n
(
h
) = (1
/n
)
P
n
i=1
f
h
(
θ
i
)
and
B
(
h
) =
E
P
(
f
h
(
θ
))
(the subscript
to the
expectation indicates that
θ
∼
P
). Then the conclusion of the theorem is the state-
ment
sup
h∈H
|
B
n
(
h
)
−
B
(
h
)
|
a.s.
−→
0
.
The integrability condition
R
sup
h
|
f
h
|
dP <
∞
seems strong,
and an even
stronger integrability condition is imposed in Theorem 3.
We discuss this issue
in Remark 1 following the statement of Theorem 3, where we explain that in fact
the two conditions are fairly easy to check in practice.
The next theorem also establishes that the class
F
is Glivenko-Cantelli.
In the
theorem,
the integrability condition on
sup
h
|
f
h
|
is replaced by an integrability
condition on
sup
h
k∇
h
f
h
k
(here,
∇
h
f
h
is the gradient vector of
f
h
with respect to
h
, and
k · k
is Euclidean norm). The condition on the gradient is sometimes easier
to check. We include the theorem in part because a component of its proof is a key
element in the proofs of Theorems 5 and 6 of this paper.
T
HEOREM
2 Suppose that
θ
1
, θ
2
, . . .
are independent
and identically distributed
according to
P
,
and that
for each
h
∈ H
,
R
|
f
h
|
dP <
∞
.
Assume also that
for
P
-almost all
θ
∈
Θ
,
∇
h
f
h
exists and is continuous on
H
. If
sup
h
k∇
h
f
h
k
is
measurable and satisfies
R
sup
h
k∇
h
f
h
k
dP <
∞
, then the class
F
is
P
-Glivenko-
Cantelli.
The Markov Chain Case.
Suppose now that the sequence
θ
1
, θ
2
, . . .
is a Mar-
kov chain with invariant distribution
P
, and that it is Harris ergodic (that is, it is
irreducible,
aperiodic,
and Harris recurrent;
see Meyn and Tweedie (1993,
chap-
ter 17) for definitions). Suppose also that
R
|
f
h
|
dP <
∞
for all
h
∈ H
. The best
way to deal
with the family of averages
(1
/n
)
P
n
i=1
f
h
(
θ
i
)
, h
∈ H
,
is through
the use of “regenerative simulation.” A
regeneration
is a random time at which a
stochastic process probabilistically restarts itself; therefore,
the “tours” made by
the process in between such random times are iid.
For example,
if the stochastic
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
7
process is a Markov chain on a discrete state space
Θ
, and if
θ
0
∈
Θ
is any point
to which the chain returns infinitely often with probability one, then the times of
return to
θ
0
form a sequence of regenerations.
This iid structure will
enable us
to establish uniform convergence of the family
(1
/n
)
P
n
i=1
f
h
(
θ
i
)
, h
∈ H
.
Be-
fore we explain this,
we first
note that
for most
of the Markov chains used in
MCMC algorithms,
the state space is continuous,
and there is no point to which
the chain returns infinitely often with probability one. Fortunately, Mykland et al.
(1995) provided a general
technique for identifying a sequence of regeneration
times
1 =
τ
0
< τ
1
< τ
2
<
· · ·
that is based on the construction of a
minorization
condition
. This construction is reviewed at the end of this subsection, and gives rise
to regeneration times with the property that
(2.2)
E
(
τ
r
−
τ
r−1
)
<
∞
.
Suppose now that there exists a regeneration sequence
1 =
τ
0
< τ
1
< τ
2
<
· · ·
which satisfies (2.2).
Such a Markov chain will
be called regenerative.
For any
h
∈ H
, consider
(1
/n
)
P
n
i=1
f
h
(
θ
i
)
. Let
(2.3)
S
(h)
r
=
τ
r
−1
X
i=τ
r−1
f
h
(
θ
i
)
,
r
= 1
,
2
, . . .
be the sum of
f
h
over the
r
th
tour.
Also,
let
N
r
=
τ
r
−
τ
r−1
, r
= 1
,
2
, . . .
,
de-
note the length of the
r
th
tour.
The
N
r
’s do not
involve
h
.
Note that
the pairs
{
(
N
r
, S
(h)
r
)
}
∞
r=1
are iid.
If we run the chain for
R
regenerations,
then the total
number of cycles is given by
n
=
R
X
r=1
N
r
=
τ
R
.
Also,
P
n
i=1
f
h
(
θ
i
) =
P
R
r=1
S
(h)
r
. We have
(2.4)
E
P
(
f
h
(
θ
))
a.s.
←−
P
n
i=1
f
h
(
θ
i
)
n
=
P
R
r=1
S
(h)
r
P
R
r=1
N
r
=
P
R
r=1
S
(h)
r

/R
P
R
r=1
N
r

/R
a.s.
−→
E
(
S
(h)
1
)
E
(
N
1
)
.
In (2.4),
the convergence statement on the left follows from Harris ergodicity of
the chain.
The convergence statement on the right follows from two applications
of the SLLN: By (2.2),
(1
/R
)
P
R
r=1
N
r
a.s.
−→
E
(
N
1
)
and this,
together with the
convergence statement on the left,
entails convergence of
(1
/R
)
P
R
r=1
S
(h)
r
. The
SLLN then implies that
E
(
|
S
(h)
1
|
)
<
∞
(if
E
(
|
S
(h)
1
|
) =
∞
then the SLLN im-
plies that
lim sup(1
/R
)
P
R
r=1
S
(h)
r
=
∞
with probability one). We conclude that
8
H. DOSS AND Y. PARK
E
(
S
(h)
1
) =
E
P
(
f
h
(
θ
))
E
(
N
1
)
. Note that continuity in
h
of
S
(h)
1
for almost all se-
quences
θ
1
, θ
2
, . . .
follows from continuity in
h
of
f
h
for almost all
θ
∈
Θ
, since
with probability one,
S
(h)
1
is a finite sum.
Suppose in addition that
sup
h
|
S
(h)
1
|
is measurable and satisfies
E
sup
h
|
S
(h)
1
|

<
∞
.
Then by Theorem 1 we have
sup
h
P
R
r=1
S
(h)
r

/R
−
E
(
S
(h)
1
)
a.s.
−→
0
. Since
P
R
r=1
N
r

/R
a.s.
−→
E
(
N
1
)
, we
obtain
sup
h
P
R
r=1
S
(h)
r

/R
P
R
r=1
N
r

/R
−
E
(
S
(h)
1
)
E
(
N
1
)
a.s.
−→
0
,
i.e.
(2.5)
sup
h
P
n
i=1
f
h
(
θ
i
)
n
−
E
P
(
f
h
(
θ
))
a.s.
−→
0
.
We summarize this in the following theorem.
T
HEOREM
3 Suppose that
θ
1
, θ
2
, . . .
is a Harris ergodic Markov chain with in-
variant distribution
P
for which there exists a regeneration sequence
1 =
τ
0
<
τ
1
< τ
2
<
· · ·
satisfying
E
(
τ
1
−
τ
0
)
<
∞
. Suppose also that
f
·
(
·
) :
H ×
Θ
→
R
is continuous in
h
for
P
-almost all
θ
. For each
h
∈ H
, let
S
(h)
r
, r
= 1
,
2
, . . .
be
defined by (2.3). If
sup
h
|
S
(h)
1
|
is measurable and satisfies
E
sup
h
|
S
(h)
1
|

<
∞
,
then (2.5) holds.
R
EMARK
1 We now discuss the integrability condition
E
sup
h
|
S
(h)
1
|

<
∞
, and
our discussion encompasses the weaker condition
R
sup
h
|
f
h
|
dP <
∞
assumed
in Theorem 1. Suppose that
R
|
f
h
|
dP <
∞
for all
h
∈ H
. In the Appendix we
show that, because
H
is assumed to be compact, it is often possible to prove that
for some
d
≥
1
,
there exist
h
1
, . . . , h
d
∈ H
and constants
c
1
, . . . , c
d
such that
sup
h
|
f
h
(
θ
)
| ≤
d
X
j=1
c
j
|
f
h
j
(
θ
)
|
for all
θ
∈
Θ
.
(2.6)
In this case, since
|
S
(h)
1
| ≤
P
τ
1
−1
i=τ
0
|
f
h
(
θ
i
)
|
, we obtain
sup
h
|
S
(h)
1
| ≤
τ
1
−1
X
i=τ
0
sup
h
|
f
h
(
θ
i
)
| ≤
τ
1
−1
X
i=τ
0
d
X
j=1
c
j
|
f
h
j
(
θ
i
)
|
.
Hence,
E

sup
h
|
S
(h)
1
|

≤
d
X
j=1
E
τ
1
−1
X
i=τ
0
c
j
|
f
h
j
(
θ
i
)
|
!
=
d
X
j=1
c
j
E
P
(
|
f
h
j
(
θ
)
|
)
E
(
N
1
)
,
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
9
which is finite.
Thus,
checking that
E
sup
h
|
S
(h)
1
|

<
∞
reduces to establish-
ing (2.6). In the Appendix we consider the Bayesian framework discussed in Sec-
tion 1,
in which
f
h
=
ν
h
/ν
h
∗
,
where
{
ν
h
, h
∈ H}
is a family of priors,
and
P
=
ν
h
∗
,y
, the posterior distribution corresponding to the prior
ν
h
∗
, where
h
∗
∈ H
is fixed. We show that if
{
ν
h
, h
∈ H}
is an exponential family, then condition (2.6)
holds. Therefore, the integrability condition
E
sup
h
|
S
(h)
1
|

<
∞
is satisfied in a
large class of examples. Moreover, the method we use for establishing (2.6) can be
applied to other examples as well.
R
EMARK
2 The idea to transform results for the iid case to the Markov chain case
via regeneration has been around for many decades. Levental (1988) also obtained
a Glivenko-Cantelli theorem for the Markov chain setting.
In essence,
the differ-
ence between his approach and ours is that his starting point is a Glivenko-Cantelli
theorem for the iid case which requires a condition involving the minimum num-
ber of balls of radius
ǫ
in
L
1
(
P
)
that are needed to cover
F
—he is using metric
entropy.
This condition is very hard to check.
By contrast,
our starting point is a
Glivenko-Cantelli theorem for the iid case which is based on bracketing entropy—
in brief,
the main regularity condition is implied by the continuity condition in
Theorem 3.
This continuity condition is trivial to verify: the parametric families
that we are working with in our Bayesian setting satisfy it automatically.
The Minorization Construction.
We now describe a minorization condition that
can sometimes be used to construct
regeneration sequences.
Let
K
θ
(
A
)
be the
transition function for the Markov chain
θ
1
, θ
2
, . . .
. The construction described in
Mykland et al. (1995) requires the existence of a function
s
:
Θ
→
[0
,
1)
,
whose
expectation with respect to
P
is strictly positive, and a probability measure
Q
on
(Θ
,
B
)
, such that
K
satisfies
(2.7)
K
θ
(
A
)
≥
s
(
θ
)
Q
(
A
)
for all
θ
∈
Θ
and
A
∈ B
.
This is called a minorization condition and, as we describe below, it can be used
to introduce regenerations into the Markov chain driven by
K
. Define the Markov
transition function
G
·
(
·
)
by
G
θ
(
A
) =
K
θ
(
A
)
−
s
(
θ
)
Q
(
A
)
1
−
s
(
θ
)
.
Note that for fixed
θ
∈
Θ
,
G
θ
is a probability measure. We may therefore write
K
θ
=
s
(
θ
)
Q
+ (1
−
s
(
θ
))
G
θ
,
which gives a representation of
K
θ
as a mixture of two probability measures,
Q
and
G
θ
. This provides an alternative method of simulating from
K
. Suppose that
10
H. DOSS AND Y. PARK
the current state of the chain is
θ
n
. We generate
δ
n
∼
Bernoulli
(
s
(
θ
n
))
. If
δ
n
= 1
,
we draw
θ
n+1
∼
Q
; otherwise,
we draw
θ
n+1
∼
G
θ
n
.
Note that if
δ
n
= 1
,
the
next
state of the chain is drawn from
Q
,
which does not
depend on the current
state.
Hence the chain “forgets” the current state and we have a regeneration.
To
be more specific,
suppose we start the Markov chain with
θ
1
∼
Q
and then use
the method described above to simulate the chain.
Each time
δ
n
= 1
,
we have
θ
n+1
∼
Q
and the process stochastically restarts itself; that is, the process regener-
ates. Mykland et al. (1995) provided a very widely applicable method, the so-called
“distinguished point technique”,
for constructing a pair
(
s, Q
)
that can be used to
form a minorization scheme which satisfies (2.2).
For any fixed
h
∈ H
, consider now the expression
P
R
r=1
S
(h)
r

/R
P
R
r=1
N
r

/R
in (2.4). The bivariate CLT gives
(2.8)
R
1/2
P
R
r=1
S
(h)
r

/R
−
E
P
(
f
h
(
θ
))
E
(
N
1
)
P
R
r=1
N
r

/R
−
E
(
N
1
)
!
d
→ N
(0
,
Σ
h
)
,
where
Σ
h
= Cov (
S
(h)
1
, N
1
)
⊤

. (We have ignored the moment conditions on
S
(h)
1
and
N
1
that are needed, but we will return to these conditions in Section 2.3, where
we give a rigorous development of a functional version of the CLT (2.8), in which
the left side of (2.8) is viewed as a process in
h
.) The delta method applied to the
function
g
(
x, y
) =
x/y
gives the CLT
R
1/2
P
R
r=1
S
(h)
r

/R
P
R
r=1
N
r

/R
−
E
P
(
f
h
(
θ
))
!
d
→ N
(0
, σ
2
h
)
,
where
σ
2
h
= (
∇
g
)
⊤
Σ
h
∇
g
(and
∇
g
is evaluated at the vector of means in (2.8)).
Moreover,
σ
2
h
can be estimated in a simple manner
using a plug-in estimate.
Whether or not this method gives estimates of variance that are useful in the prac-
tical
sense depends on whether or not
the minorization condition we construct
yields regenerations which are sufficiently frequent.
Successful
constructions of
minorization conditions have been developed for widely used chains in many pa-
pers (we mention in particular Mykland et al. (1995), Roy and Hobert (2007), Tan and Hobert
(2009), and Doss et al. (2014)); nevertheless, successful construction of a minoriza-
tion condition is the exception rather than the norm. In this context,
we point out
that here regenerative simulation is notable primarily as a device that enables us to
prove the theoretical results in the present paper and to arrive at informative expres-
sions for asymptotic variances,
but it may be possible to estimate these variances
by other methods; this point is discussed further in Section 2.2.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
11
R
EMARK
3 The main regularity assumption in Theorem 3 is
the condition
E
sup
h
|
S
(h)
1
|

<
∞
. Without giving the details, we mention that in analogy with
Theorem 2, it is possible to give a version of Theorem 3 in which this condition is
replaced with the condition
E
sup
h
k∇
h
S
(h)
1
k

<
∞
.
2.2.
A Consistent
Estimator and Confidence Sets for
arg max
h
B
(
h
)
.
This
section pertains to
arg max
h
B
n
(
h
)
as an estimator of
arg max
h
B
(
h
)
.
After es-
tablishing that (2.5) entails that
arg max
h
B
n
(
h
)
is consistent, we show that under
additional
regularity conditions,
(i)
n
1/2
arg max
h
B
n
(
h
)
−
arg max
h
B
(
h
)

is
asymptotically normal, and (ii) we can consistently estimate the asymptotic vari-
ance. Results (i) and (ii) enable us to form asymptotically valid confidence sets for
arg max
h
B
(
h
)
.
L
EMMA
1 Suppose that
H
is a compact subset of Euclidean space, and let
f
n
, n
=
1
,
2
, . . .
and
f
be deterministic real-valued functions defined on
H
. Suppose further
that
f
is continuous and has a unique maximizer, and that for each
n
the maximizer
of
f
n
exists and is unique. If
f
n
converges to
f
uniformly on
H
, then the maximizer
of
f
n
converges to the maximizer of
f
.
The proof of Lemma 1 is routine and is given in the Appendix.
Consider now
B
n
(
h
) = (1
/n
)
P
n
i=1
f
h
(
θ
i
)
and
B
(
h
) =
E
P
(
f
h
(
θ
))
. By Lemma 1, if
B
is con-
tinuous and its maximizer is unique,
then
sup
h
|
B
n
(
h
)
−
B
(
h
)
|
a.s.
−→
0
implies
arg max
h
B
n
(
h
)
a.s.
−→
arg max
h
B
(
h
)
.
Thus,
under continuity of
B
and unique-
ness of its maximizer,
any conditions that
imply (2.5)—in particular the condi-
tions of Theorems 1, 2, or 3—are also conditions that imply strong consistency of
arg max
h
B
n
(
h
)
as an estimator of
arg max
h
B
(
h
)
.
Before stating the next
theorem,
we need to set
some notation and assump-
tions.
We assume that each of
B
and
B
n
, n
= 1
,
2
, . . .
has a unique maximizer,
and we denote
h
0
= arg max
h
B
(
h
)
and
h
n
= arg max
h
B
n
(
h
)
. For a function
g
:
H →
R
,
∇
h
g
(
h
)
denotes the gradient
vector and
∇
2
h
g
(
h
)
denotes the Hes-
sian matrix. We will assume that for every
θ
,
∇
h
f
h
(
θ
)
and
∇
2
h
f
h
(
θ
)
exist and are
continuous for all
h
.
Recall that
S
(h)
r
is defined by (2.3). The Markov chain will
be run for
R
regenerations,
and in the asymptotic results below,
R
→ ∞
.
We
will use the notation
¯
N
=
P
R
r=1
N
r

/R
,
¯
S
(h)
=
P
R
r=1
S
(h)
r

/R
,
∇
h
¯
S
(h)
=
P
R
r=1
∇
h
S
(h)
r

/R
,
etc.
For almost
any realization
θ
1
, θ
2
, . . .
,
the random vari-
able
S
(h)
r
is a finite sum, and therefore
∇
h
S
(h)
r
=
P
τ
r
−1
i=τ
r−1
∇
h
f
h
(
θ
i
)
. Similarly,
∇
2
h
S
(h)
r
=
P
τ
r
−1
i=τ
r−1
∇
2
h
f
h
(
θ
i
)
.
We will assume that the family
{
f
h
, h
∈ H}
is
such that the interchange of the order of integration and either first or second order
12
H. DOSS AND Y. PARK
differentiation is permissible, i.e.
(2.9)
∇
h
Z
f
h
dP
=
Z
∇
h
f
h
dP
and
∇
2
h
Z
f
h
dP
=
Z
∇
2
h
f
h
dP.
For
h
∈ H
, let
J
(
h
) =
∇
2
h
B
(
h
)
,
J
n
(
h
) =
∇
2
h
B
n
(
h
)
,
τ
2
(
h
) = [
E
(
N
1
)]
−2
E


∇
h
S
(h)
1
−
N
1
E
P
(
∇
h
f
h
(
θ
))

∇
h
S
(h)
1
−
N
1
E
P
(
∇
h
f
h
(
θ
))

⊤

,
and
τ
2
n
(
h
) =
1
R
¯
N
2
R
X
r=1
∇
h
S
(h)
r
−
N
r
∇
h
¯
S
(h)
/
¯
N

∇
h
S
(h)
r
−
N
r
∇
h
¯
S
(h)
/
¯
N

⊤
.
Suppose that
X
1
, X
2
, . . .
is a Markov chain on the measurable space
(
X
,
B
)
and
has
π
as an invariant
probability measure.
Let
K
n
(
x, A
)
be the
n
-step Markov
transition function.
Recall that the chain is called
geometrically ergodic
if there
exist
a constant
c
∈
[0
,
1)
and a function
M
:
X
→
[0
,
∞
)
such that
for
n
=
1
,
2
, . . .
,
sup
A∈B
|
K
n
(
x, A
)
−
π
(
A
)
| ≤
M
(
x
)
c
n
for all
x
∈
X
.
If
Q
(
θ
)
is a
k
×
k
matrix, then a statement of the sort
E
(
|
Q
(
θ
)
|
)
<
∞
will mean
E
(
|
Q
i,j
(
θ
)
|
)
<
∞
for
i, j
= 1
, . . . , k
. We will refer to the following conditions.
A1
The chain
{
θ
i
}
∞
i=0
is geometrically ergodic.
A2
For every
h
∈ H
, there exists
ǫ >
0
such that
E
P
k∇
h
f
h
(
θ
)
k
2+ǫ

<
∞
.
A3
The function
B
is twice continuously differentiable and the
k
×
k
matrix
J
(
h
0
)
is nonsingular.
A4
sup
h
|
S
(h)
1
|
is measurable and
E
sup
h
|
S
(h)
1
|

<
∞
.
A5
sup
h
|∇
2
h
S
(h)
1
|
is measurable and
E
sup
h
|∇
2
h
S
(h)
1
|

<
∞
.
A6
sup
h
|∇
h
f
h
|
is measurable and
E
(sup
h
|∇
h
f
h
|
)
<
∞
.
A7
sup
h
|∇
h
S
(h)
1
|

sup
h
|∇
h
S
(h)
1
|

⊤
is measurable and has finite expectation.
T
HEOREM
4 Suppose that
θ
1
, θ
2
, . . .
is a regenerative Markov chain with invariant
distribution
P
. Let
(2.10)
v
2
=
J
(
h
0
)
−1
τ
2
(
h
0
)
J
(
h
0
)
−1
.
1.
Under A1–A5
(2.11)
R
1/2
(
h
n
−
h
0
)
d
→ N
(0
, v
2
)
as
R
→ ∞
,
and consequently
(2.12)
n
1/2
(
h
n
−
h
0
)
d
→ N
0
, E
(
N
1
)
v
2

as
R
→ ∞
.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
13
2.
Under A1–A7,
for large
R
the matrix
J
n
(
h
n
)
is invertible,
and the variance
estimate
v
2
n
=

J
n
(
h
n
)

−1
τ
2
n
(
h
n
)

J
n
(
h
n
)

−1
is a strongly consistent estimate of
v
2
.
R
EMARK
4 In the expression for the asymptotic variance given by (2.10), the term
τ
2
(
h
0
)
is the variance of a certain function of the Markov chain,
and the term
J
(
h
0
)
−1
measures the inverse of the curvature of
B
at its maximum (
B
is a deter-
ministic function and does not involve the Markov chain): the flatter the surface
B
at its maximum, the higher is the asymptotic variance.
R
EMARK
5 The integrability condition in Assumption A4 was discussed in Re-
mark 1, where we showed that it is satisfied whenever there exist
h
1
, . . . , h
d
∈ H
such that
sup
h
|
f
h
(
θ
)
|
≤
P
d
j=1
|
f
h
j
(
θ
)
|
for all
θ
∈
Θ
(cf.
(2.6),
in which with-
out loss of generality we take the constants
c
j
to be equal to
1
.) The integrability
conditions in A5–A7 are satisfied under (2.13) and (2.14) below,
which are very
similar to (2.6). To make our explanation notationally less cumbersome and easier
to follow,
we will assume that
dim(
H
) = 1
,
so that
∇
h
S
(h)
1
,
∇
h
f
h
(
θ
)
,
∇
2
h
S
(h)
1
,
and
∇
2
h
f
h
(
θ
)
are all scalars. Assume that there exist
h
1
, . . . , h
d
∈ H
and constants
c
1
, . . . , c
d
such that
sup
h
|∇
h
f
h
(
θ
)
| ≤
d
X
j=1
c
j
|∇
h
f
h
j
(
θ
)
|
for all
θ
∈
Θ
,
(2.13)
sup
h
|∇
2
h
f
h
(
θ
)
| ≤
d
X
j=1
c
j
|∇
2
h
f
h
j
(
θ
)
|
for all
θ
∈
Θ
.
(2.14)
The integrability condition in A5,
E
sup
h
|∇
2
h
S
(h)
1
|

<
∞
, follows from (2.14)
using an argument identical to the one we used to show that the integrability con-
dition in A4 follows from (2.6). Clearly, A6 follows immediately from (2.13).
We now deal with A7 and consider
sup
h
|∇
h
S
(h)
1
|

2
= sup
h
∇
h
S
(h)
1

2
. Let
F
(
θ
) =
P
d
j=1
c
j
|∇
h
f
h
j
(
θ
)
|
, and let
T
1
denote the set of indices that comprise the
first tour. Since
∇
h
S
(h)
1
=
P
i∈T
1
∇
h
f
h
(
θ
i
)
, we have
|∇
h
S
(h)
1
| ≤
X
i∈T
1
|∇
h
f
h
(
θ
i
)
| ≤
X
i∈T
1
F
(
θ
i
)
,
where the second inequality is from (2.13). Therefore
∇
h
S
(h)
1

2
≤
P
i∈T
1
F
(
θ
i
)

2
,
and hence
(2.15)
sup
h
∇
h
S
(h)
1

2
≤
P
i∈T
1
F
(
θ
i
)

2
.
14
H. DOSS AND Y. PARK
Now by A2 and the Minkowski inequality,
E
P
F
2+ǫ
(
θ
)

<
∞
. This integrability
condition,
together with geometric ergodicity of the chain (cf. A1), enables us to
apply Theorem
2
of Hobert et al. (2002) to conclude that
E

P
i∈T
1
F
(
θ
i
)

2

<
∞
which, by (2.15), implies that
E

sup
h
∇
h
S
(h)
1

2

<
∞
, which is the integra-
bility condition in A7.
R
EMARK
6 To see why convergence statement (2.12) is a consequence of (2.11),
note that
n
=
P
R
r=1
N
r
, so
n/R
=
P
R
r=1
N
r

/R
a.s.
−→
E
(
N
1
)
. So from (2.11)
and Slutsky’s theorem,
we have
(
n/R
)
1/2
R
1/2
(
h
n
−
h
0
)
d
→ N
0
, E
(
N
1
)
v
2

,
which is statement (2.12).
R
EMARK
7 We now step back and put
Theorem 4 in the context
of frequentist
inference. We do not require that the number of components of our data vector
Y
goes to infinity,
or even that the components are iid.
We observe
Y
=
y
,
which
induces a marginal
likelihood surface
m
y
(
·
)
,
and Theorem 4 pertains to estima-
tion of this surface and its argmax,
with the asymptotics referring to the Markov
chain length
n
going to infinity.
In this regard,
it
is natural
to ask what
are the
frequentist
properties of inference based on this argmax.
A very general
result,
known as the Bernstein-von Mises Theorem,
asserts that under certain regularity
conditions,
if
Y
1
, Y
2
, . . .
are iid with distribution
Q
θ
0
, and if
ˆ
θ
m
is the maximum
likelihood estimate of
θ
based on
Y
(m)
= (
Y
1
, . . . , Y
m
)
,
then for any
h
∈ H
,
ν
h,y
(m)
−
φ
ˆ
θ
m
,i
−1
(θ
0
)/m
TV
m→∞
−→
0
,
[
Q
θ
0
]
-a.s.
Here,
φ
a,V
denotes the normal
distribution with mean vector
a
and covariance matrix
V
,
i
(
θ
)
is the Fisher infor-
mation at
θ
, and the subscript TV denotes total variation norm.
In particular,
the
usual Bayesian
95%
credible region coincides with the usual
95%
confidence re-
gion,
and therefore has asymptotic frequentist
coverage probability equal to
.
95
.
Theorem 1 of Petrone et al. (2014) goes further, and states that the Bernstein-von
Mises Theorem holds when we use
h
0
,
the maximum marginal
likelihood esti-
mate of
h
.
There are regularity conditions;
see Petrone et al.
(2014),
which also
contains references for precise statements of the Bernstein-von Mises Theorem.
To conclude,
if
n
is sufficiently large,
95%
credible sets based on
ν
h
n
,y
(m)
have
asymptotic frequentist coverage probability equal to
.
95
.
We now discuss the role of regenerative simulation in our development. Broadly
speaking, the
existence
of regenerative sequences is guaranteed under very general
conditions—here we note not only the distinguished point technique of Mykland et al.
(1995) mentioned earlier, but also the fact that for any chain satisfying our minimal
regularity condition of Harris ergodicity, there exists a
j
≥
1
such that there is a mi-
norizing pair
(
s, Q
)
for the
j
-step Markov transition function
K
j
(Meyn and Tweedie,
1993,
Section 5.2).
However,
it
is often very difficult
to construct
a
useful
mi-
norization condition, i.e. one that gives rise to regenerations that are frequent enough
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
15
so that law of large numbers and CLT approximations are valid for reasonable sam-
ple sizes.
If we do succeed in obtaining a useful regeneration sequence,
then we
can estimate variances and construct
confidence sets using the estimate given in
Part
2
of Theorem 4, and it is widely recognized that estimation of variances using
regeneration—when it is feasible—outperforms estimation using other methodolo-
gies (Flegal and Jones, 2010). Additionally,
it has the advantage that because we
start the chain at a regeneration point (i.e.
θ
1
∼
Q
), the issue of burn-in does not
even exist.
It is very interesting to note that we have used regenerative simulation in a the-
oretical manner: our proof of asymptotic normality of
n
1/2
(
h
n
−
h
0
)
(see (2.12))
requires only the existence of a regeneration sequence,
and does not require that
we go through a laborious trial and error process to construct one that is useful in
the practical sense. Very briefly, to obtain asymptotic results regarding
h
n
, we need
uniformity in the convergence of
B
n
to
B
. Empirical process theory gives us re-
sults on uniformity, but only in the iid setting, and regenerative simulation bridges
the gap between the Markov chain setting and the iid setting.
Once we have es-
tablished the asymptotic normality of
n
1/2
(
h
n
−
h
0
)
, we are free to estimate the
asymptotic variance and form confidence sets using other methods,
for example
batching, which we now discuss.
Batching is implemented by breaking up the sequence
θ
1
, . . . , θ
n
into
M
consec-
utive pieces of equal lengths called batches. For
m
= 1
, . . . , M
, batch
m
is used to
produce an estimate
h
[m]
n
in the obvious way. If
M
is fixed, then under the regularity
conditions of Theorem 4, (2.12) states that for each
m
,
(
n/M
)
1/2
(
h
[m]
n
−
h
0
)
d
→
N
(0
, σ
2
)
,
where
σ
2
=
E
(
N
1
)
v
2
.
If the batch length is large enough relative to
the “mixing time” of the chain,
then the
h
[m]
n
’s are approximately independent.
If the independence assumption was exactly true rather than approximately true,
then the sample variance of
(
n/M
)
1/2
h
[1]
n
, . . . ,
(
n/M
)
1/2
h
[M ]
n
would be a valid
estimator of
σ
2
. Standard theoretical results regarding batching deal with the sit-
uation in which
g
is a
P
-integrable function,
and the Markov chain
θ
1
, . . . , θ
n
is
used to estimate
R
g dP
via
(1
/n
)
P
n
i=1
g
(
θ
i
)
.
These results,
which assume that
n
1/2
(1
/n
)
P
n
i=1
g
(
θ
i
)
−
R
g dP

d
→ N
(0
, σ
2
(
g
))
, state that under regularity con-
ditions which include
M
→ ∞
at a certain rate, the batch-based estimate of
σ
2
(
g
)
is strongly consistent; see Flegal et al. (2008) and also Jones et al. (2006), who rec-
ommend using
M
=
n
1/2
. Our situation is different in that our estimate
h
n
is not
an average, but is the argmax of a function based on
θ
1
, . . . , θ
n
. Nevertheless, the
method applies, with the minor modification that when we form the “sample vari-
ance,” the centering value is based on
h
n
rather than on the average of the
h
[m]
n
’s.
As is clear from the description above, batch-based estimates of variance are very
easy to program. However, it is generally acknowledged that they are outperformed
16
H. DOSS AND Y. PARK
by estimates based on regeneration or spectral methods.
2.3.
Convergence of Estimate of Posterior Expectation.
This section concerns
the Bayesian framework discussed earlier,
in which
{
ν
h
, h
∈ H}
is a family of
prior densities on
θ
; for each
h
,
ν
h,y
is the posterior corresponding to
ν
h
;
h
1
∈ H
is fixed but arbitrary, and
θ
1
, θ
2
, . . .
is an ergodic Markov chain with invariant dis-
tribution
ν
h
1
,y
. Suppose that
g
is a real-valued function of
θ
and consider
I
g
(
h
) =
R
g
(
θ
)
ν
h,y
(
θ
)
dθ
, the posterior expectation of
g
(
θ
)
given
Y
=
y
, when the prior is
ν
h
. We have
(2.16)
1
n
n
X
i=1
g
(
θ
i
)
ν
h
(
θ
i
)
ν
h
1
(
θ
i
)
a.s.
−→
Z
g
(
θ
)
ν
h
(
θ
)
ν
h
1
(
θ
)
ν
h
1
,y
(
θ
)
dθ
=
m
y
(
h
)
m
y
(
h
1
)
I
g
(
h
)
,
in which the first equality follows from (1.2) and cancellation of the likelihood.
Therefore,
(2.17)
ˆ
I
g
(
h
)
:
=
(1
/n
)
P
n
i=1
g
(
θ
i
)[
ν
h
(
θ
i
)
/ν
h
1
(
θ
i
)]
(1
/n
)
P
n
i=1
[
ν
h
(
θ
i
)
/ν
h
1
(
θ
i
)]
a.s.
−→
[
m
y
(
h
)
/m
y
(
h
1
)]
I
g
(
h
)
m
y
(
h
)
/m
y
(
h
1
)
=
I
g
(
h
)
,
where the convergence of the numerator and the denominator in the expression for
ˆ
I
g
(
h
)
follow from (2.16) and (1.3), respectively.
In the original expression given
in (1.6),
ˆ
I
g
(
h
)
is a weighted average of the
g
(
θ
i
)
’s (with weights all equal to
1
/n
if
ν
h
=
ν
h
1
, and becoming more disparate as
ν
h
and
ν
h
1
become more dis-similar).
The definition of
ˆ
I
g
(
h
)
given in (2.17) clearly matches the original expression, so
we see that
ˆ
I
g
(
h
)
may be represented either as a weighted average or as a ratio
of two ordinary averages. To establish almost sure uniform convergence and func-
tional weak convergence results for
ˆ
I
g
(
h
)
, we will work with the latter represen-
tation, because doing so will enable us to use tools from empirical process theory.
With this in mind, recall that in the present framework
f
h
=
ν
h
/ν
h
1
. We will work
with the classes of functions
F
=
{
f
h
, h
∈ H}
and
G
=
{
gf
h
, h
∈ H}
. We will
later assume that the sequence
θ
1
, θ
2
, . . .
is a Markov chain satisfying certain con-
ditions, and Theorem 6 pertains to that case; however, in order to give an overview
of our results,
it is convenient
to first assume that the
θ
i
’s form an iid sequence:
θ
i
iid
∼
P
:
=
ν
h
1
,y
. Recall that
P
n
is the empirical measure that gives mass
1
/n
to
each of
θ
1
, . . . , θ
n
, and that for a signed measure
µ
and a function
f
,
µ
(
f
)
denotes
R
f dµ
. In the present specialized Bayesian context,
f
h
≥
0
; thus the
L
1
(
P
)
norm
of
f
h
is simply
R
f
h
dP
. Our goal is to establish that under certain conditions:
1.
We have the Glivenko-Cantelli results
sup
h∈H
|
(
P
n
−
P
)(
f
h
)
|
a.s.
−→
0
and
sup
h∈H
|
(
P
n
−
P
)(
gf
h
)
|
a.s.
−→
0
.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
17
2.
We have the “Donsker results”
(2.18)
n
1/2
(
P
n
−
P
)(
f
·
)
d
→
F
(
·
)
and
n
1/2
(
P
n
−
P
)(
gf
·
)
d
→
G
(
·
)
,
where
F
and
G
are mean
0
Gaussian processes indexed by
H
.
By applying the delta method to the function
q
(
u, v
) =
u/v
, we then obtain the
Glivenko-Cantelli and Donsker results
3.
sup
h∈H
|
ˆ
I
g
(
h
)
−
I
g
(
h
)
|
a.s.
−→
0
,
4.
(2.19)
n
1/2
ˆ
I
g
(
·
)
−
I
g
(
·
)

d
→
I
g
(
·
)
,
where
I
g
is a mean
0
Gaussian process indexed by
H
.
We now give some definitions we will
need in order to explain what
is meant
by (2.18) and (2.19). Define
X
n
=
n
1/2
(
P
n
−
P
)
. Let
V
be any set of real-valued
functions defined on
Θ
and let
l
∞
(
V
)
denote the space of bounded functions from
V
to
R
equipped with the supremum norm. Assume that
sup
V ∈V
|
V
(
θ
)
−
P
(
V
)
|
<
∞
for every
θ
∈
Θ
.
Under this condition the empirical
process
{
X
n
(
V
)
, V
∈ V}
can be viewed as
a map from
Θ
n
into
l
∞
(
V
)
. Any measurable function
Z
:
Θ
n
→
l
∞
(
V
)
induces
a distribution on
l
∞
(
V
)
.
Although the functions we will be working with will in
general be measurable,
in order to properly state the relevant definitions and the-
orems from empirical
process theory,
in our definitions we will deal
with func-
tions which are not necessarily measurable. For an arbitrary map
M
from an arbi-
trary probability space
(Ω
,
E
, µ
)
to the extended real line
¯
R
,
E
∗
(
M
)
denotes the
outer integral of
M
with respect to
µ
. (The outer integral is defined by
E
∗
(
M
) =
inf
{
R
Y dµ
:
Y
is
E
-measurable
, Y
≥
M
}
.) Suppose
Z
1
, Z
2
, . . .
and
Z
are maps
into
l
∞
(
V
)
, and that
Z
is measurable. We say that
Z
n
converges weakly to
Z
, and
we write
Z
n
d
→
Z
, if
E
∗
(
φ
(
Z
n
))
→
E
(
φ
(
Z
))
for every bounded, continuous, real
function
φ
on
l
∞
(
V
)
.
We now return to the empirical process
X
n
=
n
1/2
(
P
n
−
P
)
. A class
V
is called
a Donsker class if
X
n
d
→
X
in
l
∞
(
V
)
,
where the limit
X
is a mean
0
Gaussian
process with covariance function
Cov
X
(
V
1
)
, X
(
V
2
)

=
P
(
V
1
V
2
)
−
P
(
V
1
)
P
(
V
2
)
,
V
1
, V
2
∈ V
,
and has paths which are uniformly continuous with respect to the semi-metric
ρ
P
on
l
∞
(
V
)
defined by
ρ
2
P
(
f
1
, f
2
) = Var
P
f
1
(
θ
)
−
f
2
(
θ
)

. Sometimes we will say
V
is
P
-Donsker, to emphasize the dependence on
P
.
18
H. DOSS AND Y. PARK
We say that a class
V
of measurable functions
V
:
Θ
→
R
is
P
-measurable if
for every
n
and every vector
(
e
1
, . . . , e
n
)
∈
R
n
, the function
(
θ
1
, . . . , θ
n
)
7→
sup
V ∈V
n
X
i=1
e
i
V
(
θ
i
)
is measurable on the completion of
(Θ
n
,
B
n
, P
n
)
.
Because
F
and
G
are simply parametric families indexed by
h
∈ H
,
we will
slightly abuse terminology and take the two convergence statements in (2.18) to
mean
X
n
d
→
X
in
l
∞
(
F
)
and
X
n
d
→
X
in
l
∞
(
G
)
, respectively.
The limit
F
is a
mean
0
Gaussian process indexed by
h
∈ H
and covariance function
Cov
F
(
h
′
)
,
F
(
h
′′
)

=
P
(
f
h
′
f
h
′′
)
−
P
(
f
h
′
)
P
(
f
h
′′
)
for any
h
′
, h
′′
∈ H
.
Similarly,
G
is a mean
0
Gaussian process indexed by
h
∈ H
and covariance
function
Cov
G
(
h
′
)
,
G
(
h
′′
)

=
P
(
g
2
f
h
′
f
h
′′
)
−
P
(
gf
h
′
)
P
(
gf
h
′′
)
for any
h
′
, h
′′
∈ H
,
and we will discuss the covariance function of the limit
I
g
in (2.19) later. For
δ >
0
,
let
F
δ
=
{
φ
−
ψ
:
φ, ψ
∈ F
,
k
φ
−
ψ
k
P,2
< δ
}
and let
F
2
∞
=
{
ξ
2
:
ξ
∈ F
∞
}
.
Before we state the next theorem, we need to lay down preparations for its fourth
part, which regards functional weak convergence of the process
n
1/2
ˆ
I
g
(
·
)
−
I
g
(
·
)

.
Let
C
(
H
)
be the space of all continuous functions
x
:
H →
R
, with the topology
induced by the sup norm metric
ρ
:
for
x, y
∈
C
(
H
)
,
ρ
(
x, y
)
=
k
x
−
y
k
∞
=
sup
h
|
x
(
h
)
−
y
(
h
)
|
. Clearly, functional weak convergence of
n
1/2
ˆ
I
g
(
·
)
−
I
g
(
·
)

cannot take place in a space of the type
l
∞
(
V
)
for some set of functions
V
, and in
fact, as we will see, the weak convergence will take place in the space
C
(
H
)
. (As
usual,
if
µ
n
, n
= 1
,
2
, . . .
and
µ
are probability measures on
C
(
H
)
, we say that
µ
n
d
→
µ
if
R
Φ
dµ
n
→
R
Φ
dµ
for all functions
Φ :
C
(
H
)
→
R
which are bounded
and continuous.)
We now define the expression for the covariance function and give motivation
for its form. For any
h
′
, h
′′
∈ H
, the multivariate CLT states that
(2.20)




U
1
U
2
U
3
U
4




:
=
n
1/2




P
n
(
gf
h
′
)
−
P
(
gf
h
′
)
P
n
(
f
h
′
)
−
P
(
f
h
′
)
P
n
(
gf
h
′′
)
−
P
(
gf
h
′′
)
P
n
(
f
h
′′
)
−
P
(
f
h
′′
)




d
→ N
0
,
Σ(
h
′
, h
′′
)

,
where
Σ(
h
′
, h
′′
)
is the
4
×
4
matrix given by
Σ(
h
′
, h
′′
)
ij
= Cov(
U
i
, U
j
)
, i, j
=
1
,
2
,
3
,
4
.
Consider
the function
φ
:
R
4
→
R
2
defined by
φ
(
u
1
, u
2
, u
3
, u
4
)
=
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
19
(
u
1
/u
2
, u
3
/u
4
)
. Then, if we apply the delta method to (2.20) using
φ
, we get
(2.21)
n
1/2

ˆ
I
g
(
h
′
)
−
I
g
(
h
′
)
ˆ
I
g
(
h
′′
)
−
I
g
(
h
′′
)

d
→ N
0
, M
(
h
′
, h
′′
)

,
where
M
(
h
′
, h
′′
) = (
∇
φ
)
⊤
Σ(
h
′
, h
′′
)
∇
φ
,
and
∇
φ
(viewed as a
4
×
2
matrix) is
evaluated at the vector of means
P
(
gf
h
′
)
, P
(
f
h
′
)
, P
(
gf
h
′′
)
, P
(
f
h
′′
)

. The matrix
M
(
h
′
, h
′′
)
describes the covariance structure for the process
I
g
(
·
)
. (Expressions for
∇
φ
and
M
(
h
′
, h
′′
)
are given in Park (2015).)
T
HEOREM
5 Assume that
θ
1
, . . . , θ
n
are independent
and identically distributed
according to
P
.
1
(a)
Suppose that
f
·
(
·
) :
H ×
Θ
→
R
is continuous in
h
for
P
-almost
all
θ
.
If
sup
h∈H
f
h
is measurable and
R
sup
h∈H
f
h
dP <
∞
,
then
F
is
P
-
Glivenko-Cantelli.
(b)
Suppose that
(
gf
·
)(
·
) :
H ×
Θ
→
R
is continuous in
h
for
P
-almost all
θ
. If
sup
h∈H
|
gf
h
|
is measurable and
R
sup
h∈H
|
gf
h
|
dP <
∞
, then
G
is
P
-Glivenko-Cantelli.
2 Assume the conditions of Part
1
of the theorem, and also that for every
θ
∈
Θ
,
∇
h
f
h
exists and is continuous on
H
. Then
(2.22)
sup
h∈H
|
ˆ
I
g
(
h
)
−
I
g
(
h
)
|
a.s.
−→
0
.
3
(a)
Suppose that
the classes
F
,
F
δ
, δ >
0
,
and
F
2
∞
are all
P
-measurable.
Assume also that for
P
-almost all
θ
∈
Θ
,
∇
h
f
h
exists and is continuous on
H
. If (1)
sup
h∈H
k∇
h
f
h
k
is measurable and (2) the functions
f
h
, h
∈ H
and
sup
h∈H
k∇
h
f
h
k
are all square integrable with respect to
P
, then the
class
F
is
P
-Donsker.
(b)
Suppose that
the classes
G
,
G
δ
, δ
>
0
,
and
G
2
∞
are all
P
-measurable.
Assume also that for
P
-almost all
θ
∈
Θ
,
∇
h
(
gf
h
)
exists and is contin-
uous on
H
. If (1)
sup
h∈H
k∇
h
(
gf
h
)
k
is measurable and (2) the functions
gf
h
, h
∈ H
and
sup
h∈H
k∇
h
(
gf
h
)
k
are all square integrable with respect
to
P
, then the class
G
is
P
-Donsker.
4 Under the conditions of Part
3
of the theorem, we have
n
1/2
ˆ
I
g
(
·
)
−
I
g
(
·
)

d
→
I
g
(
·
)
in
C
(
H
)
,
where
I
g
is a Gaussian process indexed by
H
with mean
0
and covariance func-
tion
Cov(
I
g
(
h
′
)
,
I
g
(
h
′′
))
=
P
(
g
2
f
h
′
f
h
′′
)
−
P
(
gf
h
′
f
h
′′
)

P (gf
h
′′
)
P (f
h
′′
)
+
P (gf
h
′
)
P (f
h
′
)

+
P (gf
h
′
)P (gf
h
′′
)
P (f
h
′
)P (f
h
′′
)
P
(
f
h
′
f
h
′′
)
P
(
f
h
′
)
P
(
f
h
′′
)
.
20
H. DOSS AND Y. PARK
Part
1
(a) is,
of course,
simply a restatement
of Theorem 1; we have repeated
it here only to clarify the structure of our results. The
P
-measurability conditions
cannot be omitted. However, in all the problems we have encountered, the relevant
functions are not only measurable, but are actually continuous.
In Remark 8, which follows the statement of Theorem 6, we develop a construc-
tion of confidence bands for
I
g
(
·
)
and we explain why Theorem 6 shows that these
bands are valid globally. Theorem 6 pertains to Markov chains, but the same con-
struction and arguments can be applied to the iid case—we use Theorem 5 instead
of Theorem 6.
The next result is a version of Theorem 5 that applies to Markov chains. Recall
that
N
r
=
τ
r
−
τ
r−1
is the length of the
r
th
tour and that
S
(h)
r
is defined by (2.3).
Similarly, define
T
(h)
r
=
P
τ
r
−1
i=τ
r−1
g
(
θ
i
)
f
h
(
θ
i
)
, r
= 1
,
2
, . . .
. Let
F
=
{
S
(h)
1
, h
∈
H}
and
G
=
{
T
(h)
1
, h
∈ H}
.
Part
3
of Theorem 6 asserts that
under certain
conditions the classes
F
and
G
are Donsker, and before stating the theorem, it is
necessary to be very clear regarding what these classes are,
and what “Donsker”
means. Let
P
be the distribution of the Markov chain
θ
1
, θ
2
, . . .
. For any
h
∈ H
,
S
(h)
1
is a function mapping the measure space
(Θ
∞
,
B
∞
,
P
)
into
R
+
. To see this
it may be helpful
to imagine that we are dealing with the very simple case of a
regenerative chain which has an “proper atom” at a singleton. That is, there exists
a point
α
∈
Θ
which has positive probability under the invariant measure.
Thus,
with probability one the chain returns to
α
infinitely often, and the times of return
to
α
are regeneration times
τ
0
, τ
1
, τ
2
, . . .
.
In this case (with probability one) the
sequence
θ
1
, θ
2
, . . .
itself determines
τ
0
and
τ
1
. Then,
S
(h)
1
: Θ
∞
→
R
+
is defined
by
S
(h)
1
(
θ
1
, θ
2
, . . .
) =
P
τ
1
−1
i=τ
0
f
h
(
θ
i
)
,
and we have a similar definition for
T
(h)
1
.
Chains which have a proper atom at a singleton are quite rare,
and we consider
them only for exposition. We remark on the case of a general regenerative Markov
chain at the end of the proof of Theorem 6.
To clarify,
F
and
G
are classes of
functions on
Θ
∞
,
in contrast
to
F
and
G
,
which are classes of functions on
Θ
.
These classes will be
P
-Donsker, and we note that
P
is a distribution on the infinite
product space
Θ
∞
, to be distinguished from
P
, which is a distribution on
Θ
.
As we will see, Parts
3
and
4
of Theorem 6 are functional CLT’s that concerns
certain stochastic processes indexed by
h
∈ H
.
In order to motivate them,
we
need to first understand the version of these parts of the theorem that pertains to
the very simple situation in which we are considering a single value of
h
.
Thus,
let
h
∈ H
be fixed.
We now consider CLT’s for averages formed from the se-
quences
S
(h)
1
, S
(h)
2
, . . .
and
T
(h)
1
, T
(h)
2
, . . .
. We have
E
(
S
(h)
1
) =
E
P
(
f
h
(
θ
))
E
(
N
1
)
and
E
(
T
(h)
1
) =
E
P
(
g
(
θ
)
f
h
(
θ
))
E
(
N
1
)
(see (2.4)).
Under A1 and the conditions
E
P
(
f
2+ǫ
h
(
θ
))
<
∞
and
E
P
[(
gf
h
)
2+ǫ
(
θ
)]
<
∞
,
the expectations
E

(
S
(h)
1
)
2

,
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
21
E

(
T
(h)
1
)
2

,
and
E
(
N
2
1
)
are all finite (Theorem
2
of Hobert et al.
2002).
There-
fore, the simple multivariate CLT gives
(2.23)
R
1/2




P
R
r=1
T
(h)
r

/R
−
E
P
(
g
(
θ
)
f
h
(
θ
))
E
(
N
1
)
P
R
r=1
S
(h)
r

/R
−
E
P
(
f
h
(
θ
))
E
(
N
1
)
P
R
r=1
N
r

/R
−
E
(
N
1
)




d
→ N
(0
, V
h
)
,
where
V
h
= Cov (
T
(h)
1
, S
(h)
1
, N
1
)
⊤

. We apply the delta method to (2.23) three
times, using the functions
q
1
(
u, v, w
) =
v/w
,
q
2
(
u, v, w
) =
u/w
, and
q
3
(
u, v, w
) =
u/v
to obtain three CLT’s:
R
1/2
P
R
r=1
S
(h)
r
P
R
r=1
N
r
−
E
P
(
f
h
(
θ
))
!
d
→ N
0
,
(
∇
q
1
)
⊤
V
h
∇
q
1

,
R
1/2
P
R
r=1
T
(h)
r
P
R
r=1
N
r
−
E
P
(
g
(
θ
)
f
h
(
θ
))
!
d
→ N
0
,
(
∇
q
2
)
⊤
V
h
∇
q
2

,
R
1/2
P
R
r=1
T
(h)
r
P
R
r=1
S
(h)
r
−
I
g
(
h
)
!
d
→ N
0
,
(
∇
q
3
)
⊤
V
h
∇
q
3

.
(2.24)
With the relationships
n
=
P
R
r=1
N
r
,
P
R
r=1
S
(h)
r
=
P
n
i=1
f
h
(
θ
i
)
,
P
R
r=1
T
(h)
r
=
P
n
i=1
g
(
θ
i
)
f
h
(
θ
i
)
, and the fact that
n/R
a.s.
−→
E
(
N
1
)
, (2.24) may be restated as
n
1/2

P
n
i=1
f
h
(
θ
i
)
n
−
E
P
(
f
h
(
θ
))

d
→ N
0
, E
(
N
1
)(
∇
q
1
)
⊤
V
h
∇
q
1

,
n
1/2

P
n
i=1
g
(
θ
i
)
f
h
(
θ
i
)
n
−
E
P
(
g
(
θ
)
f
h
(
θ
))

d
→ N
0
, E
(
N
1
)(
∇
q
2
)
⊤
V
h
∇
q
2

,
n
1/2

P
n
i=1
g
(
θ
i
)
f
h
(
θ
i
)
P
n
i=1
f
h
(
θ
i
)
−
I
g
(
h
)

d
→ N
0
, E
(
N
1
)(
∇
q
3
)
⊤
V
h
∇
q
3

(2.25)
(with the understanding that here,
n
is random). Of course, under geometric ergod-
icity and the moment conditions
E
P
(
f
2+ǫ
h
(
θ
))
<
∞
and
E
P
[(
gf
h
)
2+ǫ
(
θ
)]
<
∞
,
asymptotic normality of the three quantities on the left
side of (2.25) is already
known (corollary to Theorem 18.5.3 of Ibragimov and Linnik 1971). The point of
obtaining (2.25) as we did above is that the method enables us to get functional
versions of the three statements in (2.25) (i.e. weak convergence of the three quan-
tities on the left side of (2.25) as processes in
h
) if we can show that the classes
F
and
G
are Donsker.
This is precisely what Part
3
of Theorem 6 asserts.
The
theorem will refer to the following conditions.
22
H. DOSS AND Y. PARK
B1
For every
h
∈ H
, there exists
ǫ >
0
such that
E
P
(
f
2+ǫ
h
(
θ
))
<
∞
.
B2
For every
h
∈ H
, there exists
ǫ >
0
such that
E
P
[(
gf
h
)
2+ǫ
(
θ
)]
<
∞
.
T
HEOREM
6 Assume that
θ
1
, θ
2
, . . .
is a Harris ergodic Markov chain with invari-
ant distribution
P
for which there exists a regeneration sequence
1 =
τ
0
< τ
1
<
τ
2
<
· · ·
satisfying
E
(
τ
1
−
τ
0
)
<
∞
.
1
(a)
Suppose that
f
·
(
·
) :
H×
Θ
→
R
is continuous in
h
for
P
-almost all
θ
. Sup-
pose also that
sup
h
S
(h)
1
is measurable and integrable. Then (2.5) holds.
(b)
Suppose that
(
gf
·
)(
·
) :
H ×
Θ
→
R
is continuous in
h
for
P
-almost all
θ
.
Suppose also that
sup
h
|
T
(h)
1
|
is measurable and integrable. Then in anal-
ogy with (2.5), we have
sup
h
1
n
n
X
i=1
g
(
θ
i
)
f
h
(
θ
i
)
−
E
P
(
g
(
θ
)
f
h
(
θ
))
a.s.
−→
0
.
2 Assume the conditions of Part
1
of the theorem, and also that for every
θ
∈
Θ
,
∇
h
f
h
exists and is continuous on
H
. Then
(2.26)
sup
h∈H
|
ˆ
I
g
(
h
)
−
I
g
(
h
)
|
a.s.
−→
0
.
3
(a)
Suppose that the classes
F
,
F
δ
, δ >
0
,
and
F
2
∞
are all
P
-measurable.
Suppose also that for almost all
θ
∈
Θ
,
∇
h
f
h
exists and is continuous on
H
. Under A1, B1, and the condition that
sup
h∈H
k∇
h
S
(h)
1
k
is measurable
and square integrable with respect to
P
, the class
F
is
P
-Donsker.
(b)
Suppose that the classes
G
,
G
δ
, δ >
0
, and
G
2
∞
are all
P
-measurable. Sup-
pose also that for almost all
θ
∈
Θ
,
∇
h
(
gf
h
)
exists and is continuous on
H
. Under A1, B2, and the condition that
sup
h∈H
k∇
h
T
(h)
1
k
is measurable
and square integrable with respect to
P
, the class
G
is
P
-Donsker.
4 Under the conditions of Part
3
of the theorem, we have
(2.27)
R
1/2
ˆ
I
g
(
·
)
−
I
g
(
·
)

d
→
I
∗
g
(
·
)
in
C
(
H
)
,
where
I
∗
g
is a Gaussian process indexed by
H
with mean
0
and covariance func-
tion
Cov
I
∗
g
(
h
′
)
,
I
∗
g
(
h
′′
)

=
h
P
S
(h
′
)
1

P
S
(h
′′
)
1

i
−1
"
P
T
(h
′
)
1
T
(h
′′
)
1

−
P
S
(h
′
)
1
T
(h
′′
)
1


P
(
T
(h
′′
)
1
)
P
(
S
(h
′′
)
1
)
+
P
(
T
(h
′
)
1
)
P
(
S
(h
′
)
1
)

+
P
(
T
(h
′
)
1
)
P
(
T
(h
′′
)
1
)
P
(
S
(h
′
)
1
)
P
(
S
(h
′′
)
1
)
P
S
(h
′
)
1
S
(h
′′
)
1

#
.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
23
Consequently,
(2.28)
n
1/2
ˆ
I
g
(
·
)
−
I
g
(
·
)

d
→
˜
I
g
(
·
)
in
C
(
H
)
,
where
˜
I
g
is a Gaussian process indexed by
H
with mean
0
and covariance func-
tion
Cov
˜
I
g
(
h
′
)
,
˜
I
g
(
h
′′
)

=
E
(
N
1
) Cov
I
∗
g
(
h
′
)
,
I
∗
g
(
h
′′
)

.
In (2.27)
ˆ
I
g
(
h
)
is interpreted as
ˆ
I
g
(
h
) =
P
R
r=1
T
(h)
r

/
P
R
r=1
S
(h)
r
, and the limit
is as
R
→ ∞
, whereas in (2.28)
ˆ
I
g
(
h
)
and the limit are interpreted differently:
ˆ
I
g
(
h
) =
P
n
i=1
g
(
θ
i
)
f
h
(
θ
i
)

/
P
n
i=1
f
h
(
θ
i
)
, and
n
=
P
R
r=1
N
r
is random.
R
EMARK
8 Here we discuss how to form globally valid confidence bands for
I
(
·
)
(we drop the subscript “
g
” to lighten the notation).
We would like to proceed as
follows.
Having established that
n
1/2
ˆ
I
(
·
)
−
I
(
·
)

d
→
˜
I
(
·
)
,
we find the distribu-
tion of
sup
h
|
˜
I
(
h
)
|
. If
s
α
is the
(1
−
α
)
-quantile of this distribution, then the band
ˆ
I
(
h
)
±
n
−1/2
s
α
has asymptotic coverage probability equal to
1
−
α
. Unfortunately,
except for very unusual cases,
the distribution of
sup
h
|
˜
I
(
h
)
|
cannot be obtained
analytically.
Spectral methods can be used for the problem of forming confidence
intervals for
I
(
h
)
for a single value of
h
, but not for the problem of forming con-
fidence bands.
We know of no way to use regenerative simulation to construct
confidence bands. However, the method of batching works, as follows.
For a positive integer
M
, the sequence
θ
1
, . . . , θ
n
is broken up into
M
consec-
utive pieces,
each of length
n/M
(we are ignoring divisibility issues).
For
m
=
1
, . . . , M
, let
ˆ
I
(m)
(
h
)
be the estimate of
I
(
h
)
based on batch
m
, and let
I
m
= sup
h

n
M

1/2
|
ˆ
I
(m)
(
h
)
−
ˆ
I
(
h
)
|
,
¯
I
m
= sup
h

n
M

1/2
|
ˆ
I
(m)
(
h
)
−
I
(
h
)
|
.
(The difference between
I
m
and
¯
I
m
is that the latter is not computable,
because
it involves the unknown function
I
(
·
)
.) Let
¯
I
[1]
≤
¯
I
[2]
≤ · · · ≤
¯
I
[M ]
be the order
statistics of the sequence
¯
I
1
, . . . ,
¯
I
M
and, similarly, let
I
[1]
≤ I
[2]
≤ · · ·
≤ I
[M ]
be the order statistics of the sequence
I
1
, . . . ,
I
M
. Now suppose that
M
→ ∞
in
such a way that
n/M
→ ∞
. Below is the outline of an argument which shows that
the band
ˆ
I
(
h
)
±
n
−1/2
I
[(1−α)M]
has coverage probability that is asymptotically
equal to
1
−
α
.
1.
For every
m
, we have
¯
I
m
d
→
sup
h
|
˜
I
(
h
)
|
by Theorem 6, and if the distribution
of
sup
h
|
˜
I
(
h
)
|
is continuous, then
¯
I
[(1−α)M]
converges in distribution to
δ
s
α
, the
point mass at
s
α
.
2.
Therefore the (uncomputable) band
ˆ
I
(
h
)
±
n
−1/2
¯
I
[(1−α)M]
has coverage prob-
ability that converges to
1
−
α
.
24
H. DOSS AND Y. PARK
3.
The difference between
I
m
and
¯
I
m
is small uniformly in
m
; more precisely, we
have
max
1≤m≤M
|I
m
−
¯
I
m
|
P
→
0
. Therefore the band
ˆ
I
(
h
)
±
n
−1/2
I
[(1−α)M]
also has coverage probability that converges to
1
−
α
.
Details are given in Park (2015).
R
EMARK
9 We have seen that for any
h
1
∈ H
, if
θ
1
, θ
2
, . . .
is a Markov chain with
invariant distribution
ν
h
1
,y
then, under certain regularity conditions, the estimates
B
n
(
h
)
and
ˆ
I
g
(
h
)
are consistent
and asymptotically normal.
These estimates can
be unstable,
however,
if
h
is far from
h
1
,
and there may not exist a single value
of
h
1
that gives rise to estimates that are stable for all
h
∈ H
.
Serial tempering
(Marinari and Parisi (1992); Geyer and Thompson (1995); see also Geyer (2011)
for a review,
and Tan (2014) for recent
developments) can be very effective in
handling this problem. A very brief description of the method in the present con-
text is as follows.
We select
m
points
h
1
, . . . , h
m
∈ H
; these should be taken to
“cover”
H
in the sense that every
h
in
H
is “close” to at least one of the
h
j
’s. Let
L
=
{
1
, . . . , m
}
; the elements of
L
are called “labels.” For each
j
∈ L
,
let
Φ
j
be a Markov transition function with invariant distribution
ν
h
j
,y
. A Markov chain
running on the state space
L ×
Θ
is generated as follows.
If the current state of
the chain is
(
j, θ
)
, a new label
j
′
is generated, and
θ
′
is generated from the distri-
bution
Φ
j
′
(
θ,
·
)
. The mechanism for generating the labels is set up in such a way
that the
θ
-sequence has invariant distribution
P
m
j=1
α
j
ν
h
j
,y
, where the
α
j
’s are all
nearly equal to
1
/m
. From the
θ
-sequence, the quantities
B
(
h
)
and
I
g
(
h
)
can be
estimated in a stable manner for any
h
which is “close” to at least one of the
h
j
’s,
or more precisely, for any
h
such that
ν
h
is “close” to at least one of
ν
h
1
, . . . , ν
h
m
.
The results of this paper do not require that the sequence
θ
1
, θ
2
, . . .
have invariant
distribution equal to
ν
h
1
,y
for some
h
1
∈ H
, and in fact the invariant distribution
can be a mixture
P
m
j=1
α
j
ν
h
j
,y
, for judiciously chosen
h
1
, . . . , h
m
, as described
above, for example.
3.
Illustrations.
Here we present two illustrations. The first deals with the so-
called Latent Dirichlet Allocation model, which is used for organizing and search-
ing electronic documents.
The version of the model
we discuss is indexed by a
two-dimensional
hyperparameter.
Our focus will
be on obtaining globally-valid
confidence sets for a certain posterior expectation of interest.
For the data set we
study,
the amount of time it takes to run the Markov chain is a significant
issue
because each cycle has length
7788
. We will use the results of Section 2.3 to deter-
mine the minimal Markov chain length that is needed to obtain acceptably narrow
confidence regions. The second illustration deals with a model for Bayesian vari-
able selection in linear regression. For this situation our interest will be on hyperpa-
rameter selection, and we will use the results of Section 2.2. We will see that for the
data set we use, a very modest Markov chain length is all that is needed to produce
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
25
narrow confidence sets for the empirical Bayes choice of the hyperparameters.
3.1.
Sensitivity Analysis in the Latent Dirichlet Allocation Model.
Probabilis-
tic topic modelling is an area of machine learning that
deals with methods for
understanding,
summarizing,
and searching large electronic archives.
Traditional
keyword-based searches are very fast, but have important deficiencies. Suppose we
are interested in searching for all statistical
papers that
deal with censored data.
A search using the keywords “censored data” will not return papers that use the
expression “incomplete data”. In topic-based searches, we do a search based on a
concept or topic. A topic is not an expression; it is, by definition, a distribution over
a set of expressions. Thus the topic mentioned above gives a lot of mass to expres-
sions like “Kaplan-Meier”, “censored data”, and “incomplete data”, and little mass
to expressions like “spectral decomposition”.
Latent Dirichlet Allocation (LDA, Blei et al. 2003) is by far the most used topic
model. We will consider the version of the model that deals only with individual
words,
as opposed to expressions consisting of several
words.
Suppose we have
a corpus of documents,
for example a set of articles from
The New York Times
,
and these span several different topics, such as sports, medicine, politics, etc. The
words in the documents come from a vocabulary
V
,
which is a set consisting of
V
words
u
1
, . . . , u
V
. For each document, the data we have for that document is a
sequence of length
V
consisting of the number of times that word
u
v
occurs,
for
v
= 1
, . . . , V
. In LDA, we imagine that for each word in each document, there is a
latent (i.e. unobserved) variable indicating a topic from which that word is drawn.
LDA enables us to make inference on these latent variables, and therefore, on the
topics that are covered by each document as a whole. Therefore, LDA enables us to
cluster together documents which are similar, i.e. documents which share common
topics. By its very nature, LDA is completely automatic in how it defines the topics:
these are distributions over the vocabulary, and are themselves latent variables. To
be more precise, in LDA there is no such thing as a topic called “sports”. Instead,
there is a distribution on
V
which gives most of its mass to words like “homerun”,
“marathon”,
and “NBA”. A human is then free to call this distribution “sports” if
he/she wishes.
We now give more detail. The vocabulary
V
is taken to be the union of all the
words in all the documents of the corpus, after removing uninformative words (like
“the” and “of”). There are
D
documents in the corpus, and for
d
= 1
, . . . , D
, doc-
ument
d
has
n
d
words,
w
d1
, . . . , w
dn
d
. The order of the words is viewed as unin-
formative, so is neglected. Each word is represented as an index
1
×
V
vector with
a
1
at the
s
th
element, where
s
denotes the term selected from the vocabulary. Thus,
document
d
is represented by the vector w
d
= (
w
d1
, . . . , w
dn
d
)
and the corpus is
represented by the vector w
= (
w
1
, . . . ,
w
D
)
. The number of topics,
K
, is finite
26
H. DOSS AND Y. PARK
and known. By definition, a topic is a point in
S
V
, the
(
V
−
1)
-dimensional simplex.
For
d
= 1
, . . . , D
, for each word
w
di
,
z
di
is an index
1
×
K
vector which represents
the latent variable that denotes the topic from which
w
di
is drawn. The distribution
of
z
d1
, . . . , z
dn
d
will depend on a document-specific variable
θ
d
which indicates a
distribution on the topics for document
d
. We will use
Dir
L
(
a
1
, . . . , a
L
)
to denote
the finite-dimensional Dirichlet distribution on the
L
-dimensional simplex.
Also,
we will use
Mult
L
(
b
1
, . . . , b
L
)
to denote the multinomial distribution with number
of trials equal to
1
and probability vector
(
b
1
, . . . , b
L
)
. We will form a
K
×
V
matrix
β, whose
t
th
row is the
t
th
topic (how β is formed will be described shortly). Thus,
β will consist of vectors
β
1
, . . . , β
K
, all lying in
S
V
. Formally, LDA is described
by the following hierarchical model, in which
η, α
∈
(0
,
∞
)
are hyperparameters:
1.
β
t
iid
∼
Dir
V
(
η, . . . , η
)
, t
= 1
, . . . , K
.
2.
θ
d
iid
∼
Dir
K
(
α, . . . , α
)
, d
= 1
, . . . , D
, and the
θ
d
’s are independent of the
β
t
’s.
3.
Given
θ
1
, . . . , θ
D
,
z
di
iid
∼
Mult
K
(
θ
d
)
, i
= 1
, . . . , n
d
, d
= 1
, . . . , D
, and the
D
vectors
(
z
11
, . . . , z
1n
1
)
, . . . ,
(
z
D1
, . . . , z
Dn
D
)
are independent.
4.
Given β and the
z
di
’s,
w
di
are independently drawn from the row of β indicated
by
z
di
, i
= 1
, . . . , n
d
, d
= 1
, . . . , D
.
From the model statement, we see that there is a latent topic variable for every
word that appears in the corpus. Thus it is possible that a document spans several
topics. However, because there is a single
θ
d
for document
d
, the model encourages
different words in the same document to have the same topic. Also note that the hi-
erarchical nature of LDA encourages different documents to share the same topics.
This is because β is chosen once, at the top of the hierarchy, and is shared among
the
D
documents. Let θ
= (
θ
1
, . . . , θ
D
)
, z
d
= (
z
d1
, . . . , z
dn
d
)
for
d
= 1
, . . . , D
,
z
= (
z
1
, . . . ,
z
D
)
, and let ψ
= (
β
,
θ
,
z
)
. The model is indexed by the hyperpa-
rameter vector
h
= (
η, α
)
. For any given
h
, lines
1
–
3
induce a prior distribution on
ψ, which we denote by
ν
h
. Line
4
gives the likelihood. The words w are observed,
and we are interested in
ν
h,w
, the posterior distribution of ψ given w correspond-
ing to
ν
h
.
The hyperparameter
h
has a strong effect on the distribution of the parameters of
the model. For example, when
η
is large, the topics tend to be probability vectors
which spread their mass evenly among many words in the vocabulary,
whereas
when
η
is small,
the topics tend to put most of their mass on only a few words.
Also,
when
α
is large,
each document tends to involve many different topics; on
the other hand, in the limiting case where
α
→
0
, each document involves a single
topic, and this topic is randomly chosen from the set of all topics.
In the literature,
the following choices for
h
= (
η, α
)
have been presented:
h
GS
= (0
.
1
,
50
/K
)
,
used in
Griffiths and Steyvers (2004);
h
A
= (0
.
1
,
0
.
1)
,
used
in Asuncion et al. (2009); and
h
RS
= (1
/K,
1
/K
)
, used in the Gensim topic mod-
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
27
elling package (
ˇ
Reh˚
uˇ
rek and Sojka, 2010), a well-known package used in the topic
modelling community. These choices are ad-hoc, and not based on any principle;
nevertheless, they do get used. Blei et al. (2003) propose
h
0
= arg max
h
m
w
(
h
)
,
as we do,
but their approach for estimating
h
0
is quite a bit different
from ours,
and involves a combination of the EM algorithm and “variational inference.” Very
briefly,
w is viewed as “observed data,” and ψ is viewed as “missing data.” Be-
cause the “complete data likelihood”
p
h
(
ψ
,
w
)
is available,
the EM algorithm is
a natural candidate for estimating
arg max
h
m
w
(
h
)
, since
m
w
(
h
)
is the “incom-
plete data likelihood.” But the E-step in the algorithm is infeasible because it re-
quires calculating an expectation with respect to the intractable distribution
ν
h,w
.
Blei et al.
(2003) substitute an approximation to this expectation.
Unfortunately,
because there are no useful bounds on the approximation, and because the approx-
imation is used at every iteration of the algorithm,
there are no results regarding
the theoretical properties of this method.
Determination of the hyperparameter is
currently an open problem in LDA modelling (Wallach et al., 2009).
We illustrate our methodology on a corpus of documents from the English Wiki-
pedia, originally created by George (2015). When a Wikipedia article is created, it
is typically tagged to one or more categories,
one of which is the “primary cate-
gory.” The corpus consists of
8
documents from the category
Leopardus
,
8
from the
category
Lynx
, and
7
from
Prionailurus
, and we took
K
= 3
, as in George (2015).
There are
303
words in the vocabulary, and the total number of words in the corpus
is
7788
. The data set is relatively small. However, it is challenging to analyze be-
cause the topics are very close to each other, so in the posterior distribution there
is a great deal of uncertainty regarding the latent topic indicator variables, and this
is why we chose this data set.
A reader of a given article may wish to look at related articles, so a question of
interest is whether the topics for two given documents are nearly the same.
One
way to word this question precisely is to ask what is the posterior probability that
k
θ
i
−
θ
j
k ≤
ǫ
, where
i
and
j
are the indices of the documents in question and
ǫ
is
some user-specified small number. Here,
k · k
denotes ordinary Euclidean distance.
This posterior probability will of course depend on
h
, and we would like to view
the estimates of the posterior probability as
h
varies, together with (simultaneous)
error margins.
To this end, we used the methodology developed in Section 2.3 for simultaneous
estimation of posterior expectations (here the posterior expectations of the indica-
tor of a set).
The warning given in Remark 9 regarding the high variance of the
simple single-chain estimate (1.3) applies,
and we use instead a serial tempering
chain (cf.
Remark 9),
the details of which are given in the next
paragraph.
We
consider documents
7
and
8
,
which are the articles “Pampas cat” and “Pantanal
cat” under the Wikipedia category Leopardus,
and we are interested in the poste-
28
H. DOSS AND Y. PARK
rior probability of the event
k
θ
7
−
θ
8
k ≤
.
05
. Our estimate of
arg max
h
m
w
(
h
)
is
h
n
= (
η
n
, α
n
) = (
.
915
, .
245)
, and the estimate of the posterior probability under
the empirical Bayes choice of
h
is
ν
h
n
,w
(
k
θ
7
−
θ
8
k ≤
.
05) =
.
7039
. For the other
choices of
h
we have
ν
h
GS
,w
(
k
θ
7
−
θ
8
k ≤
.
05) =
.
1619
,
ν
h
A
,w
(
k
θ
7
−
θ
8
k ≤
.
05) =
.
1498
, and
ν
h
RS
,w
(
k
θ
7
−
θ
8
k ≤
.
05) =
.
1298
, and we see that all three are far from
the estimate based on the empirical Bayes choice of
h
. We also calculated the ratio
of the marginal
likelihood of
h
n
to the marginal
likelihood of each of
h
GS
,
h
A
,
and
h
RS
and noted that each ratio is astronomically large. Therefore, none of these
values of
h
are deemed even remotely plausible, and as these choices of
h
do not
have any theoretical basis, there is no credibility to posterior probability estimates
based on them.
Figure 1 gives a plot of the estimate of
ν
h,w
(
k
θ
7
−
θ
8
k ≤
.
05)
,
together with a globally valid confidence set of level
.
95
over a relatively small
region centered at
h
n
. The figure shows that the posterior probabilities vary greatly
with
h
,
ranging from
.
553
to
.
972
,
even over a small
h
-region,
underscoring the
fact that the choice of hyperparameter should be made carefully.
Our serial tempering chain is based on the “augmented collapsed Gibbs sam-
pler” developed in George (2015), and which runs on the entire set of latent vari-
ables
(
β
,
θ
,
z
)
. A single cycle of this Markov chain runs over
7788
nodes. To form
the confidence region we used the construction described in Remark 8. We took the
grid size for the chain (“
m
” in Remark 8) to be
105
, with the
105
reference values
evenly spaced over the
h
-region. With this choice the chain gives very stable esti-
mates. The length of the chain was
500
,
000
, and the number of batches was
707
(roughly the square root of the chain length). With this chain length the confidence
region is adequately narrow, and with a length of only
50
,
000
it was not.
3.2.
Hyperparameter Choice for Bayesian Variable Selection in Linear Regres-
sion.
The most
commonly used setup for variable selection in Bayesian linear
regression is described as follows. We have a response vector
Y
= (
Y
1
, . . . , Y
m
)
⊤
and a set of potential predictors
X
1
, . . . , X
q
, each a vector of length
m
. Every sub-
set of predictors is identified with a binary vector
γ
= (
γ
1
, . . . , γ
q
)
⊤
∈ {
0
,
1
}
q
,
where
γ
j
= 1
if
X
j
is included in the model and
γ
j
= 0
otherwise. For every
γ
,
we have a model given by
Y
= 1
m
β
0
+
X
γ
β
γ
+
ǫ,
where
1
m
is the vector of
m
1
’s,
X
γ
is the design matrix whose columns con-
sist
of the predictor vectors corresponding to
γ
,
β
γ
is the vector of coefficients
for that
subset,
and
ǫ
∼ N
m
(0
, σ
2
I
)
.
For this setup,
the unknown parameter is
θ
= (
γ, σ, β
0
, β
γ
)
, which includes the indicator of the subset of variables that go
into the regression model.
The prior on
θ
is a hierarchy in which we first select
the variables that go into the regression model,
then a “non-informative prior” is
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
29
F
IG
1. Estimates with confidence region for I(h) = ν
h,w
(kθ
7
−θ
8
k ≤ .05), the posterior probability
that the topics for documents 7 and 8 of the Wikipedia corpus are “very close.” The plot shows that
this posterior probability varies considerably with h, and suggests that care be taken in choosing the
hyperparameter.
given to
(
σ
2
, β
0
)
,
and given
γ
and
σ
,
we choose
β
γ
from some proper distribu-
tion.
The specific instance of this model that we will consider is indexed by two
hyperparameters,
w
∈
(0
,
1)
and
g >
0
, and is given in detail as follows:
given
γ, σ, β
0
, β
γ
,
Y
∼ N
m
(1
m
β
0
+
X
γ
β
γ
, σ
2
I
)
,
(3.1a)
given
γ, σ,
β
γ
∼ N
q
γ
0
, gσ
2
(
X
⊤
γ
X
γ
)
−1

,
(3.1b)
(
σ
2
, β
0
)
∼
p
(
β
0
, σ
2
)
∝
1
/σ
2
,
(3.1c)
γ
∼
p
(
γ
) =
w
q
γ
(1
−
w
)
q−q
γ
.
(3.1d)
The prior on
γ
given by (3.1d) is the so-called independence Bernoulli
prior,
in
which every variable goes into the model
with probability
w
,
independently of
all the other variables.
In (3.1b),
q
γ
=
P
q
j=1
γ
j
is the number of predictors that
go in the regression,
and the prior on
β
γ
is Zellner’s
g
-prior (Zellner, 1986). Be-
cause
(
σ
2
, β
0
)
is given an improper prior (line (3.1c)), the prior on
θ
is improper;
however,
it turns out that the posterior distribution of
θ
is proper.
Models of the
type (3.1) were introduced by Mitchell and Beauchamp (1988) and have been stud-
ied in dozens of papers; see Liang et al. (2008) for a review.
The hyperparameter
h
= (
w, g
)
plays a critical
role:
if
w
is small
and
g
is
large,
the prior
ν
h
concentrates its mass on models with few variables and large
coefficients,
while if
w
is large and
g
is small,
ν
h
concentrates its mass on mod-
els with many variables and small coefficients.
(To appreciate the importance of
the role played by
h
, note that George and Foster (2000) have shown that for the
30
H. DOSS AND Y. PARK
slightly different version of (3.1) in which
σ
2
is assumed known,
h
can be chosen
so that the highest posterior probability model is exactly the best model under the
AIC/
C
p
, BIC, or RIC criteria.) Thus,
h
effectively determines the method that is
used to carry out variable selection, so it is important to choose it properly.
Unless
q
is relatively small (
q
less than
20
or
25
), the posterior distribution of
θ
= (
γ, σ, β
0
, β
γ
)
is intractable,
because to compute it we need to calculate
2
q
integrals (George and Foster, 2000). Smith and Kohn (1996) developed a Markov
chain algorithm which runs only on
γ
,
the other variables being integrated out.
Their chain is a simple Gibbs sampler which runs on the vector
(
γ
1
, . . . , γ
q
)
⊤
,
updating one component
at
a time.
This chain does not
fit
into our framework,
which requires a Markov chain that runs on
θ
= (
γ, σ, β
0
, β
γ
)
.
Buta (2010) de-
veloped a Markov chain,
based on the Smith and Kohn (1996) chain,
which runs
over
(
γ, σ, β
0
, β
γ
)
. (She proved that for her Markov chain, the rate of convergence
to the posterior distribution of
θ
is exactly the same as the rate of convergence to
the posterior distribution of
γ
for the Smith and Kohn (1996) chain, where conver-
gence is in terms of the absolute deviation norm.) We will use the chain developed
by Buta (2010) for the analysis below.
To implement the methods of this paper, we need a “ratio of densities
ν
h
1
/ν
h
2
”
(cf. equation (1.3)). Note that the prior distributions are not absolutely continuous
with respect to the product of counting measure on
{
0
,
1
}
q
and Lebesgue measure
on
(0
,
∞
)
×
R
+
×
R
q+1
(the dimension of
β
γ
is not fixed). The “ratio of densities
ν
h
1
/ν
h
2
” then needs to be replaced by the Radon-Nikodym derivative. To be pre-
cise, let
¯
ν
h
be the distribution on
θ
induced by (3.1d), (3.1c), and (3.1b). Then (1.3)
becomes
1
n
n
X
i=1

d
¯
ν
h
d
¯
ν
h
1

(
θ
i
)
a.s.
−→
Z

d
¯
ν
h
d
¯
ν
h
1

(
θ
) ¯
ν
h
1
,y
(
dθ
) =
m
y
(
h
)
m
y
(
h
1
)
.
The Radon-Nikodym derivative was obtained in Doss (2007) and is given by

d
¯
ν
h
1
d
¯
ν
h
2

(
θ
) =

w
1
w
2

q
γ

1
−
w
1
1
−
w
2

q−q
γ
×
φ
q
γ
β
γ
; 0
, g
1
σ
2
(
X
′
γ
X
γ
)
−1

φ
q
γ
β
γ
; 0
, g
2
σ
2
(
X
′
γ
X
γ
)
−1

,
where
φ
d
(
u
;
a, V
)
is the density of the
d
-dimensional
normal
distribution with
mean
a
and covariance
V
, evaluated at
u
.
For our illustration we consider the ragweed data of Stark et al.
(1997),
who
were interested in determining how meteorological variables can be used to fore-
cast ragweed pollen levels. The response variable is the ragweed level (grains/m
3
)
for
335
days in Kalamazoo, Michigan, USA. Although the data set contains other
predictors,
we restrict
our analysis to two:
day
(day number in the current
rag-
weed pollen season) and
wind
(wind speed forecast
in knots for following day).
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
31
Following Ruppert et al.
(2003),
we take the square root of the ragweed level as
the response. Figure 2 gives separate plots of the response versus each of the two
predictors. From the figure we see that the effect of
day
is certainly nonlinear, but
whether
wind
acts nonlinearly is not clear.
0
20
40
60
80
0
5
10
15
20
Day in season
Square root of ragweed level
0
5
10
15
0
5
10
15
20
Wind speed
Square root of ragweed level
F
IG
2. Scatterplots of response against each of two predictors for the ragweed data set.
We fit each of the two predictors nonparametrically via cubic regression splines
involving
10
equally spaced knots. Hence the model we use has the form
Y
i
=
β
0
+
α
1
day
i
+
α
2
day
2
i
+
α
3
day
3
i
+
P
10
t=1
α
t+3
(
day
i
−
˜
d
t
)
3
+
+
β
1
wind
i
+
β
2
wind
2
i
+
β
3
wind
3
i
+
P
10
t=1
β
t+3
(
wind
i
−
˜
w
t
)
3
+
+
ǫ
i
,
for
i
= 1
, . . . ,
335
, where
˜
d
1
<
· · ·
<
˜
d
10
represent the knots for the
day
explana-
tory variable,
˜
w
1
<
· · ·
<
˜
w
10
the knots for the
wind
explanatory variable,
and
(
x
)
+
= max
{
0
, x
}
.
Note that there are
26
coefficients that could be set to
0
, of
which
20
correspond to knots along the domain of the two predictors. Our plan is
to carry out the following two steps:
1.
We form a point estimate and confidence region for
arg max
h
m
y
(
h
)
by running
a Markov chain.
2.
We estimate the posterior distribution of
θ
when the prior is
ν
h
n
, where
h
n
is
the estimate of
arg max
h
m
y
(
h
)
obtained in Step
1
, by running another Markov
chain.
For Step
1
we ran a Markov chain of length
40
,
000
,
using
h
1
= (
.
3
,
100)
,
from which we formed the surface
B
n
(
h
)
, shown on the left panel of Figure 3. The
argmax
of
the
surface
is
(
.
23
,
176)
,
and
the
95%
confidence
region
for
arg max
h
m
y
(
h
)
is the ellipse shown in the right panel of Figure 3.
For Step
2
,
we ran a new Markov chain, of length
10
5
. For this chain, the highest probability
model is the model which selects the variables
wind
,
day
2
,
day
3
,
(
day
−
˜
d
3
)
3
+
, and
32
H. DOSS AND Y. PARK
(
day
−
˜
d
5
)
3
+
.
Interestingly,
this model
is the same as the model
selected by the
lasso, when we choose the tuning parameter by cross-validation.
w
0.1
0.2
0.3
0.4
g
50
100
150
200
250
Estimate of m(h) up to constant
0.0
0.5
1.0
1.5
2.0
0.2280
0.2290
0.2300
175.5
176.0
176.5
177.0
w
g
F
IG
3. Left Panel: Estimate of the marginal likelihood m
y
(h) (up to a multiplicative constant). The
argmax is (w
n
, g
n
) = (.23, 176), and the small value of w
n
suggests a sparse model. Right Panel:
Confidence region for arg max
h
m
y
(h).
The tight
region indicates that
the small
Markov chain
length used is adequate.
Let
E
denote the ellipse.
Our theory tells us that
we are
95%
confident
that
arg max
h
B
(
h
)
∈ E
, so we should run chains with posterior distributions
ν
h,y
, h
∈
E
, and determine the highest posterior probability models for all
h
∈ E
. By check-
ing a few points on the boundary of the ellipse,
we saw that the ellipse is narrow
enough so that the highest probability model is the same for all
h
∈ E
. Had this
not been the case, we would have run the Step
1
chain for more cycles, getting a
ellipse that is more narrow.
The value of
w
that is selected is small, which reflects sparsity: a small model is
adequate for fitting the data. We now put our approach in the context of the exist-
ing literature. Liang et al. (2008) review methods for selecting
g
in the version of
model (3.1) in which
w
is fixed at
1
/
2
. The literature has several data-independent
choices (e.g.
g
= max(
m, q
2
))
,
but
these generally do not
perform well.
As a
data-dependent
choice,
they propose
ˆ
g
= arg max
g
m
y
(
g
)
,
and to obtain it sug-
gest an EM algorithm in which the model indicator
γ
is viewed as missing data.
Unfortunately, the M-step in the algorithm involves a sum of
2
q
terms. Unless
q
is
relatively small, complete enumeration is not possible, and Liang et al. (2008) pro-
pose summing only over the most significant terms. However, determining which
terms these are may be very difficult in some problems. Our approach provides a
feasible way of obtaining the maximizer of the likelihood,
and this for the model
in which both
w
and
g
are unknown.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
33
APPENDIX.
Proof of Theorem 2.
In order to prove Theorem 2, we need a few definitions
and results from empirical process theory. An envelope
U
is any function satisfying
|
V
|
≤
U
for all
V
∈ V
.
For example,
sup
h∈H
f
h
is an envelope for the class
F
=
{
f
h
, h
∈ H}
.
D
EFINITION
1 (Definition 2.7 of Pakes and Pollard (1989))
We say that the class
F
is Euclidean for the envelope
F
if there exist positive constants
A
and
b
with the
following property: if
0
< ǫ
≤
1
and if
Q
is a measure for which
R
F dQ <
∞
,
then there are functions
f
1
, . . . , f
n
in
F
such that
1.
n
≤
Aǫ
−b
2.
The class
F
is covered by the union of the closed balls (in the
L
1
(
Q
)
metric)
with radius
ǫ
R
F dQ
and centers
f
1
, . . . , f
n
; in other words, for each
f
in
F
, there is an
f
i
, i
= 1
, . . . , n
, with
R
|
f
−
f
i
|
dQ
≤
ǫ
R
F dQ
.
The constants
A
and
b
may not depend on
Q
.
L
EMMA
2 (Lemma 2.8 of Pakes and Pollard (1989))
If
F
is Euclidean for the
envelope
F
and if
R
F dP <
∞
, then
k
P
n
−
P
k
F
converges to
0
almost surely.
L
EMMA
3 (Lemma 2.13 of Pakes and Pollard (1989))
Let
F
=
{
f
(
·
, h
) :
h
∈
H}
be a class of functions on
Θ
indexed by a bounded subset
H
of
R
k
.
If there
exist an
α >
0
and a nonnegative function
φ
(
·
)
such that
|
f
(
θ, h
)
−
f
(
θ, h
′
)
|
≤
φ
(
θ
)
k
h
−
h
′
k
α
for
θ
∈
Θ
and
h, h
′
∈ H
,
then
F
is a Euclidean class with the
envelope
F
(
·
)
=
|
f
(
·
, h
∗
)
|
+
Mφ
(
·
)
,
where
h
∗
is an arbitrary point
of
H
and
M
= (2
k
1/2
sup
H
k
h
−
h
∗
k
)
α
.
Proof of Theorem 2.
Recall that we have assumed that for almost all
θ
,
∇
h
f
h
(
θ
)
is continuous in
h
∈ H
, and that
H
is compact. Therefore, there exists a set
D
, with
P
(
D
) = 1
, such that for all
θ
∈
D
we have
sup
h
k∇
h
f
h
(
θ
)
k
<
∞
. For
θ
∈
D
and
any
h, h
′
∈ H
, we have
|
f
(
θ, h
)
−
f
(
θ, h
′
)
| ≤ k∇
h
f
h
(
θ
)
⌋
h=
˜
h(θ)
k k
h
−
h
′
k ≤
sup
h
k∇
h
f
h
(
θ
)
k k
h
−
h
′
k
,
where
˜
h
(
θ
)
lies between
h
and
h
′
.
Let
h
∗
be an arbitrary point
of
H
.
Define
F
: Θ
→
¯
R
as follows:
F
(
θ
) =
(
|
f
(
θ, h
∗
)
|
+
M
sup
h
k∇
h
f
h
(
θ
)
k
if
θ
∈
D,
∞
if
θ /
∈
D,
where
M
= 2
k
1/2
sup
h
k
h
−
h
∗
k
. By Lemma 3 with
φ
(
θ
) = sup
h
k∇
h
f
h
(
θ
)
k
and
α
= 1
,
F
is Euclidean with envelope
F
. We have
Z
F dP
=
Z
D
F dP
+
Z
D
c
F dP
=
Z
D
|
f
h
∗
|
dP
+
M
Z
D
sup
h
k∇
h
f
h
k
dP <
∞
,
34
H. DOSS AND Y. PARK
since
R
f
h
dP <
∞
for any
h
∈ H
, and
R
sup
h
k∇
h
f
h
k
dP <
∞
by assumption.
Therefore, by Lemma 2,
k
P
n
−
P
k
F
converges to
0
almost surely, i.e. the class
F
is
P
-Glivenko-Cantelli.
Proof of Lemma 1.
Denote
h
0
= arg max
h
f
(
h
)
and
h
n
= arg max
h
f
n
(
h
)
.
Let
ǫ >
0
and let
B
ǫ
h
0
be the open ball centered at
h
0
and with radius
ǫ
. Since
h
0
is
the unique maximizer of
f
, for any
h /
∈
B
ǫ
h
0
,
f
(
h
)
< f
(
h
0
)
, and since
H
\
B
ǫ
h
0
is
compact,
f
achieves its maximum on
H
\
B
ǫ
h
0
, say at
h
∗
, i.e.
sup
h∈H\B
ǫ
h
0
f
(
h
) =
f
(
h
∗
)
< f
(
h
0
)
.
Let
δ
=
f
(
h
0
)
−
f
(
h
∗
)
.
By uniform convergence,
there exists
n
0
such that for all
n
≥
n
0
,
sup
h
|
f
n
(
h
)
−
f
(
h
)
|
< δ/
2
, and in particular, for all
n
≥
n
0
, f
n
(
h
0
)
> f
(
h
0
)
−
δ/
2
. We have
(A.1)
f
n
(
h
n
)
≥
f
n
(
h
0
)
> f
(
h
0
)
−
δ/
2
.
At the same time, for all
n
≥
n
0
, f
n
(
h
)
< f
(
h
) +
δ/
2
for all
h
∈
H
\
B
ǫ
h
0
. Now
if
h
n
was in
H
\
B
ǫ
h
0
, we would have
f
n
(
h
n
)
< f
(
h
n
) +
δ/
2
≤
f
(
h
∗
) +
δ/
2 =
f
(
h
0
)
−
δ
+
δ/
2 =
f
(
h
0
)
−
δ/
2
,
which contradicts (A.1). Therefore, we conclude that
h
n
∈
B
ǫ
h
0
.
Proof of Theorem 4.
Proof of Part 1.
Recall that
n
=
τ
R
is the total number of
cycles required to achieve
R
regenerations, and note that
R
→ ∞
implies
n
→ ∞
.
We expand
∇
h
B
n
(
h
n
)
around
h
0
:
∇
h
B
n
(
h
n
) =
∇
h
B
n
(
h
0
) +
∇
2
h
B
n
(
h
∗
)(
h
n
−
h
0
)
,
where
h
∗
is between
h
n
and
h
0
. Since
∇
h
B
n
(
h
n
) = 0
and
∇
h
B
(
h
0
) = 0
, we have
R
1/2
(
h
n
−
h
0
) =
− ∇
2
h
B
n
(
h
∗
)

−1
R
1/2
∇
h
B
n
(
h
0
)
=
− ∇
2
h
B
n
(
h
∗
)

−1
R
1/2
∇
h
B
n
(
h
0
)
− ∇
h
B
(
h
0
)

.
Our plan is to show that
∇
2
h
B
n
(
h
∗
)
a.s.
−→
J
(
h
0
)
and that
(A.2)
R
1/2
∇
h
B
n
(
h
0
)
− ∇
h
B
(
h
0
)

d
→ N
(0
, τ
2
(
h
0
))
,
as this will prove the theorem. To show
∇
2
h
B
n
(
h
∗
)
a.s.
−→
J
(
h
0
)
, we first note that
(A.3)
k∇
2
h
B
n
(
h
∗
)
−∇
2
h
B
(
h
0
)
k ≤ k∇
2
h
B
n
(
h
∗
)
−∇
2
h
B
(
h
∗
)
k
+
k∇
2
h
B
(
h
∗
)
−∇
2
h
B
(
h
0
)
k
.
Since all the conditions of Theorem 3 are satisfied,
sup
h
|
B
n
(
h
)
−
B
(
h
)
|
a.s.
−→
0
,
which by Lemma 1 entails
h
n
a.s.
−→
h
0
,
so by continuity of
∇
2
h
B
(
h
)
at
h
0
,
we
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
35
conclude that
the second term on the right
side of (A.3) converges to
0
almost
surely.
We now consider the first term on the right side of (A.3) and we use arguments
similar to those used in the proof of Theorem 3 to show that this term converges to
0
almost surely. For any
h
∈ H
,
∇
2
h
B
n
(
h
)
− ∇
2
h
B
(
h
) =
P
R
r=1
∇
2
h
S
(h)
r

/R
P
R
r=1
N
r

/R
− ∇
2
h
E
P
(
f
h
(
θ
))
=
P
R
r=1
∇
2
h
S
(h)
r

/R
P
R
r=1
N
r

/R
−
E
P
∇
2
h
f
h
(
θ
)

=
P
R
r=1
∇
2
h
S
(h)
r

/R
P
R
r=1
N
r

/R
−
E
(
N
1
)
E
P
∇
2
h
f
h
(
θ
)

E
(
N
1
)
,
(A.4)
where the second equality in (A.4) follows by assumption (2.9). By A5, Theorem 1
implies that
sup
h
1
R
R
X
r=1
∇
2
h
S
(h)
r
−
E
(
N
1
)
E
P
∇
2
h
f
h
(
θ
)

a.s.
−→
0
,
and since
(1
/R
)
P
R
r=1
N
r
a.s.
−→
E
(
N
1
)
, we obtain
sup
h
P
R
r=1
∇
2
h
S
(h)
r

/R
P
R
r=1
N
r

/R
−
E
(
N
1
)
E
P
∇
2
h
f
h
(
θ
)

E
(
N
1
)
a.s.
−→
0
,
i.e.
sup
h
|∇
2
h
B
n
(
h
)
− ∇
2
h
B
(
h
)
|
a.s.
−→
0
. This shows that the first term on the right
side of (A.3) converges to
0
almost surely, which now implies that
k∇
2
h
B
n
(
h
∗
)
−
∇
2
h
B
(
h
0
)
k
a.s.
−→
0
. Therefore,
(A.5)
∇
2
h
B
n
(
h
∗
)
a.s.
−→ ∇
2
h
B
(
h
0
) =
J
(
h
0
)
.
We now consider the left side of (A.2). We have
R
1/2
∇
h
B
n
(
h
0
)
− ∇
h
B
(
h
0
)

=
R
1/2
P
R
r=1
∇
h
S
(h
0
)
r
P
R
r=1
N
r
−
E
P
(
∇
h
f
h
0
(
θ
))
!
=
R
1/2
P
R
r=1
N
r

/R

P
R
r=1
∇
h
S
(h
0
)
r
−
P
R
r=1
N
r
E
P
(
∇
h
f
h
0
(
θ
))
R

.
Now in view of
A1 and A2,
Theorem
2
of
Hobert et al.
(2002)
implies that
E
k∇
h
S
(h
0
)
1
k
2

<
∞
and
E
(
N
2
1
)
<
∞
.
Also,
P
R
r=1
N
r

/R
a.s.
−→
E
(
N
1
)
.
36
H. DOSS AND Y. PARK
Therefore,
by the CLT,
R
1/2
∇
h
B
n
(
h
0
)
− ∇
h
B
(
h
0
)

d
→ N
0
, τ
2
(
h
0
)

, and to-
gether with (A.5), this implies (2.11).
Proof of Part 2.
That
J
n
(
h
n
)
a.s.
−→
J
(
h
0
)
follows by an argument virtually identical
to the argument used to show that
∇
2
h
B
n
(
h
∗
)
a.s.
−→ ∇
2
h
B
(
h
0
) =
J
(
h
0
)
. Since
J
(
h
0
)
is nonsingular, we obtain

J
n
(
h
n
)

−1
a.s.
−→

J
(
h
0
)

−1
.
We now proceed to show that
τ
2
n
(
h
n
)
a.s.
−→
τ
2
(
h
0
)
, and we do this by working
with quantities
ρ
2
(
h
)
and
ρ
2
n
(
h
)
which are the same as
τ
2
(
h
)
and
τ
2
n
(
h
)
, respec-
tively, except that they do not include the terms
[
E
(
N
1
)]
−2
and
¯
N
−2
, respectively:
Define
ρ
2
(
h
) =
E


∇
h
S
(h)
1
−
N
1
E
P
(
∇
h
f
h
(
θ
))

∇
h
S
(h)
1
−
N
1
E
P
(
∇
h
f
h
(
θ
))

⊤

,
and
ρ
2
n
(
h
) =
1
R
R
X
r=1
∇
h
S
(h)
r
−
N
r
∇
h
¯
S
(h)
/
¯
N

∇
h
S
(h)
r
−
N
r
∇
h
¯
S
(h)
/
¯
N

⊤
.
We will show that
ρ
2
n
(
h
n
)
a.s.
−→
ρ
2
(
h
0
)
, which will show that
τ
2
n
(
h
n
)
a.s.
−→
τ
2
(
h
0
)
.
To show that
ρ
2
n
(
h
n
)
a.s.
−→
ρ
2
(
h
0
)
,
we express
ρ
2
n
(
h
n
)
−
ρ
2
(
h
0
)
as the sum of
four differences, and we show that each of these converges to
0
almost surely. As
in Remark 5,
we will assume that
dim(
H
) = 1
.
We do this only for notational
simplicity, as all our results and arguments are valid without this restriction.
The first difference is
D
1
:
= (1
/R
)
P
R
r=1
∇
h
S
(h
n
)
r

2
−
E

∇
h
S
(h
0
)
1

2

. Let-
ting
D
11
=
1
R
R
X
r=1
∇
h
S
(h
n
)
r

2
−
E

∇
h
S
(h
n
)
1

2

,
D
12
=
E

∇
h
S
(h
n
)
1

2

−
E

∇
h
S
(h
0
)
1

2
,
we have
|
D
1
|
≤ |
D
11
|
+
|
D
12
|
.
By A7,
Theorem 1 implies that
D
11
a.s.
−→
0
.
Consider now
D
12
.
Clearly
∇
h
S
(h
n
)
r

2
a.s.
−→ ∇
h
S
(h
0
)
r

2
.
By A7,
we may ap-
ply the dominated convergence theorem to conclude that
E

∇
h
S
(h
n
)
1

2

a.s.
−→
E

∇
h
S
(h
0
)
1

2

, i.e.
D
12
a.s.
−→
0
. Therefore
D
1
a.s.
−→
0
.
The second difference is
D
2
:
=
∇
h
¯
S
(h
n
)
¯
N
1
R
R
X
r=1
∇
h
S
(h
n
)
r
N
r
−
E
P
(
∇
h
f
h
0
(
θ
))
E
∇
h
S
(h
0
)
1
N
1

.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
37
We have
|
D
2
| ≤
∇
h
¯
S
(h
n
)
¯
N
1
R
R
X
r=1
∇
h
S
(h
n
)
r
N
r
−
E
P
(
∇
h
f
h
n
(
θ
))
E
∇
h
S
(h
n
)
1
N
1

+
E
P
(
∇
h
f
h
n
(
θ
))
E
∇
h
S
(h
n
)
1
N
1

−
E
P
(
∇
h
f
h
0
(
θ
))
E
∇
h
S
(h
0
)
1
N
1

:
=
|
D
21
|
+
|
D
22
|
,
in self-defining notation.
Consider
D
21
. From A7,
E
sup
h
|∇
h
S
(h)
1
|

<
∞
, and
together with the SLLN, this gives
∇
h
¯
S
(h
n
)
/
¯
N
−
E
∇
h
S
(h
n
)
1

/E
(
N
1
)
a.s.
−→
0
,
i.e.
(A.6)
∇
h
¯
S
(h
n
)
¯
N
−
E
P
(
∇
h
f
h
n
(
θ
))
a.s.
−→
0
.
Now
(A.7)
E

sup
h
|∇
h
S
(h)
1
N
1
|

≤

E


sup
h
|∇
h
S
(h)
1
|

2

E
(
N
2
1
)

1/2
by the Cauchy-Schwartz inequality. The first expectation on the right side of (A.7)
is finite by A7, and
E
(
N
2
1
)
<
∞
by Theorem
2
of Hobert et al. (2002). Therefore,
(A.8)
1
R
R
X
r=1
∇
h
S
(h
n
)
r
N
r
−
E
∇
h
S
(h
n
)
1
N
1

a.s.
−→
0
.
From (A.6)
and (A.8)
we see that
D
21
a.s.
−→
0
.
From A6 and finiteness
of
E
sup
h
|∇
h
S
(h)
1
N
1
|

, we may apply dominated convergence to see that
D
22
a.s.
−→
0
,
and so conclude that
D
2
a.s.
−→
0
.
Let
D
3
denote the third difference.
Since
D
3
=
D
2
, we have
D
3
a.s.
−→
0
also.
The fourth difference is
D
4
=

∇
h
¯
S
(h
n
)
¯
N

2
1
R
R
X
r=1
N
2
r
−

E
P
(
∇
h
f
h
0
(
θ
))

2
E
(
N
2
1
)
.
We showed earlier
that
∇
h
¯
S
(h
n
)
/
¯
N
a.s.
−→
E
P
(
∇
h
f
h
0
(
θ
))
.
The SLLN gives
(1
/R
)
P
R
r=1
N
2
r
a.s.
−→
E
(
N
2
1
)
(finiteness of
E
(
N
2
1
)
is a consequence of Theorem
2
of Hobert et al. (2002)). Therefore
D
4
a.s.
−→
0
.
Before we prove Theorem 5, we need to give some background material on em-
pirical processes. The Pollard-Koltchinskii Theorem (Pollard, 1982; Koltchinskii,
38
H. DOSS AND Y. PARK
1981), stated as Theorem 7 below, gives sufficient conditions for a class of func-
tions to be Donsker. In order to state it, we need to introduce additional terminol-
ogy. The covering number
N
(
ǫ,
V
,
k · k
)
is the minimum number of open balls of
radius
ǫ
using the norm
k · k
whose union covers the class
V
. In all of our devel-
opment
we will use the
L
1
norm or the
L
2
norm.
The uniform entropy integral
is
(A.9)
J
(
V
) =
Z
1
0
r
log sup
Q∈D
N ǫ
k
U
k
Q,2
,
V
, L
2
(
Q
)

dǫ,
where
D
is the set
of
all
finitely discrete probability measures on
(Θ
,
B
)
and
k
U
k
2
Q,2
=
R
U
2
dQ
.
T
HEOREM
7 (Theorem 8.19 in Kosorok (2008))
Let
F
be a class of measurable
functions with envelope
F
and for which
J
(
F
)
<
∞
.
Suppose that
the classes
F
δ
, δ >
0
and
F
2
∞
are all
P
-measurable. If
F
2
is measurable and integrable, then
F
is
P
-Donsker.
The condition
J
(
F
)
<
∞
in Theorem 7 can be verified by applying a simple
upper bound to the covering number (inequality (A.10)) and Lemma 4 below.
L
EMMA
4 Let
g
:
R
+
→
R
+
be a nonincreasing function.
Suppose that
g
(
ǫ
)
≤
Cǫ
−c
for some constants
C >
0
and
c >
0
. Then
R
1
0
p
log(
g
(
ǫ
))
dǫ <
∞
.
Proof of Lemma 4.
We have
log(
g
(
ǫ
))
≤
log(
C
) +
c
log(1
/ǫ
)
. Therefore
ǫ
log(
g
(
ǫ
))
≤
ǫ
log(
C
) +
c ǫ
log(1
/ǫ
)
→
0
as
ǫ
ց
0
.
This convergence implies that there exists
δ >
0
such that
ǫ
log(
g
(
ǫ
))
≤
1
when-
ever
ǫ
∈
(0
, δ
)
. Without loss of generality, we suppose that
δ <
1
. We have
Z
1
0
p
log(
g
(
ǫ
))
dǫ
=
Z
δ
0
p
log(
g
(
ǫ
))
dǫ
+
Z
1
δ
p
log(
g
(
ǫ
))
dǫ
≤
Z
δ
0
ǫ
−1/2
dǫ
+
Z
1
δ
p
log(
g
(
δ
))
dǫ
= 2
√
δ
+ (1
−
δ
)
p
log(
g
(
δ
))
<
∞
.
Let
V
be a set of functions defined on
Θ
with envelope
U
, let
p >
0
, and let
Q
be a probability measure on
Θ
. Suppose that
Q
(
U
p
)
<
∞
; we can then define the
norm on
V
given by
k
φ
k
Q,p,U
=

Q
(
|
φ
|
p
)
Q
(
U
p
)

1/p
.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
39
Suppose additionally that
V
is Euclidean for
U
,
and let
A
and
b
be the positive
constants appearing in the definition of Euclidean (Definition 1). If
ǫ
∈
(0
,
1]
and
p >
1
, then
(A.10)
N
(
ǫ,
V
,
k · k
Q,p,U
)
≤
A
(2
/ǫ
)
pb
(Nolan and Pollard, 1987, p. 789). We now return to the class
F
=
{
f
h
, h
∈ H}
.
In the proof of Theorem 2 we showed that if for
P
-almost all
θ
∈
Θ
,
∇
h
f
h
exists
and is continuous on
H
, then for any point
h
′
∈ H
the class
F
is Euclidean with
envelope
(A.11)
F
(
θ
) =
f
h
′
(
θ
) +
M
sup
h∈H
k∇
h
f
h
(
θ
)
k
,
where
M
= 2
k
1/2
sup
h∈H
k
h
−
h
′
k
(recall that
k
is the dimension of
H
). Thus,
by (A.10) with
p
= 2
,
for
ǫ
∈
(0
,
1]
,
for any probability measure
Q
satisfying
Q
(
F
2
)
<
∞
we have
N
(
ǫ,
F
,
k · k
Q,2,F
)
≤
A
(2
/ǫ
)
2b
.
For any probability measure
Q
and
ǫ
∈
(0
,
1]
we have
N ǫ
k
F
k
Q,2
,
F
, L
2
(
Q
)

=
N
(
ǫ,
F
,
k · k
Q,2,F
)
≤
A
(2
/ǫ
)
2b
.
Therefore,
g
(
ǫ
)
:
= sup
Q∈D
N ǫ
k
F
k
Q,2
,
F
, L
2
(
Q
)

≤
A
(2
/ǫ
)
2b
,
so,
Lemma 4 with
C
=
A
2
2b
and
c
= 2
b
gives
R
1
0
p
log(
g
(
ǫ
))
dǫ <
∞
, i.e. the
condition
J
(
F
)
<
∞
in Theorem 7 is satisfied. We summarize this in the following
theorem.
T
HEOREM
8 If for
P
-almost all
θ
∈
Θ
,
∇
h
f
h
exists and is continuous on
H
, then
the class
F
is Euclidean with envelope
F
given by (A.11), and
J
(
F
)
<
∞
.
Proof of Theorem 5.
1.
Part (a) is a verbatim restatement
of Theorem 1 and Part (b) follows from
Theorem 1.
2.
In essence the result
is trivial:
for
P
-almost
every sequence
θ
1
, θ
2
, . . .
,
(1
/n
)
P
n
i=1
g
(
θ
i
)
f
h
(
θ
i
)
converges
to
P
(
gf
h
)
uniformly
in
h
and
(1
/n
)
P
n
i=1
f
h
(
θ
i
)
converges to
P
(
f
h
)
uniformly in
h
,
so in view of the
continuity of the function
q
(
u, v
) =
u/v
we have
(1
/n
)
P
n
i=1
g
(
θ
i
)
f
h
(
θ
i
)
(1
/n
)
P
n
i=1
f
h
(
θ
i
)
converges to
P
(
gf
h
)
P
(
f
h
)
uniformly in
h,
40
H. DOSS AND Y. PARK
which is assertion (2.22).
There is a detail
we need to check,
namely that
P
(
f
h
)
is bounded away from
0
. Now by assumption, for every
θ
,
∇
h
f
h
exists
and is continuous in
h
; so in particular,
for every
θ
,
f
h
is continuous in
h
.
Therefore,
P
(
f
h
)
is continuous in
h
by the dominated convergence theorem,
and since
H
is compact,
inf
h
P
(
f
h
)
>
0
.
3.
We will show that the class
F
is
P
-Donsker by checking the conditions of
Theorem 7. By Theorem 8, the class
F
is Euclidean with envelope
F
given
by (A.11), and
J
(
F
)
<
∞
. Equation (A.11) expresses
F
as a sum of two
functions,
f
h
′
and
M
sup
h∈H
k∇
h
f
h
k
. Since each of these is measurable and
square-integrable with respect to
P
, we may conclude that
F
2
is measurable
and integrable with respect to
P
. Therefore the conditions of Theorem 7 are
all satisfied, and we conclude that the class
F
is
P
-Donsker. The proof that
G
is
P
-Donsker is essentially identical.
4.
For
P
-almost every
θ
,
f
h
(
θ
)
is continuous in
h
, and as we saw in the proof
of Part 2 of the present theorem,
P
(
f
h
)
is continuous in
h
; so with probabil-
ity one,
n
1/2
(
P
n
(
f
h
)
−
P
(
f
h
))
∈
C
(
H
)
. Because
H
is compact,
C
(
H
)
⊂
l
∞
(
F
)
(a formal proof of this fact is given in Park (2015)). Therefore, weak
convergence of
n
1/2
(
P
n
(
f
h
)
−
P
(
f
h
))
in
l
∞
(
F
)
implies weak convergence
of
n
1/2
(
P
n
(
f
h
)
−
P
(
f
h
))
in
C
(
H
)
, where
C
(
H
)
is endowed with the sup
norm (cf. van der Vaart and Wellner, 1996, Theorem 1.3.10); i.e.
n
1/2
(
P
n
−
P
)(
f
·
)
d
→
F
(
·
)
in
C
(
H
)
,
where
F
(
·
)
is a mean
0
Gaussian process.
Simi-
larly,
n
1/2
(
P
n
−
P
)(
gf
·
)
d
→
G
(
·
)
in
C
(
H
)
, where
G
(
·
)
is a mean
0
Gaussian
process.
Define the map
Φ :
C
(
H
)
×
C
(
H
)
→
C
(
H
)
by
(Φ(
x, y
))(
h
) =
x
(
h
)
/y
(
h
)
where,
for definiteness,
we define
0
/
0 = 0
.
It
is not
hard to
check that
Φ
is Hadamard differentiable at the point
(
P
(
gf
·
)
, P
(
f
·
))
(for a
definition of Hadamard differentiability see, e.g., van der Vaart and Wellner
(1996, Section 3.9.1))—we use the fact
inf
h
P
(
f
h
)
>
0
, established in the
proof of Part
2.
The result
now follows from the functional
delta method
(van der Vaart and Wellner, 1996, Theorem 3.9.4).
Proof of Theorem 6.
1.
That (2.5) holds was demonstrated in the proof of Theorem 3, and the proof
of the corresponding statement
for the functions
gf
h
is completely analo-
gous.
2.
The proof of (2.26) is identical to the proof of Part 2 of Theorem 5.
3.
The proof is analogous to the proof of Part 3 of Theorem 5.
For Part (a),
we consider
S
(h)
1
and
F
instead of
f
h
and
F
, respectively.
Continuity in
h
of
∇
h
S
(h)
1
for almost all sequences
θ
1
, θ
2
, . . .
follows from continuity in
h
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
41
of
∇
h
f
h
for almost all
θ
∈
Θ
,
since with probability one,
S
(h)
1
is a finite
sum.
In addition,
by A1 and B1,
E
[(
S
(h)
1
)
2
]
<
∞
for each
h
∈ H
. Since
sup
h
k∇
h
S
(h)
1
k
is measurable and square integrable with respect
to
P
,
by
Part 3 of Theorem 5 we see that
the class
F
is
P
-Donsker.
The proof of
Part
(b) is virtually identical.
The only changes are that
we consider
gf
h
instead of
f
h
, and obtain finiteness of
E
[(
T
(h)
1
)
2
]
for all
h
∈ H
as a conse-
quence of A1 and B2.
4.
The proof is entirely parallel to that of Part 4 of Theorem 5.
Prior to the statement of Theorem 6,
we noted that when the chain has a proper
atom at a singleton, then the sequence
θ
1
, θ
2
, . . .
itself determines the regeneration
times
τ
0
, τ
1
, . . .
,
so that
S
(h)
1
can be viewed as a function mapping
Θ
∞
to
R
+
.
The minorization condition discussed in Section 2.1 (cf. (2.7)) determines the so-
called “split chain”
(
θ
1
, δ
1
)
,
(
θ
2
, δ
2
)
, . . .
, for which the set
Θ
×{
1
}
is a proper atom
(Nummelin, 1984, Section 4.4). The functions
S
(h)
1
, h
∈ H
may then be viewed
as maps
S
(h)
1
: (Θ
× {
0
,
1
}
)
∞
→
R
+
, and the situation is the same as the simple
situation described earlier.
Verification of Condition (2.6) for Exponential Families in Canonical Form.
We now show that if
f
h
=
ν
h
/ν
h
∗
for some fixed
h
∗
∈ H
, and if
{
ν
h
, h
∈ H}
is
an exponential family and
h
is the canonical parameter, then condition (2.6) holds.
It is clearly sufficient to show that
there exist
h
1
, . . . , h
d
∈ H
and constants
c
1
, . . . , c
d
such that
sup
h∈H
ν
h
(
θ
)
≤
d
X
i=1
c
i
ν
h
i
(
θ
)
for all
θ
∈
Θ
.
(A.12)
(In fact,
we can take
f
h
=
ν
h
/q
where
q
/
∈ {
ν
h
, h
∈ H}
.
So for example,
in-
stead of using a Markov chain with invariant distribution
ν
h
∗
,y
, we can use a se-
rial
tempering chain,
whose invariant
distribution is a mixture of the posteriors
ν
h
∗1
,y
, . . . , ν
h
∗m
,y
for
h
∗1
, . . . , h
∗m
∈ H
; see Remark 9.) Recall that
k
denotes the
dimension of
h
.
We will slightly abuse notation and write
ω
instead of
h
,
and
Ω
instead of
H
.
This is to avoid notational
clashes,
e.g.
writing
h
= (
h
1
, . . . , h
k
)
and at
the same time having
h
1
, . . . , h
d
∈ H
.
We assume that
the
ν
ω
’s form a
k
-parameter exponential family with dominating measure
µ
. Thus for
ω
∈
Ω
,
ν
ω
is a density with respect
to
µ
,
having the form
ν
ω
(
θ
)
= exp
P
k
i=1
ω
i
T
i
(
θ
)
−
A
(
ω
)

, where the
T
i
’s and
A
are real-valued functions.
The set of all
ω
such that
R
exp
P
k
i=1
ω
i
T
i
(
θ
)

dµ
(
θ
)
<
∞
is called the natural parameter space, and we as-
sume that
Ω
is a compact subset of the interior of the natural parameter space. It is
42
H. DOSS AND Y. PARK
well known that
A
(
ω
) = log
R
exp
P
k
i=1
ω
i
T
i
(
θ
)

dµ
(
θ
)

is infinitely differen-
tiable in the interior of the natural parameter space, and in particular is continuous
there.
We will prove (A.12) for the case
k
= 2
,
the case
k >
2
being no more
difficult.
When
k
= 2
,
we have
ω
= (
ω
1
, ω
2
)
.
We let
U
= exp

ω
1
T
1
(
θ
) +
ω
2
T
2
(
θ
)

for notational brevity. Without loss of generality we take the compact set
Ω
to be
[
ω
1l
, ω
1u
]
×
[
ω
2l
, ω
2u
]
. For any fixed
ω
∈
[
ω
1l
, ω
1u
]
×
[
ω
2l
, ω
2u
]
, we have
U
≤











exp

ω
1u
T
1
(
θ
) +
ω
2u
T
2
(
θ
)

if
T
1
(
θ
)
≥
0
and
T
2
(
θ
)
≥
0
,
exp

ω
1u
T
1
(
θ
) +
ω
2l
T
2
(
θ
)

if
T
1
(
θ
)
≥
0
and
T
2
(
θ
)
<
0
,
exp

ω
1l
T
1
(
θ
) +
ω
2u
T
2
(
θ
)

if
T
1
(
θ
)
<
0
and
T
2
(
θ
)
≥
0
,
exp

ω
1l
T
1
(
θ
) +
ω
2l
T
2
(
θ
)

if
T
1
(
θ
)
<
0
and
T
2
(
θ
)
<
0
.
Therefore,
U
≤
exp

ω
1u
T
1
(
θ
) +
ω
2u
T
2
(
θ
)

+ exp

ω
1u
T
1
(
θ
) +
ω
2l
T
2
(
θ
)

+ exp

ω
1l
T
1
(
θ
) +
ω
2u
T
2
(
θ
)

+ exp

ω
1l
T
1
(
θ
) +
ω
2l
T
2
(
θ
)

(A.13)
for all
θ
∈
Θ
. Let
c
= sup
ω∈Ω
exp[
−
A
(
ω
)]
, which is finite, since
A
is continuous
and
Ω
is compact. Let
c
1
=
c
exp[
A
(
ω
(1)
)]
, ω
(1)
= (
ω
1u
, ω
2u
)
,
c
2
=
c
exp[
A
(
ω
(2)
)]
, ω
(2)
= (
ω
1u
, ω
2l
)
,
c
3
=
c
exp[
A
(
ω
(3)
)]
, ω
(3)
= (
ω
1l
, ω
2u
)
,
c
4
=
c
exp[
A
(
ω
(4)
)]
, ω
(4)
= (
ω
1l
, ω
2l
)
.
By (A.13) we get
sup
ω∈Ω
ν
ω
(
θ
)
≤
c
1
ν
ω
(1)
(
θ
) +
c
2
ν
ω
(2)
(
θ
) +
c
3
ν
ω
(3)
(
θ
) +
c
4
ν
ω
(4)
(
θ
)
for all
θ
∈
Θ
.
Acknowledgments.
We thank the referees for their helpful comments.
References.
Asuncion, A., Welling, M., Smyth, P. and Teh, Y. W. (2009).
On smoothing and inference for topic
models.
In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence.
UAI ’09, AUAI Press, Arlington, Virginia, United States.
Berger, J. O. (1994).
An overview of robust Bayesian analysis (with discussion).
Test 3 5–124.
Blei, D. M.,
Ng, A. Y.
and Jordan, M. I.
(2003).
Latent
Dirichlet allocation.
Journal
of
Machine
Learning Research 3 993–1022.
Buta, E. (2010).
Computational Approaches for Empirical Bayes Methods and Bayesian Sensitivity
Analysis.
Ph.D. thesis, University of Florida.
Doss, C., Flegal, J. M., Jones, G. L. and Neath, R. C. (2014).
Markov chain Monte Carlo estimation
of quantiles.
Electronic Journal of Statistics 8 2448–2478.
Doss, H. (2007).
Bayesian model selection: Some thoughts on future directions.
Statistica Sinica 17
413–421.
MCMC APPROACH TO EMPIRICAL BAYES INFERENCE
43
Doss, H. and Tan, A. (2014).
Estimates and standard errors for ratios of normalizing constants from
multiple Markov chains via regeneration.
Journal
of the Royal Statistical Society,
Series B 76
683–712.
Flegal, J. M., Haran, M. and Jones, G. L. (2008).
Markov chain Monte Carlo: Can we trust the third
significant figure? Statistical Science 23 250–260.
Flegal, J. M. and Jones, G. L. (2010).
Batch means and spectral variance estimators in Markov chain
Monte Carlo.
The Annals of Statistics 38 1034–1070.
George, C. P.
(2015).
Latent Dirichlet Allocation: Hyperparameter Selection and Applications to
Electronic Discovery.
Ph.D. thesis, University of Florida.
George, E. I. and Foster, D. P. (2000). Calibration and empirical Bayes variable selection. Biometrika
87 731–747.
Geyer, C. J. (2011).
Importance sampling, simulated tempering, and umbrella sampling.
In Hand-
book of Markov Chain Monte Carlo (S. P. Brooks,
A. E. Gelman, G. L. Jones and X. L. Meng,
eds.). Chapman & Hall/CRC, Boca Raton, 295–311.
Geyer, C. J. and Thompson, E. A. (1995).
Annealing Markov chain Monte Carlo with applications
to ancestral inference.
Journal of the American Statistical Association 90 909–920.
Griffiths, T. L.
and Steyvers, M.
(2004).
Finding scientific topics.
Proceedings of
the National
Academy of Sciences 101 5228–5235.
Hobert, J. P., Jones, G. L., Presnell, B. and Rosenthal, J. S. (2002).
On the applicability of regenera-
tive simulation in Markov chain Monte Carlo.
Biometrika 89 731–743.
Ibragimov, I. A. and Linnik, Y. V. (1971).
Independent and Stationary Sequences of Random Vari-
ables.
Wolters-Noordhoff, Groningen.
Jones, G. L., Haran, M., Caffo, B. S. and Neath, R. (2006).
Fixed-width output analysis for Markov
chain Monte Carlo.
Journal of the American Statistical Association 101 1537–1547.
Kadane, J.
and Wolfson, L. J.
(1998).
Experiences in elicitation.
Journal
of the Royal Statistical
Society: Series D (The Statistician) 47 3–19.
Koltchinskii, V. I. (1981). On the central limit theorem for empirical measures. Theory of Probability
and Mathematical Statistics 24 71–82.
Kosorok, M. R.
(2008).
Introduction to Empirical
Processes
and Semiparametric Inference.
Springer, New York.
Levental, S. (1988).
Uniform limit theorems for Harris recurrent Markov chains.
Probability Theory
and Related Fields 80 101–118.
Liang, F.,
Paulo, R.,
Molina, G.,
Clyde, M. A.
and Berger, J. O.
(2008).
Mixtures of g-priors for
Bayesian variable selection.
Journal of the American Statistical Association 103 410–423.
Marinari, E. and Parisi, G. (1992).
Simulated tempering: A new Monte Carlo scheme.
Europhysics
Letters 19 451–458.
Meyn, S. P. and Tweedie, R. L. (1993).
Markov Chains and Stochastic Stability.
Springer-Verlag,
New York, London.
Mitchell, T. and Beauchamp, J. (1988).
Bayesian variable selection in linear regression.
Journal of
the American Statistical Association 83 1023–1036.
Mykland, P., Tierney, L. and Yu, B. (1995).
Regeneration in Markov chain samplers.
Journal of the
American Statistical Association 90 233–241.
Newton, M. and Raftery, A. (1994).
Approximate Bayesian inference with the weighted likelihood
bootstrap (with discussion).
Journal of the Royal Statistical Society, Series B 56 3–48.
Nolan, D. and Pollard, D. (1987).
U-Processes: Rates of convergence.
The Annals of Statistics 15
780–799.
Nummelin, E. (1984).
General Irreducible Markov Chains and Non-negative Operators.
Cambridge
University Press, London.
Pakes, A. and Pollard, D. (1989). Simulation and the asymptotics of optimization estimators. Econo-
metrica 57 1027–1057.
44
H. DOSS AND Y. PARK
Park, Y. (2015). A Markov Chain Monte Carlo Approach to Empirical Bayes Inference and Bayesian
Sensitivity Analysis via Empirical Processes.
Ph.D. thesis, University of Florida.
Petrone, S.,
Rousseau, J.
and Scricciolo, C.
(2014).
Bayes and empirical
Bayes:
do they merge?
Biometrika 101 285–302.
Pollard, D. (1982).
A central limit theorem for empirical processes.
Journal of the Australian Math-
ematical Society, Series A 33 235–248.
ˇ
Reh˚
uˇ
rek, R. and Sojka, P. (2010).
Software framework for topic modelling with large corpora.
In
Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. ELRA, Val-
letta, Malta.
Roy, V. and Hobert, J. P. (2007).
Convergence rates and asymptotic standard errors for MCMC al-
gorithms for Bayesian probit
regression.
Journal
of
the Royal
Statistical
Society,
Series B 69
607–623.
Ruppert, D., Wand, M. and Carroll, R. (2003).
Semiparametric Regression.
Cambridge University
Press, Cambridge.
Smith, M. and Kohn, R. (1996). Nonparametric regression using Bayesian variable selection. Journal
of Econometrics 75 317–343.
Stark, P. C.,
Ryan, L. M.,
McDonald, J. L.
and Burge, H. A.
(1997).
Using meteorologic data to
model and predict daily ragweed pollen levels.
Aerobiologia 13 177–184.
Sung, Y. J. and Geyer, C. J. (2007).
Monte Carlo likelihood inference for missing data models.
The
Annals of Statistics 35 990–1011.
Tan, A. and Hobert, J. P. (2009). Block Gibbs sampling for Bayesian random effects models with im-
proper priors: convergence and regeneration.
Journal of Computational and Graphical Statistics
18 861–878.
Tan, Z. (2014).
Self-adjusted mixture sampling and locally weighted histogram analysis.
Tech. rep.,
Technical Report, Department of Statistics, Rutgers University.
van der Vaart, A. W.
and Wellner, J. A. (1996).
Weak Convergence and Empirical Processes,
With
Applications to Statistics.
Springer-Verlag, New York.
Wallach, H. M., Murray, I., Salakhutdinov, R. and Mimno, D. (2009).
Evaluation methods for topic
models. In Proceedings of the 26th Annual International Conference on Machine Learning. ACM.
Wellner, J. (2005).
Empirical processes: Theory and applications.
URL https://www.stat.washington.edu/people/jaw/RESEARCH/TALKS/Delft/emp-proc-delft-big.pdf
Wolpert, R. L.
and Schmidler, S. C.
(2012).
α-stable limit laws for harmonic mean estimators of
marginal likelihoods.
Statistica Sinica 22 1233–1251.
Zellner, A.
(1986).
On assessing prior distributions and Bayesian regression analysis with g-prior
distributions.
In Bayesian Inference and Decision Techniques: Essays in Honor of
Bruno de
Finetti (P. K. Goel and A. Zellner, eds.). Elsevier, New York.
D
EPARTMENT OF
S
TATISTICS
U
NIVERSITY OF
F
LORIDA
G
AINESVILLE
, FL 32611
USA
E-
MAIL
: doss@stat.ufl.edu
D
EPARTMENT OF
B
IOSTATISTICS
MD A
NDERSON
C
ANCER
C
ENTER
H
OUSTON
, TX 77030
USA
E-
MAIL
: ypark3@mdanderson.org
