Proceedings of the Society for Computation in Linguistics
Volume 1
Article 10
2018
Modeling the Complexity and Descriptive
Adequacy of Construction Grammars
Jonathan Dunn
Illinois Institute of Technology, jdunn8@iit.edu
Follow this and additional works at: http://scholarworks.umass.edu/scil
Part of the Computational Linguistics Commons
This Paper is brought to you for free and open access by ScholarWorks@UMass Amherst. It has been accepted for inclusion in Proceedings of the
Society for Computation in Linguistics by an authorized editor of ScholarWorks@UMass Amherst. For more information, please contact
scholarworks@library.umass.edu.
Recommended Citation
Dunn, Jonathan (2018) "Modeling the Complexity and Descriptive Adequacy of Construction Grammars," Proceedings of the Society
for Computation in Linguistics: Vol. 1 , Article 10.
DOI: 10.7275/R59P2ZTB
Available at: http://scholarworks.umass.edu/scil/vol1/iss1/10
Modeling the Complexity and Descriptive Adequacy
of Construction Grammars
Jonathan Dunn
Illinois Institute of Technology
Dept. of Computer Science
jdunn8@iit.edu
Abstract
This paper uses the Minimum Description
Length paradigm to model
the complex-
ity of CxGs (operationalized as the encod-
ing size of a grammar) alongside their de-
scriptive adequacy (operationalized as the
encoding size of a corpus given a gram-
mar).
These two quantities are combined
to measure the quality of potential
CxGs
against
unannotated corpora,
supporting
discovery-device CxGs for English, Span-
ish, French, German, and Italian.
The re-
sults show (i) that these grammars provide
significant generalizations as measured us-
ing compression and (ii) that
more com-
plex CxGs with access to multiple levels
of representation provide greater general-
izations than single-representation CxGs.
1
Complexity and Descriptive Adequacy
Construction Grammars (CxGs;
Goldberg,
2006;
Langacker, 2008) operate at multiple levels of rep-
resentation (lexical, syntactic, and semantic) mak-
ing them potentially much more complex than
purely syntactic grammars.
This paper
models
both (i)
the computational
complexity of
CxGs
and (ii) their descriptive adequacy against unanno-
tated corpora using Minimum Description Length
(MDL). These two measures, complexity and de-
scriptive adequacy,
can be used together
as an
objective function for
measuring the quality of
CxGs:
the optimum grammar
balances
higher
descriptive adequacy against
lower
complexity.
Once we can measure the quality of a particular
grammar in reference to a corpus of observed lan-
guage use,
we can search until we find the opti-
mum grammar for that
corpus.
This paper uses
measures of complexity and descriptive adequacy
to learn CxGs for English,
Spanish,
French,
Ger-
man, and Italian.
The goal is not to examine the representational
capacity of CxGs in general because CxG is a fun-
damentally usage-based paradigm (Hopper, 1987;
Kay & Fillmore, 1999; Bybee, 2006).
This means
that
the general
capacity of
its grammars must
be weighted by their actual content:
how can we
model
the complexity of a specific CxG used to
describe a specific language, where that language
is represented by a specific observable corpus?
Previous computational
work on CxG (Steels,
2004;
Bryant,
2004;
Chang,
et al.,
2012;
Steels,
2012) has relied on introspection-based represen-
tations that require a linguist to determine the opti-
mum constructions by intuition.
From a linguistic
perspective, these representations are neither repli-
cable nor falsifiable and are unable to test hypothe-
ses about the mechanisms of emergence that map
from observed usage to learned generalizations.
From a computational perspective, these represen-
tations are not
scalable across domains and lan-
guages and are subject
to all
the constraints of
knowledge-based systems.
Other data-driven ap-
proaches (Wible & Tsao,
2010;
Forsberg,
et
al.,
2014) generate potential constructions but do not
evaluate the quality of competing CxGs as collec-
tions of constructions.
Section 2 discusses how CxGs are represented
and Section 3 considers interactions between dif-
ferent levels of representation.
Section 4 presents
Minimum Description Length as a joint measure
of complexity and descriptive adequacy suitable
for measuring grammar quality while Section 5
operationalizes
CxG encoding.
Section 6 de-
scribes the search algorithm for optimizing gram-
mar quality.
Section 7 describes a multi-lingual
experiment in measuring CxG complexity and de-
scriptive adequacy and Appendix A discusses con-
structions learned from the corpus of English.
81
Proceedings of the Society for Computation in Linguistics (SCiL) 2018, pages 81-90.
Salt Lake City, Utah, January 4-7, 2018
(1a) [
SLOT
1 —
SLOT
2 —
SLOT
3 —
SLOT
4]
(1b) [
NOUN
— “gave” —
(animate)
— “a hand”]
(1c) “Bill gave Peter a hand.”
(1d) [
NOUN
—
(transf er)
—
(animate)
—
NOUN
]
(1e) “Bill sent Peter a package.”
Table 1: Construction Notation and Examples
2
Representing CxGs
This section introduces the symbolic notation used
to represent CxGs and describes how these repre-
sentations are implemented.
The algorithm rec-
ognizes three distinct
types of representation as
atomic units in its descriptions:
Lexical represen-
tation consists of tokenized word-forms (in low-
ercase).
Syntactic representation consists of part-
of-speech categories (defined using the Universal
POS tagset, Petrov, et al., 2012, and computed us-
ing RDRPosTagger,
Nguyen,
et
al.,
2016).
Se-
mantic representation consists of clusters of dis-
tributionally similar words that
represent
seman-
tic domains and are computed using GenSim’s
implementation of word2vec (Rehurek & Sojka,
2010).
The embedding model
is trained using 1
billion words from web-crawled corpora for each
language (from the WAC corpora:
Baroni,
et al.,
2009;
and Aranea corpora:
Benko,
2014) using
skip-grams with 500 dimensions.
These embed-
dings are segmented into categorical domains us-
ing k-means clustering (
k = 100
).
The idea be-
hind these three types of representation is that
a
particular slot in a construction can be defined or
constrained at
the lexical,
syntactic,
or semantic
level.
These representations thus form the basic
alphabet of the algorithm.
Constructions are sequences containing a cer-
tain number of slots, as in (1a) with four individual
slots. Each construction is surrounded by brackets
and each slot within a construction is separated by
a dash (“—”). Each slot in a construction is repre-
sented or defined by constraints that govern which
units can occupy that slot.
Lexical constraints are
indicated using single quotes (e.g.,“gave” in 1b).
Syntactic constraints are indicated using part-of-
speech tags in uppercase (e.g.,
NOUN
in 1b).
Se-
mantic constraints are indicated within parenthe-
ses with the identifier
for
the semantic domain
(e.g.,
animate
in 1b).
Thus,
the construction in
(1b) describes the utterance in (1c) but not the ut-
terance in (1e); the construction in (1d) describes
the utterances in both (1c) and (1e).
This
provides
a good example of
the com-
plexity problem:
CxGs potentially have multi-
ple overlapping representations for any given sen-
tence.
The sentence in (1e),
for
example,
can
be represented by the construction in (1d),
in
which slots are defined by both syntactic con-
straints (i.e.,
NOUN
) and semantic constraints (i.e.,
animate
). CxGs can distinguish between (1e) and
its more idiomatic counterpart
(1c) using repre-
sentations such as (1d) and (1b).
The question,
however,
is how many of these item-specific or
idiomatic representations are needed in the gram-
mar:
each item-specific construction increases
grammar complexity.
In this paper, the term construction refers to the
grammatical
description (e.g.,
1b)
and the term
construct
refers to a member of the set
of utter-
ances which that construction represents (e.g.,1c).
For a given grammar,
the set
of constructions is
closed but
the set
of constructs is open.
A con-
struct or utterance can be represented by multiple
constructions:
representations like (1b)
that
are
more item-specific alongside representations like
(1d) that
are more schematic.
This leads to re-
lationships between constructions:
an inheritance
hierarchy in which (1b) is a child of (1d).
The
current implementation has three limitations in re-
spect to the ideal CxG: First,
constraints are lim-
ited to a single type of representation per slot. For
example,
if a slot
is constrained to the semantic
domain
animate
, any syntactic category could be
used to fill that slot. Second, although constituents
are able to fill
construction slots (i.e.,
“a hand”
can occupy a single slot as a single
NOUN
), larger
constructions such as (1d) cannot fill slots in other
constructions.
Third,
no relations are learned be-
tween constructions in the grammar (i.e.,
the in-
heritance hierarchy is not modeled).
In computational terms, each construction is an
array of slots.
Each slot is defined as a tuple that
contains two pointers:
first,
a pointer to the al-
phabet constraining that slot (i.e.,
lexical or syn-
tactic units) and,
second,
a pointer to a particular
82
unit within that alphabet (i.e., “a hand” or
NOUN
).
Constituents are allowed to fill slots.
This is ac-
complished using a context-free phrase structure
grammar containing rules such as
DETERMINER
—
NOUN
→
NOUN
that is learned during a syntax-only iteration de-
scribed in the next section.
The syntactic alpha-
bet,
then,
also supports pointers to complex se-
quences through this CFG: the construction points
to a
NOUN
and the CFG allows larger constituents
to be labeled as a single
NOUN
.
The current im-
plementation produces a context-free CxG.
3
Finding CxGs
In the experiments
that
follow,
each language
is represented by a large web-crawled corpus in
that language.
Its grammar is learned by search-
ing across potential
grammars,
each of which is
evaluated against
the corpus until
the optimum
grammar
is found (using a measure defined in
Section 4).
The search for the optimum gram-
mar
is conducting using a tabu search (Glover
1989, 1990a) with multi-unit association measures
(Dunn,
2017) used to sample potential
construc-
tions.
The main focus of this paper is on defining
the objective function: how can we know that one
grammar is better than another without evaluating
them against gold-standard annotations?
Three levels of
CxGs are learned:
The first
pass
operates
on only lexical
representations,
CxG
LEX
.
This identifies purely lexical construc-
tions:
sequences of lexical
items that
have been
fused together so that their internal structure can
be ignored. For example, “could be” and “will be”
are identified as single units when the algorithm is
applied to English. Later passes view these lexical
constructions as a single lexical item with a single
syntactic type.
The second pass operates on only syntactic rep-
resentations,
CxG
SY N
.
Syntactic constructions
are later used as phrase structure rules.
For ex-
ample, when applied to English the sequence
[
VERB
−
NOUN
]
is identified as a purely syntactic construction.
In
later
passes,
these sequences are converted into
constituents that
can be treated as a single unit.
The third pass operates on all levels of representa-
tion,
CxG
F ULL
. The grammar accumulates struc-
ture across these iterations in the sense that con-
structions output
from a previous pass become
atomic units in the current
pass.
This set-up al-
lows us to examine complexity and descriptive ad-
equacy across CxGs with access to different lev-
els of representation:
do we actually benefit from
more complex multi-level grammars?
4
Measuring Grammar Quality
This approach depends on the central
insight
of
MDL (Rissanen,
1978,
1986;
Gr
¨
unwald & Ris-
sanen,
2007):
a grammar is a method for encod-
ing observed linguistic utterances and the learner
is searching for
the smallest
adequate encoding
method.
Explanation here is a matter of predic-
tion:
can the grammar produce the utterances ob-
served in held-out test-sets? The optimum gram-
mar balances model complexity (the number and
type of
constructions in the grammar)
and the
amount of compression achieved when the model
is used to encode a test
corpus (c.f.,
Goldsmith,
2001;
2006).
The complexity of
the grammar
is balanced against its descriptive adequacy on a
held-out corpus. This is formalized in MDL as
MDL = min
G
{L
1
(G) + L
2
(D | G)}
This defines the optimum grammar as the one
which minimizes
the model
complexity,
repre-
sented by the encoding size of the grammar, plus
the size of the dataset
encoded by means of the
grammar.
Encoding size in MDL (here based on
the natural log) is further defined as
L
C
(X
n
) = −log
e
P (X
n
)
Methods for
calculating the encoding size of
CxGs are discussed below in Section 5.
An addi-
tional term,
L
3
(G)
, is sometimes used (Gr
¨
unwald
& Rissanen, 2007:
409) to control for the size of
the encoding required for the universal code used
to determine the size of
G
.
This term is often not
included in the MDL metric (it
is not
necessary
when evaluating models against one another).
It
will be necessary here, however, when measuring
grammar quality against the baseline of an unen-
coded test set. We are using the MDL principle as
a metric for model selection. One aspect of model
selection is confidence: to what degree is
G
A
bet-
ter than
G
B
? This is given by
|MDL(G
A
) − MDL(G
B
)|
83
Units Not Covered By 
Construction Are 
Encoded Per Usage 
CxG Model Size 
CONSTRUCTIONS
REGRET
Cost Per Usage
-log
e
(1/N
UNENCODED
) 
-log
e
(1/N
CONSTRUCTIONS
) 
Cost In Grammar 
Σ(Unit Encodings) 
Figure 1: Encoding Model
Higher values indicate a more significant differ-
ence between
G
A
and
G
B
(c.f., Gr
¨
unwald & Ris-
sanen,
2007:
411).
This measure of confidence
will be useful for evaluating the quality of gram-
mars against the baseline of an unencoded dataset.
We can refine this measure of confidence further
1 −
MDL(G
A
)
MDL(U)
This is the relative degree of compression ad-
justed so that
values close to 1 represent
higher
compression (
U
represents the size of
the data
without the grammar).
Thus,
if the MDL of
G
A
is 256 and the unencoded MDL,
U
,
is 927,
this
gives a compression of 0.7239 over the unencoded
baseline as a measure of grammar quality.
Neg-
ative values indicate that the grammar makes the
MDL metric worse,
an unlikely but
possible oc-
currence. This ratio measure is important because,
without it, the MDL metric and the significance of
the metric are both dependent on the encoding size
of a specific test set.
We are searching for the grammar with the low-
est MDL metric on a held-out test set, but we also
need to measure the amount
of variation across
restarts.
This provides a measure of stability:
a
restart is a search technique that restarts the search
for the optimum grammar from scratch on a dif-
ferent portion of the corpus in order to determine
if similar grammars are discovered. Let
G
k
be the
optimum grammar across restarts and
G
i...n
be the
set of all output grammars across restarts regard-
less of whether they are optimal.
The agreement
between the two grammars is
A
k
i
=
(k ∩ i)
(k ∪ i)
The significance of the difference between the
encoding quality of
k
and
i
relative to the encoding
quality of the optimum grammar is
M
k
i
= 1 −
|MDL(k) − MDL(i)|
MDL(k)
This is adjusted to make large differences closer
to 0 and small differences closer to 1. The stability
measure,
ST A(k)
, is
P
n
i=0
A
k
i
(M
k
i
)
n
This is the mean agreement between the current
grammar and the optimum grammar for all restarts
n
with each weighted so that more significant dif-
ferences in the MDL metric lower the agreement.
This is a joint
measure of
stability in grammar
content
and grammar quality,
with higher scores
(toward 1) indicating stable grammars and lower
scores (toward 0) indicating unstable grammars.
This section has used the Minimum Description
Length paradigm to develop measures of grammar
complexity (i.e,
L
1
) and descriptive adequacy (i.e.,
L
2
) that do not rely on gold-standard annotations.
This is important for two reasons: First, we do not
necessarily have gold-standard annotations for ev-
ery language and language variety we are inter-
ested in (i.e.,
CxGs are also subject to variation).
84
Second,
simply relying on gold-standard annota-
tions ignores the question we are most interested
in:
how do we know empirically that one gram-
mar is better than another?
5
Measuring the Encoding Size of CxGs
The MDL paradigm depends on the concept of en-
coding size to measure complexity and descriptive
adequacy:
how do we calculate this for CxGs?
The MDL metric contains three terms:
L
1
, or the
encoding size of the grammar;
L
2
, or the encoding
size of the corpus given the grammar; and
L
3
, or
the encoding size of the universal code necessary
for encoding
L
1
.
Additionally,
we need to deter-
mine the uncompressed encoding size of the cor-
pus to serve as a baseline for measuring the overall
rate of compression of competing grammars.
The basic encoding model,
shown in Figure 1,
has two top level categories composing its alpha-
bet:
Constructions
(representations within the
current
CxG),
and
Regret
(units not
described
by known constructions).
Each of these top-level
categories is assigned the same probability,
0.5,
and thus,
because encoding size is equivalent
to
−log
e
P (X
n
)
,
each comes with an initial encod-
ing size of 0.693 nats (where a nat is a bit based
on the natural logarithm).
The reason for separating these top-level cate-
gories is that each has a different number of units,
each of which is again assigned equal
probabil-
ity.
For example, if there are 1,000 constructions
in the grammar,
then each usage of a construc-
tion costs 0.693 nats (for indicating a construction)
and 6.907 nats (for pointing to a specific construc-
tion).
Rather than assume that each construction
in a given CxG is equally probable,
an alternate
approach is to assign probabilities to individual
constructions and use these to determine the cost
of encoding constructions on an individual basis.
This problem is left for future work.
Here,
con-
structions are distinguished from one another only
using (i) their relative complexity and (ii) the pro-
ductivity of the particular grammar they belong to.
The
Regret
category holds units in the cor-
pus that
are not
described by a construction in
the current grammar.
Each occurrence of a non-
construction unit
is encoded on-the-fly:
as the
number of undescribed units increases, the cost in
nats of encoding each occurrence also increases.
For example, if there are 1,000 undescribed units
the cost per unit is 0.693 nats plus 6.907 nats;
if
there are 10,000 undescribed units the cost per unit
is 0.693 nats plus 9.210 nats.
This cost is specific
to a given dataset,
not to a given model,
because
the cost
per undescribed unit
depends on the to-
tal
number of undescribed units.
It
is important
to note that each instance of a unit not described
by the grammar is stored in the
Regret
category
independently: this is a measure of model error.
If
the encoded dataset
were transmitted,
the
model itself would need to be encoded and trans-
mitted at
the same time in order
to decode the
dataset; this is the information-theory rationale be-
hind
L
1
,
the encoding size of the grammar.
In
linguistic terms,
grammars with larger encoding
sizes are more complex.
The
Regret
category
has already been encoded with unique pointers for
each undescribed unit;
thus,
it does not incur an
additional model cost.
The cost of encoding the
model, then, consists entirely of the cost of encod-
ing each construction it
contains:
the sum of all
unit-encoding costs for each slot-filler representa-
tion in the construction,
N
SLOT S
X
i
− log
e
(
1
N
R
i
) + −log
e
(
1
T
R
)
N
SLOT S
here is the number of slots in the con-
struction being encoded,
N
(R
i
)
is the number of
units available for a given representation type, and
T
R
is the number of representation types total for
the current grammar.
This is the total cost of en-
coding both (i) which representation type (alpha-
bet) fills the slot and (ii) which unit of that alpha-
bet fills the slot.
The full CxG has three representation types so
that, for this grammar type, the encoding size for
each slot
is 1.098 nats (the cost
of
encoding a
three-way distinction) plus
log
e
(1/N )
where
N
is
the total vocabulary of that unit type. Thus, if there
are 20,000 lexical items in the vocabulary, the cost
of encoding a construction with three lexically-
filled slots is 11.001 nats per slot or 33.003 nats
total.
This is a one-time encoding cost:
each oc-
currence of a construction is a pointer that incurs
the encoding cost described above.
The
Regret
category more properly belongs as
an added term in
L
2
, the size of the dataset as en-
coded by the grammar.
However,
in this case it
clarifies the discussion of grammar complexity to
show the impact that each unencoded unit has on
the MDL metric as a whole.
Note that the com-
plexity cost includes
L
3
or the cost of encoding the
85
UNCLASSIFIED
0
0.05
0.1
0.15
0.2
0.25
English
Spanish
French
Italian
German
Lexical
Syntactic
Full
Figure 2: Compression Rates Across Grammar Types
encoding size of the grammar.
In other words, in
order for each construction to be encoded we also
have to encode the lexicon of lexical,
syntactic,
and semantic units used in construction descrip-
tions.
This is included as part of the cost of each
construction in the grammar.
5.1
Maintaining Lossless Encoding
The data consists of atomic units from three types
of representation.
In order to maintain the gram-
mar as a lossless encoding of the corpus,
we de-
fine the task for
CxG
F ULL
as encoding one of
these representations for each unit.
Importantly,
this means that each unit needs to be represented
by only one type of representation in the decoded
version of the dataset; part of the learning task for
CxG
F ULL
is to choose the optimum type of rep-
resentation for each slot.
What lossless encoding
means,
in practice,
depends on the type of CxG.
For
CxG
LEX
lossless encoding means to return
the same word-forms but for
CxG
SY N
,
it means
to return the original sequence of parts-of-speech.
It is important that
CxG
SY N
is evaluated while
not
in Chomsky normal
form in order
to cor-
rectly encode the complexity of
the grammar.
Consider the individual
phrase structure rules in
(2a)
through (2c)
which map from a particu-
lar
sequence of
part-of-speech tags to a single
constituent
type.
For
CxG
SY N
internally each
sequence
is
a
construction (i.e.,
phrase
struc-
ture rules
are not
typed).
In the same way,
for
CxG
LEX
internally,
each sequence of word-
forms is not
typed (i.e.,
assigned to a part-of-
speech category).
Constructions
from each of
these passes need to be typed before filling slots
in later passes.
The part-of-speech tagger is used
to assign lexical
constructions to a single part-
of-speech.
An additional
algorithm (outside the
scope of this paper but available in the external re-
sources) converts
CxG
SY N
sequences into phrase
structure rules to support
the CFG that
allows
longer sequences to fill individual slots.
(2a)
DET
—
NOUN
→
NOUN
(2b)
NOUN
→
NOUN
(2c)
NOUN
—
NOUN
→
NOUN
The point
is that,
while the representations in
(2a)
through (2c)
do not
provide a lossless en-
coding of the observed utterances, the MDL met-
ric is not
applied to these representations but
to
their untyped forms (e.g.,
[
DET
—
NOUN
]).
The
CxG encoding system consists of
AtomicU nits
located within
Constructions
.
As the level
of
abstraction increases (i.e., as we go through mul-
tiple iterations),
members of
the
Construction
repository for
the
current
pass
become
mem-
bers of the
AtomicU nits
repository for the next
pass.
Thus,
lexical
constructions are considered
part
of
Constructions
in
CxG
LEX
but
part
of
AtomicU nits
in
CxG
SY N
.
The effect
of
this
is to maintain lossless encoding at
each level
of
abstraction while incorporating previously learned
representations into the next level of abstraction.
This means that grammar complexity is not di-
rectly comparable across iterations because each
iteration is encoding a different
level
of abstrac-
tion. For example, the task for
CxG
SY N
is to pro-
vide a lossless encoding of sequences of syntactic
units (out of an inventory of 14 unit types).
A rel-
atively small number of syntactic sequences will
be able to form phrase structure rules that,
taken
together,
provide a high rate of compression.
A
full CxG, however, must do much more than pre-
dict
sequences of syntactic units because it
also
incorporates lexical and semantic representations.
86
UNCLASSIFIED
0
0.2
0.4
0.6
0.8
1
English
Spanish
French
Italian
German
Lexical
Syntactic
Full
Figure 3: Stability Over Folds Across Grammar Types
On the other
hand,
though,
the full
MDL met-
ric is comparable across iterations because it bal-
ances complexity and descriptive adequacy:
does
the more complex
CxG
F ULL
provide enough de-
scriptive adequacy to justify incorporating multi-
ple types of representation?
6
Searching Over Potential CxGs
The search algorithm has three components:
(i)
randomly initializing the starting state, or what set
of constructions belongs in the initial
grammar;
(ii) an indirect tabu search (Glover,
1989,
1990a)
to move toward the optimum grammar by updating
construction sampling parameters;
and (iii) a di-
rect tabu search across constructions to determine
if small changes in the inventory of constructions
improves the quality of the current CxG.
The first
tabu search takes
a randomly ini-
tialized starting state and searches for improved
grammars by exploring different sampling param-
eters.
These parameters take a number of associ-
ation measures (c.f.,
Dunn,
2017) and use them
to determine which constructions belong in the
grammar.
The essential idea of tabu search is (i)
to define the set of possible moves from the cur-
rent grammar state to a new grammar state and (ii)
to combine tabu restrictions and aspiration crite-
ria to move the search toward promising areas of
the overall search space that are not directly reach-
able from the current state.
We divide the param-
eter space into
n
discrete values for each of the 30
direction-specific association measures,
with the
maximum and minimum values defined empiri-
cally.
This provides a finite set of possible moves
from any given state.
For each turn,
the algorithm generates a set of
possible moves and,
after evaluating each,
takes
the best available move even if it reduces the over-
all
grammar
quality.
Best
is defined using the
MDL-metric: the best move is that which provides
the smallest
MDL-metric of all
possible moves.
Available is defined as a move that is either (i) not
on the tabu list or (ii) satisfies an aspiration criteria
that overrules the tabu list. The tabu list is a short-
term memory item that contains the last
n
moves,
each represented using the association measures
that have been changed.
For practical reasons,
n
is set at 7 (c.f., Glover, 1990b); this means that for
any given turn the best move cannot involve a sam-
pling parameter that has been changed over the last
7 turns.
This prevents the algorithm from cycling
between local optima in an endless loop.
The as-
piration criteria used is that the grammar produced
by a move is not only the best available grammar
but also the best observed grammar: a new global
minimization of the MDL metric.
Thus,
the tabu
against
altering a recently changed sampling pa-
rameter can be overruled if that change creates a
new best
grammar.
The use of such an aspira-
tion criteria makes intuitive sense: the tabu search
is designed to prevent cycling between previously
visited states, but a grammar which reaches a new
global minimum has not previously been visited.
Three types of moves are available at each turn:
First, a parameter can be removed from the current
sampler (i.e.,
OFF
); this allows the tabu search to
eliminate sampling parameters that reduce gram-
mar quality.
Second, a parameter can be grouped
with
n
randomly chosen changes to other parame-
ters (i.e.,
AND
); this allows the tabu search to ex-
plore states similar to the current grammar. Third,
a parameter can be allowed to overrule all
other
parameters (i.e.,
OR
);
this allows the tabu search
to move toward better but more distant states.
Potential moves for each turn are generated as
follows:
for each association measure,
one move
87
is added with that measure removed from the sam-
pler (
OFF
);
two
OR
moves above and two below
the feature’s current threshold,
serving as escape
hatches; and 25
AND
moves that include the cur-
rent feature and
1...k
other features (
k = 5
).
The
stopping criteria is that
a new best
grammar has
not been observed for 14 turns,
twice the size of
the tabu list.
This stopping criteria is an interme-
diate memory item that monitors the general direc-
tion of the search. The intuition is that, if a new op-
timum grammar has not been reached within two
complete cycles of the short-term tabu list,
such
a grammar is unlikely to exist.
It is important to
keep in mind that each turn evaluates a wide range
of possible moves. This means that a large number
of potential grammars are evaluated in determin-
ing each move.
Given the size of the space reach-
able from any given state and the number of states
visited during the tabu search, it is unlikely at this
point that a significantly better grammar exists.
7
Results and Discussion
The evaluation uses web-crawled corpora (from
the WaC and Aranea projects) for English, Span-
ish,
French,
German,
and Italian.
The same data
segmentation shown in Table 3 is used for each
language.
Each grammar
type is evaluated us-
ing cross-validation with two folds;
the training-
testing split
is randomly assigned.
The search
stage uses two restarts,
each with a unique seg-
ment
of the training data.
This means that
the
learning algorithm makes four passes per iteration
(two folds with two restarts) over which we can
measure stability.
Used For
# Sentences
Candidates and Association
1 million
Test Sets for Restarts (
Lex, Syn
)
100k
Test Sets for Restarts (
F ull
)
20k
Calculating Evaluation Metric
200k
Table 2: Data Segmentation Per Fold
The first measure of grammar quality, in Figure
2, is the compression achieved over the unencoded
dataset
on held-out testing data.
Values close to
1 represent a large amount of compression while
values close to 0 represent very little compression.
We see across languages that lexical constructions
(i.e., “because of”) do not provide much compres-
sion.
In part,
this is because few such construc-
tions are selected:
an average of 22 per language.
Purely syntactic constructions,
however,
do pro-
vide compression (with an average of 120 identi-
fied per language).
For all languages except En-
glish
CxG
F ULL
has the highest rate of compres-
sion,
with each grammar containing between 4k
and 5k constructions.
This measure shows us three things: First, there
is a balance between complexity and descriptive
adequacy that is forced by MDL. In other words,
the descriptive power of the purely lexical
con-
structions are only able to justify 22 construc-
tions as opposed to 4k - 5k for
CxG
F ULL
.
CxGs
with multiple types of representations are allowed
to produce more complex grammars because they
produce better descriptions of the corpus. Second,
the learned grammars provide meaningful gener-
alizations.
In other words, this compression met-
ric shows that
not
only does the algorithm find
the optimum grammar with respect to competing
grammars but that it also finds grammars that offer
above-the-baseline compression.
Full
compres-
sion is, of course, impossible and these results pro-
vide a benchmark for future work. Third, these re-
sults show that the addition of semantic represen-
tations provide improved descriptive adequacy.
A
representative sample of the output of
CxG
F ULL
for English is shown in Appendix A.
How consistent are the grammars learned across
different sub-sets of the corpora?
This is shown
in Figure 3 using the stability metric introduced in
Section 4 over the grammars produced from differ-
ent sub-sets of the corpora. We see that more com-
plicated grammars are less stable. Thus,
CxG
LEX
has low compression but
almost
perfect
stability
because the same small
number
of
lexical
con-
structions are consistently identified.
CxG
F ULL
,
on the other hand,
has a much larger number of
constructions that provide much higher compres-
sion;
but
the inventory of these constructions is
subject to more variation.
Lack of stability here is not necessarily caused
by error: grammars are subject to variation. Some
amount of this variation results from errors:
tag-
ging errors,
parsing errors,
and learning errors in
which the search algorithm does not converge on
the best
grammar.
Some amount
of
this varia-
tion,
however,
comes from differences in usage
across different portions of the corpus: these large
corpora contain many varieties, dialects, domains,
and speakers,
each introducing variant
construc-
tions. To what degree do these variations represent
88
error and to what degree do they represent actual
grammatical differences across the corpora? That
is a question for future work because it
requires
testing grammars over data explicitly drawn from
different varieties of a language.
This paper has shown that the MDL paradigm
can be used to jointly model the complexity and
descriptive adequacy of
CxGs
against
unanno-
tated corpora.
This is important because methods
that rely on gold-standard annotations to evaluate
grammar quality ultimately depend on the intro-
spections behind those annotations.
How valid
are these CxGs using external
measures?
One
application-specific evaluation of a learned gram-
mar
is its ability to model
dialectal
variations.
Separate work using these learned CxGs for di-
alectometry (Dunn, Forthcoming) shows that these
grammars are able to model regional varieties with
a high degree of accuracy.
Resources.
Code and models for this work are available
at jdunn.name and github.com/jonathandunn/c2xg
Acknowledgements.
This research was supported in part
by an appointment to the Visiting Scientist Fellowship at the
National Geospatial-Intelligence Agency administered by the
Oak Ridge Institute for Science and Education through an in-
teragency agreement between the U.S. Department of Energy
and NGA.
The views expressed in this presentation are the
author’s and do not
imply endorsement
by the DoD or the
NGA.
Appendix A: Representative Examples
[
ADVERB
— “about”]
Modified Adverbs
“at about”
This simple construction modifies adverbs
“how about”
to include information about vagueness.
“only about”
“on about”
[“provide” —
25
—
25
]
Verb-Specific Direct Object
“provide added value”
This verb-specific construction constrains
“provide an opportunity”
the object of “provide” to members of an
“provide general advice”
unlabeled semantic domain.
“provide information about”
[
25
— “to” —
14
]
Complex Verb Phrase
“designed to ensure”
This construction represents a complex event
“want to improve”
phrase that contains both a main verb, “want,”
“made to ensure”
as well as an infinitive verb, “improve.”
“able to understand”
[
VERB
— “to” —
25
—
ADVERB
]
Evaluative Verb Phrase
“need to consider how”
This construction describes a basic verb phrase
“wish to consider how”
embedded within an evaluative verb describing
“want to be here”
how the speaker perceives the event.
“like to find out”
[
DETERMINER
—
NOUN
—
ADPOSITION
—
14
]
Complex Noun Phrase
“some experience in research”
This construction encodes a noun phrase that
“a need for research”
contains a modifying prepositional phrase.
“the process of planning”
“a number of activities”
[
SUB
-
CONJ
.
—
25
—
ADJECTIVE
—
NOUN
]
Subordinated Noun Phrase
“whether small independent companies”
This construction provides sub-ordinated
“that the international community”
noun phrases that attach to main clause verbs
“because the current version”
and then act as the subject for additional
“while the other party”
modifying material that remains unspecified.
[
PRON
.
—
AUX
.
—
VERB
—
PARTICLE
—
25
]
Partial Main Clause
“you should continue to receive”
This construction represents the largest
“i was told to make”
representations that are identified by the
“they were going to have”
algorithm; it specifies most of a main clause
“this was going to be”
with a pronominal subject.
89
References
Baroni,
M.,
Bernardini,
S.,
Ferraresi,
A.,
and Zanchetta,
E.
2009.
The WaCky Wide Web: A Collection of Very Large
Linguistically Processed Web-crawled Corpora.
Lan-
guage Resources and Evaluation, 43: 209-226.
Benko,
V.
2014.
Aranea:
Yet Another Family of (Compa-
rable) Web Corpora.
In Proceedings of Text, Speech and
Dialogue. 17th International Conference. 257-264.
Bryant, J. 2004.
Scalable Construction-based Parsing and Se-
mantic Analysis.
In Proceedings of the Workshop on Scal-
able Natural
Language Understanding (HLT-NAACL):
33-40.
Bybee,
J. 2006.
From Usage to Grammar:
The Mind’s Re-
sponse to Repetition.
Language, 82(4): 711-733.
Chang,
N.;
De Beule,
J.;
and Micelli,
V.
2012.
Computa-
tional construction grammar:
Comparing ECG and FCG.
In Steels,
L.
(ed.),
Computational
Issues in Fluid Con-
struction Grammar. Berlin: Springer. 259-288.
Dunn,
J.
2017.
Computational
Learning of
Construction
Grammars.
Language & Cognition, 9(2): 254-292.
Dunn,
J.
Forthcoming.
Finding Variants for Construction-
Based Dialectometry:
A Corpus-Based Approach to Re-
gional CxGs.
Cognitive Linguistics.
Forsberg,
M.;
Johansson,
R.;
Bckstrm,
L.;
Borin,
L.;
Lyn-
gfelt, B.; Olofsson, J.; and Prentice, J. 2014.
From Con-
struction Candidates to Constructicon Entries:
An exper-
iment using semi-automatic methods for identifying con-
structions in corpora.
Constructions and Frames,
6(1):
114-135.
Glover, F. 1989.
Tabu Search, Part 1.
ORSA Journal on Com-
puting, 1(3): 190-206.
Glover.
F.
1990a.
Tabu Search,
Part
2.
ORSA Journal
on
Computing, 2(1): 4-32.
Glover. F. 1990b.
Tabu Search: A Tutorial.
Interfaces, 20(4):
74-94.
Goldberg,
A.
2006.
Constructions at Work:
The Nature of
Generalization in Language.
Oxford:
Oxford University
Press.
Goldsmith, J. 2001.
Unsupervised Learning of the Morphol-
ogy of a Natural Language.
Computational Linguistics,
27(2): 153-198.
Goldsmith,
J.
2006.
An Algorithm for
the Unsupervised
Learning of Morphology.
Natural Language Engineering,
12(4): 353-371.
Gr
¨
unwald, P. and Rissanen, J. 2007.
The Minimum Descrip-
tion Length Principle.
Cambridge, MA: The MIT Press.
Hopper, P. 1987.
Emergent Grammar.
In Proceedings of the
13th Annual Meeting of the Berkeley Linguistics Society,
139-157.
Kay,
P.
and Fillmore,
C.
1999.
Grammatical Constructions
and Linguistic Generalizations:
The Whats X Doing Y?
Construction.
Language, 75(1): 1-33.
Langacker, R. 2008.
Cognitive Grammar: A Basic Introduc-
tion.
Oxford: Oxford University Press.
Nguyen,
Dat
Quoc;
Nguyen,
Dai
Quoc;
Pham,
Dang Duc;
and Pham,
Son Bao.
2016.
A Robust
Transformation-
Based Learning Approach Using Ripple Down Rules for
Part-Of-Speech Tagging.
AI
Communications,
29(3):
409-422.
Petrov,
S.;
Das,
D.;
and McDonald,
R.
2012.
A Universal
Part-of-Speech Tagset.
In Proceedings of the Eight Inter-
national Conference on Language Resources and Evalua-
tion.
Rehurek,
R.
and Sojka,
P.
2010.
Software Framework for
Topic Modelling with Large Corpora.
In Proceedings of
the LREC 2010 Workshop on New Challenges for NLP
Frameworks.
Rissanen,
J. 1978.
Modeling by the Shortest Data Descrip-
tion.
Automatica, 14: 465-471.
Rissanen, J. 1986.
Stochastic Complexity and Modeling.
An-
nals of Statistics, 14: 1,080-1,100.
Steels,
L.
2004.
Constructivist
development
of
grounded
construction grammar.
In Proceedings of the 42nd Meet-
ing of the Association for Computational Linguistics:
9-
16.
Steels, L. 2012.
Design methods for fluid construction gram-
mar.
In Steels,
L.
(ed),
Computational
Issues in Fluid
Construction Grammar. Berlin: Springer. 3-36.
Wible,
D.
and Tsao,
N.
2010.
StringNet
as a Computa-
tional
Resource for
Discovering and Investigating Lin-
guistic Constructions.
In Proceedings of
the Workshop
on Extracting and Using Constructions in Computational
Linguistics (NAACL-HTL): 25-31.
90
