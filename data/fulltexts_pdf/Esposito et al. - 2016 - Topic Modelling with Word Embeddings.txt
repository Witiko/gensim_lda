Pr
oceedings
of th
e
Th
ird 
It
alian 
Co
nference
on
Co
mputational 
Li
nguistics
CL
iC-it 
2016
5-6 De
cember 
2016
, 
Na
poli
Ed
itors:
An
na 
Co
razza
Si
monetta 
Mo
ntemagni
Gi
ovanni 
Se
meraro
aA
ccademia
university
press
aA
CLiC it
CLIC_2016_Proceedings.indd 1
02/12/16 15.02
© 2016 by AILC - Associazione Italiana di Linguistica Computazionale
sede legale: c/o Bernardo Magnini, Via delle Cave 61, 38122 Trento
codice fiscale 96101430229
email: info@ai-lc.it
Pubblicazione resa disponibile
nei termini della licenza Creative Commons
Attribuzione – Non commerciale – Non opere derivate 4.0
Accademia University Press
via Carlo Alberto 55
I-10123 Torino
info@aAccademia.it
isbn 978-88-99982-08-9
www.aAccademia.it/CLIC_2016
Accademia University Press è un marchio registrato di proprietà
di LEXIS Compagnia Editoriale in Torino srl
CLIC_2016_Proceedings.indd 2
02/12/16 15.03
1
Preface 
Our very warm welcome to CLiC-it 2016 (http://clic-it2016.dieti.unina.it/), the 3
rd
edition of 
the 
Italian Conference on Computational Linguistics
, held on December 5
th
and 6
th
, in Naples, 
Italy, co-located with Evalita 2016 (http://www.evalita.it/2016), hosted and locally organized 
by Università Federico II, one the oldest public and laic universities in the world. The 
organization of the conference is the result of a fruitful conjoint effort of different research 
groups (Istituto di Linguistica Computazionale “Antonio Zampolli” del CNR, Università degli 
Studi di Bari Aldo Moro and Università degli Studi di Napoli Federico II) showing the 
nationwide spreading of Computational Linguistics in Italy. The CLiC-it conference series is 
organized by the 
Italian Association for Computational Linguistics
(AILC) and has clearly 
established itself as the premier national forum for research and development in the fields of 
Computational Linguistics (CL) and Natural Language Processing (NLP), where leading 
researchers and practitioners from academia and industry meet to share their challenges, 
solutions, research results, and experiences. 
CLiC-it covers all aspects of computational linguistics and natural language (both written 
and 
spoken) 
processing, 
and 
targets 
state-of-art 
theoretical 
results, 
experimental 
methodologies, technologies, as well as application perspectives, which may contribute to 
advance the field. 
As in the previous editions, CLiC-it 2016 is organized around thematic areas, each chaired 
by two or more Area Chairs: 
•
Cognitive 
modeling 
of 
language 
processing 
and 
psycholinguistics
. 
Area 
chairs: 
Davide 
Crepaldi, 
(Scuola 
Internazionale 
Superiore 
di 
Studi 
Avanzati, 
Trieste), 
Gianluca Lebani (Università degli Studi di Pisa), Vito Pirrelli (Istituto di Linguistica 
Computazionale “Antonio Zampolli”, CNR, Pisa) 
•
NLP for Digital Humanities
. Area chairs: Marco Passarotti (Università Cattolica del 
Sacro Cuore, Milano), Sara Tonelli (Fondazione Bruno Kessler, Trento) 
•
Information Retrieval and Question Answering
. Area chairs: Nicola Ferro (Università 
degli Studi di Padova), Alessandro Moschitti (Università degli Studi di Trento - Qatar 
Computing Research Institute) 
•
Information Extraction, Entity Linking and (Linked) Open Data
. Area chairs: Valerio 
Basile (INRIA Sophia Antipolis Méditerranée), Roberto Navigli (Università degli 
Studi “La Sapienza” di Roma) 
•
Linguistic Resources
. Area chairs: Cristina Bosco (Università degli Studi di Torino), 
Monica Monachini (Istituto di Linguistica Computazionale “Antonio Zampolli” del 
CNR, Pisa), Simonetta Vietri (Università degli Studi di Salerno) 
•
Machine Translation and Multilingual Applications
. 
Area 
chairs: 
Mauro 
Cettolo 
(Fondazione Bruno Kessler, Trento), Johanna Monti (Università degli Studi di Sassari) 
•
Pragmatics, 
Creativity 
and 
Linguistic 
Games
. 
Area 
chairs: 
Marco 
de 
Gemmis
(Università degli Studi di Bari “Aldo Moro”), Marco Gori (Università degli Studi di 
Siena), Massimo Poesio (Sussex University, UK) 
•
Semantics and Knowledge Acquisition
. Area chairs: Raffaella Bernardi (Università 
degli 
Studi 
di 
Trento), 
Aldo 
Gangemi 
(Istituto 
di 
Scienze 
e 
Tecnologie 
della 
Cognizione, CNR, Roma), Fabio Massimo Zanzotto (Università degli Studi di Roma 
Tor Vergata) 
•
Spoken language processing and understanding
. Area chairs: Piero Cosi (Istituto di 
Scienze e Tecnologie della Cognizione, CNR, Padova), Antonio Origlia (Università 
degli Studi di Napoli Federico II) 
•
Morphology and Syntax Processing
. Area chairs: Alberto Lavelli (Fondazione Bruno 
Kessler, Trento), Alessandro Mazzei (Università degli Studi di Torino) 
CLIC_2016_Proceedings.indd 1
02/12/16 15.03
2

Morphology and Syntax Processing. Area chairs: Alberto Lavelli (Fondazione Bruno 
Kessler, Trento), Alessandro Mazzei (Università degli Studi di Torino) 

NLP for Web and Social Media. Area chairs: Danilo Croce (Università degli Studi di 
Roma 
Tor 
Vergata), 
Felice 
Dell’Orletta 
(Istituto 
di 
Linguistica 
Computazionale 
“Antonio Zampolli”, CNR, Pisa) 

Linguistic Issues in CL and NLP. Area chairs: Alessandro Lenci (Università degli 
Studi di Pisa), Paola Merlo (University of Geneva, CH) 

Machine Learning for CL and NLP. Area chairs: Giuseppe Attardi (Università degli 
Studi di Pisa), Roberto Basili (Università degli Studi di Roma Tor Vergata) 
The maturity of the conference is clearly demonstrated by the high quality of the submitted 
research work. This year CLiC-it received 69 submissions by 212 authors from 14 countries 
and the Program Committee worked very hard to ensure that every paper got at least two 
careful and fair reviews, with the 74% of the papers which received three or even more 
reviews. This process finally led to the acceptance of 28 papers for oral presentation and 27 
papers 
for poster presentation, 
with a 
global acceptance rate of 80% 
motivated by the 
inclusive spirit of the conference and which is in line with the previous editions (77% in 2014 
and 81% 
in 2015). 
Regardless of the 
format of presentation, all accepted papers were 
allocated 6 pages in the proceedings, available as “open access” publication on different 
online platforms
1
. We are therefore extremely grateful to our 152 Program Committee 
members and to our 3 additional reviewers 
for producing 
more than 206 detailed and 
insightful reviews, as well as to the Area Chairs, who assisted the Program Chairs in their 
work. 
In 2016, the submissions were articulated into 13 thematic areas, some of which shared 
with the previous 
year(s), others which were introduced for the first time. The area of 
Linguistic Resources was confirmed as the track attracting the higher number of submissions: 
the papers in this area cover 32% of the submissions, against 29% in 2014 and 25% in 2015. 
In line with international computational linguistics conferences such as COLING 2014, this 
year two new tracks were introduced tackling transversal issues: namely, Linguistic Issues in 
CL and NLP and Machine Learning for CL and NLP, which attracted - together - almost 12% 
of 
the 
submitted 
papers. 
The 
track 
Cognitive 
modeling 
of 
language 
processing 
and 
psycholinguistics, new with respect to 2015 but already present in CLiC-it 2014, represents 
more than 8% of the submissions: interestingly, they originate also from research groups 
working in the area of cognitive psychology and neuroscience, thus complying with the 
conference goal of bridging the gap between the results emerging in different areas of 
computational linguistics and other related disciplines. 
The remaining tracks represent, with minor adjustments, a continuation of the thematic 
areas of 2015 and 2014 editions. Here, the main difference lies at the level of the number of 
attracted submissions with respect to the total, which range from the 69% and 75% of 2014 
and 2015 respectively, to the 48% of this year. This significant reduction of submissions can 
mainly be explained by the co-location of the conference with the Evalita final Workshop, 
whose challenges coincide with central topics of these areas: see, for instance, the track NLP 
for Web and Social Media and the SENTIPOLC (SENTIment POLarity Classification) 
Evalita shared task, or the track Morphology and Syntax Processing and the PoSTWITA 
(POS tagging for Italian Social Media Texts) task. The complementarity of the contributions 
of the two conferences emerges clearly by comparing the author keywords associated with 
individual CLiC-it and Evalita papers. It is interesting to note that key hot topics of these 
areas, such as Deep Learning, Named Entity Linking and Recognition, Part-of-speech tagging 
1
The CLiC-it 2016 proceedings were originally published online by CEUR (CEUR-WS.org, ISSN 1613-0073). 
CLIC_2016_Proceedings.indd 2
02/12/16 15.03
3
or Question Answering to mention just a few, are more frequently associated to papers in 
Evalita’s rather than CLiC-it’s proceedings: in some cases, they do not appear at all, as in the 
case of Deep Learning which is not among the author keywords associated with CLiC-it 
papers. 
The rich and articulated picture emerging from the wide variety of contributions to CLiC-it 
2016 creates the prerequisites for a fruitful and stimulating conference. Therefore, we would 
like to thank the authors of all papers for submitting their work to the conference. Among 
them, many are young authors (PhD students and Postdocs). As in the previous editions, 
Young Author Best Paper Awards will be assigned to meritorious papers involving PhD 
students and Postdocs. 
Besides the 
technical paper program consisting of oral presentations and two poster 
sessions, the core conference program also includes two keynote speeches, by Mirella Lapata 
(University of Edinburgh) and Joakim Nivre (Uppsala University). We are honoured they 
accepted to contribute to CLiC-it 2016 and thank them for agreeing to share their knowledge 
and expertise on key computational linguistics topics with the Italian community. Last but not 
least, the program also includes two panels, focusing on the impact to research results on the 
economy and society at large and aimed at creating a national and international network 
around the Italian computational linguistics community. Our thanks also go to the panelists 
who accepted to be involved in the event. 
We also would like to take this opportunity to thank all our colleagues, who volunteered 
their time to contribute to the success of this conference, as well as to acknowledge the 
support from endorsing organizations and institutions and from our sponsors, who generously 
provided funds and services that are crucial for the organization of this event. At the time of 
writing this preface, CLiC-it was generously sponsored by the following companies and 
associations: Interactive Media s.p.a. 
(Gold Sponsor); CELI 
Language 
Technology and 
GruppoMeta (Silver Sponsors); the European Linguistic Resources Association (ELRA) and 
NTT DATA (Bronze Sponsors). We also would like to thank the following organizations for 
endorsing 
CLiC-it 
2016: 
Associazione 
Italiana 
per 
l’Intelligenza 
Artificiale 
(AI*IA); 
Associazione 
Italiana 
Scienze 
della 
Voce 
(AISV); 
Associazione 
Italiana 
di 
Linguistica 
Applicata 
(AItLA); 
Associazione 
per 
l’Informatica 
Umanistica 
e 
la 
Cultura 
Digitale 
(AIUCD); Società Italiana di Glottologia (SIG); Società di Linguistica Italiana (SLI). Last but 
not 
least, 
special 
thanks are also due to 
Università di Napoli Federico 
II and to 
the 
Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione of this university 
for the support in the organization of the event and hosting the conference. 
This conference would also not be possible without the dedication, devotion and hard work 
of the members of our local organizing committee. Our special thanks extend to all of them. 
Finally, we want to acknowledge the EasyChair infrastructure for the management of the 
review process. 
Please join us at CLiC-it 2016 to interact with experts from academia and industry on 
topics 
related 
to 
Computational 
Linguistics 
and 
Natural 
Language 
Processing 
and 
to 
experience and share new research 
findings, best practices, state-of-the-art systems and 
applications. 
Anna Corazza, Simonetta Montemagni and Giovanni Semeraro 
CLiC-it 2016 Conference Co-Chairs 
November 2016 
CLIC_2016_Proceedings.indd 3
02/12/16 15.03
4
Committees 
Conference Chairs 

Anna Corazza, Università degli Studi di Napoli Federico II 

Simonetta Montemagni, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Giovanni Semeraro, Università degli Studi di Bari “Aldo Moro” 
Program Committee 
Cognitive modeling of language processing and psycholinguistics. 
Area chairs: 

Davide Crepaldi, Scuola Internazionale Superiore di Studi Avanzati, Trieste 

Gianluca Lebani, Università degli Studi di Pisa 

Vito Pirrelli, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 
Reviewers: 

Valentina Bambini, Istituto Universitario di Studi Superiori di Pavia 

Anna Borghi, Università degli Studi di Bologna - Istituto di Scienze e Tecnologie 
della Cognizione, CNR 

Roberto Bottini, Università degli Studi di Trento 

Basilio Calderone, CNRS - Université de Toulouse-Jean Jaurès 

Cristiano Chesi, Istituto Universitario di Studi Superiori di Pavia 

Marcello Ferro, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Marco Marelli, Ghent University 

Claudia Marzi, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Claudio Mulatti, Università degli Studi di Padova 

Daniela Paolieri, Universidad de Granada 

Lucia Passaro, Università degli Studi di Pisa 

Giovanni Pezzulo, Istituto di Scienze e Tecnologie della Cognizione, CNR 

Valentina Schettino, Università degli Studi di Napoli Federico II 

Marco Senaldi, Scuola Normale Superiore, Pisa 

Simone Sulpizio, Università degli Studi di Trento 

Eva Maria Vecchi, University of Cambridge 

Francesco Vespignani, Università degli Studi di Trento 

Alessandra Zarcone, Universität des Saarlandes 
Information Extraction, Entity Linking and (Linked) Open Data 
Area chairs: 

Valerio Basile, INRIA 

Roberto Navigli, Università degli Studi “La Sapienza” di Roma 
Reviewers: 

Gianni Barlacchi, Università degli Studi di Trento 

Pierpaolo Basile, Università degli Studi di Bari “Aldo Moro” 

Annalina Caputo, Trinity College Dublin 

Giuseppe Castellucci, Università degli Studi di Roma Tor Vergata 

Danilo Croce, Università degli Studi di Roma Tor Vergata 

Stefano Faralli, University of Mannheim 
CLIC_2016_Proceedings.indd 4
02/12/16 15.03
5

Aldo Gangemi, Université Paris 13 - Istituto di Scienze e Tecnologie della 
Cognizione, CNR 

Pasquale Lops, Università degli Studi di Bari “Aldo Moro” 

Cataldo Musto, Università degli Studi di Bari “Aldo Moro” 

Viviana Patti, Università degli Studi di Torino 

Simone Paolo Ponzetto, University of Mannheim 

Giuseppe Rizzo, Istituto Superiore Mario Boella 

Paolo Rosso, Technical University of Valencia 

Fabrizio Silvestri, Facebook 

Marco Turchi, Fondazione Bruno Kessler, Trento 
Information Retrieval and Question Answering 
Area chairs: 

Nicola Ferro, Università degli Studi di Padova 

Alessandro Moschitti, Università degli Studi di Trento - Qatar Computing 
Research Institute 
Reviewers: 

Gianluca Demartini, University of Sheffield 

Claudio Lucchese, Istituto di Scienza e Tecnologie dell’Informazione “A. Faedo”, 
CNR 

Raffaele Perego, Istituto di Scienza e Tecnologie dell’Informazione “A. Faedo”, 
CNR 

Paolo Rosso, Technical University of Valencia 

Fabrizio Silvestri, Facebook 

Guido Zuccon, Queensland University of Technology 
Linguistic Issues in CL and NLP 
Area chairs: 

Alessandro Lenci, Università degli Studi di Pisa 

Paola Merlo, University of Geneva, CH 
Reviewers: 

Marco Baroni, Università degli Studi di Trento 

Marie Candito, Université Paris Diderot - INRIA 

Barbara Di Eugenio, University of Illinois at Chicago 

Francesca Masini, Università degli Studi di Bologna 

Suzanne Stevenson, University of Toronto 

Roberto Zamparelli, Università degli Studi di Trento 
Linguistic Resources 
Area chairs: 

Cristina Bosco, Università degli Studi di Torino 

Monica Monachini, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Simonetta Vietri, Università degli Studi di Salerno 
Reviewers: 

Núria Bel, Universitat Pompeu Fabra 

Luisa Bentivogli, Fondazione Bruno Kessler, Trento 

Johan Bos, University of Groningen 
CLIC_2016_Proceedings.indd 5
02/12/16 15.03
6

Nicoletta Calzolari, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Tommaso Caselli, Vrije Universiteit Amsterdam 

Isabella Chiari, Università degli Studi “La Sapienza” di Roma 

Elisa Corino, Università degli Studi di Torino 

Thierry Declerck, DFKI GmbH 

Francesca Frontini, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Aldo Gangemi, Université Paris 13 - Istituto di Scienze e Tecnologie della 
Cognizione, CNR 

Elisabetta Jezek, Università degli Studi di Pavia 

Fahad Khan, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Borja Navarro-Colorado, Universidad de Alicante 

Malvina Nissim, University of Groningen 

Irene Russo, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Maria Simi, Università degli Studi di Pisa 

Claudia Soria, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Laure Vieu, Institut de Recherche en Informatique de Toulouse 
Machine Learning for CL and NLP 
Area chairs: 

Giuseppe Attardi, Università degli Studi di Pisa 

Roberto Basili, Università degli Studi di Roma Tor Vergata 
Reviewers: 

Pierpaolo Basile, Dipartimento di Informatica - University of Bari 

Daniele Bonadiman, Università degli Studi di Trento 

Francesco Cutugno, Università degli Studi di Napoli Federico II 

Simone Filice, Università degli Studi di Roma Tor Vergata 

Bernardo Magnini, Fondazione Bruno Kessler, Trento 

Alessandro Moschitti, Università degli Studi di Trento - Qatar Computing 
Research Institute 

Malvina Nissim, University of Groningen 

Antonio Origlia, Università degli Studi di Napoli Federico II 

Maria Simi, Università degli Studi di Pisa 

Fabio Tamburini, Università degli Studi di Bologna 
Machine Translation and Multilingual Applications 
Area chairs: 

Mauro Cettolo, Fondazione Bruno Kessler, Trento 

Johanna Monti, Università degli Studi di Sassari 
Reviewers: 

Anabela Barreiro, INESC ID 

Nicola Bertoldi, Fondazione Bruno Kessler, Trento 

José Guilherme Camargo de Souza, eBay Inc 

Marcello Federico, Fondazione Bruno Kessler, Trento 

Matteo Negri, Fondazione Bruno Kessler, Trento 

Bruno Pouliquen, World Intellectual Property Organization 

Marco Turchi, Fondazione Bruno Kessler, Trento 
CLIC_2016_Proceedings.indd 6
02/12/16 15.03
7
Morphology and Syntax Processing 
Area chairs: 

Alberto Lavelli, Fondazione Bruno Kessler, Trento 

Alessandro Mazzei, Università degli Studi di Torino 
Reviewers: 

Giuseppe Attardi, Università degli Studi di Pisa 

Bernd Bohnet, Google 

Cristiano Chesi, Istituto Universitario di Studi Superiori di Pavia 

Felice Dell’Orletta, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Albert Gatt, University of Malta 

Vincenzo Lombardo, Università degli Studi di Torino 

Daniele Radicioni, Università degli Studi di Torino 

Francesco Sartorio, Università degli Studi di Padova 

Giorgio Satta, Università degli Studi di Padova 

Fabio Tamburini, Università degli Studi di Bologna 
NLP for Digital Humanities 
Area chairs: 

Marco Passarotti, Università Cattolica del Sacro Cuore, Milano 

Sara Tonelli, Fondazione Bruno Kessler, Trento 
Reviewers: 

Federico Boschetti, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Giovanni Colavizza, École Polytechnique Fédérale de Lausanne 

Antske Fokkens, Vrije Universiteit Amsterdam 

Emiliano Giovannetti, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Mike Kestemont, University of Antwerp 

John Lee City, University of Hong Kong 

Eleonora Litta Modignani, Università Cattolica del Sacro Cuore, Milano 

Francesco Mambrini, Deutsches Archäologisches Institut 

Stefano Menini, Fondazione Bruno Kessler - Università degli Studi di Trento 

Geoffrey Rockwell, University of Alberta 

Matteo Romanello, King’s College London 

Rachele Sprugnoli, Fondazione Bruno Kessler - Università degli Studi di Trento 
NLP for Web and Social Media 
Area chairs: 

Danilo Croce, Università degli Studi di Roma Tor Vergata 

Felice Dell’Orletta, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 
Reviewers: 

Costanza Asnaghi, Gent University - KU Leuven 

Francesco Barbieri, Universitat Pompeu Fabra 

Pierpaolo Basile, Università degli Studi di Bari “Aldo Moro” 

Valerio Basile, INRIA 
CLIC_2016_Proceedings.indd 7
02/12/16 15.03
8

Dominique Brunato, Istituto di Linguistica Computazionale “Antonio Zampolli”, 
CNR 

Annalina Caputo, Trinity College Dublin 

Giuseppe Castellucci, Università degli Studi di Roma Tor Vergata 

Francesca Chiusaroli, Università degli Studi di Macerata 

Andrea Cimino, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Stefano Cresci, Istituto di Informatica e Telematica, CNR 

Federica Da Milano, Università degli Studi di Milano-Bicocca 

Anna Feltracco, Fondazione Bruno Kessler, Trento 

Simone Filice, Università degli Studi di Roma Tor Vergata 

Lorenzo Gatti, Fondazione Bruno Kessler, Trento 

Nicola Grandi, Università degli Studi di Bologna 

Felicia Logozzo, Università degli Studi di Roma Tor Vergata 

Simone Magnolini, Fondazione Bruno Kessler, Trento 

Diego Marcheggiani, University of Amsterdam 

Alejandro Moreo Fernández, Istituto di Scienza e Tecnologie dell’Informazione 
“A. Faedo”, CNR 

Cataldo Musto, Università degli Studi di Bari “Aldo Moro” 

Nicole Novielli, Università degli Studi di Bari “Aldo Moro” 

Viviana Patti, Università degli Studi di Torino 

Marco Pedicini, Università degli Studi Roma Tre 

Maria Laura Pierucci, Università degli Studi di Macerata 

Francesco Ronzano, Universitat Pompeu Fabra 

Maurizio Tesconi, Istituto di Informatica e Telematica, CNR 

Andrea Vanzo, Università degli Studi “La Sapienza” di Roma 

Giulia Venturi, Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR 

Torsten Zesch Sprachtechnologie, University of Duisburg-Essen 
Pragmatics, Creativity and Linguistic Games 
Area chairs: 

Marco de Gemmis, Università degli Studi di di Bari “Aldo Moro” 

Marco Gori, Università degli Studi di Siena 

Massimo Poesio, Sussex University, UK 
Reviewers: 

Carla Bazzanella 

Gemma Boleda, Universitat Pompeu Fabra 

Francesca Bonin, Trinity College Dublin 

Rossana Damiano, Università degli Studi di Torino 

Rodolfo Delmonte 

Diana Inkpen, University of Ottawa 

Beata Klebanov 

Costanza Navarretta, University of Copenhagen 

Vincent Ng, University of Texas at Dallas 

Malvina Nissim, University of Groningen 

Viviana Patti, Università degli Studi di Torino 

Arndt Riester, University of Stuttgart 

Carlo Strapparava, Fondazione Bruno Kessler, Trento 
CLIC_2016_Proceedings.indd 8
02/12/16 15.03
9
Semantics and Knowledge Acquisition 
Area chairs: 

Raffaella Bernardi, Università degli Studi di Trento 

Aldo Gangemi, Université Paris 13 - Istituto di Scienze e Tecnologie della 
Cognizione, CNR 

Fabio Massimo Zanzotto, Università degli Studi di Roma Tor Vergata 
Reviewers: 

Maria Aloni, Universiteit van Amsterdam 

Elena Cabrio, University of Nice Sophia Antipolis 

Aurelie Herbelot, Università degli Studi di Trento 

Omer Levy, Bar-Ilan University 

Denis Paperno, Università degli Studi di Trento 

Diego Reforgiato Recupero, Università degli Studi di Cagliari 
Spoken language processing and understanding 
Area chairs: 

Piero Cosi, Istituto di Scienze e Tecnologie della Cognizione, CNR 

Antonio Origlia, Università degli Studi di Napoli Federico II 
Reviewers: 

Francesco Cutugno, Università degli Studi di Napoli Federico II 

Bogdan Ludusan, LSCP - École Normale Supérieure - CNRS, Paris 
Additional Reviewers 

Anna Lisa Gentile, Universität Mannheim 

Julia Bosque-Gil, Universidad Politécnica de Madrid 

Manuela Sanguinetti, Università degli Studi di Torino 
Local Organizing Committee 

Anna Corazza 

Francesco Cutugno 

Francesco Isgrò 

Andrea Apicella 

Dario Di Mauro 

Fabrizio Esposito 

Antonio Origlia 

Valentina Schettino 

Giuseppe Vettigli 
CLIC_2016_Proceedings.indd 9
02/12/16 15.03
Contents
Andrea Abel, Aivars Glaznieks, Lionel Nicolas and Egon Stemle
An extended version of the KoKo German L1 Learner corpus ............................................................. 
13
Linda Alfieri and Fabio Tamburini
(Almost) Automatic Conversion of the Venice Italian Treebank into the Merged Italian Dependency 
Treebank Format ...................................................................................................................................... 
19
David Alfter and Yuri Bizzoni
Hybrid Language Segmentation for Historical Documents .................................................................... 
24
Anita Alicante, Anna Corazza, Francesco Isgrò and Stefano Silvestri
Relation mining from clinical records ..................................................................................................... 
29
Anita Alicante, Anna Corazza and Antonio Pironti
Twitter Sentiment Polarity Classification using Barrier Features ........................................................... 
34
Daniela Baiamonte, Tommaso Caselli and Irina Prodanof
Annotating Content Zones in news articles ............................................................................................ 
40
Gianni Barlacchi, Azad Abad, Emanuele Rossinelli and Alessandro Moschitti
Appetitoso: A Search Engine for Restaurant Retrieval based on Dishes ............................................... 
46
Pierpaolo Basile, Valerio Basile, Elena Cabrio and Serena Villata
Argument Mining on Italian News Blogs ............................................................................................... 
51
Pierpaolo Basile, Annalina Caputo, Roberta Luisi and Giovanni Semeraro
Diachronic Analysis of the Italian Language exploiting Google Ngram ............................................... 
56
Giulia Benotto, Emiliano Giovannetti and Simone Marchi
Investigating the Application of Distributional Semantics to Stylometry .............................................. 
61
Toine Bogers, Georgeta Bordea, Paul Buitelaar, Nicola Ferro and Gianmaria Silvello
IR Scientific Data: How to Semantically Represent and Enrich Them .................................................. 
66
Stavros Bompolas, Marcello Ferro, Claudia Marzi, Franco Alberto Cardillo and Vito Pirrelli
Reassessing inflectional regularity in Modern Greek conjugation ......................................................... 
72
Roberto Bottini, Daniel Casasanto, Andrea Nadalini and Davide Crepaldi
Stepping out of the Chinese Room: Word meaning with and without consciousness ........................... 
78
Alice Bracchi, Tommaso Caselli and Irina Prodanof
Enrichring the Ita-TimeBank with Narrative Containers ........................................................................ 
83
Valeria Caruso, Anna De Meo and Vincenzo Norman Vitale
Increasing information accessibility on the Web: a rating system for specialized dictionaries ............. 
89
Rajen Chatterjee, Gebremedhen Gebremelak, Matteo Negri and Marco Turchi
Online Automatic Post-Editing across Domains ..................................................................................... 
94
Anna Corazza, Valerio Maggio and Giuseppe Scanniello
A new dataset for source code comment coherence ............................................................................... 
100
Elisa Corino and Claudio Russo
Parsing di corpora di apprendenti di italiano: un primo studio su VALICO ......................................... 
105
Danilo Croce, Simone Filice and Roberto Basili
Nystrom Methods for Efficient Kernel-Based Methods for Community Question Answering ............. 
111
CLIC_2016_Proceedings.indd 10
02/12/16 15.03
Marco Del Tredici, Malvina Nissim and Andrea Zaninello
Tracing metaphors in time through self-distance in vector spaces ......................................................... 
117
Giorgio Maria Di Nunzio, Maria Maistro and Daniel Zilio
Gamification for IR: The Query Aspects Game ...................................................................................... 
123
Fabrizio Esposito, Anna Corazza and Francesco Cutugno
Topic Modelling with Word Embeddings ............................................................................................... 
129
Anna Fantini
Spammare senza pieta - Corpus based analysis of English, unacclimatised verb loans in Italian 
and creation of a reference lexicon ......................................................................................................... 
135
Anna Feltracco, Elisabetta Jezek, Bernardo Magnini and Manfred Stede
LICO: A Lexicon of Italian Connectives ................................................................................................ 
141
Marcello Ferro, Franco Alberto Cardillo, Vito Pirrelli, Christina L. Gagné and Thomas L. Spalding
Written word production and lexical self-organisation: evidence from English (pseudo)compounds .. 
146
Francesca Franzon, Giorgio Arcara and Chiara Zanini
Lexical categories or frequency effects? A feedback from quantitative methods applied 
to psycholinguistic models in two studies on Italian .............................................................................. 
152
Jennifer-Carmen Frey, Aivars Glaznieks and Egon W. Stemle
The DiDi Corpus of South Tyrolean CMC Data: A multilingual corpus of Facebook texts ................. 
157
Lorenzo Gregori, Alessandro Panunzi and Andrea Amelio Ravelli
Linking IMAGACT ontology to BabelNet through action videos ......................................................... 
162
Francesca Guglielmi, Pierpaolo Basile, Antonietta Curci and Giovanni Semeraro
Sentiment Analysis: applicazione in un dominio psico-forense ............................................................. 
168
Alberto Lavelli
Comparing State-of-the-art Dependency Parsers on the Italian Stanford Dependency Treebank ......... 
173
Antonio Lieto, Enrico Mensa and Daniele P. Radicioni
Taming Sense Sparsity: a Common-Sense Approach ............................................................................. 
179
Eleonora Litta, Marco Passarotti and Chris Culy
Formatio formosa est. Building a Word Formation Lexicon for Latin .................................................. 
185
Felicia Logozzo
Sequenze N+pN (nome comune + nome proprio): descrizione linguistica da un corpus dell’italiano . 
190
Azzurra Mancuso, Maria De Martino and Alessandro Laudanna
Semantic priming effects in Italian verbs recognition: the role of grammatical classes 
and semantic categories ........................................................................................................................... 
195
Alessandro Mazzei
Building a computational lexicon by using SQL .................................................................................... 
200
Anne-Lyse Minard, Manuela Speranza, Bernardo Magnini and Mohammed R. H. Qwaider
Semantic Interpretation of Events in Live Soccer Commentaries .......................................................... 
205
Johanna Monti, Federico Sangati, Francesca Chiusaroli, Martin Benjamin and Sina Mansour
Emojitalianobot and EmojiWorldBot - New online tools and digital environments for translation 
into emoji ................................................................................................................................................. 
211
Giovanni Moretti, Rachele Sprugnoli and Sara Tonelli
KD Strikes Back: from Keyphrases to Labelled Domains Using External Knowledge Sources .......... 
216
CLIC_2016_Proceedings.indd 11
02/12/16 15.03
Franca Orletti, Felice Dell'Orletta and Rossella Iovino
La leggibilità dei testi di ambito medico rivolti al paziente: il caso dei bugiardini di farmaci 
senza obbligo di prescrizione medica ..................................................................................................... 
222
Lucia C. Passaro, Alessandro Bondielli and Alessandro Lenci
FB-NEWS15: A Topic-Annotated Facebook Corpus for Emotion Detection and Sentiment Analysis . 
228
Marco Passarotti and Marco Budassi
May the Goddess of Hope Help Us. Homonymy in Latin Lexicon and Onomasticon ......................... 
233
Sandro Pezzelle, Ionut Sorodoc, Aurelie Herbelot and Raffaella Bernardi
Imparare a quantificare guardando .......................................................................................................... 
237
Silvia Piccini, Andrea Bellandi, Giulia Benotto and Emiliano Giovannetti
La Modellazione Diacronica di Risorse Termino-Ontologiche nell'Ambito delle Digital Humanities: 
Esperimenti su Clavius ............................................................................................................................ 
243
Giulia Pieri, Dominique Brunato and Felice Dell'Orletta
Studio sull’ordine dei costituenti nel confronto tra generi e complessità .............................................. 
248
Edoardo Maria Ponti, Elisabetta Jezek and Bernardo Magnini
Grounding the Lexical Sets of Causative-Inchoative Verbs with Word Embedding ............................. 
253
Martina A. Rodda, Marco S.G. Senaldi and Alessandro Lenci
Panta Rei: Tracking Semantic Change with Distributional Semantics in Ancient Greek ...................... 
258
Irene Russo, Simone Pisano and Claudia Soria
Sardinian on Facebook: Analysing Diatopic Varieties through Translated Lexical Lists ..................... 
263
Marco S. G. Senaldi, Gianluca E. Lebani and Alessandro Lenci
Determining the Compositionality of Noun-Adjective Pairs with Lexical Variants and Distributional 
Semantics ................................................................................................................................................. 
268
Emilio Sulis, Cristina Bosco, Viviana Patti, Mirko Lai, Delia Irazu Hernandez Farias, 
Letizia Mencarini, Michele Mozzachiodi and Daniele Vignoli
Subjective Well-Being and Social Media. A Semantically Annotated Twitter Corpus on Fertility and 
Parenthood ............................................................................................................................................... 
274
Fabio Tamburini
(Better than) State-of-the-Art PoS-tagging for Italian Texts .................................................................. 
280
Shiva Taslimipoor, Anna Desantis, Manuela Cherchi, Ruslan Mitkov and Johanna Monti
Language resources for Italian: towards the development of a corpus of annotated Italian multiword 
expressions ............................................................................................................................................... 
285
Sara Tonelli, Alessio Palmero Aprosio and Francesca Saltori
SIMPITIKI: a Simplification corpus for Italian ...................................................................................... 
291
Erica Tusa, Felice Dell'Orletta, Simonetta Montemagni and Giulia Venturi
Dieci sfumature di marcatezza sintattica: verso una nozione computazionale di complessità .............. 
297
Antonio Uva and Alessandro Moschitti
Tree Kernels-based Discriminative Reranker for Italian Constituency Parsers ..................................... 
303
Andrea Vanzo, Danilo Croce, Roberto Basili and Daniele Nardi
Context-aware Spoken Language Understanding for Human Robot Interaction ................................... 
308
Index of authors
....................................................................................................................................... 
314
CLIC_2016_Proceedings.indd 12
02/12/16 15.03
13
An extended version of the KoKo German L1 Learner corpus
Andrea Abel, Aivars Glaznieks, Lionel Nicolas, Egon Stemle
Institute for Specialised Communication and Multilingualism
EURAC Research
Bolzano/Bozen, Italy
andrea.abel@eurac.edu, aivars.glaznieks@eurac.edu
lionel.nicolas@eurac.edu, egon.stemle@eurac.edu
Abstract
English.
This
paper
describes
an ex-
tended version of the KoKo corpus (ver-
sion KoKo4,
Dec
2015),
a
corpus
of
written German L1 learner
texts
from
three different
German-speaking regions
in three different countries. The KoKo cor-
pus is richly annotated with learner lan-
guage features on different linguistic lev-
els such as errors or other linguistic char-
acteristics that are not deficit-oriented, and
is enriched with a wide range of metadata.
This paper complements a previous publi-
cation (Abel et al.,
2014a) and reports on
new textual
metadata and lexical
annota-
tions and on the methods adopted for their
manual annotation and linguistic analyses.
It
also briefly introduces some linguistic
findings that
have been derived from the
corpus.
Italiano.
Il
contributo
descrive
una
versione
estesa del
corpus
KoKo (ver-
sione KoKo4,
Dic 2015),
corpus che rac-
coglie produzioni scritte di apprendenti di
tedesco L1,
provenienti da tre distinte re-
gioni germanofone, a loro volta situate in
tre diversi
paesi.
Il
corpus KoKo
`
e an-
notato dettagliatamente su differenti livelli
linguistici
rilevanti,
quali
gli errori
o al-
tre caratteristiche linguistiche non diretta-
mente ricollegabili a deficit individuali, ed
arricchito da un’ampia gamma di
meta-
dati. Questo contributo integra una prece-
dente pubblicazione (Abel et al., 2014a)
`
e
informa sui nuovi metadati testuali e sulle
nuove annotazioni lessicali cosi come sui
metodi
adottati
per la loro annotazione
manuale e per le loro analisi linguistiche.
Inoltre presenta brevemente alcuni
risul-
tati ricavati dal corpus.
1
Introduction
The study of linguistically annotated learner cor-
pora has received a growing interest over the past
20 years (Granger et
al.,
2013).
In learner cor-
pus linguistics, such corpora are usually defined as
“systematic computerized collections of texts pro-
duced by language learners” (Nesselhauf,
2005).
Unlike most
learner corpora focusing on L2/FL
learners (i.e. learners learning a foreign language),
the KoKo corpus focuses on advanced L1 speakers
that are still learning their mother tongue,
which
typically happens in educational contexts.
This paper describes an extended version of the
KoKo corpus (Abel
et
al.,
2014a),
a corpus cre-
ated for the purposes of the KoKo project which
aims at investigating the writing skills of German-
speaking secondary school pupils. The creation of
the corpus was guided by two goals:
on the one
hand to describe writing skills at the end of sec-
ondary school,
on the other hand to consider ex-
ternal socio-linguistic factors (e.g.
gender,
socio-
economic background etc.).
The previous description focused on the data
collection,
the data processing,
the annotation of
orthographic and grammatical features as well as
on aspects regarding annotation quality (Abel
et
al.,
2014a).
This paper,
however,
introduces the
new textual metadata and lexical annotations.
The paper is structured as follows. In section 2,
key facts are briefly reported, including references
to related work.
The new textual
metadata and
lexical annotations are then described in section 3,
alongside with the methods adopted for their man-
ual
annotation and linguistic analyses and some
examples of linguistic findings.
In section 4,
fu-
ture works are discussed right before concluding
in section 5.
CLIC_2016_Proceedings.indd 13
02/12/16 15.03
14
2
Key Information about the Corpus
The KoKo corpus is a collection of 1,503 authen-
tic argumentative essays,
and the corresponding
survey information about their authors,
produced
in classrooms under
standardized conditions by
learners of 85 classes of
66 schools from three
different German-speaking areas:
South Tyrol in
Italy, North Tyrol in Austria and Thuringia in Ger-
many.
1
Such areas are particularly suitable for
comparative studies because of differences regard-
ing the German standard varieties,
the use of di-
alectal vs. standard varieties and the monolingual
vs. plurilingual environments (Abel et al., 2014a).
The corpus is roughly equally distributed over
the three regions and amounts to 824,757 tokens
(punctuation excluded). All writers were attending
secondary schools one year before their school-
leaving examinations.
83% of
the pupils were
native speakers of
German.
The corresponding
L1 part
of
the corpus
amounts
to 726,247 to-
kens.
Metadata annotations amount to 52,605 an-
notations whereas manual annotations amount to
117,422 annotations.
Furthermore,
366 features
to measure linguistic complexity
2
(Hancke et
al.,
2012; Hancke and Meurers, 2013) were automat-
ically calculated per
text
(550,098 in total)
and
added as metadata.
Previous evaluation showed high accuracy of
manual transcriptions (
>
99%
), and automatic to-
kenization (
>
99%
),
sentence splitting (
>
96%
)
and
POS-tagging
(
>
96%
)
(Glaznieks
et
al.,
2014).
As it is among the first accessible richly linguis-
tically annotated German L1 learner corpora,
the
KoKo corpus is particularly relevant to L1 learner
language researchers, and for the field of didactics
of German as L1.
Other comparable language re-
sources are either not accessible (Berg et al., 2010;
DESI-Konsortium, 2006; Nussbaumer and Sieber,
1994),
or although accessible,
have not been en-
riched with linguistic information (Augst
et
al.,
2007;
Fix and Melenk,
2002) or are only partly
1
We followed the privacy policy for such surveys and re-
quested a signed consent from all adult participants and par-
ents of minors.
In addition,
all students participated anony-
mously,
no names of the students were collected,
names of
schools were codified and made anonymous.
2
e.g. syntactic features such as the average length of NPs,
VPs and PPs as well as their number per sentence, morpho-
logical features such as the number of modal verbs per total
number of verbs or the average compound depth of nouns,
and lexical
features such as lexical
diversity described by
means of different measures
annotated (Thelen, 2010).
Some other corpora in-
clude L1 data,
but as reference for L2/FL learner
corpus research (Reznicek et al., 2010; Zinsmeis-
ter and Breckle, 2012).
3
New Metadata and Annotations
This section describes the main features of the lat-
est corpus version KoKo4 (Dec.
2015) that have
been added to the version KoKo3 (Dec.
2014).
It
thus focuses on a new set of textual metadata and
a new layer of lexical annotations which is, due to
the selected features and the degree of granular-
ity,
a novelty in (corpus-based) modeling of L1-
writing competences for German .
3.1
Textual Metadata
In the KoKo corpus,
two kinds of Metadata in-
formation are available:
(1)
non-linguistic,
i.e.
person-related information provided by each par-
ticipant via a questionnaire survey in class that is
available for
the whole sample and (2)
linguis-
tic,
i.e.
text-related information provided for
a
subsample of the corpus (569 texts,
equally dis-
tributed over the three regions involved) through
an online evaluation form by three different spe-
cially trained raters originating from the different
participating regions.
While type (1)
metadata allow for
sociolin-
guistic analyses in order
to detect
relations be-
tween linguistic features (e.g. text length, sentence
length,
orthographic errors,
grammatical
errors,
etc.)
and non-linguistic person-related informa-
tion, type (2) metadata constitute a further expan-
sion of our analysis by including textual features
as well.
Text
analysis was done holistically us-
ing an evaluation form and detailed guidelines that
were elaborated on the basis of recent findings in
writing research and text analyses (Brinker, 2010;
Feilke,
2010;
Augst
et
al.,
2007;
B
¨
ottcher
and
Becker-Mrotzek,
2006;
Jechle,
1992;
Augst
and
Faigel, 1986) and the curricula in the participating
regions.
The text
evaluation form distinguishes
four categories :
(A) formal
completeness,
(B)
content, (C) formal and linguistic means of text
arrangement and (D) overall impression.
For category A, 10 questions of the online eval-
uation form focused on the presence of
obliga-
tory text
parts (introduction,
main part,
closing
part) and explicitly requested constituents of ar-
gumentative essays (opinion of the author, conclu-
sion).
The 25 questions of category B belong to
CLIC_2016_Proceedings.indd 14
02/12/16 15.03
15
two subcategories:
(B1) the topics of the essay (9
questions), (B2) patterns of topic development (16
questions).
B1 comprises evaluations on e.g.
the
topics of each text part,
gaps,
and the overall co-
herence of the text.
B2 refers to the main pattern
of topic development (argumentative, etc.), the ar-
gumentation strategies (point of view,
concessive
or not),
and the motivation of arguments (objec-
tive vs.
subjective stance,
quality of arguments).
Formal and linguistic means of text arrangement
(category C, 7 questions) focus on the use of para-
graphs, the explicit announcement of and commit-
ment to the function of the essay,
and the use of
linguistic means to structure the text with regards
to content.
Finally,
category D (20 questions)
aims for an overall
impression and therefore fo-
cuses on the completion of the task (successful or
not),
the overall quality of the text and the over-
all consistency of both the quality and coherence.
Of all 62 questions of the entire online evaluation
form,
we used 57 for each document of the sub-
corpus (alltogether 33,972 annotations).
The analyses revealed, among other things, that
the text
quality is classified as quite satisfactory
on a 5 point Likert-scale
3
. More specifically, there
are significant
correlations between text
quality
assessment and other linguistic variables:
thus,
a
lower number of e.g. lexical errors is connected to
a higher text quality score
4
, and, finally, a variety
of group differences could be detected (e.g.
con-
cerning school
type:
lower
text
quality scores
within vocational
schools
compared to general
high schools
5
).
3.2
Lexical Annotations
As for the manual
annotations of orthographic
and grammatical
features added to previous cor-
pus versions (Abel
et
al.,
2014a),
a specifically
crafted tag set and annotation manual were used
for
the annotation of
lexical
features.
61,728
lexical
annotations were manually performed by
trained annotators on a subcorpus of 980 texts, al-
most equally distributed over the three regions.
The analyses of lexical features focuses on lex-
ical
knowledge as a central
part
of lexical
com-
petence which includes the dimensions of
lexi-
cal breadth (quantitative aspect) and lexical depth
3
percentages: 1 (scarse): 6.2 - 2: 22.9 - 3: 39.0 - 4: 26.3 -
5 (excellent): 5.7)
4
Kruskal
Wallis H Test:
FS errors X
2
(1) = 10.417,
p =
.036, single word errors: ANOVA F(4, 338) = 2.805, p = .026
5
Kruskal Wallis H Test: X
2
(1) = 49.147, p = .000
Category
Sub-category
Total
Single
Neol. & occas.
4,670
words
Arg. adv. & conj.
14,345
Referential
18,708
Phrasemes
Communicative
4,824
Structural
2,704
Semantic
8,397
Particula-
Stylistic
236
rities
Form
1,923
Metalinguistic
1,412
Target hyp.
4,509
Table 1:
Quantitative figures for the 980 docu-
ments annotated with the new lexical annotations.
(qualitative aspect) (Steinhoff, 2009; B
¨
ottcher and
Becker-Mrotzek,
2006;
Mukherjee,
2005;
Read
and Nation,
2004;
Read,
2000;
Nation,
2001).
Whereas the analyses of
quantitative aspects of
lexical knowledge were performed automatically
by using different measures (e.g. lexical diversity
measures such as MTDL and Yule’s K, or lexical
frequency scores based on dlexDB (Hancke and
Meurers,
2013)),
the analyses of
qualitative as-
pects were done by means of manual annotations.
We focus hereafter exclusively on the manual an-
notations allowing us to model qualitative aspects
of lexical knowledge.
For annotating lexical
features,
we developed
a new hierarchically-structured linguistic classifi-
cation scheme inspired by previous work that fo-
cused on L2 learner languages (Abel et al., 2014b;
Konecny et al.,
2016).
The classification scheme
takes both into account
occurrences of
selected
lexical phenomena and defective as well as non-
defective particularities of learner languages con-
sidering two dimensions: (1) the linguistic subcat-
egory, e.g. collocations and idioms, and (2) a tar-
get modification classification,
e.g.
omission,
ad-
dition (D
´
ıaz-Negrillo and Dom
´
ınguez, 2006; Abel
et al., 2014b).
Furthermore, we formulated target
hypotheses for those categories that we annotated
as defective in order to make the error interpreta-
tion transparent (L
¨
udeling et al., 2005). The corre-
sponding annotation scheme contains 77 different
tags including a set of further attributes.
In a multi-stage annotation procedure,
all
oc-
currences of phenomena on both single words and
formulaic sequences (FS) were annotated (Wray,
2005).
Annotations for particularities were subse-
quently added in order to distinguish between er-
CLIC_2016_Proceedings.indd 15
02/12/16 15.03
16
rors concerning correctness, errors concerning ap-
propriateness of usage (Eisenberg,
2007; Schnei-
der,
2013),
non-defective modifications (to cap-
ture,
for example,
creative use of language),
and
diasystematic markedness.
At
the single word
level,
we considered all out-of-vocabulary tokens
of
the part-of-speech tagger
(Schmid,
1994)
as
candidates of neologisms or occasionalisms.
In
addition,
we captured a variety of
tokens rele-
vant
for
the text
genre of
an argumentative es-
say (i.e. argumentative adverbs and conjunctions).
At
the level
of FS,
we applied a function-based
approach distinguishing between three main cate-
gories of phrasemes (Burger, 2007), each of them
with further
subcategories (Abel
et
al.,
2014b;
Konecny et al., 2016; Granger and Paquot, 2008;
Burger,
2007;
Stein,
2007;
Steinhoff,
2007),
as
well as a “mixed classification” (Burger, 2007):
Referential
phrasemes include collocations
6
and idioms
7
,
distinguished among other
things
with respect to their degree of idiomaticity.
Com-
municative phrasemes are subdivided into those
bound
to
specific
situations
8
,
and
those
not
bound to specific situations
9
.
Finally,
structural
phrasemes comprise complex conjunctions and
prepositions
10
and concessive constructions
11
.
For particularities, we considered four main cat-
egories, each with further subcategories:
On a
semantic
dimension a
distinction is
made between denotative errors concerning cor-
rectness or appropriatness of use
12
,
and connota-
tive markedness or appropriatness of use
13
.
The
stytlistic dimension considers repetition,
and re-
dundancy.
The form dimension focusses
on
6
further
divided into restricted and loose collocations,
light
verb constructions
(called ”Funktionsverbgef
¨
uge” in
German) as well
as special
classes such as irreversible bi-
and trinominals, similes etc.
7
further divided into nominative idioms and fixed phrases,
and special
classes such as irreversible bi- and trinominals
etc.
8
further divided into general routine or speech act formu-
las, special classes such as commonplaces, slogans, proverbs
etc., and empty formulas
9
further divided into text organising formulas,
and inter-
action organising formulas
10
further divided into phraseological connectors and syn-
tactically complex connectors, and secondary prepositions
11
further divided into constructions with ”although” and a
correlate of the ”but”-class,
and constructions with a modal
word and a correlate of the ”but”-class
12
further
divided into reference/function,
contextual
fit-
ness, semantic compatibility, and precision
13
further divided into speaker’s attitude,
and diasystem-
atic markedness concerning language usage,
i.e.
diaphasic
markedness, diachronic markedness, diatopic markedness
word formation errors (concerning single word
units only
14
),
and on omission,
choice,
position
and addition errors as well
as creative modifica-
tions (concerning FS). Concerning metalinguistic
markers the appropriateness of the use of quota-
tion marks for highlighting units is considered.
An overview of the number of annotations is
provided in Table 1.
Results of
the analyses showed,
among oth-
ers,
that
pupils use different
types of
FS quite
frequently,
on average
5.12 constructions
per
100 words:
with 62%,
non idiomatic referen-
tial
phrasemes
constitute
the
major
part,
fol-
lowed by idiomatic referential phrasemes (19%),
and,
finally,
structural (10%) and communicative
phrasemes (9%).
However,
lexical errors in gen-
eral
affect
more often FS than single word units
(10% of the FS vs.
1.04% of the single words).
The latter are most frequently form errors (5.50%
of FS affected, especially choice errors: 4.17%).
4
Future Work
The KoKo project
was completed and presented
to the public in December 2015.
We will
start
releasing the data via the corpus exploration in-
terface ANNIS3 (Krause and Zeldes,
2016) and
for download on request,
after signing a license
agreement.
15
Aside from the aforementioned data,
future versions will also include additional meta-
data information about the authors integrated for
the purposes of future socio-linguistic analyses.
Consensus in the annotations among annotators,
and as such an indication of
its reliability,
will
be evaluated on sub-sets of texts that were anno-
tated for this purpose by more than one annotator.
Three annotators independently annotated the text
level metadata annotations on 27 texts, and six an-
notators independently annotated the lexical level
annotations on the same 27 texts.
Inter-annotator
agreement will be calculated for annotations and
segmentation,
i.e.
the agreement
on the decision
which word sequence needs to be tagged vs. what
annotation needs to be assigned to it,
and will be
evaluated and reported in the form of Fleiss Multi-
k and boundary similarity (Artstein and Poesio,
2008; Fournier, 2013).
Finally, thanks to its relatively large size and its
richly annotated nature,
potential additional uses
14
distinguishing between errors with respect to derivation
and to composition
15
We have been trying to make the data available for direct
download – but have to take more legal hurdles.
CLIC_2016_Proceedings.indd 16
02/12/16 15.03
17
of the KoKo corpus in Natural Language Process-
ing and Corpus Linguistics are being considered.
Regarding Natural Language Processing, the error
annotations paired with target hypothesis annota-
tions allow for creating an aligned corpus.
Such
corpora can be used to improve machine transla-
tion for automatically correcting learner texts (Ng
et al.,
2014).
Regarding Corpus Linguistics,
ma-
chine learning methods can be used (e.g. as being
done in WebAnno (Yimam et al.,
2014)) to drive
linguistic intuitions when performing annotations
or analyses. Because of the richness of its annota-
tion schemes, the KoKo corpus constitutes a chal-
lenging but at the same time promising dataset to
test if the developed methods are able to uncover
relevant correlations that have already been inves-
tigated, or to uncover even new ones that are worth
considering for future linguistic analyses.
5
Conclusion
This paper described the most recent version of the
KoKo corpus, a collection of richly annotated Ger-
man L1 learner texts, and focused on the new tex-
tual metadata and lexical annotations.
Because other comparable language resources
are either not accessible, or have not been enriched
with linguistic information or are only partly an-
notated,
the corpus is a valuable resource for re-
search on L1 learner language,
in particular for
the research on writing skills, and for teachers of
German as L1, in particular for the teaching of L1
German writing skills.
References
Andrea Abel,
Aivars Glaznieks,
Lionel
Nicolas,
and
Egon Stemle.
2014a.
Koko:
An L1 learner corpus
for german.
In Proceedings of LREC 2014,
pages
2414–2421.
Andrea Abel,
Katrin Wisniewski,
Lionel Nicolas,
and
Detmar Meurers.
2014b.
A trilingual learner cor-
pus illustrating european reference levels.
RICOG-
NIZIONI— Rivista di Lingue, Letterature e Culture
Moderne, 1(2):111–126.
Ron Artstein and Massimo Poesio.
2008.
Inter-coder
agreement for computational linguistics.
Computa-
tional Linguistics, 34(4):555–596.
Gerhard Augst and Peter Faigel.
1986.
Von der Rei-
hung zur Gestaltung:
Untersuchungen zur Ontoge-
nese der schriftsprachlichen F
¨
ahigkeiten von 13-23
Jahren,
volume 5 of Theorie und Vermittlung der
Sprache.
Peter Lang, Frankfurt.
Gerhard Augst, Katrin Disselhoff, Alexandra Henrich,
Thorsten Pohl,
and Paul
V
¨
olzing.
2007.
Text-
Sorten-Kompetenz.
Eine echte Longitudinalstudie
zur Entwicklung der Textkompetenz im Grundschul-
alter.
Peter Lang, Frankfurt.
Margit Berg, Anne Berkemeier, Reinold Funke, Chris-
tian
Gl
¨
uck,
Christiane
Hofbauer,
and
Jordana
Schneider,
editors.
2010.
Sprachliche Hetero-
genit
¨
at in der Sprachheil- und der Regelschule. Ab-
schlussbericht
im Programm ,,Bildungsforschung”
der Landesstiftung Baden-Wrttemberg, Germany.
Ingrid B
¨
ottcher and Michael
Becker-Mrotzek.
2006.
Schreibkompetenz entwickeln und beurteilen.
Cor-
nelsen, Berlin.
Klaus Brinker.
2010.
Linguistische Textanalyse. Eine
Einf
¨
uhrung in Grundbegriffe und Methoden.
Bear-
beitet
von Sandra Ausborn-Brinker,
7.,
durchgese-
hene Auflage,
volume 29 of Grundlagen der Ger-
manistik.
Erich Schmidt Verlag, Berlin.
Harald Burger.
2007.
Phraseologie: Eine Einf
¨
uhrung
am Beispiel des Deutschen, volume 36 of Grundla-
gen der Germanistik.
Erich Schmidt Verlag, Berlin.
DESI-Konsortium, editor.
2006.
Unterricht und Kom-
petenzerwerb in Deutsch und Englisch.
Beltz Ver-
lag, Weinheim – Bern.
Ana D
´
ıaz-Negrillo and Jes
´
us Fern
´
andez Dom
´
ınguez.
2006.
Error tagging systems for learner corpora.
Revista espa
˜
nola de ling
¨
u
´
ıstica aplicada,
(19):83–
102.
Peter
Eisenberg.
2007.
Sprachliches
Wissen im
W
¨
orterbuch der Zweifelsf
¨
alle.
¨
Uber die Rekonstruk-
tion einer Gebrauchsnorm.
Aptum.
Zeitschrift
f
¨
ur
Sprachkritik und Sprachkultur, 3(2007):209–228.
Helmuth Feilke.
2010.
Schriftliches
Argumen-
tieren zwischen N
¨
ahe und Distanz am Beispiel wis-
senschaftlichen Schreibens.
N
¨
ahe und Distanz im
Kontext
variationslinguistischer Forschung,
pages
209–231.
Martin Fix and Hartmut
Melenk.
2002.
Schreiben
zu Texten-Schreiben zu Bildimpulsen:
das
Lud-
wigsburger Aufsatzkorpus; mit 2300 Sch
¨
ulertexten,
Befragungsdaten und Bewertungen auf
CD-ROM.
Schneider-Verlag, Hohengehren.
Chris Fournier.
2013.
Evaluating Text Segmentation
using Boundary Edit
Distance.
In Proceedings of
51st Annual Meeting of the ACL, pages 1702–1712.
ACL.
Aivars Glaznieks,
Lionel
Nicolas,
Egon Stemle,
An-
drea Abel,
and Verena Lyding.
2014.
Establishing
a standardised procedure for building learner cor-
pora.
Apples - Journal of Applied Language Studies,
8(3):5–20.
Sylviane Granger and Magali
Paquot.
2008.
Disen-
tangling the phraseological
web.
Phraseology.
An
interdisciplinary perspective, pages 27–50.
CLIC_2016_Proceedings.indd 17
02/12/16 15.03
18
Sylviane Granger, Ga
¨
etanelle Gilquin, and Fanny Me-
unier.
2013.
Twenty Years of Learner Corpus Re-
search. Looking Back, Moving Ahead: Proceedings
of
the First
Learner Corpus Research Conference
(LCR 2011).
Julia Hancke and Detmar Meurers.
2013.
Exploring
CEFR classification for German based on rich lin-
guistic modeling.
In Proceedings of
the Learner
Corpus
Research Conference (LCR 2013),
pages
54–56.
Julia Hancke,
Sowmya Vajjala,
and Detmar Meurers.
2012.
Readability classification for german using
lexical,
syntactic,
and morphological
features.
In
Martin Kay and Christian Boitet,
editors,
Proceed-
ings of COLING 2012, pages 1063–1080, Mumbai.
Thomas Jechle.
1992.
Kommunikatives Schreiben:
Prozess
und
Entwicklung
aus
der
Sicht
kogni-
tiver Schreibforschung,
volume 41 of ScriptOralia.
Gunter Narr Verlag, T
¨
ubingen.
Christine Konecny,
Andrea Abel,
Erica Autelli,
and
Lorenzo Zanasi.
2016.
Identification and Classi-
fication of Phrasemes in an L2 Learner Corpus of
Italian.
In Gloria Corpas Pastor,
editor,
Comput-
erised and Corpus-based Approaches to Phraseol-
ogy, pages 533–542. Editions Tradulex, Geneva.
Thomas Krause and Amir Zeldes.
2016.
ANNIS3:
A
New Architecture for Generic Corpus Query and Vi-
sualization.
Digital Scholarship in the Humanities,
31(1):118–139.
Anke L
¨
udeling, Maik Walter, Emil Kroymann, and Pe-
ter Adolphs.
2005.
Multi-level error annotation in
learner corpora.
In Proceedings of Corpus Linguis-
tics 2005, pages 15–17.
Joybrato Mukherjee.
2005.
The native speaker is alive
and kicking:
Linguistic and language-pedagogical
perspectives.
Anglistik, 16(2):7–23.
I.S.P. Nation.
2001.
Learning Vocabulary in Another
Language.
Foreign Language Study.
Cambridge
University Press.
Nadja Nesselhauf.
2005.
Collocations in a Learner
Corpus, volume 14 of Studies in Corpus Linguistics.
John Benjamins Publishing, Amsterdam.
Hwee Tou Ng,
Siew Mei Wu,
Ted Briscoe,
Christian
Hadiwinoto, Raymond Hendy Susanto, and Christo-
pher Bryant.
2014.
The CoNLL-2014 Shared Task
on Grammatical Error Correction.
In Proceedings of
the Eighteenth Conference on Computational Natu-
ral Language Learning:
Shared Task,
pages 1–14,
Baltimore, Maryland. ACL.
Markus Nussbaumer and Peter Sieber.
1994.
Texte
analysieren mit dem Z
¨
urcher Textanalyseraster.
In
Peter
Sieber,
editor,
Sprachf
¨
ahigkeiten–Besser als
ihr Ruf und n
¨
otiger den je!, pages 141–186. Verlag
Sauerl
¨
ander, Aarau.
John Read and Paul
Nation.
2004.
Measurement
of formulaic sequences.
In Norbert
Schmitt,
edi-
tor,
Formulaic sequences:
Acquisition,
processing
and use, Language Learning & Language Teaching,
pages 23–35.
John Benjamins Publishing,
Amster-
dam.
John Read.
2000.
Assessing vocabulary.
Cambridge
University Press.
Marc Reznicek,
Maik Walter,
Karin Schmidt,
Anke
L
¨
udeling,
Hagen Hirschmann,
Cedric Krummes,
and Torsten Andreas.
2010.
Das Falko-Handbuch.
Korpusaufbau und Annotationen.
Technical
re-
port,
Institut
f
¨
ur deutsche Sprache und Linguistik,
Humboldt-Universit
¨
at zu Berlin.
Helmut
Schmid.
1994.
Probabilistic part-of-speech
tagging using decision trees.
In International Con-
ference on New Methods in Language Processing,
pages 44–49, Manchester, UK.
Jan Georg Schneider.
2013.
Sprachliche ,Fehler’ aus
sprachwissenschaftlicher
Sicht.
In Sprachreport,
volume 1-2/2013, pages 30–37. Institut fr Deutsche
Sprache, Mannheim.
Stephan Stein.
2007.
M
¨
undlichkeit und Schriftlichkeit
aus phraseologischer Perspektive.
In Harald Burger,
Dmitrij
Dobrovolskij,
Peter
K
¨
uhn,
and Neal
R.
Norrick,
editors,
Phraseologie.
Ein internationales
Handbuch zeitgen
¨
ossischer Forschung,
volume 1,
pages 220–236. de Gruyter, Berlin – New York.
Torsten Steinhoff.
2007.
Wissenschaftliche Textkom-
petenz: Sprachgebrauch und Schreibentwicklung in
wissenschaftlichen Texten von Studenten und Ex-
perten,
volume 280 of Reihe Germanistische Lin-
guistik.
de Gruyter, Berlin – New York.
Torsten Steinhoff.
2009.
Wortschatz–eine Schalt-
stelle f
¨
ur den schulischen Spracherwerb?,
volume
17/2009 of SPASS.
Universit
¨
at Siegen, FB 3.
Tobias
Thelen.
2010.
Automatische Analyse or-
thographischer
Leistungen von Schreibanf
¨
angern.
Ph.D. thesis, University of Osnabr
¨
uck.
Alison Wray.
2005.
Formulaic language and the lexi-
con.
Cambridge University Press.
Seid Muhie Yimam, Richard Eckart de Castilho, Iryna
Gurevych,
and Chris
Biemann.
2014.
Auto-
matic Annotation Suggestions and Custom Annota-
tion Layers in WebAnno.
In Kalina Bontcheva and
Zhu Jingbo, editors, Proceedings of the 52nd Annual
Meeting of the ACL. System Demonstrations, pages
91–96. ACL, jun.
Heike
Zinsmeister
and
Margit
Breckle.
2012.
The
alesko
learner
corpus:
design–annotation–
quantitative analyses.
Multilingual
Corpora and
Multilingual
Corpus
Analysis.
Amsterdam:
John
Benjamins, pages 71–96.
CLIC_2016_Proceedings.indd 18
02/12/16 15.03
19
(Almost) Automatic Conversion of the Venice Italian Treebank into the
Merged Italian Dependency Treebank Format
Linda Alfieri
FICLIT, University of Bologna, Italy
lindalfieri1988@gmail.com
Fabio Tamburini
FICLIT, University of Bologna, Italy
fabio.tamburini@unibo.it
Abstract
English.
This paper describes the auto-
matic procedure we developed to convert
an Italian dependency treebank into a dif-
ferent format. We defined about 4,250 for-
mal
rules for rewriting dependencies and
token tags as well as an algorithm for tree-
bank rewriting able to avoid rule interfer-
ence.
At
the end of this process a large
portion of the whole treebank was auto-
matically converted, with very few errors,
leaving only a small amount of work to be
done manually.
Italiano.
Questo contributo descrive la
procedura automatica sviluppata per con-
vertire un treebank italiano in un formato
diverso.
Abbiamo definito circa 4.250 re-
gole formali di riscrittura per le strutture a
dipendenza e i tag dei token e un algoritmo
per la conversione del treebank in grado di
evitare l’interferenza tra le regole.
Al ter-
mine del processo una consistente sezione
dell’intero treebank
`
e stata automatica-
mente convertita, con un numero ridotto di
errori,
lasciando solo una piccola quan-
tit
`
a di lavoro da svolgersi manualmente.
1
Introduction
The availability of large annotated language re-
sources is a prerequisite for the development
of
reliable automatic annotation tools using machine
learning techniques.
Automatic tools able to enrich real
texts with
sentence syntactic structures
are central
instru-
ments
in Natural
Language
Processing (NLP)
pipelines for a reliable annotation of text corpora.
Modern NLP parsers heavily depend on complex
training phases performed by examining manually
annotated treebanks.
Data sparsity, especially for
low-resourced languages,
seriously affect parsers
performances,
forcing scholars to annotate more
and more data.
Since 2012 the state-of-the-art for Italian tree-
banks were not
so satisfactory:
three different
projects and institutions produced three treebanks
using different background theories, different for-
mats and also different syntactic structures.
They
were the Italian Syntactic Semantic Treebank -
ISST (Montemagni
and Simi,
2007),
the Turin
University Treebank - TUT (Bosco et
al.,
2000)
and the Venice Italian Treebank - VIT (Delmonte
et al., 2007).
Table 1 outlines the main character-
istics of these treebanks at that time.
ISST
TUT
VIT
Size (approx.)
tokens
80,000
104,000
320,000
sentences
3,100
3,400
10,200
Type
Depend.
Depend.
Phr. Str.
Table 1: Italian treebanks in 2012.
ISST and TUT were used as gold standards in
various evaluation campaigns (CoNLL2007 and
EVALITA series),
but
only in 2012 the research
groups developing such treebanks started to inte-
grate them into a unique resource.
In 2012 the
Merged Italian Dependency Treebank - MIDT -
was created and released by fusing the two re-
sources (Bosco et
al.,
2012)
and in the follow-
ing years this project evolved such resource insert-
ing it into the big Universal Dependency - UD -
project (Nivre, 2015; Attardi et al., 2015), through
another intermediate step, the Italian Stanford De-
pendency Treebank - ISDT (Bosco et al.,
2013).
During this process some other
annotated texts
were added to the treebank leveraging its
size
to around 315,000 tokens and 12,700 sentences
(UD
Italian, v1.3).
This paper describes the latest effort for the Ital-
ian treebank merging:
the conversion,
harmoni-
CLIC_2016_Proceedings.indd 19
02/12/16 15.03
20
sation and integration of the written sections of
VIT,
not previously included into ISST,
with the
other two resources for reaching a global amount
of about 600,000 tokens and 23,000 sentences syn-
tactically annotated.
For practical
issues we de-
cided to convert
VIT into the MIDT format
and
then use the set of already designed automatic pro-
cedures and checking programs to transform it into
the final UD format.
There are other notable works aimed at treebank
conversion in various languages,
for example we
can cite (Bos et al., 2009) for Italian.
2
The Venice Italian Treebank
The Venice Italian Treebank was created by the
Laboratory of
Computational
Linguistics of
the
Department of Language Sciences,
University of
Venice (Delmonte et
al.,
2007).
The theoretical
framework behind VIT syntactic representation is
the X-bar theory, thus the early version of the tree-
bank expresses syntactic information as trees.
At
a later time,
one of the authors converted
the treebank from phrase-structure to dependency
structures (Delmonte, 2009), but this was not dis-
tributed. This version of VIT was the starting point
for the conversion described in this paper.
3
The Merged Italian Dependency
Treebank
The Merged Italian Dependency Treebank was
created as a first
attempt
to merge two existing
Italian resources,
namely the TUT and a special
version of the ISST treebank named ISST-TANL
(Bosco et
al.,
2012)
and represents the starting
point
for all
subsequent
attempts to convert
and
harmonise this resource to different standards, first
the Stanford Dependencies
1
and last the Universal
Dependencies
2
.
4
VIT Conversion
The main part
of
the VIT conversion process
was completely automatic.
Using the Semgrex
package
3
(Chambers et al.,
2007) from the Stan-
fordNLP group, we set up a set of procedures that,
starting from the definition of conversion rules, au-
tomatically converted the VIT into the MIDT for-
mat.
This procedure has been developed specifi-
1
http://nlp.stanford.edu/software/stanford-
dependencies.shtml
2
http://universaldependencies.org/
3
http://nlp.stanford.edu/software/tregex.shtml
cally for our conversion problem, but can be used,
in principle,
to convert any dependency treebank
represented using the CoNLL format in a different
format that does not require re-tokenisation steps.
4.1
The Semgrex language
Semgrex
represents
nodes
in
a
dependency
graph as
a
(non-recursive)
attribute-value
ma-
trix.
It
then
uses
regular
expressions
for
subsets
of
attribute
values.
For
example,
{
word:amo;tag:/N.
*
/
}
refers to any node
that has a value ‘amo’ for the attribute ‘word’ and
a ‘tag’ starting with ‘N’, while ‘
{}
’ refers to any
node in the graph.
The most
important
part
of
Semgrex is that it allows you to specify relations
between nodes or group of nodes.
For example,
‘
{}
=1 <subj
{}
=2’ finds all the pairs of nodes
connected by a directed ‘subj’ relation.
Logical
connectives can be used to form more complex
patterns and node naming (the ‘=’ assignments)
can help retrieve matched nodes from the patterns.
Unfortunately
Semgrex
is
simply
a
query
language and,
in its
original
form,
cannot
be
used to rewrite dependency (sub)graphs.
In order
to extend the possibility of
Semgrex,
we then
modified the original application to manage pairs
of patterns: the first is used to search into the tree-
bank for the required subgraphs,
and the second
is used to specify how the retrieved subsgraphs
have to be rewritten.
For example the pattern pair
{
tag:det
}
=1 >arg
{
tag:noun
}
=2
-->
{
tag:ART
}
=1 <DET
{
tag:NN
}
=2,
what
we
called a ‘Semgrex rule’,
changes the direction of
the dependency and,
at
the same time,
changes
the words tags and relation label. The starting and
final
patterns have to contain the same number
of nodes and dependency edges.
Node naming
has been the fundamental trick to introduce such
extension allowing for
node matching between
patterns.
4.2
Conversion Procedure
For converting VIT into MIDT format, we manu-
ally defined about 4,050 Semgrex rules each cap-
turing a specific syntactic configuration in VIT and
transforming it into the MIDT schema and about
150 rules for
residual
tag rewriting.
We spent
about six months for writing the entire set of rules.
We have defined a set of new rewriting opera-
tions on a general dependency treebank:
•
DEL
REL(graphID, depID, headID): deletes
CLIC_2016_Proceedings.indd 20
02/12/16 15.03
21
a dependency edge between two graph nodes;
•
INS REL(graphID,
depID,
headID,
label):
inserts a new labelled dependency edge be-
tween two graph nodes;
•
REN
TAG(graphID,
nodeID,
tag):
replace
the tag of a specific graph node.
The conversion task has been implemented as a
three-steps process:
•
first of all,
each Semgrex rule is always ap-
plied to the original treebank producing a set
of matching subgraphs that have to be rewrit-
ten;
•
for each match, a set of specific operations for
rewriting the subgraph corresponding to the
processed matching are generated and stored;
•
last,
the whole set
of
operations produced
processing the entire set
of Semgrex rules,
each applied to the
original
treebank,
is
sorted by graphID,
duplicates are removed
and every operation is applied graph by graph
respecting the following order:
first
depen-
dency deletions,
second dependency inser-
tions and lastly tag renaming.
This way of
processing the original
treebank
and transforming it
into the new format
should
guarantee that we do not experience rule interfer-
ence during the conversion,
because the genera-
tion of the rewriting operations due to the Sem-
grex rules application is decoupled from the real
treebank rewriting.
5
Some Linguistic Issues
The set
of rules manually written for converting
VIT dependency structures can be subdivided into
two macro-classes: (a) rules that do not modify the
structures and (b) rules that need to modify the de-
pendencies, both in term of edge direction and in
term of different structuring between the involved
nodes.
Regarding the rules that do not modify the de-
pendency structures,
they simply rename the de-
pendency label using a 1:1 or an N:1 look-up ta-
ble,
as VIT,
with respect
to MIDT,
typically in-
volves more specific dependency types.
Figure
1 outlines some simple examples of such kind of
conversions.
Figure 1:
Some simple examples of rules that do
not modify the dependency structures.
There are,
of course,
other kind of operations
on subgraphs that require also the rewriting of the
dependency structure.
A good example concerns
relative clauses in which the role of the relative
pronoun and,
as a consequence,
the connections
of the edge expressing the noun modification are
completely different in the two formalisms. Figure
2 shows one example of this kind of rewriting.
Cases of coordination presented several
prob-
lems:
in VIT the head of the coordinated struc-
ture is linked to the connective and then the two
(or possibly more) coordinated structures can be
linked with a wide range of different dependency
types (e.g.
between phrases - sn,
sa,
savv,
sq,
sp, predicative complements - acomp, ncomp, ad-
juncts - adj,
adjt,
adjm,
adjv,
subjects - subj,
ob-
jects -
obj,
etc.)
leading to a large number
of
different
combinations.
Moreover,
each depen-
dency combination has to be further specified by
the different token tags.
MIDT represents coordi-
nate structures in a different way:
the connective
and the second conjunct are both linked to the first
conjunct that is connected to the head of the coor-
dinated structure.
Figure 3 shows one example:
the first
formal
rule represents an abstract rule pattern that has to
be filled with all the real tag combinations found
in VIT,
generating a huge number
of
different
rules,
one of them outlined by the second com-
plete formal
rule.
This process generated more
than 2,800 different rules for handling all the co-
ordinated structures in VIT.
There is also a need for a third kind of rules
for rewriting single PoS-tags that might have re-
mained unchanged during the main conversion
process.
CLIC_2016_Proceedings.indd 21
02/12/16 15.03
22
Figure 2: An example of rule that rewrite the dependency structure.
Figure 3: An example of coordination structures in VIT and MIDT and the conversion rule.
One further point deserves some discussion.
In
VIT,
articulated prepositions are represented as
two different tokens both linked with a common
head:
the preposition is tagged part/partd/partda
and usually connected to the head with some kind
of modification relations and the article is always
tagged art
and linked to the head with a det
re-
lation.
In MIDT articulated prepositions are rep-
resented by a single token.
As we said before,
our process does not
allow re-tokenisation rules.
Given that MIDT is only an intermediate format
and the goal is to convert VIT into the UD standard
that requires two tokens for this phenomenon, we
decided to avoid any re-tokenisation and to convert
such structures linking the preposition to the head
and the article to the preposition by introducing a
new, dummy, relation label ‘REL
EA’.
6
Evaluation
Applying all the 4,250 Semgrex rules, we obtained
a converted treebank in which 228,534 out
of
280,641 dependency relation were automatically
converted, giving a global coverage of 81.4%.
To test the effectiveness of the conversion pro-
cedure and the conversion rules we randomly se-
lected 100 sentences (2582 dependency relations
to be converted) from the treebank and manually
checked every newly created dependency relation,
both in term of the connected nodes and the as-
signed label.
We obtained the following results:
among the
2008 relations that have been automatically con-
verted we found 125 wrongly converted depen-
dency relations. So, on this sample, we obtained a
coverage of 2008/2582 = 77.8%, slightly less than
on the whole treebank, with a conversion error rate
= 125/2008 = 6.2%.
7
Discussion and Conclusions
This paper presents the procedure we developed
to convert VIT, one Italian treebank, into a differ-
ent format.
Most of the described conversion pro-
cedure rely on an automatic algorithm based on
CLIC_2016_Proceedings.indd 22
02/12/16 15.03
23
formal rules that is able to automatically convert
the 81.4% of the treebank. This procedure can be,
in principle, adaptable to any conversion between
different dependency treebank formats.
The formal rules has been manually defined by
using a well known dependency search procedure,
Semgrex from StanfordNLP group,
properly ex-
tended to handle rewriting rules and the final result
was manually evaluated to test the effectiveness of
the written rules obtaining a very small error rate.
To the best of our knowledge, there is no general
purpose tool available to automatise this task for
dependency graphs.
We can find some powerful
converters in literature but they are usually tied to
specific pair of tagsets (often tailored to the Penn
treebank) (Johansson and Nugues, 2007; Choi and
Palmer,
2010),
and cannot
be easily adapted to
general needs, or are devoted to tree manipulation,
for example the tool ‘Tregex’ (Levy and Andrew,
2006).
Even if the described procedure can convert a
large part of the treebank automatically with a very
small quantity of errors,
the conversion certainly
needs a careful
manual
analysis to complete the
task and check the new treebank for
remaining
mistakes.
The VIT treebank contains a lot of spe-
cific and peculiar dependency subgraph for repre-
senting phenomena in a very detailed way. Trying
to capture all these different variations into formal
rules can result in a very large rule set mostly com-
posed of rule that handle single cases. We stopped
the production of new rules when this situation
arose.
Acknowledgments
We wish to thank Rodolfo Delmonte and Maria
Simi
for their precious suggestions and explana-
tions for the analysis of linguistic phenomena and
for defining the conversion process.
References
Giuseppe Attardi,
Simone Saletti,
and Maria Simi.
2015.
Converting Italian Treebanks:
Towards an
Italian Stanford Dependency Treebank.
In Proc. of
2nd Italian Conference on Computational Linguis-
tics - CLiC-it 2015, pages 25–30, Trento.
Johan Bos,
Cristina Bosco,
and Alessandro Mazzei.
2009.
Converting a dependency treebank to a cat-
egorial grammar treebank for Italian.
In Proc. of 8th
International Workshop on Treebanks and Linguistic
Theories - TLT8, Milano.
Cristina Bosco, Vincenzo Lombardo, Daniela Vassallo,
and Leonardo Lesmo.
2000.
Building a treebank
for
Italian:
a data-driven annotation schema.
In
Proc.
2nd International
Conference on Language
Resources and Evaluation - LREC 2000, pages 99–
105, Athens.
Cristina Bosco,
Simonetta Montemagni,
and Maria
Simi.
2012.
Harmonization and Merging of two
Italian Dependency Treebanks.
In Proc.
of
LREC
2012,
Workshop on Language Resource Merging,
pages 23–30, Istanbul.
Cristina Bosco,
Simonetta Montemagni,
and Maria
Simi.
2013.
Converting Italian Treebanks: Towards
an Italian Stanford Dependency Treebank.
In Proc.
of ACL Linguistic Annotation Workshop & Interop-
erability with Discourse, Sofia.
Nathanael
Chambers,
Daniel
Cer,
Trond Grenager,
David Hall, Chloe Kiddon, Bill MacCartney, Marie-
Catherine de Marneffe,
Daniel
Ramage,
Eric Yeh,
and Christopher Manning.
2007.
Learning Align-
ments and Leveraging Natural Logic.
In Proc. of the
Workshop on Textual Entailment and Paraphrasing,
pages 165–170.
Jinho Choi
and Martha
Palmer.
2010.
Robust
Constituent-to-Dependency Conversion for English.
In Proc. of 9th International Workshop on Treebanks
and Linguistic Theories - TLT9, Tartu, Estonia.
Rodolfo Delmonte, Antonella Bristot, and Sara Tonelli.
2007.
VIT - Venice Italian Treebank: Syntactic and
Quantitative Features.
In Proc.
Sixth International
Workshop on Treebanks and Linguistic Theories.
Rodolfo Delmonte.
2009.
Treebanking in VIT: from
Phrase Structure to Dependency Representation.
In
Sergei Nirenburg, editor, Language Engineering for
Lesser-Studied Languages, pages 51–81. IOS Press,
Amsterdam, The Netherlands.
Richard Johansson and Pierre Nugues.
2007.
Ex-
tended Constituent-to-dependency Conversion for
English.
In Proc.
of
NODALIDA 2007,
Tartu,
Es-
tonia.
Roger Levy and Galen Andrew.
2006.
Tregex and
Tsurgeon:
tools for querying and manipulating tree
data structures.
In Proc.
of 5th International Con-
ference on Language Resources and Evaluation -
LREC 2006, Genoa, Italy.
Simonetta Montemagni
and Maria Simi.
2007.
The
italian dependency annotated corpus developed for
the conll-2007 shared task.
Tech. report, ILC-CNR.
Joakim Nivre.
2015.
Towards a Universal
Gram-
mar for Natural Language Processing.
In Proc.
of
16th International
Conference Computational
Lin-
guistics and Intelligent
Text
Processing - CICLing
2015, pages 3–16, Cairo, Egypt.
CLIC_2016_Proceedings.indd 23
02/12/16 15.03
24
Hybrid Language Segmentation for Historical Documents
Alfter,
David and Bizzoni,
Yuri
University of Gothenburg
{firstname.lastname}@gu.se
Abstract
English.
Language segmentation, i.e.
the
division of a multilingual text into mono-
lingual
fragments has been addressed in
the past,
but its application to historical
documents has been largely unexplored.
We propose a method for language seg-
mentation for multilingual historical doc-
uments.
For documents that
contain a
mix of high- and low-resource languages,
we leverage the high availability of high-
resource language material
and use un-
supervised methods for the low-resource
parts.
We show that our method outper-
forms previous eﬀorts in this ﬁeld.
Italiano.
La segmentazione del linguaggio,
la
divisione di un testo multilingue in frammenti
monolingue,
è stata aﬀrontata nel passato,
ma
la sua applicazione a documenti
storici
è ri-
masta in gran parte inesplorata.
Proponiamo
un metodo per la segmentazione linguistica di
documenti
storici
multilingue.
Per documenti
che contengono sia lingue ad alta disponibil-
ità di risorse che lingue sottorappresentate, uti-
lizziamo a nostro vantaggio l’elevata disponi-
bilità delle
lingue
con un’ampia gamma di
risorse e impieghiamo sistemi non supervision-
ati
per le parti
che dispongono di
un minor
numero di
risorse.
Mostriamo che il
nostro
metodo supera gli
sforzi
precedenti
in questo
settore.
1
Introduction
e computational
processing of historical
doc-
uments presents challenges that
modern docu-
ments do not; oen there is no standard orthogra-
phy,
and the documents may interleave multiple
languages (Garree et al., 2015).
Furthermore, the
languages used in the documents may by now be
considered dead languages.
is work will
address the issue of language
segmentation, i.e.
segmenting a multilingual text
into monolingual fragments for further process-
ing.
While this task has been addressed in the past
using supervised and weakly supervised meth-
ods such as trained language models (Řehŭřek
and Kolkus,
2009;
King and Abney,
2013),
unsu-
pervised methods (Biemann and Teresniak, 2005;
Yamaguchi and Tanaka-Ishii, 2012; Aler, 2015a),
the application to short
messages (Porta,
2014;
Aler,
2015b)
and the application to historical
documents with regard to OCR tasks (Garree
et al.,
2015),
there is still room for improvement,
especially concerning historical documents.
Due to the scarcity of multilingual corpora (Lui
et al.,
2014),
a popular approach is to use mono-
lingual training data.
However, in the case of his-
torical documents,
the number of available texts
in a given historical language might be too low to
yield representative language models.
We propose a method that works on texts con-
taining at least one high resource language and
at least one low resource language.
e intuition
is to use supervised and weakly supervised meth-
ods for the high resource languages and unsuper-
vised methods for the low resource languages to
arrive at a beer language segmentation;
super-
vised methods derived from high-resource lan-
guages single out these languages while unsuper-
vised algorithms tackle the remaining unknown
language(s) and cluster them by similarity.
e presented approach is extendable to more
than one high-resource language,
in which case
a separate language model has to be trained for
each language; the approach is also applicable to
more than one low-resource language, where the
unsupervised methods are expected to produce an
accurate split of all languages present.
CLIC_2016_Proceedings.indd 24
02/12/16 15.03
25
2
Hybrid language segmentation
Let
D
=
w
1
...w
n
be a document consisting of the
words
w
1
to
w
n
.
Let
L
h
be a character-level n-
gram language model trained on data for a high
resource language which occurs in the document
D
.
We ﬁrst apply the language model
L
h
to the
document
D
and assign each word
w
i
the proba-
bility given by
L
h
(1).
∀
w
i
∈
D
:
P
(
w
i
) =
L
h
(
w
i
)
(1)
e language model
L
h
is implemented as a tri-
gram language model
with non-linear back-oﬀ.
For testing purposes, we trained a language model
on a dump of the English Wikipedia (3 GB of com-
pressed data).
Under the assumption that the text contains at
least two languages with at least one word from
each language, we determine the minimum prob-
ability
P
min
for a split (2).
is probability corre-
sponds to the lowest probability assigned by the
language model
L
h
to any word in the text.
P
min
=
min
i=1..n
P
(
w
i
)
(2)
Next,
we determine the maximum probability
distance
P
a
between adjacent words (3) and the
global maximum probability distance
P
g
between
any two words (4).
P
a
=
max
i=2..n
(


P
(
w
i−1
)
−
P
(
w
i
)


)
(3)
P
g
=
max
i=1..n,j=1..n
(


P
(
w
i
)
−
P
(
w
j
)


)
(4)
We also calculate the mean probability
P
mean
between the two adjacent words which maximize
P
a
(5).
P
mean
=
P
(
w
i
) +
P
(
w
j
)
2
(5)
Finally, we calculate the sharpest drop in prob-
abilities and deﬁne
P
mindrop
as the probability at
the lowest point of the drop (6).
P
mindrop
=
max
i=3..n
(


P
(
w
i−2
)
−
P
(
w
i−1
)


+


P
(
w
i−1
)
−
P
(
w
i
)


)
(6)
We
then set
a
preliminary language
split
threshold
P
split
based on
P
min
,
P
a
,
P
g
,
P
mean
and
P
mindrop
(7).
P
split
=
P
a
+P
g
3
+P
mean
2
+
P
mindrop
2
(7)
In a ﬁrst step,
every word
w
i
with a probability
P
above the split threshold
P
split
is considered to
belong to the high resource language modeled by
L
h
and is tagged as such,
while every word
w
j
with a probability
P
below the split threshold is
considered as belonging to an unknown language
and is le untagged.
In a second step,
all untagged words are clus-
tered by similarity.
is is done by using lan-
guage model induction (Aler, 2015a).
All words
le untagged by the previous step are regarded as
one text.
From the ﬁrst word
w
1
,
an initial lan-
guage model
L
i
is created.
e next word
w
2
is
tested against the initial model.
If the probabil-
ity
P
(
w
2
|
L
i
)
exceeds a certain threshold value,
the model is updated with
w
2
,
otherwise a new
model is created.
In this way, we iterate through
the text,
creating language models as necessary.
e same procedure is done starting from the last
word and moving towards the beginning of the
text.
From the two sets of language model induc-
tions (forward, backward), the most similar mod-
els according to their n-gram distribution are then
merged.
is process is repeated, keeping the pre-
viously merged models, until no more models are
induced.
Each
word
is
then tagged
with
the
lan-
guage model
L
m
(
≈
cluster)
which maximizes
P
(
w
|
L
m
)
.
Finally,
all
words
are
evaluated in a local
context
using variable-length Markov Models
(VMM).
is step aims at eliminating inconsis-
tencies,
detecting other-language inclusions and
merging back together same-language fragments.
Řehŭřek and Kolkus (2009)
use a similar tech-
nique, but they use a ﬁxed-width sliding window
while we use a variable window size based on
context.
For each word
w
i
, we look at its tag
t
i
.
We then
consider all the words immediately to the le of
w
i
and all the words immediately to the right of
w
i
that have a tag diﬀerent from
t
i
.
From these
words,
we create local context language models
le (
L
l
) and right (
L
r
).
We calculate the similar-
ity between
L
l
and
L
r
as well as the similarity of
w
i
to
L
l
and
L
r
.
ere are diﬀerent possible sce-
narios:
CLIC_2016_Proceedings.indd 25
02/12/16 15.03
26
1.
L
l
is similar to
L
r
(a)
w
i
is similar to
L
l
or
L
r
(b)
w
i
is dissimilar to
L
l
or
L
r
2.
L
l
is dissimilar to
L
r
(a)
w
i
is similar to
L
l
(b)
w
i
is similar to
L
r
(c)
w
i
is dissimilar to
L
l
and
L
r
In case 1a, we assimilate the tag of
w
i
to the tag
of either
L
l
or
L
r
;
in that case,
the labels for
L
l
and
L
r
are the same.
In case 1b,
w
i
is probably
an other-language inclusion, since it is dissimilar
to its context, while the le and right contexts are
similar.
In case 2a, we assimilate the tag of
w
i
to
the tag of
L
l
, and similarly in case 2b, we assimi-
late the tag of
w
i
to
L
r
.
In case 2c,
w
i
is dissimilar
to its context and the le and right contexts are
also dissimilar.
In this case,
we leave the tag un-
changed.
e following sections describe the data used
for evaluation as well as the results.
3
Data and Evaluation
Pacati,
[Ved.
pacati,
Idg.
*peqǔō,
Av.
pac-;
Obulg.
peka to fry,
roast,
Lith,
kepū bake, Gr.
pέssw cook, pέpwn ripe]
to cook, boil, roast Vin.
IV, 264; ﬁg.
tor-
ment in purgatory (trs.
and intrs.):
Ni-
raye pacitvā aer roasting in N.S.II, 225,
PvA.
10,
14.
– ppr.
pacanto torment-
ing,
Gen.
pacato (+Caus.
pācayato) D.
I,
52 (expld at DA.
I,
159,
where read
pacato for
paccato,
by pare daṇḍena
pīḷentassa).
– pp.
pakka (q.v.).
< -
>Caus.
pacāpeti & pāceti (q.
v.).
– Pass.
paccati
to be roasted or tormented (q.
v.).
(Page 382)
In the absence of beer comparable data,
we
re-use the Pali dictionary data entries presented
in Aler (2015a) and compare our calculated lan-
guage segmentation to the segmentation pre-
sented in Aler (2015a).
e extract
shown corresponds
to the ﬁh
Pali
text
used in the experiments.
It
shows
among others some of
the languages used,
the
unclear
boundaries
between languages,
abbre-
viations,
symbols and references.
Monolingual
stretches tend to be short with interspersed lan-
guage inclusions.
Based on the ﬁndings in Aler (2015a)
that
neither a high Rand Index nor a high F-score
alone yield good segmentations,
but a combina-
tion of high Rand Index and F-score yield good
segmentations,
we have adopted a new measure
of
goodness-of-segmentation
G
s
,
which is the
arithmetic mean of the Rand Index and F5 score
(8).
G
s
=
RI
+
F
5
2
(8)
Due to how precision and recall are calculated
in the context of cluster evaluation, seing
β >
1
,
and thus placing more emphasis on recall,
pe-
nalizes the algorithm for clustering together data
points that are separated in the gold standard and
lowers the impact spliing of data points which
are clustered together in the gold standard.
In-
deed,
it is preferable to have multiple clusters of
a certain language than to have clusters of mixed
languages.
us, we use F5 (
β
= 5
) instead of F1
scores.
We have found le context assimilation to be
working beer than right context assimilation or
both side context assimilation.
We therefore use
only le context assimilation and leave out the
other two options.
4
Results
e following table shows our results (Hybrid
Language Segmentation,
HLS)
compared to the
results given in Aler (2015a) (Language Model
Induction, LMI). We converted the scores given in
Aler (2015a) to the new compound score
G
s
.
e
baselines from Aler (2015a) are also indicated.
AIO indicates the baseline where each word is
thrown into the same cluster;
there is only one
cluster (all-in-one).
AID indicates the baseline
where each word is separated into its own cluster;
there is one cluster per word (all-in-diﬀerent).
Text
AIO
AID
LMI
HLS
Pali 1
0.3174
0.4643
0.5296
0.6665
Pali 2
0.3635
0.5188
0.7662
0.5916
Pali 3
0.4996
0.3071
0.4700
0.6056
Pali 4
0.4047
n/a
n/a
0.4730
Pali 5
0.5848
0.2833
0.4402
0.5863
Table 1:
Results
As
can be
seen from the
results,
our
ap-
proach outperforms the baselines as well
as the
CLIC_2016_Proceedings.indd 26
02/12/16 15.03
27
purely unsupervised language model
induction
approach except for one data point where the lan-
guage model induction produced an almost per-
fect clustering whereas the hybrid language seg-
mentation method did not.
5
Discussion
A big problem with the dictionary data is that
it is transcribed in a noisy manner.
is is not
immediately clear from looking at the data,
but
on closer inspection,
it
can be seen that
some
symbols like commas and full stops are rendered
with non-standard Unicode characters (Unicode
codepoint U+FF0C (FULLWIDTH COMMA) and
Unicode codepoint U+FF0E (FULLWIDTH FULL
STOP))
which break the chosen whitespace to-
kenization method.
is results in chunks that
are bigger than they should be,
oen contain-
ing multiple languages.
We can also see that the
transcription of Greek characters were rendered
as character that look alike but are not actually
Greek characters (see the quote at the beginning
of section 3).
If we look more closely at the results,
we can
see that our approach tends to be overly conﬁ-
dent when assigning words to the high-resource
language,
which in this case is English.
is in-
cludes words that clearly are not English, such as
‘°itar’ and ‘°ātar’
1
.
e following example (Pali 1)
shows the full dictionary entry.
[n.
ag.
fr.
abhijjhita
in med.
function]
one who covets M <small-
caps>i.</smallcaps> 287 (T.
abhijjhā-
tar,
v.
l.
°itar)
=
A <small-
caps>v.</smallcaps> 265 (T.
°itar,
v.
l.
°ātar).
e poor discriminatory power of the model is
probably related to the training data.
While the
English Wikipedia oﬀers a huge amount of train-
ing data, it also includes many non-English words
in explanations and on pages about non-English
non-translatable terms for example.
us, the re-
sulting language model is noisy.
It
might
be possible to increase accuracy by
changing the split
threshold
P
split
,
but
while
choosing a higher
P
split
will eﬀectively reduce the
amount of erroneous English tags, it will also de-
crease the amount of correctly tagged words.
It is
1
Here, ° stands for the root of the head word of the entry,
so °itar should be read ‘abhijjhitar’ and °ātar should be read
‘abhijjhātar’
possible that the unsupervised approach followed
by the local
context smoothing might re-assign
the English words to the English model or at least
to a consistent,
second model.
However,
this re-
mains to be tested.
We think that simply using
more ‘pure’ English training data will improve the
language model’s accuracy.
As for local
context smoothing,
we have not
reached conclusive results.
While in some cases,
it succeeds in re-assigning the correct tag to a pre-
viously incorrectly tagged word,
it also induces
errors by erroneously re-tagging previously cor-
rect tags.
is is most probably due to the short
monolingual fragments in our data; longer mono-
lingual fragments would yield more reliable lan-
guage models.
In connection to this,
calculating
similarity based on small
contexts seems prob-
lematic.
Another problem are non-words and
their treatment.
We have chosen not to cross non-
word boundaries when calculating local context,
but doing so might improve the results.
Finally, we have only tested the approach with
one high resource language and a multitude of
low-resource languages.
It would be interesting
to test the method more extensively using more
high resource language models (which in turn
might interfere with each other).
6
Conclusion
We have introduced a hybrid language segmen-
tation method which leverages the presence of
high-resource language content
in mixed lan-
guage historical documents and the availability of
the necessary resources to build language models,
coupled with an unsupervised language model in-
duction approach which covers the low-resource
parts.
We have shown that
our
method out-
performs the previously introduced unsupervised
language model induction approach.
We have also found that our method seems to
work both on longer texts and on shorter texts,
whereas the approach described in Aler (2015a)
seems to be working beer on shorter texts such
as Twier messages.
e local context approach yields inconclusive
results.
is is most probably due to the similar-
ity measure used and the small
size of the con-
text.
We would need, if possible, a beer similar-
ity measure for small language models or another
method of evaluating the word in respect to its
context.
CLIC_2016_Proceedings.indd 27
02/12/16 15.03
28
References
Aler, D. (2015a).
Language Segmentation.
Mas-
ter’s thesis, Universität Trier.
Aler, D. (2015b). Language segmentation of twit-
ter tweets using weakly supervised language
model induction.
TweetMT @ SEPLN.
Biemann,
C.
and Teresniak,
S.
(2005).
Dis-
entangling
from
babylonian
confusion–
unsupervised
language
identiﬁcation.
In
Computational
Linguistics
and
Intelligent
Text
Processing, pages 773–784. Springer.
Garree,
D.,
Alpert-Abrams,
H.,
Berg-
Kirkpatrick,
T.,
and Klein,
D.
(2015).
Un-
supervised
code-switching
for
multilingual
historical document transcription.
In Proceed-
ings of NAACL.
King,
B.
and Abney,
S.
P.
(2013).
Labeling the
Languages of Words in Mixed-Language Doc-
uments using Weakly Supervised Methods.
In
Proceedings of the Conference of the North American
Chapter of the Association for Computational
Lin-
guistics and Human Language Technologies,
pages
1110–1119.
Lui,
M.,
Lau,
J.
H.,
and Baldwin,
T.
(2014).
Auto-
matic detection and language identiﬁcation of
multilingual documents.
Transactions of the As-
sociation for Computational Linguistics, 2:27–40.
Porta,
J.
(2014).
Twier Language Identiﬁcation
using Rational Kernels and its potential appli-
cation to Sociolinguistics.
TweetLID @ SEPLN.
Řehŭřek,
R.
and Kolkus,
M.
(2009).
Language
identiﬁcation on the web:
Extending the dic-
tionary method.
In Computational
Linguistics
and Intelligent
Text
Processing,
pages 357–368.
Springer.
Yamaguchi,
H.
and Tanaka-Ishii,
K.
(2012).
Text
segmentation by language using minimum de-
scription length. In Proceedings of the 50th Annual
Meeting of the Association for Computational
Lin-
guistics, pages 969–978. Association for Compu-
tational Linguistics.
CLIC_2016_Proceedings.indd 28
02/12/16 15.03
29
Relation mining from clinical records
Anita Alicante, Anna Corazza, Francesco Isgr
`
o
Department of Electrical Engineering and Information Technologies (DIETI)
Universit
`
a di Napoli Federico II
via Claudio 21, 80125 Napoli, Italy
{
anita.alicante|anna.corazza|francesco.isgro
}
@unina.it
Stefano Silvestri
Institute for High Performance Computing and Networking, ICAR-CNR
via P. Castellino, 111, 80131 Napoli, Italy
stefano.silvestri@icar.cnr.it
Abstract
English.
We propose a system to extract
entities and relations from a set
of clini-
cal records in Italian based on two preced-
ing works (Alicante et al., 2016b) and (Al-
icante et al.,
2016a).
This approach does
not require annotated data and is based on
existing domain lexical resources and un-
supervised machine learning techniques.
Italiano.
Proponiamo un sistema per e-
strarre entit
`
a e relazioni da un insieme di
cartelle cliniche in Italiano basato su due
precedenti lavori (Alicante et al., 2016b) e
(Alicante et
al.,
2016a).
Questo approc-
cio non richiede dati
annotati
e si
basa
su risorse lessicali di dominio gi
`
a esistenti
e tecniche di
apprendimento automatico
senza supervisione.
1
Introduction
The digitization of medical documents in hospitals
has produced plenty of information which should
be adequately organized.
While part of the mate-
rial, mainly including international scientific pub-
lications,
is in English,
increasingly more mate-
rial is being created in the language of the country
of the medical
institution.
The main part
of the
local
language material
is represented by patient
records.
They contain important information not
only for preparing care plans or solve problems for
the particular patient, but also to extract statistics
useful for research and also for logistics adminis-
tration.
Automatic processing of such repositories still
can not be straightforwardly applied.
One of the
principal issues to be solved is the automatic ex-
traction of relevant information, usually consisting
in entities and relations connecting them (Alicante
et al.,
2016b).
In the cited work,
we extensively
discuss a domain entity and relation recognition
system for Italian. Such step is at the basis of more
sophisticated analyses, including semantics-based
indexing of documents for improved retrieval, ad-
vanced query based information extraction,
and
the application of
ontology-based strategies for
privacy protection.
General
tools,
such as TextPro (Pianta et
al.,
2008), are not adapted for technical domains such
as the medical one, as they are trained on generic
documents, rather than domain-specific ones. Fur-
thermore,
a lot of tools are available for English
and only a few of them have been ported to Italian.
Another problem to take into account is the occur-
rence,
in clinical
records,
of typos and nonstan-
dard abbreviations,
in addition to the most usual
acronyms.
Last but not least, passing from text to
knowledge processing raises tricky privacy prob-
lems. In fact, especially but not only in small hos-
pitals, obscuring the patient names is not sufficient
to hide their identity as the medical information re-
ported in records are often sufficient to reconstruct
a precise profiling of the patients.
Therefore,
ad hoc solutions represent the only
way to build effective applications to solve this
kind of problems.
For example,
not only domain
entities and relations can help identifying poten-
tially dangerous information, but also ontological
information can be exploited to better protect pa-
tient
privacy (Bonatti
and Sauro,
2013).
Again,
ontologies construction and population are based
on entity and relation extraction.
Efforts to port
systems to languages different
from English require, first of all, the development
of lexical
resources for the considered language.
However,
they are not
sufficient,
because of the
intrinsic differences between languages. A widely
CLIC_2016_Proceedings.indd 29
02/12/16 15.03
30
adopted way to tackle such difficulties is repre-
sented by machine learning approaches.
Although supervised approaches
are
usually
more effective,
they require large corpora of an-
notated data, which are quite expensive to obtain,
as they require that
domain experts invest
time
in a long and tedious annotation activity.
In the
medical
domain,
staff should invest
part
of their
precious time to annotate data with information
about
the presence and the type of domain rele-
vant entities and relations in records to be used for
the training phase.
Things would be much eas-
ier if domain experts are only required to check
an automatically produced annotation.
We there-
fore propose to integrate a knowledge-based and
a text
mining approaches to develop an applica-
tion which requires the expert intervention only to
check on medical and pharmaceutical labels asso-
ciated to groups of relations.
More in detail,
we propose here to integrate
the systems discussed in (Alicante et al.,
2016b)
and in (Alicante et al., 2016a):
the former adopts
domain dependent
lexical
resources
to extract
entities and unsupervised machine learning ap-
proaches to decide where relations occur in the
text.
The latter clusters and labels the extracted
relations with an approach based on lexical seman-
tics.
The paper is organized with Section 2 detail-
ing the approach implementation and Section 3 for
conclusions and future works.
2
Proposed approach
The framework proposed is composed by three
modules,
and its logical
structure is depicted in
Figure 1. The first one is devoted to domain entity
(i.e.,
medical
and pharmaceutical
entities) iden-
tification and classification,
and exploits domain
related lexical resources and standard natural lan-
guage tools.
The second one is based on an unsu-
pervised machine learning approach, namely clus-
tering,
to avoid the necessity of annotating data,
for the relation extraction.
A potential relation is
hypothesized among all pairs of the entities iden-
tified in the preceding phase.
Clustering is then
applied to group similar entity pairs.
Small clus-
ters indicate the lack of repetitive patterns and will
therefore be considered as entity pairs which are
not in relation to each other, while larger clusters
are likely to correspond to different relation types.
Relations are clustered and labeled using the ap-
proach proposed in (Alicante et al.,
2016a).
The
decision about
how a relation can be labeled is
only based on the terms involved in the corre-
sponding entity pair, without considering the con-
text in which it occurs. In fact, this is complemen-
tary with respect to the task of deciding whether
two entities are related,
which should be decided
on the basis of the context where the two entities
occur, as in (Alicante et al., 2016b).
On the other
hand,
by considering only the two involved en-
tities,
we can only decide the type of a relation.
Then,
to decide whether the relation is stated or
negated, also the context should be considered in
the analysis.
The third module of the framework is based on
Word Embeddings (WEs) (Mikolov et al.,
2013)
to represent the words involved in each entity with
a real
valued array.
WEs most
interesting char-
acteristic consists in the fact that the mutual posi-
tion of words in a metric space strongly depends
on their meanings,
so that
words having similar
semantics have large similarity, when this is com-
puted, for example, by cosine similarity.
Embed-
dings can be automatically built from a large col-
lection of unannotated text with a very efficient al-
gorithm.
Therefore, they can be easily applied to
any language, in our case to Italian, provided that
enough texts are available.
We used documents
extracted from Wikipedia for training.
In particu-
lar, we considered pages flagged as Medicine, Bi-
ology and Pharmacy in Italian.
For the extraction,
we used CatScan v3.0
1
,
Wikipedia Export
tool
2
and Wikiextractor
3
.
For each entity,
we then consider the embed-
dings corresponding to each token.
As shown
in (Paperno and Baroni,
2016),
a good represen-
tation for a string of words is given by the sum
of the corresponding WEs.
However,
as we do
not want that such representation depends on the
string length, we normalize the sum by the number
of words involved in the entity,
obtaining the av-
erage or centroid of the corresponding WEs. Each
pair of entities occurring in the same sentence rep-
resents a possible candidate for a relation.
We
therefore build the feature vector for each entity
pair by juxtaposing the average vectors for each
1
https://tools.wmflabs.org/catscan2/
catscan2.php
2
https://en.wikipedia.org/wiki/
Special:Export
3
medialab.di.unipi.it/Project/
SemaWiki/Tools/WikiExtractor.py
CLIC_2016_Proceedings.indd 30
02/12/16 15.03
31
!"#$%&'()*+%,$-%&'(
!"#$%&'().#/0%",&(1
*(%&%2)*+%,$-%&'(
!"#$%&!'()*
#)+$,-.$(
/012&$(-,3
"456$7,2*
')8!#733$(
9$::7&-.$(
97;$00-,3!
6$<-=70!>,&-&--$2
"?698!5!'@A*
*#"-%,'(&-
3%$#&$(
4"5&-$#)
!"-',50
B)(<!>:;$<<-,3!
C$7&1($!D-=&-),7(E
.#/0%",)6$7"#&(1
A7((-$(!C$7&1($
>%&(7=&-),
F5G(7:2
>%&(7=&-),
B)(<!
>:;$<<-,3!
C$7&1($!
>%&(7=&-),
'7-(!H<$,&-I-=7&-),
/012&$(-,3
"456$7,2*
Figure 1:
Architecture for Relation mining from
clinical records.
entity and input this representation into a
k
-means
clustering (Manning et al.,
2008; Shalev-Shwartz
and Ben-David, 2014).
2.1
Input Preprocessing
The text,
processed by our system,
is extracted
from anonymized medical records, in the form of
plain text
encoded in UTF-8.
The text
includes
a small
set
of special
characters,
used as delim-
iters and/or formatters.
The largest part of these
medical
records has been produced by an HL7-
compatible information system. At the end of each
medical record, there is often an ICD9M (Interna-
tional Standard for Encoding and Classifying Dis-
eases) disease code,
which we disregard together
with the rest of the structured part of the records.
The text is initially preprocessed for extracting
textual parts from the medical records, and to get
rid of non-textual characters.
The plain text, pro-
duced by this preprocessing step, is passed to the
natural language processing suite TextPro to per-
form tokenization, sentence splitting, PoS tagging
and lemmatization.
2.2
Entity Extraction
Entity extraction is crucial
for our analysis,
and
a specific module has been implemented with the
goal
of extracting entities which are relevant
for
the application domain:
biomedical and pharma-
ceutical entities in our case. The module follows a
pattern matching approach by identifying each oc-
currence of a number of PoS patterns in the input
text as a candidate to be further analysed.
Afterwards,
for
each token occurring in the
identified pattern,
we search for matches of the
corresponding lemma in the dictionaries.
In case
of multi-word expressions,
when several patterns
apply to overlapping strings of tokens,
we apply
a greedy approach by choosing the longest
one
matching the input.
The output
is produced following the TextPro
format,
that
is a line for each token,
and a col-
umn for each analysis level.
In our system these
files are enriched by the information about Medi-
cal and Pharmaceutical entities obtained from the
dictionaries provided by UMLS
4
and PRB
5
. These
information are labeled as MED for the medical
entities, and FAR for the pharmaceutical ones (the
whole entity tag list is shown in the Table 1).
Table 1: List of medical sub-categories
Description
Label
Medical
MED
Pharmaceutical
FAR
Anatomy
ANA
Organisms
ORG
Diseases
MAL
Chemicals and Drugs
CHE
Technical medical equipment
TEC
Psychology and Psychiatric
PSI
Biology
BIO
Natural Sciences
NAT
Anthropology and Social Science
SOC
Technology, Industry and Agriculture
IND
Humanities
UMA
Computer Science
INF
Groups of People
GRU
Health care
ASS
Characteristics of Publication
PUB
Locations
LOC
In addition to a label indicating whether the en-
tity is medical
(MED) or pharmaceutical
(FAR),
we also add to each medical entity annotation the
sub-categories included in the UMLS database in
correspondence to the dictionary entry. The list of
sub-categories labels are summarized in Table 1.
A side-effect of such sub-categorization is that the
number of potential relations increases while it be-
comes possible to find more specific relations.
4
Unified Medical
Language
System,
http://www.
nlm.nih.gov/research/umls
5
Pharmaceutical Reference Book, officially mantained by
Agenzia Italiana del Farmaco
CLIC_2016_Proceedings.indd 31
02/12/16 15.03
32
2.3
Relation Clustering
We apply the
k
-means approach that
identifies
groups of relations of the same type appearing in
the data set.
Each pair of entities occurring in the
same sentence identifies a potential relation, there-
fore all possible entity pairs must be considered.
We then apply a clustering algorithm to the set of
all the potential relations identified. We will disre-
gard all entity pairs belonging to clusters having a
size smaller than a given threshold.
We then concentrate on the remaining entity
pairs, which are likely to represent actual relations
and semantically cluster them.
The approach pro-
posed for this is structured in three main modules:
Feature Construction, Clustering, and Cluster La-
beling.
The first
module builds a feature vector
based on WEs for each relation candidate; for do-
ing this, first it constructs a WE dictionary by us-
ing a large collection of unannotated texts, in our
case extracted from Wikipedia.
This module is
based on word2vec
6
(Mikolov et al.,
2013).
For
the feature vectors length we chose
500
,
which
is the default choice,
and set the minimum word
count to
3
, to exclude the less frequent words from
the dictionary, obtaining a set of
260
,
680
vectors.
After that, the
k
-means clustering is applied to
the set of feature vectors obtained by the first mod-
ule.
For every entity pair we then construct a Fea-
ture Vector
(FV)
starting from the WE of
each
word involved.
Each entity can be composed by
one or more words, as for example conati di vom-
ito:
in this case, for each entity, we take the aver-
age among the WEs of the words composing the
entity associated to the entity pair.
Finally,
we
concatenate the FVs of the two entities, obtaining
a FV of
1
,
000
entries.
The clustering algorithm is then applied to the
FV data set
by means
of
the C Clustering li-
brary (de Hoon et
al.,
2004),
a fast
C imple-
mentation of the
k
-means algorithm.
As the
k
-
means is characterized by a random initial choice
of the seeds,
we repeated each run
10
times,
al-
ways choosing the best solution.
We considered
the cosine similarity,
choosing a number of clus-
ters equal to
40
, which seemed a reasonable choice
given the results from the experiments in (Alicante
et al., 2016b) and in (Alicante et al., 2016a).
Eventually, to label each cluster we ordered the
pairs in each cluster according to its cosine simi-
6
The software is freely available at
https://code.
google.com/p/word2vec/
larity from the cluster centroid: the first four pairs
are then chosen to characterize the cluster.
As discussed above, each FV can be partitioned
in two parts:
the first half corresponds to the first
entity in the pair,
the second one to the other.
Such partition is consistently maintained during
the whole processing.
Also in the computation of
centroids in the
k
-means clustering algorithm, the
former half of each centroid derives from the av-
erage of the former half of the involved FVs and
then corresponds to the first entity.
Correspond-
ingly,
the latter half of each centroid vector only
depends on the second entity of each involved pair.
The choice of the cluster to which a given item
is assigned is based on the cosine similarity.
Its
computation can be divided in three parts: the dot
product of the part of the two FVs corresponding
to the first entity,
the same for the second entity
and eventually the normalization with respect
to
the whole FV. Therefore, the evaluation of the co-
sine similarity is based on a trade-off between how
similar are the first and the second entities in each
pair.
In other words,
they represent
actual
enti-
ties pairs which are similar to the (abstract) cluster
representative, corresponding to the centroid.
3
Conclusions and future work
In this paper we presented a system for the extrac-
tion of information from clinical records in Italian.
A first part of the system aims to extract domain
relevant entities from medical reports by a pattern
matching approach.
A second part takes the out-
put of the former step and applies a clustering ap-
proach to explore possible relations between such
entities.
A third part is based on WE and aims to
give cues about the type of the relations.
Interestingly, the approach does not require an-
notated data, but only easily available data such as
Wikipedia and off-the-shelf tools in addition to the
documents to process.
Naturally,
available tools
have been trained on annotated data,
but without
any adaptation to the specific domain.
It
would
therefore be interesting to port
it
to a new lan-
guage, possibly different from English, which rep-
resents the most
widely studied among all
lan-
guages.
Acknowledgments
The research presented in this paper was partially
supported by the national projects CHIS - Cultural
Heritage Information System (PON), and BIG4H
CLIC_2016_Proceedings.indd 32
02/12/16 15.03
33
-
Big Data Analytics for
E-Health Applications
(POR).
References
Anita Alicante,
Anna Corazza,
Francesco Isgr
`
o,
and
Stefano Silvestri.
2016a.
Semantic cluster labeling
for medical relations.
In Proceeding of Innovation
in Medicine and Healthcare 2016,
pages 183–193,
Puerto de la Cruz, Tenerife, Spain. Springer.
Anita Alicante,
Anna Corazza,
Francesco Isgr
`
o,
and
Stefano Silvestri.
2016b.
Unsupervised entity and
relation extraction from clinical
records in Italian.
Computers in Biology and Medicine, 72:263–275.
Piero A.
Bonatti
and Luigi
Sauro.
2013.
A confi-
dentiality model
for ontologies.
In Harith Alani,
Lalana Kagal, Achille Fokoue, Paul T. Groth, Chris
Biemann,
Josiane
Xavier
Parreira,
Lora
Aroyo,
Natasha F. Noy, Chris Welty, and Krzysztof Janow-
icz, editors, International Semantic Web Conference
(1), volume 8218 of Lecture Notes in Computer Sci-
ence, pages 17–32. Springer.
Michiel
J.L.
de Hoon,
Seiya Imoto,
John Nolan,
and
Satoru Miyano.
2004.
Open source clustering soft-
ware.
Bioinformatics, 20(9):1453–1454.
C.D.
Manning,
P.
Raghavan,
and H.
Sch
¨
utze.
2008.
Introduction to Information Retrieval.
Cambridge
University Press.
Tomas Mikolov,
Greg Corrado,
Kai
Chen,
and Jef-
frey Dean.
2013.
Efficient
estimation of
word
representations in vector space.
Proc.
of the Inter-
national
Conference on Learning Representations
(ICLR 2013), pages 1–12.
Denis
Paperno and Marco Baroni.
2016.
When
the
Whole
is
Less
than the
Sum of
its
Parts:
How Composition Affects PMI Values in Distribu-
tional
Semantic Vectors.
Computational
Linguis-
tics, 42(2):345–350.
Emanuele
Pianta,
Christian
Girardi,
and
Roberto
Zanoli.
2008.
The TextPro Tool Suite.
In Proceed-
ings of the Sixth International Conference on Lan-
guage Resources and Evaluation (LREC’08), pages
28–30,
Marrakech,
Morocco.
European Language
Resources Association (ELRA).
Shai Shalev-Shwartz and Shai Ben-David.
2014.
Un-
derstanding Machine Learning: From Theory to Al-
gorithms.
Cambridge University Press,
New York,
NY, USA.
CLIC_2016_Proceedings.indd 33
02/12/16 15.03
34
Twitter Sentiment Polarity Classification using Barrier Features
Anita Alicante, Anna Corazza, Antonio Pironti
Department of Electrical Engineering and Information Technologies (DIETI)
Universit
`
a di Napoli Federico II
via Claudio 21, 80125 Napoli, Italy
anita.alicante@unina.it, anna.corazza@unina.it,
antonio.pironti@gmail.com
Abstract
English.
A crucial point for the applica-
bility of sentiment analysis over Twitter is
represented by the degree of manual inter-
vention necessary to adapt the approach to
the considered domain.
In this work we
propose a new sentiment
polarity classi-
fier exploiting barrier features,
originally
introduced for the classification of textual
data.
Empirical
tests
on SemEval2014
competition data sets show that
such ap-
proach overcomes performance of
base-
line systems in nearly all cases.
Italiano.
Un
punto
cruciale
per
l’applicabilit
`
a
della
sentiment
analy-
sis su Twitter
`
e rappresentato dal
livello
di
intervento
manuale
necessario
per
adattare l’approccio al
dominio consid-
erato.
In questo lavoro proponiamo un
nuovo classificatore di sentiment polarity
che sfrutta le barrier features,
originaria-
mente introdotte per la classificazione di
relazioni
estratte da testi.
Test
empirici
sui
data sets
usati
nella competizione
SemEval2014 mostrano che l’approccio
proposto
supera
le
performance
dei
sistemi
baseline
nella maggioranza dei
casi.
1
Introduction
Sentiment analysis (SA) (Pang and Lee, 2008), or
opinion mining,
is mainly about
finding out
the
feelings of people from data such as product
re-
views and news articles.
Most
methods
adopt
a two-step strategy for
SA (Pang and Lee, 2008): in the subjectivity clas-
sification step,
the target
is classified to be sub-
jective or neutral (objective), while in the polarity
classification step the subjective targets are further
classified as positive or negative.
Therefore,
two
classifiers are trained for the whole SA process:
the subjectivity classifier and the polarity classi-
fier.
Polarity is an aspect
of sentiment
analysis
which can be faced as a three-way classification
problem, in that it aims to associate either a posi-
tive, negative or neutral polarity to each tweet.
Expressions in tweets are often ambiguous be-
cause they are very informal messages no longer
than 140 characters, containing a lot of misspelled
words, slang, modal particles and acronyms.
The
characteristics of the employed language are very
different from more formal documents and we ex-
pect statistical methods trained on tweets to per-
form well
thanks to an automatic adaptation to
such specificities.
As evidenced by tasks included in competitions
(Rosenthal et al., 2015) and (Nakov et al., 2016),
twitter sentiment
analysis is a relevant
topic for
scientific research.
To the best of our knowledge
(Ravi and Ravi, 2015; Kolchyna et al., 2015; Silva
et
al.,
2016) present
a comprehensive,
State-of-
the-Art (SoA) review on the research work done
in various aspects of SA.
Furthermore some ap-
proaches, as described in (Gonc¸alves et al., 2016),
are based on the combination of several existing
SoA “off-the-shelf” methods
for
sentence-level
sentiment analysis
1
.
(Saif et al.,
2016) proposes an approach based
on the notion that the sentiment of a term depends
on its contextual semantics and some trigonomet-
ric properties on SentiCircles, that is a
2
D geomet-
ric circle.
These properties are applied to amend
an initial
sentiment
score of terms,
according to
the context in which they are used.
The sentiment
identification at either entity or tweet-level is then
performed by leveraging trigonometric identities
1
A point of strength of this kind of systems is that combin-
ing several classification methods in an ensemble approach
results to be very strong with respect to the input vocabulary
size and to the amount of available training.
CLIC_2016_Proceedings.indd 34
02/12/16 15.03
35
on SentiCircles.
The approach we are proposing has been exper-
imentally assessed by comparing its performance
with two baseline systems.
In addition to that, the
capability of adaptation of the approach to slightly
different
domains has been tested by comparing
on a web-blog data set
the performances of two
systems in which the Barrier Feature(BF) dictio-
nary has been respectively built on a collection of
tweets and Wikipedia webpages.
Eventually,
the
contribution of BF has been evaluated.
2
Proposed approach
Some automatic machine learning approaches re-
cently applied to Twitter sentiment polarity classi-
fication try new ways to run the analysis, such as
performing sentiment label propagation on Twit-
ter follower graphs and employing social relations
for user-level sentiment analysis (Speriosu et al.,
2011).
Others,
not
differently from the one we
are proposing here,
investigate new sets of fea-
tures to train the model
for
sentiment
identifi-
cation,
such as microblogging features including
hashtags, emoticons etc. (Barbosa and Feng, 2010;
Kouloumpis et al., 2011).
Indeed, we are propos-
ing to add Barrier Features (BFs) (Alicante and
Corazza,
2011) to unigrams,
bigrams and input
parse tree and to provide them as input to a Sup-
port Vector Machine (SVM) classifier.
Introduced in the context of another application
of text mining, namely relation classification, BFs
are inspired by (Karlsson et al., 1995) for Part-of-
Speech (PoS) tagging,
but
they have been com-
pletely redesigned as features rather
than rules.
BFs have also been exploited in (Alicante et
al.,
2016) for Italian Language in a unsupervised en-
tity and relation extraction system,
proving the
language portability of
these features.
BFs de-
scribe a linguistic binding between the entities in-
volved in each relation.
BFs require PoS tagging of the considered texts,
which can be automatically performed with very
high accuracy (Gim
´
enez and M
`
arquez,
2004).
In
fact, they consist of sets of PoS tags occurring be-
tween a predefined PoS pair,
namely (endpoint,
trigger).
Similarly to unigrams and bigrams of
words, these features are Boolean: for each tweet,
their value is true if the feature occurs in the tweet,
false otherwise.
Given a set of (endpoint, trigger) pairs P and a
sentence (or tweet, in our case) s, the BFs extrac-
tion algorithm loops over the PoS tags in s and,
for each trigger tag t, it looks backward in the sen-
tence finding the closest occurrence of a PoS tag
e such that
(
e, t
)
∈
P
.
If such endpoint is found,
then the algorithm extracts the barrier feature (e, t,
P T
e,t
),
where
P T
e,t
is the set of PoS tags occur-
ring between e and t. Otherwise it extracts as many
barrier features as the number of the elements in P
having t as trigger tag and, for each of them, the re-
lated tag set is the set of POS tags of all the words
in the sentence preceding the trigger.
While in the preceding work
(Alicante and
Corazza, 2011) (endpoint, trigger) pairs were pre-
defined,
in this work we apply an innovative ap-
proach:
we choose such pairs in a completely au-
tomatic and unsupervised way,
starting from an
unannotated data set,
not necessarily in the same
domain as the final task.
In fact,
BFs are unlexi-
calized as they only depend on PoS tags:
for any
text collection,
we can perform this analysis bas-
ing on a different one which has to be similar in
the kind of language but not necessarily in the do-
main.
For instance, we expect the pairs which are
more effective for the language adopted in tweets
to be generally different from the ones adopted for
standard texts.
In choosing the (endpoint,
trigger)
pairs,
our
purpose is two-fold: we aim to obtain a high vari-
ability of the identified sets of tags while only con-
sidering statistically significant
patterns,
that
is,
patterns having a rather large number of occur-
rences.
In addition to this, we do not want to pe-
nalize longer patterns,
although they usually cor-
respond to larger and then more infrequent sets.
Table 1:
Endpoints and triggers of the BFs em-
ployed for the tweet and text messages task.
Endpoint
Trigger
DT
JJR or NNPS
NNP
NNP or VBZ
IN
NNS
NN
NN or VBG or VBN
RB
RBR
PRP
VBD or VBP
TO
VB
For each possible trigger,
we therefore choose
the endpoint ep which maximizes the expected in-
formation per tag of the set corresponding to the
CLIC_2016_Proceedings.indd 35
02/12/16 15.03
36
Table 2:
BFs built
considering the (endpoint,
trigger) pairs listed in Table 1 and the following text:
Now/RB
I/PRP
can/MD
see/VB
why/WRB
Dave/NNP
Winer/NNP
screams/NNS
about/IN
lack/NN
of/IN
Twitter/NNP
API/NNP
,/,
its/PRP
limitations/NNS
and/CC
access/NN
throttles/NNS
!/.
Barrier Feature
Combined Text
(TO, VB, {MD, PRP, RB})
Now I can see
(NNP, NNP, {MD, PRP, RB, VB, WRB})
Now I can see why Dave
(NNP, NNP, {})
Dave Winer
(IN, NNS, {MD, NNP, PRP, RB, VB, WRB})
Now I can see why Dave Winner screams
(NN, NN, {IN, MD, NNP, NNS, PRP, RB, VB, WRB})
Now I can see why Dave Winner screams about lack
(NNP,NNP, {IN, NN, NNS})
Winer screams about lack of Twitter
(NNP, NNP, {})
Twitter API
(IN, NNS {,, NNP, PRP})
of Twitter API, its limitations
(NN, NN, {,, CC, IN, NNP, NNS, PRP})
lack of Twitter API, its limitations and access
(IN,NNS, {,, CC, NN, NNP, NNS, PRP})
of Twitter API, its limitations and access throttles
BF, that is:
sc
(
ep
) =
−

BF
Pr(
BF
)
1
len
(
BF
)
log Pr(
BF
)
(1)
where
Pr(
BF
)
has been estimated by the corre-
sponding frequency.
In order to cut off insignif-
icant cases,
a threshold has been put on the min-
imum number
of
occurrences of
the considered
BF candidates.
The normalization on the set size
len(BF) has been introduced to avoid penalizing
larger sets.
Table 1 reports the pairs resulting from this
new approach and adopted for the experiments de-
scribed in Section 3, Table 2 shows an example of
BF extraction based on those pairs.
While in the system presented in (Alicante and
Corazza, 2011) BFs were collected by only using
the training set, in this work we consider an addi-
tional feature reduction step: we only take into ac-
count the BFs contained in a BFs dictionary, which
is built by only considering the BFs whose num-
ber of occurrences within an unannotated data set
is greater or equal than a threshold value. The data
set
employed in the BFs dictionary construction
step is not necessarily constrained to the training
set
2
.
Being unlexicalized, BFs lead us to improve the
portability of our approach not only towards new
languages but also towards new kinds of applica-
tions.
In particular,
this and the dictionary con-
struction steps are decisive both for the automation
of the process and for its performance.
2
Specifically, we used the same data set employed for the
identification of the PoS (endpoint, trigger) pairs. This aspect
is not
as trivial
as it
might
seem:
such strategy allows the
application of the approach also to tasks where the size of the
annotated training set is limited.
Figure 1:
Architecture of the system for Twitter
sentiment polarity classification.
3
Experimental Assessment
In order to evaluate our system performance,
we
implemented a solution for
the Message Polar-
ity Classification subtask of SemEval-2014 Task 9
(Sentiment Analysis in Twitter)
3
(Rosenthal et al.,
2014). For each input tweet, our classification sys-
tem decides whether it expresses a positive, nega-
tive, or neutral sentiment.
According to the com-
petition rules,
the only training data we used are
the ones that have been provided by the task or-
ganisers.
We used a training set
of about
8,000
tweets,
a subset
of the training and the develop-
ment data released by the organisers
4
.
After training the classifier on this training set,
the performance of the obtained system have been
evaluated against
the test
datasets provided for
3
The SemEval-2014 Task 9 competition website: http:
//alt.qcri.org/semeval2014/task9/
4
The only way to collect the data is by using the down-
loader script available to the participants to the competition
and some of the tweets were no longer available on Twitter at
the time we ran the script.
CLIC_2016_Proceedings.indd 36
02/12/16 15.03
37
the competition: Twitter2013 (T2013), tweets pro-
vided for
testing the task in 2013;
Twitter2014
(T2014),
a new test
set
delivered in 2014;
Twit-
ter2014Sarcasm( T2014Sa),
a dataset
of
sarcas-
tic tweets;
LiveJournal2014 (LJ2014),
a set
of
sentences extracted from the LiveJournal
blog;
SMS13,
text
messages provided for
testing the
same task in 2013.
The statistics for
each test
datasets are shown in Table 3.
Table 3: Dataset Statistics of SemEval2014-taskB,
Message Polarity Classification
Data Set
Positive
Negative
Neutral
Total
LiveJournal2014
427
304
411
1142
SMS2013
492
394
1207
2093
Twitter2013
1281
542
1426
3249
Twitter2014
633
125
453
1211
Twitter2014Sarcasm
33
40
13
86
Table 4: Experimental results to compare the per-
formance of our systems with the two baseline sys-
tems.
Bold cases correspond to the best
perfor-
mance, while symbol
‡
indicates statistical signif-
icance of the comparison with the confidence in-
terval.
Data Set
LJ2014
SMS2013
T2013
T2014
T2014Sa
BLS1
74.84
70.28
70.75
69.85
58.16
BLS2
69.44
57.36
72.12
70.96
56.50
BFS
68.91
72.01‡
72.88‡
72.10‡
58.79‡
Table 5:
Experimental results to evaluate the BF
contribution.
Bold cases correspond to the best
performance. Symbol
†
indicates the improvement
of BFS is statistical significant,
verified with ap-
proximate randomisation.
Data set
System
P
R
F1
LiveJournal
WOBFS
68.94
62.34
65.32
2014
BFS
74.69†
63.97†
68.91†
SMS
WOBFS
64.25
72.92
67.14
2013
BFS
74.80†
69.43
72.01†
Twitter
WOBFS
74.30
67.32
70.62
2013
BFS
77.96†
68.45†
72.88†
Twitter
WOBFS
76.09
65.81
70.57
2014
BFS
78.19†
66.98†
72.10†
Twitter2014
WOBFS
61.12
52.92
55.28
Sarcasm
BFS
64.75†
54.59†
58.79†
The Barrier Features System (BFS) implements
the approach we are proposing and follows the
schema depicted in Figure 1.
Input is tagged by
using SVMtool
5
(Gim
´
enez and M
`
arquez, 2004) an
SVM-based tagger able to achieve a very compet-
itive accuracy on English texts.
Although accu-
racy is likely to be lower on tweets, classification
performance does not appear to be affected;
this
is probably due to the robustness of the statisti-
cal learner against such kind of errors.
In order to
reduce syntactical irregularities, we remove hash-
tags from tweets before providing them to the PoS-
tagger component.
In the BFS system,
we use the STS data set
6
to build both the (endpoint, trigger) PoS pairs and
the BFs dictionary.
For the BFs dictionary con-
struction step we considered a threshold value of
10
,
chosen by
5
-fold cross validation on the Se-
mEval2014 training set.
This resulted in
44
,
536
different
BFs.
In conclusion,
once BFs are ex-
tracted from the SemEval2014 datasets,
a vector
of binary features which encodes all
the related
unigrams, bigrams and BFs is associated to every
tweet.
We use the Stanford Parser
7
(Klein and Man-
ning, 2003a; Klein and Manning, 2003b) to extract
the parse trees for each of the sentences contained
in the datasets.
Since a tweet
can be composed
by several sentences, we use Tsurgeon
8
(Levy and
Andrew, 2006) to build a single parse tree for each
dataset’s item (tweet, text messages, etc.).
The classification module based on Support
Vector Machines has been implemented using the
SVMLight-TK
9
(Moschitti,
2006) package.
This
module takes as input both the feature vectors and
the parse trees.
Moreover,
by applying SVMs
with a combination of two different kernel func-
tions, we can handle at the same time both struc-
tured and non-structured information.
Indeed,
as
in (Alicante et
al.,
2014;
Alicante and Corazza,
2011),
we applied tree kernels to the parse trees
and a linear
kernel
to the vector
of
binary fea-
5
The software can be freely downloaded from http:
//www.lsi.upc.edu/
˜
nlp/SVMTool/
6
The
Stanford
Twitter
Sentiment
(STS)
data
set
can
be
freely
downloaded
from
http://help.
sentiment140.com/for-students/
7
The
parser
can be
freely downloaded from http:
//nlp.stanford.edu/software/lex-parser.
shtml
8
Tsurgeon can be freely downloaded from http://
nlp.stanford.edu/software/tregex.shtml
9
The
software
package
can
be
freely
downloaded
from
http://disi.unitn.it/moschitti/
Tree-Kernel.htm
CLIC_2016_Proceedings.indd 37
02/12/16 15.03
38
tures
described above.
We build three binary
classifiers, one for each sentiment/class (positive,
negative,
neutral).
Moreover,
for each classifier,
the training phase has been performed by consid-
ering gold positive examples for the considered
class, while negative examples are represented by
all
the other
messages.
In this way,
the num-
ber of negative examples is much larger than the
positive ones.
SVMLight
allows to balance the
number of positive and negative examples by us-
ing a cost
factor
given by the rate between the
number
of
negative and positive training exam-
ples.
In order to assess our classification system
performance,
we consider
two baseline systems
(BLS),
namely the two systems that won the Se-
mEval2014 competition (Rosenthal et al.,
2014).
The former, BLS1 (Zhu et al., 2014), is based on
an SVM classifier and a feature set composed by
some lexical
and syntactical
features,
while the
latter,
BLS2 (Miura et
al.,
2014),
exploits a Lo-
gistic Regression trained with features based on
lexical knowledge.
4
Results
Performance is
assessed by adopting the same
evaluation metrics as in the SemEval2014 compe-
tition (Rosenthal et al., 2014).
As usual, they are
based on
F
1
-measure,
which is separately com-
puted for each class (positive,
negative and neu-
tral).
Table 4 compares the classification per-
formance of our tweet system,
namely BFS,
and
the baseline systems,
namely BLS1 (Zhu et
al.,
2014) and BLS2 (Miura et
al.,
2014) by adopt-
ing the same evaluation protocol used in the Se-
mEval2014 competition (Rosenthal et al.,
2014).
Our
system performs significantly better
on all
data sets except LiveJournal2014.
However, addi-
tional experiments, whose results are here omitted
due to space constraints, showed that our approach
performs better than BLS2 on this data set when
the BF dictionary is built on Wikipedia.
We think that the explanation for this behaviour
depends on the capability of the approach to adapt
to the employed data set.
In fact,
our strategy is
based on the use of unsupervised mining of text
to maximize the adaptation to the specificity of
the type of the language.
This also explains why
BFS performs worse than the others on LiveJour-
nal2014: the syntactical structure of the structured
sentences contained in a weblog is quite different
from the tweets’ one.
It is worth highlighting that
the difference in performance is not
statistically
significant though.
The main innovation of our
system is the introduction of BFs and the way in
which it learns them from data. We assess the BFs
contribution to the overall
classification perfor-
mance by comparing the performance between the
Barrier Features System (BFS) and Barrier Fea-
tures System (WOBFS) systems we described in
Section 3 and report results in Table 5.
Note that
this table is more detailed than Table 4 because
in this case we can run both systems and collect
all
the different
parameters.
Barrier features al-
most
always improve performance both in terms
of precision and recall,
and thus also in terms of
F
1
.
In a few cases,
the introduction of BFs im-
proves precision while decreasing recall: however,
in all these cases
F
1
improves in BFS with respect
to WOBFS.
In conclusion,
the introduction of BFs always
comes with an improvement
in terms of
F
1
and
such improvement
is nearly always statistically
significant.
We can therefore conclude that
BFs
provide a crucial contribution to sentiment polar-
ity classification.
5
Conclusions and future work
We explored the effectiveness of BFs for senti-
ment polarity classification in Twitter posts and we
showed on SemEval2014 data sets that
they can
be very effective.
In our approach,
the need of a
manual
intervention is really minimum.
Indeed,
the BFs dictionary can be built from any collec-
tion of tweets, even one that do not belong to the
same domain of the considered task.
This is quite
interesting because it suggests that BFs are able to
capture hints about the polarity of the expressions
in a domain independent way.
References
Anita Alicante and Anna Corazza.
2011.
Barrier
features for classification of semantic relations.
In
Galia Angelova, Kalina Bontcheva, Ruslan Mitkov,
and Nicolas Nicolov,
editors,
RANLP,
pages 509–
514. RANLP 2011 Organising Committee.
Anita Alicante,
Massimo Benerecetti,
Anna Corazza,
and Stefano Silvestri.
2014.
A distributed in-
formation extraction system integrating ontological
knowledge and probabilistic classifiers.
In Proceed-
ings of the 9th International 3PGCIC-2014 Confer-
ence, Guangzhou, CHINA. In Press.
Anita Alicante,
Anna Corazza,
Francesco Isgr
`
o,
and
Stefano Silvestri.
2016.
Unsupervised entity and
CLIC_2016_Proceedings.indd 38
02/12/16 15.03
39
relation extraction from clinical
records in Italian.
Computers in Biology and Medicine.
Luciano Barbosa and Junlan Feng.
2010.
Robust sen-
timent
detection on twitter from biased and noisy
data.
In Proceedings
of
the 23rd International
Conference on Computational Linguistics: Posters,
COLING ’10, pages 36–44, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Jes
´
us Gim
´
enez and Llu
´
ıs M
`
arquez.
2004.
SVMTool:
A general
POS tagger generator based on Support
Vector Machines.
In Proceedings of
4th Interna-
tional Conference on Language Resources and Eval-
uation (LREC), pages 43–46, Lisbon, Portugal.
Pollyanna
Gonc¸alves,
Daniel
Hasan Dalip,
Helen
Costa, Marcos Andr
´
e Gonc¸alves, and Fabr
´
ıcio Ben-
evenuto.
2016.
On the combination of off-the-shelf
sentiment analysis methods.
In Proceedings of the
31st Annual ACM Symposium on Applied Comput-
ing, pages 1158–1165. ACM.
Fred Karlsson,
Atro Voutilainen,
Juha Heikkila,
and
Arto Anttila,
editors.
1995.
Constraint Grammar:
A Language-Independent System for Parsing Unre-
stricted Text.
Mouton de Gruyter.
Dan Klein and Christopher D. Manning.
2003a.
Accu-
rate unlexicalized parsing.
In Proc. of ACL 03 of the
41st Annual Meeting on Association for Computa-
tional Linguistics, pages 423–430, Morristown, NJ,
USA. Association for Computational Linguistics.
Dan Klein and Christopher D. Manning.
2003b.
Fast
exact
inference with a factored model
for
natural
language parsing.
In Proc of NIPS03: In Advances
in Neural Information Processing Systems, pages 3–
10. MIT Press.
Olga Kolchyna,
Th
´
arsis TP Souza,
Philip Treleaven,
and Tomaso Aste.
2015.
Twitter sentiment analysis:
Lexicon method, machine learning method and their
combination.
arXiv preprint arXiv:1507.00955.
E. Kouloumpis, T. Wilson, and J. Moore.
2011.
Twit-
ter Sentiment Analysis:
The Good the Bad and the
OMG!
In Fifth International AAAI Conference on
Weblogs and Social Media.
Roger Levy and Galen Andrew.
2006.
Tregex and tsur-
geon:
tools for querying and manipulating tree data
structures.
In Proceedings of the fifth international
conference on Language Resources and Evaluation,
pages 2231–2234. Citeseer.
Yasuhide Miura, Shigeyuki Sakaki, Keigo Hattori, and
Tomoko Ohkuma.
2014.
Teamx:
A sentiment ana-
lyzer with enhanced lexicon mapping and weighting
scheme for unbalanced data.
In Proceedings of the
8th International Workshop on Semantic Evaluation
(SemEval
2014),
pages 628–632,
Dublin,
Ireland,
August.
Association for Computational Linguistics
and Dublin City University.
Alessandro Moschitti.
2006.
Making tree kernels prac-
tical for natural language learning.
In EACL.
Preslav Nakov,
Alan Ritter,
Sara Rosenthal,
Fabrizio
Sebastiani,
and Veselin Stoyanov.
2016.
Semeval-
2016 task 4:
Sentiment analysis in twitter.
In Pro-
ceedings of the 10th international workshop on se-
mantic evaluation (SemEval 2016),
San Diego,
US
(forthcoming).
Bo Pang and Lillian Lee.
2008.
Opinion mining and
sentiment
analysis.
Found.
Trends Inf.
Retr.,
2(1-
2):1–135, January.
Kumar Ravi and Vadlamani Ravi.
2015.
A survey on
opinion mining and sentiment analysis:
Tasks,
ap-
proaches and applications.
Knowledge-Based Sys-
tems, 89:14–46.
Sara
Rosenthal,
Alan
Ritter,
Preslav
Nakov,
and
Veselin Stoyanov.
2014.
Semeval-2014 task 9: Sen-
timent
analysis in twitter.
In Proceedings of
the
8th International Workshop on Semantic Evaluation
(SemEval 2014), pages 73–80, Dublin, Ireland, Au-
gust. Association for Computational Linguistics and
Dublin City University.
Sara Rosenthal,
Preslav Nakov,
Svetlana Kiritchenko,
Saif M Mohammad,
Alan Ritter,
and Veselin Stoy-
anov.
2015.
Semeval-2015 task 10: Sentiment anal-
ysis in twitter.
Proceedings of SemEval-2015.
Hassan Saif, Yulan He, Miriam Fernandez, and Harith
Alani.
2016.
Contextual
semantics for sentiment
analysis of twitter.
Information Processing & Man-
agement, 52(1):5–19.
Nadia Felix F Da Silva,
Luiz FS Coletta,
and Ed-
uardo R Hruschka.
2016.
A survey and compar-
ative study of
tweet
sentiment
analysis via semi-
supervised learning.
ACM Computing Surveys
(CSUR), 49(1):15.
Michael
Speriosu,
Nikita Sudan,
Sid Upadhyay,
and
Jason Baldridge.
2011.
Twitter polarity classifica-
tion with label propagation over lexical links and the
follower graph.
In Proceedings of the First Work-
shop on Unsupervised Learning in NLP,
EMNLP
’11,
pages 53–63,
Stroudsburg,
PA,
USA.
Associ-
ation for Computational Linguistics.
Xiaodan Zhu, Svetlana Kiritchenko, and Saif Moham-
mad.
2014.
Nrc-canada-2014:
Recent
improve-
ments in the sentiment analysis of tweets.
In Pro-
ceedings of the 8th International Workshop on Se-
mantic Evaluation (SemEval 2014), pages 443–447,
Dublin,
Ireland,
August.
Association for Computa-
tional Linguistics and Dublin City University.
CLIC_2016_Proceedings.indd 39
02/12/16 15.03
40
Annotating Content Zones in News Articles
Daniela Baiamonte
University of Pavia
daniela.baiamonte01@uni
versitadipavia.it
Tommaso Caselli
VU University Amsterdam
t.caselli@vu.nl
Irina Prodanof
University of Pavia
irina.prodanof@gmail.com
Abstract
English.
This paper presents a method-
ology for the annotation of the semantic
and functional
components of news arti-
cles (Content Zones, henceforth CZs). We
distinguish between narrative and descrip-
tive zones and, within them, among finer-
grained units contributing to the overall
communicative purpose of the text.
Fur-
thermore,
we show that the segmentation
in CZs could provide valuable cues for
the recognition of time relations between
events.
Italiano.
In questo lavoro viene presen-
tata una metodologia per l’annotazione
delle componenti
semantiche e funzion-
ali
del
testo giornalistico (Zone di
Con-
tenuto).
Distinguiamo tra zone narrative
e descrittive e,
al loro interno,
tra ulteri-
ori
unità che contribuiscono al
dispiega-
mento dello scopo comunicativo del testo.
Inoltre,
mostriamo che la segmentazione
in Zone di Contenuto offre preziosi indizi
per il riconoscimento delle relazioni tem-
porali tra eventi.
1
Introduction
The logical structure of a document,
i.e.
its hier-
archical arrangement in sections, paragraphs, sen-
tences and the like, reflects a functional organiza-
tion of the information flow and creates expecta-
tions on where the desired information may be lo-
cated. As it is often the case, however, breakups in
sections and paragraphs are motivated by style or
even arbitrary choices.
The segmentation of the text in Content Zones
(CZs,
henceforth),
i.e.
functional categories con-
tributing to the overall message or purpose, as in-
duced by the genre of the text
1
, provides more re-
liable and fine-grained cues to access the struc-
ture of its types of
functional
content.
Previous
attempts
to annotate CZs
have mainly focused
on highly standardized texts like scientific articles
(Teufel et al.,
2009; Liakata et al.,
2012; Liakata
and Teufel et al., 2010) and scheduling dialogues
(Taboada and Lavid, 2003), or on semi-structured
texts like film reviews (Bieler et al., 2007; Taboada
et al.,
2009).
Other work (Palmer and Friedrich,
2014; Mavridou et al., 2015) adopts the theory of
discourse modes (Smith, 2003) to distinguish be-
tween the different types of text passages in a text
document.
To the best
of our knowledge,
no efforts have
been undertaken to devise an annotation scheme
targeting the functional structure of news articles
in terms of
their
content:
the inverted pyramid
structure,
i.e.
the gathering of key details at
the
beginning, followed by supporting information in
order
of
diminishing importance,
is too coarse-
grained to be effectively used for information ex-
traction purposes. Our hypothesis is that modeling
the document’s content via CZs could yield ben-
efits for high-level
NLP tasks such as Temporal
Processing, Summarization, Question-Answering,
among others.
In addition to this,
CZs qualify as
a higher-level
analysis of a text/discourse which
captures different information with respect to Dis-
course Relations.
The remainder of the paper is
structured as follows: in Section 2 the motivations
of this work are presented,
together with related
studies. Section 3 reports on our inventory of CZs,
used to annotate a corpus of English news arti-
cles.
Details on the corpus are provided in Sec-
tion 4.
In Section 5,
we describe a case-study
on the correlation between CZs and temporal re-
1
We
adopt
Systemic
Functional
Linguistics’
view of
genre as
“a staged,
goal
oriented,
purposeful
activity in
which speakers engage as members of our culture" (Martin,
1984:25).
CLIC_2016_Proceedings.indd 40
02/12/16 15.03
41
lations to show that the segmentation in CZs can
provide cues in recognizing temporal relations be-
tween events.
Finally, Section 6 draws on conclu-
sion and suggests directions for future work.
2
Motivations and related work
The bulk of the work on discourse structures has
focused on low-level structures corresponding to
Discourse Relations holding between textual seg-
ments pairs.
CZs take a different
view on texts,
as they perform a function towards the text
as
a whole.
As an instance of
a particular
genre,
every text
is meant
to accomplish a culturally-
established communicative purpose,
e.g.
a news
article reports on events happening in the world.
This goal
is not
accomplished all
at once:
sepa-
rate functional stages (i.e.
CZs) convey fragments
of its overall meaning (Eggins and Martin, 1997).
Therefore,
the knowledge about the typical func-
tional structure of genres can be exploited to pre-
dict the internal organization of a text.
This kind
of information can be of help to produce balanced
summaries or to select the passages most likely to
contain the answer to a question.
Teufel et al.
(2009) and Liakata et al.
(2010)’s
works
present
two complementary perspectives
on scientific papers:
the former
models
their
argumentative/rhetorical
structure (following the
knowledge claims made by the authors);
the lat-
ter treats them as the humanly readable represen-
tations of scientific investigations. In the works of
Bieler et al. (2007) and Taboada et al. (2009), two
different kinds of zones are recognized in film re-
views:
formal zones (required by the genre,
e.g.
credits and cast) and functional zones (reflecting
the abstract functions of describing and comment-
ing).
In the elaboration of
news articles’
CZs,
we
were mostly inspired by Labov (2013)’s study of
oral narratives of personal experiences and by Bell
(1991)’s analysis of the structure of news stories.
3
Annotation Schema
The opposition between dynamicity and staticity,
mainly realized by grammatical and lexical aspect,
is adopted as the basic parameter for differenti-
ating between two macro CZs:
NARRATION
and
DESCRIPTION
.
The former is aimed at reporting
temporally interrelated (dynamic) events, the latter
is used to comment by focusing on selected enti-
ties, properties, and states of affairs. Each of these
two macro CZs is further divided into more fine-
grained categories.
The class
NARRATION
(
NARR
) includes the fol-
lowing zones:
•
Foreground (FGR):
text
span containing
the most salient events,
i.e.
those in the fo-
cus of
attention (as intended by Boguraev
and Kennedy, 1999). The information it con-
veys is both referentially and relationally new
(Gundel and Fretheim, 2005), as it is usually
mentioned at the beginning of the article.
•
Background (BGR):
ancillary,
referen-
tially and relationally old information per-
forming an explanatory function (through
causal and temporal precedence relations) to-
wards FGRs.
•
Follow-up (FUP):
reactions
and conse-
quences to FGR events (to whom they’re re-
lated through cause-effect and temporal suc-
cession relations), i.e.
relationally new infor-
mation moving the discourse forward.
•
Expectation (EXP):
assumptions
and
probable or possible outcomes, i.e.
non fac-
tual
information (e.g.
conditionals,
modal-
ity).
The class
DESCRIPTION
(
DSCR
)
includes the
following zones:
•
Description (DES):
characteristics
of
a person or
an object,
customary circum-
stances, or states of affairs.
•
Evaluation (EVL):
subjective
descrip-
tions, explicit judgements showing the author
or some other agent’s attitude towards a tar-
get.
In addition, a third macro-class is posited,
OTHER
(
OTHR
),
containing categories performing auxil-
iary functions towards the other CZs:
•
Attribution (ATT): text span containing
the source and, if present, the cue of an attri-
bution (as intended by Pareti
and Prodanof,
2010) - while the content is assigned the rel-
evant CZ(s).
•
Metatext (MTX):
text
span guiding the
reader’s
attention towards
metatextual
ele-
ments like figures or tables.
•
Interrogative (INT): questions directly
addressed to the reader,
e.g.
to introduce a
new topic or to prompt a reaction.
CLIC_2016_Proceedings.indd 41
02/12/16 15.03
42
Major approaches to functional discourse structur-
ing adopt the sentence or the paragraph as unit of
annotation.
On the other hand, we have opted for
a clause level annotation as this allows us to bet-
ter deal with news articles’ high level of informa-
tion density.
Although CZs are conceptually non-
overlapping,
empirical
analysis indicates that
an
annotation unit
may fit
into more than one cate-
gory, that is a clause may represent complex con-
tents.
Cases as such suggest that the more infor-
mative content should be preferred.
In the exam-
ple below, the tag ATT is assigned, even though a
descriptive content may as well be recognized.
1.
[On an office wall of the Senate intelligence
committee
hangs
a
quote
from Chairman
David Boren,]
AT T
{PDTB
2
, wsj_0771}
The annotation of CZs is further complicated
by the fact the distribution of the zones does not
follow the linear order of the text.
In most cases,
CZs are discontinuous, that is either their contigu-
ity may be “broken” by the presence of other CZs
or the same CZ may appear in different sentences
along the entire document (see example ?? for the
FGR zone).
2.
[South Korea registered a trade deficit
of
$101
million
in
October,]
FGR
[reflecting
the country’s
economic sluggishness,]
EV L
[according to government
figures
released
Wednesday.]
AT T
[Preliminary tallies by the
Trade
and Industry Ministry showed an-
other
trade
deficit
in
October,
the
fifth
monthly
setback
this
year,]
FGR
[casting
a cloud on South Korea’s
export-oriented
economy.]
EV L
{PDTB, wsj_0011}
In other cases,
due to the use of the clause as
minimal annotation span of a CZ, nested CZs may
occurr (see example ??).
3.
[South Korea’s economic boom,
[which be-
gan in 1986,]
BGR
stopped this
year
be-
cause
of
prolonged labor
disputes,
trade
conflicts and sluggish exports.]
BGR
{PDTB,
wsj_0011}
4
Description of the corpus
We used the CZs annotation schema and the an-
notation tool
CAT (Bartalesi
Lenzi
et
al.,
2012)
to construct
a small
corpus of
57 news articles
2
Penn Discourse TreeBank (Prasad et al., 2008).
Tense
FGR
BGR
FUP
EXP
DES
EVL
ATT
MTX
INT
PRESENT
46
46 26 21 35 58
34
0
0
PAST
66 204 29
3
2 10 172
0
0
FUTURE
21
1 25 22
0
2
0
0
0
INFINITIVE
32
51 26 18
2 12
1
0
0
PRESPART
6
19 10
5
2
3
9
0
0
PASTPART
2
11
1
1
0
2
1
0
0
NONE
6
8
6 21
0
2
2
0
0
Table 1: Distribution of tenses among CZs.
(20 from the test
section of TempEval-3 (UzZa-
man et
al.,
2013),
20 shared between the PDTB
(Prasad et al., 2008) and the training section of the
TimeBank (Pustejovsky et al., 2003), 17 from the
PDTB). The corpus contains 2059 annotation units
and it
is dominated by narrative sections (57%).
Within them,
the most
frequent
CZ is the BGR
(26.5%),
followed by FGR (12.4%),
EXP (9.6%)
and FUP (8.4%).
These figures show that
news
articles mostly consist
of redundant
information,
only mentioned in order to help the reader to an-
chor the new data to the prior knowledge.
De-
scriptive sections constitute the 25.5% of the cor-
pus:
EVLs are slightly more frequent than DESs
(14.8% vs.
8.9%)
— contradicting the alleged
objectivity expected in news reports (note,
how-
ever,
that EVLs tend to occur in association with
ATTs).
As to the
OTHER
macro CZ, it makes up
the 17.4% of the corpus:
this percentage almost
entirely refers to ATTs, since MTXs and INTs are
only marginal
zones (0.19% and 0.33%,
respec-
tively).
To test our hypotheses about some formal prop-
erties of CZs, we carried out a corpus study.
The
results are reported below.
Position in the text.
71.7% of FGRs are lo-
cated in the opening sections of the articles and
their
occurrence decreases
towards
the central
(18.4%) and closing sections (9.8%).
BGRs show
a fairly complementary distribution to FGRs,
as
they mostly occupy the central (31.6%) and clos-
ing sections (27.3%) of the articles.
As expected,
ATTs are quite evenly distributed among the three
sections.
The remaining CZs do not
show any
clear-cut tendencies.
Verbal tenses.
Table ?? shows the distribution
CLIC_2016_Proceedings.indd 42
02/12/16 15.03
43
source
target
FGR
BGR
FUP
EXP
DES
EVL
ATT
MTX
INT
FGR 46 13 1 -
2 12 8
1
1
-
-
-
2
2
9
-
-
-
-
-
1
2
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
1 1 3 38 7 -
-
-
1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
BGR 16
1
-
1 -
1
8 91 45 1 3 2 41 8
6
-
-
-
-
-
-
7
-
-
-
-
-
-
3 -
-
-
-
-
-
5
-
-
-
-
-
-
81 5 -
-
-
5
2
-
-
-
-
-
-
-
-
-
-
-
-
-
-
FUP
1
4
-
-
-
1
4
-
-
-
-
-
-
-
33 6 -
1 6 10 -
1
-
-
-
-
-
-
-
-
-
-
-
1 1
2
1 1 -
-
-
-
-
-
-
-
-
3
1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
EXP
-
1
-
-
-
-
1
-
-
-
-
-
-
1
-
-
-
-
-
-
-
24 10 -
1 1 7 -
-
-
-
-
-
-
-
2
2 -
-
-
-
-
2
1 -
-
-
1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
DES
2
1
-
-
-
-
1
-
1
-
-
-
-
2
2
1 -
-
-
1
-
5
-
-
-
-
-
1 4 -
2 -
-
2 -
1
1 -
-
-
1 -
5
3 -
-
-
1
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
EVL
1
1
-
-
-
1
3
2
2
-
-
-
1
1
2
2 -
-
-
1
-
4
-
-
-
-
-
-
-
-
-
-
-
1 -
15 -
-
-
-
5 -
7
3 2 -
-
5
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
ATT 16
1
-
-
-
1
1 18
2
-
-
-
4
-
18 1 -
-
-
1
-
21
1
-
-
-
-
-
3 -
-
-
-
-
-
2
-
-
-
-
1 -
14 5 -
-
-
44 21 -
-
-
-
-
-
-
-
-
-
-
-
-
-
MTX -
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
INT
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
BEFORE
,
INCLUDES
,
DURING
,
BEGINS
,
ENDS
,
SIMULTANEOUS
,
IDENTITY
Table 2: Distribution of time relations among CZs.
of
verbal
tenses,
as annotated in the TimeBank
corpus,
among CZs.
BGRs and ATTs are domi-
nated by the past tense, this is in accordance with
our
expectations as the former
is characterized
by temporal
precedence relations to FGR events
and the second mostly contains events of saying.
CZs belonging to the
DSCR
class are significantly
dominated by the present tense, usually associated
with imperfective aspect
and staticity.
The high
frequency of present
tenses in FGRs and BGRs
doesn’t
necessarily defy our
expectations,
since
FGRs contain both dynamic and static events and
the tag
PRESENT
is also used to refer to instances
of present perfect.
Modality markers.
The majority of modality
markers is located in EXPs and, more broadly, in
the narrative CZs,
as shown in Figure ??.
In the
TimeBank corpus,
the
MODALITY
tag is mostly
assigned to modal auxiliaries, we believe that the
annotation of modal
adverbs would further raise
the percentages observed in EXPs and in the
NARR
class.
Pronouns.
Looking at
Figure ?? we can see
that
almost
50% of
all
pronouns
is
located in
BGRs.
The percentages are consistent
with our
expectations as BGRs convey referentially old in-
formation and, although FUPs and EXPs elaborate
on FGR events, they often introduce new referents.
Note that the distribution of pronouns is not, alone,
a sufficient
indicator of referential
oldness since
also lexical
and zero anaphoras should be taken
into account.
5
Interactions between CZs and time
relations
In news articles events are not iconically presented
in the linear order of their real
succession,
this
poses a challenge to systems aimed at
uncover-
Modality markers,
Pronouns
0
10
20
30
40
50
FGR
BGR
FUP
EXP
DES
EVL
ATT
MTX
INT
9.05
47.32
4.8
7.95
6.44
15.22
9.05
0
0.13
12.12
19.69
13.63
43.93
3.03
3.03
4.54
0
0
Percentage (%)
Figure 1:
Distribution of modality markers and
pronouns among CZs.
ing their temporal event structure.
Therefore,
we
used the annotations available for the TimeBank
section of the corpus to check whether some con-
nections between CZs and temporal relations be-
tween event pairs exist.
The full set of temporal
relations specified in TimeML contains 14 types
of relations:
BEFORE
,
AFTER
,
IBEFORE
,
IAFTER
,
BEGINS
,
BEGUN
_
BY
,
ENDS
,
ENDED
_
BY
,
DUR
-
ING
,
DURING
_
INV
,
INCLUDES
,
IS
_
INCLUDED
,
SIMULTANEOUS
and
IDENTITY
.
We simplified
the set
as follows:
the relation types that
invert
each other were collapsed into a single type; given
the low frequency of the relation type
IBEFORE
,
it was mapped to the corresponding more coarse-
grained type
BEFORE
.
Given the narrative shape of news articles,
the
corpus is considerably dominated by precedence
CLIC_2016_Proceedings.indd 43
02/12/16 15.03
44
source - target
BFR
INCL
DUR
BEG
ENDS
SMLT
IDNT
NARR
-
NARR
218
77
1
6
11
71
26
NARR
-
DSCR
17
1
1
0
1
2
7
NARR
-
OTHR
119
9
0
0
0
10
3
DSCR
-
DSCR
30
5
3
0
0
12
6
DSCR
-
NARR
20
8
0
0
0
4
6
DSCR
-
OTHR
16
10
2
0
0
6
0
OTHR
-
OTHR
14
5
0
0
0
44
21
OTHR
-
NARR
72
5
0
0
0
6
0
OTHR
-
DSCR
6
0
0
0
0
1
1
Table 3:
Distribution of time relations among the
macro-classes.
(
BEFORE
) and succession (
AFTER
) relations.
Ta-
ble ?? shows that
the majority of temporal
rela-
tions holds between events belonging to the same
CZ types:
events tend to precede,
include,
oc-
cur
during,
begin,
end,
be simultaneous to and
anaphorically evoke (through TimeML
IDENTITY
temporal relations) other events belonging to the
same zone.
FGR events precede rather
than follow ATT,
FUP and EXP events.
BGR events,
the most in-
volved in
BEFORE
relations, tend to precede other
events,
especially if located in ATTs and FGRs.
Unexpected outcomes mostly occur in cases like
the following,
where the FGR event precedes the
BGR one.
This is because conflicting contents
may be expressed in the same unit
(in this case
a reaction to the FGR event
and the list
of
its
premises):
4.
[Delta Air
Lines
earnings
soared
to 33%
to a record in the fiscal
first
quarter,]
FGR
[bucking the industry trend toward declining
profits.]
F UP
[The Atlanta-based airline,
the
third largest
in the U.S.,
attributed the in-
crease to higher passenger traffic, new inter-
national routes and reduced service by Rival
Eastern Airlines...]
BGR
{PDTB, wsj_1011}
As highlighted in Table ??,
NARR
events begin or
end other
NARR
or
DSCR
events (more specifically,
these relations hold between events belonging to
instances of the same CZ) and
DSCR
events in-
clude (rather than being included in) other events.
IDENTITY
relations mostly involve FGRs:
as
a result of their textual salience,
FGR events can
be mentioned in other FGRs or further clarified in
narrative or descriptive sections.
6
Conclusions and future work
We have developed an inventory of zone labels
for
the genre news
article and shown that
the
so-generated content structure could help narrow-
ing down the range of time relations connecting
events.
Future work would involve testing the stabil-
ity and reproducibility of the annotation scheme
through the measurement of inter-annotator agree-
ment
and
elaborating
a
separate
annotation
scheme for editorials,
whose argumentative style
reflects different structuring principles than those
acting in news reports.
Finally,
we would like
to automatize the process of annotation and test
the effectiveness of the approach in texts belong-
ing to different genres,
e.g.
novels (Ouyang and
McKeown, 2014) and historical essays.
Even the
basic distinction between narrative and descrip-
tive zones could facilitate the performance of more
complex NLP tasks by targeting the relevant
in-
formational zones.
The corpus and the annotation
guidelines are publicly available
3
.
Acknowledgment
This has been partially supported by the Erasmus
+ Traineeship Program 2015/2016 from Univer-
sity of Pavia and the NWO Spinoza Prize project
Understanding Language by Machines (sub-track
3).
References
Baiamonte,
D.
2016.
Annotazione di
Zone di
Con-
tenuto: una strutturazione funzionale del testo gior-
nalistico.
Thesis of the Master in Theoretical
and
Applied Linguistics.
University of Pavia, Pavia.
Bärenfänger,
M.,
Hilbert,
M.,
Lobin,
H.,
Lüngen,
H.,
Puskás,
C.
2006.
Cues and constraints for the re-
lational
discourse analysis of complex text
types -
the role of logical and generic document structure.
Sidner C.L.,
Harpur J. Benz A.,
Kühnlein P. (eds.),
Proceedings of the Workshop on Constraints in Dis-
course.
Maynooth, Ireland. 27-34.
Bartalesi Lenzi,
V.,
Moretti,
G.,
Sprugnoli,
R.
2012.
CAT: the CELCT Annotation Tool.
Proceedings of
LREC 2012.
Istanbul.
3
https://github.com/cltl/ContentZones.
git
CLIC_2016_Proceedings.indd 44
02/12/16 15.03
45
Bell, A.
1991.
The Language of News Media.
Black-
well Publishers, Oxford.
Bieler, H., Dipper, S., Stede, M.
2007.
Identifying For-
mal and Functional Zones in Film Reviews.
Keizer
S.,
Bunt
H.,
Paek T.
(eds.),
Proceedings of
the
8th SIGdial Workshop on Discourse and Dialogue.
Antwerp, Belgium. 75-78.
Boguraev,
B.
and Kennedy,
C.
1999.
Salience-based
content
characterisation of text
documents.
Inder-
jeet M. and Maybury M. T. (eds.),
Advances in Auto-
matic Text Summarization.
MIT Press, Cambridge,
MA.
Eggins, S. and Martin, J. R.
1997.
Genres and registers
of discourse.
van Dijk T. (ed.),
Discourse Studies.
Discourse as structure and process, volume 1.
Sage,
London (UK) and Thousand Oaks (CA). 230-257.
Gundel,
J.
K.
and Fretheim,
T.
2005.
Topic and Fo-
cus.
Horn L. and Ward G. (eds.),
The Handbook of
Pragmatics.
Blackwell Publishing, 175-196.
Labov,
W.
2013.
The Language of
Life and Death.
Cambridge University Press, Cambridge, UK.
Liakata,
M.,
Saha,
S.,
Dobnik,
S.,
Batchelor,
C.,
Rebholz-Schuhmann,
D.
2012.
Automatic recog-
nition of conceptualization zones in scientific arti-
cles and two life science applications.
Bioinformat-
ics 2012, volume 28.
991-1000.
Liakata, M., Teufel, S., Siddharthan, A., Batchelor, C.
2010.
Corpora for conceptualisation and zoning of
scientific papers.
Proceedings of the 7th conference
on Internation Language Resource and Evaluation
(LREC10).
Martin,
J.
R.
1984.
Language,
register and genre.
Christie F. (ed.),
Language studies:
Children writ-
ing.
Reader.
Deakin University Press,
Geelong,
Australia. 21-30.
Mavridou,
K.,
Friedrich,
A.,
Peate
Sørensen,
M.,
Palmer,
A.,
and Pinkal,
M.
2015.
Linking dis-
course modes and situation entity types in a cross-
linguistic corpus study. September 2015. In Proceed-
ings of Linking Models of Lexical.
Sentential and
Discourse-level Semantics (LSDSem). ,
Lisbon, Por-
tugal.
Ouyang,
J.
and McKeown,
K.
2014.
Towards auto-
matic detection of narrative structure.
Proceedings
of LREC14,
Reykjavik, Iceland.
Palmer, A. and Friedrich, A.
2014.
Genre distinctions
and discourse modes:
Text types differ in their sit-
uation type distributions.
Proceedings of the Work-
shop on Frontiers and Connections between Argu-
mentation Theory and Natural
Language Process-
ing. Forlí-Cesena, Italy.
Pareti, S. and Prodanof, I.
2010.
Annotating Attribu-
tion Relations:
Towards an Italian Discourse Tree-
bank.
Proceedings of LREC10.
Prasad,
R.,
Dinesh,
N.,
Lee,
A.,
Miltsakaki,
E.,
Robaldo, L., Joshi, A., Webber, B.
2008.
The Penn
Discourse TreeBank 2.0.
Proceedings of the 6th In-
ternational Conference on Language Resources and
Evaluation (LREC).
Marrakech, Morocco.
Pustejovsky, J., Hanks, P., Sauri, R., See, A., Day, D.,
Ferro,
L.,
Gaizauskas,
R.,
Lazo,
M.,
Setzerr,
A.,
Sundheim, B.
2003.
The TimeBank Corpus.
Cor-
pus Linguistics.
647-56.
Smith, S. Carlota 2003.
Modes of discourse: The local
structure of texts.
Cambridge University Press.
Stede,
M.
2011.
Discourse Processing.
Morgan &
Claypool Publishers. 7-38.
Taboada, M., Brooke, J., Stede, M.
2009.
Genre based
paragraph classification for sentiment analysis.
Pro-
ceedings of SIGDIAL 2009: the 10th Annual Meet-
ing of the Special Interest Group in Discourse and
Dialogue.
Queen Mary University of London.
62-
70.
Taboada, M. and Lavid, J.
2003.
Rhetorical and The-
matic Patterns in Scheduling Dialogues:
A Generic
Characterization.
Functions of
Language,
10(2).
147-179.
Teufel,
S.,
Siddharthan,
A.,
Batchelor,
C.
2009.
To-
wards discipline-independent argumentative zoning:
Evidence from chemistry and computational linguis-
tics.
Proceedings of
the 2009 Conference on Em-
pirical
Methods in Natural
Language Processing,
EMNLP 2009.
Singapore.
UzZaman,
N.,
Llorens,
H.,
Derczynski,
L.,
Allen,
J.
Verhagen, M., Pustejovsky, J.
2013.
SemEval-2013
Task 1: TempEval-3: Evaluating Time Expressions,
Events, and Temporal Relations.
Second Joint Con-
ference on Lexical
and Computational
Semantics
(*SEM),
Volume 2:
Proceedings of the Seventh In-
ternational Workshop on Semantic Evaluation (Se-
mEval 2013)
CLIC_2016_Proceedings.indd 45
02/12/16 15.03
46
Appetitoso: A Search Engine for Restaurant Retrieval based on Dishes
Gianni Barlacchi
1,2
, Azad Abad
1
, Emanuele Rossinelli
3
, Alessandro Moschitti
1,4
1
Department of Information Engineering and Computer Science, University of Trento
2
TIM Semantics and Knowledge Innovation Lab, Trento
3
Kloevolution S.r.l.
4
Qatar Computing Research Institute, HBKU
{
gianni.barlacchi,e.rossinelli,amoschitti
}
@gmail.com
azad.abad@unitn.it
Abstract
English.
Recent
years have seen an im-
pressive development and diffusion of web
applications to food domains,
e.g.,
Yelp,
TripAdvisors.
These mainly exploit
text
for
searching and retrieving food facili-
ties, e.g., restaurants, caff
´
e, pizzerias. The
main features of such applications are: the
location and quality of the facilities, where
quality is extrapolated by the users’
re-
views.
More recent
options also enable
search based on restaurant categorization,
e.g.,
Japanese,
Italian,
Mexican.
In this
work,
we introduce Appetitoso
1
,
an in-
novative approach for finding restaurants
based on the dishes a user would like to
taste rather than using the name of food
facilities or their general categories.
Italiano.
Recentemente si
`
e assistito ad
un impressionante sviluppo e diffusione di
applicazioni web per il dominio del cibo,
e.g., Yelp, TripAdvisors.
Queste sfruttano
principalmente il testo per la ricerca e il
recupero di punti di ristoro, e.g., ristoranti,
bar, pizzerie.
Le caratteristiche principali
usate dalle applicazioni sono: la posizione
e la qualit
´
a delle strutture che servono il
cibo,
dove la qualit
´
a
´
e estrapolata dalle
recensioni
degli
utenti.
Opzioni
pi
´
u re-
centi consentono anche la ricerca in base
alla categoria del
ristorante,
e.g.,
Giap-
ponese, Italiano, Messicano.
Questo arti-
colo introduce Appetitoso, un nuovo modo
di
trovare punti
di
ristoro sulla base dei
piatti
che il
cliente vuole gustare invece
che sul nome del ristorante o su categories
generali.
1
http://www.appetitoso.it
1
Introduction
In late 2000’s,
we assisted to the explosion of
TripAdvisor
2
, the world’s largest travel site, which
offers advice about hotel and restaurants.
In few
years,
it
has revolutionized the restaurant
indus-
try, allowing its users to search restaurants by lo-
cation, broad food categories (e.g., Mexican, Ital-
ian, French), reviews and ratings provided by other
users.
However, the user expectation has evolved over-
time:
looking for restaurants is not
enough any-
more,
people are now considering finer-grained
properties of food,
e.g.,
a particular way to cook
a dish along with its specific ingredients.
Thus,
there is a clear gap between what the market pro-
poses and the emerging trends.
In this work,
we present
Appetitoso,
a search
engine that seeks for restaurants based on dishes.
This approach is designed to help users to find
their
restaurants
having already a specific dish
preference in mind,
using fine-grained properties
of the dish.
Appetitoso integrates state-of-the-art search en-
gines,
such as
BM25,
with a domain specific
knowledge base describing properties and similar-
ity relations between different Italian dishes.
This
knowledge is very useful, e.g., in our experiments,
we show that it greatly boosts dish retrieval.
Appetitoso is available as a mobile phone ap-
plication (e.g., Android and iOS) and website, re-
leased in 2014 for two languages, English and Ital-
ian.
It
is an end-to-end application for
finding
restaurants offering the desired dish.
We evalu-
ated it using a set of 547 popular queries typed by
its users in the cities of Rome, Milan and Florence.
In the reminder of this paper,
in Section 2,
we
report related work on systems for automatic food
recommendation,
In Section 3,
we introduce Ap-
petitoso,
its knowledge base and the food search
2
http://www.tripadvisor.com
CLIC_2016_Proceedings.indd 46
02/12/16 15.03
47
engine. Section 4, we describe our experiments on
restaurant retrieval on Italian language and finally,
in Section 5, we provide our conclusion.
2
Related Work
Nowdays,
the importance of
data analysis is
becoming fundamental
in many fields.
From
telecommunications
to social
media,
the
huge
amount of available data allows scientists and re-
searchers to address previously unsolved problems
(Barlacchi et al.,
2015).
The food domain repre-
sents one of the field in which emerging big data
techniques demonstrated to be very promising and
able to impact the every daily life of people.
In
recipe recommendation,
for instance,
Teng et al.
(2012) proposed an approach based on networks
of ingredients, which has been built from a dataset
of recipes.
In order to capture both ingredient re-
lations and users’ knowledge for combining ingre-
dients in new recipes,
they created two separate
networks used for recipe recommendation.
Moreover, Ahn et al. (2011) explored the impact
of flavor compounds on ingredient
combinations
through a network-based approach.
An interest-
ing application was developed by IBM with Chef
Watson
3
, which is part of the cognitive computing
applications developed by the company.
The sys-
tem models the chemical compounds of different
ingredients together with textual
information ex-
tracted from thousands recipes for suggesting new
ones using innovative ingredient combinations.
Among the different kinds of data,
text surely
represents one of the richest sources of informa-
tion from which we can extract
a wide range of
statements about food. The use of text in food do-
main has been widely explored showing promis-
ing results with different
models,
ranging from
the measurement
of
sentiment
in food reviews
(Kang et al.,
2012) and relation extraction (Wie-
gand and Klakow,
2013;
Wiegand et
al.,
2012),
to the prediction of
attribute reviews in recipes
(Druck, 2013).
3
Appetitoso
We introduce the idea of searching a dish and
then finding the best restaurants that can offer it.
Thus, the aim of our search engine, Appetitoso, is
to find the best restaurants offering dishes relevant
to the user’s request.
Starting from a query with
food-related content, e.g., bistecca alla fiorentina
3
https://www.ibmchefwatson.com
Query
Location
Dishes 
Databases
Web
Food 
Guides
Index Dishes
Ingredients
Dish Name
Similars
NLP pipeline to gather and 
analyze data
Search Dishes
Present Search
Results
Tags
Figure 1: Architecture of Appetitoso.
(t-bone steak), the system retrieves places that sat-
isfy the constraint on the location and, at the same
time, prepare the desired dish or similar dishes.
Appetitoso
retrieves
restaurants
from
a
semistructured database,
Food Taste Knowledge
Base
(FKB),
which contains
text
descriptions
of
dishes and restaurants:
we in part
manually
inserted them or
gathered them from various
sources
such as
foodblogs,
restaurants
reviews
and food guides.
The search processes is divided
in two phases: first, the user has to type the query
and a location, e.g., the address of a target place or
the current user position captured by GPS. These
are both sent
to the Appetitoso’s search engine,
which retrieves a list of related dishes from FKB.
The results are grouped by dish name and shown
to the user in different course categories, i.e., an-
tipasto/entree, primo/first course, secondo/second
course,
dessert.
The input
location is used to
restrict the search area of interest,
relying on the
restaurant position available in FKB.
The second phase of the searching process is de-
voted to select the best restaurant.
Once the user
chooses a dish from the list above, Appetitoso pro-
vides a list of restaurants that offer such food spe-
ciality.
Indeed,
all
the restaurants offering that
dish are stored in FBK.
Additionally,
Appetitoso
provides a DishScore
4
for each restaurant,
which
is a measure of the goodness of the dish in that
restaurant. Fig. 1 shows the high-level architecture
4
We only inserted restaurant that have a good reputation
in FBK. In order to generate the DishScore, we trained a lo-
gistic regression over 5 different review scores, e.g., 1 star, 2
star etc.
We used various features, e.g., Tripadvisor and food
guide scores. This description is however beyond the purpose
of the current paper.
CLIC_2016_Proceedings.indd 47
02/12/16 15.03
48
of the system. In the next section, we illustrate our
FKB,
which enables accurate retrieval of similar
dishes.
3.1
The Food Taste Knowledge Base (FKB)
A quick analysis of Italian menus clearly show
that,
in many cases,
the name of
a dish is not
enough to understand its content,
which means
that
names do not
support
an accurate similarity
measures between dishes.
Thus, we created FKB,
which also organizes dishes in a hierarchical struc-
ture,
where each node is connected to others in
case there is a similarity between them.
For instance,
Bucatini alla amatriciana (buca-
tini with amatriciana sauce) can be extended from
Spaghetti alla amatriciana (spaghetti with amatri-
ciana sauce) since the only difference between the
two dishes is the type of pasta (spaghetti vs.
bu-
catini).
In this case, we marked the first dish as a
template for the second one.
The relation is one-
to-many: one dish can be a template for many oth-
ers but
it
can be only assigned to one template.
Since every restaurant can have its own way to pre-
pare the dish, multiple instances of the same dish
can be present in the FKB. We differentiate them
by adding the restaurant ID.
Since there is no defined way to assess the sim-
ilarity between two dishes:
they may be similar
as they are made by similar ingredients or because
they are cooked in the same way, we built the FKB
hierarchy with a semi-automatic approach.
We
used name similarity to select similar candidates,
which are then manually annotated by food ex-
perts.
We manually populated FKB with data col-
lected from the web,
food guides and foodblogs.
Every dish belonging to a restaurant is represented
by means of the following information:
-
ID: unique identifier for the dish.
-
Name of the dish:
the name of the dish as re-
ported in the restaurant menu.
-
Ingredients:
list
of
the
principal
ingredients.
When the ingredients are not
provided by the
restaurant,
we use a list
of common ingredients
for the dish (e.g., ingredients from online recipes).
-
Tags:
list of tags useful to characterize the dish.
The tag list does not include ingredients but only
categorical information that can help to character-
ize the dish (e.g., meat or fish).
-
Similar dishes:
list of similar dishes defined ac-
cording to our hierarchy described above.
-
Template: ID of the template dish, if it is present.
Spaghetti allo 
scoglio
Spaghetti alla 
trabaccolara
Linguine 
all’astice
Carbonara di 
mare
Paccheri con 
pesce spada
Figure 2: Connection between similar fish dishes.
-
Restaurant:
information about the restaurant that
cook this dish (e.g.
restaurant name and restau-
rant ID).
-
DishScore: a value that indicates the goodness of
the dish. It is calculated taking into account many
factors such as the reputation of the restaurant in
cooking that dish, the number of mentions in food
guide and the sentiment extracted from foodblog-
ger articles and restaurant reviews.
This hierarchical organization is very powerful
and allows us to easily keep track of similarities
that are not explicit.
Fig. 2 shows an example of
connections between similar dishes.
It
is worth
to mention that
Appetitoso aims to suggest
only
restaurants that
own a good reputation in cook-
ing target dishes, i.e., restaurants in Rome that are
famous for pasta alla carbonara.
Consequently,
this limits the number of dishes contained in the
FKB and thus on the territory coverage.
On the
other hand, it makes it possible to create a manu-
ally checked resource.
3.2
Dish Retrieval
Italy has
long and variegated traditions
on
preparing food: it is possible to find different kinds
of cuisine even in nearby cities.
This makes the
Italian food incredibly varied and fascinating, but,
at the same time,
difficult to interpret from a lin-
guistic viewpoint.
The same dish can be called
in many different
ways.
In Florence people call
Carabaccia the common dish Zuppa di
cipolle
with the consequence that the underlying retrieval
problem cannot be addressed by just using a sim-
ple word matching approach.
Indeed,
even if a
dish is conceptually the same of another, different
restaurants (e.g., in different locations) have their
own way to call it.
CLIC_2016_Proceedings.indd 48
02/12/16 15.03
49
To tackle the problem above, we verified the hy-
pothesis that a search engine can achieve a better
result if we consider further information such as
ingredients and tags.
This approach significantly
improves the accuracy of the retrieved list
com-
paring to the simple word matching approach.
More specifically, we applied BM25 (Robertson
et al., 1995) to FKB. Given a dish query,
Q
and a
representation of a candidate dish,
D
, BM25 ranks
the latter according to the following score:
s
(
Q, D
) =
n

i=0
IDF
(
q
i
)
·
((
k
+ 1)
·
T F
(
q
i
, D
))

k
·
(1
−
b
+
b
·
|D|
avgD
) +
T F
(
q
i
, D
)

,
where
k
and
b
are two free parameters that modify
respectively the impact of term frequency (TF) and
the document length through the term
|D|
avgD
,
|
D
|
is
the document length and
avgD
, i.e., the average of
D over the whole dataset.
Finally,
IDF
(
q
i
)
is the
Inverse Document
Frequency for the query term
q
i
, computed as:
log

1 +
(
N
−
DF
(
q
i
) + 0
.
5)
(
DF
(
q
i
) + 0
.
5)

,
where
N
is the total number of documents in the
collection, and
DF
(
q
i
)
is the document frequency
of the term
q
i
.
Additionally, we created four different indexes
5
with the information contained in FKB,
i.e.,
the
(i) dish name,
(ii) ingredients,
(iii) tags and (iv)
similar dishes.
Each list is built using the words
describing the four items above.
Thus,
when we
query a dish, we first retrive four different sets of
results and then,
since they have different impor-
tance, we combine them together assigning differ-
ent weights,
where the latter are set using cross-
fold validation.
4
Experiments
Our experiments aim at
demonstrating the ef-
fectiveness of our models on the task of dish re-
trieval.
We used the well
known metrics:
Pre-
cision at
rank 1 (P@1),
Mean Reciprocal
Rank
(MRR) and Mean Average Precision (MAP). P@1
indicates the percentage of
queries with a cor-
rect
answer (e.g.,
the desired dish) found in the
first position.
The MRR is computed as follows:
MRR
=
1
|Q|

|Q|
q=1
1
rank(q)
,
where rank(q) is the
position of the first correct answer in the retrieved
list.
For a group of queries
Q
,
MAP is the mean
5
We use Lucene (McCandless et al., 2010)
Model
City
MRR
MAP
P@1
Baselines
String Matching
(on entire names)
Milan
53.28
53.28
53,28
Rome
71.23
71.23
71.23
Florence
44.87
44.87
44.87
All
56.46
56.46
56.46
BM25
(on names only)
Milan
69.75
65.44
68.18
Rome
63.86
60.32
58.90
Florence
42.31
40.94
37.18
All
58.64
55.56
54.75
Our Model
Appetitoso
(names, ingredients
tags, similar names)
Milan
95.35
85.69
93.43
Rome
87.40
76.23
84.93
Florence
83.55
75.38
78.21
All
88.76
79.10
85.52
Table 1: Ranking evaluation for different models
over the average precision scores for each query:
1
Q

Q
q=1
AveP
(
q
)
.
Due to the fact that FKB contains multiple in-
stances of the same dish,
we evaluated the col-
lapsed list of results by considering the dish name.
It is worth to mention that the names of the dishes
are not
standard,
thus some dishes are the same
still
having slightly different
names.
To make
them more similar, we normalized name forms by
removing space, articles and punctuation. We con-
sidered a set of 547 popular queries typed by users
in Milan (396 queries),
Rome (73 queries)
and
Florence (78 queries).
The number of retrieved
dishes varies for the different
queries with aver-
ages of 22.8,
22.3 and 37.4,
for Florence,
Milan
and Rome,
respectively.
For each retrieved dish,
we manually annotated the relevance respect to the
input query.
It should be noted that the same dish
is associated (in FKB) with all of the restaurants
that are offering it.
Thus,
restaurant retrieval is a
side effect of dish retrieval.
We considered two baselines for evaluating our
model, namely, String Matching and BM25.
The
first is based on simple string matching between
the query and the dish names.
The second is
BM25,
which can be applied to dish names only.
We refer to our system (BM25 applied to the 4
indexes as described in Sec.
3.2) with the name
Appetitoso.
Table 1 shows the results of the baselines and
our model by cities and overall (All).
Appetitoso
largely outperforms String Matching and BM25
applied to names only, e.g., up to 32 and 24 abso-
lute percent points in MRR and MAP, respectively.
5
Conclusion
In this paper
we presented Appetitoso,
a se-
mantic search engine for food.
The aims of the
CLIC_2016_Proceedings.indd 49
02/12/16 15.03
50
search engine is to provide the users with a way
of searching restaurants by dishes rather than just
using the restaurants’ address or cuisine type.
We
show that,
given the complexity of dish naming,
a semistructured database for dishes can largely
improve BM25.
Overall,
Appetitoso shows good
performance,
e.g.,
achieving 88.76% in MAP.
In
the future,
we would like to include more com-
plex unstructured data such as the description of
the dishes and also explore the possibility of word
embeddings for the food domain.
Moreover, it is
also important
increase the coverage of the sys-
tem by adding more dishes to the FKB.
Even if
the manual annotation is important,
and in some
cases fundamental,
it
represents a bottleneck for
the expansion process.
For this reason, in the fu-
ture it would be necessary consider approaches to
automatically extract dish entities from text (e.g.
NER for food).
Acknowledgments
We would like to thank the Appetitoso team for
making available the system and for providing us
with the data for this work.
This work has been
partially supported by the EC project
CogNet,
671625 (H2020-ICT-2014-2,
Research and Inno-
vation action) and by an IBM Faculty Award. The
first
author was supported by a fellowship from
TIM. Many thanks to the anonymous reviewers for
their valuable suggestions.
References
Yong-Yeol Ahn, Sebastian E Ahnert, James P Bagrow,
and Albert-L
´
aszl
´
o Barab
´
asi.
2011.
Flavor network
and the principles of food pairing.
Scientific reports,
1.
Gianni Barlacchi,
Marco De Nadai,
Roberto Larcher,
Antonio Casella, Cristiana Chitic, Giovanni Torrisi,
Fabrizio Antonelli,
Alessandro Vespignani,
Alex
Pentland,
and Bruno Lepri.
2015.
A multi-source
dataset
of urban life in the city of milan and the
province of trentino.
Scientific data, 2.
Gregory Druck.
2013.
Recipe attribute prediction us-
ing review text
as supervision.
In Cooking with
Computers 2013, IJCAI workshop.
Hanhoon Kang,
Seong Joon Yoo,
and Dongil
Han.
2012.
Senti-lexicon and improved na
¨
ıve bayes algo-
rithms for sentiment analysis of restaurant reviews.
Expert
Systems
with
Applications,
39(5):6000–
6010.
Michael McCandless, Erik Hatcher, and Otis Gospod-
netic.
2010.
Lucene in Action,
Second Edition:
Covers Apache Lucene 3.0.
Manning Publications
Co., Greenwich, CT, USA.
Stephen E Robertson,
Steve Walker,
Susan Jones,
Micheline
M Hancock-Beaulieu,
Mike
Gatford,
et al.
1995.
Okapi at trec-3.
NIST SPECIAL PUB-
LICATION SP, 109:109.
Chun-Yuen Teng,
Yu-Ru Lin,
and Lada A Adamic.
2012.
Recipe recommendation using ingredient net-
works.
In Proceedings of the 4th Annual ACM Web
Science Conference, pages 298–307. ACM.
Michael
Wiegand and Dietrich Klakow.
2013.
To-
wards the detection of reliable food-health relation-
ships.
NAACL 2013, page 69.
Michael
Wiegand,
Benjamin
Roth,
and
Dietrich
Klakow.
2012.
Data-driven knowledge extraction
for the food domain.
In KONVENS, pages 21–29.
CLIC_2016_Proceedings.indd 50
02/12/16 15.03
51
Argument Mining on Italian News Blogs
Pierpaolo Basile
University of Bari
pierpaolo.basile@uniba.it
Valerio Basile
Universit
´
e C
ˆ
ote d’Azur, Inria,
CNRS, I3S, France
valerio.basile@inria.fr
Elena Cabrio, Serena Villata
Universit
´
e C
ˆ
ote d’Azur, CNRS,
Inria, I3S, France
firstname.lastname@unice.fr
Abstract
English.
The goal of argument mining is
to extract
structured information,
namely
the arguments and their relations, from un-
structured text.
In this paper,
we propose
an approach to argument
relation predic-
tion based on supervised learning of lin-
guistic and semantic features of the text.
We test
our
method on the CorEA cor-
pus of user comments to online newspaper
articles,
evaluating our
system’s
perfor-
mances in assigning the correct
relation,
i.e.,
support
or
attack,
to pairs of
argu-
ments.
We obtain results consistently bet-
ter than a sentiment
analysis-based base-
line (over two out three correctly classified
pairs), and we observe that sentiment and
lexical semantics are the most informative
features with respect to the relation predic-
tion task.
Italiano.
L’estrazione automatica di
ar-
gomenti
ha come scopo recuperare in-
formazione strutturata,
in particolare gli
argomenti
e
le
loro
relazioni,
a
par-
tire da testo semplice.
In questo con-
tributo proponiamo un metodo di
predi-
zione delle relazioni tra argomenti basato
sull’apprendimento supervisionato di fea-
ture linguistiche e semantiche del testo.
Il
metodo
`
e testato sul
corpus di
commenti
di news CorEA, ed
`
e valutata la capacit
`
a
del
sistema di
classificare le relazioni
di
supporto ed attacco tra coppie di
argo-
menti. I risultati ottenuti sono superiori ad
una baseline basata sulla sola analisi del
sentimento (oltre due coppie di argomenti
su tre
`
e classificata correttamente) ed os-
serviamo che il sentimento e la semantica
lessicale sono gli indicatori pi
`
u informa-
tivi per la predizione delle relazioni tra ar-
gomenti.
1
Introduction
The argument mining (Peldszus and Stede, 2013;
Lippi
and Torroni,
2016)
research area has re-
cently become very relevant in computational lin-
guistics.
Its main goal
is the automated extrac-
tion of natural
language arguments and their re-
lations
from generic textual
corpora,
with the
final
goal
of
providing machine-readable struc-
tured data for computational models of argument
and reasoning engines.
Two main stages have
to be considered in the typical
argument
mining
pipeline,
from the unstructured natural
language
documents towards structured (possibly machine-
readable) data: (i) argument extraction, i.e., to de-
tect
arguments within the input
natural
language
texts,
and (ii) relation extraction,
i.e.,
to predict
what are the relations holding between the argu-
ments identified in the first stage. The relation pre-
diction task is extremely complex,
as it
involves
high-level
knowledge representation and reason-
ing issues.
The relations between the arguments
may be of heterogeneous nature, like attack, sup-
port or entailment (Cabrio and Villata, 2013).
The increasing amount of data available on the
Web from heterogeneous sources, e.g., social net-
work posts,
forums,
news blogs,
and the specific
form of language adopted there challenge argu-
ment
mining methods,
with the aim to support
users to understand and interact with such a huge
amount of information.
In this paper, we address this issue by present-
ing an argument relation prediction approach for
Italian.
We test
the method on the CorEA cor-
pus (Celli
et
al.,
2014) of user comments to the
news articles of an Italian newspaper,
annotated
with agreement
(i.e.,
support) and disagreement
(i.e.,
attack) relations.
We extract argument-level
features from the CorEA comment (i.e., argument)
CLIC_2016_Proceedings.indd 51
02/12/16 15.03
52
Figure 1: Example of debate structure.
pairs, and we train our system to predict the sup-
port and attack relations.
2
Mining Arguments
A debate, whether it happens online or in person,
can be modeled as a set of arguments proposed by
the participants.
Arguments can be independent,
for instance expressing the participant’s stance on
a particular topic, but often they are replies to pre-
vious arguments put forward in the debate.
This
results in a network structure of the debate,
that
is, a (possibly disconnected) directed graph where
nodes are arguments,
and the two kinds of edges
are the support and attack relations between them.
In Figure 1,
each node represents an argument
with a numeric identifier, filled and dashed edges
represent respectively support and attack relations,
and dotted edges are neutral relations.
The hub-
like node labeled
11
is a news article, thus attract-
ing many first-level comments.
The goal of our work is to be able to predict the
relations between the arguments in a given debate,
thus reconstructing the relation graph.
We there-
fore cast the problem as a classification task: given
two arguments from a debate,
we aim to predict
whether one argument attacks the other,
supports
it,
or there is no relation between the two argu-
ments.
The construction of the graph structure is
then straightforward, resulting from the combina-
tion of all the argument pairs we considered.
2.1
Features
We
extract
argument-level
features
from the
CorEA comment pairs, that we group into the fol-
lowing categories:
Lexical
We take into account several lexical fea-
tures: tokens, bi-grams, and the first bi-gram
and tri-gram of each argument.
Syntactic We exploit the output of a dependency
parser. We consider two kinds of dependency
features: the former is the original output, the
latter generalizes a word to its POS tag.
For
instance,
“amod(denaro,
pubblico)” is gen-
eralized as the “amod(NN,
pubblico)” and
“amod(denaro,
ADJ)”.
We adopt
the Malt
parser (Nivre, 2003) trained on the Universal
Dependency Treebank
1
.
Message info We extract
the argument
size,
the
number of uppercase words,
the number of
negations
2
,
the number of sequences of two
or more punctuation characters,
the number
of citations.
A citation is a quoted sequence
of words in the second argument that occurs
in the first argument.
Message overlap Cosine similarity between two
arguments is computed exploiting TF/IDF.
Word-embedding We
build
word-embeddings
relying on the
Pais
`
a
corpus
through the
word2vec (Mikolov et al., 2013) tool. We use
a vector dimension equal to 50, and we con-
sider only words that occur at least 20 times.
For each argument, we use the vector compo-
nents as features directly.
Sentiment
We extract the sentiment from the ar-
guments with two separate tools.
Alchemy
API
3
, the sentiment analysis feature of IBM’s
Semantic Text Analysis API, returns a polar-
ity label (positive, negative or neutral) and a
1
http://universaldependencies.org/it/
overview/introduction.html
2
The occurrences of the word “non”
3
http://www.alchemyapi.com/
CLIC_2016_Proceedings.indd 52
02/12/16 15.03
53
polarity score between -1 (totally negative)
and 1 (totally positive).
The UNIBA sys-
tem (Basile and Novielli,
2014),
one of the
most successful participants in the Sentipolc
task at Evalita 2014 (Basile et al., 2014), re-
turns a subjectivity label (subjective or objec-
tive) and a polarity label (positive,
negative,
neutral or mixed).
Topic model
We
train
a
domain-independent
topic model for Italian and compute, for each
argument, its representing vector in the topic
space.
The 300-dimensional
topic model
is
created with Gensim
4
using the ItWaC cor-
pus (Baroni
et
al.,
2009).
We use the vec-
tor components as features directly, i.e., each
comment has 300 topic-based features.
3
Evaluation
The goal of the evaluation is twofold:
i) to com-
pute the performance of several machine learning
methods and compare them with respect to some
baselines, and ii) to investigate the importance of
each group of features through an ablation test.
3.1
Data
We test our approach on the CorEA corpus (Celli
et al., 2014), a collection of text from Italian news
blogs.
It
contains 27 news articles,
about
1,660
unique authors and more than 2,900 comments.
The corpus is annotated with emotions and, most
interestingly for our work, the comments are anno-
tated pair-wise with agreement information (Celli
et al., 2016). We extracted such comment pairs for
a total of 1,275 pairs: 682 disagreement, 106 neu-
tral,
180 agreement (307 pairs are not classified,
examples in Figure 2).
The CorEA dataset
provides several
informa-
tion about each message.
Beside the features de-
scribed in Section 2.1, we also extract the follow-
ing dataset-dependent
features:
the set
of manu-
ally annotated topics, the news category of the ar-
ticle, the count of replies to the message, the count
of message likes,
the participant’s activity score,
the participant’s interests,
the participant’s page
views, the participant’s total comments, the partic-
ipant’s total shares, the participant’s likes received,
and the overall emotion declared by the participant
after reading the articles.
4
https://radimrehurek.com/gensim/
3.2
System setup
We exploit
two kinds of learning algorithms:
1)
different
configurations
of
SVM based on lin-
ear kernel (
SV M
lin
), degree-2 polynomial kernel
(
SV M
poly
),
and RBF kernel (
SV M
rbf
); 2) Ran-
dom Forest (
RF
).
The baseline method always predicts the most
frequent class, in this case “attack”. Moreover, we
test the two simple sentiment analysis systems al-
ready described in 2.1,
SA
alchemy
and
SA
uniba
.
In particular, these systems exploit the result of the
sentiment
analysis in terms of polarity (positive,
negative, or neutral) for predicting the relation be-
tween two arguments:
if two arguments have the
neutral polarity,
they are tagged as neutral,
while
they are tagged as “support” in case they have the
same polarity, otherwise the “attack” class is pre-
dicted.
The system is implemented in JAVA rely-
ing on the Weka tool (Hall et al., 2009). All the ex-
periments are performed by adopting the 10-folds
cross-validation.
For all the learning methods, we
adopt the default Weka parameters since the goal
of our work is not
to optimize the classification
performance but to provide a features study.
3.3
Results
Table 1 reports on the best results obtained by each
method.
Regarding
RF
the best result is obtained
using 10 trees, while for
SV M
we optimize only
the
C
parameter using default values for the other
ones.
The best
C
value for
SV M
lin
is 1, 2 in all
the other settings.
Each one of the supervised systems performs
better than the baseline. The good performance of
the linear kernel classifier is likely to be ascribed
to the high number of features.
The performance
of Random Forest is also quite good, considering
that only ten trees are employed.
Table 1: Results
System
P
R
F
baseline
0.4964
0.7045
0.5824
SA
alchemy
0.3553
0.3616
0.3584
SA
uniba
0.2942
0.3286
0.3105
SV M
lin
0.6789
0.7169
0.6719
RF
0.6607
0.7180
0.6491
SV M
poly
0.6609
0.7097
0.6486
SV M
rbf
0.6414
0.7076
0.6120
As can be seen from the results of ablation tests
(see Table 2), the features that contribute the most
CLIC_2016_Proceedings.indd 53
02/12/16 15.03
54
Relation
Example
Attack
“in certi paesi 100 sterline a settimana permettono di vivere come un pasci
`
a”
“si ma in certi altri no..;-) la cifra mi sembra davvero esigua..”
Support
“Caro Renzi , hai visto com’
`
e semplice restituire i soldi? Basta una firmetta... perch
`
e
non lo fai anche tu invece di promettere e promettere e promettere?”
“Bisogna prendere atto che il movimento 5 stelle sta davvero restituendo i
soldi agli Italiani. Questo
`
e un fatto, tutto il resto sono chiacchere.”
Neutral
“E le riforme?”
“le riforme cominciano dl’atteggiamento dei parlamentari. con il
cambiamento del mind-set . il punto di partenza.”
Figure 2: Examples of relations between pairs of comments in CorEA.
to the argument classification task are the seman-
tic features (i.e.,
embeddings) and the sentiment
features.
This confirms our hypothesis that senti-
ment
is a key information for argument
mining,
and more specifically for the relation prediction
task.
The results also confirm that
lexical
and
semantic features are useful
for the task,
as ex-
pected. Table 2 reports also the number of features
(Feat.Size) and the F1 (F1-f) achieved by exploit-
ing the respective feature in isolation.
It is impor-
tant to note that, despite the bad performance ob-
tained by both embedding and sentiment features,
their contribution in the overall performance is rel-
evant.
Table 2: Ablation test
Features
F1
∆%
Feat.Size
F1-f
all
0.6719
-
220,499
-
-lexical
0.6624
-1.42
140,443
0.66
-syntactic
0.6702
-0.26
80,909
0.65
-info
0.6691
-0.42
220,490
0.58
-CorEA
0.6674
-0.68
220,218
0.64
-embedding
0.6525
-2.89
220,399
0.59
-overlap
0.6724
0.07
220,498
0.58
-sentiment
0.6622
-1.45
220,491
0.58
-topic
0.6673
-0.69
220,045
0.59
4
Related Work
(Lippi
and Torroni,
2016)
and (Peldszus
and
Stede, 2013) provide an overview about the argu-
ment mining research area. In particular, some ap-
proaches have been recently proposed to address
the same task addressed in this paper,
i.e.
pre-
dicting relations between arguments,
even if ours
is the first
effort
for the Italian language.
(Aha-
roni et al.,
2014) assume that evidence is always
associated with a claim,
enabling the use of in-
formation about the claim to predict the evidence.
The support relations are thus obtained by defini-
tion when predicting the evidence. (Mochales and
Moens, 2011) have addressed the problem by pars-
ing with a manually-built context-free grammar to
predict
relations between argument
components.
The grammar rules follow the typical
rhetorical
and structural
patterns of
sentences in juridical
texts. This is a highly genre-specific approach, and
its direct use in other genres would be unlikely to
yield accurate results.
(Stab and Gurevych, 2014)
instead employ a binary SVM classifier to predict
relations in a claim/premise model.
(Biran and
Rambow,
2011) apply the same method adopted
for
the detection of
premises also for
the pre-
diction of relations between premises and claims.
(Wang and Cardie, 2014) apply an isotonic Condi-
tional
Random Fields based sequential
model
to
make predictions on sentence-
or
segment-level
on discussions on Wikipedia Talk pages.
Finally,
(Cabrio and Villata,
2013) adopt
Textual
Entail-
ment to infer whether a support or attack relation
between two given arguments holds.
5
Conclusions
In this paper, we have presented a supervised ap-
proach for argument
relation prediction for Ital-
ian,
mainly relying on features including seman-
tics and sentiment.
We tested such approach on
the CorEA corpus, extracted from user comments
to online news. Our experimental results are good,
and foster future research in the direction of in-
cluding semantics as well as sentiment analysis in
the argument mining pipeline.
It will be also in-
teresting,
as future work,
to refine the model
in
order to consider the full sequence of interactions
between arguments.
CLIC_2016_Proceedings.indd 54
02/12/16 15.03
55
References
Ehud Aharoni, Anatoly Polnarov, Tamar Lavee, Daniel
Hershcovich,
Ran Levy,
Ruty Rinott,
Dan Gutfre-
und, and Noam Slonim.
2014.
A benchmark dataset
for automatic detection of claims and evidence in the
context
of controversial
topics.
In Proceedings of
the First Workshop on Argumentation Mining, pages
29–38,
Baltimore,
Maryland,
June.
Association for
Computational Linguistics.
Marco Baroni,
Silvia Bernardini,
Adriano Ferraresi,
Eros Zanchetta,
Springer,
and Science+business
Media B.
V.
2009.
The wacky wide web:
A col-
lection of
very large linguistically processed we-
bcrawled corpora.
language resources and evalua-
tion.
Pierpaolo Basile and Nicole Novielli.
2014.
Uniba
at evalita 2014-sentipolc task: Predicting tweet sen-
timent polarity combining micro-blogging,
lexicon
and semantic features.
Proceedings of
EVALITA,
pages 58–63.
Valerio Basile,
Andrea Bolioli,
Malvina Nissim,
Vi-
viana Patti,
and Paolo Rosso.
2014.
Overview of
the Evalita 2014 SENTIment
POLarity Classifica-
tion Task.
In Proceedings of the 4th evaluation cam-
paign of Natural Language Processing and Speech
tools for Italian (EVALITA’14), Pisa, Italy.
Or Biran and Owen Rambow.
2011.
Identifying justi-
fications in written dialogs by classifying text as ar-
gumentative.
Int. J. Semantic Computing, 5(4):363–
381.
Elena Cabrio and Serena Villata.
2013.
A natural
language bipolar argumentation approach to support
users in online debate interactions
†
.
Argument
&
Computation, 4(3):209–230.
Fabio Celli,
Giuseppe Riccardi,
and Arindam Ghosh.
2014.
Corea: Italian news corpus with emotions and
agreement.
In CLIC-it 2014, pages 98–102.
Fabio Celli, Giuseppe Riccardi, and Firoj Alam.
2016.
Multilevel
annotation of
agreement
and disagree-
ment
in italian news blogs.
In Nicoletta Calzo-
lari
(Conference Chair),
Khalid Choukri,
Thierry
Declerck,
Sara
Goggi,
Marko Grobelnik,
Bente
Maegaard,
Joseph Mariani,
Helene Mazo,
Asun-
cion Moreno,
Jan Odijk,
and Stelios Piperidis,
edi-
tors, Proceedings of the Tenth International Confer-
ence on Language Resources and Evaluation (LREC
2016), Paris, France, may. European Language Re-
sources Association (ELRA).
Mark Hall,
Eibe Frank,
Geoffrey Holmes,
Bernhard
Pfahringer,
Peter
Reutemann,
and Ian H.
Witten.
2009.
The weka data mining software:
An update.
SIGKDD Explor. Newsl., 11(1):10–18, November.
Marco Lippi and Paolo Torroni.
2016.
Argumentation
mining:
State of the art and emerging trends.
ACM
Trans. Internet Techn., 16(2):10.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean.
2013.
Efficient estimation of word represen-
tations in vector space.
In Workshop at ICLR, 2013.
Raquel
Mochales and Marie-Francine Moens.
2011.
Argumentation mining.
Artificial
Intelligence and
Law, 19(1):1–22.
Joakim Nivre.
2003.
An efficient algorithm for pro-
jective dependency parsing.
In Proceedings of the
8th International Workshop on Parsing Technologies
(IWPT).
Andreas Peldszus and Manfred Stede.
2013.
From ar-
gument diagrams to argumentation mining in texts:
A survey.
IJCINI, 7(1):1–31.
Christian Stab and Iryna Gurevych.
2014.
Identifying
argumentative discourse structures in persuasive es-
says.
In Proceedings of the 2014 Conference on Em-
pirical
Methods in Natural
Language Processing,
EMNLP 2014,
October 25-29,
2014,
Doha,
Qatar,
A meeting of
SIGDAT,
a Special
Interest
Group of
the ACL, pages 46–56.
Lu Wang and Claire Cardie.
2014.
Improving agree-
ment and disagreement identification in online dis-
cussions with a socially-tuned sentiment lexicon.
In
Proceedings of the 5th Workshop on Computational
Approaches to Subjectivity,
Sentiment
and Social
Media Analysis,
pages 97–106,
Baltimore,
Mary-
land, June. Association for Computational Linguis-
tics.
CLIC_2016_Proceedings.indd 55
02/12/16 15.03
56
Diachronic Analysis of the Italian Language exploiting Google Ngram
Pierpaolo Basile
1
and Annalina Caputo
1
and Roberta Luisi
2
and Giovanni Semeraro
1
Department of Computer Science
University of Bari Aldo Moro
Via, E. Orabona, 4 - 70125 Bari (Italy)
1
{
firstname.surname
}
@uniba.it
2
{
roby.luisi
}
@gmail.com
Abstract
English.
In this paper,
we propose sev-
eral
methods for
the diachronic analysis
of the Italian language.
We build several
models by exploiting Temporal
Random
Indexing and the Google Ngram dataset
for the Italian language.
Each proposed
method is evaluated on the ability to auto-
matically identify meaning shift over time.
To this end,
we introduce a new dataset
built by looking at the etymological infor-
mation reported in some dictionaries.
Italiano. In questo lavoro proponiamo al-
cuni metodi per l’analisi diacronica della
lingua italiana.
Abbiamo costruito differ-
enti modelli utilizzando la tecnica del Tem-
poral Random Indexing e Google Ngram
per l’italiano.
Ciascun metodo proposto
`
e stato valutato rispetto alla capacit
`
a di
identificare automaticamente i
cambi
di
significato nel tempo.
A tale scopo intro-
duciamo uno nuovo dataset costruito me-
diante le informazioni
etimologiche pre-
senti in alcuni dizionari.
1
Motivation and Background
Languages can be studied from two different and
complementary viewpoints:
the diachronic per-
spective considers the evolution of a language over
time,
while the synchronic perspective describes
the language rules at a specific point of time with-
out
taking its history into account
(De Saussure,
1983).
In this work,
we focus on the diachronic
approach,
since language appears to be unques-
tionably immersed in the temporal
dimension.
Language is subject to a constant evolution driven
by the need to reflect
the continuous changes of
the world.
The evolution of word meanings has
been studied for several centuries, but this kind of
investigation has been limited by the low amount
of data on which to perform the analysis.
More-
over, in order to reveal structural changes in word
meanings, this analysis has to explore long periods
of time.
Nowadays,
the large amount of digital content
opens new perspectives for the diachronic analysis
of language.
This large amount of data needs effi-
cient computational approaches.
In this scenario,
Distributional Semantic Models (DSMs) represent
a promising solution.
DSMs are able to repre-
sent words as points in a geometric space, gener-
ally called WordSpace (Schiitze,
1993; Sahlgren,
2006) simply analysing how words are used in a
corpus. However, a WordSpace represents a snap-
shot of a specific corpus and it does not take into
account temporal information.
Since its first release, the Google Ngram dataset
(Michel et al.,
2011) has inspired a lot of works
on the analysis of
cultural
trends and linguistic
variations.
Moving away from mere frequentist
approaches, Distributional Semantic Models have
proved to be quite effective in measuring a mean-
ing shift through the analysis of variation of word
co-occurrences.
One of the earlier attempts can
be dated to Gulordava and Baroni (2011),
where
a co-occurrence matrix is used to model
the se-
mantics of terms.
In this model, similarly to ours,
the cosine similarity between vectors representing
a term in two different
periods is exploited as a
predictor of the meaning shift: low values suggest
a change in the words that co-occur with the tar-
get.
The co-occurrence matrix is computed with
local mutual information scores and the context el-
ements are fixed with respect to the different time
CLIC_2016_Proceedings.indd 56
02/12/16 15.03
57
periods,
hence the spaces are directly compara-
ble.
However, this kind of direct comparison does
not hold when the vector representation is manipu-
lated, like in reduction methods (SVD), or learning
approaches (word2vec). In these cases, each space
has its own coordinate axis.
Then,
some kind of
alignment between spaces is required. To this end,
Hamilton et al. (2016) use orthogonal Procrustes,
while Kulkarni et al.
(2015a) learn a transforma-
tion matrix.
In this paper,
we propose an evolution of our
previous work (Basile et
al.,
2014;
Basile et
al.,
2015)
for
analysing word meanings over
time.
This model, differently from those of Hamilton et
al. (2016) and Kulkarni et al. (2015a), creates dif-
ferent WordSpaces for each time period in terms
of the same common random vectors; then, the re-
sulting word vectors are directly comparable with
one another.
In particular,
we propose an effi-
cient
method for
building a DSM model
which
takes into account temporal information relying on
a very large corpus: the Google Ngram for the Ital-
ian language. Moreover, for the first time, we pro-
vide a dataset for the evaluation of word meaning
change points detection specifically set up for the
Italian language.
The paper
is
structured as
follows:
Section
2 provides details about
our methodology,
while
Section 3 describes the dataset that we have devel-
oped and the results of a preliminary evaluation.
Section 4 reports final remarks and future work.
2
Methodology
Our method has its roots in a previous model based
on Temporal
Random Indexing (TRI) (Basile et
al.,
2014;
Basile et
al.,
2015).
In particular,
we
evolve the TRI approach in two directions:
1) we
improve the system in order to manage very large
datasets, such as Google Ngram; 2) we introduce
a new approach based on Reflective Random In-
dexing (RRI) (Cohen et al., 2010) with the aim of
identifying indirect inferences that can lead to the
discovery of implicit
connections between word
meanings.
The
idea
behind TRI
is
to
build
different
WordSpaces for each time period that we want to
analyse.
The peculiarity of TRI is that word vec-
tors over different time periods are directly compa-
rable because they are built using the same random
vectors. In particular TRI works as follows:
1.
Given a corpus
C
of documents and a vo-
cabulary
V
of terms
1
extracted from
C
,
the
method assigns a random vector
r
i
to each
term
t
i
∈
V
. A random vector is a vector that
has values only in
{
-1, 0, 1
}
and it is sparse
with few non-zero elements distributed ran-
domly along its dimensions.
The set of ran-
dom vectors assigned to all
terms in
V
are
near-orthogonal;
2.
The corpus
C
is split in different time periods
T
k
using temporal information,
for example
the year of publication;
3.
For
each period
T
k
,
a WordSpace
WS
k
is
built.
All the terms of
V
occurring in
T
k
are
represented by a semantic vector. The seman-
tic vector
sv
k
i
for the
i
-th term in
T
k
is built as
the sum of all the random vectors of the terms
co-occurring with
t
i
in
T
k
.
When comput-
ing the sum, we weigh the random vector; in
this case we adopt a formula based on inverse
document frequency.
Formally, the weight is
computed as
w
(
r
i
) =
log

C
k
#t
k
i

,
where
C
k
is the total number of occurrences in
T
k
and
#
t
k
i
is the occurrences of the term
t
i
in
T
k
.
The idea is to give less weight
to the most
frequent words.
In this way, the semantic vectors across all time
periods are comparable since they are the sum of
the same random vectors.
RRI can be implemented by repeating the steps
2 and 3 several times. Where at each iteration ran-
dom vectors are replaced by the semantic vectors
built
in the previous step.
The idea is to model
implicit connections between terms that never co-
occur
together,
but
that
could occur
frequently
with other shared terms.
The next two sub-sections provide details about
the Google Ngram dataset and the method used to
automatically detect word meanings shift.
2.1
Google Ngram
Google Ngram is a very large dataset containing
all the n-grams (up to five) extracted from Google
Books.
It is built by analysing over five millions
books
spanning the years
from 1500 to 2012,
but the developers estimate that the most reliable
period is from 1800 to 2012.
The dataset covers
several
languages
including Italian.
For
each
1
The terms that we want to analyse.
Usually, the most n
frequent terms are extracted.
CLIC_2016_Proceedings.indd 57
02/12/16 15.03
58
language,
several
compressed files are released.
Each file contains
for
each line the following
information:
Ngram <TAB> year <TAB>
match count <TAB> volume count.
For
example,
the
line
“analysis is often
described as 1991 104 5”
means
that
the ngram “analysis is often described as” occurs
104 times in 5 books in the 1991 .
We modify TRI for building the WordSpaces
directly from the
Google
Ngram dataset.
In
particular,
we
need
a
pre-processing
step
in
which we split
the n-grams in several
files ac-
cording to the time periods
we want
to anal-
yse.
For
example,
if
we
fix the
dimension
of
a
time
period to ten years
from 1850 to
2012,
we
build several
files
for
each period:
T
1
= 1850
-
1859
, T
2
= 1860
-
1869
, . . . , T
16
=
2000
-
2009
, T
17
= 2010
-
2012
.
Each file contains
only the n-grams that
occur in the specific time
period. We remove information about the year and
the book count since they are not useful in the sub-
sequent steps.
Considering the previous example,
the line “analysis is often described
as 104” will be stored in the file 1990-1999.
After this pre-processing step, we can easily run
TRI and RRI, where RRI can be repeated multiple
times.
2.2
Change point detection
To track the word meaning change over time,
for
each term
t
i
we build a time series
Γ(
t
i
)
taking
into account several methods.
A time series is a
sequence of values,
one value for each time pe-
riod, that indicates the semantic shift of that term
in the specific period.
We adopt several strategies
for building time series. The first strategy is based
on term log-frequency; each value in the series is
defined as:
Γ
k
(
t
i
) =
log
(
#t
k
i
C
k
)
.
In order to exploit
the ability of our methods
in computing vectors similarity over time periods,
we define two strategies for building the time se-
ries:
point-wise:
Γ
k
(
t
i
)
is defined as the cosine simi-
larity between
sv
k
i
and
sv
k−1
i
.
In this way,
we want to capture vector changes between
two time periods;
cumulative:
we
build
a
cumulative
vector
sv
C
k−1
i
=

k−1
j=0
sv
j
i
and compute the cosine
similarity with respect
to the vector
sv
k
i
.
The idea is that the semantics at point
k
−
1
depends on the semantic of all the previous
time periods.
Given a time series we need a method for find-
ing significant
change points in the series.
We
adopt
the strategy proposed in (Kulkarni
et
al.,
2015b)
based on the Mean shift
model
(Taylor,
2000). According to this model, we define a mean
shift of a general time series
Γ
pivoted at time pe-
riod
j
as:
K
(Γ) =
1
l
−
j
l

k=j+1
Γ
k
−
1
j
j

k=1
Γ
k
(1)
In order to understand if a mean shift is statisti-
cally significant at time
j
, a bootstrapping (Efron
and Tibshirani, 1994) approach under the null hy-
pothesis that
there is no change in the mean is
adopted.
In particular,
statistical
significance is
computed by first constructing
B
bootstrap sam-
ples by permuting
Γ(
t
i
)
.
Second,
for each boot-
strap sample P,
K
(
P
)
is calculated to provide
its corresponding bootstrap statistic and statistical
significance (p-value) of observing the mean shift
at
time
j
compared to the null
distribution.
Fi-
nally, we estimate the change point by considering
the time point
j
with the minimum p-value score.
Since multiple words can have the same p-value,
we sort
them according to their frequency.
The
output of this process is a ranking of words that
potentially have changed meaning.
3
Evaluation
The goal of the evaluation is twofold:
1) to build
a standard benchmarking for meaning shift detec-
tion for the Italian language; 2) to evaluate the per-
formance of the proposed methods and compare
them with the baseline model based on the word
frequency.
A list of meaning shifts for the Italian language
is not available, then we build a new dataset using
a pooling strategy.
In particular,
we retrieve the
list of meaning shifts, as explained in Section 2.2,
using the cumulative strategy for each of the fol-
lowing methods: word frequency, TRI, TRRI with
one iteration and TRRI with two iterations.
Taking into account the first
50
words for each
system,
we manually check for
each word if
a
meaning shift occurs by exploiting some dictionar-
ies.
We use two dictionaries:
the “Sabatino Co-
letti” available on-line
2
and the “Dizionario Eti-
2
http://dizionari.corriere.it/
dizionario_italiano/
CLIC_2016_Proceedings.indd 58
02/12/16 15.03
59
mologico Zanichelli” available on CD-ROM.
Fi-
nally, we obtain a gold standard that consists of 40
words and their corresponding change points.
All
the methods,
with exception of word fre-
quency,
are built
using co-occurrences informa-
tion extracted from 5-grams in the Google Ngram
dataset for the Italian. The vector dimension is set
to 1,000 for all the approaches based on Random
Indexing using two non-zero elements in the ran-
dom vector.
We adopt accuracy as evaluation metric.
Given
a list
of
n
change points returned by the sys-
tem, we compute the ratio between the number of
change points correctly identified in the gold stan-
dard
3
and
n
. In order to identify the correct change
points,
we consider not only the word
4
,
but also
the year of the change point. In particular, the year
predicted by the system must be equal or greater
than one of the years reported in the gold standard.
We compute the accuracy using different values of
n
(10, 100, ALL). Results of the evaluation are re-
ported in Table 1. In particular, we evaluate 7 sys-
tems:
logf req
is the baseline based on word fre-
quency;
T RI
is the Temporal Random Indexing
method,
T RRI
1
is the Temporal Reflective Ran-
dom Indexing with one iteration,
while
T RRI
2
adopts two iterations.
For the methods based on
Random Indexing,
we investigate both the point-
wise and the cumulative strategy to compute the
change points.
Table 1: Results of the evaluation.
Method
acc@10
acc@100
ALL
T RI
point
0.0247
0.1111
0.3086
T RI
cum
0.0123
0.0247
0.2963
T RRI
1
point
0.0000
0.0247
0.2716
logf req
0.0247
0.1111
0.2346
T RRI
2
point
0.0000
0.0370
0.1728
T RRI
1
cum
0.0000
0.0000
0.1605
T RRI
2
cum
0.0000
0.0000
0.1235
The analysis of the results shows that
T RI
gen-
erally provides better results than
T RRI
.
More-
over,
the point-wise strategy always outperforms
the cumulative one.
With respect to the baseline,
it has the same accuracy of
T RI
for both acc@10
3
The gold standard adopted in this evaluation is available
here:
https://dl.dropboxusercontent.com/u/
16026979/data/TRI_CLIC_2016_change_word.
4
The word matching is performed taking into account also
the inflected forms.
and acc@100, while it performs worse than
T RI
and
T RRI
1
when the accuracy is computed over
the whole list of terms (ALL). These results sug-
gest that, while there are not too many differences
between the two methods considering smaller lists
of
results,
T RI
is actually able to detect
more
meaning shifts on a larger set of terms.
T RRI
2
always provides the worst
results;
we speculate
that two iterations introduce too much noise in the
model.
A closer scrutiny to the list of words pro-
vided by
T RRI
2
highlights the presence of many
foreign words:
a simplistic conclusion may sug-
gest that this approach is able to identify foreign
terms that are introduced in the Italian language.
However, we think that the output of this method
deserves more investigations carried out
by de-
signing an ad-hoc evaluation.
The evaluation is based on the predicted year,
which has to be equal or greater than one of the
years reported in the gold standard,
we conduct
a further analysis to measure how far the predic-
tion is from the exact
value.
In particular,
we
compute the mean and the standard deviation tak-
ing into account the differences between the pre-
dicted and the exact year.
The results of this anal-
ysis are reported in Table 2.
We observe the both
T RRI
1
cum
and
T RRI
2
cum
produce the best re-
sults despite their low accuracy, while
T RI
cum
re-
ports the best trade-off between accuracy and pre-
cision in detecting the correct year. It is important
to underline that the size of the time interval influ-
ences this kind of analysis since if the algorithm
predicts 1900,
the change point
could happen in
the interval 1900-1909
5
. We plan to design a more
accurate analysis by exploring a time interval set
to one year as future work.
Table 2:
Mean and standard deviation of the dif-
ferences between the predicted and the exact year.
Method
Mean
Std.Deviation
T RI
point
38.04
34.90
T RI
cum
26.45
19.60
T RRI
1
point
65.86
49.96
logf req
24.15
16.19
T RRI
2
point
54.50
52.70
T RRI
1
cum
16.61
14.62
T RRI
2
cum
19.40
19.85
5
In our experiment,
the size of the time interval is set to
ten years.
CLIC_2016_Proceedings.indd 59
02/12/16 15.03
60
4
Conclusions
In this work we proposed several methods based
on Random Indexing for
the diachronic analy-
sis of
the Italian language.
We built
a dataset
for the evaluation of meaning shift by exploiting
etymological
information taken from two Italian
dictionaries.
We compared our approaches with
respect
a baseline based on word frequency ob-
taining promising results.
In particular,
the TRI
method showed its better capability in retrieving
more meaning shifts on a longer list of terms.
As
future work, we plan to extend the dataset with fur-
ther words and to investigate other methods based
on word-embeddings.
Acknowledgement
This work is partially supported by the project
“Multilingual Entity Liking” funded by the Apu-
lia Region under the program FutureInResearch.
References
Pierpaolo Basile,
Annalina Caputo,
and Giovanni Se-
meraro.
2014.
Analysing word meaning over time
by exploiting temporal random indexing.
In Roberto
Basili,
Alessandro Lenci,
and Bernardo Magnini,
editors,
First Italian Conference on Computational
Linguistics CLiC-it 2014. Pisa University Press.
Pierpaolo Basile,
Annalina Caputo,
and Giovanni Se-
meraro.
2015.
Temporal random indexing:
A sys-
tem for analysing word meaning over time.
Italian
Journal
of
Computational
Linguistics,
1(1):55–68,
12.
Trevor Cohen, Roger Schvaneveldt, and Dominic Wid-
dows.
2010.
Reflective random indexing and indi-
rect inference:
A scalable method for discovery of
implicit connections.
Journal of biomedical infor-
matics, 43(2):240–256.
Ferdinand De Saussure.
1983.
Course in general lin-
guistics.
La Salle, Illinois: Open Court.
Bradley Efron and Robert J Tibshirani.
1994.
An intro-
duction to the bootstrap.
Chapman and Hall/CRC.
Kristina Gulordava and Marco Baroni.
2011.
A distri-
butional similarity approach to the detection of se-
mantic change in the google books ngram corpus.
In
Proceedings of
the GEMS 2011 Workshop on GE-
ometrical
Models of
Natural
Language Semantics,
pages 67–71,
Edinburgh,
UK, July. Association for
Computational Linguistics.
William L.
Hamilton,
Jure Leskovec,
and Dan Ju-
rafsky.
2016.
Diachronic word embeddings re-
veal
statistical
laws of
semantic change.
CoRR,
abs/1605.09096.
Vivek Kulkarni,
Rami
Al-Rfou,
Bryan Perozzi,
and
Steven Skiena.
2015a.
Statistically significant de-
tection of linguistic change.
In Proceedings of the
24th International Conference on World Wide Web,
WWW ’15,
pages 625–635,
New York,
NY,
USA.
ACM.
Vivek Kulkarni,
Rami
Al-Rfou,
Bryan Perozzi,
and
Steven Skiena.
2015b.
Statistically significant de-
tection of linguistic change.
In Proceedings of the
24th International Conference on World Wide Web,
pages 625–635. ACM.
Jean-Baptiste Michel,
Yuan Kui
Shen,
Aviva Presser
Aiden,
Adrian Veres,
Matthew K Gray,
Joseph P
Pickett,
Dale Hoiberg,
Dan Clancy,
Peter Norvig,
Jon Orwant,
et
al.
2011.
Quantitative analysis of
culture using millions of digitized books.
science,
331(6014):176–182.
Magnus Sahlgren.
2006.
The word-space model:
Us-
ing distributional analysis to represent syntagmatic
and paradigmatic relations between words in high-
dimensional vector spaces.
Hinrich Schiitze.
1993.
Word space.
Advances in neu-
ral information processing systems, 5:895–902.
Wayne A Taylor.
2000.
Change-point analysis: a pow-
erful new tool for detecting changes.
Taylor Enter-
prises, Inc.
CLIC_2016_Proceedings.indd 60
02/12/16 15.03
61
Investigating the Application of Distributional Semantics to Stylometry
Giulia Benotto, Emiliano Giovannetti, Simone Marchi
Istituto di Linguistica Computazionale “A. Zampolli”
Consiglio Nazionale delle Ricerche
Via G. Moruzzi 1, 56124, Pisa - Italy
{
name.surname
}
@ilc.cnr.it
Abstract
English.
The inclusion of semantic fea-
tures in the stylometric analysis of liter-
ary texts appears to be poorly investigated.
In this work,
we experiment with the ap-
plication of Distributional Semantics to a
corpus of Italian literature to test if words
distribution can convey stylistic cues.
To
verify our hypothesis,
we have set
up an
Authorship Attribution experiment.
In-
deed, the results we have obtained suggest
that the style of an author can reveal itself
through words distribution too.
Italiano.
L’inclusione
di
caratteris-
tiche
semantiche
nell’analisi
stilomet-
rica di
testi
letterari
appare poco stu-
diata.
In
questo
lavoro,
sperimenti-
amo l’applicazione della Semantica Dis-
tribuzionale ad un corpus di
letteratura
italiana per verificare se la distribuzione
delle
parole
possa fornire
indizi
stilis-
tici.
Per verificare la nostra ipotesi, abbi-
amo imbastito un esperimento di Author-
ship Attribution.
I risultati
ottenuti
sug-
geriscono che, effettivamente, lo stile di un
autore pu rivelarsi anche attraverso la dis-
tribuzione delle parole.
1
Introduction
Stylometry, that is the application of the study of
linguistic style,
offers a means of capturing the
elusive character of an author’s style by quanti-
fying some of its features.
The basic stylometric
assumption is that
each writer has certain stylis-
tic idiosyncrasies (a “human stylome” (Van Hal-
teren et al.,
2005)) that define their style.
Analy-
sis based on stylometry are often used for Author-
ship Attribution (AA) tasks,
since the main idea
behind computationally supported AA is that
by
measuring some textual
features,
we can distin-
guish between texts written by different
authors
(Stamatatos, 2009).
One of the less investigated stylistic feature is
the way in which authors use words from a seman-
tic point
of view,
e.g.
if they tend to use more,
when dealing with polysemous words,
a certain
sense over the others,
or senses that differ (even
slightly) from the one that’s more commonly used
(as it happens, typically, in poetry).
A possible approach to the analysis of this char-
acteristic is to consider
the textual
contexts
in
which certain words appear.
According to Dis-
tributional Semantics (DS), certain aspects of the
meaning of lexical expressions depend on the dis-
tributional properties of such expressions,
or bet-
ter,
on the contexts in which they are observed
(Lenci, 2008; Miller and Charles, 1991).
The se-
mantic properties of a word can then be defined by
inspecting a significant number of linguistic con-
texts, representative of the distributional behavior
of such word.
In this work we would like to investigate if the
analysis of the distribution of words in a text can
be exploited to provide a stylistic cue.
In order to
inspect
that,
we have experimented with the ap-
plication of DS to the stylometric analysis of liter-
ary texts belonging to a corpus constituted by texts
pertaining to the work of six Italian writers of the
late nineteenth century.
In the following,
Section 2 gives a short
in-
sight on the state of the art of computational stylis-
tic analysis,
Section 3 describes the approach to-
gether with the corpus used to conduct our inves-
tigation and Section 4 discuss about
results.
Fi-
nally, Section 5 draws some conclusions and out-
lines some possible future works.
2
State of the Art
The very first attempts to analyze the style of an
author were based on simple lexical features such
CLIC_2016_Proceedings.indd 61
02/12/16 15.03
62
as sentence length counts and word length counts,
since they can be applied to any language and
any corpus with no additional requirements (Kop-
pel and Schler, 2004; Stamatatos, 2006; Zhao and
Zobel,
2005;
Argamon et
al.,
2007).
Similarly,
character measures have been proven to be quite
useful to quantify the writing style (Grieve, 2007;
De Vel
et
al.,
2001;
Zheng et
al.,
2006).
Basi-
cally, a text can be viewed as a mere sequence of
characters, so that various measures can be defined
(including alphabetic,
digit,
uppercase and low-
ercase characters count,
etc.).
A more elaborate
text
representation method is to employ syntac-
tic information (Gamon,
2004;
Stamatatos et al.,
2000; Stamatatos et al., 2001; Hirst and Feiguina,
2007;
Uzuner and Katz,
2005).
The idea is that
authors tend to use similar syntactic patterns un-
consciously.
Therefore,
syntactic information is
considered a more reliable authorial fingerprint in
comparison to lexical information.
More complicated tasks such as full
syntactic
parsing,
semantic analysis,
or
pragmatic analy-
sis cannot
yet
be handled adequately by current
NLP technologies for unrestricted text.
As a re-
sult, very few attempts have been made to exploit
high-level features for stylometric purposes.
Per-
haps the most important method of exploiting se-
mantic information so far was described in (Arga-
mon et al., 2007). This work was based on the the-
ory of Systemic Functional Grammar (SFG) (Hal-
liday, 1994) and consisted on the definition of a set
of functional features that associate certain words
or phrases with semantic information.
The previously described features are applica-
tion independent since they can be extracted from
any textual
data.
Beyond that,
one can define
application-specific measures in order
to better
represent the nuances of style in a given text do-
main (such as e-mail
messages,
or online forum
messages) (Li et al., 2006; Teng et al., 2004).
To the best of our knowledge, the application of
DS to the analysis of literary texts has been docu-
mented in a rather small number of works (Buite-
laar et al.,
2014;
Herbelot,
2015).
In both these
works,
DS is used as a theoretical basis in order
to verify some hypotheses on specific semantic
characteristics of poetic works.
In more details,
in (Buitelaar et al., 2014) the authors investigated
through DS the influence of Lord Byron’s work
on Thomas Moore trying to find a shared vocab-
ulary or specific formal textual characteristics.
In
(Herbelot, 2015) it is argued how distributionalism
can support the notion that the meaning of poetry
comes from the meaning of ordinary language and
how distributional
representations can model
the
link between ordinary and poetic language.
How-
ever,
the role of DS in the study of a style of an
author was not the aim of these works.
3
Experimental Setup
First, we want to specify that it is not our purpose
to propose new ways to improve state-of-the-art
AA algorithms.
Indeed,
our aim is just to verify
the hypothesis that
the distribution of words can
provide an indication of a distributional
stylistic
fingerprint of an author. To do this, we have set up
a simple classification task. Subsection 3.1 briefly
depicts the data set we used, while Section 3.2 de-
scribes the steps implemented in our experiment.
3.1
Data Set Construction
In order to build the reference and test corpora, we
started from texts pertaining to the work of six Ital-
ian writers working at the turn of the 20
th
century,
namely,
Luigi
Capuana,
Federico De Roberto,
Luigi Pirandello, Italo Svevo, Federigo Tozzi and
Giovanni Verga.
We chose contiguous authors in
chronological sense,
whose texts are available in
digital
format
(in fact
we could not
do a similar
survey on the narrative of the 90s because it is still
under copyrights).
Indeed,
we used texts freely
available for download from the digital library of
the Manunzio project, via the LiberLiber website
1
.
Since they were encoded in various formats, such
as .epub,
.odt
and .txt,
our
pre-processing con-
sisted in converting them all in .txt format and get-
ting rid of all xml tags, together with footnotes and
editors’ notes and comments.
3.2
Experiment Description
According to Rudman (1997), a striking problem
in stylometry is due to the lack of homogeneity
of the examined corpora,
in particular to the im-
proper selection or fragmentation of the texts, that
might cause alterations in the writers’ style. In or-
der to create balanced reference corpora, i.e.
cov-
ering all
the authors’ different
stylistic and the-
matic phases,
for each author,
as shown in Fig-
ure 1,
we built a reference corpus as the compo-
sition of the 70% of each single work (usually a
novel). The same technique was used to create the
1
http://www.liberliber.it/
CLIC_2016_Proceedings.indd 62
02/12/16 15.03
63
Figure 1:
RWP
ref
and RWP
test
creation process
for an author.
test
corpus by using the remaining 30% of each
work. Typical AA approaches consist in analyzing
known authors and assigning authorship to previ-
ously unseen text on the basis of various features.
Train and test
sets should then contain different
texts.
Contrary to the classical AA task, our train
and test
sets contain different
parts of the same
texts.
Indeed, with this experiment, we wanted to
understand if the semantics that an author bestows
to a word, is peculiar to his writing. To prove this,
we wanted to cover all the different stylistic and
thematic phases an author can go through during
his activity, hence the partition of all his texts in a
reference and a test portion.
We then analyzed each reference and test cor-
pora with a Part-of-Speech (PoS) tagger and a lem-
matizer for Italian (Dell’Orletta et al., 2014).
For
every author, we built two lists of word pairs (with
their lemma and PoS),
one relative to the tagged
reference corpus (reference pairs) and the other to
the tagged test
set
(test
pairs),
where each word
was paired with all the other words with the same
PoS. We also filtered the pairs to leave only nouns,
adjectives and verbs. Starting from the tagged cor-
pora,
we built
two words-by-words matrixes
2
of
co-occurrence counts (co-occurrence matrixes) for
each author,
using a context window of 4
3
.
The
chosen DS model (Baroni and Lenci,
2010) was
applied to each matrix to calculate the cosine be-
2
Being the corpus relatively small and not having partic-
ular computability issues, we chose not to apply decomposi-
tion techniques to reduce the size of the matrixes (and thus
not losing any information).
3
We performed different
empiric setup of the window’s
size and chose the one that showed more suitable results, ac-
cording to what is stated by Kruszewski and Baroni (2014).
tween the vectors representing the two words of
each pair.
This allowed us to evaluate the seman-
tic relatedness between the words by assessing
their proximity in the distributional space as rep-
resented by the cosine value:
the more this value
tends to 1, the more the two words of the pair are
considered to be related.
We then obtained two
related word pair (RWP) lists for each author A:
RWP
ref
A
and RWP
test
A
.
Figure 1 shows the pro-
cess described above.
Since we wanted to focus on the analysis of the
semantic distribution of words, we decided to ex-
clude any possible “lexical bias”.
For this reason,
we restricted the analysis on a common vocabu-
lary,
i.e.
a vocabulary constituted by the inter-
section of the six authors’ vocabularies.
In this
way, we prevent our classifier to exploit, as a fea-
ture, the presence of words used by some (but not
all) of the authors.
Moreover,
we removed from
the RWP
test
lists all those pairs of words occurring
frequently together in the same context, since they
might constitute a multiword expression that, once
again, could be pertaining with the signature lex-
icon of each author.
To remove them,
we com-
puted the number of times (#co-occ in Table 1)
they appeared together in the context window,
as
well
as their total
number of occurrences (#occ
a
and #occ
b
)
and we excluded from the analysis
those pairs for which the ratio between the num-
ber of co-occurrences and the total occurrences of
the less frequent word was higher than the empir-
ically set threshold of 0.5.
The first two pairs of
Table 1 would be removed as probable multiword
(PM column in Table 1):
“scoppio” (burst) and
“risa” (laughter) could mostly co-occur in “scop-
pio di risa” (meaning “burst of laughter”) and the
words “man” and “mano” (both meaning “hand”)
could mostly co-occur in “man mano” (meaning
“little by little”, or “progressively”).
W
a
W
b
#occ
a
#occ
b
#co-occ
ratio
PM
scoppio–s
risa–s
19
9
7
0.78
yes
man–n
mano–n
50
1325
47
0.94
yes
nausea–n
disgusto–n
27
26
0
0
no
piccolo–a
grande–a
248
237
14
0.06
no
Table 1:
An example of co-occurring RWs from
Pirandello’s test list:
the first two pairs would be
removed.
Finally,
we reduced the size of the six RWP
ref
and RWP
test
lists by sorting them in decreasing or-
der of the cosine value and then by keeping the
CLIC_2016_Proceedings.indd 63
02/12/16 15.03
64
pairs with the highest cosine, selected using a per-
centage parameter
θ
as threshold
4
.
We chose to
introduce the parameter
θ
for two reasons:
i) to
avoid the classification algorithm to be disturbed
by noisy (i.e.
not significative) pairs which would
not hold any relevant stylistic cue, and ii) to ease
a literary scholar in the interpretation of the re-
sults by having to analyze just a limited selection
of (potentially) semantically related word pairs.
For the last phase of our experiment we defined
a classification algorithm to test the effective pres-
ence of stylistic cues inside the obtained RWP
test
lists. We defined a classifier using a nearest-cosine
method to attribute each test
list
to an author.
The method consisted in searching for a pair of
words contained in the test list inside each refer-
ence list
and incrementing by 1 the score of the
author whose reference list included the pair with
the more similar cosine value (i.e. having the min-
imum difference):
the chosen author was the one
with the highest score.
Table 2 shows the classifi-
cation results for
θ
= 5%.
Capuana
De
Pirandello
Svevo
Tozzi
Verga
Roberto
Capuana
1884
1269
1321
797
755
1054
De Roberto
729
1041
712
498
451
579
Pirandello
1387
1278
2114
937
747
1056
Svevo
353
371
341
593
372
356
Tozzi
199
219
183
242
281
244
Verga
650
671
656
473
430
851
Table 2:
Classification results,
obtained via the
nearest-cosine method for
θ
= 5%.
4
Interpreting the Results
As summarized in Table 3, a correct classification
of all
RWPs in RWP
test
lists has been obtained
with a
θ
value of 5%.
To help in interpreting the failure of the algo-
rithm in classifying Tozzi’s test
list
for
θ
values
lower than 5% (as shown in Table 3) we calculated
the cardinality of the RWP
test
lists for each author
with the change in
θ
value (Tables 4).
It is possible to observe how the choice of
θ
in-
fluences the correct
classification of Tozzi’s test
list.
Indeed,
the use of a
θ
value below 5% has
the effect of remarkably reducing an already small
4
At the following url we have uploaded an archive con-
taining all the data we have used and processed for our exper-
iment: https://goo.gl/nrTqWh
0.5%
1%
2%
5%
Capuana
Capuana
Capuana
Capuana
Capuana
De Roberto
De Roberto
De Roberto
De Roberto
De Roberto
Pirandello
Pirandello
Pirandello
Pirandello
Pirandello
Svevo
Svevo
Svevo
Svevo
Svevo
Tozzi
Verga
Verga
Tozzi/Verga
Tozzi
Verga
Verga
Verga
Verga
Verga
Table 3:
Results of the classification.
Classifica-
tion errors are highlighted.
0.5%
1%
2%
5%
#RWP
test
Capuana
678
1357
2714
6785
#RWP
test
De Roberto
488
977
1954
4886
#RWP
test
Pirandello
692
1385
2770
6925
#RWP
test
Svevo
425
851
1702
4257
#RWP
test
Tozzi
246
493
986
2466
#RWP
test
Verga
526
1053
2106
5267
Table 4:
Cardinality of RWP
test
for each author
and for each
θ
value.
test list (RWP
text
Tozzi
) as shown in Table 4.
It is
apparent
that
increasing the value of
θ
and con-
sequently the number of significant RW pairs that
are analysed, the system is able to correctly clas-
sify RWP
test
Tozzi
(see the values in Tozzi’s row of
Table 3).
5
Conclusion and Next Steps
In this paper we investigated the possibility that
an analysis of the semantic distribution of words
in a text can be potentially exploited to get cues
about
the style of
an author.
In order
to vali-
date our hypothesis,
we conducted a first experi-
ment on six different Italian authors.
The results
seem to suggest that the way words are distributed
across a text,
can provide a valid stylistic cue to
distinguish an author’s work.
Of course,
it is not
our intent, with this paper, to define new methods
for enhancing state-of-the-art
authorship attribu-
tion algorithms.
Our research will
focus,
in the
next steps, in detecting and providing useful indi-
cations about the style of an author.
This can be
done by highlighting,
for example,
atypical
dis-
tributions of words (e.g.
with contrastive meth-
ods) or by analysing their distributional variability.
Furthermore, it could be interesting to use a differ-
ent distributional measure, than the cosine, to test
our hypothesis.
CLIC_2016_Proceedings.indd 64
02/12/16 15.03
65
References
Shlomo Argamon,
Casey Whitelaw,
Paul Chase,
Sob-
han Raj Hota, Navendu Garg, and Shlomo Levitan.
2007.
Stylistic text
classification using functional
lexical
features.
Journal
of
the American Society
for Information Science and Technology, 58(6):802–
822, April.
Marco Baroni
and Alessandro Lenci.
2010.
Dis-
tributional
memory:
A general
framework
for
corpus-based semantics.
Computational
Linguis-
tics, 36(4):673–721.
Paul
Buitelaar,
Nitish Aggarwal,
and Justin Tonra.
2014.
Using distributional semantics to trace influ-
ence and imitation in romantic orientalist poetry.
In
AHA!-Workshop 2014 on Information Discovery in
Text. ACL.
Olivier De Vel, Alison Anderson, Malcolm Corney, and
George Mohay.
2001.
Mining e-mail content for au-
thor identification forensics.
ACM Sigmod Record,
30(4):55–64.
Felice Dell’Orletta,
Giulia Venturi,
Andrea Cimino,
and Simonetta Montemagni.
2014.
T2kˆ
2:
a
system for automatically extracting and organizing
knowledge from texts.
In LREC, pages 2062–2070.
Michael Gamon.
2004.
Linguistic correlates of style:
authorship classification with deep linguistic analy-
sis features.
In Proceedings of the 20th international
conference on Computational Linguistics, page 611.
Association for Computational Linguistics.
Jack Grieve.
2007.
Quantitative Authorship Attribu-
tion:
An Evaluation of Techniques.
Literary and
Linguistic Computing, 22(3):251–270, May.
Michael
AK Halliday.
1994.
Functional
grammar.
London: Edward Arnold.
Aur
´
elie Herbelot.
2015.
The semantics of poetry:
A
distributional
reading.
Digital
Scholarship in the
Humanities, 30(4):516–531.
Graeme Hirst and Olga Feiguina.
2007.
Bigrams of
Syntactic Labels for Authorship Discrimination of
Short
Texts.
Literary and Linguistic Computing,
22(4):405–417, September.
Moshe Koppel and Jonathan Schler.
2004.
Authorship
verification as a one-class classification problem.
In
Proceedings of the twenty-first international confer-
ence on Machine learning, page 62. ACM.
Germ
´
an Kruszewski and Marco Baroni.
2014.
Dead
parrots make bad pets: Exploring modifier effects in
noun phrases.
Lexical and Computational Seman-
tics (* SEM 2014), page 171.
Alessandro Lenci.
2008.
Distributional semantics in
linguistic and cognitive research.
Italian journal of
linguistics, 20(1):1–31.
Jiexun Li,
Rong Zheng,
and Hsinchun Chen.
2006.
From fingerprint to writeprint.
Communications of
the ACM, 49(4):76–82.
George A Miller and Walter G Charles.
1991.
Contex-
tual correlates of semantic similarity.
Language and
cognitive processes, 6(1):1–28.
Joseph Rudman.
1997.
The state of authorship attri-
bution studies: Some problems and solutions.
Com-
puters and the Humanities, 31(4):351–365.
Efstathios Stamatatos,
Nikos Fakotakis,
and George
Kokkinakis.
2000.
Automatic text categorization in
terms of genre and author.
Computational linguis-
tics, 26(4):471–495.
Efstathios Stamatatos,
Nikos Fakotakis,
and Georgios
Kokkinakis.
2001.
Computer-based authorship at-
tribution without lexical measures.
Computers and
the Humanities, 35(2):193–214.
Efstathios Stamatatos.
2006.
Authorship attribution
based on feature set
subspacing ensembles.
In-
ternational Journal on Artificial Intelligence Tools,
15(05):823–838.
Efstathios Stamatatos.
2009.
A survey of modern au-
thorship attribution methods.
J.
Am.
Soc.
Inf.
Sci.
Technol., 60(3):538–556, March.
Gui-Fa Teng,
Mao-Sheng Lai,
Jian-Bin Ma,
and Ying
Li.
2004.
E-mail authorship mining based on svm
for computer forensic.
In Machine Learning and
Cybernetics,
2004.
Proceedings of
2004 Interna-
tional Conference on,
volume 2,
pages 1204–1207.
IEEE.
¨
Ozlem Uzuner and Boris Katz.
2005.
A comparative
study of language models for book and author recog-
nition.
In Natural
Language Processing–IJCNLP
2005, pages 969–980. Springer.
Hans Van Halteren,
Harald Baayen,
Fiona Tweedie,
Marco Haverkort,
and Anneke Neijt.
2005.
New
machine learning methods
demonstrate the exis-
tence of a human stylome.
Journal of Quantitative
Linguistics, 12(1):65–77.
Ying Zhao and Justin Zobel.
2005.
Effective and scal-
able authorship attribution using function words.
In
Information Retrieval
Technology,
pages 174–189.
Springer.
Rong Zheng,
Jiexun Li,
Hsinchun Chen,
and Zan
Huang.
2006.
A framework for authorship identi-
fication of online messages:
Writing-style features
and classification techniques.
Journal of the Ameri-
can Society for Information Science and Technology,
57(3):378–393, February.
CLIC_2016_Proceedings.indd 65
02/12/16 15.03
66
IR Scientific Data: How to Semantically Represent and Enrich Them
Extended abstract of (Silvello et al., 2016)
Toine Bogers
Aalborg University Copenhagen, Denmark
toine@hum.aau.dk
Georgeta Bordea
Paul Buitelaar
Insight Centre, National University of Ireland, Galway, Ireland
{
georgeta.bordea, paul.buitelaar
}
@insight-centre.org
Nicola Ferro
Gianmaria Silvello
University of Padua, Padua, Italy
{
ferro, silvello
}
@dei.unipd.it
Abstract
English.
Experimental evaluation carried
out in international large-scale campaigns
is a fundamental pillar of the scientific and
technological advancement of Information
Retrieval
(IR) systems.
Such evaluation
activities produce a large quantity of sci-
entific and experimental
data,
which are
the foundation for all the subsequent sci-
entific production and development of new
systems.
We discuss how to annotate and
interlink this data, by proposing a method
for exposing experimental data as Linked
Open Data (LOD) on the Web and as a
basis for enriching and automatically con-
necting this data with expertise topics and
expert
profiles.
In this context,
a topic-
centric approach for expert search is pro-
posed, addressing the extraction of exper-
tise topics,
their semantic grounding with
the LOD cloud, and their connection to IR
experimental data.
Italiano.
La
valutazione
sperimen-
tale condotta mediante campagne inter-
nazionali
su
larga
scala,
`
e
un
pilas-
tro fondante dello sviluppo scientifico e
dell’avanzamento tecnologico dei
sistemi
di reperimento dell’informazione.
Queste
attivit
`
a
di
valutazione
producono
una
grande quantit
`
a di
dati
sperimentali
che
costituiscono la base per la conseguente
produzione
scientifica e
lo sviluppo di
nuovi
sistemi.
In questo lavoro,
si
dis-
cute
come
annotare
e
collegare
questi
dati,
proponendo un metodo per esporre
i
dati
sperimentali
come LOD nel
Web
e per usare tali
dati
come base per ar-
ricchirli.
In questo contesto,
viene pro-
posto un approccio centrato sui topic per
la ricerca di esperti,
che affronta il prob-
lema dell’estrazione dei topic e il collega-
mento di questi con la “LOD cloud” e con
i dati sperimentali.
1
Introduction
The importance of research data is widely recog-
nized across all scientific fields as this data consti-
tutes a fundamental building block of science. Re-
cently,
a great deal of attention was dedicated to
the nature of research data (Borgman,
2015) and
how to describe,
share,
cite,
and re-use them in
order to enable reproducibility in science and to
ease the creation of advanced services based on
them (Ferro et al., 2016; Silvello and Ferro, 2016).
Nevertheless,
in the field of
Information Re-
trieval (IR), where experimental evaluation based
on shared data collections and experiments has
always been central
to the advancement
of
the
field (Harman,
2011),
the
Linked Open Data
(LOD)
paradigm has not
been adopted yet
and
no models or common ontologies for data sharing
have been proposed.
So despite the importance of
data to IR, the field does not share any clear ways
of exposing, enriching, and re-using experimental
data as LOD with the research community.
Therefore, the main contributions of this paper
are to:
•
define an Resource Description Framework
(RDF) model
of the scientific IR data with
the aim of enhancing their discoverability and
easing their
connections with the scientific
production related to and based on them;
CLIC_2016_Proceedings.indd 66
02/12/16 15.03
67
•
provide a methodology for automatically en-
riching the data by exploiting relevant exter-
nal entities from the LOD cloud.
2
Use Case: Discover, Understand and
Re-use IR Experimental Data
In this section, we discuss an example of the out-
comes of the semantic modeling and automatic en-
richment processes applied to the use case of dis-
covering,
understanding and re-using the experi-
mental data. Figure 1 shows an RDF graph, which
provides a visual representation of how the experi-
mental data are enriched. In particular, we can see
the relationship between a contribution and an au-
thor enriched by expertise topics,
expert
profiles
and connections to the LOD cloud,
as supported
by the Distributed Information Retrieval
Evalua-
tion Campaign Tool (DIRECT) system which pro-
vides the conceptual
model
for representing and
enriching the data (Agosti and Ferro, 2009; Agosti
et al., 2012).
In this
instance,
the author
(Jussi
Karlgren)
and the contribution (KarlgrenEtAl-CLEF2012)
are data derived from the evaluation workflow,
whereas all
the other
information are automati-
cally determined by the enrichment process.
The
adopted methodology for expertise topics extrac-
tion determined two main topics, “reputation man-
agement” and “information retrieval”,
which are
related to the KarlgrenEtAl-CLEF2012 contribu-
tion.
We can see that KarlgrenEtAl-CLEF2012 is
featured by “reputation management” with a score
of
0
.
53
and by “information retrieval” with
0
.
42
,
meaning that both these topics are subjects of the
contribution; the scores (normalized in the interval
[0
,
1]
) give a measure of how much this contribu-
tion is about a specific topic and we can see that
in this case it is concerned a bit more with reputa-
tion management than with information retrieval.
Furthermore,
the backward-score gives us addi-
tional information by measuring how much a con-
tribution is authoritative with respect to a scientific
topic.
In Figure 1, we can see that KarlgrenEtAl-
CLEF2012 is authoritative for reputation manage-
ment (backward-score of
0
.
87
), whereas it is not a
very important reference for information retrieval
(backward-score of
0
.
23
).
Summing up,
we can
say that if we consider the relation between a con-
tribution and an expertise topic,
the score indi-
cates the pertinence of the expertise topic within
the contribution; whereas the backward score indi-
cates the pertinence of the contribution within the
expertise topic.
The higher the backward score,
the more pertinent is the contribution for the given
topic.
This information is confirmed by the expert pro-
file data; indeed,
looking at the upper-left part of
Figure 1, the author Jussi
Karlgren is considered
“an expert in” reputation management (backward-
score of
0
.
84
),
even if it is not his main field of
expertise (score of
0
.
46
).
All
of
this
automatically extracted informa-
tion enriches the experimental data enabling for a
higher degree of re-usability and understandabil-
ity of the data themselves.
In this use case,
we
can see that the expertise topics are connected via
an owl:sameAs property to external
resources
belonging to the DBPedia
1
linked open dataset.
These connections are automatically defined via
the semantic grounding methodology described
below and enable the experimental data to be eas-
ily discovered on the Web.
In the same way,
authors
and contributions
are connected to the
DBLP
2
linked open dataset.
In Figure 1 we can see how the contribution
(KarlgrenEtAl-CLEF2012)
is related to the ex-
periment
(profiling
kthgavagai 1) on which it
is
based.
This
experiment
was
submitted to the
RepLab 2012 of the evaluation campaign CLEF
2012. It is worthwhile to highlight that each evalu-
ation campaign in DIRECT is defined by the name
of the campaign (CLEF) and the year it took place
(e.g., 2012 in this instance); each evaluation cam-
paign is composed of one or more tasks identified
by a name (e.g.,
RepLab 2012) and the experi-
ments are treated as submissions to the tasks. Each
experiment
is described by a contribution which
reports the main information about
the research
group which conducted the experiment,
the sys-
tem they adopted, developed and any other useful
detail about the experiment.
We can see that
most
of
the reported infor-
mation are directly related to the contribution
and they allow us to explicitly connect
the re-
search data with the scientific publications based
on them.
Furthermore,
the experiment
is evalu-
ated from the “effectiveness” point of view by us-
ing the “accuracy” measurement
which has
0
.
77
score.
Retaining and exposing this information as
LOD on the Web allow us to explicitly connect the
1
http://www.dbpedia.org/
2
http://dblp.l3s.de/
CLIC_2016_Proceedings.indd 67
02/12/16 15.03
68
Jussi
Karlgren
Link
ims:relation
ims:has-source
ims:has-target
is-expert-in
Reputation
Management
0.46
0.84
ims:score
ims:backward-score
CLEF2012wn-
RepLab-
KarlgrenEtAl
2012
Link
ims:has-source
ims:has-target
ims:relation
feature
0.53
0.87
ims:score
ims:backward-score
Proﬁling Reputation of Corporate 
Entities in Semantic Space
ims:title
dbpedia.or
g/resource/
Reputation_
manageme
nt
owl:sameAs
dbpedia.or
g/resource/
Information
_
retrieval
Link
ims:has-source
ims:has-target
ims:relation
0.42
0.23
ims:score
ims:backward-score
Information
Retrieval
owl:sameAs
swrc:has-author
dblp.l3s.de/d2r/
resource/
publications/
conf/clef/
KarlgrenSOEH1
2
owl:sameAs
dblp.l3s.de/
d2r/resource/
authors/
Jussi_Karlgre
n
owl:sameAs
RepLab
2012
CLEF
2012
proﬁling
_kthgavagai
_1
Measure
0.77
ims:score
Effectiveness
Accuracy
ims:refersTo
ims:submittedTo
ims:isPartOf
ims:evaluates
ims:isEvaluatedBy
ims:assignedTo
ims:measuredBy
Figure 1:
An example of RDF graph showing how expertise topics and expert
profiles are used for
enriching IR experimental data.
results of the evaluation activities to the claims re-
ported by the contributions.
The details of the full RDF model are reported
in (Silvello et al., 2016).
2.1
Accessing the Experimental Data
The described RDF model
has been realized by
the DIRECT system which allows for accessing
the experimental evaluation data enriched by the
expert profiles created by means of the techniques
that
will
be described in the next
sections.
This
system is called LOD-DIRECT and it
is avail-
able at the URL: http://lod-direct.dei.
unipd.it/.
The data currently available include the contri-
butions produced by the Conference and Labs of
the Evaluation Forum (CLEF) evaluation activi-
ties,
the authors of the contributions,
information
about CLEF tracks and tasks,
provenance events
and the above described measures.
Furthermore,
this data has been enriched with expert profiles and
expertise topics which are available as linked data
as well.
At
the time of writing,
LOD-DIRECT allows
access to
2
,
229
contributions,
2
,
334
author pro-
files and
2
,
120
expertise topics.
Overall,
1
,
659
experts have been individuated and on average
there are
8
experts per expertise topics (an expert
can have more than one expertise of course).
The URIs of the resources are constructed fol-
lowing the pattern:
base-path/{resource-name}/
{id};{ns}
where,
•
base-path
is
http://lod-direct.dei.unipd.it;
•
resource-name is the name of
the re-
source to be accessed as defined in the RDF
model presented above;
•
id is the identifier of the resource of interest;
•
ns is the namespace of the resource of inter-
est, this applies only for the namespace iden-
tifiable resources.
As
an
example,
the
URI
corresponding
to
the
contribution
resource
shown
in
Fig-
ure 1 with identifier
CLEF2012wn-RepLab-
KarlgrenEt2012b is:
http://lod-direct.dei.
unipd.it/contribution/
CLEF2012wn-RepLab-KarlgrenEt2012b
CLIC_2016_Proceedings.indd 68
02/12/16 15.03
69
Figure 2:
Data flow of the semantic enrichment
approach
3
Semantic Enrichment
In this section we describe SOME methods for se-
mantically enriching experimental
IR data mod-
elled as described above,
by analysing unstruc-
tured data available in scientific publications. Fig-
ure 2 presents an overview of the semantic en-
richment of documents and authors based on term
and topical hierarchy extraction. First, we propose
a method to automatically extract
expertise top-
ics from a domain-specific collection of publica-
tions using an approach for term extraction. Then,
we present
a preliminary approach for enriching
expertise topics by grounding them in the LOD
cloud.
Topic-centric approaches for expert search em-
phasize the extraction of keyphrases that can suc-
cinctly describe expertise areas, also called exper-
tise topics, using term extraction techniques (Bor-
dea et
al.,
2012).
Expertise topics are extracted
from a domain-specific corpus using the follow-
ing approach.
First, candidate expertise topics are
discovered from text using a syntactic description
for terms (i.e.,
nouns or noun phrases) and con-
textual patterns that ensure that the candidates are
coherent within the domain.
A domain model is
constructed using the method proposed in (Bordea
et
al.,
2013) and then noun phrases that
include
words from the domain model
or that
appear in
their immediate context are selected as candidates.
These topics describe core concepts of the do-
main such as search engine,
IR system,
and re-
trieval
task, as well as prominent subfields of the
domain including image retrieval, machine trans-
lation, and question answering.
Only the best 20 expertise topics are stored for
each document, ranking expertise topics based on
Table 1: Precision and recall for DBpedia URI ex-
traction
Approach
Precision
Recall
F-score
String Matching
0.96
0.93
0.94
Lemmatisation
0.99
0.90
0.94
their overall
score.
In this way,
each document
is enriched with keyphrases, taking into consider-
ation the quality of a term for the whole corpus
in combination with its relevance for a particular
document.
Expertise topics can be used to provide links be-
tween IR experimental data and other data sources.
These
links
play an important
role
in cross-
ontology question answering,
large-scale infer-
ence and data integration (Ngonga Ngomo, 2012).
Additional
background knowledge,
as found on
the LOD cloud,
can inform expert
search at
dif-
ferent stages.
A first
step in the direction of exploiting this
potential is to provide an entry point in the LOD
cloud through DBpedia
3
.
Our goal is to associate
as many terms as possible with a concept from the
LOD cloud through DBpedia URIs—as shown in
the use-case above.
Where available, concept de-
scriptions are collected as well and used in our sys-
tem.
Two approaches for grounding expertise topics
on DBpedia have been evaluated.
The first
ap-
proach matches a candidate DBpedia URI with an
expertise topic, using the string as it appears in the
corpus.
The second approach makes use of the
lemmatised form of the expertise topic.
In order
to evaluate our URI discovery approach, we build
a small gold standard dataset by manually anno-
tating 186 expertise topics with DBpedia URIs.
First
of all,
we note that
about
half of the anal-
ysed expertise topics have a corresponding con-
cept in DBpedia.
One of the main reasons for the
low coverage is that DBpedia is a general knowl-
edge datasource that has a limited coverage of spe-
cialised technical domains.
Although both approaches achieve similar re-
sults in terms of F-score, the approach that makes
use of lemmatisation (A2) achieves better preci-
sion, as can be seen in Table 1. Surprisingly, using
lemmatization achieves a lower recall but higher
precision but this might be due to the small size of
the dataset.
Expert finding is the task of identifying the most
3
DBpedia: http://dbpedia.org/
CLIC_2016_Proceedings.indd 69
02/12/16 15.03
70
knowledgeable person for a given expertise topic.
In this task,
several competent people have to be
ranked based on their relative expertise on a given
expertise topic.
We compare several topic-centric
methods for
expert
finding with two language-
modelling baselines.
The results for the expert finding task are pre-
sented in Table 2.
The expert
finding methods
evaluated in this section include Experience (E),
Relevance and Experience (RE)
and Relevance,
Experience and Area Coverage (REC).
Experience (E) is based on the idea that docu-
ments written by a person can be used as an indi-
rect evidence of expertise, assuming that an expert
often mentions his areas of interest. Relevance and
Experience (RE) exploits the idea that expertise is
closely related to the notion of experience.
The
assumption is that the more a person works on a
topic,
the more knowledgeable they are.
We es-
timate the experience of a researcher on a given
topic by counting the number of publications that
have the topic assigned as a top ranked keyphrase.
Relevance and expertise measure different aspects
of expertise and can be combined to take advan-
tage of both features. In the case that the subtopics
of an expertise topic are known,
we can evaluate
the expertise of a person based on their knowledge
of the more specialised fields.
A previous study
showed that experts have increased knowledge at
more specific category levels than novices (Tanaka
and Taylor, 1991).
We introduce a novel measure
for
expertise called Area
Coverage (REC)
that
measures whether an expert has in depth knowl-
edge of an expertise topic, using an automatically
constructed topical hierarchy.
The Area Coverage measure makes use of a top-
ical
hierarchy.
Therefore we automatically con-
struct a topical hierarchy for IR using the method
proposed in (Hooper
et
al.,
2012).
Figure 3
shows a small extract from this hierarchy that cor-
rectly identifies “information retrieval” as the root
of the taxonomy as well
as several
subfields in-
cluding “digital
libraries”,
“interactive informa-
tion retrieval”,
and “cross language information
retrieval”.
The details on the algorithms and weighting
schemes for topic extraction, expert profiling, and
expert
finding are reported in (Silvello et
al.,
2016).
Figure 3:
Sample hierarchical relations for the IR
domain
4
Conclusion
In this paper we discussed the data modelling and
the semantic enrichment of IR experimental data,
as produced by large-scale evaluation campaigns.
In particular, the main results of the paper are:
•
an accurate RDF data model
for
describ-
ing IR experimental
data in detail,
avail-
able
at
http://ims.dei.unipd.it/
data/rdf/direct.3.10.ttl;
•
a dataset about CLEF contributions, extracted
expertise topics and related expert profiles;
•
the online accessible LOD DIRECT system,
available at http://lod-direct.dei.
unipd.it/, to access the above data in dif-
ferent serialization formats, RDF+XML, Tur-
tle, N3, XML and JSON.
Future work will
concern the application of
these semantic modeling and automatic enrich-
ment
techniques to other areas of the evaluation
workflow.
For example, expert profiling and topic
extraction could be used to automatically improve
and enhance the descriptions of the single experi-
ments submitted to an evaluation campaign, which
are typically not very rich and often cryptic—for
example “second iteration with tuned parameters”
as description—and to automatically link exper-
iments to external
resources,
e.g.,
describing the
used components,
such as stemmers or stop lists,
and systems.
Finally,
the RDF model
defined
within DIRECT opens up the possibility of inte-
grating established Digital Library (DL) method-
ologies for data access and management which in-
CLIC_2016_Proceedings.indd 70
02/12/16 15.03
71
Dataset
Measure
LM1
LM2
E
RE
REC
MAP
0.0071
0.0056
0.0335
0.0335
0.0340
CL
MRR
0.0631
0.0562
0.2734
0.2738
0.2754
P@5
0.0202
0.0173
0.1340
0.1339
0.1347
MAP
0.0070
0.0067
0.0327
0.0305
0.0314
SW
MRR
0.0528
0.0522
0.2262
0.2115
0.2095
P@5
0.0182
0.0188
0.1065
0.0967
0.0994
MAP
0.0599
0.0402
0.1592
0.1669
0.1657
IR
MRR
0.1454
0.1231
0.4056
0.4141
0.4120
P@5
0.0614
0.0485
0.1771
0.1771
0.1783
MAP
0.2009
0.1994
0.1155
0.1151
0.1158
UvT
MRR
0.3551
0.3571
0.2298
0.2266
0.2281
P@5
0.1357
0.1347
0.0850
0.0846
0.0841
Table 2:
Expert finding results for the language modelling approach (LM), Experience (E), Relevance
and Experience (RE), and Relevance, Experience and Area Coverage (REC)
creasingly exploit the LOD paradigm (Hennicke et
al., 2011; Di Buccio et al., 2013).
This would en-
able broadening the scope and the connections be-
tween IR evaluation and other related fields,
pro-
viding new paths for semantic enrichment of the
experimental data.
References
M. Agosti and N. Ferro.
2009.
Towards an Evaluation
Infrastructure for DL Performance Evaluation.
In
G.
Tsakonas and C.
Papatheodorou,
editors,
Eval-
uation of
Digital
Libraries:
An insight
into useful
applications and methods,
pages 93–120.
Chandos
Publishing, Oxford, UK.
M. Agosti,
E. Di Buccio,
N. Ferro,
I. Masiero,
S. Pe-
ruzzo, and G. Silvello.
2012.
DIRECTions: Design
and Specification of an IR Evaluation Infrastructure.
In T. Catarci, P. Forner, D. Hiemstra, A. Pe
˜
nas, and
G. Santucci, editors, Information Access Evaluation.
Multilinguality, Multimodality, and Visual Analytics.
Proceedings of
the Third International
Conference
of the CLEF Initiative (CLEF 2012),
pages 88–99.
Lecture Notes in Computer Science (LNCS) 7488,
Springer, Heidelberg, Germany.
Georgeta Bordea, Sabrina Kirrane, Paul Buitelaar, and
Bianca O Pereira.
2012.
Expertise Mining for
Enterprise Content
Management.
In N.
Calzolari,
K.
Choukri,
T.
Declerck,
M.
U.
Dogan,
B.
Mae-
gaard, J. Mariani, J. Odijk, and S. Piperidis, editors,
Proc. of the Eighth Int. Conference on Language Re-
sources and Evaluation (LREC-2012), pages 3495–
3498.
European Language Resources Association
(ELRA).
G.
Bordea,
T.
Polajnar,
and P.
Buitelaar.
2013.
Domain-Independent Term Extraction Through Do-
main Modelling.
In 10th International Conference
on Terminology and Artificial Intelligence.
C. L. Borgman.
2015.
Big Data, Little Data, No Data.
MIT Press.
E. Di Buccio, G. M. Di Nunzio, and G. Silvello.
2013.
A Curated and Evolving Linguistic Linked Dataset.
Semantic Web, 4(3):265–270.
N.
Ferro,
N.
Fuhr,
K.
J
¨
arvelin,
N.
Kando,
M.
Lip-
pold, and J. Zobel.
2016.
Increasing Reproducibil-
ity in IR:
Findings from the Dagstuhl
Seminar on
“Reproducibility of Data-Oriented Experiments in
e-Science”.
SIGIR Forum, 50(1):68–82, June.
D.
K.
Harman.
2011.
Information Retrieval Evalua-
tion.
Morgan & Claypool Publishers, USA.
S.
Hennicke,
M.
Olensky,
V.
de Boer,
A.
Isaac,
and
J.
Wielemaker.
2011.
Conversion of
EAD into
EDM Linked Data.
In L.
Prediu,
S.
Hennicke,
A.
N
¨
urnberger,
A.
Mitschick,
and S.
Ross,
edi-
tors, Proc. 1st International Workshop on Semantic
Digital Archives (SDA 2011) http://ceur-ws.
org/Vol-801/, pages 82–88.
Clare J. Hooper, Nicolas Marie, and Evangelos Kalam-
pokis.
2012.
Dissecting the butterfly:
represen-
tation of disciplines publishing at
the web science
conference series.
In Noshir S.
Contractor,
Brian
Uzzi,
Michael W.
Macy,
and Wolfgang Nejdl,
edi-
tors, WebSci, pages 137–140. ACM.
Axel-Cyrille Ngonga Ngomo.
2012.
On link discovery
using a hybrid approach.
Journal on Data Seman-
tics, 1(4):203–217.
G. Silvello and N. Ferro.
2016.
“Data Citation is Com-
ing”. Introduction to the Special Issue on Data Cita-
tion.
Bulletin of IEEE Technical Committee on Dig-
ital Libraries (IEEE-TCDL), 12(1):1–5, May.
G.
Silvello,
G.
Bordea,
N.
Ferro,
P.
Buitelaar,
and
T.
Bogers.
2016.
Semantic Representation and
Enrichment
of Information Retrieval
Experimental
Data.
International
Journal
on Digital
Libraries
(IJDL).
James W.
Tanaka and Marjorie Taylor.
1991.
Object
categories and expertise: Is the basic level in the eye
of the beholder? Cognitive Psychology, 23(3):457–
482, July.
CLIC_2016_Proceedings.indd 71
02/12/16 15.03
72
Reassessing inflectional regularity in Modern Greek conjugation 
Stavros Bompolas 
University of Patras, Greece 
stavros.bompolas@gmail.com
Marcello Ferro 
ILC-CNR Pisa, Italy 
marcello.ferro@ilc.cnr.it
Claudia Marzi 
ILC-CNR Pisa, Italy 
claudia.marzi@ilc.cnr.it 
Franco Alberto Cardillo 
ILC-CNR Pisa, Italy 
francoalberto.cardilllo@ilc.cnr.it
Vito Pirrelli 
ILC-CNR Pisa, Italy 
vito.pirrelli@ilc.cnr.it
Abstract 
Paradigm-based approaches to word pro-
cessing/learning assume that word forms 
are not acquired in isolation, but through 
associative relations linking members of 
the same word family (e.g. a paradigm, 
or a set of forms filling the same para-
digm 
cell). 
Principles 
of 
correlative 
learning offer a set of dynamic equations 
that are key to modelling this complex 
dynamic at a considerable level of detail. 
We use these dynamic equations to simu-
late acquisition of Modern Greek conju-
gation, and we compare the results with 
evidence from German and Italian. Simu-
lations show that different Greek verb 
classes are processed and acquired differ-
entially, depending on their degrees of 
formal 
transparency 
and 
predictability. 
We relate these results to psycholinguis-
tic evidence on Modern Greek word pro-
cessing, 
and 
interpret 
our 
findings 
as 
supporting a view of the mental lexicon 
as an emergent integrative system. 
Secondo l’approccio paradigmatico allo 
studio 
dell’elaborazione 
e 
dell’appren-
dimento lessicali, le parole di una lingua 
non sono acquisite in isolamento, ma at-
traverso legami associativi tra membri 
della stessa famiglia morfologica, la cui 
dinamica 
è 
modellata 
dalle 
equazioni 
dell’apprendimento 
correlativo. 
Il 
pre-
sente contributo offre una serie di espe-
rimenti nei quali l’apprendimento del si-
stema verbale del greco moderno è simu-
lato 
come 
un 
processo 
di 
auto-
organizzazione dinamica di parole me-
morizzate in modo concorrente. I risultati 
mostrano chiari effetti di interazione di-
namica tra trasparenza e regolarità mor-
fologica 
nell’acquisizione 
di 
classi 
di 
forme del verbo greco. 
1
Introduction 
Issues of morphological (ir)regularity have tradi-
tionally been investigated through the prism of 
morphological competence, with particular em-
phasis 
on 
aspects 
of the 
internal 
structure 
of 
complex words (Bloomfield, 1933; Bloch, 1947; 
Chomsky and Halle, 1968; Lieber, 1980; Selkirk, 
1984; among others). Within this framework, one 
of the most influential theoretical positions is 
that morphologically, phonologically, or/and se-
mantically 
transparent 
words 
are 
always 
pro-
cessed on-line through their constituent elements, 
whereas irregular, idiosyncratic (non-transparent) 
forms are stored (and retrieved) as wholes in the 
lexicon 
(Pinker 
and 
Prince, 
1994). 
Likewise, 
Ullman and colleagues (1997) assume that the 
past tense formation of regular verbs in English 
requires on-line application of an affixation rule 
(e.g. 
walk
> 
walk
+
ed
), while irregular past tense 
forms, involving stem allomorphy (e.g. 
drink 
> 
drank
), are retrieved from the lexicon. 
Modern Greek introduces an interesting varia-
tion in this picture. First, stem allomorphy and 
suffixation are not necessarily mutually exclu-
sive processes, but coexist in the same inflected 
forms (e.g. 
lin-o
‘I untie’ > 
e-li-s-a 
‘I untied’, 
aɣap(a)-o
‘I love’ > 
aɣapi-s-a 
‘I loved’). Sec-
ondly, affixation rules may select unpredictable 
stem allomorphs: 
aɣap(a)-o
‘I love’ > 
aɣapi-s-a 
‘I loved’, 
for(a)-o
‘I wear’ > 
fore-s-a 
‘I wore’, 
xal(a)-o
‘I demolish’ > 
xala-s-a
‘I demolished’. 
These 
cases 
suggest 
that 
inflectional 
(ir)regularity is not an all-or-nothing notion in 
Greek. 
Different 
inflectional 
processes 
may 
compound in the same words to provide a chal-
lenging word processing scenario (Tsapkini et 
al., 2004). From this perspective, Modern Greek 
offers the opportunity to test traditional hypothe-
ses of grammar and lexicon interaction in word 
processing and learning, to explore the potential 
of single, distributed mechanisms in addressing 
word processing challenges (Alegre and Gordon, 
1999; Baayen, 2007). 
CLIC_2016_Proceedings.indd 72
02/12/16 15.03
73
1.1
The evidence 
Modern Greek conjugation is stem-based, each 
fully 
inflected 
verb 
form 
requiring 
obligatory 
suffixation of person, number and tense markers 
that attach to either a bare or a complex stem in 
both 
regular 
(
aɣap-o
‘I 
love’ 
~ 
aɣapis-a 
‘I loved’) and irregular verbs (
pern-o
‘I take’ ~ 
pir-a
‘I took’). Unlike English speakers, Greek 
speakers must always resort to an inflectional 
process to understand or produce a fully inflected 
form, no matter how regular the form is (Terzi et 
al., 2005: 301). 
Classifying a Greek verb as either regular or 
irregular thus requires observation of the stem 
formation processes on whose basis agreement 
and tense suffixes are selected. Accordingly, it is 
assumed that the presence or absence of the as-
pectual marker is a criterion for assessing the 
degree of regularity of a Greek verb. In particu-
lar, so-called “sigmatic” past-tense forms (e.g. 
aɣap-o
~ 
aɣapis-a
) are traditionally considered 
to be regular, in that they involve a segmentable 
marker (-
s
-) combined with phonologically pre-
dictable 
or 
morphologically 
systematic 
stem-
allomorphs. 
Asigmatic 
past-tense 
forms 
(e.g. 
pern-o
~ 
pir-a
), in contrast, exhibit typical prop-
erties of irregular inflection, since they involve 
unsystematic stem 
allomorphs 
(in some 
cases 
suppletive stems), and no segmentable affixes 
marking perfective aspect. This distinction has 
also been supported by psycholinguistic evidence 
(Stamouli, 2000; Tsapkini et al., 2001, 2002a,b,c, 
2004; 
Mastropavlou, 
2006; 
Varlokosta 
et 
al., 
2008; Stavrakaki and Clahsen, 2009a,b; Statho-
poulou 
and 
Clahsen, 
2010; 
Stavrakaki 
et 
al., 
2012; Konstantinopoulou et 
al., 
2013; 
among 
others), suggesting that sigmatic past-tense forms 
are 
typically 
produced 
on-line 
by 
rules, 
and 
asigmatic forms are stored and accessed from the 
mental lexicon. 
However, careful analysis of the Greek verb 
system appears to question such a sharp pro-
cessing-storage divide. In particular, Greek data 
provide the case of a mixed inflectional system 
where 
both 
stored 
allomorphy 
and 
rule-based 
affixation are simultaneously present in the for-
mation of past tense forms. Ralli (2005) provided 
a classification of verb paradigms which is based 
on two criteria; firstly, the presence vs. absence 
of the sigmatic affix and, secondly, the presence 
vs. absence of (systematic) stem allomorphy. As 
a result, we can define the following three clas-
ses (see also Tsapkini et al., 2001, 2002a,b,c, 
2004): 
(i) 
an affix-based class, requiring 
the presence 
of the aspectual marker 
-s-
, and including 
verbs with a predictable phonological stem-
allomorph 
(e.g., 
lin-o
‘I 
untie’ ~ 
e-li-s-a 
‘I 
untied’, 
ɣraf-o
‘I 
write’ 
~ 
e-ɣrap-s-a 
‘I wrote’); 
(ii) 
a mixed class where active perfective past 
tense forms are produced by affixation of 
the 
aspectual 
marker 
-s-
to 
a 
systematic 
morphological stem-allomorph (e.g., 
mil-o
‘I speak’ ~ 
mili-s-a 
‘I spoke’); 
(iii) an idiosyncratic verb class whose forms are 
based 
on 
non-systematic stem-allomorphy 
(requiring 
stem-internal 
alternation 
or 
suppletion) or no stem-allomorphy at all, 
and no (sigmatic) 
aspectual marker (e.g., 
pern-o
‘I take’ ~ 
pir-a 
‘I took’, 
tro-o
‘I eat’ 
– 
e-fag-a 
‘I ate’, 
krin-o
‘I judge’ – 
e-krin-a 
‘I judged’). 
It should be noted that, in regular Greek verbs, 
transparency/systematicity and predictability are 
not 
mutually 
implied. 
The 
morphologically-
conditioned 
allomorphy 
of 
class-(ii) 
verbs 
re-
quires a systematic pattern 
of perfective stem 
formation, namely X
(a)
~ X + V (e.g. 
aɣap(a)-
> 
aɣapi-
), where ‘X’ is a variable standing for the 
bare stem, ‘V’ stands for a vowel, and the sub-
scripted ‘(a)’ indicates an optional ‘a’, forming a 
Modern Greek free variant of the imperfective 
stem 
(e.g. 
aɣapo
~ 
aɣapao
, 
see 
Ralli, 
2005, 
2007). The variable 
V
in the perfective stem can 
be instantiated as an 
i
, 
e
or 
a
, and cannot be pre-
dicted from the bare stem. On the other hand, the 
phonologically-conditioned allomorphs of class-
(i) verbs (e.g. 
lin- > e-li-s-
) 
are the outcome of 
exception-less phonological rules, which none-
theless obfuscate a full formal correspondence 
(transparency) 
between 
the 
imperfective 
stem 
and the perfective stem. 
Evidence from language acquisition and ex-
perimental psycholinguistics shows that percep-
tion of formal transparency between imperfective 
and perfective Greek stems plays a prominent 
role in human word processing strategies (Tsap-
kini et al., 2002c: 116, 2004: 616; Stavrakaki and 
Clahsen, 2009a: 117; Stathopoulou and Clahsen, 
2010: 872). More specifically, lack of full formal 
nesting 
between 
imperfective 
and 
perfective 
stems 
(compare 
aɣap-o
‘I 
love’ 
~ 
aɣapi-s-a 
‘I 
loved’ 
vs.
ðulev-o 
‘I 
work’ 
~ 
ðulep-s-a 
‘I worked’) appears to have an extra processing 
cost (Tsapkini et al., 2002c: 116). 
To sum up, analysis of Greek data offers evi-
dence of graded levels of morphological regulari-
CLIC_2016_Proceedings.indd 73
02/12/16 15.03
74
ty, 
based 
on 
the 
interaction 
between 
formal 
transparency 
(degrees 
of 
stem 
similarity) 
and 
(un)predictability of stem allomorphs. The evi-
dence appears to question a dichotomous view of 
storage vs. rule-based processing mechanisms. In 
fact, 
no 
sharp 
distinction 
between 
affix 
pro-
cessing and allomorph retrieval can account for 
the interaction of formal transparency and pre-
dictability in Greek word processing. On the one 
hand, rule-based mechanisms are called for to 
account for transparency effects of stem allo-
morphy on word processing. On the other hand, 
storage is required if the 
same
allomorphs cannot 
be predicted. In the remainder of this paper, we 
test the hypothesis that this evidence is compati-
ble 
with 
a 
parallel 
processing 
architecture 
(a 
Temporal 
Self-organising 
Map) 
where 
pro-
cessing and storage are in fact mutually implied. 
2
TSOMs 
Temporal Self-organising Maps (TSOMs, Ferro 
et al., 2011; Marzi and Pirrelli, 2015; Pirrelli et 
al., 2015) are unsupervised artificial neural net-
works that learn to dynamically memorise input 
strings as chains of maximally-responding pro-
cessing nodes (
Best Matching Units
or 
BMU
s), 
whose level of sensitivity to input symbols in 
specific contexts is a continuous function of the 
distributional regularities of the input symbols 
during 
training. 
In 
a 
TSOM, 
each 
processing 
node has two layers of synaptic connectivity: an 
input layer, connecting the node to the current 
input stimulus (e.g. the letter of a written word), 
and a (re-entrant) temporal layer, connecting the 
node to all other nodes. 
Given the 
BMU
at time 
t
, the temporal layer 
encodes the expectation of the current 
BMU
for 
the node to be activated at time 
t+1
. The strength 
of the connection between consecutively activat-
ed 
BMU
s is trained through the following princi-
ples 
of 
correlative 
learning 
(compatible 
with 
Rescorla-Wagner (1972) equations): 
Given the input bigram 
ab
, the connection 
strength between 
BMU
of 
a
at time 
t
and 
BMU
of 
b
at time 
t+1
will 

increase if 
a
often precedes 
b
in training 
(entrenchment) 

decrease if 
b
is often preceded by a sym-
bol other than 
a
(competition). 
The interaction between entrenchment and com-
petition in a TSOM accounts for important dy-
namic 
effects 
of 
self-organisation 
of 
stored 
words (Marzi et al., 2014, 2016). In particular, 
high-frequency words tend to recruit specialised 
(and 
stronger) 
chains 
of 
BMU
s, 
while 
low-
frequency 
words 
are 
responded 
to 
by 
more 
“blended” (and weaker) 
BMU
chains. In what 
follows, we report how well a TSOM can ac-
commodate the complexity of the Greek verb 
system, by controlling factors such as word fre-
quency distribution, degrees of inflectional regu-
larity and word length. 
2.1
The experiment 
To allow pairwise comparison with existing ex-
perimental 
evidence 
on 
German 
and 
Italian 
(Marzi et al., 2016), the Greek training dataset 
was designed to contain 50 top-ranked paradigms 
by cumulative token frequency, for a total of 750 
verb forms, whose frequency distributions were 
sampled 
from 
the 
FREQcount 
section 
of 
the 
Greek 
SUBTLEX-GR 
corpus 
(BCBL, 
2016). 
From each paradigm, 15 inflected forms were 
extracted: the full set of present indicative (6) 
and simple past tense (6) forms, and the singular 
forms of simple future (3). As we were mainly 
interested in effects of global paradigm-based 
organisation of active voice indicative forms, we 
excluded paradigms with systematic gaps, imper-
sonal verbs, and deponent verbs. We included 
high-frequency paradigms with suppletive forms 
or/and
non-systematic allomorphy (Ralli, 2007, 
2014) as attested in the training set. 
The dataset was administered to a 42x42 node 
map for 100 learning epochs. Word frequencies 
in the training data were a function of the real 
word frequency distribution in the reference cor-
pus, fitted in the 1-1000 range. To control for 
random variability, we repeated the experiment 5 
times. 
For each repetition, we then assessed how well 
the map could acquire the 750 input forms, using 
the task of Word Recall as a probe. Word recall 
is defined as the process of retrieving a word 
form from its chain of 
BMU
s. Successful recall is 
possible if inter-node connections on the tem-
poral layer are finely tuned to the distribution of 
symbols in the training data. The more accurate 
the re-entrant temporal coding is, the easier for 
the map to retrieve the symbols of a word in their 
appropriate order. We make the further reasona-
ble assumption that a word is acquired by a 
TSOM when the map is in a position to recall the 
word accurately and consistently from its 
BMU
chain. 
Average 
recall 
accuracy 
at 
epoch 
100 
turned out to be considerably high: 99.6 % (std = 
0.1%). 
CLIC_2016_Proceedings.indd 74
02/12/16 15.03
75
3
Data analysis 
Results were analysed using Linear Mixed Ef-
fects (LME) models with experiment repetitions 
and training items as random variables. 
Figure 1 shows the marginal plot of the inter-
action between word length and regular vs. ir-
regular 
verb 
classes 
for 
German, 
Italian 
and 
Greek, using an LME model fitting word learn-
ing epochs, with (log) word frequency, inflec-
tional class and word length as fixed effects. In 
German 
and 
Italian, 
the 
distinction 
between 
regular and irregular paradigms is based on the 
criterion of absence vs. presence of stem allo-
morphy across all forms of a paradigm (Marzi et 
al., 2016). In Greek, we consider regular all par-
adigms showing a sigmatic perfective stem, and 
irregular those with an asigmatic perfective stem. 
Unlike German and Italian (Figure 1, top and 
middle panels), where irregulars tend to be ac-
quired systematically later than length-matched 
regulars 
are, 
and 
no 
significant 
interaction 
is 
found, Greek data (Figure 1, bottom panel) show 
an interesting crossing pattern: shorter irregulars 
are acquired earlier than length-matched regulars 
of comparable frequency, but long irregulars are 
acquired later than long regulars. 
Marzi and colleagues (2016) account for earli-
er learning epochs of both German and Italian 
regulars as an effect of stem transparency on cu-
mulative input frequencies. With German and 
Italian regular verbs, stems are shown to the map 
consistently more often, since they are transpar-
ently nested in all forms of their own paradigm. 
This makes their acquisition quicker, due to spe-
cialised chains of stem-sensitive 
BMUs
getting 
more quickly entrenched. Once a stem is ac-
quired, it can easily be combined with a common 
pool of inflectional endings for tense and agree-
ment, simulating an effect of (nearly) instantane-
ous 
(or 
paradigm-based, 
as 
opposed 
to 
item-
based) acquisition. In contrast, Greek verb clas-
ses always present stem allomorphy throughout 
their paradigms, no matter whether allomorphy is 
systematic, phonologically motivated or unsys-
tematic. In regular verbs, where perfective stem 
formation 
requires 
-
s
- 
affixation, 
perfective 
stems are systematically longer than their imper-
fective counterparts, and are acquired after them. 
Nonetheless, since imperfective stems are redun-
dantly embedded in perfective stems, learning a 
long regular perfective form is easier (i.e. it takes 
a comparatively shorter time) than learning an 
irregular perfective form of comparable length. 
This is, again, a regularity-by-transparency ef-
fect, and explains why long regular forms tend to 
be acquired (on average) more easily than long 
irregular forms. 
Figure 1.
Marginal plots of interaction effects between word 
length and inflectional regularity in an LME model fitting 
word learning epochs in German (top), Italian (middle) and 
Greek (bottom). Solid lines = regulars, dotted lines = irregu-
lars. 
To further investigate the impact of degrees of 
formal transparency on the processing of Greek 
verb forms, we conducted an LME analysis of 
the interaction between word length and classes 
of (ir)regularity in word recall (Figure 2). When 
we control for length, regular verbs with system-
atic morphological allomorphs (e.g. 
aɣap(a)-o 
~ 
aɣapi-s-a
, solid line in the plot) are recalled more 
easily than regular verbs with phonological allo-
morphs (e.g. 
ðulev-o
~ 
ðulep-s-a
, dashed line in 
the plot). Notably, both classes are easier to re-
call than asigmatic (irregular) verbs (dotted line 
in the plot), which show, in most cases, formally 
more opaque allomorphs (e.g. 
pern-o
~ 
pir-a
). 
As shown by the difference in slope between the 
solid line and the other two lines of Figure 2, 
CLIC_2016_Proceedings.indd 75
02/12/16 15.03
76
facilitation increases with word length, support-
ing our interpretation of the crossing pattern in 
the bottom panel of Figure 1. 
Figure 2.
Marginal plot of interaction effects between length 
(x axis), and degrees of stem regularity in an LME model 
fitting Difficulty of Recall (y axis) by TSOMs trained on 
Greek verb forms
4
Conclusions 
Data analysis highlighted a hierarchy of regulari-
ty-by-transparency effects that appear to have 
consequences on morphological processing. In 
particular, the evidence offered here emphasises 
the role of formal preservation of the stem (or 
stem transparency) in the paradigm as a key fa-
cilitation factor for morphological processing. 
Our case study is focused on a distinguishing 
characteristic of Greek conjugation: all verb par-
adigms, 
both 
regulars 
and 
irregulars, 
involve 
(unpredictable) 
stem 
allomorphy 
in 
past-tense 
formation. Hence, the difference between regular 
and irregular verbs could not be attributed to the 
presence or absence of stem allomorphy as is the 
case with other languages, such as English and 
Italian (and, to a lesser extent, German), but ra-
ther to the type of stem allomorphy itself. The 
ﬁnding 
(Figure 
2) 
that 
stem-ﬁnal 
systematic 
change, 
as 
in 
the 
case 
of 
regulars, 
led 
to 
signiﬁcantly 
easier 
recall 
than 
stem-internal 
vowel 
changes 
and 
non-systematic/non-
predictable stem-final change, as is the case of 
irregulars, lends support to the conclusion that 
the type of stem allomorphy is what determines 
the different levels of morphological regularity in 
Greek. Crucially, this seems to involve a regular-
ity-by-transparency interaction, with predictabil-
ity playing second fiddle. 
Our data meet growing psycholinguistic evi-
dence pointing in the same direction, to empha-
sise the importance of formal redundancy for 
speakers’ perception of morphological structure. 
Furthermore, it paves the way to the definition of 
a 
performance-oriented 
notion 
of 
inflectional 
regularity that may ultimately cut across tradi-
tional 
competence-based 
classifications, 
which 
presuppose a hardly tenable subdivision of work 
between storage and processing. 
References 
Alegre, M. and P. Gordon. 1999. Frequency effects, 
and the representational status of regular inflec-
tions. 
Journal of Memory, and Language
, 40: 41-
61. 
Baayen, H. R. 2007. Storage, and computation in the 
mental lexicon. In: G. Jarema and G. Libben (eds.), 
The Mental Lexicon: Core Perspectives
. Amster-
dam: Elsevier, 81-104. 
BCBL. 2016. 
SUBTLEX-GR: The corpus
. Donostia: 
Basque Center on Cognition, Brain, and Language. 
[Retrieved 
from: 
http://www.bcbl.eu/subtlex-gr/, 
12-04-2016]. 
Bloch, B. 1947. English verb inflection. 
Language
, 
23: 399-418. 
Bloomfield, L. 1933. 
Language
. New York: Henry 
Holt, and Co. 
Chomsky, N. and M. Halle. 1968. 
The sound pattern 
of English
. New York: Harper and Row. 
Ferro, M., Marzi, C. and V. Pirrelli. 2011. A Self-
Organizing model of word storage and processing: 
implications 
for 
morphology 
learning. 
Lingue 
e 
Linguaggio
, X(2): 209-226. 
Konstantinopoulou, P., Stavrakaki, S., Manouilidou, 
C. and D. Zafeiriou. 2013. Past tense in children 
with focal brain lesions. 
Stem-, Spraak- en Taalpa-
thologie
, 18(1): 90-94.
Lieber, R. 1980. 
On the organization of the lexicon
. 
PhD thesis. Cambridge: MIT. 
Marzi, C., Ferro, M. and V. Pirrelli. 2014. Morpho-
logical structure through lexical parsability. 
Lingue 
e Linguaggio
, XIII(2): 263-290. 
Marzi, 
C. 
and 
V. 
Pirrelli. 
2015. 
A 
neuro-
computational approach to understanding the Men-
tal Lexicon. 
Journal of Cognitive Science
, 16(4): 
493-534. 
Marzi, C., Ferro, M., Cardillo, F. A. and V. Pirrelli. 
2016. Effects of frequency, and regularity in an in-
tegrative model of word storage, and processing. 
Italian Journal of Linguistics
, 28(1): 79-114. 
Mastropavlou, M. 2006. 
The effect of phonological 
saliency, and LF-interpretability in the grammar of 
Greek 
normally 
developing, 
and 
language 
im-
paired children
. Ph.D. thesis. Thessaloniki: Aristo-
tle University of Thessaloniki. 
Pinker, S. and A. Prince. 1994. Regular, and irregular 
morphology, and the psychological status of rules 
of grammar. In: S. D. Lima, R. L. Corrigan and G. 
K. Iverson (eds.), 
The reality of linguistic rules
. 
Amsterdam: Benjamins, 321-351. 
CLIC_2016_Proceedings.indd 76
02/12/16 15.03
77
Pirrelli, V., Ferro, M. and C. Marzi. 2015. Computa-
tional complexity of abstractive morphology, In: 
M. Baerman, D. Brown and G. Corbet (eds.), 
Un-
derstanding and Measuring Morphological Com-
plexity
. Oxford: Oxford University Press, 141-166. 
Ralli, 
A. 2005. 
Morfologia 
[Morphology]. 
Athens: 
Patakis. 
Ralli, A. 2007. On the role of allomorphy in inflec-
tional morphology: evidence from dialectal varia-
tion. In: G. Sica (ed.), 
Open problems in linguis-
tics, and lexicography
. Milano: Polimetrica, 123-
152. 
Ralli, A. 2014. Suppletion. In: G. K. Giannakis (ed.), 
Encyclopedia of Ancient Greek language, and lin-
guistics
, Vol. 3. Leiden, Boston: Brill, 341-344. 
Selkirk, E. 1984. 
Phonology, and Syntax
. The MIT 
Press. 
Stamouli, S. 2000. Simfonia, xronos ke opsi stin elin-
iki idiki glosiki diataraxi [Agreement, tense, and 
aspect in specific language impairment in Greek]. 
In: 
Proceedings of the 8
th
symposium of the Pan-
hellenic Association of Logopedists
. Athens: El-
linika Grammata. 
Stathopoulou, N. and H. Clahsen. 2010. The perfec-
tive past tense in Greek adolescents with Down 
Syndrome. 
Clinical 
Linguistics 
& 
Phonetics
, 
24(11): 870-882. 
Stavrakaki, S. and H. Clahsen. 2009a. The perfective 
past 
tense 
in 
Greek 
child 
language. 
Journal 
of 
Child Language
, 36: 113-142. 
Stavrakaki, S. and H. Clahsen. 2009b. Inflection in 
Williams Syndrome. The perfective past tense in 
Greek. 
The Mental Lexicon
, 4: 215-238. 
Stavrakaki, 
S., 
Koutsandreas, 
K. 
and 
H. 
Clahsen. 
2012. The perfective past tense in Greek children 
with specific language impairment. 
Morphology
, 
22: 143-171. 
Terzi, A., Papapetropoulos, S. and E. D. Kouvelas. 
2005. Past tense formation, and comprehension of 
passive sentences in Parkinson’s disease: Evidence 
from Greek. 
Brain, and Language
, 94: 297-303. 
Tsapkini, K., Jarema, G. and E. Kehayia. 2001. Mani-
festations of morphological impairments in Greek 
aphasia: A case study. 
Journal of Neurolinguistics
, 
14: 281-296. 
Tsapkini, K., Jarema, G. and E. Kehayia. 2002a. A 
morphological processing deficit in verbs but not 
in nouns: A case study in a highly inflected lan-
guage. 
Journal of Neurolinguistics
, 15: 265-288. 
Tsapkini, K., Jarema, G. and E. Kehayia. 2002b. The 
role of verbal morphology in aphasia during lexical 
access: Evidence from Greek. In: E. Fava (ed.), 
Clinical 
linguistics, 
and 
phonetics: 
Theory, 
and 
applications 
in 
speech 
pathology, 
and 
therapy
. 
Amsterdam/Philadephia: 
John 
Benjamins, 
315-
335. 
Tsapkini, K., Jarema, G. and E. Kehayia. 2002c. Reg-
ularity revisited: Evidence from lexical access of 
verbs, and nouns in Greek. 
Brain, and Language
, 
81: 103-119. 
Tsapkini, K., Jarema, G. and E. Kehayia. 2004. Regu-
larity 
re-revisited: 
Modality 
matters. 
Brain, 
and 
Language
, 89: 611-616. 
Ullman, M., Corkin, S., Coppola, M., Hickok, G., 
Growdon, 
J. 
H., 
Koroshetz, 
W. 
and 
S. 
Pinker. 
1997. A neural dissociation within language: evi-
dence that the mental dictionary is part of declara-
tive memory, and that grammatical rules are pro-
cessed by the procedural system. 
Journal of Cogni-
tive Neuroscience
, 9(2): 266-276. 
Varlokosta, S., Arhonti, A., Thomaidis, L. and V. 
Joffe. 2008. Past tense formation in Williams syn-
drome: evidence from Greek. In: A. Gavarro and 
M. 
Freitas 
(eds.), 
Proceedings 
of 
GALA 
2007
. 
Cambridge: Cambridge Scholars Publishing, 483-
491. 
Rescorla R. and A. Wagner. 1972. A theory of Pavlo-
vian conditioning: variations in the effectiveness of 
reinforcement 
and 
non-reinforcement. 
In: 
A. 
H. 
Black and W. F. Prokasy (eds.), 
Classical 
condi-
tioning 
ii
. 
New 
York: 
Appleton-Century-Crofts
,
64-99. 
CLIC_2016_Proceedings.indd 77
02/12/16 15.03
78
Stepping out of the Chinese Room: Word meaning with and without 
consciousness
Roberto Bottini 
Center for Mind/Brain Sciences, 
University of Trento, Italy 
bottini.r@gmail.com
Daniel Casasanto 
University of Chicago, IL 
USA 
casasanto@uchicago.edu 
Andrea Nadalini 
International School for Advanced Studies (SISSA) 
Trieste, Italy 
anadalini@sissa.it
Davide Crepaldi 
Milan Center for Neuroscience 
Milan, Italy 
davide.crepaldi@sissa.it
Abstract 
English. 
What is the role of consciousness in 
language processing? Unconscious priming 
experiments show that words can prime other 
words with related meanings (cat – dog), and 
these priming effects are assumed to reflect 
the activation of conceptual knowledge in 
semantic 
memory. 
Alternatively, 
however, 
unconscious 
priming 
effects 
could 
reflect 
predictive relationships between the words’ 
forms, since words that are semantically re-
lated are also statistically related in language 
use. 
Therefore, 
unconscious 
“semantic” 
priming effects could be due to relationships 
between words’ forms mimicking conceptual 
relationships, as in Searle’s Chinese Room 
thought 
experiment. 
To 
distinguish 
word-
form-based and semantics-based accounts of 
priming 
we 
conducted 
an 
experiment 
in 
which 
temporal 
words 
(e.g., 
earlier, 
later) 
were preceded by spatial words that were 
processed either consciously or unconscious-
ly. Time is typically conceptualized as a spa-
tial 
continuum 
extending 
along 
either 
the 
sagittal (front-back) or the lateral (left-right) 
axis, but only the sagittal space-time map-
ping is encoded in language (e.g. the future is 
ahead
, not 
to the right
). Results showed that 
temporal words were primed both by sagittal 
words (back, front) and lateral words (left, 
right) 
when 
primes 
were 
perceived 
con-
sciously, 
as 
predicted 
by 
both 
wordform-
based 
and 
semantics-based 
accounts. 
Yet, 
only sagittal words produced an unconscious 
priming 
effect, as 
predicted 
by 
the 
word-
form-based account. Unconscious word pro-
cessing appears to be limited to relationships 
between 
words’ 
forms, 
and 
consciousness 
may be needed to activate words’ meanings. 
Italiano. 
Qual 
è 
il 
ruolo 
della 
coscienza 
nell’elaborazione 
semantica 
delle 
parole? 
Esperimenti 
di 
masked 
priming 
semantico 
mostrano che la vista di una parola può faci-
litare il riconoscimento di un’altra parola 
dal contenuto semantico simile (gatto – ca-
ne). Questo effetto di priming è solitamente 
interpretato 
come 
evidenza 
che 
la 
parola 
inconscia è processata a livello semantico. 
Tuttavia, tale effetto può essere spiegato an-
che sulla base di relazione tra forme lessicali 
(senza attivazione di informazione nella me-
moria semantica). Infatti, parole che sono 
semanticamente 
legate 
sono 
anche 
legate 
statisticamente 
nel 
linguaggio. 
Il 
priming 
semantico inconscio potrebbe semplicemente 
emulare relazioni concettuali, come nel fa-
moso esperimento mentale della stanza cine-
se di Searle. Per distinguere il priming lessi-
cale dal priming semantico abbiamo condot-
to un esperimento in cui parole temporali 
(ieri, 
domani) 
erano 
precedute 
da 
parole 
spaziali mostrate sia a livello subliminale 
che 
supraliminale. 
Il 
tempo 
è 
tipicamente 
concettualizzato 
attraverso 
mappe 
spaziali 
che si estendono lungo l’asse sagittale (il 
passato è dietro, e il futuro davanti) e lungo 
l’asse laterale (il passato è a sinistra, futuro 
a destra). Solo la mappatura sagittale è però 
codificata nel linguaggio (il futuro è davanti, 
non a destra). I risultati mostrano come sia 
le parole sagittali (dietro, davanti) che quelle 
laterali (sinistra, destra) facilitano l'elabora-
zione di parole temporali (ad esempio prima 
e dopo), quando percepite consciamente. Al 
contrario, quando i prime sono elaborati al 
di fuori della coscienza, l’effetto sull’asse 
laterale viene meno. Il processo inconscio 
delle parole sembra dunque essere limitato a 
relazioni 
tra 
forme lessicali; 
la 
coscienza 
CLIC_2016_Proceedings.indd 78
02/12/16 15.03
79
potrebbe essere necessaria per attivarne il 
significato.
1
Introduction 
What 
role 
does 
consciousness 
play 
in 
word 
meaning’s construction? As previous literature 
has pointed out, lexical items seem to be pro-
cessed up to the semantic level even when pro-
cessed out of awareness (Quinn & Kinoshita, 
2008; Ansorge, Kiefer, Khalid, Grassl, & König, 
2010). Most evidence for this claim comes from 
masked priming: When two words are sequen-
tially presented, the recognition of the latter is 
made easier if the two are semantically related 
(cat-dog), even when the visibility of the former 
(the prime) is prevented by displaying it very 
briefly, 
embedded 
between 
visual 
masks 
(Forster, 2006; Dehaene et al., 1998). For in-
stance, participants are likely to classify more 
quickly the word 
dog 
as referring to a living enti-
ty when it is preceded by the semantically related 
word 
cat, 
rather than by a semantically unrelated 
word like 
apple
. As similar effects are attested 
when the prime word is clearly visible, it has 
been suggested that lexical items can be pro-
cessed up to the semantic level irrespective of 
their visibility. We will refer to this perspective 
as the 
semantic-based account
of masked prim-
ing, as it assumes that words are processed be-
yond their surface structure and activate concep-
tual 
knowledge 
about 
their 
referents. 
Such 
knowledge is thought to be stored within the se-
mantic memory, where concepts and concepts’ 
features 
are 
represented 
in 
an 
interconnected 
network (Tulving, 1972; 
Masson, 
1995). 
In such a view, 
cat 
would prime 
dog 
as both 
words refer to mammals that have four legs, have 
a tail, can be pet, and so on; and therefore they 
are more closely related to each other than to 
apple
. 
However, there is an aspect of semantic similari-
ty that has been largely overlooked in the prim-
ing-related 
literature, 
that 
words 
with 
similar 
meaning tend to have a similar contextual distri-
bution. 
As 
corpus-based 
studies 
have 
pointed 
out, words referring to entities with similar per-
ceptual and conceptual attributes tend be used 
together (e.g., 
dog 
and 
cat 
are more likely to co-
occur in the same sentence than 
dog
and 
apple
), 
and to be used in similar contexts (e.g., both 
cat
and 
dog
tend to appear when speaking about 
pets, whether or not they co-occur within a given 
utterance; Louwerse, 2011; Landauer & Dumais, 
1997). Based on this fact, unconscious priming 
may be alternatively explained through predic-
tive relationships between words’ forms estab-
lished in language use. According to the 
word-
form-based account, cat 
would prime 
dog simply 
because the two words share a similar contextual 
distribution. No conceptual representation is in-
volved, as the locus of the unconscious semantic 
priming would be the lexical system, not seman-
tic memory (Collins & Loftus, 1975). 
This latter interpretation of unconscious word 
processing 
somehow 
resembles 
the 
Chinese 
Room thought experiment developed by the phi-
losopher John Searle, where an English-speaking 
man is closed in a room receiving message writ-
ten in Chinese characters (Searle, 1980). Due to a 
set of norms that determine the relationships be-
tween those characters (if you see X followed by 
Y, than reply Z), he is able to provide answers 
that would look perfectly appropriate to a native 
speaker. From the outside, it would appear that 
the man has a good understanding of the lan-
guage, while instead he is acting on the basis of 
associations between word forms. Indeed, if he 
received a message saying that the room is about 
to explode, he would reply appropriately; but 
would not leave the room. 
For the 
semantic-based 
and 
wordform-based 
accounts of masked priming to be distinguished, 
it is necessary to find concepts that are related in 
the semantic system, but not in the lexical sys-
tem. This is the case for the metaphorical rela-
tionship linking time to space. The two domains 
are strictly intertwined in the human mind, in 
such a way that space is often used to think about 
time (Lakoff & Johnson, 1980). Time conceptu-
alization involves both the sagittal and the lateral 
axis (Casasanto & Bottini, 2014; Bonato, Zorzi 
& Umiltà, 2012). For example, participants are 
faster 
in 
responding 
to 
past-related 
words 
by 
providing 
a 
leftward response, 
and to 
future-
related words by providing a rightward response, 
relative to the opposite pattern. The same holds 
for the sagittal arrangement, with backward re-
sponse associated with past-related words and 
forward response associated with future-related 
words. Moreover, neurological evidence shows 
that patients with hemispatial neglect have also 
impairments in temporal judgments (i.e. if they 
neglect the left side on space, they also show 
worst 
memory 
for 
past-related 
events; 
Saj, 
Fuhrman, 
Vuilleumier, 
& 
Boroditsky, 
2013). 
Finally, people have been found to use hand ges-
tures along both the lateral and the sagittal line 
when speaking about time (Casasanto & Jasmin, 
CLIC_2016_Proceedings.indd 79
02/12/16 15.03
80
2012). Critically, while the sagittal mapping is 
linguistically encoded in sentences such as “a 
bright future 
in front of
you”, the lateral one is 
not. The existence of these two mental timelines, 
and the fact that only one of them is linguistical-
ly expressed, offers the ideal test-bed for con-
trasting the 
semantic-based 
and 
wordform-based 
accounts of unconscious word processing. The 
latter 
predicts 
that 
space–time 
priming 
would 
only 
emerge 
along 
the 
linguistically 
encoded 
sagittal axis when primes are kept outside of 
awareness; while the former would predict prim-
ing to emerge along both axes, both supra- and 
subliminally. 
We tested these predictions in a priming study 
with spatial words related to the lateral (
left-
right
) and the sagittal (
ahead
-
behind
) axis as 
primes, and temporal words referring to either 
the past (
yesterday
) or the future (
tomorrow
) as 
target stimuli. In the first experiment, primes 
were clearly visible In the second experiment, 
prime visibility was prevented by means of a 
masking procedure. 
2
Experiments 
2.1
Experiment 1a - Visible primes 
Participants: 
60 volunteers were recruited for the 
experiment; all subjects were right-handed, and 
they all stated being native Italian speakers, with 
normal or corrected-to-normal vision and no his-
tory of neurological disorders. Each subject gave 
written informed consent for participation. 
Stimuli, apparatus and procedure:
Primes were 2 
spatial words related to the lateral axis (“sinis-
tra”, 
left,
and “destra”, 
right
) and 2 spatial words 
related to the sagittal axis (“davanti”, 
front,
and 
“dietro”, 
back
). Target stimuli were 8 temporal 
words. Four of them refer to the past (“prima”, 
earlier
, 
“ieri”, 
yesterday
, 
“passato”, 
past
, 
“scorso”, 
previous
), and four refers to the future 
(“dopo”, 
later
, 
“domani”, 
tomorrow
, “futuro”, 
future
, “successivo”, 
next
). 
Each trial consisted of a fixation point (+) dis-
played for 750 ms. Then a blank screen was 
shown for 200ms, followed by the prime and by 
another blank screen, both lasting 50 ms. Finally, 
the target word was presented for 1500 ms, or 
until a response was provided. 
Participants engaged in a GO/NO_GO task: They 
had to press a key if the target word referred to 
the past and do nothing if the target word re-
ferred to the future, or vice versa, according to 
the block instructions. 
Results and discussion: 
analyses were conducted 
only on “GO” trials. Inaccurate trials (less than 
1%) were excluded. In order to reduce the effect 
of outliers, those individual datapoints standing 
at more than 2 standard deviations from each 
participant’s mean (~5% of the correct trials) 
were also removed from the analyses. A 2–by–2 
ANOVA on the log-transformed RTs revealed a 
significant main effect of Congruity, F(1, 59)= 
11.47, p= 0.001, indicating that participants were 
faster in congruent trials (535 ms) compared to 
incongruent ones (540 ms). We found no effect 
of Axis, F(1, 59)= 0.41, p> .250, and no Axis by 
Congruity interaction, F(1, 59)= 0.06, p>0.250. 
Pairwise comparisons showed that the priming 
effect was 
significant
both in the sagittal (4 ms; 
F(1, 59)= 5.79, p= 0.02) and the lateral axis (6 
ms; F(1, 59)= 6.76, p= 0.01). 
Thus, 
significant 
congruity 
effects 
were 
pro-
duced both by sagittal and lateral spatial prime 
words, consistent with previous studies that pro-
vide 
evidence 
for 
sagittal 
and 
lateral 
mental 
timelines. 
2.2
Experiment 1b - Subliminal primes 
Participants:
60 volunteers from the same popu-
lation as in Experiment 1a were recruited into the 
experiment. None of them took part in the previ-
ous experiment. 
Stimuli, apparatus and procedure 
were the same 
as in Experiment 1a with one exception, i.e the 
blank screens that were displayed before and af-
ter the prime word were replaced with two visual 
masks in order to make the prime invisible (sub-
jects were not informed of the presence of the 
primes). 
Prime visibility task: 
after the end of the last part 
of the experiment, all subjects were informed 
about the presence of the prime word between 
the masks. Then, they performed a prime visibil-
ity test that included 10 practice and 128 experi-
mental trials. The stimuli to be detected were the 
same spatial words we used in the previous ex-
periment in half of the trials, and a string of iden-
tical lowercase letters (<aaaaaaaa>) in the other 
half. 
Results and discussion:
only the “GO” trials, in 
which 
participants 
provided 
a 
response, 
were 
analyzed. Inaccurate trials (less than 1%) were 
excluded. In order to reduce the effect of ex-
tremely 
long and 
short RTs, those 
individual 
datapoints standing at more than 2 standard devi-
ations from each participant’s mean (~4% of the 
correct trials) were also removed from the anal-
yses. 
CLIC_2016_Proceedings.indd 80
02/12/16 15.03
81
A 2–by–2 ANOVA on the log-transformed RTs 
revealed a significant main effect of Congruity, 
F(1, 58)= 27.63, p< .001, and an Axis by Con-
gruity interaction, F(1, 58)= 14.986, p< 0.001, 
which we followed up through pairwise compari-
sons showing that priming was significant for the 
sagittal axis (9 ms; F(1, 58)= 40.21, p< 0.001), 
but not for the lateral axis (2 ms; F(1, 58)= 1.52, 
p= 0.22). 
No participant reported having noticed the prime. 
Overall, 
the 
average 
d-prime 
value 
was 
0.33 
(SD= 
0.37). 
Although 
significantly 
different 
from zero, t(58)= 7.03, p< 0.001, this value is 
widely taken to indicate that the prime was effec-
tively 
masked 
from 
perceivers’ 
awareness 
(Kouider & Dupoux, 2005). 
Experiment 
1b 
clearly 
suggests 
that 
spatio–
temporal masked priming is limited to the sagit-
tal axis, with no apparent effect on the lateral 
axis. Thus, the pattern of results provides evi-
dence in favor of the 
wordform-based 
account of 
unconscious word processing. 
3
Conclusion 
In this study we looked at the nature of word 
processing with and without awareness. Using 
the relationships between space and time, we 
were 
able 
to 
disentangle 
the 
wordform-based 
from 
the 
semantic-based 
account 
of 
masked 
priming. When words were clearly visible, we 
found priming effect on both axes, which reflects 
the sagittal, linguistically encoded, timeline, as 
well as the lateral mapping, which relies only on 
conceptual 
knowledge. 
Conversely, 
subliminal 
priming 
was 
obtained 
only 
with 
the 
sagittal 
words, matching the predictions of the 
word-
form-based 
account. Therefore, our data suggests 
that when people read words unconsciously, ac-
tivation spreads only between predictively relat-
ed wordforms. 
Unconscious priming between semantically re-
lated words may mimic semantic priming, much 
in the same way as the man inside Searle’s Chi-
nese Room mimics knowledge of Chinese, on the 
basis of “meaningless” wordform-wordform rela-
tionships. Unconscious word processing appears 
to be limited to relationships between words’ 
forms, and consciousness may be needed to acti-
vate words’ meanings. 
Reference 
Ansorge, U., Kiefer, M., Khalid, S., Grassl, S., & Kö-
nig, P. (2010). Testing the theory of embodied 
cognition 
with 
subliminal 
words. 
Cognition
, 
116(3),303–320. 
Bonato, M., Zorzi, M., & Umiltà, C. (2012). When 
time is space: evidence for a mental time line. 
Neuroscience and Biobehavioral Reviews
, 
36
(10), 
2257–73. 
Casasanto, D., & Bottini, R. (2014). Mirror Reading 
Can 
Reverse 
the 
Flow 
of 
Time. 
Journal 
of 
Experimental Psychology. General
, 
143
(2). 
Casasanto, D., & Jasmin, K. (2012). The Hands of 
Time: 
Temporal 
gestures 
in 
English 
speakers. 
Cognitive Linguistics
, 
23
(4), 643 – 674. 
Collins, A. M., & Loftus, E. F. (1975). A Spreading-
Activation Theory of Semantic Processing, 
Psych 
Review
, 82(6), 407–428. 
Dehaene, S., Naccache, L., Le Clec’H, G., Koechlin, 
E., Mueller, M., Dehaene-Lambertz, G., Van de 
Mortele, P-F, & Le Bihan, D. (1998). 
Imaging 
unconscious semantic priming. 
Nature
, 
395
(6702), 
597–600. 
Fodor, J. (1983). 
The modularity of mind
. Cambridge. 
MIT Press. 
Forster, K. I. (2006). Early activation of category in-
formation in visual word recognition More on the 
turple effect, 
The Mental Lexicon
, 1, 35–58. 
Kouider, S., & Dupoux, E. (2005). Subliminal speech 
priming. 
Psychological Science
, 16(8), 617–25. 
Lakoff, G., & Johnson, M. (1980). 
Metaphors we live 
by
. Chicago, IL: University of Chicago Press. 
Landauer, T. K., & Dumais, S. T. (1997). A solution 
to Plato ’ s problem : The Latent Semantic Analy-
sis Theory of Acquisition , Induction , and Repre-
sentation 
of 
Knowledge. 
Psychological 
Review
, 
104(2), 211–240. 
Louwerse, M. M. (2011). Symbol interdependency in 
symbolic and embodied cognition. 
Topics in Cog-
nitive Science
, 3(2), 273–302. 
Masson, 
M. 
E. 
J. 
(1995). 
A 
Distributed 
Memory 
Model for Semantic Priming. Journal of Experi-
mental Psychology. 
Quinn, W. M., & Kinoshita, S. (2008). Congruence 
effect 
in 
semantic 
categorization 
with 
masked 
primes with narrow and broad categories. 
Journal 
of Memory and Language
, 58(2), 286–306. 
Saj, A., Fuhrman, O., Vuilleumier, P., & Boroditsky, 
L. (2013). Patients With Left Spatial Neglect Also 
Neglect the “Left Side” of Time. 
Psychological 
Science
, (November). 
Searle, J. R. (1980). 
Minds , brains , and programs
, 
BBS
, 3, 1–19. 
CLIC_2016_Proceedings.indd 81
02/12/16 15.03
82
Tulving, E. (1972). 
Episodic and semantic memory
. In 
Organization of memory (Vol. 381). London: Aca-
demic. 
CLIC_2016_Proceedings.indd 82
02/12/16 15.03
83
Enrichring the Ita-TimeBank with Narrative Containers
Alice Bracchi
Universit
`
a degli Studi di Pavia
C.so Strada Nuova 65
27100 Pavia
alice.bracchi@gmail.com
Tommaso Caselli
Vrije Universiteit Amsterdam
De Boelelaan 1105
1081 HV Amsterdam
t.caselli@vu.nl
Irina Prodanof
Universit
`
a degli Studi di Pavia
C.so Strada Nuova 65
27100 Pavia
irina.prodanof@gmail.com
Abstract
English.
This paper reports on an annota-
tion experiment to enrich an existing tem-
porally annotated corpus of Italian news
articles with Narrative Containers,
anno-
tation devices representing temporal win-
dows in text and marking up very informa-
tive temporal
relations between temporal
entities. The annotation has shown that the
distribution of Narrative Containers is sen-
sitive to the text genre and may be used to
facilitate the creation of informative time-
lines.
Italiano.
Questo lavoro illustra i
risul-
tati di un esperimento di annotazione per
l’identificazione di
Contenitori
Narrativi,
ovvero marcatori
di
“finestre” temporali
in un testo,
come
strategia per
arric-
chire un corpus di
articoli
di
quotidiano
in lingua italiana,
gi
`
a annotato con in-
formazioni
temporali.
L’annotazione ha
mostrato che la distribuzione dei Conteni-
tori Narrativi
`
e legata al genere testuale e
pu
`
o essere usata per facilitare la creazione
di
linee temporali
di
eventi
pi
`
u informa-
tive.
1
Introduction
Research in Temporal Processing has seen an in-
creasing interest
thanks to the availability of an-
notation schemes
and corpora in multiple lan-
guages (Pustejovsky et
al.,
2003;
Bittar
et
al.,
2011;
Caselli
et
al.,
2011;
Saurı
and Badia,
2012),
and the organization of
evaluation cam-
paigns (TempEval (Verhagen et al.,
2007; Verha-
gen et
al.,
2010;
UzZaman et
al.,
2013),
Clin-
ical
TempEval
(Bethard et
al.,
2015;
Bethard
et
al.,
2016),
Cross-Document
TimeLine (Mi-
nard et
al.,
2015),
Temporal
QA (Llorens et
al.,
2015)), and EVENTI (Caselli et al., 2014)).
This
has established best practices, common evaluation
frameworks,
international
standards (e.g.
ISO-
TimeML (Pustejovsky et
al.,
2010)),
and ap-
proaches to solve such a complex task.
How-
ever,
the expression of time in text/discourse is
by no means obvious and the automatic extraction
of timelines is not a solved task yet.
One of the
limits of current annotation frameworks and cor-
pora relies mainly in the sparseness of the avail-
able temporal relations and in the fine-grained val-
ues used to classify the temporal
links.
For in-
stance,
in the TempEval-3 corpus the ratio be-
tween temporal
relations and event
plus tempo-
ral
expressions is 0.8 (Bethard et
al.,
2014) for
13 temporal
values.
In the EVENTI corpus,
the
ratio is even smaller,
only 0.19 for 13 temporal
values.
1
Furthermore,
in some cases annotation
guidelines are not informative enough concerning
what types of temporal links to annotate,
or they
force the annotation of temporal relations between
pairs of events when they should not be annotated.
Attempts to overcome these limits have focused
on three main strategies:
i.)
annotating particu-
lar sets of temporal
relations (Kolomiyets et
al.,
2012); ii.)
elaborating detailed annotation guide-
lines for each kind of temporal
relations (event-
temporal expression pairs,
event-event pairs,
and
temporal
expression-temporal
expressions pairs);
and iii.)
developing densely connected temporal
graphs,
where all valid relations among the tem-
poral
entities (events and temporal
expressions)
are marked up,
including inferred relations based
on transitive properties of the temporal
relations
(e.g.
if event
A is BEFORE event
B and event
B IS INCLUDED in event
C,
then event
A is
BEFORE event
C)
(Bethard et
al.,
2014).
We
1
The smaller ratio for the Italian data is also due to spe-
cific restrictions on the annotation of the temporal relations
as reported in the EVENTI Annotation Guidelines and ex-
plained in Section 2.
CLIC_2016_Proceedings.indd 83
02/12/16 15.03
84
consider these solution as partial
as they are not
able to address the issue of identifying and ex-
tracting informative timelines,
i.e.
a set of max-
imally informative temporal links where relevant
events in a text/discourse are correctly anchored
to time,
and then chronologically ordered.
This
paper reports on the first annotation effort to en-
rich existing resources for
Temporal
Processing
in Italian by adopting a document-level approach
rather than a sentence-level
one.
Following the
proposal of Narrative Containers (NCs) (Puste-
jovsky and Stubbs, 2011), as embedding intervals
where events occur,
we developed an annotation
scheme for
their
identification on the EVENTI
corpus (Caselli et al., 2014)
2
, as a strategy to in-
crease the informativeness of the existing anno-
tations and, possibly, improve systems’s temporal
awareness.
The remainder of this paper is structured as fol-
lows:
the EVENTI corpus will
be shortly intro-
duced in Section 2, with a particular emphasis on
the available temporal
relations.
Section 3 will
present the notion of Narrative Container and the
proposed annotation scheme.
In Section 4 the re-
sults of a pilot annotation on the EVENTI dataset
will be reported.
Finally, conclusion, future work,
and a pointer to the annotated data and guidelines
will be reported in Section 5.
2
Temporal Relations in the EVENTI
Corpus
The EVENTI corpus, released in the context of the
EVALITA 2014
3
workshop, consists of 3 datasets:
the Main task training data,
the Main task test
data,
and the Pilot
task test
data.
The corpus
has been annotated with a simplified version of
the It-TimeML Annotation Guidelines (Caselli et
al.,
2011),
an adapted version to Italian of
the
TimeML Guidelines.
Four tags have been used
to annotate the data: EVENT, TIMEX3, SIGNAL,
and TLINK.
The EVENT tag is used to annotate all
lexical
items which may realize an event mention.
It in-
cludes verbs, nouns, adjectives, and prepositional
phrases.
The tag is enriched with 8 attributes
expressing tense,
(grammatical)
aspect,
part-of-
speech,
mood,
modality,
verb form,
TimeML
class, and polarity.
2
https://sites.google.com/site/
eventievalita2014/
3
http://www.evalita.it/2014/tasks/
eventi
The TIMEX3 tag is used for
the annotation
of temporal expressions (timexes), expressing the
type,
the value and whether
the timex is abso-
lute or relative (e.g.
“2015-05-18” vs.
“yester-
day”[ieri]).
The SIGNAL tag is employed to mark any lin-
guistic elements,
such as prepositions (e.g.
in
[in]),
adverbs (e.g.
before [prima]),
or conjunc-
tions (e.g.
when [quando]),
which support
the
identification and classification of a temporal re-
lation between target
entities (e.g.
events and
timexes).
Finally,
the TLINK tag is
used to annotate
temporal
relations.
In the EVENTI
task,
the
subset
of
possible temporal
relations
has
been
restricted
to
three
subtypes
of
intra-sentence
relations,
namely:
i.)
pairs of
syntactic main
events in the same sentence; ii.) pairs of syntactic
main event
and subordinate event
in the same
sentence; and iii.) pairs of event and timexes.
All
13 temporal relation values from It-TimeML (BE-
FORE,
AFTER,
IS INCLUDED,
INCLUDES,
SIMULTANEOUS,
I(MMEDIATELY) AFTER,
I(MMEDIATELY) BEFORE,
IDENTITY,
MEA-
SURE,
BEGINS,
ENDS,
BEGUN BY
and
ENDED BY) have been used.
The
Main
task
datasets,
which
have
been
enriched with Narrative Containers,
add up to
130,279 tokens,
divided into 103,593 tokens for
training and 26,686 for test.
They contain 21,633
EVENTs (17,835 in training and 3,798 in test),
3,359 TIMEX3 (2,753 in training and 624 in test),
1,163 SIGNALs (923 in training and 231 in test),
and 4,561 TLINKs (3,500 in training and 1,061 in
test).
3
Adding Narrative Containers to News
Articles
The notion of Narrative Container (NC) was first
introduced by Pustejovsky and Stubbs (2011) to
deal
with some aspects of Temporal
Processing,
such as sensitivity to the text
genre and interac-
tion with discourse relations, not addressed in the
TimeML Guidelines nor in the TimeBank corpus.
NCs were proposed as a temporal
window,
pro-
viding left
and right
boundaries,
to when events
not anchored to timexes could have happened, thus
overcoming issues related to linking of events with
the Document Creation Time (DCT), i.e.
when a
text was written or published.
In particular, stan-
dard TimeML markup imposes that all events have
CLIC_2016_Proceedings.indd 84
02/12/16 15.03
85
a link with the DCT but fail to specify that each
event should also be annotating to its actual tem-
poral anchor, i.e.
to its moment of occurrence.
As
reported in Pustejovsky and Stubbs (2011), in ex-
ample 1, TimeML guidelines will order both event
mentions, e
1
and e
2
, to the DCT with a BEFORE
relation, anchor e
1
to the timex “yesterday” (t) but
will fail to provide the anchoring of e
2
:
1.
The bomb exploded
e1
yesterday
t2011−09−09
and killed
e2
three people.
[DCT=2011-09-
10]
A further justification to the introduction of NCs
is related to the different
informational
status of
temporal relations.
Assuming the informativeness
of a temporal link as a function of the information
contained in the individual links and their closure,
an anchoring relation,
that
is a relation between
a timex and an event
explicitly stating when the
event
occurred as the one between e
1
and timex
“yesterday” in example 1 (i.e. a temporal value of
INCLUDES or IS INCLUDED), is assumed to be
more informative than an ordering relations, i.e.
a
precedence relation between two events.
To the best of our knowledge,
the only corpus
which extensively adopts the notion of NC and has
available annotated data is the THYME corpus of
clinical narratives (Styler IV et al., 2014). Our task
is the first
attempt
at
tackling temporal
contain-
ment annotation over news articles in Italian.
A NC enables an accurate reproduction of the
way events in text
cluster
around temporal
ref-
erence points,
explicitly or implicitly realized in
the document,
as the narration unfolds.
NC re-
lations are thus anchoring relations between pairs
of
events
or
events
and temporal
expressions.
They are marked with an additional link tag,
i.e.
CONTAINS,
to distinguish them from standard
TLINKs.
Each NC relation admits two compo-
nents:
i.)
the narrative anchor,
i.e.
an element
pointing to a specific temporal dimension shared
by other events or timexes within the text;
and
ii.)
the anchored element(s),
i.e.
events which
satisfy the anchorability requirements (see Section
3.1 for details) and participate in an NC relation.
Timex anchors are chosen on a transparency basis
(i.e.
granularity and nature of the timex), whereas
Event anchors are chosen according to their rele-
vance and salience for the timeline.
Two sub-types of NCs can be identified:
•
Temporal
Containers
(TCs):
they corre-
spond to the timexes in the text which clearly
anchor the events in analysis on a timeline;
the relation can hold both at intra- and inter-
sentence level.
Example 2 from our anno-
tated corpus shows a timex (2001) and the
events it anchors (e1–e4):
2.
[...]
la
Sonata
composta
[
e
1]
nel
2001
[T
C
anchor]
,
il
cui
primo
esecu-
tore
fu
[
e
2]
lo stesso Lucchesini.
In
questa esecuzione
[
e
3]
si ritrovavano
[
e
4]
gi
`
a tutte le doti
musicali
di
Lucchesini
[...].
•
Event Containers (ECs):
they correspond
to event
mentions which function as a tem-
poral anchor for other event mentions.
ECs
can be useful
in cases where no anchoring
timex is available or to model event-subevent
relations.
Example 3 shows a sentence with
no explicit
temporal
expression,
where the
anchoring of events (e1–e3) is possible only
with respect to the event (ricognizione).
3.
[...] Durante la ricognizione
[E
C
anchor]
,
il
tenente ha dato disposizioni
[
e
1]
per
il
presidio,
e nella fase
[
e
2]
iniziale ha
ordinato
[
e
3]
ai
sottoposti
di
fare rap-
porto al campo base.
Figure 1 serves as a visual representation of the
NC as annotated in example 2.
By means of NCs,
a document timeline will result in an ordered suc-
cession of NCs rather than of isolated events. This
is the NC resulting from the following sentence,
taken from the annotated corpus.
Figure 1:
Visual
representation of a NC for the
sentence in Example 2.
Naturally,
the NC represented here is only a
visual
aid picturing the conceptual
outcome of
CLIC_2016_Proceedings.indd 85
02/12/16 15.03
86
applying CONTAINS relations between the an-
chor (here,
the TIMEX3 2001) and anchored el-
ements (here,
EVENTs composta,
fu,
esecuzione,
and ritrovavano)
3.1
Event Anchorability Requirements
The set of events which can be anchored has been
restricted to factual events.
The identification of
eligible anchorable events has been manually con-
ducted at this stage of the annotation.
We adopted
the definition of factuality as proposed in the Fact-
Bank (Saur
´
ı, 2008) and which is based on the dou-
ble axis of
polarity (positive vs.
negative)
and
certainty.
For
the sake of
our
annotation task,
only positive and certain events can be anchored.
Events in the future were generally not annotated
as they normally do not
have a certain status.
However, those events with an established sched-
ule (e.g.
deadlines,
meetings),
or whose future
temporal window is assumed to be certain, such as
festivities, have been annotated in anchoring rela-
tions as well.
We excluded all events which are presented as
subjective (i.e.
judgements,
opinions).
In ex-
ample 4,
esplosione is a factual
event
and was
anchored as such,
whereas sbagliato describes it
through the grid of the writer’s judgement,
who
states that the explosion was a mistake,
and thus
not anchored.
4.
L’esplosione
e1
`
e avvenuta a mezzanotte di
luned
`
ı [...].
Insomma,
gli attentatori hanno
sbagliato
e2
obiettivo.
Finally,
generic events,
i.e.
events which ac-
quire some kind of attributive value towards dis-
course participants,
expressing persistent proper-
ties or reiterated,
habitual activities,
were not an-
chored.
4
The EVENTI-NC Corpus
The
EVENTI-NC corpus
includes
documents
from both the training and the test sections of the
Main task of the EVENTI corpus.
It includes 58
annotated articles,
for
a total
of
24.259 tokens,
covering roughly 11% of the EVENTI corpus; Ta-
ble 1 shows the number of EVENTs and TIMEX3
involved in our annotation.
Table 2 reports the number of annotated con-
tainers in our corpus, and their distribution accord-
ing to their type.
TCs make up for almost 63% of
the total number of NCs, against the 37% of ECs.
General EVENTI-NC statistics
Annotated tokens
24.259
Annotated articles
58
EVENT markables
3645
TIMEX3 markables
595
Table 1: Overview of corpus statistics.
Annotated NCs
Type
Number
%
ECs
Verbal anchors
61
19.5
Nominal anchors
55
17.6
Total EC n.
116
37.1
TCs
Text-consuming TIMEX3s
160
51.1
Empty TIMEX3s
37
11.8
Total TC n.
197
62.9
Total NC n.
313
Table 2:
Distribution of Narrative Containers in
the corpus.
It is interesting to notice that 11.8% of TCs is re-
alized by empty TIMEX3s,
i.e.
temporal expres-
sions which do not correspond to lexical items but
can be inferred and which are necessary to for as-
signing a correct value to a timex.
4.1
Distribution of Narrative Containers
anchors
We conducted an in-depth analysis of the NC an-
chors following two parameters: i.) the properties
of NC anchors on their own; and ii.) the sensitiv-
ity to the document genre,
i.e.
the news domain,
on the line of Pustejovsky and Stubbs (2011).
Concerning the first parameter, we first investi-
gated the incidence of verbal anchors as opposed
to nominal anchors. Whereas there appear to be no
tendency towards verb or nouns being more likely
to anchor other events,
it
is interesting to take a
look within these categories.
Out
of all
the ver-
bal
anchors,
42.9% are reporting verbs or verbs
employed in a declarative context.
We observed
that there is a preference for ECs to correspond to
the the event with the highest degree of topicality
in the article, or the most important event (climax
CLIC_2016_Proceedings.indd 86
02/12/16 15.03
87
event).
For example, one article
4
reports on Pres-
ident Clinton’s surgery in 2004:
the largest EC in
the document is anchored by intervento (surgery),
with a total of 12 anchored items.
Sensitivity to text genre can be easily observed
with TC anchors.
25% of them anchor events in
a timespan that can be measured as
±
1 day with
respect to the DCT. Anchors for these containers
are mostly represented by non absolute temporal
expressions, such as temporal adverbs (e.g.
“ieri”
[yesterday], “domani” [tomorrow], among others)
and by the DCT itself,
which represents 11% of
the TC anchors.
Genre-sensitivity might
also be the factor be-
hind the average number of NCs in the corpus.
The documents have an average of 5.17 NCs, and
even for more lengthy articles, the textual anchors
were rarely more than 7.
The average of
5.17
NCs/article might be due to the fact that newspa-
per articles usually refer to a limited number of
facts, whose core is usually made of a handful of
recent
happenings;
whereas the fluctuating rela-
tionship between length and NC number usually
depends both on the content of the article and on
the granularity of the selected NC.
5
Conclusion
This paper reports on a first proposal of an annota-
tion scheme and accompanying annotated data for
NCs in Italian news articles. The NC annotation is
an additional layer on top of already available data
for Temporal
Processing in Italian.
It
addresses
pending issues (e.g.
the annotation of the tem-
poral
relations between event
and the Document
Creation Time) and increases the informativeness
of the document timelines.
Overall,
we observed
that there is a preference for NC to be realized by
timexes in a limited time span. However, NCs may
also be realised by events.
In this case, nouns and
verbs have a similar distribution with a preference
for events which have a central role in the news or
facilitate the clustering of the information (e.g. re-
porting events). Such a behaviour is different with
respect to clinical narratives where nominal events
are more frequently selected as NC (Bethard et
al.,
2016).
This suggests that
different
text
gen-
res present different ways of organizing events on
a timeline.
The introduction of the factuality pa-
rameter to select the anchoring events is a strategy
to clean timelines and to move Temporal Process-
4
adige20040709 id405401.txt
ing from a single document to a cross-document
task.
Future work will aim at assessing the reliabil-
ity of the proposed scheme via an inter-annotator
agreement study and at completing the annotation
of the entire EVENTI corpus.
Finally,
the anno-
tated data and guidelines are publicly available
5
to encourage additional testing and experiments.
References
Steven Bethard,
Nathaniel Chambers,
Bill McDowell,
and Taylor Cassidy.
2014.
An annotation frame-
work for
dense event
ordering.
In 52nd Annual
Meeting of the Association for Computational Lin-
guistics,
52,
Baltimore,
MD,
USA,
June.
Associa-
tion for Computational Linguistics.
Steven Bethard, Guergana Savova, James Pustejovsky,
and Mark Verhagen.
2015.
SemEval-2015 Task 6:
Clinical
TempEval.
In Proceedings of
the 9th In-
ternational Workshop on Semantic Evaluation (Se-
mEval 2015), pages 806–814. Association for Com-
putational Linguistics.
Steven Bethard,
Savova Guergana,
Leon Derczynski,
Wei-Te Chen,
James Pustejovski,
and Mark Verha-
gen.
2016.
SemEval-2010 Task 13:
TempEval-
2.
In Proceedings of SemEval-2016,
SemEval ’13,
pages 977–987, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Andr
´
e Bittar,
Pascal
Amsili,
Pascal
Denis,
and Lau-
rence Danlos.
2011.
French Timebank:
an ISO-
TimeML annotated reference corpus.
In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational
Linguistics:
Human Language
Technologies:
short
papers-Volume 2,
pages 130–
134. Association for Computational Linguistics.
Tommaso Caselli,
Valentina Bartalesi
Lenzi,
Rachele
Sprugnoli,
Emanuele Pianta,
and Irina Prodanof.
2011.
Annotating Events,
Temporal
Expressions
and Relations in Italian: the It-TimeML Experience
for the Ita-TimeBank.
In Proceedings of the Fifth
Law Workshop (LAW V), pages pages 143–151, Port-
land,
Oregon.
Association for Computational
Lin-
guistics.
Tommaso Caselli,
Rachele Sprugnoli,
Manuela Sper-
anza,
and Monica Monachini.
2014.
EVENTI:
EValuation of Events and Temporal INformation at
Evalita 2014.
In Proceedings of
the First
Italian
Conference on Computational
Linguistics CLiC-it
2014 & and of
the Fourth International
Workshop
EVALITA 2014. Pisa University Press.
5
https://sites.google.com/
site/ittimeml/documents/
narrative-container-data.zip?
attredirects=0&d=1
CLIC_2016_Proceedings.indd 87
02/12/16 15.03
88
Oleksandr
Kolomiyets,
Steven Bethard,
and Marie-
Francine Moens.
2012.
Annotating narrative time-
lines as temporal
dependency structures.
In Pro-
ceedings of
the International
Conference on Lin-
guistic Resources and Evaluation.
Hector
Llorens,
Nathanael
Chambers,
Naushad Uz-
Zaman,
Nasrin Mostafazadeh,
James
Allen,
and
James Pustejovsky.
2015.
SemEval-2015 Task
5: QA TempEval—Evaluating temporal information
understanding with question answering.
In Proceed-
ings of the 9th International Workshop on Semantic
Evaluation (SemEval 2015), pages 792–800.
Anne-Lyse
Minard,
Manuela
Speranza,
Eneko
Agirre,
Itziar Aldabe,
Marieke van Erp,
Bernardo
Magnini,
German Rigau,
Ruben Urizar,
and Fon-
dazione Bruno Kessler.
2015.
Semeval-2015 task
4:
Timeline:
Cross-document
event
ordering.
In
Proceedings
of
the
9th
International
Workshop
on Semantic
Evaluation (SemEval
2015),
pages
778–786.
James Pustejovsky and Amber Stubbs.
2011.
Increas-
ing informativeness in temporal annotation.
In Pro-
ceedings of the 5th Linguistic Annotation Workshop,
pages 152–160. Association for Computational Lin-
guistics.
James Pustejovsky,
Patrick Hanks,
Roser Sauri,
An-
drew See,
Robert
Gaizauskas,
Andrea
Setzer,
Dragomir Radev,
Beth Sundheim,
David Day,
Lisa
Ferro, et al.
2003.
The TimeBank corpus.
In Cor-
pus linguistics, volume 2003, page 40.
James Pustejovsky, Kiyong Lee, Harry Bunt, and Lau-
rent Romary.
2010.
ISO-TimeML: An international
standard for
semantic annotation.
In Seventh In-
ternational Conference on Language Resources and
Evaluation (LREC’10), Valletta, Malta.
Roser Saurı and Toni Badia.
2012.
Spanish TimeBank
1.0.
LDC catalog ref. LDC2012T12.
Roser Saur
´
ı.
2008.
A Factuality Profiler for Eventual-
ities in Text.
Ph.D. thesis, Brandeis University.
William F Styler
IV,
Steven Bethard,
Sean Finan,
Martha Palmer,
Sameer Pradhan,
Piet C de Groen,
Brad Erickson, Timothy Miller, Chen Lin, Guergana
Savova,
et
al.
2014.
Temporal
annotation in the
clinical domain.
Transactions of the Association for
Computational Linguistics, 2:143–154.
Naushad UzZaman,
Hector
Llorens,
Leon Derczyn-
ski,
James Pustejovsky,
and James Allen.
2013.
Semeval-2010 task 13: Tempeval-2.
In Second Joint
Conference on Lexical
and Computational
Seman-
tics (*SEM), Volume 2: Seventh International Work-
shop on Semantic Evaluation (SemEval 2013),
Se-
mEval ’13,
pages 1–9,
Stroudsburg,
PA,
USA.
As-
sociation for Computational Linguistics.
Marc Verhagen,
Robert
Gaizauskas,
Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007.
SemEval-2007 Task 15: TempEval Temporal
Relation Identification.
In Proceedings of the 4th In-
ternational Workshop on Semantic Evaluations, Se-
mEval ’07, pages 75–80, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Marc Verhagen,
Roser Saur
´
ı,
Tommaso Caselli,
and
James Pustejovsky.
2010.
Semeval-2010 task 13:
Tempeval-2.
In Proceedings of the 5th International
Workshop on Semantic Evaluation,
SemEval
’10,
pages 57–62,
Stroudsburg,
PA,
USA.
Association
for Computational Linguistics.
CLIC_2016_Proceedings.indd 88
02/12/16 15.03
89
Increasing information accessibility on the Web: a rating system for 
specialized dictionaries 
Valeria Caruso*, Anna De Meo*, Vincenzo Norman Vitaleº 
*Università degli Studi di Napoli ‘L’Orientale’, 
ºUniversità degli Studi di Napoli Federico II 
vcaruso@unior.it, ademeo@unior.it,
vincenzon.vitale@studenti.unina.it
Abstract 
English. 
The paper illustrates the features 
of the 
WLR
(Web Linguistic Resources) 
portal, which collects specialized online 
dictionaries and asses their suitability for 
different functions using a specifically de-
signed 
rating 
system. 
The 
contribution 
aims to demonstrate how the existing tool 
has improved the usefulness of lexico-
graphical portals and how its effectiveness 
can be further increased by transforming 
the portal into a collaborative resource. 
Italiano.
Questo contributo descrive le 
caratteristiche del portale WLR (Web Lin-
guistic Resources) che raccoglie dizionari 
specialistici della Rete e ne stima l’utiliz-
zabilità per diverse funzioni, avvalendosi 
di uno specifico sistema di valutazione. 
Viene quindi mostrato come questo stru-
mento incrementi l’utilizzabilità dei por-
tali lessicografici finora sviluppati e come 
la 
sua 
efficacia 
possa 
essere 
ulterior-
mente migliorata trasformandolo in ri-
sorsa collaborativa. 
1
Introduction 
This paper sketches out the current features and an 
upcoming new application of a rating system de-
signed to assess online specialized dictionaries. 
The system evaluative parameters are managed 
through a relational database accessible for free 
online at the 
Web Linguistic Resources
(
WLR
) 
site. These parameters are used to identify the best 
available dictionaries to satisfy different types of 
information needs experienced by the Internet 
surfers, while the assessment procedure has been 
1
For the concept of hybridization in electronic lexi-
cography, see Granger 2011. 
designed to be flexible and can be readapted to es-
timate the supportive value of other resources as 
well, like grammars or corpora. On the other side, 
once the score assignment for each dictionary fea-
ture has been decided, grades are given automati-
cally by the database. 
The assessment procedure is straight and strictly 
operationalized (Swanepoel, 2008, 2013), and it 
can be used as a guided process to collect data pro-
vided by the users themselves. The system is in 
fact going to be updated and transformed in a col-
laborative (Carr, 1977) dictionary portal, collect-
ing forms that have been filled in by the Web surf-
ers themselves. 
2
Information overload on the Internet 
The 
WLR
dictionary portal has been designed as a 
tool that can offer assistance to solve different 
problems concerning specialized knowledge and 
lexicon that Web users might experience on dif-
ferent occasions in their lives. For example, if they 
need to understand specific concepts belonging to 
some technical fields, like a journalist who needs 
to acquire specific information about different 
topics 
during 
his/her 
professional 
activity. 
Or 
translators, who need both concise explanations of 
concepts and cross linguistic correspondences in 
order to understand specialized texts and translate 
them. Dictionaries can offer, in fact, proper assis-
tance in a wide variety of different occasions, pro-
vided that they are reliable and efficient tools. The 
enormous inventory of specialized online diction-
aries counts already reference works for top pro-
fessionals in one field, like the authoritative 
The
New Palgrave Dictionary of Economics
, but also 
different hybrid
1
tools addressed to school chil-
dren, like the entertaining 
Math Spoken Here!
, 
which has been conceived to assist in learning and 
homework activities. 
CLIC_2016_Proceedings.indd 89
02/12/16 15.03
90
Surfing the Web it is possible to experience the 
tremendous amount of specialized dictionaries 
that are available for the most different fields. 
Compared to these resources, the number of gen-
eral language vocabularies is but a few drops in 
the ocean. This state of affairs is however unsur-
prising, since similar disproportions were the rule 
in the paper dictionary era (Tarp, 2010), when vo-
cabularies were not so easily accessible and one 
could not directly experience the real composition 
of the lexicographical production. The availability 
of these resources on the Internet has however 
overturned the proportion between the user, who 
is in need of lexicographical assistance, and the 
number of specialized resources he can consult, 
thus causing such an information overload that the 
user is either forced to resort to one of the usual 
Wikipedia
pages, or to abandon the search com-
pletely. In both cases the user is stressed by the 
demanding activity of finding a source of infor-
mation, rather than solving his/her information 
voids. 
3
Solutions for integrated information 
access 
Information overproduction on the Web has be-
come one of the tasks of electronic lexicography 
since the advent of the first metalexicographical 
sites, called ‘dictionary collections’ (Engelberg 
and Müller-Spitzer, 2013), offering lists of links 
to different dictionaries. This practice has rapidly 
evolved into steadier solutions that have served 
also the opposite aim of a controlled integration of 
lexicographical data, made possible by the ‘dic-
tionary portals’ (Engelberg and Müller-Spitzer, 
2013) 
of 
well-established 
publishing 
houses, 
which have implemented the integration among 
their vocabularies in order to better meet the in-
formation needs of their users. In the 
Pons
or 
Cambridge
dictionary sites, for example, it is pos-
sible to access different vocabularies by filling in 
a single search mask and selecting the desired re-
source from a menu. 
According 
to 
Engelberg 
and 
Müller-Spitzer 
(2013), dictionary portals “have followed [the] 
course from the single lexicographic product to 
the general lexicographic information service” 
that was predicted by Arnold (1979) and Kay 
(1983) as far as thirty years ago, thus creating a 
new type of dictionary. The possibility to cross-
link well-structured informative resources, such 
as dictionaries, has in fact broaden the possibility 
of users to be informed promptly, by querying a 
single search engine that gives access to many dic-
tionaries. 
The right of ownership to the inventoried diction-
aries is one of major restrictions determining the 
kind of access to the lexicographical information, 
thus influencing the portal typology. In the classi-
fication 
proposed 
by 
Engelberg 
and 
Müller-
Spitzer (2013), dictionaries issued by the same 
publishing house may form ‘integrated dictionary 
nets’, if every vocabulary has been compiled with 
“a common concept of data modelling and struc-
turing”, thus allowing users to retrieve lemmata 
with similar properties from the different diction-
aries inventoried, such as in the OWID. On the 
contrary, portals having no rights of ownership to 
the dictionaries, called ‘dictionary collections’, 
generally offer simple lists of links to external re-
sources. Only a few of them are also provided 
with query systems that carry out searches in the 
lemma lists or in the whole text of the inventoried 
resources (see 
OneLook
). 
3.1
The WLR database assessment system 
In addition to the types listed by Engelberg and 
Müller-Spitzer (2013), the 
WLR
site increases the 
typologies of ‘dictionary collections’ by offering 
inventories of vocabularies that have been evalu-
ated on the basis of the kind of data they contain 
(Caruso & De Meo, 2014). The assessment is car-
ried out by a multi-parametric searchable data-
base, which inventories dictionary features and 
assigns scores in order to display lists of resources 
that are more suited for two different types of pa-
rameters. It is in fact possible to search for dic-
tionaries assisting with specific tasks, or ‘lexico-
graphical functions’ that the dictionary should be 
able to fulfill (Tarp 2008), like acquiring new 
knowledge on a specific topic, solving communi-
cative issues, or giving assistance with transla-
tions or learning tasks. These parameters can be 
set in 
WLR
database by choosing the correspond-
ing option in the ‘Kind of assistance’ box of the 
search form. Additionally, the user can set his/her 
level of expertise in the specialized field consid-
ered, and thus select the layman, semi-expert or 
expert profile in the ‘Expertise level’ box. 
The rating system used in the 
WLR
site is intended 
to increase the effectiveness and efficacy of por-
tals, making dictionary collections less time wast-
ing and more useful also for the less experienced 
dictionary users, since they avoid the display of 
“long lists” that show “results from trustworthy 
sources and downright amateurish concoctions all 
mixed up” (de Schryver 2003: 157). The evalua-
CLIC_2016_Proceedings.indd 90
02/12/16 15.03
91
tion system relies in fact on the presence or ab-
sence of 58 types of data, addressing all the com-
ponent parts of dictionaries (Caruso & De Meo, 
2014): from the host site and the general organi-
zation (or macrostructure), to the mediostructure 
and microstructure, for which both linguistic and 
encyclopedic data are taken into consideration. 
Additionally, explicit guidelines are followed for 
the score assignment system: characterizing data 
for a specific parameter receive one or two points, 
according to their degree of relevance. Negative 
scores (-1, -2) are instead given to contradictory 
data. Similarly, each lexicographical parameter 
considered (‘Kind of assistance’ and ‘Expertise 
level’) can reach the same maximum score: for ex-
ample, the different types of users may have no 
more than 24 points. In the meanwhile, for contra-
dictory profiles, such as laymen and experts, the 
score distribution cannot be the same. 
All this things considered, one can affirm that the 
WLR
site aims to support different types of users 
decreasing the information overload that occurs 
while 
consulting 
rich 
inventories 
of 
non-inte-
grated resources, such as dictionary collections 
sites. Additionally, the 
WLR
rating system is in 
line with the parameters identified by Swanepoel 
(2008; 2013) to carry out dictionary evaluations 
that are scientifically grounded, i.e. assessments 
that explicitly state the analytic principles they use 
and the way these are applied, together with in-
structions to measure the compliance or non-com-
pliance to these same principles. 
Additionally, the portal wires together fragments 
of the huge repository of specialized knowledge 
available on the Internet (Caruso 2014), hosting 
dictionaries of around 60 different fields, such as 
oenology, mathematics and medicine. 
4
How to make effective searches 
Recent studies have underlined that electronic dic-
tionaries are special types of information systems 
(Tarp, 2008; Bothma, 2011; Gows, 2011; Heid, 
2011) and evaluative parameters borrowed from 
the Information Science are used in the literature 
on electronic lexicography topics. In particular, 
the quality of one dictionary can be assessed on 
the basis of its usefulness for a task completion, 
like finding a specific collocate while writing a 
text. Therefore, the dictionary is considered to be 
effective if it provides “the right data and the right 
amount of data to the user” (Heid 2011: 290). On 
the contrary, it is efficient if gives quick access to 
the data needed. 
The 
WLR
database developed so far assures that 
the search for a dictionary is less time wasting for 
the user but it does not guarantee that the data pro-
vided by one dictionary are correct or correctly 
stated. Contrarily, the quality of data is always 
paramount, and users’ searches would be more ef-
fective if they could avoid to consult vocabularies 
whose data are unreliable. 
For example, the following Spanish oenological 
dictionary (
Infoagro.com - Diccionario del vino
) 
explains that ‘ácido’ is a “green wine” whose col-
our seems to be a consequence of a bed fermenta-
tion: 
[1]
“Ácido: 
Vino 
verde. 
Producto 
de 
una 
mala fermentación maloláctica, una uva 
en 
mal 
estado 
o 
recolectada 
antes 
de 
tiempo.” 
On the contrary, many other dictionaries explain 
the same term as denoting a sour wine, or a wine 
that is high in acidity, like in following entry (
Dic-
cionario del vino.com
): 
[2]
“Ácido: 1.- Vino cuya acidez sobrepasa la 
media de la región. La acidez puede ser 
debida a un exceso de ácidos organicos o 
a un desequilibrio entre los sabores del 
vino. 
2.- Vinos con PH inferior a 3,2” 
In order to carry out more efficient searches using 
the current release of the 
WLR
database, one can 
look for dictionaries compiled exclusively by au-
thoritative institutions, thus restricting the search 
to ‘Institutional’ and ‘Specialized’ host sites, two 
features that users can select in the database 
search form. However, even the dictionaries ed-
ited by the most authoritative institutions offer ex-
amples of bad explanations that can be misleading 
for the user, or even difficult to interpret (Caruso 
& De Meo, 2014). For example, the 
Talking Glos-
sary of Genetics
, published by the National Hu-
man Genome Research Institute, in the 
Chromo-
some
definition explains that: “Humans have 23 
pairs of Chromosomes (…), and one pair of sex 
chromosomes, X and Y”. Stated this way the def-
inition is incorrect, since only male humans have 
an XY pair of chromosomes, while females have 
an XX pair. Effective lexicographical definitions 
should obviously provide more complete descrip-
tions and should avoid incorrect generalizations 
like this. 
Assessing data quality poses however many meth-
odological and theoretical problems regarding the 
CLIC_2016_Proceedings.indd 91
02/12/16 15.03
92
terms and the definition features that must be rated 
(see Caruso & De Meo, 2014) by the system. For 
example, the number of the assessed lemma must 
remain the same despite the number of dictionary 
entries? Which definition features are suited to es-
timate whatever concept belonging the special-
ized fields as different as, for example, figurative 
arts and finance? Furthermore, at least one expert 
for each specialized field considered should verify 
the information provided, which is probably the 
most serious obstacle to future developments of 
the project. However, a completely different solu-
tion has been imagined, as will be shown in a mo-
ment. 
4.1
The database as a data validation tool 
The 
WLR
database has been conceived as a flexi-
ble tool that allows its administrators to add or 
change labels in the three component parts that 
make up the repository system, which are called 
‘categories’, ‘features’ and ‘rating system’. The 
first component, or ‘category’, lists the types of 
inventoried linguistic resources: only dictionaries 
have been assessed so far, but other supportive in-
struments to solve linguistic issues could be added 
to the database, like corpora or grammars. To each 
category the administrator assigns different de-
scriptive features, which is the second component 
of the rating system, and can be both binary or 
multivalve. The ‘dictionary’ category has 58 fea-
ture (see Caruso, 2014 for a complete list), some 
of them can only be present or not, thus are binary, 
like 
Cultural Notes
, others are multivalue and thus 
need further specifications, like the 
Kind of Dic-
tionary
, which must be set choosing among dif-
ferent choices: 
Monolingual dictionary
, 
Monolin-
gual word list
, 
Multilingual dictionary
, 
Multilin-
gual word list
, 
Plurilingual dictionary
2
. Lastly, 
grades are assigned to each of these values accord-
ing to the methodology described above. The ad-
ministrator can decide to set different evaluative 
parameters for each category taken into account: 
for example, if grammars were added to the repos-
itory, the language proficiency level could be a 
suitable evaluation parameters for it. 
Once however that the grades distribution has 
been decided, the database assigns points auto-
matically and independently from any actions per-
formed by the compiler of the evaluation forms, 
who can set only the values of the different fea-
tures. 
Likewise, 
if 
the 
score 
assignment 
is 
2
For the concept of Plurilingual Dictionary, see Ca-
ruso, 2011. 
changed, the inventoried dictionaries will imme-
diately change their evaluations. The automatiza-
tion of grades assignment guarantees no errors in 
the final score computation, however, the selec-
tion of values that describe the dictionary features 
are of crucial relevance for the accuracy of the 
evaluation. 
Under this respect, the inventoried resources must 
be analysed carefully, because most of the times 
specialized online dictionaries lack strict lexico-
graphical organization and display different data 
types unsystematically: for example, basic infor-
mation on the word form might be given exclu-
sively in some of the entries of one dictionary, in-
dependently of any significant paradigmatic vari-
ation of the language considered. For similar 
cases, the compiler must set the ‘sometimes’ value 
in the corresponding feature of the evaluation 
form, and the record of the data that are sporadi-
cally given by the dictionary will make the evalu-
ation procedure more reliable. 
Actually, the current development of the project is 
improving the existing database components with 
an additional part that keeps track of where unsys-
tematic data, like those mentioned above, are pre-
sent in the dictionary. This addition will make the 
assessment procedure extremely reliable, since 
the less evident features can be registered, making 
the evaluation accuracy easily verifiable. 
With this new database component, the evaluation 
forms will be fillable by anyone and the 
WLR
da-
tabase will become a collaborative portal. This, 
hopefully, will make the number of the invento-
ried resources increase, and it will offer other ad-
ditional developments. 
While compiling the forms, in fact, users could 
also contribute to verify the quality of the data 
provided, signalling for each dictionary feature if 
any wrong information is given. For each incon-
sistency the user should indicate one alternative 
data and the source of information from which this 
was driven. On the other hand, the database will 
offer warning signals that indicate the presence of 
problematic data within one dictionary. 
Acknowledgements 
We wish to thank Gianluca Monti for managing 
the first version of the 
WLR
database and site. 
The present research has been sustained by aca-
demic 
grants 
from 
the 
University 
of 
Naples 
‘L’Orientale’. 
CLIC_2016_Proceedings.indd 92
02/12/16 15.03
93
References 
Arnold, D. I., 1979, “Synonyms and the College-Level 
Dictionary”, Dictionaries, 1: 103–12. 
Bothma, T.J.D, 2011, “Filtering and Adapting Data 
and Information in an Online Environment in 
Response to User Needs”, in Fuertes-Olivera, 
P.A., Bergenholtz, H. (Eds.), 71-102. 
Carr, M.,
1997, “Internet Dictionaries and Lexicogra-
phy”, 
International 
Journal 
of 
lexicography, 
10/3: 209-230. 
Caruso V., 2011, “Online specialised dictionaries: a 
critical survey”, in Kosem I., Kosem, K. (eds.) 
Electronic lexicography in the 21st century: 
new applications for new users. Proceedings of 
eLex 2011
, Ljubljana: Trojina, Institute for Ap-
plied Slovene Studies, 66-75. 
Caruso V., 2014, “A Guide (not only) for Economics 
Dictionaries”, Hermes – Journal of Language 
and Communication in Business, 52: 75-91. 
Caruso, V., De Meo, A., 2014, “A Dictionary Guide for 
Web Users”, in Abel, A., Vettori, C. & Ralli, N. 
(eds.), 
Proceedings of the XVI EURALEX Inter-
national Congress: The User in Focus
, Bol-
zano: EURAC, 1087-1098. 
De Schryver, G. M., 2003, “Lexicographers’ Dreams 
in the Electronic-Dictionary Age”, International 
Journal of Lexicography, 16/ 2: 143-199. 
Engelberg, S., Müller-Spitzer, C, 2013, “Dictionary 
Portals”, in Gouws, R. H., Heid, U., Schweick-
ard, W., e Wiegand, H. E. (eds.), 
Dictionaries. 
An international encyclopedia of lexicography. 
Supplementary volume: Recent developments 
with special focus on computational lexicogra-
phy
. Berlin/New York: de Gruyter, 1023-1035. 
Fuertes-Olivera, P.A., Bergenholtz, H. (Eds.), 2011, 
e-
Lexicography: The Internet, Digital Initiatives 
and Lexicography
, London, New York: Contin-
uum. 
Gouws, R.H, 2011, “Learning, Unlearning and Innova-
tion in the Planning of Electronic Dictionaries”, 
in 
Fuertes-Olivera, 
P.A., 
Bergenholtz, 
H. 
(Eds.), 17-29. 
Granger, S., 2012, “Introduction: Electronic Lexicog-
raphy 
from 
Challenge 
to 
Opportunity”, 
in 
Granger, S. & Paquot, M. (Eds.), Oxford: OUP, 
1-11. 
Heid, U. 2011. ‘Electronic Dictionaries as Tools: To-
wards an Assessment of Usability.’ In P. A. Fuertes-
Olivera and H. Bergenholtz (eds.), 287–304. 
Kay, M., 1983, “The dictionary of the future and the 
future of the dictionary”, in Zampolli, A. & Cap-
pelli, A. (eds.), 
The Possibilities and Limits of the 
Computer in Producing and Publishing Dictionar-
ies: Proceedings of the European Science Founda-
tion Workshop
, Pisa: Giardini Editori, 161–74. 
Swanepoel, Piet, 2008, “Towards a Framework for the 
Description and Evaluation of Dictionary Eval-
uation Criteria”, Lexikos, 18: 207-231. 
- 2013, “Evaluation of dictionaries”, in Gouws, R. 
H., Heid, U., Schweickard, W., e Wiegand, H. 
E. (a cura di), 
Dictionaries. An international en-
cyclopedia of lexicography. Supplementary vol-
ume: Recent developments with special focus on 
computational lexicography
. Berlin/New York: 
de Gruyter, 587-596. 
Tarp, S., 2008, 
Lexicography in the borderland be-
tween 
knowledge 
and 
non-knowledge
, 
Tü-
bingen: Niemeyer. 
- 2010, “Beyond Lexicography: New Visions and 
Challenges in the Information Age”, in Ber-
genholtz, H., Nielsen, S. & S. Tarp (eds.), 
Lexi-
cography at a Crossroads. Dictionaries and En-
cyclopedias Today, Lexicographical Tools To-
morrow
, Bertlin et.: Peter Lang, 17-32. 
Online Dictionaries and resources 
Cambridge Dictionaries
, http://dictionary.cam-
bridge.org/it/, accessed July 2016. 
Diccionario del vino.com
, http://www.diccionariodel-
vino.com/index.php/letra/a/. 
Infoagro.com - Diccionario del vino
, http://www.in-
foagro.com/viticultura/diccionario/dicciona-
rio.htm, accessed July 2016.
Math Spoken Here! An Arithmetic and Algebra Dic-
tionary
, 
http://www.mathnstuff.com/math/spo-
ken/here/, accessed July 2016. 
OneLook
, www.onelook.com, accessed July 2016. 
OWID
(
Online-Wortschatz-Informationssystem 
Deutsch
), http://www.owid.de/, accessed July 
2016. 
Pons, www.pons.eu, accessed July 2016. 
Talking Glossary of Genetics
, https://www.ge-
nome.gov/glossary/, accessed July 2016. 
The new Palgrave dictionary of economics
, Basing-
stoke 
and 
New 
York: 
Palgrave 
Macmillan, 
http://www.dictionaryofeconomics.com, 
accessed 
July 2016. 
Web Linguistic Resources 
(
WLR
)
,
www.weblinguis-
ticresources.org, accessed July 2016. 
CLIC_2016_Proceedings.indd 93
02/12/16 15.03
94
Online Automatic Post-Editing across Domains
Rajen Chatterjee, Gebremedhen Gebremelak, Matteo Negri, Marco Turchi
Fondazione Bruno Kessler, Italy
{
chatterjee, gebremelak, negri, turchi
}
@fbk.eu
Abstract
English.
Recent
advances in automatic
post-editing (APE) have shown that
it
is
possible to automatically correct
system-
atic errors made by machine translation
systems.
However,
most
of
the current
APE techniques
have only been tested
in controlled batch environments,
where
training and test
data are sampled from
the same distribution and the training set
is fully available.
In this paper,
we pro-
pose an online APE system based on an
instance selection mechanism that is able
to efficiently work with a stream of data
points belonging to different domains. Our
results on a mix of two datasets show that
our system is able to:
i) outperform state-
of-the-art online APE solutions and ii) sig-
nificantly improve the quality of rough MT
output.
Italiano.
Recenti
miglioramenti
dei
sis-
temi automatici di post-editing hanno di-
mostrato la loro capacit
`
a di correggere er-
rori ricorrenti commessi dalla traduzione
automatica.
Spesso,
tuttavia,
tali
sis-
temi
sono
stati
valutati
in
condizioni
controllate
dove
i
dati
di
training/test
sono selezionati dalla stessa distribuzione
e
l’insieme
di
training
`
e
interamente
disponibile.
Questo articolo propone un
sistema di
post-editing online,
basato su
tecniche di
selezione dei
dati,
capace di
trattare sequenze di dati appartenenti a di-
versi
dominii.
I
risultati
su un insieme
di dati misti mostrano che il sistema
`
e in
grado di ottenere risultati migliori rispetto
i) allo stato dell’arte e ii) al
sistema di
traduzione.
1
Introduction
Nowadays, machine translation (MT) is a core el-
ement in the computer-assisted translation (CAT)
framework (Federico et al., 2014). The motivation
for integrating MT in the CAT framework lies in
its capability to provide useful suggestions for un-
seen segments, thus increasing translators produc-
tivity.
However,
it has been observed that MT is
often prone to systematic errors that human post-
editing has to correct before publication.
The by-
product
of this “translation as post-editing” pro-
cess is an increasing amount of parallel data con-
sisting of MT output on one side and its corrected
version on the other side.
Besides being used to
improve the MT system itself (Bentivogli
et
al.,
2016),
this data can be leveraged to develop au-
tomatic MT quality estimation tools (Mehdad et
al.,
2012;
Turchi et al.,
2013;
C.
de Souza et al.,
2013; C. de Souza et al., 2014; C. de Souza et al.,
2015) and automatic post-editing (APE) systems
(Chatterjee et al., 2015b; Chatterjee et al., 2015a;
Chatterjee et al., 2016). The APE components ex-
plored in this paper should be capable not
only
to spot
recurring MT errors,
but
also to correct
them.
Thus, integrating an APE system inside the
CAT framework can further improve the quality
of the suggested segments, reduce the workload of
human post-editors and increase the productivity
of translation industries.
In the last decade many
studies on APE have shown that the quality of the
machine translated text
can be improved signifi-
cantly by post-processing the translations with an
APE system (Simard et
al.,
2007;
Dugast
et
al.,
2007; Terumasa,
2007; Pilevar,
2011; B
´
echara et
al., 2011; Chatterjee et al., 2015b). These systems
mainly follow the phrase-based machine transla-
tion approach where the MT outputs (with option-
ally the source sentence) are used as the source
language corpus and the post-edits are used as the
target language corpus.
Although these standard
CLIC_2016_Proceedings.indd 94
02/12/16 15.03
95
approaches showed promising results,
they lack
of the ability to continuously update their inner
models by incorporating human feedback from a
stream of data.
To address this problem,
several
online systems have been proposed in MT,
but
only few of them have been applied to the APE
scenario (Simard and Foster, 2013; Lagarda et al.,
2015),
only in a controlled working environment
where they are trained and evaluated on homoge-
neous/coherent data sets.
In this paper,
we propose a novel
online APE
system that is able to efficiently leverage data from
different domains.
1
Our system is based on an in-
stance selection technique that is able to retrieve
the most relevant training instances from a pool of
multi-domain data for each segment to post-edit.
The selected data is then used to train and tune the
APE system on-the-fly. The relevance of a training
sample is measured by a similarity score that takes
into account the context of the segment to be post-
edited. This technique allows our online APE sys-
tem to be flexible enough to decide if it has the cor-
rect knowledge for post-editing a sentence or if it
is safer to keep the MT output untouched, avoiding
possible damages.
The results of our experiments
over the combination of two data sets show that
our approach is robust enough to work in a multi-
domain environment and to generate reliable post-
edits with significantly better performance than a
state-of-the-art online APE system.
2
Online translation systems
Online translation systems aim to incorporate hu-
man post-editing feedback (or the corrected ver-
sion of the MT output) into their models in real-
time,
as soon as it becomes available.
This feed-
back helps the system to learn from the mistakes
made in the past translations and avoid to repeat
them in future translations. This continuous learn-
ing capability will eventually improve the quality
of the translations and consequently increase the
productivity of
the translators/post-editors (Tat-
sumi,
2009) working with MT suggestions in a
CAT environment.
The basic workflow of an on-
line translation system goes through the follow-
ing steps repeatedly:
i) the system receives an in-
put
segment;
ii) the input
segment
is translated
and provided to the post-editor to fix any errors
1
A domain is made of segments belonging to the same
text genre and the MT outputs are generated by the same MT
system.
in it;
and iii)
the human post-edited version of
the translation is incorporated back into the sys-
tem, by stepwise updating the underlying models
and parameters.
In the APE context,
the input
is a machine-translated segment (optionally with
its corresponding source segment),
which is pro-
cessed by the online APE system to fix errors,
and then verified by the post-editors.
Several on-
line translation systems have been proposed over
the years (Hardt
and Elming,
2010;
Bertoldi
et
al.,
2013;
Mathur et
al.,
2013;
Simard and Fos-
ter, 2013; Ortiz-Mart
¨
ınez and Casacuberta, 2014;
Denkowski et al., 2014; Wuebker et al., 2015).
The state-of-the-art
online APE system is the
Thot
toolkit
(Ortiz-Mart
¨
ınez
and Casacuberta,
2014) that has been previously developed to sup-
port fully automatic and interactive statistical ma-
chine translation and then used in the APE task
(Lagarda et al., 2015). To update the inner models
with the user feedback, a set of sufficient statistics
was maintained and incrementally updated.
In the
case of language model,
only the n-gram counts
are required to maintain sufficient
statistics.
To
update the translation model,
an incremental ver-
sion of EM algorithm is used to first obtain word
alignment and then phrase pairs counts were ex-
tracted to update the sufficient
statistics.
Other
features like source/target
phrase-length models
or
distortion model
are implemented by means
of geometric distributions with fixed parameters.
However, Thot differs from our approach because
it
does not
embed any techniques for
selecting
the most
relevant
training data.
In the long-run,
when data points from different domain are con-
tinuously analysed,
this system tends to become
more and more generic, which may not be useful
and even harmful
for
automatically post-editing
domain-specific segments.
3
Instance Selection for online APE
system
To preserve all the knowledge gained in the online
learning process and at the same time being able to
apply specific post-editing rules when needed, we
propose an instance selection technique for online
APE that
has the ability to retrieve specific data
points whose context is similar to the segment to
be post-edited.
These data points are then used to
build reliable APE models.
When there are no re-
liable data points in the knowledge base,
the MT
output is kept untouched, as opposed to the exist-
CLIC_2016_Proceedings.indd 95
02/12/16 15.03
96
ing APE systems, which tends to always translate
the given input
segment
independently from the
reliability of the applicable correction rules.
Our
proposed algorithm emulates
an online
APE system and assumes to have the following
data to run the online experiments: i) source (src);
ii) MT output (mt); and iii) human post-edits (pe)
of the MT output. At the beginning the knowledge
base of our online APE system is empty and it
will be updated whenever an instance (a tuple con-
taining parallel segments from all the above men-
tioned documents) is processed. When the system
receives an input (src, mt), the most relevant train-
ing instances from a pool
of multi-domain data
stored in our knowledge base are retrieved.
The
similarity between the training instances and the
input segment is measured by a score based on the
term frequency
−
inverse document frequency (tf-
idf ),
generally used in information retrieval.
The
larger the number of words in common between
the training and the input sentences, the higher is
the score.
In our system,
these scores are com-
puted using the Lucene library.
2
Only those train-
ing instances that
have similarity score above a
certain threshold (decided over a held-out devel-
opment set) are used to build:
i) a tri-gram local
language model over the target side of the training
corpus with the IRSTLM toolkit (Federico et al.,
2008);
ii) the translation and reordering models
using the Moses toolkit (Koehn et al.,
2007) and
the word alignment of each sentence pair is com-
puted using the incremental
GIZA++ software.
3
The log-linear
model
parameters are optimized
over a part
of the selected instances.
To obtain
reliably-tuned weights and a fast optimization pro-
cess, multiple instances of MIRA (Chiang, 2012)
are run in parallel on three small development sets
randomly selected from the retrieved sentences.
The obtained weights are then averaged. If a mini-
mum value of retrieved sentences is not reached,
the optimization step is skipped because having
few sentences might not yield reliable weights.
In
this case,
the weights computed on the previous
input
segment
are used.
The tuned weights and
the models built
on all
the data are then used to
post-edit the input sentences.
In a real translation workflow, the APE segment
is then passed to the human translator that
cre-
ates the post-edited segment. Once the post-edit is
2
https://lucene.apache.org/
3
https://code.google.com/archive/p/
inc-giza-pp/
available it is added to the knowledge base along
with the source and the mt sentences. In our exper-
iments we emulate the post-edited sentence of the
APE segment with the post-edit of the mt output.
4
Experimental setup
Data
To examine the performance of the online
APE systems in a multi-domain translation envi-
ronment,
we select two data sets for the English-
German language pair belonging to information
technology (IT).
Although they come from the
same category (IT),
they feature variability in
terms
of
vocabulary coverage,
MT errors,
and
post-editing style.
The two data sets are respec-
tively a subset of the Autodesk Post-Editing Data
corpus and the resources used at the second round
of the APE shared task at the first conference on
machine translation (WMT2016).
4
The data sets
are pre-processed to obtain a joint-representation
that
links
each source word with a MT word
(mt#src).
This representation has been proposed
in the context-aware APE approach by (B
´
echara et
al., 2011) and leverages the source information to
disambiguate post-editing rules.
Recently, (Chat-
terjee et al.,
2015b) also confirmed this approach
to work better than translating from raw MT seg-
ments over multiple language pairs.
The joint-
representation is used as a source corpus to train
all the APE systems reported in this paper and it is
obtained by first aligning the words of source (src)
and MT (mt) segments using MGIZA++ (Gao and
Vogel,
2008),
and then each mt word is concate-
nated with its corresponding src words.
The Autodesk training,
and development
sets
consist
of
12,238,
and 1,948 segments
respec-
tively, while the WMT2016 data contains 12,000,
and 1,000 segments.
To measure the diversity of
the two data sets we compute the vocabulary over-
lap between the two joint-representations.
This is
performed internally to each data set (splitting the
training data in two halves) and across them.
As
expected,
in the first case the vocabulary overlap
is much larger (
>
40%) than in the second one
(
∼
15%);
this indicates that the two data sets are
quite different and few information can be shared.
To emulate the multi-domain scenario, the two
training data sets are first merged together and then
shuffled.
The same strategy is also used for the
development sets.
This represents the situation in
4
http://www.statmt.org/wmt16/
ape-task.html
CLIC_2016_Proceedings.indd 96
02/12/16 15.03
97
which an APE system serves two CAT tools that
process documents from two domains and the se-
quence of points is random. Our approach and the
competitors are run on all the shuffled training data
and evaluated on the second half (12,100 points).
Evaluation metrics
The performance of the dif-
ferent APE systems is evaluated using the Transla-
tion Error rate (TER) (Snover et al., 2006), BLEU
(Papineni
et
al.,
2002) and the precision (Chat-
terjee et
al.,
2015a).
TER and BLEU measures
the similarity between the MT outputs and their
references by looking at
the word/n-gram over-
laps, while precision is the ratio of number of sen-
tences an APE system improves (with respect to
the MT output)
over
all
the sentences it
modi-
fies.
5
Larger values indicate that
the APE sys-
tem is able to improve the quality of most of the
sentences it changes.
The statistical significance
test for BLEU is computed using the paired boot-
strap resampling technique (Koehn, 2004), and for
TER using the stratified approximate randomiza-
tion technique (Clark et al., 2011).
Terms of comparison
We evaluate our online
learning approach against the output produced by
the MT system,
the batch APE system that
fol-
lows the approach proposed in (Chatterjee et al.,
2015b), and the Thot toolkit.
5
Experiments and Results
The main goal of this research is to examine the
performance of online APE methods in a multi-
domain scenario, where the APE system receives
a stream of data coming from different domains.
The parameters of our approach (i.e.
similarity
score threshold and minimum number of selected
sentence) are optimised following the grid search
strategy.
We set the threshold values to 1 and the
minimum number of selected sentences to 20. The
results of all the systems are reported in Table 1.
The batch APE system that
is trained only on
the first half of the data is able to slightly improve
the performance of the MT system, but it damages
most of the sentence it changes (precision smaller
than 45%).
Although Thot can learn from all the
data, it is interesting to note that it does not signif-
icantly improve over the MT system and the batch
APE system.
This suggests that using all the data
5
For each sentence in the test
set,
if the TER score of
APE system is different than the baseline then it is considered
as a modified sentence
BLEU
TER
Precision (%)
MT
52.31
34.52
N/A
Batch APE
52.52
34.45
42.67
Thot
52.51
34.37
42.22
Our approach
53.97
†
33.13
†
64.82
Table 1: Results on the mixed data. (
†
: statistically
significant wrt. MT with p
<
0.05)
without
considering the peculiarities of each do-
main does not allow an APE system to efficiently
learn reliable correction rules and to improve the
machine translation quality.
Moreover,
these re-
sults also show that few information can be shared
between the two data sets. This is expected consid-
ering the limited overlap between the two corpora.
Our
approach provides
significant
improve-
ments in BLEU,
TER and precision over all
the
competitors.
In particular, it can obtain more than
one TER and BLEU point improvement, and more
than 20% precision points increment over the best
APE system (the Thot
toolkit).
Such gains con-
firm that the instance selection mechanism allows
our APE system to identify domain-specific data
and to leverage it for extracting reliable correction
rules.
Further analysis of the performance of the
online systems revealed that our approach modi-
fies less segments compared with Thot, because it
builds a model only if it finds relevant data, leav-
ing the MT segment untouched otherwise.
These
untouched MT segments, when modified by Thot,
often lead to deterioration.
This suggests that, the
output obtained with our solution has a higher po-
tential for being useful to human translators. Such
usefulness comes not
only in terms of
a more
pleasant post-editing activity, but also in terms of
time savings yield by overall better suggestions.
6
Conclusion
We addressed the problem of building a robust on-
line APE system that is able to efficiently work on
a stream of data points belonging to different do-
mains.
In this condition,
our APE has shown its
capability to continuously adapt to the dynamics
of diverse data processed in real-time.
In partic-
ular, the instance selection mechanism allows our
APE method to reduce the number of wrong modi-
fications, which result in significant improvements
in precision over the state-of-the-art
online APE
system, and thus making it a viable solution to be
deployed in a real-word CAT framework.
CLIC_2016_Proceedings.indd 97
02/12/16 15.03
98
7
Acknowledgements
This work has been partially supported by the EC-
funded H2020 project QT21 (grant agreement no.
645452).
References
Hanna B
´
echara,
Yanjun Ma,
and Josef van Genabith.
2011.
Statistical post-editing for a statistical mt sys-
tem.
In Proceedings of the XIII MT Summit,
pages
308–315.
Luisa Bentivogli, Nicola Bertoldi, Mauro Cettolo, Mar-
cello Federico,
Matteo Negri,
and Marco Turchi.
2016.
On the evaluation of adaptive machine trans-
lation for human post-editing.
IEEE/ACM Trans.
Audio, Speech & Language Processing, 24(2):388–
399.
Nicola Bertoldi,
Mauro Cettolo,
and Marcello Fed-
erico.
2013.
Cache-based online adaptation for ma-
chine translation enhanced computer assisted trans-
lation.
Proceedings of the XIV MT Summit,
pages
35–42.
Jos
´
e G.
C.
de Souza,
Christian Buck,
Marco Turchi,
and Matteo Negri.
2013.
FBK-UEdin Participation
to the WMT13 Quality Estimation Shared Task.
In
Proc. of the Eighth Workshop on Statistical Machine
Translation,
pages 352–358,
Sofia,
Bulgaria. Asso-
ciation for Computational Linguistics.
Jos
´
e G.
C.
de Souza,
Jes
´
us Gonz
´
alez-Rubio,
Chris-
tian Buck, Marco Turchi, and Matteo Negri.
2014.
FBK-UPV-UEdin
Participation
in
the
WMT14
Quality Estimation Shared-task.
In Proc.
of
the
Ninth Workshop on Statistical Machine Translation,
pages 322–328, Baltimore, Maryland, USA.
Jos
´
e G.
C.
de Souza,
Matteo Negri,
Elisa Ricci,
and
Marco Turchi.
2015.
Online multitask learning for
machine translation quality estimation.
In Proceed-
ings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th Interna-
tional Joint Conference on Natural Language Pro-
cessing (Volume 1:
Long Papers),
pages 219–228,
Beijing, China, July. Association for Computational
Linguistics.
Rajen Chatterjee,
Marco Turchi,
and Matteo Negri.
2015a.
The fbk participation in the wmt15 auto-
matic post-editing shared task.
In Proceedings of the
Tenth Workshop on Statistical Machine Translation,
pages 210–215.
Rajen Chatterjee,
Marion Weller,
Matteo Negri,
and
Marco Turchi.
2015b.
Exploring the planet of the
apes:
a comparative study of state-of-the-art meth-
ods for mt automatic post-editing.
In Proceedings
of
the 53rd Annual
Meeting of
the Association for
Computational Linguistics, pages 156–161, July.
Rajen Chatterjee,
Jos
´
e G. C. de Souza,
Matteo Negri,
and Marco Turchi.
2016.
The fbk participation in
the wmt
2016 automatic post-editing shared task.
In Proceedings of the First Conference on Machine
Translation,
pages 745–750,
Berlin,
Germany,
Au-
gust. Association for Computational Linguistics.
David Chiang.
2012.
Hope and fear for discriminative
training of statistical translation models.
Journal of
Machine Learning Research, 13(Apr):1159–1187.
Jonathan H Clark, Chris Dyer, Alon Lavie, and Noah A
Smith.
2011.
Better hypothesis testing for statisti-
cal
machine translation:
Controlling for optimizer
instability.
In Proceedings of the 49th Annual Meet-
ing of
the Association for Computational
Linguis-
tics, pages 176–181.
Michael
Denkowski,
Chris
Dyer,
and Alon Lavie.
2014.
Learning from post-editing:
Online model
adaptation for
statistical
machine translation.
In
Proceedings of the 14th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 395–404, April.
Lo
¨
ıc Dugast, Jean Senellart, and Philipp Koehn.
2007.
Statistical post-editing on systran’s rule-based trans-
lation system.
In Proceedings of the Second Work-
shop on Statistical Machine Translation, pages 220–
223.
Marcello Federico,
Nicola Bertoldi,
and Mauro Cet-
tolo.
2008.
Irstlm:
an open source toolkit for han-
dling large scale language models.
In Proceedings
of Interspeech, pages 1618–1621.
Marcello Federico,
Nicola Bertoldi,
Mauro Cettolo,
Matteo Negri,
Marco Turchi,
Marco Trombetti,
Alessandro Cattelan,
Antonio Farina,
Domenico
Lupinetti, Andrea Martines, Alberto Massidda, Hol-
ger Schwenk, Lo
¨
ıc Barrault, Frederic Blain, Philipp
Koehn, Christian Buck, and Ulrich Germann.
2014.
The matecat tool.
In Proceedings of COLING 2014,
the 25th International Conference on Computational
Linguistics:
System Demonstrations,
pages
129–
132, Dublin, Ireland, August.
Qin Gao and Stephan Vogel.
2008.
Parallel implemen-
tations of word alignment
tool.
In Proceedings of
Software Engineering,
Testing,
and Quality Assur-
ance for Natural
Language Processing,
pages 49–
57.
Daniel
Hardt
and Jakob Elming.
2010.
Incremental
re-training for post-editing smt.
In Proceedings of
AMTA.
Philipp Koehn,
Hieu Hoang,
Alexandra Birch,
Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke
Cowan,
Wade
Shen,
Christine
Moran,
Richard Zens,
et
al.
2007.
Moses:
Open source
toolkit
for statistical
machine translation.
In Pro-
ceedings of the 45th Annual Meeting of the Associa-
tion for Computational Linguistics. System Demon-
strations, pages 177–180.
CLIC_2016_Proceedings.indd 98
02/12/16 15.03
99
Philipp Koehn.
2004.
Statistical significance tests for
machine translation evaluation.
In Proceedings of
EMNLP, pages 388–395.
Antonio L Lagarda, Daniel Ortiz-Mart
¨
ınez, Vicent Al-
abau,
and Francisco Casacuberta.
2015.
Translat-
ing without in-domain corpus:
Machine translation
post-editing with online learning techniques.
Com-
puter Speech & Language, 32(1):109–134.
Prashant
Mathur,
Mauro Cettolo,
Marcello Federico,
and FBK-Fondazione Bruno Kessler.
2013.
On-
line learning approaches in computer assisted trans-
lation.
In Proceedings of the Eighth Workshop on
Statistical
Machine Translation,
ACL,
pages 301–
308.
Yashar
Mehdad,
Matteo Negri,
and Marcello Fed-
erico.
2012.
Match without
a Referee:
Eval-
uating MT Adequacy without
Reference Transla-
tions.
In Proceedings of
the Machine Translation
Workshop (WMT2012),
pages 171–180,
Montr
´
eal,
Canada, June.
Daniel
Ortiz-Mart
¨
ınez
and
Francisco
Casacuberta.
2014.
The new thot toolkit for fully-automatic and
interactive statistical
machine translation.
In 14th
Annual
Meeting of
the European Association for
Computational Linguistics: System Demonstrations,
pages 45–48.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu.
2002.
Bleu: a method for automatic eval-
uation of machine translation.
In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311–318.
Abdol
Hamid Pilevar.
2011.
Using statistical
post-
editing to improve the output of rule-based machine
translation system.
IJCSC.
Michel Simard and George Foster.
2013.
Pepr:
Post-
edit
propagation using phrase-based statistical
ma-
chine translation.
In Proceedings of
the XIV MT
Summit, pages 191–198.
Michel
Simard,
Cyril
Goutte,
and Pierre
Isabelle.
2007.
Statistical
Phrase-Based Post-Editing.
In
Proceedings of the Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 508–515.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul.
2006.
A study of
translation edit rate with targeted human annotation.
In Proceedings of AMTA, pages 223–231.
Midori
Tatsumi.
2009.
Correlation between auto-
matic evaluation metric scores,
post-editing speed,
and some other factors.
In Proceedings of the XII
MT Summit, pages 332–339.
Ehara Terumasa.
2007.
Rule based machine trans-
lation combined with statistical
post
editor
for
japanese to english patent translation.
In Proceed-
ings of the XI MT Summit, pages 13–18.
Marco Turchi,
Matteo Negri,
and Marcello Federico.
2013.
Coping with the Subjectivity of
Human
Judgements in MT Quality Estimation.
In Proc. of
the Eighth Workshop on Statistical Machine Trans-
lation, pages 240–251, Sofia, Bulgaria. Association
for Computational Linguistics.
Joern Wuebker,
Spence Green,
and John DeNero.
2015.
Hierarchical incremental adaptation for sta-
tistical
machine
translation.
In Proceedings
of
EMNLP, pages 1059–1065, September.
CLIC_2016_Proceedings.indd 99
02/12/16 15.03
100
A New Dataset for Source Code Comment Coherence
Anna Corazza
DIETI,
Univ. di Napoli Federico II
anna.corazza@unina.it
Valerio Maggio
Fondazione
Bruno Kessler
vmaggio@fbk.eu
Giuseppe Scanniello
Dept. of Mathematics, Information
Technology, and Economics
Univ. della Basilicata
giuseppe.scanniello@unibas.it
Abstract
English.
Source code comments
pro-
vide useful
insights
on a codebase and
on the intent behind design decisions and
goals.
Often,
the information provided
in the comment
of
a method and in its
corresponding implementation may be not
coherent
with each other
(i.e.,
the com-
ment
does not
properly describe the im-
plementation).
Several could be the moti-
vations for this issue (e.g.,
comment
and
source code do not
evolve coherently).
In this paper,
we present
the results of
a manual
assessment
on the coherence
between comments and implementations
of
3
,
636
methods,
gathered from
4
Java
open-source software.
The results of this
assessment has been collected in a dataset
that
we made publicly available on the
web.
We also sketch here the protocol to
create this dataset.
Italiano.
I
commenti
al
codice
sor-
gente
forniscono
informazioni
utili
sull’implementazione del
codice e sulle
intenzioni
relative alle decisioni
e agli
scopi del progetto. Spesso, le informazioni
presenti
nel
commento di
un metodo e
nella sua implementazione possono non
essere
coerenti
(nel
senso che
il
com-
mento non d
`
a una descrizione adeguata
dell’implementazione).
Ci
possono es-
sere diverse spiegazioni
per
questo (ad
esempio, commenti e codice sorgente non
sono stati modificati in modo coerente). In
questo articolo,
presentiamo i risultati di
una valutazione manuale della coerenza
tra commenti e implementazione di
3
,
636
metodi,
raccolti
da
4
applicazioni
open
source
in Java.
I
risultati
di
questa
valutazione
sono
stati
raccolti
in
un
dataset
che abbiamo pubblicato sul
web.
Accenniamo anche al
protocollo seguito
per la preparazione del dataset.
1
Introduction
Natural language is used in different ways in the
development
process of
a software system and
therefore techniques of natural language process-
ing (NLP) and information retrieval (IR) are more
and more frequently integrated into software de-
velopment
and maintenance tools.
Many auto-
mated or
semi-automated techniques have been
proposed to aid developers
in the comprehen-
sion and in the evolution of
existing systems,
e.g., (Corazza et al., 2016; Scanniello et al., 2010).
Natural
language information is
provided in
source code comments and in the name of identi-
fiers. In the former case, standard natural language
is usually adopted, although quite technical. Com-
ments are written in English, even when develop-
ers have different
mother-tongues.
On the other
hand, identifiers are typically constructed by com-
posing multiple terms and abbreviations.
There-
fore, more sophisticated techniques are necessary
to extract the lexical information contained in each
identifier (Corazza et al., 2012).
Most of these techniques assume that the same
words are used whenever
referring to a partic-
ular
concept
(Lawrie et
al.,
2010).
In many
cases, this represents an oversimplification: meth-
ods are often modified without updating the cor-
responding comments (Salviulo and Scanniello,
2014). In these cases, comments might convey in-
formation unrelated or inconsistent with the cor-
responding implementation.
Nevertheless,
com-
ments are extremely important
because they are
CLIC_2016_Proceedings.indd 100
02/12/16 15.03
101
expected to convey the main intent behind design
decisions, along with some implementation details
(e.g., types of parameters and of returned values).
Therefore,
more sophisticated models are nec-
essary to determine if there is coherence between
the lexicon provided in comments and in its corre-
sponding source code.
Hence, there exists coher-
ence between a lead comment of a method and its
source code (also simply coherence, from here on)
if that comment describes the intent of the method
and its actual implementation.
In this work, we focus on the lead comment of
methods. This kind of comments precedes the def-
inition of a given method and is supposed to pro-
vide its documentation and details about the im-
plementation.
We discuss here a dataset we made
publicly available on the web.
1
It contains anno-
tations about the coherence of
3
,
636
methods col-
lected from
4
implementations of
3
open source
projects written in Java. The defined protocol used
for its creation is also sketched, to give researchers
the opportunity to possibly extend it.
Further de-
tails on this protocol can be found in (Corazza et
al., 2015).
For the assessment of the quality of the annota-
tion with special focus on computational linguis-
tics applications,
a few indexes have been con-
sidered (Eugenio and Glass,
2004;
Artstein and
Poesio,
2008; Mathet et al.,
2015),
among which
the kappa index (Cohen, 1960) is the most widely
adopted because of
its favorable characteristics.
The inter-annotator agreement has therefore been
assessed by this parameter.
We expect
that
making freely available this
dataset could give impulse to the research for ap-
proaches to assess the coherence between the im-
plementation of a method and its lead comment
(simply coherence,
from here on).
In fact,
al-
though no approach has been yet proposed in this
regard,
they could be of great
help for software
maintenance and evolution activities.
The paper is structured as follows. In Section 2,
we discuss the methodology used to create our
dataset.
A description of the main characteristics
of the dataset is given in Section 3, while in Sec-
tion 4 the annotation is assessed.
Some final con-
siderations conclude the paper.
1
www2.unibas.it/gscanniello/coherence/
2
Dataset Construction
To create our dataset, we adopted the perspective-
based
and
the
checklist-based
review meth-
ods (Wohlin et al.,
2012).
The perspective is the
one of the Researcher aiming at assessing the co-
herence between the lead comment
of a method
and its implementation. The process of creation is
based on the following elements:
1.
Working Meetings. We used meetings to de-
termine the goals of our research work and
the process to create the dataset.
2.
Dataset Creation.
We instantiated the de-
fined process to create our dataset.
3.
Outcomes.
We gathered results during and
after the creation of our dataset.
4.
Publishing
Results
and
Dataset.
We
shared our
experience with the community
in (Corazza et
al.,
2015)
and released the
dataset on the web.
The construction of the dataset has been com-
pleted in two main consecutive phases by using an
ad-hoc web system implemented for the purpose:
•
Verify coherence.
Annotators
verify by
means of a checklist the coherence between
the lead comments of a set
of methods and
their corresponding implementation.
•
Resolve conflicts.
The intervention of ex-
perts is required whenever the judgements of
the annotators differ.
In our case, two of the
authors, with a background in software engi-
neering, assumed the role of experts and ex-
amined the problematic cases.
For each con-
flicting method,
the experts should reach an
agreement
about
the coherence or the non-
coherence.
Methods on which experts do not
get a consensus are automatically discarded.
3
Dataset Description
Some descriptive statistics (e.g., number of classes
and methods)
of
the
software
systems
in our
dataset are shown in Table 1.
•
CoffeeMaker
2
is a software to manage in-
ventory and recipes and to purchase bever-
ages.
We chose this software because it has
2
agile.csc.ncsu.edu/SEMaterials/
tutorials/coffee_maker/
CLIC_2016_Proceedings.indd 101
02/12/16 15.03
102
Table 1: Descriptive statistics of the software sys-
tems in the dataset:
N
f
stands for the number of
files,
N
c
for the number of classes,
N
m
for the
number
of
methods and
N
∗
m
for
the number
of
methods with lead comments.
System
Version
N
f
N
c
N
m
N
∗
m
CoffeeMaker
-
7
7
51
47 (92%)
JFreeChart 6.0
0.6.0
82
83
617
485 (79%)
JFreeChart 7.1
0.7.1
124
127
807
624 (77%)
JHotDraw
7.4.1
575
692
6414
2480 (39%)
a simple and clear design (being it developed
for educational purposes).
•
JFreechart
3
is a Java tool supporting the vi-
sualization of data charts (e.g.,
scatter plots
and histograms).
We included two versions
of
this software.
As reported in Table 1,
both these versions contain almost
the
80%
of methods with lead comments.
This sug-
gests an extensive use of comments, which is
the main reason why we decided to include
this software in the dataset.
•
JHotDraw
4
is a framework for technical and
structured graphics.
Even if the source code
of JHotDraw is scarcely commented (see Ta-
ble 1), it is well-known in the software main-
tenance community due to its good Object-
Oriented design (Scanniello et al., 2010).
In
Figure
1,
we
report
the
imple-
mentation
and
the
lead
comment
of
setTickLabelsVisible
(extracted
from
JFreeChart
ver.
0.7.1,
included in our dataset).
According to our
definition of
coherence,
we
can assert
that
this method is coherent.
On the
other hand, the save method reported in Figure 2
provides
a
very poor
and inadequate
descrip-
tion of
the design intent
of
the method,
thus
reflecting a lack of coherence with the underlying
implementation.
Three annotators were involved in the dataset
creation process.
Two of them hold a Bachelor
degree in Computer Science,
and have very sim-
ilar technical
backgrounds.
On the other hand,
the third annotator can be considered more expe-
rienced than the other two since he holds a Master
degree in Computer Science.
We distributed the
effort among the annotators so that each software
3
www.jfree.org/jfreechart/
4
www.jhotdraw.org/
/
**
*
Sets the flag that determines whether or not
*
the tick labels are visible.
*
Registered listeners are notified of a
*
general change to the axis.
*
*
@param flag The flag to set.
*
/
public void setTickLabelsVisible(boolean flag) {
if (flag!=tickLabelsVisible) {
tickLabelsVisible = flag;
notifyListeners(new AxisChangeEvent(this));}
}
Figure 1: The lead comment and the implementa-
tion of the method setTickLabelsVisible
of JFreeChart 0.7.1
// GEN-FIRST:event_save
// Code for dispatching events from components
// to event handlers.
private void save(java.awt.event.ActionEvent evt) {
try {
String methodName = getParameter("datawrite");
if (methodName.indexOf(’(’) > 0) {
methodName = methodName.substring(0,
methodName.indexOf(’(’) - 1); }
JSObject win = JSObject.getWindow(this);
Object result = win.call(methodName, new
Object[]{getData()});
} catch (Throwable t) {
TextFigure tf = new TextFigure("Fehler: " + t);
AffineTransform tx = new AffineTransform();
tx.translate(10, 20);
tf.transform(tx);
getDrawing().add(tf); }
}
Figure 2: Non-Coherent method in
JHotDraw 7.4.1
would be separately evaluated by at least two an-
notators.
This allowed us to have multiple judge-
ments for each method in the dataset,
and to cal-
culate the rate of agreement among annotators.
4
Annotation Assessment
The whole dataset creation process occurred from
January,
15
th
2014 to June,
20
th
2014,
for a to-
tal of 800 man-hours.
This gives an estimation of
the effort required to conduct the study presented
in this paper, and provides an indication to the re-
searcher interested in extending our dataset.
The
annotators
provided indications
on the
coherence
of
methods
by assigning them one
out
of
three
following possible
values:
Non-
Coherent, Don’t Know, and Coherent.
In this scenario, we use the kappa index (Cohen,
1960) to obtain an assessment
of the agreement
among annotators,
thus estimating the reliability
of their evaluations.
In fact,
if annotators agree
on a large number of methods,
we can conclude
CLIC_2016_Proceedings.indd 102
02/12/16 15.03
103
that their annotations are reliable. The kappa index
is designed for categorical
judgments and refers
the agreement rate calculation to the rate of chance
agreement:
kappa
=
p
o
−
p
c
1
−
p
c
,
(1)
p
o
is the observed probability of agreement, while
p
c
is the chance probability of agreement.
Both
probabilities are estimated by the corresponding
frequencies.
By a simple algebraic manipulation,
Equation 1 can be written as:
kappa
= 1
−
q
o
q
c
,
(2)
where
q
o
= 1
−
p
o
and
q
c
= 1
−
p
c
and corre-
spond to the observed and the chance probabili-
ties of disagreement, respectively.
Usually the in-
dex assumes values in
]0
,
1]
5
, as it can be expected
that the observed disagreement is less likely than
chance.
A null
value signals that
observed dis-
agreement is exactly as likely as chance, while the
kappa index assumes negative values in the un-
wanted case where disagreement
is more likely
than chance.
Perfect
agreement
corresponds to
k
= 1
.
Values greater
than
0
.
80
are usually
considered as a cue of good agreement.
Values
in the interval
[0
.
67
,
0
.
80]
are considered accept-
able (Cohen, 1960).
The classical
formulation of
the kappa index
considers
a binary classification problem (e.g.,
Non-Coherent or Coherent). However in our case,
the neutral
judgement
(i.e.,
Don’t
know) is also
allowed.
Therefore,
possible disagreements in-
clude the case where one of the two answers is
the neutral one.
In this case,
it is possible to dif-
ferently weigh the possible disagreements among
annotators.
In fact, disagreements due to the neu-
tral
answers are less serious than disagreements
where judgments are totally divergent
(i.e.,
Co-
herent
and Non-Coherent,
in our case).
To this
end, Cohen (Cohen, 1968) presents a variant of the
kappa index, where in case of a disagreement, dif-
ferent
weights can be applied.
In case the same
weight
is assigned to all
possible disagreement
combinations, the original (unweighted) formula-
tion is obtained.
The formulation of the Weighted
Kappa (WK) is the one in the equation (2), but for
the computation of
q
o
and
q
c
the contributions are
5
The notation means that
1 is included in the interval,
while 0 is not.
Table 2:
Agreement Rate of Judges as computed
by the Cohen’s Kappa Index.
System
UK
WK
CoffeeMaker
0.913
0.913
JFreeChart 6.0
0.939
0.918
JFreeChart 7.1
0.983
0.977
JHotDraw
0.824
0.684
weighted according to the importance given to the
corresponding disagreement
cases.
By contrast,
we refer to the original formulation of the kappa
index as Unweighted Kappa (UK).
We assign to
the Don’t know response a weight that is half the
weight
assigned to the Not-Coherent
(or Coher-
ent) one.
This is the same schema reported by
Cohen (Cohen, 1968).
Weighted and Unweighted
kappa indexes are reported in Table 2.
The agreement between annotators is good on
the first
three systems,
and acceptable for JHot-
Draw.
However, on this system the difference be-
tween the values for UK and WK is large,
thus
providing a more accurate indication on the agree-
ment of the evaluations on this software.
At
the end of the first
step of the dataset
cre-
ation process,
the number of methods on which
annotators did not agree was
302
,
corresponding
to the
8
.
3%
of the total number of methods from
all the systems in the dataset. Most of these meth-
ods are those in JHotDraw,
as suggested by the
kappa index values (see Table 2).
These methods
were reviewed by two of the authors.
An agree-
ment was reached on all of these methods, which
were then included in the dataset.
The total num-
ber of methods in the dataset is reported in Table 3
(i.e.,
2
,
883
).
5
Conclusions and future work
In this paper,
we have presented the early steps
of our research on the coherence between the lead
comment
of methods and their implementations.
In particular,
we have provided a description of
the problem settings, along with the experimental
protocol defined to create our dataset.
We made it
publicly available on the web.
We also sketched
the results of quantitative analysis conducted on a
codebase of
3
,
636
methods, gathered from
4
dif-
ferent open-source systems written in Java.
There could be many possible future directions
for our research.
For example,
it would be inter-
esting to conduct an empirical study to investigate
CLIC_2016_Proceedings.indd 103
02/12/16 15.03
104
Table 3:
Descriptive Statistics of the Dataset:
C
stands for Coherent, NC for Non-Coherent.
System
C
NC
Total
Don’t Know
(Not included)
CoffeeMaker
27
20
47
0
JFreeChart 6.0
406
55
461
24
JFreeChart 7.1
520
68
588
36
JHotDraw
762
1025
1787
693
Total
1715
1168
2883
the effect of maintenance operations on the coher-
ence for multiple versions of the same system.
As
a step forward in this future research direction, we
already included in the dataset two versions of the
JFreeChart system.
Our results and those by Fluri
et al.
(Fluri et al.,
2007) represent a viable start-
ing point.
Finally,
we would like to exploit
the
collected data as an evaluation set
to assess the
performance of approaches able to discern method
coherence.
References
Ron Artstein and Massimo Poesio.
2008.
Inter-coder
agreement for computational linguistics.
Computa-
tional Linguistics, 34(4):555–596, December.
J. Cohen.
1960.
A coefficient of agreement for nom-
inal
scales.
Educational
and Psychological
Mea-
surement, 20(1):37–46.
J.
Cohen.
1968.
Weighted kappa:
Nominal
scale
agreement provision for scaled disagreement or par-
tial credit.
Psychological Bulletin.
A. Corazza, S. Di Martino, and V. Maggio.
2012.
LIN-
SEN:
An efficient
approach to split
identifiers and
expand abbreviations.
In Proceedings of
Interna-
tional Conference on Software Maintenance,
pages
233–242.
IEEE Computer Society.
A. Corazza, V. Maggio, and G. Scanniello.
2015.
On
the coherence between comments and implementa-
tions in source code.
In 41st
Euromicro Confer-
ence on Software Engineering and Advanced Appli-
cations, EUROMICRO-SEAA 2015, Madeira, Portu-
gal,
August 26-28,
2015,
pages 76–83. IEEE Com-
puter Society.
A.
Corazza,
S.
Di Martino,
V.
Maggio,
and G.
Scan-
niello.
2016.
Weighing lexical
information for
software clustering in the context of architecture re-
covery.
Empirical Software Engineering, 21(1):72–
103.
Barbara Di
Eugenio and Michael
Glass.
2004.
The
Kappa statistic:
a second look.
Computational Lin-
guistics, 30(1).
B.
Fluri,
M.
Wursch,
and H.C.
Gall.
2007.
Do code
and comments co-evolve?
on the relation between
source code and comment changes.
In Proceedings
of the Working Conference on Reverse Engineering,
pages 70–79. IEEE Computer Society.
D Lawrie,
D Binkley,
and C Morrell.
2010.
Normal-
izing Source Code Vocabulary.
In Proceedings of
Working Conference on Reverse Engineering, pages
3–12.
IEEE Computer Society.
Yann Mathet,
Antoine Widl
¨
ocher,
and Jean-Philippe
M
´
etivier.
2015.
The unified and holistic method
gamma
γ
for inter-annotator agreement measure and
alignment.
Computational
Linguistics,
41(3):437–
479, September.
F.
Salviulo and G.
Scanniello.
2014.
Dealing
with identifiers and comments in source code com-
prehension
and
maintenance:
Results
from an
ethnographically-informed study with students and
professionals.
In Proceedings of International Con-
ference on Evaluation and Assessment
in Software
Engineering, pages 423–432. ACM Press.
G.
Scanniello,
A.
D’Amico,
C.
D’Amico,
and
T. D’Amico.
2010.
Using the kleinberg algorithm
and vector space model
for software system clus-
tering.
In Proceedings of International Conference
on Program Comprehension, pages 180–189. IEEE
Computer Society.
C.
Wohlin,
P.
Runeson,
M.
H
¨
ost,
M.C.
Ohlsson,
B.
Regnell,
and A.
Wessl
´
en.
2012.
Experimenta-
tion in Software Engineering.
Computer Science.
Springer.
CLIC_2016_Proceedings.indd 104
02/12/16 15.03
105
Parsing di corpora di apprendenti di italiano: 
un primo studio su VALICO 
Elisa Corino
1
Università di Torino 
elisa.corino@unito.it 
Claudio Russo 
Università di Torino 
clrusso@unito.it 
Abstract 
English
. Modern learner corpora are 
now routinely PoS tagged, whereas syn-
tactic parsing is 
much less frequent. 
This paper proposes a first attempt of 
parsing applied to a subcorpus of VAL-
ICO, in an effort to identify key ele-
ments to be further used to parse cor-
pora of Italian as a foreign language in 
a proper way. 
Italiano
. 
I moderni corpora di appren-
denti sono ormai abitualmente annotati 
per PoS. Meno frequente è invece il par-
sing sintattico delle varietà di apprendi-
mento. Questo contributo propone un 
primo tentativo di parsing applicato a 
un sottocorpus di VALICO, nel tentativo 
di individuare elementi chiave che pos-
sano servire a tracciare una rotta per 
l’etichettatura sintattica di corpora di 
italiano come lingua straniera/seconda 
(LS).
1
Introduzione 
È ormai prassi lemmatizzare e annotare i cor-
pora di apprendenti per Parts of Speech (PoS) e 
molti sono gli esempi di etichettatura degli er-
rori; non altrettanto diffuse sono invece le espe-
rienze di parsing e annotazioni sintattiche di 
learner corpora. 
Le ragioni sono molteplici, ma certamente ri-
conducibili all’estrema imprevedibilità e mar-
catezza che caratterizza l’interlingua degli ap-
1 
Il contributo è il risultato della collaborazione dei due autori; tuttavia a Elisa Corino vanno attribuiti i 
§§ 1, 2, 4 e 5; a Claudio Russo il § 3. Si ringraziano Cristina Bosco e Alessandro Mazzei per il prezioso aiuto e 
per aver messo a nostra disposizione gli strumenti elaborati dal loro gruppo di ricerca. 
prendenti. Nonostante la complessità dell’ope-
razione, 
che 
richiede 
necessariamente 
una 
buona dose di intervento manuale, il parsing di 
un 
learner corpus
può avere ricadute positive in 
più di un ambito: oltre al contributo per i conte-
sti che si occupano in modo precipuo di lingui-
stica 
computazionale, 
esso 
diventa 
estrema-
mente utile per le ricerche su acquisizione e ap-
prendimento, perché permette 
di individuare 
più facilmente errori, deviazioni dalla norma e 
distribuzione di categorie e strutture sintattiche 
altrimenti difficili da far emergere interrogando 
un corpus etichettato unicamente per parti del 
discorso. 
Applicare processi di parsing alle varietà di ap-
prendimento non è certo una novità: il tratta-
mento sintattico delle interlingue degli appren-
denti è da tempo il focus di sistemi di Computer 
Assisted Language Learning (CALL) e Intelli-
gent Language Tutoring Systems (ILTS) (Van-
deventer Faltin, 2003; Heift & Nicholson, 2001; 
Amaral & Meurers, 2011). In questi casi la vio-
lazione delle regole sintattiche, come ad esem-
pio il mancato accordo tra soggetto e verbo, di-
venta spia della presenza di un errore da segna-
lare a chi produce il testo. Menzel & Schröder 
(1999) usano parametri che descrivono le di-
pendenze all’interno delle lingue degli appren-
denti, alle quali vengono applicati vincoli pesati 
e procedimenti di 
robust parsing
per definire la 
deviazione dalla norma. 
La distanza da strutture canoniche e non mar-
cate va tuttavia definita a partire da uno stan-
dard al quale le varietà di apprendimento ven-
gono ricondotte. Ecco perché il parser del 
lear-
ner corpus
deve essere preliminarmente appli-
cato ad un corpus di nativi – possibilmente com-
parabile a quello degli apprendenti. Una prassi 
CLIC_2016_Proceedings.indd 105
02/12/16 15.03
106
diffusa è poi quella di riportare le occorrenze er-
rate ad una forma target, un procedimento ma-
nuale in genere usato da quei learner corpora 
annotati anche per errori. Alcuni tentativi sono 
stati fatti fino ad ora soprattutto per il tedesco 
(Nivre et al., 2007, Lüdeling 2008, Ott & Zai 
2010), ma il terreno pare ancora inesplorato per 
quanto riguarda il panorama italiano. 
Questo contributo si propone come un primo 
tentativo di applicare procedure di parsing a un 
corpus di apprendenti di italiano come lingua 
straniera, per definirne criticità e vantaggi sia 
dal punto di vista computazionale, sia rispetto 
allo studio delle varietà di apprendimento. 
In particolare verranno presi in considera-
zione alcuni dati estratti dal corpus VALICO
2
, 
selezionati a partire da sottocorpora definiti in 
base alla L1 degli apprendenti. Per questo stu-
dio pilota si è scelto di comparare i risultati del 
trattamenti di testi di apprendenti ispanofoni e 
germanofoni, con l’intento di individuare pecu-
liarità sintattiche delle interlingue di discenti 
provenienti da lingue tipologicamente diverse: 
tipicamente romanza – e quindi vicina all’ita-
liano l’una, rappresentativa dell’area germanica 
l’altra. Sono stati sottoposti al parser 12 testi 
(quattro per ciascuna delle prime tre annualità 
di studio di italiano) estratti in modo casuale dal 
sottocorpus germanofono e 12 testi derivati dal 
sottocorpus ispanofono, secondo gli stessi cri-
teri di selezione. Per il gruppo tedesco sono 
state processate in totale 126 frasi, per il gruppo 
spagnolo 78. 
Fine ultimo è stabilire quali deviazioni dalla 
norma dell’uno e dell’altro gruppo non sono eti-
chettate correttamente, in modo da tracciare un 
percorso che possa portare alla definizione di 
regole di etichettatura per allenare il parser e 
migliorarne le prestazioni su questa varietà di 
lingua. 
VINCA, il corpus di nativi appaiato a VA-
LICO, servirà da corpus di riferimento per il 
parser a dipendenze sviluppato tra gli strumenti 
del Turin University Linguistic Environment 
(TULE). 
2
Il corpus VALICO 
VALICO è un corpus di scritti di apprendenti di 
italiano 
LS 
liberamente 
consultabile 
online 
(Marello et al. 2011, Marello & Corino i.s.), eti-
chettato per PoS con il TreeTagger dell’IMS di 
2
Varietà di Apprendimento Lingua Italiana Corpus 
Online, liberamente consultabile all’indirizzo 
www.valico.org. 
Stoccarda e codificato 
in CQP (Heid 2007, 
2009). 
L’architettura del corpus permette di appli-
care le query a sottosezioni selezionate in base 
ai metadati contenuti nella 
Header
, inseriti in 
una base dati (Colombo i.s.), tra questi la L1 de-
gli apprendenti, l’annualità di studio di italiano, 
il luogo di produzione del testo, le altre LS co-
nosciute. 
Gli stimoli iconici dai quali è stato elicitato 
VALICO sono le stesse vignette somministrate 
agli autori di VINCA
3
; i due corpora sono 
quindi appaiati e comparabili per lessico, strut-
ture sintattiche, organizzazione testuale (Corino 
& Marello 2009), si veda ad esempio la somi-
glianza tra (1a) e (1b) in relazione alla Fig. 1: 
Fig. 1 
(1a) […] la donna , arrabbiata , impreca contro di 
me dicendomi che quello che avevo appena pic-
chiato è il suo ragazzo ! [VINCA] 
(1b) Ha cominciato a sgridarme 
per farle una 
brutta passata e quello che riteneva molto grave era 
che avevo picchiato al suo ragazzo. [VALICO, L1 
Spagnolo] 
VINCA si presta quindi a fungere da corpus 
di controllo e modello per il parsing di VA-
LICO. 
In questa prima fase esplorativa delle moda-
lità di etichettatura sintattica del corpus, è stato 
deciso di non ricorrere a ipotesi esplicite sul tar-
get 
delle 
produzioni 
degli 
apprendenti, 
così 
come avviene invece per altri learner corpora 
(ad es. FALKO, Lüdeling et al 2012). L’unica 
operazione di riconduzione a forme standard è 
stata fatta per identificare PoS e lemma di les-
semi scorretti dal punto di vista ortografico, 
forme “creative” sia dal punto di vista lessicale 
che morfologico. 
Già le forme segn
alate dal TreeTagger come 
unknnown
erano state corrette manualmente e 
ricondotte a PoS e lemma appropriato in rela-
zione anche al co-testo nel quale esse occorre-
vano. Infatti è possibile interrogare VALICO, 
nella sua attuale forma, per lemmi e ottenere an-
che quelle occorrenze che morfologicamente 
3
www.valico.org/vignette 
CLIC_2016_Proceedings.indd 106
02/12/16 15.03
107
non rispondono alla norma linguistica standard 
(ad es. cercando il lemma 
minacciare
otteniamo 
sì forme quali 
minacciano
, 
minacciato
, 
minac-
cia
, ma anche 
minaccava
e 
minaciò
). 
3
Dal PoS tagging al parsing 
Il lavoro di disambiguazione e correzione degli 
unknown
rilevati dal TreeTagger è tutt’ora in 
corso, anche se buona parte di essi sono già stati 
corretti e ad oggi tokenizzazione, PoS tagging e 
lemmatizzazione del corpus sono piuttosto affi-
dabili. 
Per questo primo tentativo di parsing del cor-
pus si è tuttavia deciso di affidarsi – anche per 
la fase di PoS tagging 
- agli strumenti 
del 
TULE: un analizzatore morfologico, un toke-
nizzatore e un parser a dipendenze: tale scelta è 
giustificata dalla natura dei moduli del TULE, 
che, in quanto costituiti da regole di disambi-
guazione, non si avvalgono di addestramneti 
stocastici; 
in 
tale 
cornice, 
la 
preferenza 
del 
POS-tagger di TULE all'etichettatura già pre-
sente in VALICO ha permesso al paser di lavo-
rare in condizioni ottimali, massimizzandone la 
precisione. Un’indagine a campione ha fatto 
emergere errori simili per entrambi gli stru-
menti, si veda ad esempio l’etichettatura della 
forma 
dona 
nella frase 
è andato in freta ha ra-
giungere la sua dona è poi a preso questo uomo 
le ha fato male
(= donna, NOME), impropria-
mente riconosciuta come imperativo verbale da 
entrambi 
dona 
(DONARE 
VERB 
MAIN 
IND 
PRES 
TRANS 3 SING) 
TULE 
dona/VER:impe/donare è/VER:pres/essere 
TreeTagger 
L’integrazione dei materiali già elaborati per 
il corpus e gli strumenti di parsing sarà necessa-
riamente il prossimo passo nello sviluppo di 
questa ricerca ed eviterà di dover intervenire an-
che su forme che già sono state corrette nel pro-
cessamento del corpus con il TreeTagger, si 
veda ad esempio 
fidansato (FIDANSATO / NOUN COMMON M 
SING) 
VALICO TULE 
fidansato (/NOM/fidanzato) 
VALICO 2016 
Eliminerà inoltre a priori alcuni errori di anno-
tazione sintattica e impedirà la generazione di 
4 
Si rimanda Lesmo (2009 e 2011) per la trattazione 
approfondita dell'implementazione del TULE. 
errori dovuti al mancato riconoscimento delle 
forme “unknown” che bloccano la sequenza di 
processamento dei dati. 
Ai fini del presente studio, è interessante sot-
tolineare poi che il tokenizzatore qui utilizzato 
si basa su un automa deterministico a stati finiti 
che risulta robusto su sequenze di caratteri ap-
partenenti a diverse lingue (tra cui rientrano in-
glese, spagnolo, hindi e italiano). Tale stru-
mento compie una prima distinzione fra parole 
in generale (qui intese come sequenze di carat-
teri alfabetici), nomi propri, abbreviazioni/si-
gle, numeri in cifre, date in formati standard, se-
gni di interpunzione, numerazioni di capitoli e 
paragrafi, anni (nelle forme contratte come '05 
per 2005). Nella fase successiva di trattamento, 
il parsing si basa su una gerarchia precompilata 
di classi trasformate per generare gli alberi sin-
tattici
4
. 
3.1
I dati di imprevedibilità morfosintat-
tica 
Le peculiarità dei dati linguistici sottoposti al 
parser hanno, come previsto, originato una serie 
di errori che hanno bloccato la sequenza di pro-
cessamento in più momenti. I problemi non na-
scono soltanto in relazione alla flessione ver-
bale o nominale, ma emergono anche laddove 
occorre un accumulo di clitici unitamente a 
forme ortografiche che deviano dalla norma. Si 
veda ad esempio la frase 
(2) […], ma la ragazza bella è stata averecela. 
Il verbo 
avere
cliticizzato ha reso impossibile 
la disambiguazione e il tagging, anche a seguito 
della normalizzazione ortografica e di alcune 
progressive semplificazioni. È stato quindi ne-
cessario sostituire il token direttamente con il 
suo lemma, per permettere al TULE di proce-
dere con il PoS tagging e, successivamente, con 
il parsing sintattico. 
Fortunatamente, 
nei 
sottocorpora 
di 
VA-
LICO qui considerati, tali errori si sono rivelati 
in quantità limitata: oltre al caso di 
avercela
, 
sono state normalizzate in 
È
tutte le istanze di 
E'
e una istanza di 
glielo
è stata normalizzata in 
lui
5
, in un atto di correzione purtroppo invasivo 
e in futuro auspicabilmente evitabile. 
5
La frase originale recitava: “Il fratellino di Leo 
non capiva perchè e così lei ha spiegato glielo.” 
CLIC_2016_Proceedings.indd 107
02/12/16 15.03
108
4
Prime 
osservazioni 
linguistiche: 
il 
gerundio e le preposizioni 
Una prima verifica sull’etichettatura dei testi fa 
emergere due ordini ricorrenti di problemi che 
paiono essere indipendenti dalla L1 degli ap-
prendenti: il primo è legato ad un uso peculiare 
del gerundio, assimilabile alle funzioni attribu-
tive delle participiali inglesi (fonte di interfe-
renza per gli ispanofoni) e tedesche; l’altro di-
pende dalla presenza di preposizioni in posi-
zione postverbale laddove invece il target ri-
chiede l’oggetto diretto. 
L’uso anomalo del gerundio, come esempli-
ficato da (2) e (3), pare ricalcato sulla struttura 
attributiva tipicamente inglese (participiale con 
la forma in -
ing
), ma possibile anche in tedesco, 
dove 
il 
participio 
specifica 
la 
condizione 
dell’antecedente dal quale dipende. 
(2) Ieri al parco mio fratello stava leggendo il 
giornale quando ha visto un uomo portando una 
donna sopra i suoi ombrelli 
[L1 Spagnolo] 
Fig. 2 Rappresentazione del segmento 
visto un 
uomo portando una donna sopra i suoi ombrelli 
(3) Ieri al parco Giacomo è stato seduto sopra un 
banco nel parco e ha letto il giornale dello sport 
quando ha visto un uomo portando una donna che ha 
gridato molto forte. 
[L1 
Tedesco] 
Fig. 3 Rappresentazione del segmento 
quando ha 
visto un uomo portando una donna che ha gridato
6
Le rappresentazioni degli alberi sintattici sono 
state generate dal software viewerTULE, imple-
mentato da L. Robaldo. 
Come si osserva nelle Figg. 2-3
6
, in entrambi 
casi il gerundio fa parte di una proposizione cir-
costanziale (RMOD) al quale è attribuito un 
soggetto non espresso dalla struttura superfi-
ciale. E
tichettare una serie di istanze verbali 
ravvicinate come entità circostanziali è un risul-
tato che certo non sorprende; in casi come que-
sti, tuttavia, il gerundio è il risultato di un’inter-
ferenza molto frequente nel corpus e non codi-
fica la struttura rilevata dal parser. 
La forma che meglio rispecchia in italiano la 
sfumatura attributiva dell’originale che ha cau-
sato il transfer è la frase relativa, pur conside-
rando anche l’infinitiva come un’opzione possi-
bile. 
In VINCA effettivamente troviamo nume-
rose occorrenze che descrivono la stessa situa-
zione (si veda ad es. (4)), codificata in una rela-
tiva, e che come tali sono correttamente segna-
late (VERBO-RMOD+RELCL, Fig. 3) 
(4) Ieri al parco stavo leggendo il giornale, seduto 
su una panchina quando vedo passare davanti a me 
un energumeno che trascina a forza una donna sulle 
spalle. [VINCA] 
Fig. 4 Rappresentazione della frase relativa 
un 
energumeno che trascina a forza una donna sulle 
spalle
Una seconda importante causa di errore di 
etichettatura 
sintattica 
è 
la 
sovraestensione 
dell’uso delle preposizioni anche a quei casi in 
cui il verbo richiede l’oggetto diretto. (5) ne è 
un esempio emblematico: 
(5) Per quello, il ragazzo di occhiali ( che stava a 
un banco del parco) va golpeare al brutto ragazzo per 
liberare a la ragazza di bricci dil ragazzo che la por-
tava. [L1 Spagnolo] 
In casi come 
va a golpeare al brutto ragazzo
, 
il parser interpreta come VERB-INDCOMP-
LOC+TO il sintagma preposizionale, che in-
vece dovrebbe essere ricondotto a un comple-
mento diretto 
CLIC_2016_Proceedings.indd 108
02/12/16 15.03
109
Fig. 5 Rappresentazione del segmento 
va a gol-
peare al brutto ragazzo
Tuttavia non si tratta di un comportamento 
consistente, poiché emergono anche casi come 
(6), in cui invece l’etichettatura è corretta (Fig. 
6), 
nonostante 
l’agrammaticalità 
dell’enun-
ciato. 
(6) Lui stava contentissimo perche pensava che 
cossì aveva aiutato a la povera donna. 
[L1 
Spagnolo] 
Fig. 6 Rappresentazione del segmento 
aveva aiu-
tato a la povera donna
L’identificazione corretta della relazione sin-
tattica sembra essere dovuta alla semantica del 
verbo e alla capacità del TULE di lemmatizzare 
correttamente la forma. 
5
Conclusioni provvisorie e futuri svi-
luppi 
L’esperienza maturata in questa prima fase del 
percorso di ricerca e implementazione del par-
sing sul corpus di apprendenti VALICO ha per-
messo di mettere in luce vantaggi e criticità de-
gli strumenti utilizzati. 
Dal punto di vista computazionale è emerso 
come sia necessario integrare risorse e definire 
“protocolli di allenamento” del parser orientati 
al trattamento di quella varietà particolare di lin-
gua che è l’interlingua di apprendenti. 
Una valutazione qualitativa ha mostrato che 
errori causati dall’omissione di elementi sintat-
tici chiave per la definizione delle dipendenze 
porta a errori nella stessa etichettatura, così 
come avviene in occasione della sovraesten-
sione di alcune forme a funzioni che esse non 
rivestono, o ancora della sinergia negativa tra 
forme morfologicamente complesse ed errori 
ortografici; altri errori invece sono trattati in 
modo aproblematico. 
Le difficoltà di gestione dei sintagmi prepo-
sizionali e fenomeni diffusi di transfer lingui-
stico soprattutto a livello di sistema verbale ri-
velano come l’individuazione di tendenze e la 
definizione 
di 
alcune 
indicazioni 
sul 
tratta-
mento di tali costruzioni potrebbero incremen-
tare notevolmente la precisione dell’etichetta-
tura automatica. 
Rispetto alla definizi
one di un’architettura 
che integri il parsing sintattico al PoS tagging, è 
necessario elaborare una chiara proposta di de-
finizione di regole di etichettatura; inoltre resta 
da stabilire se sia veramente necessario alli-
nearsi alle scelte operate per altri 
learner cor-
pora
in cui viene definita un’ipotesi target che 
segna la struttura obiettivo della produzione 
dell’apprendente e ne mette in luce la distanza 
dalla versione effettivamente riportata nel cor-
pus. 
Bibliografia 
Amaral, L.; Meurers, D.(2011). On Using Intelligent 
Computer-Assisted Language Learning in Real-
Life Foreign Language Teaching and Learning. 
ReCALL 
23(1), 
4–24. 
URL 
http://purl.org/dm/papers/amaral-meurers-
10.html. 
Colombo, S. (in stampa). Storia dell’architettura di 
VALICO. In E. Corino, C. Marello, VALICO e 
VINCA: 
corpora 
di 
apprendenti 
di 
italiano, 
Guerra, Perugia. 
Corino, E.; Marello, C. (2009). Elicitare scritti a Par-
tire da storie disegnate: il corpus di apprendenti 
Valico. In C. Andorno, S. Rastelli (a cura di), Cor-
pora di Italiano L2: Tecnologie, metodi, spunti 
teorici, Perugia: Guerra. 
Dickinson, M.; Ragheb, M. (2009). Dependency An-
notation for Learner Corpora. In Proceedings of 
the Eighth Workshop on Treebanks and Linguis-
tic Theories (TLT-8). 
Heid, U. (2007). Il corpus WorkBench come stru-
mento per la linguistica dei corpora. Principi ed 
applicazioni’ in M. Barbera, E. Corino, C. Onesti 
(a cura di) (2007), 
Corpora e linguistica in rete
. 
Guerra, Perugia, pp. 89-108. 
Heid, U. (2009). Metadata for learner corpora. A 
case study on VALICO. In E. Corino, C. Marello 
(a cura di), VALICO. Studi di linguistica e didadt-
tica. Perugia: Guerra, 151-165. 
Heift, T; Nicholson, D. (2001). Web Delivery of 
Adaptive and Interactive Language Tutoring. 
In-
ternational Journal of Artificial Intelligence in 
Education 
12(4), 310–325 
CLIC_2016_Proceedings.indd 109
02/12/16 15.03
110
Lesmo, L. (2009). The Turin University Parser at 
Evalita 2009. In: Proceedings of Evalita '09, Reg-
gio Emilia, Italy. 
Lesmo, L. (2011). Use of semantic information in a 
syntactic 
dependency 
parser. 
In 
Magnini 
B., 
Cutugno F., Falcone M., Pianta E. (eds) "Evalua-
tion of Natural Language and Speech Tools for 
Italian 
- 
Proceedings 
of 
Evalita 
2011". 
LNCS/LNAI, Springer-Verlag 
Lüdeling, A. et al. (2008). Syntactic Misuse, Over-
use and Underuse: A Study of a Parsed Learner 
Corpus and its Target Hypothesis 
Lüdeling, A. et al. (2012). Das Falko-Handbuch 
Korpusaufbau und Annotationen Version 2.01 
Marello, C. et al (2011). I corpora VALICO e 
VINCA: stranieri e italiani alle prese con le stesse 
attività scritte. In La Piazza delle lingue L’italiano 
degli altri. Firenze, 27-31 maggio 2010. Atti, a 
cura di Nicoletta Maraschio e Domenico De Mar-
tino, Firenze, Accademia della Crusca, 2011 (“La 
Piazza delle lingue”, 2). pp.49-61 
Menzel, W.; Schröder, I. (1999). Error Diagnosis for 
Language 
Learning 
Systems 
[http://citese-
erx.ist.psu.edu/viewdoc/down-
load?doi=10.1.1.34.4723&rep=rep1&type=pdf] 
Nivre et al., (2007). MaltParser: A Language-Inde-
pendent 
System 
for 
Data-Driven 
Dependency 
Parsing. 
Natural Language Engineering 
13(1), 1–
41. 
Ott, N.; Ziai, R. (2010). Evaluating Dependency 
Parsing Performance on German Learner Lan-
guage. In Proceedings of the Ninth Workshop on 
Treebanks 
and 
Linguistic 
Theories 
(TLT-9), 
Tartu. 
Vandeventer Faltin, A. (2003). Natural language 
processing tools for computer assisted language 
learning. 
In 
Linguistik 
online 
17, 
15/03 
[http://www.linguistik-
online.de/17_03/vandeventer.html] 
CLIC_2016_Proceedings.indd 110
02/12/16 15.03
111
Nystr
¨
om Methods for Efficient Kernel-Based Methods
for Community Question Answering
Danilo Croce
1
, Simone Filice
2
and Roberto Basili
1
1
Dept. of Enterprise Engineering
2
Dept. of Civil Engineering and Computer Science Engineering
University of Roma, Tor Vergata, Italy
{croce,filice,basili}@info.uniroma2.it
Abstract
English.
Expressive but
complex kernel
functions,
such as Sequence or Tree ker-
nels,
are usually underemployed in NLP
tasks,
e.g.,
in community Question An-
swering (cQA),
as
for
their
significant
complexity in both learning and classi-
fication stages.
Recently,
the Nystr
¨
om
methodology for data embedding has been
proposed as
a viable solution to scala-
bility problems.
By mapping data into
low-dimensional approximations of kernel
spaces,
it
positively increases scalability
through compact linear representations for
highly structured data.
In this paper,
we
show that
Nystr
¨
om methodology can be
effectively used to apply a kernel-based
method in the cQA task,
achieving state-
of-the-art results by reducing the compu-
tational cost of orders of magnitude.
Italiano.
Metodi
di
apprendimento
automatico
basato
su
funzioni
ker-
nel
complesse,
come
Sequence
o Tree
Kernel,
rischiano di
non poter
essere
adeguatamente
utilizzati
in
problemi
legati
all’elaborazione
del
linguaggio
naturale (come ad esempio in Community
Question Answering)
a causa degli
alti
costi computazionali per l’addestramento
e la classificazione.
Recentemente
´
e stata
proposta
una
metodologia,
basata
sul
metodo di Nystr
¨
om, per poter far fronte a
questi
problemi
di
scalabilit
´
a:
essa per-
mette di proiettare gli esempi, osservabili
in fase di addestramento e classificazione,
all’interno di spazi a bassa dimensionalit
´
a
che approssimano lo spazio sottostante
la funzione kernel.
Queste rappresen-
tazioni compatte permettono di applicare
algoritmi
di
apprendimento automatico
estremamente efficienti
e scalabili.
In
questo lavoro si dimostra che
´
e possibile
applicare metodi
kernel
al
problema di
Community
Question
Answering,
otte-
nendo risultati che sono lo stato dell’arte,
riducendo di
ordini
di
grandezza i
costi
computazionali.
1
Introduction
Kernel
methods
(Shawe-Taylor
and Cristianini,
2004)
have been employed in several
Machine
Learning algorithms (Crammer et al., 2006; Vap-
nik, 1998) achieving state-of-the-art performances
in many classification tasks.
Recently,
the kernel
based approach presented in (Filice et
al.,
2016)
has been applied in the community Question An-
swering (cQA) challenge at SemEval 2016 (Nakov
et al., 2016) obtaining state-of-the-art results.
Unfortunately, when large data volumes are in-
volved,
time and space complexity required in
learning and classification may prevent the adop-
tion of expressive but
complex kernel
functions,
such as Sequence (Cancedda et al., 2003) or Tree
kernels (Collins and Duffy,
2001).
In particular,
the classification cost required by a kernel-based
model crucially depends on its number of support
vectors: classifying a new instance requires a ker-
nel computation against all support vectors.
This
scalability issue is evident in many NLP and IR ap-
plications, such as in re-ranking answers in ques-
tion answering (Moschitti et al., 2007; Severyn et
al., 2013; Filice et al., 2016), where the number of
support vectors is typically very large.
Some approaches have been defined to bound
the complexity of kernel-based methods,
such as
(Wang and Vucetic, 2010; Vedaldi and Zisserman,
2012; Filice et al., 2014), but they are still specific
to kernel formulations and learning algorithms.
In (Croce and Basili,
2016) it has been shown
that
a viable and more general
solution to the
CLIC_2016_Proceedings.indd 111
02/12/16 15.03
112
above scalability issues is the Nystr
¨
om method-
ology,
a dimensionality reduction technique that
has been applied also in kernel-based methods
since (Williams and Seeger, 2001).
This method-
ology has been designed to approximate the Gram
Matrix derivable by a kernel
function,
enabling
the projections of examples into low-dimensional
spaces.
The Nystr
¨
om projection function is gen-
erated by using some examples called landmarks,
whose number directly impacts on the embeddings
quality; dually, costs of projecting a new example
in the embedding space rise linearly with the num-
ber of landmarks, that is usually of orders of mag-
nitude lower with respect
of the number of pos-
sible support
vectors that
can be derived from a
learning process.
Once each example is projected
in the dense low-dimensional space,
the applica-
tion of efficient linear learning methods is enabled,
such as (Hsieh et al., 2008), preserving at the same
time the expressiveness and effectiveness of ker-
nel methods.
This approach is highly applicable
to different input data as well as to different ker-
nels or learning algorithms, as discussed in (Croce
and Basili, 2016).
In this paper we show that the Nystr
¨
om method
can be effectively used in the cQA task, by adopt-
ing the same kernel functions proposed in (Filice
et al.,
2016) and obtaining the same results w.r.t.
the metrics adopted in the SemEval task, by reduc-
ing the computational cost of orders of magnitude.
In Section 2,
we demonstrate the viability of
the Nystr
¨
om method to reduce the computational
costs of
kernel
machines.
Experimental
results
(obtained by adopting efficient SVM learning over
the cQA task) are discussed in Section 3.
Finally,
Section 4 describes related work, while in Section
5 conclusions are derived.
2
Linearizing linguistic properties
through Nystr
¨
om Approach
Given an input
training dataset
o
i
∈ D
,
a kernel
function
K
(
o
i
, o
j
)
is a similarity function that cor-
responds to a dot
product
in the implicit
kernel
space,
i.e.,
K
(
o
i
, o
j
) = Φ(
o
i
)
·
Φ(
o
j
)
.
The ad-
vantage of kernels is that the projection function
Φ(
o
i
)
=
x
i
∈
R
n
is never explicitly computed
(Shawe-Taylor and Cristianini, 2004). In fact, this
operation may be prohibitive when the dimension-
ality
n
of the underlying kernel space is extremely
large.
For
example,
Tree Kernels (Collins and
Duffy, 2001) give rise to spaces whose number of
dimensions is proportional to the number of possi-
ble sub-trees in a Natural Language.
Kernel func-
tions are exploited by kernel-based learning algo-
rithms, such as SVM (Vapnik, 1998), to operate on
the implicit kernel space without its explicit defi-
nition.
Let
us assume that,
given a kernel
K
,
its ex-
plicit projection function
φ
over
D
is available to
derive new representations
x
i
being the rows of
the resulting matrix
X
.
We define the Gram Ma-
trix as
G
=
XX

, with each single element corre-
sponding to
G
ij
= Φ(
o
i
)Φ(
o
j
) =
K
(
o
i
, o
j
)
.
The
aim of the Nystr
¨
om method is to derive a new low-
dimensional embedding in a
l
-dimensional space,
with
l

n
so that
G
≈
˜
G
=
˜
X
˜
X

.
This is ob-
tained by generating an approximation of
G
using
a subset of
l
columns of the matrix.
This corre-
sponds to selecting a subset
L
of the available ex-
amples, called landmarks.
Suppose we randomly
sample
l
columns of
G
,
and let
C
be the
n
×
l
matrix of these sampled columns.
Then,
we can
rearrange the columns and rows of
G
and define
X
= [
X
1
X
2
]
such that:
G
=
XX

=

W
X

1
X
2
X

2
X
1
X

2
X
2

and
C
=

W
X

2
X
1

(1)
where
W
=
X

1
X
1
, i.e., the subset of
G
that only
considers landmarks. The Nystr
¨
om approximation
can be defined as:
G
≈
˜
G
=
CW
†
C

(2)
where
W
†
denotes the Moore-Penrose inverse of
W
.
The Singular
Value Decomposition (SVD)
is used to obtain
W
†
as it
follows.
First
W
is
decomposed so that
W
=
USV

where
U
and
V
are both orthogonal
matrices,
and
S
is a di-
agonal
matrix containing the (non-zero) singular
values of
W
on its diagonal.
Since
W
is sym-
metric and positive definite
W
=
USU

.
Then
W
†
=
US
−1
U

=
US
−
1
2
S
−
1
2
U

and the Equa-
tion 2 can be rewritten as
G
≈
˜
G
=
CUS
−
1
2
S
−
1
2
U

C

= (
CUS
−
1
2
)(
CUS
−
1
2
)

=
˜
X
˜
X

(3)
Given an input
example
o
i
∈ D
,
a new low-
dimensional
representation
˜
x
i
can be thus deter-
mined by considering the corresponding
i
-th item
of
C
as
˜
x
i
= Θ(
o
i
) =

c
i
US
−
1
2
(4)
CLIC_2016_Proceedings.indd 112
02/12/16 15.03
113
where

c
i
corresponds to a vector whose dimen-
sions contain the evaluation of the kernel
func-
tion between
o
i
and each landmark
o
j
∈
L
.
The
method produces
l
-dimensional vectors, and no re-
striction is applied to the input dataset as long as a
valid
K
(
o
i
, o
j
)
is used.
Several policies have been defined to determine
the best selection of landmarks to reduce the Gram
Matrix approximation error.
In this work the uni-
form sampling without replacement is adopted, as
suggested by (Kumar et al., 2012), where this pol-
icy has been theoretically and empirically shown
to achieve results comparable with other
(more
complex) selection policies.
Assuming that
k
is the computational cost
1
of
a single kernel operation,
the runtime cost of the
Nystr
¨
om method is
O
(
knl
+
l
3
+
nl
2
)
as it
de-
pends on (i)
the computation of
the
n
×
l
ma-
trix
C
,
i.e.,
O
(
knl
)
;
(ii) the SVD evaluation on
W
,
which is
O
(
l
3
)
;
and (iii)
the projection of
the entire dataset through the multiplication by
C
,
i.e.,
O
(
nl
2
)
.
For several classes of kernels,
such
as Tree or Sequence Kernels (Collins and Duffy,
2001),
the kernel
computation cost
is extremely
high.
Therefore,
the computational
cost
for the
construction of the matrix
C
dominates the overall
expression.
Once
an
example
is
projected
in
the
l
-
dimensional space, efficient and large-scale learn-
ing algorithm can be applied.
To further control
the computational cost of the training step, we ad-
dressed a class of algorithms that bounds the num-
ber of times a single instance is re-used during
training.
In particular,
we investigated the Dual
Coordinate Descent algorithm (Hsieh et al., 2008):
it is a batch learning algorithm whose achievable
accuracy is made inversely dependent on the num-
ber of iterations
T
over a training dataset. Its train-
ing time cost on a dataset of
n
examples in
R
l
is
O
(
T nl
)
.
Being fixed the number of iterations re-
quired to obtain an accurate model
2
,
such cost is
negligible w.r.t.
the projection cost.
Therefore,
a
complete training process exploiting the Nystr
¨
om
method is simply
O

kln
)
,
that
should be com-
pared with a traditional kernel-based SVM learn-
ing algorithm, e.g., (Chang and Lin, 2011), whose
computational cost is almost
O

kn
2
)
, with
l

n
.
The computational cost of a classification step
only depends on the projection of the example in
1
Expressed in terms of basic operations, such as products.
2
In (Croce and Basili,
2016)
a number
of
iterations
T = 30 obtained stable and accurate results in several tasks.
the new space, i.e.,
O

kl
)
.
In fact, once a test ex-
ample is projected, the final decision requires a dot
product between the low-dimensional representa-
tion
˜
x
i
and the hyperplane underlying the classi-
fication function: again, this is negligible with re-
spect
to the cost
of the single kernel
operations.
Such cost
is typically extremely lower
than the
cost
of a pure kernel-based classification,
which
requires a kernel operation againts all the support
vectors selected during the training process, which
is usually far larger than the number of landmarks.
3
Empirical Investigation: the
Community QA task
The proposed stratified Nystr
¨
om method has been
applied in the SemEval-2016 community Ques-
tion Answering (cQA) task.
In this task,
partici-
pants are asked to automatically provide good an-
swers in a community question answering setting
(Nakov et al., 2016).
In particular,
we focused on the Subtask A:
given a question and a large collection of question-
comment
threads created by a user
community,
the task consists in (re-)ranking comments that are
most useful for answering the question.
This task
is interesting as kernel methods achieved the high-
est
results in the cQA task,
as demonstrated by
the KeLP team (Filice et
al.,
2016).
In particu-
lar, Subtask A is modeled as a binary classification
problem,
where examples are generated by con-
sidering (question,comment) pairs. Each pair gen-
erates an example for a binary SVM,
where the
positive label is associated with a good comment
and the negative label
includes the potential and
bad comments.
The classification score is used
to sort
the instances and produce the final
rank-
ing.
According to the above setting,
a train and
test
dataset
made of 20,340 and 3,270 examples
are generated.
In (Filice et al.,
2016),
a Kernel-
based SVM classifier achieved state-of-the-art re-
sults by adopting a kernel
combination that
ex-
ploited (i)
feature vectors
containing linguistic
similarities between the texts in a pair; (ii) shallow
syntactic trees that encode the lexical and morpho-
syntactic information shared between text
pairs;
(iii) feature vectors capturing task-specific infor-
mation.
First,
a batch kernel-based SVM (Chang and
Lin,
2011)
learning algorithm operating on the
kernel
function proposed in (Filice et
al.,
2016)
is adopted to determine the upper bound in terms
CLIC_2016_Proceedings.indd 113
02/12/16 15.03
114
of classification quality (but
with higher compu-
tational costs).
Then,
multiple standard Nystr
¨
om
methods are used to linearize the dataset by sam-
pling different numbers of landmarks:
10 config-
urations have been investigated by starting from
100 landmarks
and incrementally adding 100
landmarks at a time.
The higher is the number of
used landmarks, the higher is the quality of the ap-
proximated low-dimensional
space (Drineas and
Mahoney, 2005), but the higher is also the compu-
tational cost.
The most complex projection func-
tion is thus based on 1,000 landmarks. Landmarks
have been selected by applying a random selec-
tion without replacement, as suggested in (Kumar
et al.,
2012).
An efficient linear SVM (Hsieh et
al.,
2008) is adopted on the resulting embedding
space.
Experiments have been carried out by us-
ing the KeLP framework
3
(Filice et al., 2015a).
Results
are reported in Table 1 in terms
of
Mean Average Precision (MAP,
the official
rank
of
the competition),
F
1
on the good class,
and
computational saving,
i.e.,
percentage of avoided
kernel
operations in classification.
The standard
SVM model contains 11,322 Support Vectors, thus
requiring more than 37M kernel
operations for
the complete classification of
the 3,270 test
in-
stances
4
.
By adopting the Nystr
¨
om methodol-
ogy with only 1,000 landmarks the same F
1
score
(i.e.,
64.4) is obtained.
Moreover,
a comparable
MAP (i.e.,
78.2%) achieved by the KeLP team is
replicated with a 91.2% of
saving.
The speed
up is impressive also when fewer landmarks are
used:
with 300 landmarks, 77.7 MAP is obtained
by saving more that 97% of kernel computations.
These results are straightforward, considering that
results comparable with the state-of-the-art can be
obtained by reducing of almost two orders of mag-
nitude the computational costs.
Overall, the MAP
obtained by the proposed approach is still higher
than the one achieved by all the other systems of
the challenge, including ConvKN (Barr
´
on-Cede
˜
no
et al., 2016) and SemanticZ (Mihaylov and Nakov,
2016), i.e., the second and third best systems, re-
spectively.
4
Related Work
Improving the efficiency of kernel-based methods
is a largely studied topic.
The reduction of com-
3
https://github.com/SAG-KeLP
4
The classification time was more than 3 hours and a half
on a standard machine with 4 cores i7-2600 3.4 GHz.
Table 1: Results in CQA. Upperbound is achieved
by a SVM with more than 37M kernel operations.
Landmarks
MAP
F1
Saving
100
76.0
58.6
99.1%
200
77.0
60.8
98.2%
300
77.5
62.2
97.4%
400
77.7
62.4
96.5%
500
77.9
63.1
95.6%
600
78.0
63.6
94.7%
700
78.1
63.7
93.8%
800
78.0
63.8
92.9%
900
78.1
64.2
92.1%
1000
78.2
64.4
91.2%
standard SVM
79.2
64.4
-
ConvKN
77.7
66.2
-
SemanticZ
77.6
61.8
-
putational
costs has been early designed by im-
posing a budget
in the number
of
support
vec-
tors (Cesa-Bianchi and Gentile,
2006;
Dekel and
Singer,
2006;
Orabona et
al.,
2008;
Wang and
Vucetic,
2010;
Filice et
al.,
2014).
However,
in complicated tasks,
such methods still
require
large budgets that
systematically rely on many
kernel computations.
They are thus less efficient
than Nystr
¨
om:
a classifier based on the Nystr
¨
om
method with
l
landmarks has approximately the
same computational
complexity of
its budgeted
counterpart with a budget set to
l
, but its accuracy
is typically higher, as shown in (Croce and Basili,
2016).
Alternatively, Zanzotto and Dell’Arciprete
(2012) proposed Distributed Tree Kernels that ap-
proximate tree kernels (Collins and Duffy,
2001)
through the explicit
mapping of
trees into vec-
tors. DTKs focus on specific tree kernel functions,
while the approach proposed here can be effec-
tively applied to any kernel function.
An alterna-
tive strategy is presented in (Filice et al., 2015b),
where a cascade of kernel-based classifiers is pro-
posed according to the computational cost of their
kernel functions, so that more complex classifiers
are invoked only on difficult instances. Their solu-
tion is strictly connected to the availability of mul-
tiple kernels that
have to be sorted according to
their complexity and expressiveness. Usually, it is
hard to define many kernels for a given task,
and
consequently only few layers can be set.
5
Conclusion
This paper discussed the application of Nystr
¨
om
method for
a significant
reduction of
computa-
CLIC_2016_Proceedings.indd 114
02/12/16 15.03
115
tional
costs in kernel-based classifications in the
cQA task.
By projecting examples
into low-
dimensional
embeddings,
Nystr
¨
om enables
the
adoption of efficient
linear classifier,
and drasti-
cally reduces the overall computational cost.
Ex-
perimental
results demonstrate that
the proposed
approach leads to a cost
reduction higher
than
90%, with a negligible performance drop.
Future
research will be devoted to the definition of a prin-
cipled strategy to estimate the optimal number of
layers,
as well as the size of embeddings at each
layer.
References
Alberto Barr
´
on-Cede
˜
no,
Giovanni
Da San Martino,
Shafiq
Joty,
Alessandro
Moschitti,
Fahad
Al-
Obaidli,
Salvatore Romeo,
Kateryna Tymoshenko,
and Antonio Uva.
2016.
Convkn at semeval-2016
task 3:
Answer and question selection for question
answering on arabic and english fora.
In Proceed-
ings of the 10th International Workshop on Seman-
tic Evaluation (SemEval-2016), pages 896–903, San
Diego,
California,
June.
Association for Computa-
tional Linguistics.
Nicola Cancedda,
´
Eric Gaussier,
Cyril
Goutte,
and
Jean-Michel
Renders.
2003.
Word-sequence ker-
nels.
Journal
of
Machine
Learning Research,
3:1059–1082.
Nicolo’
Cesa-Bianchi
and Claudio Gentile.
2006.
Tracking the best hyperplane with a simple budget
perceptron.
In In proc. of the nineteenth annual con-
ference on Computational
Learning Theory,
pages
483–498. Springer-Verlag.
Chih-Chung Chang and Chih-Jen Lin.
2011.
Libsvm:
A library for support vector machines.
ACM Trans.
Intell. Syst. Technol., 2(3):27:1–27:27, May.
Michael Collins and Nigel Duffy.
2001.
Convolution
kernels for natural language.
In Proceedings of Neu-
ral
Information Processing Systems (NIPS’2001),
pages 625–632.
Koby Crammer,
Ofer
Dekel,
Joseph Keshet,
Shai
Shalev-Shwartz,
and Yoram Singer.
2006.
Online
passive-aggressive algorithms.
Journal of Machine
Learning Research, 7:551–585, December.
Danilo Croce and Roberto Basili.
2016.
Large-scale
kernel-based language learning through the ensem-
ble nystrom methods.
In Advances in Informa-
tion Retrieval
-
38th European Conference on IR
Research,
ECIR 2016,
Padua,
Italy,
March 20-23,
2016. Proceedings, pages 100–112.
Ofer Dekel and Yoram Singer.
2006.
Support vector
machines on a budget.
In Bernhard Schlkopf, John
Platt,
and Thomas Hoffman,
editors,
NIPS,
pages
345–352. MIT Press.
Petros Drineas and Michael W.
Mahoney.
2005.
On
the nystrm method for approximating a gram matrix
for improved kernel-based learning.
Journal of ML
Research, 6.
Simone Filice,
Giuseppe Castellucci,
Danilo Croce,
and Roberto Basili.
2014.
Effective kernelized on-
line learning in language processing tasks.
In Pro-
ceedings of ECIR 2014, pages 347–358.
Simone Filice,
Giuseppe Castellucci,
Danilo Croce,
and Roberto Basili.
2015a.
Kelp:
a kernel-based
learning platform for natural
language processing.
In Proceedings
of
ACL:
System Demonstrations,
Beijing, China, July.
Simone
Filice,
Danilo Croce,
and Roberto Basili.
2015b.
A Stratified Strategy for Efficient
Kernel-
based Learning.
In AAAI Conference on Artificial
Intelligence.
Simone Filice,
Danilo Croce,
Alessandro Moschitti,
and Roberto Basili.
2016.
Kelp at
semeval-2016
task 3:
Learning semantic relations between ques-
tions
and answers.
In Proceedings
of
the 10th
International
Workshop on Semantic
Evaluation
(SemEval-2016), pages 1116–1123, San Diego, Cal-
ifornia,
June.
Association for
Computational
Lin-
guistics.
Cho-Jui
Hsieh,
Kai-Wei
Chang,
Chih-Jen
Lin,
S.
Sathiya Keerthi,
and S.
Sundararajan.
2008.
A
dual coordinate descent method for large-scale lin-
ear svm.
In Proceedings of the ICML 2008,
pages
408–415, New York, NY, USA. ACM.
Sanjiv Kumar,
Mehryar Mohri,
and Ameet Talwalkar.
2012.
Sampling methods for the nystr
¨
om method.
J. Mach. Learn. Res., 13:981–1006, April.
Todor Mihaylov and Preslav Nakov.
2016.
Semanticz
at semeval-2016 task 3: Ranking relevant answers in
community question answering using semantic simi-
larity based on fine-tuned word embeddings.
In Pro-
ceedings of the 10th International Workshop on Se-
mantic Evaluation (SemEval-2016), pages 879–886,
San Diego,
California,
June.
Association for Com-
putational Linguistics.
Alessandro
Moschitti,
Silvia
Quarteroni,
Roberto
Basili,
and Suresh Manandhar.
2007.
Exploit-
ing syntactic
and shallow semantic
kernels
for
question/answer
classification.
In Proceedings of
ACL’07.
Preslav Nakov,
Llu
´
ıs M
`
arquez,
Alessandro Moschitti,
Walid Magdy,
Hamdy Mubarak,
Abed Alhakim
Freihat,
Jim Glass,
and Bilal
Randeree.
2016.
SemEval-2016 task 3: Community question answer-
ing.
In Proceedings of the 10th International Work-
shop on Semantic Evaluation,
SemEval
’16,
San
Diego,
California,
June.
Association for Computa-
tional Linguistics.
CLIC_2016_Proceedings.indd 115
02/12/16 15.03
116
Francesco Orabona,
Joseph Keshet,
and Barbara Ca-
puto.
2008.
The projectron: a bounded kernel-based
perceptron.
In Proceedings of
ICML ’08,
pages
720–727, USA. ACM.
Aliaksei
Severyn,
Massimo Nicosia,
and Alessandro
Moschitti.
2013.
Building structures from classi-
fiers for passage reranking.
In Proceedings of
the
22nd ACM international
Conference on Informa-
tion and Knowledge Management, CIKM ’13, pages
969–978, New York, NY, USA. ACM.
John Shawe-Taylor and Nello Cristianini.
2004.
Ker-
nel Methods for Pattern Analysis.
Cambridge Uni-
versity Press, New York, NY, USA.
Vladimir N. Vapnik.
1998.
Statistical Learning The-
ory.
Wiley-Interscience.
Andrea Vedaldi
and Andrew Zisserman.
2012.
Ef-
ficient
additive kernels via explicit
feature maps.
Pattern Analysis and Machine Intelligence,
IEEE
Transactions on, 34(3).
Zhuang Wang and Slobodan Vucetic.
2010.
Online
passive-aggressive algorithms on a budget.
Journal
of Machine Learning Research - Proceedings Track,
9:908–915.
Christopher K. I. Williams and Matthias Seeger.
2001.
Using the nystr
¨
om method to speed up kernel ma-
chines.
In Proceedings of NIPS 2000.
Fabio Massimo Zanzotto and Lorenzo Dell’Arciprete.
2012.
Distributed tree kernels.
In Proceedings of
ICML 2012.
CLIC_2016_Proceedings.indd 116
02/12/16 15.03
117
Tracing metaphors in time through self-distance in vector spaces
Marco Del Tredici
ILLC, Univ. of Amsterdam
Amsterdam, The Netherlands
marcodeltredici@gmail.com
Malvina Nissim
CLCG, Univ. of Groningen
Groningen, The Netherlands
m.nissim@rug.nl
Andrea Zaninello
Zanichelli editore
Bologna, Italy
azaninello@zanichelli.it
Abstract
English.
From a diachronic corpus of Ita-
lian,
we build consecutive vector spaces
in time and use them to compare a term’s
cosine similarity to itself in different time
spans.
We assume that
a drop in simi-
larity might be related to the emergence
of a metaphorical
sense at
a given time.
Similarity-based observations are matched
to the actual year when a figurative mean-
ing was documented in a reference dictio-
nary and through manual inspection of cor-
pus occurrences.
Italiano.
Nel presente esperimento costru-
iamo spazi vettoriali progressivi nel tempo
su un corpus diacronico dell’italiano e
calcoliamo la distanza di
alcuni
termini
rispetto a loro stessi in differenti periodi.
L’ipotesi
`
e che un calo di similitudine possa
essere indicativo dell’acquisizione di
un
significato metaforico. Tale ipotesi
`
e valu-
tata attraverso una risorsa lessicografica
esterna e l’annotazione manuale dei con-
testi dei termini nel corpus.
1
Introduction
It is widely acknowledged that metaphors are per-
vasive in language use, and that their detection and
interpretation are crucial to language processing
(Group, 2007; Turney et al., 2011; Shutova, 2015).
One tricky aspect related to metaphors is their
dynamic nature:
new metaphors are created all
the time.
For example,
in recent
years the Ital-
ian term “talebano” (‘Taliban’),
previously only
used to refer to the Islamic fundamentalist political
movement founded in the Nineties in Afghanistan
(Example 1),
has come to define more generally
someone who is extreme in his or her positions, for
example regarding food, use of medicines, and the
like (Example 2).
1
(1)
(lit.) l’operazione [...] ha permesso di ar-
restare un talebano esperto in esplosivi
(2)
(fig.) [...] senza l’atteso top player, e di un
allenatore talebano della tattica
If the metaphorical meaning becomes commonly
used, it might get recorded in reference dictionaries,
too.
Indeed, for the case of “talebano” the Italian
dictionary Zingarelli (Zingarelli, 1993–2017) has
recorded the metaphorical extension (“che (o chi)
`
e dogmatico, integralista”) in the year 2009, while
until then only the literal meaning was included.
Most of the computational work on metaphors
has focused on their identification and interpreta-
tion using a variety of techniques and models, such
as clustering (Shutova and Sun, 2013), LDA topic
modeling (Heintz et al., 2013), tree kernels (Hovy
et al., 2013), but all from a purely synchronic per-
spective.
2
The way metaphors develop across time,
instead,
and whether the shift of a word’s literal
meaning to a figurative one can be automatically
detected and modelled is as of now a little investi-
gated aspect.
As a contribution in this sense, we build on the
basic observation that if a metaphorical meaning
is acquired by a term at a certain point in time, the
context of use of that term will, at least partially,
change.
In this paper we offer a proof of concept
of this assumption, based on a selection of terms.
(Dis)similarity of contexts is measured relying on
the distributional semantics approach, and thus on
the terms’ vector representations, and the existence
of a metaphoric shift is derived from the Zingarelli
dictionary of Italian.
1
All of the examples in this paper are from the newspaper
la Repubblica, see Section 4.2.
2
For
a detailed survey on current
NLP systems
for
metaphor modeling see (Shutova, 2015).
CLIC_2016_Proceedings.indd 117
02/12/16 15.03
118
2
Approach
According to the principle of distributional seman-
tics, the meaning of a word is represented by vec-
tors that encode the contextual information of that
word in a corpus (Turney et al., 2010). All vectors
representing words are included in a distributional
semantic space in which similar words are repre-
sented by vectors that are close in that space, while
different words are distant.
We rely on the intuition that if a term develops
a metaphoric sense, its contexts of occurrence will
start to differ, at least partially, from those observed
for the very same term at the time the metaphorical
meaning had not emerged yet.
This implies that
detecting a distance in space across time could be
indicative of a meaning shift.
Hence,
instead of
comparing different terms synchronically, we focus
on their self-distance across time, thus tracing their
diachronic evolution of meaning.
Practically,
we train vector representations of
words in consecutive time spans, and compare such
representations to one another,
for a set of pilot
terms.
As a default, a term is expected to exhibit
a vector representation roughly similar to itself
across time.
If we observe a drop in similarity
between vectors in consecutive spaces, we can hy-
pothesise the emergence of a new sense for this
term, potentially metaphoric.
By using the information recorded for the se-
lected terms in a reference dictionary for the Italian
language, we observe whether there is some corre-
spondence between the observed similarity drop,
if present, and the time of inclusion of a figurative
sense. Finally, for each year cluster, we manually
inspect the occurrences of our target terms in order
to see if changes of use can be observed.
We are aware of the fact that changes in distance
of a word to itself across time might be triggered by
phenomena other than the rise of a metaphoric shift.
Indeed,
especially for polysemous words,
extra-
linguistic factors could cause the dominance of one
sense over the others at a given time.
In a larger-
scale, bottom-up approach to detect metaphorical
shifts, this would need to be properly accounted for.
In the context of this proof-of-concept, we control
for this factor by choosing words that are not or are
minimally polysemous (see Section 4.1).
3
Related Work
The automatic modelling of diachronic shift
of
meaning has been investigated employing several
different techniques. Among these, most recently,
Latent Semantic Analysis (Sagi et al.,
2011;
Ja-
towt and Duh, 2014), topic clustering (Wijaya and
Yeniterzi, 2011) and dynamic topic modeling (Fr-
ermann and Lapata, 2016). Vector representations
for diachronic shift
of meaning have been used
by Gulordava and Baroni (2011), with a simple co-
occurence matrix of target words and context terms.
Jatowt and Duh (2014) and Xu and Kemp (2015)
experimented both with a bag-of-words approach
and a more linguistically motivated representation
that also captures the relative position of lexical
items in relation to the target word.
Recently, Word Embeddings (Mikolov and Dean
(2013),
see also Section 4.3) have been used to
investigate diachronic meaning shifts: vectors are
usually created independently for each time span
and then mapped from one year to another via a
transformation matrix, thus leveraging the stabil-
ity of the relative positions of vectors in different
spaces (Kulkarni et al., 2015; Zhang et al., 2015;
Hamilton et al., 2016).
An alternative approach, which we also adopt –
with a slight change – in our work, is introduced
by Kim et al.
(2014),
who propose a simple but
effective methodology to make vectors trained on
different corpora directly comparable: embeddings
created for year
y
are used to initialise the vectors
for year
y
+1
. The process is progressively applied
to all time spans.
4
Experiment
Following the approach described in Section 2, we
selected a small set of pilot terms from a lexico-
graphic reference, and observed their space devel-
opment
across time,
on a diachronic corpus for
Italian that we collected for this purpose.
Due to
the absence of datasets in which words are anno-
tated for meaning change, a qualitative analysis of
a set of hand-selected words like the one we pro-
pose has established itself as a common evaluation
method in previous work on diachronic meaning
change (Frermann and Lapata, 2016).
4.1
Lexicographic reference and term
selection
The Zingarelli dictionary is a reference dictionary
for the Italian language,
updated and published
every year, both in digital and paper version. The
dictionary is traditionally dated one year ahead of
the year it is published, hence the Zingarelli 2017
CLIC_2016_Proceedings.indd 118
02/12/16 15.03
119
Table 1:
Selected terms.
a-date
= first attested;
d-date
= decision date for extended meaning to be
included in dictionary; i-date = actual inclusion date in Zingarelli for extended meaning.
term
literal
figurative
a-date
d-date
i-date
implosione
implosion
cedimento, tracollo improvviso (collapse)
1932
2013
2015
kamikaze
kamikaze
chi compie un’impresa rischiosa o destinata al
fallimento (daredevil, reckless)
1944
2007
2009
rottamatore
dismantler
nel
linguaggio giornalistico e della politica,
chi si propone di allontanare e sostituire un
gruppo dirigente considerato antiquato (new
broom)
1990
2012
2014
talebano
Taliban
che (o chi)
`
e dogmatico,
integralista (hard-
liner, extremist)
1995
2007
2009
tsunami
tsunami
evento che determina lo sconvolgimento di un
assetto costituito (devastation, havoc)
1907
2008
2010
is published in June 2016, and it refers to decisions
about
new words and new meanings (including
metaphorical ones) made up until December 2015.
We analysed the behaviour of a small set of terms
extracted from the dictionary.
We searched the
2017 edition to extract nouns that record a figura-
tive meaning, limiting our search to words whose
first occurrence is recorded in the 20th or 21st cen-
tury. Newly born words (including borrowings) are
more likely to show a meaning shift in the time
span considered in our search (1984-2015) than
older words (especially if derived directly form
Latin, where the figurative meaning was also origi-
nally highly available, so probably arisen earlier).
Out of a total of 447 hits, five target words were
chosen for this pilot study.
They are reported in
Table 1 together with relevant information.
In order to minimise (at least in the context of
this experiment) the influence of polysemy in the
observable similarity distance across years, we ver-
ified that the selected terms are not polysemous,
or minimally so.
For the words “rottamatore”,
“talebano”, and “tsunami”, the Zingarelli records
one sense only.
For the word “implosione” three
senses in total are recorded, two of which are how-
ever technical language, in the fields of linguistics
(phonology) and psychology, and we assume will
not be used much in newswire.
For “kamikaze”
the Zingarelli records one meaning only (Japanese
pilot) to which is associated the extended sense of
someone who kills himself in a terrorist attack; in
our corpus the extended meaning is clearly the pri-
mary one, and the figurative sense that we consider
is derived from it (see also Section 4.4).
4.2
Corpus
We created a diachronic corpus of approximately
60 millions tokens by collecting articles from the
Italian newspaper la Repubblica from 1984 (the
first year for which data is available digitally) to
2015.
All texts were tokenised and lowercased.
Because we are interested in how a term’s context
changes over time, we had to determine time-spans
for our corpus, and we settled on two-year blocks,
for a total of 16 time spans, the first one being 1984-
1985 and the last 2014-2015. These subcorpora are
used to train consecutive vector space models.
4.3
Model
We implemented vector representations using the
skip-gram architecture introduced by Mikolov and
Dean (2013). Such representations (Word Embed-
dings) are low dimensional, dense and real-valued
vectors that have been proved to preserve syntac-
tic and semantic information in several NLP tasks
(Baroni et al., 2014).
Vectors created on different corpora cannot be
directly compared, since every semantic space im-
plements arbitrary orthogonal transformations and
hence there is no direct correspondence between
word vectors in different semantic spaces (Zhang
et al., 2015). This would hold true also for our data,
since we create a different corpus for each time
span. Therefore, in order to create comparable vec-
tor representations for each word in any time span,
we adopt the methodology introduced by Kim et al.
(2014) (see Section 3), slightly modifying it. While
Kim et al. (2014) use vectors of span
y
to initialise
the vectors for year
y
+ 1
, we do the opposite, i.e.
CLIC_2016_Proceedings.indd 119
02/12/16 15.03
120
we start with 2014-15, and use those vectors to ini-
tialise the 2012-13 time span, and thus backwards
until 1984-85.
This methodological choice is due to the fact
that the majority of the words in the set we con-
sidered for this experiment (included the selected
target words, see 4.1) have few or no occurrences
in the first time spans of the corpus: for example,
“rottamatore” and “talebano” occur for the first time
in 96/97. Indeed, using Kim et al. (2014)’s original
approach, which we implemented in a preliminary
experiment, the vectors for these words were cor-
rectly initialised, but were basically random vectors
with no meaningful information.
Conversely, our
reverse setting, while still offering the same oppor-
tunity to trace shifts of meaning across time, allows
to initialise all target words on a time span (14/15)
in which they occur a number of times sufficient to
create a more stable, meaningful representation.
Using the
gensim
library (
ˇ
Reh
˚
u
ˇ
rek and Sojka,
2010), we trained the models with the following
parameters: window size of 5, learning rate of 0.01
and dimensionality of 200. We filtered out words
with frequency lower than 5 occurrences. The vo-
cabulary was initialised over the whole dataset.
4.4
Results and discussion
Figure 1 shows the similarity values for one time
span to the next (dotted line), together with the av-
erage shift of meaning of a subset of 5000 nouns
randomly selected (solid line).
While we cannot
draw any statistically significant conclusions from
such little data, we aim at potentially observing pat-
terns of shift of meaning through change of vector
representations that could be used for developing
predictive metrics of metaphorical shifts in time.
We interpret the results of our models according
to (i) information in the Zingarelli dictionary and
(ii) a manual inspection of the context of use of our
target words in the corpus.
For (i),
we verify if,
for a given term,
an ob-
servable correlation exists between changes in its
vector representations and the insertion of a figura-
tive sense in the dictionary. Results show that such
a correlation exists for “talebano”, “rottamatore”,
and “tsunami”.
For these words a drop in cosine
similarity can be observed between three and five
years before the insertion of the figurative meaning
in the dictionary.
This fits well with the timing
for new meanings to be recorded in lexicographic
resources (see Section 4.1). The nouns “kamikaze”
and “implosione”, instead, show a more stable evo-
lution of meaning in time,
with no clear drop in
cosine similarity, and thus no evident correlation
between changes in vector representations and in-
sertion of a figurative meaning in dictionary.
For (ii), we manually inspected the contexts in
which target terms occur in the the corpus as literal
or metaphoric, in order to check if some relevant
change in words usage could be observed in cor-
respondence to drops in cosine similarity between
time spans.
“Tsunami” occurs 27 times between 84/85 and
02/03: in 88.9% of the cases the word is used liter-
ally, with only 3 metaphorical uses in 98/99 (mir-
rored in a slight drop in cosine similarity). Of the
930 occurrences from 04/05 to 14/15, only 59.1%
are literal.
In Figure 1 we can observe a major
drop in cosine similarity exactly between 04/05
and 06/06.
“Rottamatore” occurs 4 times between 84/85 and
08/09, always used literally. From 10/11 on, there
are 156 occurrences, all metaphorical.
Thus, the
drop corresponds to change in usage here too.
“Talebano” occurs 12 times between 84/85 and
02/03,
with 83.3% of literal usage.
Once again,
the drop in cosine coincides with the time span in
which the term started to be used metaphorically:
between 02/03 and 08/09 40% of the occurrences of
“talebano” are metaphorical. Then, another relevant
drop is observed between 08/09 and 10/11,
and
this is due to the sudden return of the literal usage
of this word (86.1%), which continues also in the
following years.
As already noticed,
“kamikaze” and “implo-
sione” do not seem to undergo a clear shift.
As
for the former, the analysis of its contexts of use
reveals that indeed it is not possible to clearly iden-
tify, in our corpus, when exactly the term started to
be used metaphorically: of the 25 occurrences of
“kamikaze” in 84/85, 32% are metaphorical. This
trend is fairly constant, and it explains why the vec-
tor representation of “kamikaze”, which from the
very beginning conflates literal and metaphorical
usages, is stable in time.
There is only a relevant
change starting from 10/11:
from this period on-
wards, the metaphorical use decreases, and almost
all the occurrences are literal.
3
Accordingly, this
3
Interestingly, this increase of literal usage is observed in
the same years also for “talebano”, a term that is semantically
related to “kamikaze”. This observation would require further
investigation in connection with the socio-political events of
those time spans.
CLIC_2016_Proceedings.indd 120
02/12/16 15.03
121
Figure 1: Cosine similarity values across time spans for target words (dotted line), average similarity of
nouns (solid line) and date of insertion of metaphorical meaning in the Zingarelli dictionary (red dot).
almost exclusively return to the literal meaning cor-
responds to a slight increase in cosine similarity
between the two last time spans.
“Implosione” occurs 433 times overall and in
92.4% of them is used metaphorically, but in few
and specific contexts.
A metaphorical, quite spe-
cific, sense of “implosione” is thus the main sense
for this term in our corpus,
and this is why we
observe, on average, a high similarity across time
spans.
There is only a small drop between 10/11
and 12/13,
when the word started to be used in
the context of the economical crisis (“l’implosione
dell’euro”).
To sum up, both “kamikaze” and “implosione”
show a similar stable behaviour in time, with only
small drops. However, while for “kamikaze” such
stability is due to a relatively constant ratio between
literal and metaphorical meanings, in the case of
“implosione” the observed stability is given by the
constant predominance of the metaphorical sense
across all the time spans.
5
Conclusion and future work
This work was meant as an exploration of the as-
sumption that the emergence of the metaphorical
use of a term might be mirrored in changes in co-
sine similarity of the term to itself across time.
Such assumption has been partially confirmed by
the comparison to the Zingarelli dictionary, while
we found a more robust evidence when inspecting
the terms’ contexts of use manually.
Future work will stem from methodology and
observations discussed here. Specifically, we plan
to investigate further several aspects of this initial
work, including the relation between changes in co-
sine similarity and frequency of use of a word: to
which extent a change of the former relates to an in-
crease of the latter? Mostly though, we plan to run
experiments on larger sets of words with the aim
to consolidate and then further exploit the mainly
qualitative observations reported here towards the
development of reliable predictive metrics which
can serve to detect the emergence of shifts automat-
ically, in a completely bottom-up fashion.
Acknowledgments
Malvina Nissim would like to thank the ILC-CNR
ItaliaNLP Lab for their hospitality while working
on this project. We are also grateful to the anony-
mous reviewers who provided insightful comments
that doubtlessly contributed to improve this paper.
CLIC_2016_Proceedings.indd 121
02/12/16 15.03
122
References
Marco
Baroni,
Georgiana
Dinu,
and
Germ
´
an
Kruszewski.
2014.
Don’t
count,
predict!
a
systematic
comparison
of
context-counting
vs.
context-predicting semantic vectors.
In Proceedings
of
the 52nd Annual
Meeting of
the Association
for
Computational
Linguistics
(Volume 1:
Long
Papers), pages 238–247, Baltimore, Maryland, June.
Association for Computational Linguistics.
Lea Frermann and Mirella Lapata.
2016.
A bayesian
model of diachronic meaning change.
Transactions
of
the Association for Computational
Linguistics,
4:31–45.
Pragglejaz
Group.
2007.
MIP:
A method for
identifying metaphorically used words in discourse.
Metaphor and symbol, 22(1):1–39.
Kristina Gulordava and Marco Baroni.
2011.
A dis-
tributional similarity approach to the detection of se-
mantic change in the Google books ngram corpus.
In Proceedings of the GEMS 2011 Workshop on GE-
ometrical
Models of
Natural
Language Semantics,
pages 67–71.
Association for
Computational
Lin-
guistics.
William L Hamilton,
Jure Leskovec,
and Dan Juraf-
sky.
2016.
Diachronic word embeddings reveal
statistical laws of semantic change.
arXiv preprint
arXiv:1605.09096.
Ilana Heintz, Ryan Gabbard, Mahesh Srinivasan, David
Barner,
Donald S Black,
Marjorie Freedman,
and
Ralph Weischedel.
2013.
Automatic extraction of
linguistic metaphor with LDA topic modeling.
In
Proceedings of the First Workshop on Metaphor in
NLP, pages 58–66.
Dirk Hovy, Shashank Srivastava, Sujay Kumar Jauhar,
Mrinmaya Sachan, Kartik Goyal, Huiying Li, Whit-
ney Sanders,
and Eduard Hovy.
2013.
Identifying
metaphorical
word use with tree kernels.
In Pro-
ceedings of the First Workshop on Metaphor in NLP,
pages 52–57.
Adam Jatowt and Kevin Duh.
2014.
A framework for
analyzing semantic change of words across time.
In
Proceedings of
the 14th ACM/IEEE-CS Joint
Con-
ference on Digital Libraries,
pages 229–238. IEEE
Press.
Yoon Kim, Yi-I Chiu, Kentaro Hanaki, Darshan Hegde,
and Slav Petrov.
2014.
Temporal
analysis of lan-
guage through neural language models.
In Proceed-
ings of the ACL 2014 Workshop on Language Tech-
nologies and Computational
Social
Science,
pages
61–65. Association for Computational Linguistics.
Vivek Kulkarni,
Rami
Al-Rfou,
Bryan Perozzi,
and
Steven Skiena.
2015.
Statistically significant detec-
tion of linguistic change.
In Proceedings of the 24th
International Conference on World Wide Web, pages
625–635. ACM.
T Mikolov and J Dean.
2013.
Distributed representa-
tions of words and phrases and their compositional-
ity.
Advances in neural information processing sys-
tems.
Radim
ˇ
Reh
˚
u
ˇ
rek and Petr Sojka.
2010.
Software Frame-
work for Topic Modelling with Large Corpora.
In
Proceedings of
the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta, May. ELRA.
Eyal Sagi,
Stefan Kaufmann,
and Brady Clark.
2011.
Tracing semantic change with latent semantic analy-
sis.
Current methods in historical semantics, pages
161–183.
Ekaterina Shutova and Lin Sun.
2013.
Unsupervised
metaphor identification using hierarchical graph fac-
torization clustering.
In HLT-NAACL,
pages 978–
988.
Ekaterina Shutova.
2015.
Design and evaluation of
metaphor processing systems.
Computational
Lin-
guistics, 41(4):579–623.
Peter D Turney,
Patrick Pantel,
et
al.
2010.
From
frequency to meaning:
Vector space models of se-
mantics.
Journal of artificial intelligence research,
37(1):141–188.
Peter D Turney,
Yair Neuman,
Dan Assaf,
and Yohai
Cohen.
2011.
Literal and metaphorical sense iden-
tification through concrete and abstract context.
In
Proceedings of the 2011 Conference on the Empiri-
cal Methods in Natural Language Processing, pages
680–690.
Derry Tanti Wijaya and Reyyan Yeniterzi.
2011.
Un-
derstanding semantic change of
words
over
cen-
turies.
In Proceedings of
the 2011 international
workshop on DETecting and Exploiting Cultural di-
versiTy on the social web, pages 35–40. ACM.
Y. Xu and C. Kemp.
2015.
A computational evaluation
of two laws of semantic change.
In Proceedings of
the 37th Annual Conference of the Cognitive Science
Society.
Yating Zhang, Adam Jatowt, Sourav S Bhowmick, and
Katsumi Tanaka.
2015.
Omnia mutantur,
nihil in-
terit: Connecting past with present by finding corre-
sponding terms across time.
In Proc. of ACL, pages
645–655.
N. Zingarelli.
1993–2017.
Lo Zingarelli - Vocabolario
della lingua italiana.
Zanichelli editore, Bologna.
CLIC_2016_Proceedings.indd 122
02/12/16 15.03
123
Gamification for IR: The Query Aspects Game
Giorgio Maria Di Nunzio
Dept. of Inf. Eng. (DEI)
University of Padua, Italy
Via Gradenigo 6/a 35131
dinunzio@dei.unipd.it
Maria Maistro
Dept. of Inf. Eng. (DEI)
University of Padua, Italy
Via Gradenigo 6/a 35131
maistro@dei.unipd.it
Daniel Zilio
Dept. of Inf. Eng. (DEI)
University of Padua, Italy
Via Gradenigo 6/a 35131
daniel.zilio.3@studenti.unipd.it
Abstract
English.
The creation of a labelled dataset for Infor-
mation Retrieval (IR) purposes is a costly
process.
For this reason, a mix of crowd-
sourcing and active learning approaches
have been proposed in the literature in or-
der to assess the relevance of documents of
a collection given a particular query at an
affordable cost.
In this paper,
we present
the design of the gamification of this inter-
active process that draws inspiration from
recent
works in the area of gamification
for IR.
In particular,
we focus on three
main points:
i) we want to create a set of
relevance judgements with the least effort
by human assessors, ii) we use interactive
search interfaces that
use game mechan-
ics, iii) we use Natural Language Process-
ing (NLP) to collect different aspects of a
query.
1
Italiano
La creazione di una collezione sperimen-
tale per l’Information Retrieval (IR)
`
e un
processo costoso sia dal
punto di
vista
economico che in termini di sforzo umano.
Per ridurre i
costi
legati
all’attribuzione
dei
giudizi
di
rilevanza ai
documenti
di
una collezione,
sono stati
proposti
ap-
procci
che integrano tecniche di
crowd-
sourcing e active learning.
In questo
paper
viene
presentata un’idea basata
sull’utilizzo della gamification (‘ludiciz-
zazione’) in IR per l’attribuzione di giudizi
di rilevanza in maniera semi-automatica.
1
This paper is partially an extended abstract
of the pa-
per “Gamification for Machine Learning:
The Classification
Game” presented at the GamifIR 2016 Workshop co-located
with SIGIR 2016 (Di Nunzio et al., 2016)
In particolare,
ci focalizzeremo su tre as-
petti
principali:
i)
si
vuole creare una
collezione in modo che l’assegnazione dei
giudizi da parte dei valutatori richieda il
minor sforzo possibile,
ii)
per mezzo di
un’interfaccia che utilizza dinamiche di
gioco iii) insieme a tecniche di
NLP per
la riformulazione della query.
1
Introduction
In Information Retrieval (IR), the performance of
a system is evaluated using experimental test col-
lections. These collections consist of a set of docu-
ments, a set of queries, and a set of relevance judg-
ments,
where each judgement explains whether a
document
is relevant
or not
to each query.
The
creation of relevance judgements is a costly, time-
consuming,
and non-trivial
task;
for
these rea-
sons, the interest in approaches that generate rele-
vance judgements with the least amount of effort
has increased in IR and related areas (i.e.,
super-
vised Machine Learning (ML) algorithms).
In the
last years, mixed approaches that use crowdsourc-
ing (Ho et al.,
2013) and active learning (Settles,
2011) have shown that it is possible to create an-
notated datasets at affordable costs.
Specifically,
crowdsourcing has been part of the IR toolbox as a
cheap and fast mechanism to obtain labels for sys-
tem evaluation.
However,
successful deployment
of crowdsourcing at scale involves the adjustment
of many variables, a very important one being the
number of assessors needed per task, as explained
in (Abraham et al., 2016).
1.1
Search Diversification and Query
Reformulation
The effectiveness of a search and the satisfaction
of users can be enhanced through providing var-
ious results of a search query in a certain order
of
relevance and concern.
The technique used
CLIC_2016_Proceedings.indd 123
02/12/16 15.03
124
to avoid presenting similar,
though relevant,
re-
sults to the user is known as a diversification of
search results
(Abid et
al.,
2016).
While exist-
ing research in search diversification offers sev-
eral solutions for introducing variety into the re-
sults, the majority of such work is based on the as-
sumption that a single relevant document will ful-
fil a user’s information need, making them inade-
quate for many informational queries.
In (Welch
et al., 2011), the authors propose a model to make
a tradeoff between a user’s desire for multiple rel-
evant documents,
probabilistic information about
an average user’s interest in the subtopics of a mul-
tifaceted query, and uncertainty in classifying doc-
uments into those subtopics.
Most
information retrieval
systems operate by
performing a single retrieval
in response to a
query.
Effective results sometimes require sev-
eral
manual
reformulations by the user or semi-
automatic reformulations assisted by the system.
Diaz presents an approach to automatic query re-
formulation which combines the iterated nature
of human query reformulation with the automatic
behavior
of
pseudo relevance
feedback (Diaz,
2016).
In (Azzopardi, 2009), the author proposes
a method for generating queries for ad-hoc top-
ics to provide the necessary data for this compre-
hensive analysis of query performance.
Bailey et
al.
explore the impact of widely differing queries
that searchers construct for the same information
need description.
By executing those queries, we
demonstrate that
query formulation is critical
to
query effectiveness (Bailey et al., 2015).
1.2
Gamification in IR
Gamification is defined as “the use of game de-
sign elements in non-game contexts” (Deterding
et
al.,
2011),
i.e.
tipical
game elements are used
for purposes different from their normal expected
employment.
Nowadays,
gamification spreads
through a wide range of disciplines and its appli-
cations are implemented in different
and various
aspects of scientific fields of study.
For instances,
gamification is applied to learning activities (Ko-
tini and Tzelepi, 2015; Kapp, 2012), business and
enterprise (Jurado et al., 2015; Stanculescu et al.,
2016; Thom et al., 2012) and medicine (Eickhoff,
2014; Chen and Pu, 2014).
IR has recently dealt with gamification, as wit-
nessed by the Workshop on Gamification for In-
formation Retrieval (GamifIR) in 2014, 2015 and
2016.
In (Galli et al., 2014), the authors describe
the fundamental
elements
and mechanics
of
a
game and provide an overview of possible applica-
tions of gamification to the IR process.
In (Shov-
man,
2014),
approaches to properly gamify Web
search are presented,
i.e.
making the search of
information and the scanning of
results a more
enjoyable activity.
Actually,
many proposals of
game applied to different aspects of IR have been
presented. For example in (Maltzahn et al., 2014),
the authors describes a game that turns document
tagging into the activity of taking care of a gar-
den,
with the aim of managing private archives.
A method to obtain ranking of images by utilizing
human computation through a gamified web appli-
cation is proposed in (Lux et al., 2014).
Fort et al.
introduce a strategy to gamify the annotation of a
French corpora (Fort et al., 2014).
In this paper, we want to apply game mechanics
to the problem of relevance assessment with three
goals in mind:
i) we want to create a set of rele-
vance judgements with the least effort by human
assessors,
ii) we use interactive search interfaces
that use game mechanics, iii) we use NLP to col-
lect different aspects of a query.
In this context,
we can define our web application as a Game with
a Purpose (GWAP), that is a game which presents
some purposes, usually boring and dull for people,
within an entertaining setting,
in order to make
them enjoyable and to solve problem with the aid
of human computation.
The design and the im-
plementation of this interactive interface will
be
used as a post-hoc analysis of two Text REtrieval
Conference (TREC)
2
2016 tracks, namely the To-
tal Recall Track and the Dynamic Domain Track.
These two tracks are interesting for our problem
since they both re-create a situation where we need
to find the best set (or the total amount) of relevant
documents with the minimum effort by the asses-
sor that has to judge the documents proposed by
the system given an information need.
2
Design of the Experiment
In this first pilot study, we will implement a sim-
ple game based on a visual interpretation of prob-
abilistic classifiers (Di Nunzio, 2014; Di Nunzio,
2009;
Di Nunzio and Sordoni,
2012).
The game
consists in separating two sets of colored points
on a two-dimensional plane by means of a straight
line, as shown in Figure 1.
Despite its simplicity,
2
http://trec.nist.gov
CLIC_2016_Proceedings.indd 124
02/12/16 15.03
125
this very abstract scenario received a good feed-
back by kids of primary schools who tested it dur-
ing the European Researcher’s Night at the Uni-
versity of Padua
3
.
The next step will be to design
and implement the game with real game develop-
ment platforms like, for example, Unity
4
or Mar-
malade
5
.
2.1
The Classification Game
The ‘original
game’ (Di
Nunzio et
al.,
2016) is
based on the two-dimensional
representation of
probabilities (Di
Nunzio,
2014;
Singh and Raj,
2004), which is a very intuitive way of presenting
the problem of classification on a two-dimensional
space.
Given two classes
c
1
and
c
2
, an object
o
is
assigned to category
c
1
if the following inequality
holds:
P
(
o
|
c
2
)



y
< m P
(
o
|
c
1
)



x
+
q
(1)
where
P
(
o
|
c
1
)
and
P
(
o
|
c
2
)
are the likelihoods of
the object
o
given the two categories, while
m
and
q
are two parameters that depend on the misclas-
sification costs that can be assigned by the user to
compensate for either the unbalanced classes situ-
ation or different class costs.
If we interpret the two likelihoods as two coor-
dinates
x
and
y
of a two dimensional
space,
the
problem of classification can be studied on a two-
dimensional plot.
The decision of the classifica-
tion is represented by the ‘line’
y
=
mx
+
q
that
splits the plane into two parts,
therefore all
the
points that
fall
‘below’ this line are classified as
objects that
belong to class
c
1
(see Figure 1 for
an example). Without entering into the mathemat-
ical
details of this approach (Di
Nunzio,
2014),
the basic idea of the game is that the players can
adapt the two parameters
m
and
q
in order to opti-
mize the separation of points and, at the same time,
can use their resources to improve the estimate of
the two likelihoods by buying training data, and/or
add more points to the plot,
by buying validation
data.
3
The Query Aspects Game
The classification game can be easily adjusted into
a relevance assessment game if the two classes are
‘relevant’ and ‘non-relevant’ (we assume only bi-
nary relevance assessment for the moment). How-
3
http://www.venetonight.it/padova/
4
https://unity3d.com
5
https://www.madewithmarmalade.com/
ever,
while in the classification game we already
have a set of labelled documents and the goal is
to find the optimal
classifier,
in this new game
we need to find the relevant documents.
To this
purpose, we will follow the idea of the works de-
scribed in the following subsections:
i) building
assessment
by varying the description of the in-
formation need,
ii) using an interactive interface
that
suggests the amount
of relevant
information
that has to be judged,
iii) using NLP approaches
to generate variations of a query.
3.1
Building Relevance Assessments With
Query Aspects
In (Efron, 2009), the author presents a method for
creating relevance judgments without explicit rel-
evance assessments.
The idea is to create differ-
ent
“aspects” of a query:
given a query
q
and a
set
of documents
D
,
the same information need
that generated
q
could also generate other queries
that focus on another aspects of the same need.
A
query aspect is an articulation of a searcher’s infor-
mation need which might be a re-elaboration (for
example,
rephrasing,
specification,
or generaliza-
tion) of the query.
By generating several queries
related to an information need and running each
of these against our document collection,
we can
create a pool of results where each result set per-
tains to a particular aspect of the information need
with a limited human effort.
In practice,
in order to build a set of relevance
assessments for
q
, we generate a number of query
aspects using a single IR system.
Then, the union
of the top
k
documents retrieved for each aspect
constitutes a list of pseudo-relevance assessments
for the query
q
.
3.2
An Interactive Interface to Generate
Query Aspects
Building different aspects of the same information
need is not an easy task.
As explained in (Umem-
oto et
al.,
2016),
searchers often cannot
easily
come up with effective queries for collecting doc-
uments that cover diverse aspects.
In general, ex-
perts that
have to search for relevant
documents
usually have to issue more queries to complete the
tasks if search engines return few documents rel-
evant
to unexplored aspects.
Moreover,
quitting
this tasks too early without
in-depth exploration
prevents searchers from finding essential informa-
tion.
CLIC_2016_Proceedings.indd 125
02/12/16 15.03
126
Figure 1: Layout of the original “classification game” that will be adapted to the “query aspects game”.
Figure 2: Scentbars and the visualization of miss-
ing information.
Figure from (Umemoto et
al.,
2016)
Umemoto et al. propose an interactive interface,
named ScentBar, that helps searchers to visualize
the amount
of missing information for both the
search query and suggestion queries in the form
of a stacked bar chart.
The interface, a portion of
which is shown in Figure 2, visualizes an estimate
of missing information for each aspect of a query
that could be obtained by the searcher.
When the
user collects new information during the browsing
of the results,
the bars of the different
query as-
pects change color to indicate the amount of effort
that the system estimates necessary to find most of
the relevant information.
The estimates of the re-
quired effort to complete a task are formalized as
as a set-wise metric were the gain for each aspects
is represented by a conditional probability.
3.3
Using NLP to Generate Query Aspects
The last
part
of the design of the query aspects
game involves the use of natural language process-
ing techniques to propose variations of a query to
express the same information need.
This problem
has been studied for more than twenty years in IR.
In (Strzalkowski
et
al.,
1997),
the authors dis-
cuss how the simplest word-based representations
of content, while relatively better understood, are
usually inadequate since single words are rarely
specific enough for accurate discrimination.
Con-
sequently, a better method is to identify groups of
words that
create meaningful
phrases,
especially
if these phrases denote important concepts in the
domain.
Some
examples
of
advanced
techniques
of
phrase extraction,
including extended N-grams
and syntactic parsing,
attempt
to uncover
con-
cepts,
which would capture underlying semantic
uniformity across various surface forms of expres-
sion.
Syntactic phrases,
for example,
appear rea-
sonable indicators of content since they can ade-
quately deal
with word order changes and other
structural
variations.
In the literature,
there are
examples of query reformulation using NLP ap-
proaches for example to the modification and/or
expansion of
both parts
thematic and geospa-
tial that are usually recognized in a geographical
query (Perea-Ortega et al., 2013), or to support the
refinement of a vague, non-technical initial query
into a more precise problem description (Roulland
et al., 2007), or to predict search satisfaction (Has-
san et al., 2013).
CLIC_2016_Proceedings.indd 126
02/12/16 15.03
127
4
Conclusions and Future Works
In this work, we presented the requirements of the
design of an interactive interface that
uses game
mechanics together with NLP techniques to gen-
erate variation of an information need in order to
label a collection of documents.
Starting from the
successful experience of the gamification of a ma-
chine learning problem (Di Nunzio et al.,
2016),
we are preparing a new pilot study of the ‘query
aspects game’ that will be used to generate rele-
vant
documents for two TREC tracks:
the Total
Recall track and the Dynamic Domain track.
The
results of this study will
be available at
the end
of November 2016, and can be presented and dis-
cussed at the workshop.
References
Adnan Abid,
Naveed Hussain,
Kamran Abid,
Farooq
Ahmad, Muhammad Shoaib Farooq, Uzma Farooq,
Sher
Afzal
Khan,
Yaser
Daanial
Khan,
Muham-
mad Azhar Naeem,
and Nabeel
Sabir.
2016.
A
survey on search results diversification techniques.
Neural
Computing and Applications,
27(5):1207–
1229.
Ittai Abraham, Omar Alonso, Vasilis Kandylas, Rajesh
Patel,
Steven Shelford,
and Aleksandrs
Slivkins.
2016.
How many workers to ask?:
Adaptive explo-
ration for collecting high quality labels.
In Proceed-
ings of the 39th International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval,
SIGIR ’16,
pages 473–482,
New York,
NY, USA. ACM.
Leif Azzopardi.
2009.
Query side evaluation:
An
empirical
analysis of effectiveness and effort.
In
Proceedings of the 32Nd International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval,
SIGIR ’09,
pages 556–563,
New
York, NY, USA. ACM.
Peter Bailey,
Alistair Moffat,
Falk Scholer,
and Paul
Thomas.
2015.
User variability and ir system evalu-
ation.
In Proceedings of the 38th International ACM
SIGIR Conference on Research and Development in
Information Retrieval,
SIGIR ’15,
pages 625–634,
New York, NY, USA. ACM.
Yu Chen and Pearl Pu.
2014.
Healthytogether: Explor-
ing social incentives for mobile fitness applications.
In Proceedings of the Second International Sympo-
sium of Chinese CHI,
Chinese CHI ’14,
pages 25–
34, New York, NY, USA. ACM.
Sebastian Deterding,
Dan Dixon,
Rilla Khaled,
and
Lennart Nacke.
2011.
From Game Design Elements
to Gamefulness:
Defining “Gamification”.
In Proc.
of the 15th International Academic MindTrek Con-
ference:
Envisioning Future Media Environments,
MindTrek ’11,
pages 9–15,
New York,
NY,
USA.
ACM.
Giorgio Maria Di
Nunzio and Alessandro Sordoni.
2012.
A Visual
Tool
for Bayesian Data Analysis:
The Impact of Smoothing on Naive Bayes Text Clas-
sifiers.
In Proc. of the ACM SIGIR’12 conference on
research and development in Information Retrieval,
Portland, OR, USA, August 12-16, 2012, page 1002.
Giorgio Maria Di Nunzio,
Maria Maistro,
and Daniel
Zilio.
2016.
Gamification for machine learning:
The classification game.
In Proceedings of the Third
International
Workshop on Gamification for Infor-
mation Retrieval co-located with 39th International
ACM SIGIR Conference on Research and Develop-
ment
in Information Retrieval
(SIGIR 2016),
Pisa,
Italy, July 21, 2016., pages 45–52.
Giorgio Maria Di Nunzio.
2009.
Using Scatterplots
to Understand and Improve Probabilistic Models for
Text
Categorization and Retrieval.
Int.
J.
Approx.
Reasoning, 50(7):945–956.
Giorgio Maria Di Nunzio.
2014.
A New Decision to
Take for Cost-Sensitive Na
¨
ıve Bayes Classifiers.
In-
formation Processing & Management,
50(5):653 –
674.
Fernando Diaz,
2016.
Pseudo-Query Reformulation,
pages 521–532.
Springer International Publishing,
Cham.
Miles Efron.
2009.
Using multiple query aspects to
build test collections without human relevance judg-
ments.
In Proceedings of the 31th European Con-
ference on IR Research on Advances in Information
Retrieval, ECIR ’09, pages 276–287, Berlin, Heidel-
berg. Springer-Verlag.
Carsten Eickhoff.
2014.
Crowd-powered experts:
Helping surgeons
interpret
breast
cancer
images.
In Proceedings of the First International Workshop
on Gamification for Information Retrieval, GamifIR
’14, pages 53–56, New York, NY, USA. ACM.
Kar
¨
en Fort,
Bruno Guillaume,
and Hadrien Chastant.
2014.
Creating zombilingo, a game with a purpose
for dependency syntax annotation.
In Proceedings
of the First International Workshop on Gamification
for Information Retrieval, GamifIR ’14, pages 2–6,
New York, NY, USA. ACM.
Luca Galli,
Piero Fraternali,
and Alessandro Boz-
zon.
2014.
On the Application of Game Mechan-
ics in Information Retrieval.
In Proc.
of
the 1st
Int. Workshop on Gamification for Information Re-
trieval,
GamifIR’14,
pages 7–11,
New York,
NY,
USA. ACM.
Ahmed Hassan,
Xiaolin Shi,
Nick Craswell,
and Bill
Ramsey.
2013.
Beyond clicks: query reformulation
as a predictor of search satisfaction.
In Proceedings
of the 22nd ACM international conference on Con-
ference on information &#38; knowledge manage-
ment, CIKM ’13, pages 2019–2028, New York, NY,
USA. ACM.
CLIC_2016_Proceedings.indd 127
02/12/16 15.03
128
Chien-Ju Ho,
Shahin Jabbari,
and Jennifer Wortman
Vaughan.
2013.
Adaptive task assignment
for
crowdsourced classification.
In Proceedings of the
30th International
Conference on Machine Learn-
ing, ICML 2013, volume 28 of JMLR Proceedings,
pages 534–542. JMLR.org.
Jose Luis Jurado,
Alejandro Fernandez,
and Cesar A.
Collazos.
2015.
Applying gamification in the con-
text
of
knowledge management.
In Proceedings
of the 15th International Conference on Knowledge
Technologies and Data-driven Business,
i-KNOW
’15, pages 43:1–43:4, New York, NY, USA. ACM.
Karl M Kapp.
2012.
The gamification of learning and
instruction: game-based methods and strategies for
training and education.
John Wiley & Sons.
Isabella
Kotini
and
Sofia
Tzelepi.
2015.
A
Gamification-Based
Framework
for
Developing
Learning Activities of Computational Thinking.
In
Torsten Reiners and C. Lincoln Wood, editors, Gam-
ification in Education and Business, pages 219–252.
Springer Int. Publ., Cham.
Mathias
Lux,
Mario
Guggenberger,
and
Michael
Riegler.
2014.
Picturesort:
Gamification of im-
age ranking.
In Proceedings of
the First
Interna-
tional
Workshop on Gamification for Information
Retrieval,
GamifIR ’14,
pages 57–60,
New York,
NY, USA. ACM.
Carlos Maltzahn,
Arnav Jhala,
Michael
Mateas,
and
Jim Whitehead.
2014.
Gamification of private digi-
tal data archive management.
In Proceedings of the
First
International
Workshop on Gamification for
Information Retrieval,
GamifIR ’14,
pages 33–37,
New York, NY, USA. ACM.
Jos
´
e M.
Perea-Ortega,
Miguel
A.
Garc
´
ıa-Cumbreras,
and L. Alfonso Ure
˜
na L
´
opez.
2013.
Applying nlp
techniques for query reformulation to information
retrieval with geographical references.
In Proceed-
ings of the 2012 Pacific-Asia Conference on Emerg-
ing Trends in Knowledge Discovery and Data Min-
ing,
PAKDD’12,
pages 57–69,
Berlin,
Heidelberg.
Springer-Verlag.
Fr
´
ed
´
eric Roulland, Aaron Kaplan, Stefania Castellani,
Claude Roux,
Antonietta Grasso,
Karin Pettersson,
and Jacki O’Neill, 2007.
Query Reformulation and
Refinement Using NLP-Based Sentence Clustering,
pages 210–221.
Springer Berlin Heidelberg, Berlin,
Heidelberg.
Burr Settles.
2011.
Closing the loop:
Fast,
interac-
tive semi-supervised annotation with queries on fea-
tures and instances.
In Proceedings of
the 2011
Conference on Empirical Methods in Natural Lan-
guage Processing,
EMNLP 2011,
27-31 July 2011,
John McIntyre Conference Centre,
Edinburgh,
UK,
A meeting of
SIGDAT,
a Special
Interest
Group of
the ACL, pages 1467–1478.
Mark Shovman.
2014.
The Game of Search:
What is
the Fun in That?
In Proc. of the 1st Int. Workshop
on Gamification for Information Retrieval,
Gami-
fIR’14, pages 46–48, New York, NY, USA. ACM.
Rita Singh and Bhiksha Raj.
2004.
Classification in
likelihood spaces.
Technometrics, 46(3):318–329.
Laurentiu Catalin Stanculescu,
Alessandro Bozzon,
Robert-Jan Sips,
and Geert-Jan Houben.
2016.
Work and play: An experiment in enterprise gamifi-
cation.
In Proceedings of the 19th ACM Conference
on Computer-Supported Cooperative Work & Social
Computing, CSCW ’16, pages 346–358, New York,
NY, USA. ACM.
Tomek Strzalkowski,
Fang Lin,
Jose Perez-Carballo,
and Jin Wang.
1997.
Building effective queries
in natural
language information retrieval.
In Pro-
ceedings of the Fifth Conference on Applied Natural
Language Processing,
ANLC ’97,
pages 299–306,
Stroudsburg,
PA,
USA.
Association for Computa-
tional Linguistics.
Jennifer
Thom,
David Millen,
and Joan DiMicco.
2012.
Removing gamification from an enterprise
sns.
In Proceedings of the ACM 2012 Conference
on Computer Supported Cooperative Work,
CSCW
’12, pages 1067–1070, New York, NY, USA. ACM.
Kazutoshi
Umemoto,
Takehiro Yamamoto,
and Kat-
sumi
Tanaka.
2016.
Scentbar:
A query sugges-
tion interface visualizing the amount of missed rele-
vant information for intrinsically diverse search.
In
Proceedings of
the 39th International
ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval,
SIGIR ’16,
pages 405–414,
New
York, NY, USA. ACM.
Michael J.
Welch,
Junghoo Cho,
and Christopher Ol-
ston.
2011.
Search result diversity for informational
queries.
In Proceedings of
the 20th International
Conference on World Wide Web,
WWW ’11,
pages
237–246, New York, NY, USA. ACM.
CLIC_2016_Proceedings.indd 128
02/12/16 17.47
129
Topic Modelling with Word Embeddings
Fabrizio Esposito
Dept. of Humanities
Univ. of Napoli Federico II
fabrizio.esposito3
@unina.it
Anna Corazza, Francesco Cutugno
DIETI
Univ. of Napoli Federico II
anna.corazza|francesco.cutugno
@unina.it
Abstract
English.
This
work aims
at
evaluat-
ing and comparing two different
frame-
works
for
the unsupervised topic mod-
elling of the CompWHoB Corpus, namely
our political-linguistic dataset.
The first
approach is represented by the application
of the latent DirichLet Allocation (hence-
forth LDA), defining the evaluation of this
model as baseline of comparison. The sec-
ond framework employs Word2Vec tech-
nique to learn the word vector representa-
tions to be later used to topic-model
our
data.
Compared to the previously de-
fined LDA baseline,
results show that the
use of Word2Vec word embeddings signif-
icantly improves topic modelling perfor-
mance but only when an accurate and task-
oriented linguistic pre-processing step is
carried out.
Italiano.
L’obiettivo di questo contributo
`
e di
valutare e confrontare due differen-
ti
framework per l’apprendimento auto-
matico del topic sul CompWHoB Corpus,
la nostra risorsa testuale.
Dopo aver im-
plementato il modello della latent Dirich-
Let
Allocation,
abbiamo definito come
standard di
riferimento la valutazione di
questo stesso approccio.
Come secondo
framework,
abbiamo utilizzato il modello
Word2Vec per apprendere le rappresen-
tazioni
vettoriali
dei
termini
successiva-
mente impiegati
come input
per la fase
di apprendimento automatico del topic.
I
risulati
mostrano che utilizzando i
‘word
embeddings’
generati
da Word2Vec,
le
prestazioni del modello aumentano signifi-
cativamente ma solo se supportati da una
accurata fase di ‘pre-processing’ linguisti-
co.
1
Introduction
Over
recent
years,
the development
of
political
corpora (Guerini et al., 2013; Osenova and Simov,
2012) has represented one of the major trends in
the fields of
corpus and computational
linguis-
tics.
Being carriers of specific content
features,
these textual resources have met the interest of re-
searchers and practitioners in the study of topic
detection.
Unfortunately,
not
only has this task
turned out
to be hard and challenging even for
human evaluators but
it
must
be borne in mind
that manual annotation often comes with a price.
Hence, the aid provided by unsupervised machine
learning techniques proves to be fundamental
in
addressing the topic detection issue.
Topic models are a family of algorithms that
al-
low to analyse unlabelled large collections of doc-
uments in order to discover and identify hidden
topic patterns in the form of
cluster
of
words.
While LDA (Blei
et
al.,
2003)
has become the
most
influential
topic model
(Hall
et
al.,
2008),
different
extensions have been proposed so far:
Rosen-Zvi et al.
(Rosen-Zvi et al.,
2004) devel-
oped an author-topic generative model to include
also authorship information; Chang et al.
(Chang
et al.,
2009a) presented a probabilist topic model
to infer descriptions of entities from corpora iden-
tifying also the relationships between them;
Yi
Yang et al.
(Yang et al.,
2015) proposed a factor
graph framework for incorporating prior knowl-
edge into LDA.
In the present
paper we aim at
topic modelling
the CompWHoB Corpus (Esposito et
al.,
2015),
a political corpus collecting the transcripts of the
White House Press Briefings.
The main charac-
teristic of
our
dataset
is represented by its dia-
logical structure:
since the briefing consists of a
question-answer sequence between the US press
secretary and the news media, the topic under dis-
cussion may change from one answer to the fol-
CLIC_2016_Proceedings.indd 129
02/12/16 17.47
130
lowing question, and vice versa.
Our purpose was
to address this main feature of the CompWHoB
Corpus associating at
each answer/question only
one topic.
In order to reach our goal, we propose
an evaluative comparison of two different frame-
works: in the first one, we employed the LDA ap-
proach by extracting from each answer/question
document
only the topic with the highest
proba-
bility;
in the second framework,
we applied the
word embeddings generated from the Word2Vec
model
(Mikolov and Dean,
2013) to our data in
order to test how dense high-quality vectors repre-
sent our data, finally comparing this approach with
the previously defined LDA baseline.
The evalua-
tion was performed using a set
of gold-standard
annotations developed by human experts in po-
litical
science and linguistics.
In Section 2 we
present the dataset used in this work. In Section 3,
the linguistic pre-processing is detailed. Section 4
shows the methodology employed to topic-model
our data. In Section 5 we present the results of our
work.
2
The dataset
2.1
The CompWHoB Corpus
The textual
resource used in the present
contri-
bution is the CompWHoB (Computational White
House press Briefings)
Corpus,
a political
cor-
pus collecting the transcripts of the White House
Press Briefings extracted from the American Pres-
idency Project
website,
annotated and formatted
into XML encoding according to TEI Guidelines
(Consortium et al., 2008).
The CompWHoB Cor-
pus spans from January 27, 1993 to December 18,
2014.
Each briefing is characterised by a turn-
taking between the podium and the journalists,
signalled in the XML files by the use of a u tag for
each utterance. At the time of writing, 5,239 brief-
ings have been collected,
comprising 25,251,572
tokens and a total
number of 512,651 utterances
(from now on,
utterances will
be referred to as
‘documents’).
The document average length has
been measured to 49.25 tokens,
while its length
variability is comprised within a range of a min-
imum of 0 and a maximum of 4724 tokens.
The
dataset used in the present contribution was built
and divided into training and test set by randomly
selecting documents from the CompWHoB Cor-
pus in order to vary as much as possible the topics
dealt with by US administration.
2.2
Gold-Standard Annotation
Two hundred documents of the test set were man-
ually annotated by scholars with expertise in lin-
guistics and political science using a set of thirteen
categories.
Seven macro-categories were created
taking into account
the US major federal
execu-
tive departments so as not to excessively narrow
the topic representation,
accounting for 28.5% of
the labelled documents.
Six more categories were
designed in order to take into account the informal
nature of the press briefings that
makes them an
atypical political-media genre (Venuti and Spinzi,
2013),
accounting for the remaining 71.5% (Ta-
ble 1). The labelled documents represent the gold-
standard to be used in the evaluation stage.
This
choice is motivated by the fact that even if metrics
such as perplexity or held-out likelihood prove to
be useful in the evaluation of topic models,
they
often fail in qualitatively measuring the coheren-
ce of the generated topics (Chang et al.,
2009b).
Thus, more formally our gold-standard can be de-
fined as the set
G
=
{
g
1
, g
2
, ..., g
S
}
where
g
i
is
the
i
th category in a range
{
1
, S
}
with
S
= 13
as
the total number of categories.
Crime and justice
Culture and Education
Economy and welfare
Foreign Affairs
Greetings
Health
Internal Politics
Legislation & Reforms
Military & Defense
President Updates
Presidential News
Press issues
Unknown topic
Table 1: Gold-Standard Topics
3
Linguistic Pre-Processing
In order to improve the quality of our textual data,
special
attention was paid to the linguistic pre-
processing step.
In particular,
since LDA repre-
sents documents as mixtures of topics in forms of
words probability, we wanted these topics to make
sense also to human judges.
Being press briefings
actual
conversations where the talk moves from
one social
register to another (e.g.
switch from
the reading of an official statement to an informal
interaction between the podium and the journal-
ists) (Partington,
2003),
the first
step was to de-
sign an ad-hoc stoplist able to take into account the
main features of this linguistic genre.
Indeed, not
only were words with a low frequency discarded,
CLIC_2016_Proceedings.indd 130
02/12/16 15.03
131
but also high frequency ones were removed in or-
der not
to overpower the rest
of the documents.
More importantly,
we included in our stoplist all
the personal and indefinite pronouns as well as the
most
commonly used honorifics (e.g.
Mr.,
Ms.,
etc.),
given their predominant
role in addressing
the speakers in both informal and formal settings
(e.g. “Mr. Secretary, you said oil production is up,
[...]”).
Moreover, the list of the first names of the
press secretaries in office during the years covered
by the CompWHoB Corpus was extracted from
Wikipedia and added to the stoplist,
since most
of the time used only as nouns of address (Brown
et al., 1960).
As regards the proper NLP pipeline
implemented in this work,
the Natural Language
ToolKit
1
(NLTK) platform (Bird et al., 2009) was
employed: word tokenization, POS-tagging, using
the Penn Treebank tag set
(Marcus et
al.,
1993)
and lemmatization were carried out to refine our
data.
When pre-processing is not
applied to the
dataset, only punctuation is removed from the doc-
uments.
4
Methodology
This section deals with the two techniques em-
ployed in this work to topic-model our data.
We
first discuss the LDA approach and then focus on
the use of the word embeddings learnt employing
Word2Vec model.
Both the techniques were im-
plemented in Python (version 3.4) using the Gen-
sim
2
library (Rehurek and Sojka, 2010).
4.1
Latent DirichLet Allocation
In our
first
experiment
we ran LDA,
a genera-
tive probabilistic model that allows to infer latent
topics in a collection of documents.
In this un-
supervised machine learning technique the topic
structure represents the underlying hidden variable
(Blei,
2012) to be discovered given the observed
variables,
i.e.
documents’ items from a fixed vo-
cabulary,
be them textual or not.
More formally,
LDA describes each document
d
as multinomial
distribution
θ
d
over topics, while each topic
t
is de-
fined as a multinomial distribution
φ
t
over words
in a fixed vocabulary where
i
d,n
is the
n
th item in
the document
d
.
4.1.1
Topic modelling with LDA
Data were linguistically pre-processed prior
to
training LDA model
and only words pos-tagged
1
http://www.nltk.org
2
https://radimrehurek.com/gensim/
as nouns (‘NN’) were kept in both the training and
test sets’ documents.
This choice was motivated
by the necessity of generating topics that could be
semantically meaningful. After having carried out
the pre-processing step,
we trained LDA model
on our training corpus by employing the online
variational Bayes (VB) algorithm (Hoffman et al.,
2010) provided by the Gensim library.
Based on
online stochastic optimization with a natural gra-
dient step, LDA online proves to converge to a lo-
cal optimum of the VB objective function.
It can
be applied to large streaming document collections
being able to make better predictions and find bet-
ter topic models with respect to those found with
batch VB. As parameters of our model, we set the
k
number of topics to thirteen as the numbers of
classes in our gold-standard,
updating the model
every 150 documents and giving two passes over
the corpus in order to generate accurate data. Once
the model was trained, we inferred topic distribu-
tions on the unseen documents of the test set.
For
each document
d
i
, the topic
t
max(i)
with the high-
est probability in the multinomial distribution was
selected and associated to it.
The cluster
ω
k
cor-
responds then to the set of documents associated
to the topic
t
k
.
Due to the presence of a gold-
standard, the external criterion of purity was cho-
sen as evaluation measure of this approach. Purity
is formally defined as:
purity
(Ω
, G
) =
1
N

k
max
j
|
w
k
∪
g
j
|
Ω =
{
ω
1
, ω
2
, ..., ω
K
}
is the set
of clusters and
G
=
{
g
1
, g
2
, ..., g
S
}
is the set
of gold-standard
classes.
The purity computed for the LDA ap-
proach is:
purity
≈
0
.
46
This measure constituted the baseline of compar-
ison with the Word2Vec word embeddings ap-
proach.
4.2
Word2Vec
Word2Vec (Mikolov et al., 2013a) is probably the
most popular software providing learning models
for the generation of dense embeddings.
Based
on Zelig Harris’
Ditributional
Hypothesis (Har-
ris,
1954) stating that words occurring in similar
contexts tend to have similar meanings, Word2Vec
model
allows to learn vector
representations of
words referred to as word embeddings. Differently
from techniques such as LSA (Dumais,
2004),
CLIC_2016_Proceedings.indd 131
02/12/16 15.03
132
LDA and other topic models that use documents as
context, Word2Vec learns the distributed represen-
tation for each target word by defining the context
as the terms surrounding it.
The main advantage
of this model is that each dimension of the embed-
ding represents a latent feature of the word (Turian
et al., 2010), encoding in each word vector essen-
tial syntactic and semantic properties (Mikolov et
al.,
2013c).
In this way,
simple vector similarity
operations can be computed using cosine similar-
ity.
Moreover, it must not be forgotten that one of
Word2Vec’s secrets lies in its efficient implemen-
tation that allows a very robust and fast training.
4.2.1
Topic modelling with Word2Vec
Training data were linguistically pre-processed
beforehand according to the ad-hoc pipeline im-
plemented in this work. The model was initialised
setting a minimum count
for
the input
words:
terms whose frequency was lower than 20 were
discarded.
In addition,
we set the default thresh-
old at
1 exp
−
3
for configuring the high-frequency
words to be randomly downsampled in order to
improve word embeddings quality (Mikolov and
Dean,
2013).
Moreover,
as highlighted by Gold-
berg and Levy (Goldberg and Levy,
2014),
both
sub-sampling and rare-pruning seem to increase
the effective size of the window making the sim-
ilarities more topical.
Finally,
based on the rec-
ommendation of Mikolov et
al.
(Mikolov et
al.,
2013b) and Baroni et al.
(Baroni et al., 2014), in
this work we trained our model using the CBOW
algorithm since more suitable for larger datasets.
The dimensionality of
our
feature vectors
was
fixed at 200. Once constructed the vocabulary and
trained the input
data,
we used the learnt
word
vector representations on our unseen test set docu-
ments. Then, we calculated the centroid
c
for each
document
d
, where
e
d,i
is the
i
th embedding in
d
,
so as to obtain a meaningful topic representation
for each document (Mikolov and Dean, 2013). Fi-
nally, we clustered our data using the k-means al-
gorithm.
In order to compare our approach with
the baseline previously defined,
the external
cri-
terion of purity was computed also in this experi-
ment to evaluate how well the k-means clustering
matched the gold-standard classes:
purity
≈
0
.
54
This
technique proved to outperform the LDA
topic model approach presented in this work. Sur-
prisingly, notwithstanding the fact that Word2Vec
relies on a broad context to produce high-quality
embeddings,
this framework showed to perform
better using a linguistically pre-processed dataset
where only nouns are kept.
Table 2 shows the re-
sults obtained in the two experiments.
Topic Models Results
Framework
Results
LDA without pre-processing
0.45
LDA with pre-processing
0.46
Word2Vec without pre-processing
0.44
Word2Vec with pre-processing
0.54
Table 2:
Results of the two frameworks.
When
pre-preprocessing is not applied, only punctuation
is removed.
5
Conclusions
In this contribution we have presented a compara-
tive evaluation of two unsupervised learning ap-
proaches to topic modelling.
Two experiments
were carried out:
in the first
one,
we applied a
classical
LDA model
to our dataset;
in the sec-
ond one,
we trained our model
using Word2Vec
so as to generate the word embeddings for topic-
modelling our test set.
After clustering the output
of the two approaches,
we evaluated them using
the external criterion of purity.
Results show that
the use of word embeddings outperforms the LDA
approach but only if a linguistic task-oriented pre-
processing stage is carried out.
As at
the mo-
ment
no comprehensive explanation can be pro-
vided,
we can only suggest that the main reason
for these results may lie in the fluctuating length
of each document in our dataset.
In fact,
we hy-
pothesise that
the use of word embeddings may
prove to be the boosting factor of Word2Vec topic
model since encoding information about the close
context of the target term.
As part of future work,
we aim to further investigate this aspect
and de-
sign a topic model framework that could take into
account the main structural and linguistic features
of the CompWHoB Corpus.
Acknowledgments
The authors would like to thank Antonio Origlia
for the useful and thoughtful discussions and in-
sights.
CLIC_2016_Proceedings.indd 132
02/12/16 15.03
133
References
Marco
Baroni,
Georgiana
Dinu,
and
Germ
´
an
Kruszewski.
2014.
Don’t
count,
predict!
a
systematic
comparison
of
context-counting
vs.
context-predicting semantic vectors.
In ACL (1),
pages 238–247.
Steven
Bird,
Ewan
Klein,
and
Edward
Loper.
2009.
Natural
Language Processing with Python.
O’Reilly Media.
David M Blei,
Andrew Y Ng,
and Michael
I Jordan.
2003.
Latent Dirichlet Allocation.
Journal of ma-
chine Learning research, 3(Jan):993–1022.
David M Blei.
2012.
Probabilistic Topic Models.
Communications of the ACM, 55(4):77–84.
Roger Brown,
Albert Gilman,
et al.
1960.
The Pro-
nouns of Power and Solidarity.
Style in language,
pages 253–276.
Jonathan Chang,
Jordan Boyd-Graber,
and David M.
Blei.
2009a.
Connections between the Lines:
Aug-
menting Social Networks with Text.
In Knowledge
Discovery and Data Mining.
Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L
Boyd-Graber,
and David M Blei.
2009b.
Reading
Tea Leaves:
How Humans Interpret Topic Models.
In Advances in neural
information processing sys-
tems, pages 288–296.
TEI
Consortium,
Lou Burnard,
Syd Bauman,
et
al.
2008.
TEI P5: Guidelines for electronic text encod-
ing and interchange.
TEI Consortium.
Susan T Dumais.
2004.
Latent semantic analysis.
An-
nual review of information science and technology,
38(1):188–230.
Fabrizio Esposito,
Pierpaolo Basile,
Francesco Cu-
tugno, and Marco Venuti.
2015.
The CompWHoB
Corpus:
Computational
Construction,
Annotation
and Linguistic Analysis of the White House Press
Briefings Corpus.
CLiC it, page 120.
Yoav Goldberg and Omer
Levy.
2014.
word2vec
Explained:
deriving
Mikolov
et
al.’s
negative-
sampling word-embedding method.
arXiv preprint
arXiv:1402.3722.
Marco
Guerini,
Danilo
Giampiccolo,
Giovanni
Moretti, Rachele Sprugnoli, and Carlo Strapparava.
2013.
The New Release of CORPS:
A Corpus of
Political Speeches Annotated with Audience Reac-
tions.
In Multimodal
Communication in Political
Speech.
Shaping Minds and Social
Action,
pages
86–98. Springer.
David Hall,
Daniel Jurafsky,
and Christopher D Man-
ning.
2008.
Studying the History of Ideas Using
Topic Models.
In Proceedings of the conference on
empirical methods in natural language processing,
pages 363–371. Association for Computational Lin-
guistics.
Zellig S Harris.
1954.
Distributional Structure.
Word,
10(2-3).
Matthew Hoffman, Francis R Bach, and David M Blei.
2010.
Online Learning for latent Dirichlet Alloca-
tion.
In advances in neural information processing
systems, pages 856–864.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz.
1993.
Building a Large Annotated
Corpus of English:
The Penn Treebank.
COMPU-
TATIONAL LINGUISTICS, 19(2):313–330.
T Mikolov and J Dean.
2013.
Distributed Representa-
tions of Words and Phrases and their Compositional-
ity.
Advances in neural information processing sys-
tems.
Tomas Mikolov,
Kai
Chen,
Greg Corrado,
and Jef-
frey Dean.
2013a.
Efficient
Estimation of Word
Representations in Vector
Space.
arXiv preprint
arXiv:1301.3781.
Tomas
Mikolov,
Quoc
V Le,
and Ilya
Sutskever.
2013b.
Exploiting
Similarities
among
Lan-
guages for
Machine Translation.
arXiv preprint
arXiv:1309.4168.
Tomas Mikolov,
Wen-tau Yih,
and Geoffrey Zweig.
2013c.
Linguistic Regularities in Continuous Space
Word Representations.
In HLT-NAACL, volume 13,
pages 746–751.
Petya Osenova and Kiril Simov.
2012.
The Political
Speech Corpus of Bulgarian.
In Nicoletta Calzo-
lari, Khalid Choukri, Thierry Declerck, Mehmet Uur
Doan,
Bente Maegaard,
Joseph Mariani,
Asuncion
Moreno,
Jan Odijk,
and Stelios Piperidis,
editors,
Proceedings of
the Eight
International
Conference
on Language Resources and Evaluation (LREC’12),
Istanbul,
Turkey,
may.
European Language
Re-
sources Association (ELRA).
Alan Partington.
2003.
The Linguistics of
Political
Argument:
The Spin-Doctor and the Wolf-Pack at
the White House.
Routledge.
Radim Rehurek and Petr
Sojka.
2010.
Software
Framework for
Topic Modelling with Large Cor-
pora.
In In Proceedings of the LREC 2010 Workshop
on New Challenges for NLP Frameworks. Citeseer.
Michal
Rosen-Zvi,
Thomas Griffiths,
Mark Steyvers,
and Padhraic Smyth.
2004.
The Author-Topic
Model for Authors and Documents.
In Proceedings
of
the 20th conference on Uncertainty in artificial
intelligence, pages 487–494. AUAI Press.
Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.
Word representations:
a simple and general method
for semi-supervised learning.
In Proceedings of the
48th annual meeting of the association for compu-
tational linguistics, pages 384–394. Association for
Computational Linguistics.
CLIC_2016_Proceedings.indd 133
02/12/16 15.03
134
M Venuti and C Spinzi.
2013.
Tracking the change in
institutional genre: a diachronic corpus-based study
of White House Press Briefings.
The three waves
of
globalization:
winds of
change in Professional,
Institutional and Academic Genres.
Yi Yang, Doug Downey, Jordan Boyd-Graber, and Jor-
dan Boyd Graber.
2015.
Efficient Methods for In-
corporating Knowledge into Topic Models.
In Pro-
ceedings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing.
CLIC_2016_Proceedings.indd 134
02/12/16 15.03
135
Spammare senza pietà - Corpus based analysis of English, un-
acclimatised verb loans in Italian and creation of a reference lexicon 
Anna Fantini 
Università degli studi di Pavia 
anna.fantini01@universitadipavia.it 
Abstract 
English
. 
We describe the lexical resource 
created to investigate the semantic changes of 
90 
English, 
un-acclimatised 
verb 
loans 
in 
Italian. Final results and interesting observa-
tions concerning the annotation task are dis-
cussed.
Italiano
. 
Descriviamo 
la 
risorsa 
lessicale 
creata per indagare in italiano il cambiamen-
to semantico di 90 prestiti verbali inglesi non 
acclimatati. Illustriamo i risultati finali e le 
interessanti osservazioni emerse dall'esperi-
mento di annotazione.
1
Introduction 
The case of language borrowing was investigated 
in depth by Gusmani (1983), who argues that a 
linguistic loan is an interference phenomenon, 
connected with contact and mutual influence of 
different languages. According to his study, the 
motivations behind the origin of a loan lie in the 
individual act of a speaker or of a group of 
speakers. The need to resort to a foreign alterna-
tive derives from the prestige held by the latter 
against an equivalent word in the mother tongue 
of the speaker (or from the absence all together 
of an alternative, as in our work: “
Se mi vede, 
Miki mi banna
(<to ban)” vs. *“
Se mi vede Miki 
mi bandisce
”). 
Facts show that language borrowing is particular-
ly common among specialized languages, more 
so if they are linked to technical contexts. 
This is extremely visible within the computer 
context. The main focus of this paper is the in-
formal variety of Italian as used by communities 
of online video-gamers, computer experts and 
amateurs, forum users, etc.; a specialized lan-
guage linked to technical context populated with 
partially integrated and un-acclimatised English 
verb loans. 
These kinds of (mostly) lexical influences are so 
recent that their structure is hardly stable, and the 
process of integration – graphical, morphologi-
cal, phonetic, and lexical – 
in the language is still 
in progress. For instance, they tend to retain the 
phonetic property of the original word, especially 
of 
the 
lexical 
root 
(to 
spawn 
> 
spawnare
/spo’nare/). 
The new word serves as an alternative – usually 
a hyponym – of an already existing term
1
. As for 
the concept of loan acclimatisation, the literature 
states that it involves the role of the new term in 
the target language. Therefore, Gusmani speaks 
of acclimatisation only with regard to the lexicon 
and 
its 
connection 
with 
speakers’ 
usage: 
the 
more they familiarise with the loan, the more the 
latter gets acclimatised. It follows that – for very 
recent, scarcely integrated loans – the majority of 
speakers, as well as linguistic authorities, do not 
perceive the influence of English as an enrich-
ment of the lexical heritage but mostly as a nui-
sance. If it is true that a number of reports de-
scribe the interference of English over Italian as 
an 
impoverishment, 
some 
attempts 
have 
also 
been made to study the less acclimatized loans 
themselves. It is thus of interest to examine why 
this kind of loan infiltrates the Italian language, 
how the speakers cope with the new word and 
what is the semantics of the loan in the target 
language. The aim of the present paper is to give 
a detailed account of how the meaning of a verb 
loan changes (and if it changes) in the target lan-
guage and to offer a reliable source of lexical 
information in the form of an electronic lexicon 
built for the occasion. Section 2 details the meth-
od used to collect suitable data; section 3 illus-
trates 
the structure and functions of the lexicon; 
section 4 provides the results of our analysis as 
well as the annotation task performed with our 
data; section 5 discusses our findings and section 
6 finally provides a conclusion. 
2
Methods 
In order to investigate the semantics of English 
un-acclimatized verb loans, we examined their 
occurrence in a monitor web-c
orpus created for 
1
E.g. 
googlare
< to google as hyponym of 
cercare
.
CLIC_2016_Proceedings.indd 135
02/12/16 15.03
136
this purpose, following the guidelines and in-
structions of previous Corpus Linguistics works 
(Baroni and Kilgarriff, 2001; Lenci et al., 2012; 
McEnery, Xiao, Tono, 2006; Pomikálek, 2011; 
Pustejovsky and Stubbs, 2012). The corpus con-
tains 
6 
transcriptions 
from 
a 
total 
of 
194,07 
minutes of audio material, collected with consen-
sual but unaware recordings and then transcribed 
using the software Elan 4.9.6 (Wittenburg et al., 
2006), 
plus 
129 
texts 
obtained 
through 
the 
Sketch Engine web-crawler, suitably set. We ex-
tracted a sum of 90 different verb lemmas (542 
different word forms), for a total of 1327 occur-
rences. The annotation involves a POS level – 
limited to the sentence containing the loan – a 
loan-type level – describing three degrees of lan-
guage integration
2
– a semantic type level
3
and a 
thematic role level
4
. The last two levels have 
been annotated using the tags proposed in Jezek 
and Nissim (2014) and Jezek and Vieu (2013) 
respectively. 
Every text has been annotated using the Mae 
software (Stubbs 2011). An annotation task was 
conducted using a sample of the corpus (see sec-
tion 4.2), its agreement result being only partially 
positive but interesting nonetheless from a lin-
guistic point of view. 
The next part of our research involved the analy-
sis of the semantic patterns for each lemma
5
, thus 
compiling one or more data-driven senses for 
every verb. The senses obtained were classified 
according to Verb Net’s semantic class hierar-
chy. 
The 
assumptions 
underlying 
this 
in-
vestigation 
are 
grounded 
on 
Corpus 
Pattern 
Analysis (CPA) and Computational Lexicogra-
phy (Hanks 2008; Hanks 2012; Jezek 2011). 
Verb patterns have – in general – the following 
structure, where: 
(1) 
Spammare
2b 
Agent[PERSON] 
V_
spammare
(Theme[ARTEFACT | ABSTRACT]). 
We have chosen all uppercase for the semantic 
type, and first letter uppercase for the thematic 
role, extended to every argument of the verb. 
Round 
brackets 
contain 
the 
possible 
optional 
arguments of the verb.
2
Totally integrated, e.g. 
spammare
; partially integrated 
(grafic), e.g. 
trackare
; partially integrated (phonetics), e.g. 
spawnare
/sp'nare/.
3
E.g. Person, Artefact, Location, Abstract, etc. 
4
E.g. Agent, Patient, Goal, Source, Duration, ect.
5
From Hanks, Pustejovsky 2005, a pattern is intended here 
as an argument structure with specifications of both the 
thematic roles and the semantic types of each argument 
positions. 
3
The Lexicon 
After extracting the semantic patterns for each 
lemma from the corpus, we stored the informa-
tion 
in 
an 
electronic 
lexicon, 
built 
using 
the 
software 
Personal 
Lexicon 
2.7.1, 
a 
language 
learning resource developed by Alexander Smith 
between 2007 and 2015. The software comes 
both in free and registered vers
ions, the current 
lexicon has been compiled – and it will be con-
sultable – using the free version.
6
The lexicon is designed to give a precise ac-
count of every semantic feature and every mean-
ing variation of the verb loans. As the reader will 
see observing Figure 1, each entry is character-
ized by the following elements (some of them 
pre-named 
in 
the 
software): 
“Figure 1. The 
spammare 
2b lexical entry” 

The entry citation form, with the number 
of the sense or of the sub-sense
7
; 

The Pronunciation of the citation form; 

The Class (pre-named) as in the loan type 
which it belongs to (whether it is fully in-
tegrated or only partially integrated); 

The Root element, as in the lexical English 
root it comes from; 

The Theme (pre-named), as in the Verb 
Net class it was reduced to; 

The Definition box, containing the lexical 
definition and the verb pattern; 

The Related entries in the lexicon, all ac-
cessible through hyperlink; 

The Personal Examples, used to extract the 
pattern. 
In figure 2 we show the Conjugations tab (pre-
named) that includes all the syntactic comple-
ments 
of the verb and their semantic properties 
(thematic roles and semantic types). 
6
The resource is not yet available for public consultation..
7
Sub-senses corresponding to GRADIT’s 
accezioni
, the 
progressively numbered paragraphs a sense is pos-sibly 
divided into.
CLIC_2016_Proceedings.indd 136
02/12/16 15.03
137
“Figure 2. Lexicon conjugation tab” 
We listed the grammatical subject, the direct ob-
ject, the indirect object and up to ten different 
indirect complements. Notice that the semantic 
type slot may specify more than one element, in 
which case we used the | separator. 
In figure 3 we illustrate the Themes section of 
the lexicon, with a partial list of Verb Net classes 
and 
sub-classes 
used 
in 
the 
resource. 
“Figure 3. Lexicon Theme section” 
Clicking on each one produces the list of entries 
belonging to that particular class; this list appears 
in the third section of the lexicon, the Lexical 
Items column storing all the entries ordered al-
phabetically. 
4
The Results 
In this section we report the results of both the 
semantic analysis of the loans and the annotation 
task.
4.1
Quantitative considerations 
The lexicon contains 157 senses for a total of 
90 verbs. As shown in Table 1, the 157 senses 
have been classified into 3 groups according to 
three main criteria about the degree of semantic 
conservativeness of the loan: 
1 The meaning remains the same as the origi-
nal verb. 
2 The meaning remains linked to the original 
one, but it diversifies to some degree. 
3 The meaning changes to the point that it be-
comes a new meaning altogether 
Group #
Type
Numbers
Group 1 
Same sense 
88 
New verb form 
11 
Group 2 
Diversified sense 
25 
Group 3 
New sense 
26 
New v. and new sense 
7 
Senses 
157 
“Table 1. Senses sorted according to their se-
mantic behaviour” 
Group 1 coincides with 63% of the total (99 
senses out of 157), 11 senses have also new verb 
forms (
bishottare, autospottare
), 78 
senses occur 
in 1 to 10 examples – they often have new verb 
forms 
(
riloggare
) 
or 
a 
very 
specific 
meaning 
(
rippare
)
8
. In this group there is the highest per-
centage (41%) of monosemic verbs. 
Group 2 coincides with 15% of the total (25 
senses out of 157), 19 senses occur only in 1 to 
10 examples – they do not have a very specific 
meaning, but may be considered as hyponyms of 
Italian verbs (
farmare
2 of 
sfruttare
)
9
. In this 
group there is the lowest percentage (16%) of 
monosemic verbs – their distribution prove
d not 
to be directly proportional to the senses’ quanti-
ty. 
Group 3 coincides with 25% of the total (33 
senses out of 157), 24 senses occur only in 1 to 
10 examples yet we also have the senses occur-
ring in the highest number of examples (
drop-
pare
1
10
and 2
11
with 189 examples). In this 
group 27% of the verbs are monosemic. 
4.2
The inter annotator agreement 
The semantic annotation task was conducted 
following the methodology of Pustejovksy and 
Stubbs (2012); only a sample of 440 random oc-
currences 
was 
annotated 
by 
9 
groups 
of 
an-
annotators, each constituted by 3 people. They 
were given guidelines explaining the method and 
the tagsets, and they were asked to separately 
annotate the semantic type and the thematic role 
of each verbal argument. We used Fleiss’
k
algo-
rithm to calculate the agreement
12
(Artstein and 
Poesio, 2008), the values being interpreted ac-
cording to Landis and Koch (1977). We already 
said that the results have been only partially posi-
tive, in particular – as for the thematic role – on-
8
E.g. 
“Non potendo accedere al CD-Rom non posso rippa-
re niente” 
.
9
E.g. “
Ok, farmerò i campi di battaglia eterni
”.
10
E.g. “
Non molto tempo fa ho droppato i bracciali”.
11
E.g. “
Non è difficile droppare un computer privato”.
12
We choose Geertzen, J. (2012) online resource for 
agreement evaluation . 
CLIC_2016_Proceedings.indd 137
02/12/16 15.03
138
ly one group reached the 0.6 threshold consid-
ered acceptable 
with semantic 
annotation, the 
others 
showing 
moderate 
agreement 
and 
fair 
agreement (one group only). For the semantic 
type annotation, three groups reached the 0.6 
value, four groups showed moderate agreement 
and two groups showed fair agreement. Nonethe-
less, we could make interesting linguistic consid-
erations. 
5
Discussion: the semantic behaviour of 
the loans 
Let us consider the case of 
spammare
13
: all its 
three main senses are distributed among the three 
groups mentioned in Table 1, the semantic be-
haviour shows not only a certain degree of con-
servativeness, but also a great degree of diversi-
fication (just 18 occurrence out of 76 keep the 
original meaning) and thus of acclimatisation. 
Italian 
speakers 
apply 
a 
saving 
strategy: 
the 
monosemous loans are also the most conserva-
tive, while diversification often results in 
polysemous verbs – it seems that, once a seman-
tic change starts, the speaker continues to use the 
loan until it reaches a definitive meaning, even-
tually becoming acclimatized. The cognitive ef-
fort behind this process is very high, but it also 
implies a certain linguistic confidence. Of course 
it is less arduous to produce a loan whose sense 
is strictly linked to the original verb's one, thus 
generating many monosemous loans. Neverthe-
less we wonder whether – aside from being eco-
nomically convenient – is it also strategically and 
linguistically sensible to produce just monose-
mous loans instead of using semantically diversi-
fied ones. Is it sensible to keep numerous and 
specific loans, when there can be fewer and pol-
ysemous ones? Further investigations of English 
un-acclimatised verb loans may answer part of 
these questions.
5.1
Interesting observations about the an-
notation task 
We feel that the only partially satisfying results 
may depend on the tricky lexical meaning of 
each loan. It is clearly easier to annotate the ar-
gument structure of a well-known verb like 
po-
tenziare
, rather than the one of the loan 
over-
13
E.g. 1 “
Magari capiterà di spammare un oggetto” 
2 
“Iniziano a spammare pubblicità a tutti gli iscritti.” 
3 
“Questa è un'abilità controversa [...] ma non va spamma-
ta” .
cloccare
14
(
potenziare
and 
overcloccare
being 
almost synonyms). The thematic role level is the 
most 
problematic, 
obtaining substantial 
agree-
ment only in one case; the semantic type level on 
the other end is perceived as a less abstract, more 
transparent concept and the annotation is slightly 
better, with three groups over 0.6. What is really 
interesting is that the group which performed 
best with thematic roles is also the one which did 
worst with semantic types. Moreover, the groups 
which 
performed 
best 
with 
semantic 
types 
showed only fair to moderate agreement in the-
matic roles. We observe a – 
general and group 
wise – performance improvement with the se-
mantic type level. 
This is because assigning a thematic role requires 
a deeper reflection and some of the roles may be 
ambiguous (for example, Beneficiary and Goal). 
The creation and combination of more specific 
sub-types and sub-roles – targeted to this kind of 
verbs – could help resolve the ambiguity hinder-
ing agreement (for example, Person split into 
Authority and Subordinate)
15
. 
Furthermore 
the 
un-
acclimatisation 
of 
the 
loans leads to somewhat different uses and dif-
ferent meanings among the speakers. This hap-
pens either between different communities, 
either 
between different speakers of the same commu-
nity. Other significant observations emerged on 
the frequency of roles and types and on their co-
occurrence: the most used roles are Agent (often 
erroneously) and Patient (often in the place of a 
more neutral Theme). The types most used are 
Person, Artefact and Abstract. The Agent-Person 
combination 
is the most frequent, even if the role 
is 
often 
wrongly 
assigned. 
Great 
uncertainty 
emerged in assigning the correct type to argu-
ments whose referents are intangible informatics 
entities, e.g. nicknames, server, updates, etc. or 
characters of a game, e.g. boss, Pokémon, etc. 
Last but not least, it was possible to already 
identify primitive verb classes, depending on the 
roles and the types assigned to verb arguments, 
i.e. verbs of change of state with a Patient role 
and possibly a Beneficiary role, or verbs of crea-
tion with a Result role and occasionally an Agent 
role. 
14
E.g. “
Prima di lanciare il tutto ho overcloccato la scheda 
video”
.
15
From section 1 “
Se mi vede Miki mi banna
” (
bannare 1a) 
Miki annotated as Agent-Authority and the personal pro-
noun as Beneficiary-Subordinate. 
CLIC_2016_Proceedings.indd 138
02/12/16 15.03
139
6
Conclusions 
The peculiarities of each group of annotators 
lead to a thought-provoking analysis of the tags-
ets and the semantic notions themselves. The 
analysis of the semantic behaviour of the loans 
unveils deeper questions on the speaker’s strate-
gy: if it is easier to reuse a loan whose meaning 
already exists, why are there also loans with new 
or diversified meaning? Furthermore it came to 
our attention that yes, many loans are linked to 
the informatics/technical context (
rippare, slog-
gare
, etc.) but others can be considered as hypo-
nyms of already existing Italian verbs, whose 
meaning is rather general (
cheattare
for 
barare
, 
whinare
for 
lamentarsi
, etc.). It is possible to 
already discern synonymic and antonymic rela-
tions 
between 
the 
loans 
themselves: 
craftare
, 
farmare
2, 
spawnare
1 
or 
sbuggare-buggare
. 
Finally, the most productive verb classes in our 
corpus are the verbs of change of state, the crea-
tion verbs and the verbs of killing. 
References 
Ron Artstein and Massimo Poesio. 2008. Inter-coder 
agreement for computational linguistics. 
Computa-
tional Linguistics
, 
34
(4), 555-596. 
Joe Barcroft, Gretchen Sunderman and Norbert 
Schmitt. 2011. Lexis. In J. Simpson, ed. 
The 
Routledge Handbook of Applied Linguistics
. 
Routledge Taylor & Francis Group. Oxon., pp. 597 
– 610. 
Marco Baroni. Italian tagset documentation. Available 
at:http://sslmit.unibo.it/~baroni/collocazioni/itwac.ta
g set.txt. 
Marco Baroni and Adam Kilgarriff. 2001. 
Large lin-
guistically processed web corpora for multiple lan-
guage. 
Raffaella Bombi. 2003. Anglicismi come banco di 
prova dell’interferenza linguistica. 
Italiano e ingle-
se a confronto, Firenze, Franco Cesati Editore. 
101-
125. 
Raffaella Bombi. 2005. 
La linguistica del contatto: 
tipologie di anglicismi nell’italiano contemporaneo 
e riflessi metalinguistici. 
(Vol. 11). Il calamo. 
Tullio De Mauro. 1999–2007. 
GRADIT - Grande Di-
zionario Italiano Dell’uso
. 6 vols. Torino: UTET. 
Joseph L. Fleiss. 1971 . 
Measuring nominal scale 
agreement among many raters
. Psychological Bul-
letin, 76:378-382. 
Thierry Fontenelle. 2011. Lexicography. In J. Simp-
son, ed 
The Routledge Handbook of Applied Lin-
guistics
. Routledge, Taylor & Francis Group. Oxon. 
pp. 53 – 66. 
Jeoren Geertzen. 2012. 
Inter-Rater Agreement with 
multiple raters and variables
. Retrieved November 
27, 2015, from https://nlp-ml.io/jg/software/ira/ 
Roberto Gusmani. 1983. 
Saggi sull’interferenza lin-
guistica (vol.1 e vol.2)
. Le lettere. 
Patrick Hanks. 2012. How people use words to make 
meanings: Semantic types meet valencies. In A. 
Boulton & J. Thomas, eds. 
Input, Process and 
Product: Developments in Teaching and Language 
Corpora
. Masaryk University Press. 
Patrick Hanks. 2008. Lexical Patterns: from Hornby 
to Hunston and beyond. In E. Bernal & J. DeCe-
saris, eds.
Proceedings of Euralex 2008
. Barcellona, 
Universitat Pompeu Fabra. 
Patrick Hanks and Elisabetta Jezek. 2010. What lexi-
cal sets tell us about conceptual categories. In 
Lexis: 
E-journal in English lexicology, 
4: Corpus Linguis-
tics and the Lexicon. 
Patrick Hanks and James Pustejovsky. 2005. A Pat-
tern Dictionary for Natural Language Processing. 
Revue française de linguistique appliquée
, 10(2). 
Martin Haspelmath. 2009. Lexical borrowing: con-
cepts and issues. 
Loanwords in the world’s lan-
guages: a comparative handbook. 
Martin Haspelmath. 2008. Loanword typology: steps 
toward a systematic cross-linguistic study of lexical 
borrowability. 
Aspects of language contact: new 
theoretical, methodological and empirical findings 
with special focus on Romancisation processes. 
Mouton de Greuyter. 
Elisabetta Jezek. 2011. 
Lessico. Classi di parole, 
strutture, combinazioni
. Il Mulino, Bologna. 
Elisabetta Jezek. 2010. Struttura argomentale dei ver-
bi. In L. Renzi – G. Salvi (a cura di) 
Grammatica 
dell’Italiano Antico
. Bologna: Il Mulino, 77-122. 
Elisabetta Jezek and Malvina Nissim. 2014. 
Linee 
guida per l’annotazione degli argomenti del verbo 
Elisabetta Jezek and Laure Vieu. 2013 . Lista di ruoli 
semantici per Senso Comune. 
Adam Kilgarrif. 2001. Web as corpus. 
Proceedings of 
corpus linguistics 2001. 
Corpus Linguistics. Read-
ing in a Widening Discipline. 
CLIC_2016_Proceedings.indd 139
02/12/16 15.03
140
Alan Kirkness. 2004. Lexicography. In A. Davies & 
C. Elder, eds. 
The Handbook of Applied Linguis-
tics
. Blackwell Handbooks in Linguistics. Black-
well Publishing, pp. 73 – 101. 
Klaus Krippendorf. 1980. 
Content Analysis: An Intro-
duction to its Methodology
. Sage Publications 
Alessandro Lenci, Simonetta Montemagni and Vito 
Pirrelli. 2012. 
Testo e computer. Elementi di lin-
guistica computazionale
. Carocci editore. 
Beth Levin. 1993. 
English verb classes and alterna-
tions: a preliminary investigation
. University of 
Chicago Press. 
Anthony McEnery, Richard Xiao and Yukio Tono. 
2006. 
Corpus based language studies. An advanced 
resource book
. Routledge, Taylor & Francis Group. 
Oxon. Routledge Applied Linguistics. 
Jan Pomikálek. 2011. 
Removing Boilerplate and Du-
plicate Content from Web Corpora
. Ph.D. thesis. 
Brno, Repubblica Ceca: Masaryk University. Avail-
able at: 
http://is.muni.cz/th/45523/fi_d/phdthesis.pdf. 
James Pustejovsky and Amber Stubbs. 2012. 
Natural 
language annotation for machine learning
. 
O’Reilly. 
Renata Savy. 2006. Specifiche per la trascrizione or-
tografica annotata dei testi raccolti. In 
Progetto 
CLIPS. Corpora e Lessici dell’Italiano Parlato e 
Scritto. 
Amber Stubbs. 2011. 
MAE and MAI: Lightweight 
Annotation and Adjudication Tools. 
Michael Stubbs. 2004. Language Corpora. In A. Da-
vies & C. Elder, eds. 
The Handbook of Applied Lin-
guistics
. Blackwell Handbooks in Linguistics. 
Blackwell Publishing, pp. 125 – 152. 
Peter Wittenburg, Hennie Brugman, Albert Russel, 
Alex Klassmann and Han Sloetjes. 2006. ELAN: a 
Professional 
Framework 
for 
Multimodality 
Re-
search. In: 
Proceedings of LREC 2006, Fifth Inter-
national Conference on Language Resources and 
Evaluation. 
CLIC_2016_Proceedings.indd 140
02/12/16 15.03
141
LICO: A Lexicon of Italian Connectives
Anna Feltracco
Fondazione Bruno Kessler
University of Pavia, Italy
University of Bergamo, Italy
feltracco@fbk.eu
Elisabetta Jezek
University of Pavia
Pavia, Italy
jezek@unipv.it
Bernardo Magnini
Fondazione Bruno Kessler
Povo-Trento, Italy
magnini@fbk.eu
Manfred Stede
University of Potsdam
Potsdam, Germany
stede@uni-potsdam.de
Abstract
English.
This
paper
presents
the first
release of
LICO,
a Lexicon for
Italian
COnnectives.
LICO includes about
170
discourse connectives used in Italian,
to-
gether with their orthographical
variants,
part
of
speech(es),
semantic relation(s)
(according to the Penn Discourse Tree-
bank relation catalogue), and a number of
usage examples.
Italiano.
Questo contributo presenta la
prima versione di LICO, un lessico di con-
nettivi
per l’italiano.
LICO comprende
circa 170 connettivi del discorso usati in
italiano, di cui abbiamo raccolto varianti
ortografiche,
le parti
del
discorso,
le re-
lazioni semantiche (ricavate dal catalogo
del Penn Discourse Treebank) espresse dal
connettivo, e alcuni esempi d’uso.
1
Introduction
Discourse connectives are explicit lexical markers
that
are used to express functional
relations be-
tween parts of the discourse.
As an example,
the
italian word “quando” in the sentence “Quando si
preme sul bottone, la porta si apre da sola” (When
you press the button, the door opens by itself) ex-
presses a conditional relation between two parts of
the sentence (from now on, arguments).
Work on discourse connectives
in Computa-
tional Linguistics was initially part of Rhetorical
Structure Theory (Mann and Thompson,
1988),
where the focus is on discourse relations,
which
are at the basis of the notion of textual coherence.
In Computational Linguistics, being able to iden-
tify connectives is a central task in “shallow dis-
course parsing”,
which has become very popular
in recent years (e.g.,
(Lin et al.,
2014)) and con-
stituted the shared task of the CONLL conference
in 2015 and 2016
1
.
Downstream applications that
can benefit from shallow discourse structure are,
inter alia,
sentiment analysis (e.g.,
(Bhatia et al.,
2015) and argumentation mining (e.g.,
(Peldszus
and Stede, 2013)).
Our work on connectives is mainly motivated
by the fact that, to the best of our knowledge, still
there is no high coverage resource of discourse
connectives available for Italian.
LICO, the Lex-
icon for Italian COnnectives,
aims at
filling this
gap,
providing a repository of Italian connectives
aligned with recent developments in discourse re-
lations (i.e.
the last version (3.0) of the Penn Dis-
course Treebank (PDTB)).
In addition,
the LICO lexicon takes advantage
from DimLex,
a similar
repository for
German
(Scheffler and Stede,
2016;
Stede and Umbach,
1998);
in fact DimLex served as the main inspi-
ration for creating LICO (see section 4).
Dim-
Lex is
an XML-encoded resource that
can be
used for NLP; the public version provides infor-
mation on orthographical
variants,
syntactic be-
havior,
semantic relations (in terms of
PDTB),
and usage examples.
It
is used for
automatic
discourse parsing,
and also for
semi-automatic
text annotation using the ConAno tool (Stede and
Heintze,
2004).
Another
relevant
resource for
connectives is LEXCONN,
for French,
(Roze et
al.,
2012),
which contains about 300 connectives
with their syntactic category and coherence rela-
tions from Segmented Discourse Representation
Theory (Asher and Lascarides, 2003)(and to some
extent
Rhetorical
Structure Theory (Mann and
Thompson, 1988)).
LICO is freely distributed under a CC-BY li-
cence.
1
http://www.cs.brandeis.edu/ clp/conll16st/
CLIC_2016_Proceedings.indd 141
02/12/16 15.03
142
2
Discourse Connectives
The definition of discourse connective is contro-
versial both in traditional grammar and in the lin-
guistic literature. Our definition is based on the en-
cyclopedia entry on connectives by Ferrari (2010),
included in the reference work for the Italian lan-
guage recently published by Treccani.
In this en-
try, connectives are defined as “each of the invari-
able forms [...], that introduce relations that struc-
ture “logically” the meanings of the sentence and
of the text”
2
.
The definition provided in Ferrari
(2010) is restrictive,
as it
does not
include vari-
able forms,
i.e.
those forms which are subject
to morphological
modifications,
such as ne con-
segue/conseguiva che ‘it
follows/followed/
that’,
nor does it include pragmatic uses of connectives
(also known as discourse markers) such as causal
perch
´
e ‘why’ in “Che ore sono? Perch
´
e ho dimen-
ticato l’orologio” (‘what time is it? Because I for-
got my watch’).
On the other end, it assumes that
logical relations marked by connectives hold be-
tween events or assertions, and therefore includes
as arguments for the relation nominal expressions
such as “dopo il
pressante invito ...” ‘after
the
pressing invitation ...’,
i.e.
expressions that con-
tain an event nominal,
- although the event is,
in
this case, referred to instead of predicated.
In our work, we partly drop the invariability cri-
teria; we do not include forms which exhibit mor-
phological inflection or conjugation, but we do in-
clude connectives which show a certain degree of
lexical variability that is,
multi-word expressions
which are not totally rigid from a lexical point of
view (ad esempio/per esempio ‘for example’; see
section 3).
3
The Structure of the Lexicon
Each entry in the LICO lexicon corresponds to a
connective (including its variants).
Currently,
for
each entry LICO specifies:
•
whether
the connective (or
its variants)
is
composed by a single token (“part = single”,
e.g. perch
´
e) or by more than one token (“part
= phrasal” e.g. di conseguenza);
•
whether the connective is composed by cor-
relating part (“orth = discont”) or not (“orth
2
“Il termine connettivo indica in linguistica ciascuna delle
forme invariabili [...],
che indicano relazioni che strutturano
‘logicamente’ i significati della frase e del testo”.
= cont”) and the specification of the two cor-
relating parts,
e.g.
“orth = discont”:
da una
parte (“part
= phrasal”),
dall’altra (“part
=
phrasal”); “orth = cont”: perch
´
e (“part = sin-
gle”);
•
possible
orthographic
variants:
e.g.
ci
`
o
nonostante (“part = phrasal”) and ciononos-
tante (“part = single”);
•
possible lexical variants: e.g dopo di ch
´
e and
dopo di ci
`
o.
Notice that in some cases this
lexical variants determine a different syntac-
tic environment,
such as in modo da and in
modo che,
the first
being followed by in-
finitive form,
the following by a subjunctive
form;
•
pos category:
adverbs,
preposition subordi-
nating or coordinating conjunctions;
•
the semantic relation(s) that
the connective
indicates, according to the PDTB 3.0 schema
(see section 3.1);
•
examples of the connectives for each seman-
tic relation;
•
possible alignments with lexicon of connec-
tives in other languages.
Table 1 shows
the entry for
quando,
which
presents more than one semantic relation, and the
entry for
ciononostante,
ci
`
o nonostante,
nonos-
tante ci
`
o,
as example of
a connective with or-
thografic variants in LICO.
3.1
Semantic relations
For
the annotation of
the semantic relation we
used the PDTB 3.0 schema of relations (Webber
et al.,
2016; Rehbein et al.,
2016) as proposed in
the DimLex resource (Scheffler and Stede, 2016),
which is our main reference resource.
The schema is a most recent version of PDTB
2.0 (Prasad et al.,
2008;
Prasad et al.,
2007) and
includes semantic relations structured in a hierar-
chy composed by three levels. In the first level, the
class level, the relations are grouped in four major
classes:
TEMPORAL,
CONTINGENCY,
COM-
PARISON and EXPANSION. The second level, the
type level,
specifies further the semantics of the
class level.
For example,
the TEMPORAL: Syn-
chronous tag is used for connectives that indicate
that the two arguments are simultaneous, while the
CLIC_2016_Proceedings.indd 142
02/12/16 15.03
143
 entry-id
146
 orth
cont
 part
single
quando
 POS
subordinating
 sem relation
TEMPORAL: Synchronous
ex.: Quando lasci
`
o l’appartamento, arriv
`
o la chiamata
rel. to German id: 5
 sem relation
CONTINGENCY:Condition
ex.: Quando si preme sul bottone, la porta si apre da sola.
ex.: Quando me lo chiedi, lo lascer
`
o stare.
rel. to German id: 116
 entry-id
30
 orth
cont
 part
single
 variant
orthographic
ciononostante
 orth
cont
 part
phrasal
 variant
orthographic
ci
`
o nonostante
 orth
cont
 part
phrasal
 variant
orthographic
nonostante ci
`
o
 POS
coordinating
 sem relation
COMPARISON:Concession:Arg2-as-denier
ex.: La procura ha ordinato la restituzione dell’esemplare
confiscato. Ciononostante l’istruttoria prosegue.
rel. to German id: 74
Table 1:
The connectives quando and ciononos-
tante, ci
`
o nonostante, nonostante ci
`
o in LICO.
TEMPORAL: Asynchronous tag is used for con-
nectives that
indicate a before-after
relation be-
tween the arguments.
The third level
(subtype
level)
3
varies according to the role of the two argu-
ments involved in the relation. For example, CON-
TINGENCY:Cause:Reason is used if the argument
introduced by the connective -Arg2-
is the rea-
son for the situation in the other argument -Arg1-
(e.g.
I stayed at
home,
because it
was raining),
while CONTINGENCY:Cause:Results is used if
Arg2 represents the result/effect of Arg1 (e.g.
It
was raining, therefore I stayed at home).
Not ev-
ery type has a further subtype.
In the LICO structure, each connective is assigned
with one or more three-level tags.
4
The Current Resource
In this Section,
we present
the current
resource
and its
construction.
In particular,
we focus
on describing how the list
of
entries has been
identified so far and how we proceeded to acquire
the semantic information for each entry.
List of connectives.
Currently,
LICO is com-
posed by 173 entries,
each one corresponding to
3
The names of
the levels are taken form Prasad et
al.
(2007).
a connective and its orthographical or lexical vari-
ants.
In order to compile this list we used a num-
ber of grammatical and lexical resources for Ital-
ian and for other languages.
First,
we retrieved the list of connectives men-
tioned by Ferrari (2010) in the Enciclopedia Trec-
cani for the entry connettivi
4
for a total of 33 con-
nectives. Then, we retrieved the list of connectives
tagged as congiunzione testuale in Sabatini Coletti
2006 (Sabatini-Coletti, 2005) discarding the ones
of literary use,
for a total of 70 entries.
Finally,
we benefited from the DimLex resource for Ger-
man,
as we enriched our list
by identifying the
equivalent
Italian terms of
the German connec-
tives
5
. This process was facilitated by the presence
of examples in the German resource in which the
connective is displayed in context: only the Italian
candidates that maintain the sense of the German
connectives were added to LICO.
We keep trace
of this “German-Italian” links and we will use this
information to enrich also the characteristic of the
entry in LICO (e.g.
aber
→
ma).
A total of 127
entries were collected with this method.
Figure
1 shows the overlap between the three resources
and Table 2 shows a sample of the connectives in
LICO and the respective sources.
Figure 1: Overlap between the resources.
Semantic relations in LICO.
In LICO connectives are tagged with the se-
mantic relations that
the connective can indicate
in a text,
selecting the most
appropriate ones in
the PDTB 3.0 schema. In this process we took ad-
vantage from the information which was already
4
http://www.treccani.it/enciclopedia/connettivi (Enciclopedia-
dell’Italiano)/, last access July 21st 2016.
5
https://github.com/discourse-lab/dimlex
CLIC_2016_Proceedings.indd 143
02/12/16 15.03
144
LICO Entries
Resources
Ferrari
Treccani
Sabatini
Coletti
DimLex
(equivalent)
dopo
dopo
dopo
dopo
dopo di che
dopodich
´
e
dopodich
´
e
dopo di che
dopotutto
dopotutto
dunque
dunque
dunque
dunque
e
e
e
ebbene
ebbene
eccetto
eccetto
eppure
eppure
eppure
Table 2:
Sample of connectives in different
re-
sources.
present in the resources we used for building the
list. In fact, the DimLex resource provides this in-
formation for the German connectives,
and both
the Italian resources previously mentioned pro-
vide useful
information about
the semantic rela-
tion triggered by the connective.
6
A total of 23 dif-
ferent PTDB relations have been used to describe
LICO entries.
In order to validate the tagging of
semantic relations, we conducted a research by ob-
serving examples of the use of the connectives in
corpora,
i.e.
we wanted to verify whether the re-
lation that a connective introduces in a portion of
text is one of the relations already tagged for that
same connective in the first step.
In particular, we
searched for 20 connectives in the ItWac corpus
(Baroni et al., 2009) and we retrieved occurrences
with 400 characters on both sides of the connec-
tive. We limited our observation to 5 retrieved seg-
ments of text in which the connective is actually
playing such a role.
We finally tagged each con-
nective in each portion of text with the semantic
relation it indicates.
To further confirm the corpus-driven evidences
for the semantic relations,
we asked two annota-
tors (one being an expert annotator, the other not)
to perform the same tagging task.
We then cal-
culated the interannotator agreement between the
two annotators adopting the Dice’s coefficient (Ri-
6
In particular,
in the online version of Sabatini
Coletti
(http://dizionari.corriere.it/dizionarioitaliano/D/dizionario
.shtml, last access July 21st 2016) the semantic relations the
connectives can trigger are described in the definition of the
connective itself,
e.g.
“quindi,
cong.
testuale:
Con valore
deduttivo-conclusivo,
perci
`
o,
di
conseguenza,
per
questo
motivo, dunque”. Ferrari (2010) in the Enciclopedia Treccani
proposes a non hierarchical classification which includes the
following relations:
“temporal
relation” “causal
relation”,
“consequence relation”,
“condition relation”,
“opposition
relations”.
jsbergen,
1997)
7
for three configurations,
one for
each level of the relation schema: class agreement,
type agreement,
subtype agreement.
We consid-
ered that there was agreement if both annotators
identify exactly the same class, type, subtype
re-
spectively. The Dice values result in 0,78 for class
agreement and 0,71 for both type agreement and
subtype agreement.
Observing
cases
of
disagreement,
we
can
make the following preliminary considerations.
The
main
cases
of
disagreement
regard
the
COMPARISON:Contrast
relation (on one hand)
and
the
COMPARISON:Concession
and
EX-
PANSION:Substitution relations
(on
the
other
hand).
These relations in fact
appear to be the
ones
that
connect
arguments
that
are
in con-
trast.
As
an example,
the connective anzich
´
e
‘rather than’ in Example (1) has been annotated
as COMPARISON:Contrast by annotator1 and as
EXPANSION:Substitution:Arg1-as-subst
by an-
notator2:
the first enlightens the contrast between
“emissione attraverso il
Tesoro” and “usare il
tradizionale sistema”, the second emphasises that
Arg2 represents the alternative to the Arg1.
(1)
[..]
chiedeva l’
emissione di
dollari
in
banconote statunitensi attraverso il Tesoro
anzich
´
e
usando
il
tradizionale
sistema
della Federal Reserve.
Another
interesting
case
concerns
the
dis-
agreement
between
the
relations
TEM-
PORAL:Asynchronous:precedence
(in
which
Arg2
follows
Arg1)
and
CONTIN-
GENCY:Cause:Result
(in
which
Arg2
is
the
results of Arg1), being the two strictly connected
(i.e.
in a cause-effect relation,
the effect follows
the cause).
As an example,
in (2)
one anno-
tator
marks
the connective as
indicator
of
the
temporal
sequence of Arg1 and Arg2,
while the
other
prefers to mark it
as an indicator
of
the
cause-effect relation.
(2)
[..]
Il bello
`
e che i tipi hanno pure accen-
nato a prendersela con me, al che io gli ho
abbaiato contro una sequela di insulti [..]
In general,
the relations that
were initially as-
7
Dice’s coefficient measures how similar two sets are by
dividing the number of shared elements of the two sets by
the total
number of elements they are composed by.
This
produces a value from 1, if both sets share all elements, to 0,
if they have no element in common.
CLIC_2016_Proceedings.indd 144
02/12/16 15.03
145
signed to these connectives were confirmed by the
corpus-based exercise (i.e.
at least one annotator
assigns the tag in at
least
one portions of text);
viceversa,
in some cases one of the two annota-
tors assigned a relation that was not initially iden-
tified.
8
5
Conclusion and Further work
In this paper we have presented LICO, a new re-
source for the Italian language describing lexical
properties of discourse connectives.
While LICO
fills a gap with respect to similar resources exist-
ing for other languages,
it is still under construc-
tion under several aspects.
Our short term plans
include the completion of the lexical entries with
corpus derived examples and the observation of
the connectives in Italian corpora,
in order to ac-
quire more information about
the semantic rela-
tions that
each connective can indicate and thus
extend the annotation of the semantic relations in
LICO.
Acknowledgment
We acknowledge Denise Pangrazzi
for her con-
tribution to identify the Italian equivalents of the
German connectives.
References
Nicholas Asher and Alex Lascarides.
2003.
Logics of
conversation.
Cambridge University Press.
Marco Baroni,
Silvia Bernardini,
Adriano Ferraresi,
and Eros
Zanchetta.
2009.
The wacky wide
web:
a collection of very large linguistically pro-
cessed web-crawled corpora.
Language resources
and evaluation, 43(3):209–226.
Parminder Bhatia,
Yangfeng Ji,
and Jacob Eisenstein.
2015.
Better
document-level
sentiment
analysis
from rst
discourse parsing.
In Proceedings of
the
2015 Conference on Empirical Methods in Natural
Language Processing, Lisbon, Portugal, September.
Association for Computational Linguistics.
Angela Ferrari.
2010.
Connettivi.
In Enciclopedia
dell’Italiano. diretta da Raffaele Simone, con la col-
laborazione di Gaetano Berruto e Paolo D’Achille,
Roma, Istituto della Enciclopedia Italiana.
Ziheng Lin,
Hwee Tou Ng,
and Min-Yen Kan.
2014.
A pdtb-styled end-to-end discourse parser.
Natural
Language Engineering, 20:151–184.
8
For this moment, the “new” relations are not included in
LICO.
William C Mann and Sandra A Thompson.
1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization.
Text-Interdisciplinary Jour-
nal for the Study of Discourse, 8(3):243–281.
Andreas Peldszus and Manfred Stede.
2013.
From ar-
gument diagrams to argumentation mining in texts:
A survey.
International Journal of Cognitive Infor-
matics and Natural Intelligence (IJCINI), 7(1):1–31.
Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan
Lee,
Aravind Joshi,
Livio Robaldo,
and Bonnie L
Webber.
2007.
The Penn Discourse Treebank 2.0
Annotation Manual.
Rashmi Prasad,
Nikhil Dinesh,
Alan Lee,
Eleni Milt-
sakaki,
Livio Robaldo,
Aravind K Joshi,
and Bon-
nie L Webber.
2008.
The Penn Discourse Tree-
Bank 2.0.
In Proceedings of the Sixth International
Conference on Language Resources and Evaluation
(LREC’08), Marrakech, Morocco, May.
Ines Rehbein,
Merel
Scholman,
and Vera Demberg.
2016.
Annotating Discourse Relations in Spoken
Language:
A Comparison of the PDTB and CCR
Frameworks.
In Proceedings of the Tenth Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2016), Portoro
ˇ
z, Slovenia, May.
CJ van Rijsbergen.
1997.
Information retrieval. 1979.
Charlotte Roze, Laurence Danlos, and Philippe Muller.
2012.
LEXCONN:
a French lexicon of discourse
connectives.
Discours.
Revue de linguistique,
psy-
cholinguistique et informatique., (10).
Il Sabatini-Coletti.
2005.
Dizionario della lingua ital-
iana 2006, con CD-ROM.
Milano, Rizzoli Larousse.
Tatjana Scheffler and Manfred Stede.
2016.
Adding
Semantic Relations to a Large-Coverage Connective
Lexicon of German.
In Proceedings of the Tenth In-
ternational Conference on Language Resources and
Evaluation (LREC 2016), Portoro
ˇ
z, Slovenia, May.
Manfred Stede and Silvan Heintze.
2004.
Machine-
assisted rhetorical structure annotation.
In Proceed-
ings of the 20th International Conference on Com-
putational Linguistics, pages 425–431, Geneva.
Manfred Stede and Carla Umbach.
1998.
Dimlex:
A lexicon of discourse markers for text generation
and understanding.
In Proceedings of the 17th inter-
national
conference on Computational
linguistics-
Volume 2,
pages 1238–1242. Association for Com-
putational Linguistics.
Bonnie Webber,
Rashmi
Prasad,
Alan Lee,
and Ar-
avind Joshi.
2016.
A Discourse-Annotated Cor-
pus of Conjoined VPs.
In Proceedings of the 10th
Linguistic Annotation Workshop held in conjunction
with ACL 2016 (LAW-X 2016),
pages 22–31. Asso-
ciation for Computational Linguistics.
CLIC_2016_Proceedings.indd 145
02/12/16 15.03
146
Written word production and lexical self-organisation: evidence from 
English (pseudo)compounds 
Marcello Ferro 
ILC-CNR Pisa, Italy 
marcello.ferro@ilc.crn.it
Franco Alberto Cardillo 
ILC-CNR Pisa, Italy 
francoalberto.cardillo@ilc.cnr.it 
Vito Pirrelli 
ILC-CNR Pisa, Italy 
vito.pirrelli@ilc.cnr.it
Christina L. Gagné 
Dept. of Psychology, University of Alberta, Canada 
cgagne@ualberta.ca
Thomas L. Spalding 
Dept. of Psychology, University of Alberta, Canada 
spalding@ualberta.ca
Abstract 
Elevation in typing latency for the initial 
letter of the second constituent of an Eng-
lish compound, relative to the latency for 
the final letter of the first constituent of 
the same compound, provides evidence 
that implementation of a motor plan for 
written 
compound 
production 
involves 
smaller constituents, in both semantically 
transparent 
and 
semantically 
opaque 
compounds. We investigate here the im-
plications of this evidence for algorithmic 
models of lexical organisation, to show 
that effects of differential perception of 
the internal structure of compounds and 
pseudo-compounds can also be simulated 
as peripheral stages of lexical access by a 
self-organising 
connectionist 
architec-
ture, 
even 
in 
the 
absence 
of 
morpho-
semantic information. This complemen-
tary evidence supports a maximization-
of-opportunity approach to lexical mod-
elling, accounting for the integration of 
effects of pre-lexical and lexical access. 
Il rallentamento nel tempo di battitura 
del primo carattere del secondo costi-
tuente di un composto inglese, rispetto al 
tempo dell’ultimo carattere del primo co-
stituente, dimostra che l’implementazione 
del programma motorio per la scrittura 
di un composto è influenzata dai costi-
tuenti del composto stesso, siano essi se-
manticamente 
trasparenti 
o 
opachi. 
Il 
presente 
contributo 
offre 
un 
modello 
computazionale di questa evidenza, e ne 
valuta l’impatto sull’organizzazione del 
lessico mentale: la percezione del confine 
di morfema tra i due costituenti è analiz-
zata come il risultato dell’interazione di-
namica tra processi di accesso pre- e 
post-lessicale. 
1
The evidence 
A key question concerning the representation and 
processing of compound words has 
focused on 
whether (and, if so, how) morphological struc-
ture plays a role. The bulk of the research on this 
issue has come from recognition or comprehen-
sion tasks such as lexical decision or reading. 
However, written production provides a useful 
counterpart and allows researchers to examine 
whether morphemes are used even after a word 
has been accessed. One advantage of a typing 
task (in which the time to type each letter of a 
word is recorded) is that researchers can examine 
differences 
in 
processing 
difficulty 
at 
various 
points in the word. Previous research found an 
elevation in typing latency for the initial letter of 
the second constituent relative to the latency for 
the final letter of the first constituent for English 
(Gagné & Spalding 2014; Libben et al. 2012; 
Libben & Weber 2014) and German compounds 
(Sahel et al. 2008; Will et al. 2006). This eleva-
tion in typing latency at the morpheme boundary 
suggests that the system plans the output mor-
pheme by morpheme, rather than as a whole unit, 
and 
that 
morphological 
programming 
is 
not 
complete when the motor system begins the out-
put of the word (Kandel et al. 2008). 
Gagné and Spalding (2016) examined the role 
of morphemic structure and semantic transparen-
cy on typing latency. The stimuli consisted in 
200 compounds, 50 pseudo-compounds, and 250 
monomorphemic words matched pairwise with 
the compounds and pseudo-compounds in the 
number 
of 
syllables 
and 
letters. 
The 
pseudo-
compounds contain two words that do not func-
tion as morphemes (e.g., 
carpet
contains 
car
and 
pet
). The compounds varied in whether the first 
and second constituent were semantically trans-
parent. The items were displayed individually 
using 
a 
progressive 
demasking 
procedure 
and 
participants typed the word as the computer rec-
orded the time required to type each letter. 
CLIC_2016_Proceedings.indd 146
02/12/16 15.03
147
The time to initiate the first letter was equiva-
lent for monomorphemic and compound words. 
Typing times got faster across the word for both 
word types, but the rate of change was faster for 
monomorphemic 
words 
than 
for 
compound 
words. This difference was not observed when 
comparing monomorphemic words and pseudo-
compounds. 
For 
compounds, 
the 
rate 
of 
speed-up 
was 
slower when the first constituent was transparent 
than when it was opaque, but was unaffected by 
the transparency of the second constituent. The 
elevation 
in 
typing 
latency 
at 
the 
morpheme 
boundary was larger when the first constituent 
was transparent than when it was opaque, but 
was unaffected by the transparency of the second 
constituent. This difference is due to the final 
letter of the first constituent when the first con-
stituent requiring less time to type when it was 
transparent than when it was opaque. 
The data for the pseudo-compounds indicated 
that embedded morphemes influence production, 
even when they do not function as morphemes. 
Typing latency increased one letter prior to the 
end 
of 
the 
first 
constituent 
of 
a 
pseudo-
compound and remained elevated through the 
boundary (e.g., both 
r 
and 
c 
in 
scarcity 
were ele-
vated relative to the 
a
). 
1.1
Implications for lexical architectures 
The reported evidence clearly indicates that mor-
phemic 
structure 
is 
involved 
in 
written 
word 
production. The production of compounds differs 
from that of monomorphemic words and the se-
mantic transparency of the two constituents leads 
to 
different 
effects. 
Furthermore, 
embedded 
pseudo-morphemes appear to influence the pro-
duction 
of 
pseudo-compounds, 
but 
not 
in 
the 
same way that the embedded morphemes affect 
the production of compounds. 
This appears to lend only partial support to 
models of lexical architecture where both com-
pounds and their constituents are represented and 
processed as independent access units (Figure 1). 
In panel 
A
, following Taft & Forster (1975), ac-
cess and output of compounds are mediated by 
their 
constituents 
(Cs), 
but 
extra 
procedures 
would be needed to account for the role of se-
mantic transparency in modulating the size of 
elevation 
in 
typing 
latency 
at 
the 
morpheme 
boundary. A supralexical account (panel 
B
: Gi-
raudo & Grainger 2000, Grainger et al. 1991), 
where constituents are activated upon composi-
tional interpretation of compounds, cannot cap-
ture the persistence of typing effects in semanti-
cally opaque compounds (and, to an extent, in 
pseudo-compounds). 
Race 
models 
(panel 
C
: 
Schreuder & Baayen 1995) posit parallel path-
ways for compound processing (both holistic and 
compositional), depending on variables such as 
whole word vs. constituent frequency, but it is 
not clear how they can account for effects of in-
teraction between the two paths. Connectionist 
models 
(panel 
D
: 
Rumelhart 
& 
McClelland 
1986, Plaut & Gonnerman 2000), on the other 
hand, tend to dispense with specialized represen-
tational levels and access procedures, and make 
room 
for 
distributed 
effects 
of 
sublexical 
co-
activation 
through 
overlaying 
patterns 
of 
pro-
cessing units. A defining feature of these models 
is that they blur the traditional distinction be-
tween representations and processing units. We 
suggest that 
blurring this distinction can go a 
long way in addressing some of the issues that 
appear to elude models 
A
, 
B
and 
C
. 
Figure 1 – Four architectures of form-meaning mapping 
in the mental lexicon: 
C1+C2
designates two-word com-
pounds and 
Cs
mono-morphemic constituents (adapted from 
Diependaele et al. 2012) 
Temporal 
Self-Organising 
Maps 
(TSOMs: 
Ferro et al. 2011; Marzi et al. 2014; Pirrelli et al. 
2015), are a time-sensitive variant of Kohonen’s 
SOMs (Kohonen, 2002), where words are stored 
through routinized, time-bound patterns of re-
peatedly successful processing units. 
Since all 
input words are stored concurrently on the same 
layer of fully connected nodes, TSOMs account 
for effects of co-activation of competing repre-
sentations in terms of a continuous function of 
distributional regularities in the input data. In 
what follows, starting from Gagné & Spalding’s 
evidence, we will focus on peripheral stages of 
lexical access/output, to verify if mechanisms of 
parallel, 
distributed 
pattern 
activation 
can 
ac-
count for differential processing effects between 
compounds and pseudo-
compounds even in the 
CLIC_2016_Proceedings.indd 147
02/12/16 15.03
148
absence 
of 
morpho-semantic 
information. 
Alt-
hough computational testing is carried out on 
TSOMs only, our discussion and concluding re-
marks address issues that go beyond a specific 
computational framework. 
2
TSOMs 
A TSOM consists of a grid of memory nodes 
with two layers of connectivity. The first layer 
(or I-layer) fully connects each node to the input 
vector, where symbols are sampled at discrete 
time ticks as patterns of activation ranging in the 
[0, 1] interval. Weights on the I-layer are adjust-
ed in training for individual nodes to develop 
specialised sensitivity to particular input sym-
bols. Each node is also connected to all other 
nodes through a layer of re-entrant connections 
(or T-layer), whose weight strength determines 
the amount of influence that activation of one 
node has on other nodes at a one-tick delay. 
When an input symbol is presented at time 
t
, 
the level of activation 
𝑦𝑦
!
𝑡𝑡
of node 
i
is a func-
tion of: (a) the node’s sensitivity to the current 
input symbol (
𝑦𝑦
!_!"#$%,!
𝑡𝑡
), and (b) the re-entrant 
support the node receives from the map activa-
tion state at 
t-1 
(
𝑦𝑦
!_!"#$%,!
𝑡𝑡
= 𝑓𝑓 𝑦𝑦
!
(𝑡𝑡 − 1)
, 
where 
f
is a linear function and 
j 
ranges over all map 
nodes). More formally: 
𝑦𝑦
!
𝑡𝑡
= 𝛼𝛼 ∙ 𝑦𝑦
!_!"#$%,!
𝑡𝑡
+ 1 − 𝛼𝛼 ∙ 𝑦𝑦
!_!"#$%,!
𝑡𝑡
The node responding most strongly to the input 
symbol 
S
at time tick 
t
is called Best Matching 
Unit (hereafter 
BMU
(
S
, 
t
) or 
BMU
(
t
) for short). 
The map’s response to a sequence of input 
symbols like 
carpet
is a chain of consecutively 
firing 
BMU
s, each responding to a letter in 
car-
pet
. During training, connection weights between 
consecutive 
BMU
s are adjusted to the frequency 
distribution of input symbols in the training set, 
according to Hebbian principles of correlative 
learning. Given the bigram 
ab
, the connection 
strength between 
BMU
(
a
, 
t
-1) and 
BMU
(
b
, 
t
) 
increases if 
a
often precedes 
b
(entrenchment) 
and decreases if 
b
is often preceded by a symbol 
other than 
a
(competition) (Figure 2, left). Com-
bination of entrenchment and competition yields 
selective specialisation of chains of 
BMU
s (Fig-
ure 2, right). If the same input symbol follows 
different contexts, it will tend to be responded to 
by 
more 
BMUs
, 
one 
for 
each 
context. 
The 
stronger the probabilistic support that the input 
symbol receives from its preceding context, the 
more likely the recruitment of a dedicated 
BMU
, 
and the stronger its re-
entrant connection. As a 
result 
of 
this 
dynamic, 
high-frequency 
words 
recruit 
specialised 
node 
chains, 
low-frequency 
words are responded to by weaker, “blended” 
node chains. 
Figure 2 - Left: operation of Hebbian rules on potentiated 
(‘+’) and inhibited (‘-‘) connections. Right: forward one-
tick-delay connections leaving ‘A’ at time 
t
-1. Larger nodes 
represent 
BMUs
. Shades of grey indicate levels of node 
activation.
2.1
The Experiment 
The 200 compounds and 50 pseudo-compounds 
used by Gagné & Spalding 
were used to train a 
40x40 node TSOM for 100 learning epochs. Be-
sides 
compounds 
and 
pseudo-
compounds, 
the 
training set included 500 (pseudo)constituents as 
individual words (e.g. 
car 
and 
wash 
in 
carwash
, 
car 
and 
pet
in 
carpet
), for a total amount of 750 
items. At each training epoch, monomorphemic 
words were shown 10 times as often as com-
pounds. We ran 5 repetitions of the experiment, 
and results were analysed using linear mixed ef-
fects models (LME), with experiment repetitions 
and training items as random variables. 
To analyse differential processing effects for 
pseudo-compounds and compounds, we focused 
on two types of evidence: (i) per-letter perfor-
mance of a trained TSOMs in incrementally an-
ticipating 
compounds 
and 
pseudo-compounds; 
(ii) structural connectivity 
of BMUs responding 
to letter bigrams at the C1-C2 boundary. 
To anticipate 
a progressively presented input 
word, a TSOM propagates the activation of the 
current 
BMU
(
t
) 
through 
its 
forward 
temporal 
connections, and outputs, at each time tick, the 
symbol 
𝑆𝑆
!"#(!!!)
encoded on the 
I
_layer of the 
most strongly (pre)activated node: 
𝐵𝐵𝐵𝐵𝐵𝐵(𝑡𝑡 + 1) = argmax
!!!,…,!
𝑚𝑚
!,!
ℎ = 𝐵𝐵𝐵𝐵𝐵𝐵 𝑡𝑡
where 
𝑚𝑚
!,!
is the weight value on the forward 
temporal connection from node 
h
to node 
i
. Each 
correctly predicted symbol in the input word is 
assigned the prediction score of the preceding 
symbol incremented by 1. Otherwise, the symbol 
receives a 0-point score. 
CLIC_2016_Proceedings.indd 148
02/12/16 15.03
149
Figure 3 – Marginal plots of interaction effects between 
compounds vs. pseudo-compounds and letter distance to 
morpheme boundary in an LME model fitting anticipation 
of up-coming 
BMU
s by a TSOM. Negative and positive 
x
values indicate letter positions located, respectively, in the 
first and second constituent. Anticipation is plotted across 
whole (pseudo)compounds (top panel), and by individual 
constituents (bottom panel). 
Figure 3 (top panel) illustrates the rate of letter 
anticipation across the word for both compounds 
and pseudo-compounds, plotted by distance to 
the morpheme boundary. The steeper rate for 
pseudo-compounds than for compounds shows 
that 
pseudo-compounds 
are 
easier 
to 
pre-
dict/anticipate 
than 
compounds. 
We 
take 
this 
evidence to be in line with evidence of a faster 
speedup rate in the typing of monomorphemic 
vs. compound words. A closer look at anticipa-
tion rates for individual constituents (Figure 3 
bottom panel) shows a drop of anticipation at the 
C1-C2 
boundary 
(more 
prominent 
for 
com-
pounds than pseudo-compounds) with a steeper 
increase in C1 and C2 for pseudo-compounds, 
which happen to be, on average, shorter than C1 
and C2 in real compounds. 
To look for structural correlates of anticipation 
rates in the map, we conducted, for each item, a 
letter-by-letter analysis of values of pointwise 
entropy (PWH) for the connections between con-
secutive 
BMU
s, 
namely 
h=BMU(t-1)
and 
i=BMU(t)
: 
𝑃𝑃𝑃𝑃𝑃𝑃 𝑚𝑚
!,!
= −𝑙𝑙𝑙𝑙𝑙𝑙
𝑚𝑚
!,!
𝑚𝑚
!,!
!
The value of PWH for the connection between 
end-C1 and start-C2 (
x 
= 0) has a local peak in 
compounds only (Figure 4). Since PWH provides 
a measure of how unexpected the activation of 
BMU
(
t
) is, this structural evidence can account 
for a delay in processing and a drop in anticipa-
tion at the morpheme boundary of compounds, 
but not of pseudo-compounds. 
Figure 4 – Marginal plots of interaction effects between 
compound vs. pseudo-compound
constituents and letter 
distance to morpheme boundary in an LME model fitting 
pointwise entropy of forward BMU connections. Negative 
and positive 
x
values indicate letter positions located, re-
spectively, in the first and second constituent.
3
Discussion and conclusions 
Trained 
on 
both 
compounds 
and 
pseudo-
compounds, TSOMs develop a growing sensi-
tivity to surface distributional properties of input 
data, turning chains of randomly connected, gen-
eral-purpose nodes into specialised sub-chains of 
BMU
s that respond to specific letter string
s at 
specific positions. Compounds not only tend to 
occur, 
on 
average, 
less 
frequently 
than 
their 
C1/C2 constituents do as independent words (Ji 
et 
al. 
2011), 
but 
they 
tend 
to 
present 
lower-
frequency bigrams at the C1-
C2 boundary than 
do 
pseudo-compounds. 
Principles 
of 
Hebbian 
learning allow TSOMs to capitalise on both ef-
fects. Entrenchment makes expectations for high-
frequency bigrams stronger and expectations for 
low-frequency 
bigrams 
weaker
. 
At 
the 
same 
time, the competition between C1 as an inde-
pendent word and C1 as the first constituent in a 
C1-C2 compound 
biases the map’s expectation 
towards the most frequent event (C1 in isola-
tion). Compound families, i.e. sets of compounds 
sharing 
C1 
(
windmill
, 
windshield
etc.) 
or 
C2 
(
snowball
, 
basketball
etc.), 
magnify 
these 
ef-
fects, making the map more sensitive to formal 
discontinuity 
at 
morpheme 
boundaries. 
When 
more C2s can follow the same C1 in complemen-
tary distribution, the left-to-right 
expectation for 
a particular C2 to occur, given C1, decreases. 
Likewise, when more C1s competitively select 
the same C2, the individual contribution of each 
C1 to the prediction of C2 decreases. We conjec-
ture that more global effects of lexical organisa-
tion like these may eventually blur local memory 
CLIC_2016_Proceedings.indd 149
02/12/16 15.03
150
effects 
based 
on 
position-independent 
bigram 
frequencies. 
Our simulations with TSOMs can model the 
correlation between continuously varying distri-
butional regularities in the input data and periph-
eral levels of routinized recognition and produc-
tion 
patterns. 
These 
patterns 
are 
in 
line 
with 
Gagné & Spalding’s evidence of (a) the influ-
ence of embedded pseudo-morphemes on cas-
caded models of written word production, and 
(b) faster anticipation rates for monomorphemic 
vs. compound words. 
Further 
experimental 
results 
(not 
reported 
here), obtained by including compound families 
in the training data, confirm slower anticipation 
rates for true compound constituents, due to the 
combined effect of word frequency distributions 
and word compositionality in compound fami-
lies. The size of a compound family can arguably 
be a function of the degree of productivity and 
semantic transparency of its members (Baroni et 
al. 2007). The influence of the compound family 
size on anticipation rates can shed light on the 
influence of levels of semantic transparency on 
compound processing. Simulation evidence sug-
gests that the bigger the family, the stronger its 
influence will be. Finally, we also monitored the 
influence 
of 
increasing 
token 
frequencies 
of 
monomorphemic words in the training data on 
the 
map 
perception 
of 
constituent 
boundaries 
within 
compounds. 
As 
expected, 
for 
constant 
frequency values of compounds in the training 
set, the higher the token frequency of monomor-
phemic words, the higher the pointwise entropy 
of connections at the C1-C2 boundary. 
A full account of Gagné & Spalding’s evi-
dence of a graded influence of semantic trans-
parency on compound processing is beyond the 
reach of the computational architecture presented 
here. Surface effects of discontinuity in the inter-
nal structure of compounds (as opposed to pseu-
do-compounds) appear to provide a purely for-
mal, pre-lexical scaffolding for truly morpho-
semantic effects to emerge at later processing 
stages. To model these effects, we appear to be 
in need of a parallel processing architecture able 
to effectively integrate several representational 
levels (orthographic, phonological, morphologi-
cal, 
and 
conceptual) 
and 
different 
processing 
steps within a single distributed system (Smolka 
et al. 2009). Nonetheless, our simulations show 
that by letting compounds, pseudo-compounds 
and (pseudo)constituents compete for the same 
level of memory resources on a topological map, 
it is possible to account for apparently contradic-
tory effects of a) graded perception of constituent 
boundary 
in 
both 
compounds 
and 
pseudo-
compounds, apparently requiring prelexical de-
composition, and b) higher anticipation rates for 
pseudo-compounds than compounds, supporting 
full form representations for lexical access. 
References 
Baroni 
M., 
Guevara 
E., 
& 
Pirrelli 
V. 
(2007) 
NN 
Compounds in Italian: Modelling Category Induc-
tion and Analogical Extension, in V. Pirrelli (Ed.) 
Psycho-computational issues in morphology learn-
ing and processing
. 
Lingue e Linguaggio
VI
(2), 
263 - 290. 
Diependaele, K., Grainger, J., & Sandra, D. (2012). 
Derivational Morphology and Skilled Reading: An 
Empirical Overview. In M. J. Spivey, J. McRae, & 
M. F. Joanisse (Eds.) 
The Cambridge Handbook of 
Psycholinguistics
, 311-332. Cambridge University 
Press. 
Ferro M., Marzi, C., & Pirrelli, V. (2011). A Self-
Organizing 
Model 
of 
Word 
Storage 
and 
Pro-
cessing: 
Implications 
for 
Morphology 
Learning. 
Lingue e Linguaggio X (2)
, 209 - 226. 
Gagné, C. L., & Spalding, T. L. (2014). Typing time 
as an index of morphological and semantic effects 
during 
English 
compound 
processing. 
Lingue 
e 
Linguaggio
, 
XIII
(2), 241-262. 
Gagné, C. L., & Spalding, T. L. (2016
). Effects of 
morphology and semantic transparency on typing 
latencies 
in 
English 
compound 
and 
pseudo-
compound 
words. 
Journal of Experimental Psy-
chology: Learning, Memory, and Cognition
, 42, 
1489-1495. 
Giraudo, H., & Grainger, J. (2000). Effects of prime 
word frequency and cumulative root frequency in 
masked 
morphological 
priming. 
Language 
and 
Cognitive Processes
, 15(4/5), 421–44. 
Grainger, J., Colé, P., & Segui, J. (1991). Masked 
morphological priming in visual word recognition. 
Journal of Memory and Language
, 30, 370–84. 
Kandel, S., Álvarez, C. J., & Vallée, N. (2008). Mor-
phemes also serve as processing units in handwrit-
ing production. In M. Baciu (Ed.), 
Neuropsycholo-
gy and cognition of language. Behavioural, neuro-
psychological and neuroimaging studies of spoken 
and written language
, 87–100. Kerala, India: Re-
search Signpost. 
Libben, G. (2010). Compound words, semantic trans-
parency, 
and 
morphological 
transcendence. 
Lin-
guistische Berichte
, 
Sonderheft 17
, 317-330. 
Libben, G., & Weber, S. (2014). Semantic transparen-
cy, compounding, and the nature of independent 
variables. In F. Rainer, W. Dressler, F. Gardani, & 
CLIC_2016_Proceedings.indd 150
02/12/16 15.03
151
H. C. Luschutzky (Eds.), 
Morphology and mean-
ing. 
Amsterdam: Benjamins. 
Libben, G., Weber, S., & Miwa, K. (2012). P3: A 
technique for the study of perception, production, 
and 
participant 
properties. 
The Mental Lexicon
, 
7
(2), 237-248. doi:10.1075/ml.7.2.05lib 
Marzi, C., Ferro, M., & Pirrelli, V. (2014) Morpho-
logical structure through lexical parsability. 
Lingue 
e Linguaggio XIII (2)
, 263-290. 
Pirrelli, V., Ferro, M., & Marzi, C. (2015). Computa-
tional complexity of abstractive morphology, In 
Baerman M., Brown D., Corbett G. (Eds.) 
Under-
standing and Measuring Morphological Complexi-
ty
. 
141-166, 
Oxford, 
United 
Kingdom: 
Oxford 
University Press. 
Plaut, 
D. 
C., 
& 
Gonnerman, 
L. 
M. 
(2000). 
Are 
nonsemantic 
morphological 
effects 
incompatible 
with a distributed connectionist approach to lexical 
processing? 
Language 
and 
Cognitive 
Processes
, 
15(4/5), 445–85. 
Sahel, S., Nottbusch, G., Grimm, A., & Weingarten, 
R. (2008). Written production of German com-
pounds: Effects of lexical frequency and semantic 
transparency. 
Written Language & Literacy
, 
11
(2), 
211-227. doi:10.1075/wll.11.2.06sah 
Schreuder, R., & Baayen, H.R. (1995) Modeling mor-
phological 
processing. 
In 
Feldman, 
L. 
B. 
(Ed.) 
Morphological 
aspects 
of 
language 
processing
, 
131–56, Hillsdale, NJ: Erlbaum. 
Smolka, E., Komlosi, S., & Rösler, F. (2009). When 
semantics means less than morphology: The pro-
cessing of German prefixed verbs. 
Language and 
Cognitive Processes
, 
24
(3), 337-375. 
Rumelhart, D., & McClelland, J. 1986. On learning 
the past tense of English verbs. In Rumelhart, D.E, 
McClelland 
J. 
(Eds.), 
Parallel 
distributed 
pro-
cessing: 
Explanations 
in 
the 
microstructure 
of 
cognition
, 216-271, The MIT Press. 
Taft, M., & Forster, K. I. (1975). Lexical storage and 
retrieval 
of 
prefixed 
words. 
Journal 
of 
Verbal 
Learning and Verbal Behavior
, 14, 638–47. 
Will, U., Nottbusch, G., & Weingarten, R. (2006). 
Linguistic units in word typing: Effects of word 
presentation modes and typing delay. 
Written Lan-
guage & Literacy
, 
9
(1), 153-176. 
CLIC_2016_Proceedings.indd 151
02/12/16 15.03
152
Lexical categories or frequency
effects? A feedback from quantitative 
methods applied to psycholinguistic models in two studies on Italian. 
Francesca Franzon
*
, Giorgio Arcara
°
, Chiara Zanini
*
*
Dipartimento di Neuroscienze, Università degli Studi di Padova 
°
IRCSS Ospedale san Camillo, Lido di Venezia 
{francescafranzon7;giorgio.arcara}@gmail.com; 
chiara.zanini.2@unipd.it 
Abstract 
English.
We examined two issues concern-
ing Italian Number morphology: the phe-
nomena related to mass and count nouns 
and to the plural dominance. By taking into 
account quantitative data from corpora and 
subjective frequency ratings in three mixed 
effect models, we found that differences in 
participants’ per
formance in two lexical de-
cision tasks could be better captured as dif-
ferences in frequency rather than in terms of 
effects of lexical categories. 
Italiano.
In questo studio sono stati posti a 
confronto due fenomeni pertinenti alla mor-
fologia nominale di Numero in italiano: la 
contabilità dei nomi e la dominanza plurale. 
Integrando 
i 
dati 
quantitativi 
provenienti 
dai corpora e da due studi di rating in 
un’analisi statistica condotta tramite model-
li a effetti misti, risulta che le differenze nel-
la prestazione dei partecipanti in due studi 
di decisione lessicale sono riconducibili a 
effetti di frequenza piuttosto che alla pre-
senza di tratti lessicali categoriali. 
Introduction 
The role of frequency in lexical retrieval is well 
known for what concerns psycholinguistic stud-
ies (since, at least, Forster & Chambers, 1973): 
the higher the frequency of a word, the faster its 
retrieval. Generally, the singular form of a noun 
is more frequent than the corresponding plural, 
and thus retrieved faster. However, some nouns 
(e.g. 
stelle, ‘stars’)
do occur more frequently in 
the plural than in the singular: the phenomenon is 
known 
as 
plural 
dominance. 
Plural 
dominant 
nouns are in fact accessed faster in the plural 
form than in the singular. Since such nouns are 
not 
identifiable 
as 
a 
homogeneous 
group 
by 
means of some semantic features, the phenome-
non has been explained as a mere 
effect of the 
frequency of occurrence of the forms (Baayen et 
al., 1996; 1997; 2007; Biedermann et al., 2013). 
While the plural dominance seems to be unre-
lated to grammatical constraints, another phe-
nomenon involving Number morphology seems 
to be grammatically grounded instead, namely 
the mass-count issue (Borer, 2005; Cheng, 1973; 
Chierchia, 2010; Jackendoff, 1991). Nouns refer-
ring to countable entities are called 
‘count nouns’ 
(
anello
, ‘ring’), nouns referring to uncountable 
entities are called ‘mass nouns’ (burro, ‘butter’)
. 
Some constraints rule the possibility for the two 
types of nouns to occur in some morphosyntactic 
contexts, for example count nouns cannot occur 
in the singular after a quantifier (*
molto anello
, 
‘much ring’), while mass nouns cannot occur 
with numerals or the indeterminate article (*
un 
burro, ‘
a 
butter’). For what concerns Number 
morphology, mass nouns should occur only in-
flected in the singular (but for a deeper discus-
sion, see i.a. Acquaviva, 2013; Marcantonio & 
Pretto, 2001; Pelletier, 2012). 
Previous lexical decision tasks have pointed 
out 
to 
some 
differences in 
the 
processing 
of 
count nouns with respect to mass nouns, which 
would require longer response times (RTs) (i.a. 
Mondini et al. 2009; Gillon et al. 1999). 
In the 
light of these results, it has been proposed that an 
additional lexical feature has to be computed for 
mass nouns as compared to count nouns. 
While psycholinguistic studies on plural dom-
inance have relied on relative frequency of sin-
gu
lar and plural forms in the selection of stimuli 
and in results analysis, even the most recent ex-
perimental studies on the mass-count issue have 
not quantified the actual occurrence of the exper-
CLIC_2016_Proceedings.indd 152
02/12/16 15.03
153
imental stimuli in mass context and in count con-
text: nouns have rather been assigned to a mass 
or to a count category on the basis of the experi-
menters
’
judgments. Quantitative data on syntac-
tic contexts can instead provide a better estimate 
of the frequency of use of nouns as countable or 
uncountable: in the present study we relied on 
the actual occurrence of nouns in the different 
syntactic 
contexts 
in 
assigning 
them 
to 
the 
“
mass
”
or 
to the “
count
”
experimental list. 
We will describe and put into comparison two 
lexical decision tasks, concerning the phenomena 
of mass-count and of plural dominance respec-
tively. We will explore the possibility that the 
mass-count effects described in psycholinguistic 
literature could be better explained in terms of 
frequency of occurrence, as it is recognized by 
most literature with respect to plural dominance. 
We hypothesize that the frequency of occurrence 
of the word form (inflected in the singular or in 
the plural) will predict the RTs in lexical deci-
sion tasks contrasting mass and count nouns, as 
well as in the ones concerning the plural domi-
nance issue. The frequency of occurrence will be 
measured by means of two subjective frequency 
rating studies and in the corpus ItWaC (Baroni et 
al. 2009). We will rely on quantitative measures 
to categorize experimental stimuli. Measures of 
plural dominance of nouns will be based on the 
ratio between their occurrence in the plural and 
in the singular; the mass and count experimental 
nouns will be categorized considering their dis-
tribution with respect to mass and count morpho-
syntactic contexts. 
1
First study: mass and count nouns 
1.1
Rating and corpus analysis 
448
concrete nouns, namely 224 nouns inflected 
both in the singular and in the plural, were se-
lected following the theoretical definitions given 
in traditional grammars. The list included the 
plural of 45 nouns for which only singular occur-
rences would be expected on a normative basis 
(pure 
“mass” 
nouns 
such 
as 
burro
‘butter’ 
- 
*
burri
‘butters’). 
A questionnaire was designed in order to eval-
uate the subjective frequency of the 448 nouns 
following the methods used in previous literature 
(Ferrand et al., 2008). The questionnaire was 
administered online by 
means of the Survey-
Monkey platform. 126 informants participated in 
this study (age: range = 22 - 76 years, mean = 
36.2, SD = 12.46; years of education: range = 8-
21). Participants were instructed not to express 
normative judgments, but to focus on the fre-
quency they had heard or read the words; they 
had to assign a score to the frequency of the 
nouns on a 7-point Likert scale, ranging from 0 = 
"never heard or seen” to 6 = “more than once a 
day”.
The nouns in the questionnaires were pre-
sented to each participant in a different random 
order. 
Table 1: Distribution of the subjective frequency 
scores. 
Absolute 
frequency 
of 
the 
aforementioned 
nouns was collected on the ItWaC corpus (Baro-
ni et al., 2009). A positive correlation was found 
between corpus 
frequency 
and 
subjective 
fre-
quency: r(446) = 0.75, p <.001. In order to dis-
ambiguate the mass use from the count use of the 
nouns presented in the rating questionnaire, we 
designed queries in CQP syntax following the 
methods described by Katz & Zamparelli (2012). 
The occurrence of nouns with determiners such 
as the indeterminate article and quantifiers were 
used to 
trace 
the 
occurrence 
in 
unambiguous 
count or mass context. 
1.2
Lexical decision task 
From the initial list of 224 nouns, 80 nouns were 
selected and presented both in the singular and in 
the 
plural 
(totally 
160 
experimental 
stimuli). 
These stimuli were selected to span as uniformly 
as possible across the range of possible values of 
subjective frequency in order to use the subjec-
tive frequency as a continuous variable in the 
analysis. From the 80 nouns we classified as 
“mass” the 18 top mass
-used nouns with the 
highest mass frequencies and values of count 
frequencies that were not among the top 18; we 
classified 
as “count” the 18 top count
-used nouns 
with the highest count frequencies and values of 
mass frequencies that were not among the top 18. 
The nouns were presented both in the singular 
and in the plural (totally 72). The remaining 
stimuli were not categorised in such terms. Ex-
perimental stimuli are displayed in table 2. The 
Score mean 
Singular 
Plural 
n = 0 
0 
0 
0 < n ≤ 1
0 
7 
1 ≤ n ≤ 2
3 
47 
2 ≤ n ≤ 3
45 
60 
3 ≤ n ≤ 4
88 
63 
4 ≤ n ≤ 5
70 
36 
n > 5 
14 
7 
CLIC_2016_Proceedings.indd 153
02/12/16 15.03
154
final list included 240 filler words, consisting in 
80 adjectives and 160 phonotactically plausible 
non-words. 
N. of 
items 
Corpus 
Frequency 
Subjective 
Frequency 
Length 
All stimuli 
160 
11850.32 
(27239.65) 
3.29 
(1.18) 
6.41 
(1.66) 
“Mass” nouns: 
singular 
18 
26204.88 
(28831.43) 
4.36 
(0.57) 
6.22 
(1.89) 
“Mass” nouns: 
plural 
18 
824 
(1187.38) 
1.95 
(0.72) 
6.28 
(1.96) 
“Count” nouns: 
singular 
18 
38570.05 
(54194.95) 
4.09 
(0.84) 
5.78 
(1.31) 
“Count”nouns: 
plural 
18 
24365 
(36455) 
4.07 
(0.80) 
5.89 
(1.27) 
Table 2: Psycholinguistic properties of experi-
mental stimuli. 
60 Italian native speakers participated in the 
experiment (mean age = 23.5, SD = 2.37; years 
of education: mean = 15.16, SD = 1.64). Partici-
pants saw a series of letter strings presented at 
the center of the screen one at a time. They had 
to press a key if they thought the string was an 
Italian word, another key in the converse case. 
1.3
Results 
Results were analyzed by means of mixed effect 
models (Baayen, Davidson & Bates, 2008). In 
the model 1, summarized in table 3, we included 
the 
72 
stimuli 
classified 
as 
mass 
and 
count 
nouns. We considered as predictors: 
category 
(mass/count)
, 
Number (singular/plural), corpus 
frequency, subjective frequency 
and
orthograph-
ic 
length
. 
Results 
show 
significant 
effects 
of 
length (longer RTs for longer items), of Number 
(longer RTs for plurals) and of subjective fre-
quency (longer RTs for low subjective frequen-
cy). 
Fixed 
effect 
Coeffi-
cient 
Stand-
ard 
Error 
df 
t 
p-value 
Intercept 
6.56 
0.05 
95.18 
130.53 
<0.001 
Number= 
plural 
0.37 
0.02 
64.33 
2.04 
0.04 
Subjective 
frequency 
-0.04 
0.007 
74.09 
-4.27 
<0.001 
Ortho-
graphic 
length 
0.009 
0.004 
65.86 
2.077 
0.04 
Table 3: Results of model 1. 
In model 2, summarized in table 4, we includ-
ed all the 160 stimuli. We considered as predic-
tors: 
Number
(singular/plural), 
corpus frequency, 
subjective 
frequency 
and 
orthographic 
length
. 
Results show significant effects of length (long-
er RTs for longer items), of corpus frequency 
(longer RTs for low corpus frequency) and of 
subjective frequency (longer RTs for low subjec-
tive frequency). 
Notably, the predictor c
ategory
is not signifi-
cant (p = 0.85); 
corpus frequency
is a significant 
predictor in model 2 (p = 0.03), but it only ap-
proached significance in model 1 (p = 0.05). Pos-
sibly, in model 1 
Number
is a significant predic-
tor 
because 
the 
categoris
ed 
items 
represent 
a 
subset that differ for frequency of occurrence in 
the plural. In fact, in model 2, in which both cat-
egorised and not categorised items were consid-
ered, no effect of Number was found. 
Table 4: Results of model 2. 
2
Second study: plural dominance 
2.1
Rating and corpus analysis 
The ItWaC corpus was queried to obtain the fre-
quency of occurrence of the singular and the plu-
rals of nouns displaying the most common in-
flectional 
patterns 
(-o/-i; 
-a/-e). 
We 
discarded 
from testing material compounds, derived nouns 
and the nouns that differ for orthographic length 
or phonological form between singular and plural 
(e.g. 
occhio - occhi
‘eye –eyes’)
. The remaining 
nouns were then ordered on the base of their plu-
ral dominance defined as the ratio plural fre-
quency/singular frequency. We calculated stem 
frequency of nouns and selected 284 nouns uni-
formly span across the range of possible values 
of frequency. 
A questionnaire was created in order to test 
the 
subjective 
frequency 
of 
the 
284 
selected 
nouns, both in the singular ad the plural (568 
experimental items). The questionnaire was ad-
ministered 
following 
the 
same 
methods 
de-
scribed 
previously 
(§2.1). 
150 
Italian 
native 
speakers participated in the study (age: range = 
18 
–
69, mean = 29; years of education: range = 
8-21). The distribution of the subjective frequen-
cy is plotted in Table 5. A positive correlation 
was found between the singular and plural forms 
Fixed effect 
Coefficient 
Standard 
Error 
df 
t 
p-
value 
Intercept 
6.73 
0.04 
219.42 
172.38 
<0.001 
Corpus 
frequency 
-0.009 
0.004 
155.55 
-2.16 
0.03 
Subjective 
frequency 
-0.05 
0.008 
152.19 
-5.37 
< 
0.001 
Orthographic 
length 
0.008 
0.004 
2.47 
2.11 
0.04 
CLIC_2016_Proceedings.indd 154
02/12/16 15.03
155
of nouns within the corpus (r(282) = 0.70, p < 
.001) and within the rating (r(282) = 0.91, p < 
.001). 
Score mean 
Singular 
Plural 
n = 0 
0 
0 
0 < n ≤ 1
0 
1 
1 ≤ n ≤ 2
19 
20 
2 ≤ n ≤ 3
88 
100 
3 ≤ n ≤ 4
139 
131 
4 ≤ n ≤ 5
31 
27 
n > 5 
7 
5 
Table 5: Distribution of the subjective frequency 
scores. 
2.2
Lexical decision task 
A lexical decision study was carried out, follow-
ing the same methods described in §2.2. From 
the 284 nouns mentioned in §3.1, we chose: the 
30 nouns with the highest ratio of plural domi-
nance, the 30 nouns with the lowest ratio of plu-
ral dominance, the 30 nouns whose ratio between 
singular ad plural was the closest to 1 (see table 
6). Each noun was presented in the singular and 
in the plural (totally 180 experimental stimuli). 
The final list included 364 filler words, consist-
ing in 184 adjectives and 180 phonotactically 
plausible non-words. 
43 Italian native speakers participated in the 
experiment. 
Domi-
nance 
(mean 
Pl/Sg) 
Morpho-
logical 
Number 
N. of 
items 
Corpus 
Frequency 
Subjective 
Frequency 
Ortho
tho-
graph
ic 
Len 
gth 
Plural 
(3.61) 
Singular 
30 
5260.3 
(7547.43) 
3.31 
(0.77) 
6.33 
(1.09) 
Plural 
30 
19026.46 
(25558.41) 
3.48 
(0.79) 
Singu-
lar 
(0.16) 
Singular 
30 
25596.9 
(44944.15) 
3.44 
(0.91) 
6.13 
(1.13) 
Plural 
30 
4276.3 
(7186.03) 
3.23 
(0.79) 
Equal 
(0.9) 
Singular 
30 
35430.33 
(99471.4) 
3.13 
(0.57) 
6.16 
(1.17) 
Plural 
30 
31921.7 
(93584.35) 
3.1 
(0.59) 
Table 6: Psycholinguistic properties of experi-
mental stimuli. 
2.3
Results 
Results were analysed by means of mixed effect 
models (Baayen, Davidson & Bates 2008). In 
model 3, summarized in table 7, we considered 
as 
predictors: 
category 
(plural/singular/equal 
dominant)
, 
Number 
(singular/plural), 
corpus 
frequency, subjective frequency 
and
orthograph-
ic 
length
. 
Results 
show 
significant 
effects 
of 
length (longer RTs for longer items), of corpus 
frequency (longer RTs for low corpus frequency) 
and of subjective frequency (longer RTs for low 
subjective frequency). 
Table 7: Results of model 3. 
3
Discussion and conclusions 
In this study we applied quantitative methods in 
the selection of experimental stimuli used in the 
two lexical decision tasks. In both tasks, results 
from the three models showed effects of subjec-
tive frequency and corpus frequency 
but not of 
category in written word recognition. For what 
concerns the plural dominance issue, this result 
was in line with previous literature. For what 
concerns the mass-count issue, our results are 
unexpected instead. Remind that frequency of 
occurrence in mass and count contexts was used 
to avoid biases in categorization of stimuli. Nev-
ertheless, we did not observe differences in RTs 
between the two so categorized groups of nouns. 
Thus, we suggest that there is no need to postu-
late the computation of a lexical feature related 
to countability or uncountability in nouns. We 
propose that the fact that a noun is considered 
“mass”
is better described as an epiphenomenon 
of the distribution of noun with respect of syntac-
tic contexts. However the possibility for a noun 
to occur in the different syntactic 
contexts does 
not predict lexical decision RTs: frequency, as 
measured in the corpus and by the rating study, is 
the predictor of the lexical access times with re-
spect to words presented in isolation. In this 
sense, the mass-count issue is similar to the plu-
ral dominance phenomenon: even in that case, 
there is no need to assume the presence of a fea-
ture marking plurality, as the frequency of the 
inflected form is sufficient to account for the ob-
served effects in lexical decision tasks. 
The frequency of occurrence of nouns consid-
ered as a continuous variable is a better predictor 
of RTs than a 
distinction attributed to alleged 
lexical categories both in the case of phenomena 
Fixed effect 
Coeffi-
cient 
Stand-
ard 
Error 
df 
t 
p-value 
Intercept 
6.79 
0.04 
211.6
4 
137.79 
<0.001 
Corpus 
frequency 
-0.02 
0.003 
171.5
5 
-7.23 
<0.001 
Subjective 
frequency 
-0.03 
0.007 
170.1
7 
-4.48 
< 0.001 
Orthographic 
length 
0.009 
0.004 
165.9
3 
2.03 
0.04 
CLIC_2016_Proceedings.indd 155
02/12/16 15.03
156
seemingly unrelated to core grammar rules, like 
the plural dominance, as well as in phenomena 
that have traditionally been described as gram-
mar based, like the mass-count issue. 
References 
Acquaviva, P. (2013).
Il nome. 
Roma: Carocci. 
Baayen, H., Burani, C., & Schreuder, R. (1996). 
Effects of semantic markedness in the pro-
cessing of regular nominal singulars and plu-
rals 
in 
Italian. 
Yearbook 
of 
morphology
, 
Springer Netherlands, 13-33. 
Baayen, R. H., Dijkstra, T., & Schreuder, R. 
(1997). Singulars and plurals in Dutch: Evi-
dence for a parallel dual-route model. 
Journal 
of Memory and Language
, 37(1), 94-117. 
Baayen, R. H., Davidson, D. J., & Bates, D. M. 
(2008). Mixed-effects modeling with crossed 
random effects for subjects and items. 
Journal 
of Memory and Language
, 
59
(4), 390-412. 
Baayen, R., Levelt, W., Schreuder, R., & Ernes-
tus, 
M. 
(2007). 
Paradigmatic 
structure 
in 
speech production. 
Proceedings from the An-
nual Meeting of the Chicago Linguistic Socie-
ty,
43(1): 1-29. Chicago Linguistic Society. 
Balota, 
D. 
A., 
Pilotti, 
M., 
& 
Cortese, 
M. 
J. 
(2001). 
Subjective 
frequency 
estimates 
for 
2,938 monosyllabic words. 
Memory & Cogni-
tion
29(4), 639-647. 
Baroni, M., Bernardini, S., Ferraresi, A., & Zan-
chetta, E. (2009). The WaCky Wide Web: A 
Collection of Very Large Linguistically Pro-
cessed Web-Crawled Corpora. 
Language Re-
sources and Evaluation
43 (3), 209-226. 
Biedermann, B., Beyersmann, E., Mason, C., & 
Nickels, 
L. 
(2013). 
Does 
plural 
dominance 
play a role in spoken picture naming? A com-
parison of unimpaired and impaired speakers
. 
Journal of Neurolinguistics,
26(6), 712-736. 
Borer, H. (2005). 
In name only
. Oxford: OUP. 
Cheng, C.-Y. (1973). Response to Moravcsik. J. 
Hintikka, 
J.M.E. 
Moravcsik, 
& 
P. 
Suppes 
(eds.). 
Approaches to Natural Language
. Dor-
drecht: Reidel, 286-288. 
Chierchia, G. (2010). Mass nouns, vagueness and 
semantic variation. 
Synthèses
174, 99-149. 
Ferrand, L., Bonin, P., Méot, A., Augustinova, 
M., 
New, B., 
Pallier, 
C., & Brysbaert, M. 
(2008). Age-of-acquisition and subjective fre-
quency 
estimates 
for 
all 
generally 
known 
monosyllabic French words and their relation 
with other psycholinguistic variables. 
Behav-
ior Research Methods
40 (4), 1049-1054. 
Forster, K. I., & Chambers, S. M. (1973). Lexical 
access 
and 
naming 
time.
Journal 
of 
verbal 
learning and verbal behavior
, 
12
(6), 627-635. 
Gillon, B., Kehayia, E., & Taler, V. (1999). The 
mass/count distinction: Evidence from on-line 
psycholinguistic performance. 
Brain and Lan-
guage 
68, 205-211. 
Jackendoff, 
R. 
(1991). 
Parts 
and 
boundaries. 
Cognition
41, 9-45. 
Katz, G. & Zamparelli, R. (2012). Quantifying 
Count/Mass Elasticity. Choi, J. et al. (eds). 
Proceedings of the 29th West Coast Confer-
ence on Formal Linguistics
. Somerville, MA: 
Cascadilla Proceedings Project, 371-379. 
Kulkarni, R., Rothstein, S., & Treves, A. (2013). 
A 
Statistical 
Investigation 
into 
the 
Cross-
Linguistic 
Distribution 
of 
Mass 
and 
Count 
Nouns: Morphosyntactic and 
Semantic 
Per-
spectives. 
Biolinguistics
7, 132-168. 
Kuperman, V., & Van Dyke, J. A. (2013). Reas-
sessing word frequency as a determinant of 
word 
recognition 
for 
skilled 
and 
unskilled 
readers. 
Journal of Experimental Psychology: 
Human 
Perception 
and Performance
39(3), 
802. 
Marcantonio, A. & Pretto, A. M. (2001). Il no-
me. 
L. 
Renzi, 
G. 
Salvi, 
& 
A. 
Cardinaletti 
(eds.). 
Grande grammatica italiana di consul-
tazione
. Bologna: Il Mulino, 329-346. 
Mondini, S., Kehaya, E., Gillon, B., Arcara, G., 
& Jarema, G. (2009). Lexical access of mass 
and count nouns. How word recognition reac-
tion times correlate with lexical and morpho-
syntactic processing. 
The Mental Lexicon 
4, 
354-379. 
Pelletier, F. J. (2012a). Lexical Nouns are Nei-
ther Mass nor Count, but they are Both Mass 
and 
Count. 
D. 
Massam 
(ed.). 
A 
Cross-
Linguistic Exploration of the Count-Mass Dis-
tinction
. Oxford: OUP, 9-26. 
Williams, R., & Morris, R. (2004). Eye move-
ments, word familiarity, and vocabulary ac-
quisition. 
European Journal of Cognitive Psy-
chology
16(1/2), 312
–
339. 
CLIC_2016_Proceedings.indd 156
02/12/16 15.03
157
The DiDi Corpus of South Tyrolean CMC Data:
A multilingual corpus of Facebook texts
Jennifer-Carmen Frey
Aivars Glaznieks
Institute for Specialised Communication and Multilingualism
EURAC Research
Bolzano/Bozen, Italy
{
jennifer.frey,aivars.glaznieks,egon.stemle
}
@eurac.edu
Egon W. Stemle
Abstract
English.
The DiDi
corpus of South Ty-
rolean data of
computer-mediated com-
munication (CMC)
is a multilingual
so-
ciolinguistic language corpus.
It consists
of around 600,000 tokens collected from
136 profiles of
Facebook users residing
in South Tyrol,
Italy.
In conformity with
the multilingual
situation of the territory,
the main languages of the corpus are Ger-
man and Italian (followed by English).
The data has been manually anonymised
and provides manually corrected part-of-
speech tags for the Italian language texts
and manually normalised data for German
texts.
Moreover, it is annotated with user-
provided socio-demographic data (among
others L1, gender, age, education, and in-
ternet communication habits) from a ques-
tionnaire,
and linguistic annotations
re-
garding CMC phenomena,
languages and
varieties. The anonymised corpus is freely
available for research purposes.
Italiano.
DiDi
`
e un corpus
di
comu-
nicazione mediata dal
computer (CMC),
che
raccoglie
dati
linguistici
di
area
sudtirolese.
Il
corpus,
multilingue
e
sociolinguistico,
`
e
composto
da
circa
600,000 occorrenze raccolte (previo con-
senso all’utilizzo dei
dati)
dai
profili
di
136 iscritti a Facebook e residenti in Alto
Adige.
Le principali
lingue del
corpus,
tedesco e italiano (seguite dall’inglese),
riflettono lo spazio plurilingue del
ter-
ritorio.
I
dati
sono stati
manualmente
anonimizzati
e i
testi
in lingua italiana
sono corredati da etichette (manualmente
corrette)
per le parti
del
discorso.
In-
oltre,
DiDi
`
e annotato con dati
sociode-
mografici
forniti
dall’utente (fra gli
al-
tri: L1, genere, et
`
a, istruzione e modalit
`
a
di comunicazione via Internet) attraverso
un questionario e contiene ulteriori
an-
notazioni linguistiche relative a fenomeni
legati alla CMC e agli usi di variet
`
a lin-
guistiche. Il corpus anonimizzato
`
e libera-
mente disponibile a fini di ricerca.
1
The DiDi Project
The autonomous Italian province of
South Ty-
rol is characterized by a multilingual environment
with three official languages (Italian, German, and
Ladin),
an institutional
bi-
or
trilingualism (de-
pending on the percentage of the Ladin popula-
tion),
and diverse individual language repertoires
(Ciccolone, 2010).
In the regionally funded DiDi project,
1
the goal
was to build a South Tyrolean CMC corpus to doc-
ument
the current
language use of residents and
to analyse it
socio-linguistically with a focus on
age.
The project initially focused on the German-
speaking language group.
However,
all informa-
tion regarding the project,
e.g.
the invitation to
participate, the privacy agreement, the project web
site, and the questionnaire for socio-demographic
data was published in German and Italian.
Hence,
we attracted speakers of both Italian and German.
Accordingly,
the collected data is multilingual,
with major parts in German but with a substantial
portion in Italian (100,000 of 600,000 tokens).
The collected multilingual
CMC corpus com-
bines Facebook status updates,
comments,
and
private
messages
with socio-demographic
data
(e.g.
language biography,
internet
usage habits,
and general
parameters
like age,
gender,
level
of education) of the writers.
The data was en-
riched with linguistic annotations on thread,
text
and token level including language-specific part-
1
For further information see www.eurac.edu/didi.
CLIC_2016_Proceedings.indd 157
02/12/16 15.03
158
of-speech (PoS) and lemma information, normali-
sation, and language identification.
In this paper,
we describe the corpus with re-
spect
to its multilingual
characteristics and give
special emphasis to the Italian part of the corpus
to which we added manually corrected PoS anno-
tations.
Hence, it presents a continuation of Frey
et al. (2015) which was restricted to German texts
of the corpus, not taking into account the full vari-
ety of data collected for the total corpus.
2
Corpus Construction
For
the purpose of
the DiDi
project,
we col-
lected language data from social networking sites
(SNS) and combined it
with socio-demographic
data about
the writers obtained from a question-
naire.
We chose to collect
data from Facebook
as this SNS is well known in South Tyrol, hosts a
wide variety of different communication settings,
and is used over the whole territory by nearly all
groups of the society.
Related research mainly draws on public data
such
as
public
Facebook
groups,
Twitter
or
chat
data (e.g.
Celli
and Polonio (2013),
Basile
and
Nissim (2013),
Burghardt
et
al.
(2016),
Beißwenger (2013)),
excluding the possibility to
analyse discourse patterns of
non-public every-
day language use.
Collecting non-public and personal data for the
DiDi corpus raised technical issues regarding Ital-
ian privacy regulations (which require user con-
sent incl.
privacy statement),
the time-saving ac-
quisition of authentic and complete language data,
and the assignment of language data to question-
naire data.
These issues have been solved by de-
veloping a Facebook application
2
that allowed for
the gathering of all three sorts of data (user con-
sent,
language data,
questionnaire data) at
once.
In addition,
the application was easy to share via
Facebook which helped to promote the project and
to reach many potential participants.
While data
collection was solely managed by the Facebook
application,
we relied on Facebook’s in-platform
means (i.e.
users’
sharing and liking)
to recruit
participants.
In order to reach older users (
>
50
years) it
was necessary to additionally resort
to
Facebook advertisment.
3
2
The
source
code
is
available
at
https:
//bitbucket.org/commul/didi_app.
3
For details regarding the technical and strategical design
of the data collection and methods of user recruitment
see
Frey et al. (2014).
With the consent
of each participant,
the data
was downloaded via the Facebook Graph API
4
and from the used questionnaire service
5
,
and
stored in a local MongoDB
6
data base.
Both enti-
ties were linked via randomised unique identifiers.
A python interface provided access points to re-
trieve user and text
data from the data base in a
linked and structured format,
and also allowed to
rebuild the conversational structure of threads by
linking successive text objects together.
This in-
formation can now be used to analyse turn-taking
and language choices within threads.
7
3
Corpus Annotations
This section describes the annotations added dur-
ing the process of corpus construction.
8
3.1
Socio-demographic Information about
Participants
The
corpus
provides
the
following
socio-
demographic information about
the participants
obtained from the online questionnaire:
gender,
education,
employment,
internet
communication
habits,
communication devices
in use,
internet
experience, first language(s) (L1), and usage of a
South Tyrolean German or Italian dialect and its
particular origin.
3.2
Linguistic Annotation of Texts
The corpus was annotated on text and token level
with a series of information.
•
Language identification:
The used languages of a text were identified
in a semi-automatic approach:
Firstly,
us-
ing the language identification tool langid.py
(Lui and Baldwin, 2012), and secondly, man-
ually correcting short
texts and texts with a
low confidence score.
•
Tokenisation:
The corpus
was
tokenized with the Twit-
ter
tokenizer
ark-twokenize-py
9
and subse-
4
https://developers.facebook.com/docs/
graph-api
5
http://www.objectplanet.com/opinio/
6
https://www.mongodb.com/
7
The
source
code
is
available
at
https:
//bitbucket.org/commul/didi_proxy.
8
See Frey et
al.
(2015) for detailed information on the
anonymisation procedure and the normalisation and process-
ing of German texts, including identification of languages and
varieties.
9
https://github.com/myleott/
ark-twokenize-py
CLIC_2016_Proceedings.indd 158
02/12/16 15.03
159
quently corrected manually for non-standard
language tokenisation issues.
•
Part-of-speech tagging and lemmatization:
(Corrected) tokens were annotated with PoS
tags and lemma information considering the
predominant
language of
the text
at
hand.
We tagged Italian texts with the Italian tag
set
of the Universal
Dependencies project
10
using the RDR PoS Tagger (Nguyen et
al.,
2014).
Subsequently, we manually corrected
PoS annotations to handle bad tagging accu-
racy for social media texts.
Additionally, we
used the TreeTagger (Schmid, 1994; Schmid,
1995)
to assign PoS tags for
German,
En-
glish,
Spanish,
French and Portuguese texts
applying the standard tagsets for
each lan-
guage.
No manual correction was performed
for these languages.
•
Normalisation:
So far,
we have manually normalised non-
standard language to word-by-word standard
transcriptions only for German texts.
•
Variety of German:
We classified German texts as dialect,
non-
dialect
or
unclassifiable
texts
applying
a
heuristic approach based on the normalisa-
tion.
•
Untranslatable dialect lexemes:
We have created a lexicon for untranslatable
dialect
words
encountered during manual
normalisation.
The dialect lexicon was used
to post-process out-of-vocabulary (OOV) to-
kens in the corpus.
•
Foreign language insertions:
The most common OOV tokens that we man-
ually classified as foreign language vocab-
ulary have been annotated with information
about their language origin.
•
CMC phenomena:
Emoticons,
emojis,
@mentions,
hashtags,
hyperlinks,
and iterations of graphemes and
punctuation marks were annotated automati-
cally using regular expressions.
•
Topic of the text:
In order to investigate context factors of lan-
guage choice we annotated texts as either
10
http://universaldependencies.org/it/
pos/index.html
political
or non-political
according to a list
of politicians,
political
parties and political
terms.
3.3
Conversation-related Annotations
We rebuilt
conversation threads by linking suc-
cessive texts and created thread objects contain-
ing ordered lists of texts that are accessible via the
Python interface. Thread objects contain informa-
tion about the used languages and the number of
active interlocutors and recipients of a message as
well as the time passed between two texts.
As described in Frey et al. (2015), no text con-
tent
of non-participants of the DiDi
project
was
stored, but general information about the publish-
ing time and the language of the text was kept.
If
all
interlocutors of a thread were participants of
the project, the whole conversation is available.
3.4
User-related Annotations
In addition to socio-demographic data,
we added
information about
the users’ (multilingual) com-
municational
behaviour,
i.e.
their
primary lan-
guage,
used languages and the number of inter-
locutors.
4
Corpus Data
4.1
Corpus Size
The DiDi corpus comprises public and non-public
language data of
136 South Tyrolean Facebook
users.
The users could choose to provide either
their
Facebook wall
communication (status up-
dates and comments), their chat (i.e. private mes-
sages) communication or both. In the end, 50 peo-
ple provided access to both types of data. 80 users
only provided access to their Facebook wall and 6
users gave us only their chat communication.
In
total,
the corpus consists of around 600 thousand
tokens that are distributed over the text categories
status updates (172 ,66 tokens), comments (94,512
tokens) and chat messages (328,796 tokens).
4.2
Multilingualism in the Corpus
The corpus is highly multilingual.
Although the
initial
intention of the project
was to document
the use of German in South Tyrol,
German lan-
guage content comprises only 58% of the corpus.
13% are written in Italian and 4% in English (the
remainder of the messages was either classified
as unidentifiable language, non-language or other
language).
The distribution of the languages is
CLIC_2016_Proceedings.indd 159
02/12/16 15.03
160
based on the language backgrounds of the partic-
ipants and is comparable to the multilingual com-
munity of South Tyrol. The following tables show
the distribution of profiles, texts and tokens (table
1) and text type (table 2) by L1.
User L1
Profiles
Texts
Tokens
IT
9
4,260
80,368
DE
108
29,883
421,262
other
3
407
8,643
IT + DE
11
4,165
75,359
DE + other
5
1,110
10,642
Total
136
39,825
596,274
Table 1:
Distribution of profiles, texts and tokens
by L1.
User L1
SU
CO
PM
IT
1,682
1,063
1,515
DE
7,286
4,890
17,707
other
172
45
190
IT+DE
1,962
343
2,791
DE+other
1,031
166
13
Total
11,102
6,507
22,216
Table 2:
Distribution of texts by text
type (SU
= status updated,
CO = comments,
PM = private
messages) by L1.
While very few users wrote only in their first
language, most users used at least two (88%), very
often even three (73%) or more (51%) languages.
Table 3 shows the number and proportion of Ger-
man,
Italian and English texts written as first
or
second/foreign language.
Text written
as L1
as L2
IT
4,761 (57%)
3,566 (42%)
DE
23,191 (99%)
170 (1%)
EN
166 (4%)
3,625 (96%)
All languages
28,120 (78%)
7,842 (22%)
Table 3: Distribution of text language by L1 or L2
use.
In terms of
multilingual
language use in the
DiDi
corpus,
we observe a slight
difference be-
tween Italian and German-speaking users. L1 Ital-
ian speakers stick more to their L1 compared to the
German-speaking participants, who are character-
ized by a higher usage of L2 Italian.
The compar-
ison of L1 and L2 usage in status updates,
com-
ments and private messages (c.f.
Table 4) shows
that the respective L1 is preferred in all messages
types.
We find the highest percentage of second
or foreign language use in status updates, whereas
in comments and private messages around 75% of
the texts are written in L1.
Text written
as L1
as L2
Status updates
6,774 (61%)
3,032 (27%)
Comments
5,089 (78%)
924 (14%)
Messages
16,257 (73%)
3,886 (17%)
Total
28,120 (71%)
7,842 (20%)
Table 4:
Distribution of L1 and L2 use by text
types.
Finally,
we observed 4,295 code-switching in-
stances on conversation level
and at
least
1,653
texts that contain multiple languages
11
.
The aver-
age number of code-switching instances per user
is 10%,
meaning that
every tenth text
does not
continue the language of the previous text in the
thread (the maximum was around every second
text, i.e. 42%). The average proportion of text with
multiple languages per user is 4% (max. 25%).
5
Issues in Corpus Creation
In addition to general issues of working with so-
cial
media texts (e.g.
text
processing on noisy,
short texts as described for example in (Baldwin
et
al.,
2013;
Eisenstein,
2013)) ,
the high diver-
sity in used languages and varieties in our corpus
led to various restraints in corpus creation and pro-
cessing as cross-lingual
annotation and informa-
tion extraction are still crucial problems in natural
language processing.
We tried to address the de-
mands of a multilingual corpus by providing lan-
guage specific PoS tagging and by applying lan-
guage independent annotations.
We are aware of
the fact that this is by no means sufficient to deal
with linguistic research questions that exceed lan-
guage boundaries.
Moreover,
manual
correction
tasks occupied a significant part of the work on the
corpus as automatic annotation (e.g. for language
identification) does not
yet
provide the accuracy
expected for linguistic studies (Carter et al., 2013;
Lui and Baldwin, 2014).
11
Texts were annotated as mixed-language texts during the
correction of the language identification,
therefore this an-
notation has not been done for the whole corpus.
A further
word-level identification of languages could detect even more
mixed-language content(Nguyen and Dogruoz, 2013)
CLIC_2016_Proceedings.indd 160
02/12/16 15.03
161
6
Conclusion and Future Work
In
this
paper
we
presented
a
freely
avail-
able language corpus of
Facebook user
profiles
from South Tyrol,
Italy.
The multilingual
cor-
pus
is
anonymised and annotated with socio-
demographic data of users, language specific (and
for
Italian manually corrected)
PoS tags,
lem-
mas and linguistic annotations mainly related to
used languages,
varieties and multilingual
phe-
nomena.
The corpus is accessible for querying
via ANNIS
12
or can be obtained as processable
data for
research purposes
on http://www.
eurac.edu/didi.
Acknowledgements
The project
was financed by the Provincia au-
tonoma di
Bolzano – Alto Adige,
Ripartizione
Diritto allo studio,
universit
`
a
e
ricerca
scien-
tifica, Legge provinciale 13 dicembre 2006, n. 14
”Ricerca e innovazione”.
References
Timothy Baldwin,
Paul
Cook,
Marco Lui,
Andrew
MacKinlay, and Li Wang.
2013.
How noisy social
media text, how diffrnt social media sources.
In Pro-
ceedings of the Sixth International Joint Conference
on Natural Language Processing, pages 356–364.
Valerio Basile and Malvina Nissim.
2013.
Sentiment
analysis on Italian tweets.
In Proceedings of the 4th
Workshop on Computational Approaches to Subjec-
tivity,
Sentiment and Social Media Analysis,
pages
100–107.
Michael
Beißwenger.
2013.
Das Dortmunder Chat-
Korpus.
Zeitschrift
f
¨
ur germanistische Linguistik,
41(1):161–164.
Manuel
Burghardt,
Daniel
Granvogl,
and Christian
Wolff.
2016.
Creating a Lexicon of Bavarian Di-
alect
by Means of
Facebook Language Data and
Crowdsourcing.
In Proceedings of
LREC 2016,
pages 2029–2033.
Simon
Carter,
Wouter
Weerkamp,
and
Manos
Tsagkias.
2013.
Microblog language identification:
Overcoming
the
limitations
of
short,
unedited
and
idiomatic
text.
Language
Resources
and
Evaluation, 47(1):195–215.
Fabio Celli and Luca Polonio.
2013.
Relationships be-
tween personality and interactions in facebook.
So-
cial
Networking:
Recent
Trends,
Emerging Issues
and Future Outlook, pages 41–54.
12
http://annis-tools.org/
Simone Ciccolone.
2010.
Lo standard tedesco in Alto
Adige.
Il segno e le lettere. LED Edizioni Universi-
tarie, Milan.
Jacob Eisenstein.
2013.
What
to do about
bad lan-
guage on the internet.
In Proceedings of
NAACL-
HLT, pages 359–369.
Jennifer-Carmen Frey,
Egon W.
Stemle,
and Aivars
Glaznieks.
2014.
Collecting language data of non-
public social
media profiles.
In Gertrud Faaß and
Josef Ruppenhofer,
editors,
Workshop Proceedings
of
the 12th Edition of
the KONVENS Conference,
pages 11–15,
Hildesheim,
Germany,
October.
Uni-
versitatsverlag Hildesheim, Germany.
Jennifer-Carmen Frey,
Egon W.
Stemle,
and Aivars
Glaznieks.
2015.
The DiDi
Corpus of South Ty-
rolean CMC Data.
In Workshop Proceedings of the
2nd Workshop on NLP4CMC at GSCL2015.
Marco Lui and Timothy Baldwin.
2012.
langid.py: An
off-the-shelf language identification tool.
In Pro-
ceedings of
the ACL 2012 system demonstrations,
pages 25–30.
Association for
Computational
Lin-
guistics.
Marco Lui and Timothy Baldwin.
2014.
Accurate lan-
guage identification of twitter messages.
In Pro-
ceedings of
the 5th Workshop on Language Anal-
ysis for Social
Media (LASM)@ EACL,
pages 17–
25, Gothenburg. Association for Computational Lin-
guistics.
Dong-Phuong Nguyen and A Seza Dogruoz.
2013.
Word level language identification in online multi-
lingual communication.
Association for Computa-
tional Linguistics.
Dat Quoc Nguyen, Dang Duc Pham Dai Quoc Nguyen,
and Son Bao Pham.
2014.
RDRPOSTagger: A rip-
ple down rules-based part-of-speech tagger.
In Pro-
ceedings of the Demonstrations at the 14th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 17–20.
Helmut
Schmid.
1994.
Probabilistic part-of-speech
tagging using decision trees.
In Proceedings of the
international
conference on new methods in lan-
guage processing, volume 12, pages 44–49.
Helmut
Schmid.
1995.
Improvements in part-of-
speech tagging with an application to German.
In
Proceedings of the ACL SIGDAT-Workshop.
CLIC_2016_Proceedings.indd 161
02/12/16 15.03
162
Linking IMAGACT ontology to BabelNet through action videos
Lorenzo Gregori
University of Florence
lorenzo.gregori@unifi.it
Alessandro Panunzi
University of Florence
alessandro.panunzi@unifi.it
Andrea Amelio Ravelli
University of Florence
aramelior@gmail.com
Abstract
English.
Herein we present a study deal-
ing with the linking of two multilingual
and multimedia resources,
BabelNet
and
IMAGACT, which seeks to connect videos
contained in the IMAGACT Ontology of
Actions
with related action concepts
in
BabelNet.
The linking is based on a ma-
chine learning algorithm that exploits the
lexical
information of the two resources.
The algorithm has been firstly trained and
tested on a manually annotated dataset and
then it
was run on all
the data,
allowing
to connect
773 IMAGACT action videos
with 517 BabelNet
synsets.
This link-
age aims to enrich BabelNet verbal entries
with a visual
representations and to con-
nect the IMAGACT ontology to the huge
BabelNet semantic network.
Italiano.
In questo articolo si
presenta
uno studio sul
linking tra due
risorse
linguistiche
multilingui
e
multimediali,
BabelNet
e
IMAGACT.
L’esperimento
ha
l’obiettivo
di
collegare
i
video
dell’ontologia dell’azione IMAGACT con
i concetti azionali contenuti in BabelNet.
Il
collegamento
`
e
realizzato attraverso
un algoritmo di
Machine Learning che
sfrutta l’informazione lessicale delle due
risorse.
L’algoritmo
`
e stato addestrato e
valutato su un dataset
annotato manual-
mente e poi
eseguito sull’insieme totale
dei
dati,
permettendo di
collegare 773
video di
IMAGACT con 517 synset
di
BabelNet.
Questo linking ha lo scopo di
arricchire le entrate verbali
di
BabelNet
con una rappresentazione
visuale
e
di
collegare IMAGACT alla rete semantica
di BabelNet.
1
Introduction
1
Ontologies are widely used to represent language
resources on the web,
allowing them to be eas-
ily accessed and exploited by machines.
For this
reason, data interconnection between different se-
mantic resources is a crucial task in order to en-
hance disambiguation and information retrieval
capabilities in Artificial Intelligence, as evidenced
by the increasing research into mapping and link-
ing techniques among ontologies (Otero-Cerdeira
et al., 2015).
Nevertheless, ontology mapping has
to face the problem of concept representation mis-
match between resources, due to different building
criteria and purposes (Siemoneit et al., 2015).
In-
stance matching techniques play an important role
in this context,
allowing to connect entities from
heterogeneous data resources which refer to the
same real-world object (Castano et al., 2008; Nath
et al., 2014).
Aside the general interest for knowledge bases
interconnection in a web-based perspective, there
is also a growing interest in multimodal resources,
which combine textual and visual data.
These re-
sources can be exploited by intelligent algorithms
integrating vision and natural language processing
techinques
2
.
This integrated approach was suc-
cessfully applied for some challenging tasks in-
volving verbs and their action reference as a video.
Regneri
et
al.
(2013) developed machine learn-
ing models for the automatic identification of sim-
ilarity among actions,
by using a corpus of natu-
ral language descriptions, derived from the videos
of the MPII Cooking Composite Activities dataset,
which represents actions involved in basic cooking
tasks.
Instead, the algorithm developed by Mathe
1
Lorenzo Gregori
developed the linking algorithm and
wrote sections 3, 4, and 5; Andrea Amelio Ravelli performed
the data annotation and wrote sections 1 and 2;
Alessandro
Panunzi supervised the research work and revised the paper.
2
Several works in this field have been developed within
The European Network on Integrating Vision and Language
(iV&L Net), http://ivl-net.eu/
CLIC_2016_Proceedings.indd 162
02/12/16 15.03
163
et
al.
(2008) extracts higher level
semantic fea-
tures in common among a sample set of verbs, us-
ing a fine-grained analysis of the represented ac-
tion concepts, intended as a subsequent stable set
of abstract features of the objects involved in the
videos.
Within this interdisciplinary perspective,
a knowledge base which relates verbal lemmas in
different languages with video prototypes can help
in serveral applications, and be exploited by both
humans and machines.
2
Resources
This paper presents a linking between BabelNet
(Navigli
and Ponzetto,
2012a)
and IMAGACT
(Moneglia et
al.,
2014a),
two multilanguage and
multimedia resources suitable for automatic trans-
lation and disambiguation tasks
(Russo et
al.,
2013; Moneglia, 2014; Moro and Navigli, 2015).
2.1
BabelNet
BabelNet
3
is a multilingual semantic network cre-
ated from the mapping together of the WordNet
thesaurus
and the Wikipedia enciclopedia.
At
present, BabelNet 3.7 contains 271 languages and
it
is the widest
multilingual
resources available
for semantic disambiguation.
Concepts and en-
tities are represented by BabelSynsets (BS),
ex-
tensions
of
WordNet
synsets:
a BS is
a uni-
tary concept identified by several kinds of infor-
mations (semantic features,
glosses,
usage exam-
ples,
etc.)
and related to lemmas (in any lan-
guage) which have a sense matching with that con-
cept.
BSs are not isolated, but connected together
by semantic relations.
Moreover,
BabelNet
re-
ceived a large contributions from its mapping with
other
resources
such as
ImageNet,
GeoNames,
OmegaWiki (along with many others),
which in-
creased its information beyond the lexicon and
produced a wide-ranging,
multimedia knowledge
base.
2.2
IMAGACT
IMAGACT
4
is a visual
ontology of
action that
provides
a
video-based translation and disam-
biguation framework for
general
verbs.
The
database evolves
continously (Moneglia et
al.,
2014b)
and at
present
contains 9 fully-mapped
languages and 13 which are underway.
The re-
source is built
on an ontology containing a fine-
3
http://babelnet.org
4
http://www.imagact.it
grained categorization of
action concepts,
each
represented by one or more video prototypes as
recorded scenes and 3D animations.
IMAGACT
currently contains
1,010 scenes
which encom-
pass the action concepts most commonly referred
to in everyday language usage
5
.
The links be-
tween verbs and video scenes are based on the co-
referentiality of different verbs with respect to the
action expressed by a scene (i.e.
different
verbs
can describe the same action,
visualised in the
scene).
The visual representations convey the ac-
tion information in a cross-linguistic environment
and IMAGACT may thus be exploited for
ref-
erence disambiguation in automatic and assisted
translation tasks (Panunzi et al., 2014).
3
Related works
Other attempts have previously been made to link
IMAGACT with other
resources.
Two experi-
ments by De Felice et
al.
(2014)
and by Bar-
tolini
et
al.
(2014) were conducted in an intra-
linguistic perspective:
their aim was to evaluate
the results of a mapping between the action con-
cepts defined in ItalWordNet and the ones catego-
rized by IMAGACT (in terms of perfect matches
or hypernym/hyponym relations).
On the contrary, the objective behind our work
is to obtain a light link between the resources by
enriching the action concepts in BabelNet with a
visual representation; in this way, we overpass the
problem of finding a match between the generic
semantic concepts in BabelNet
and the specific
pragmatic concepts in IMAGACT. This methodol-
ogy is also enforced by the multilingual frame in
which the experiment is conducted. As a matter of
fact, the relation between words and concepts can
deeply differ across languages, while the prototyp-
ical scenes ensure a language-independent modal-
ity which is able to keep together the different lex-
icalizations of the action space.
This work is a further
step from a previous
IMAGACT-BabelNet linking experiment (Gregori
et al., 2015). Even if it was just a feasibility test to
check the consistency of the linking, we reported
good results
in automatic assignment
of
IMA-
GACT prototypical
scenes to BabelNet
synsets.
For this reason,
we built a bigger dataset and we
went from a metric-based to a Machine Learning
algorithm to be run on the whole set of IMAGACT
5
The data is derived from the annotation of verb occur-
rences in spontaneous spoken corpora (Moneglia et al., 2012)
CLIC_2016_Proceedings.indd 163
02/12/16 15.03
164
scenes.
4
Linking experiment
The aim of this experiment
is to link the IMA-
GACT video scenes to the BabelNet interlinguis-
tic concepts (BabelSynsets).
In fact,
the Babel-
Net
objects are already enriched with visual
ob-
jects,
though this information contains static im-
ages which are inadequate for representing action
concepts.
In this way, adding video scenes to the
verbs is very desirable and would suggest itself as
a natural extension of BabelNet.
4.1
Training and test set
A manually annotated dataset of 50 scenes and 57
BabelSynsets (2,850 judgments) was created in or-
der to test the algorithm and evaluate the results.
The sampling was carried on in two steps.
First
of all, a purely actional semantic area has been se-
lected by taking BSs and scenes linked to 7 En-
glish action verbs, which are general and very fre-
quent in the language use: put, move, take, insert,
press, give and strike.
The wide variation of these
verbs allowed us to obtain a big set of concepts,
with a high variation in terms of frequency and
generality. On this set, a second sampling has been
performed by preserving the variability in terms of
number of connected verbs,
that is a measurable
parameter in both the resources.
Each

BS,Scene

pair
has been evaluated to
check if
the scene is
appropriate in represent-
ing the BS. Three annotators compiled the binary
judgment table and we reported the values shared
by at
least
2 of 3.
The measured Fleiss’ kappa
inter-rater agreement for this task was 0.74
6
.
Finally,
the dataset has been split in a training
set and a test set, with the proportions of 80% and
20% respectively (10 randomly chosen scenes for
the test
set
and the remaining 40 scenes for the
training set).
4.2
Algorithm
For this task, we developed a new algorithm which
uses Machine Learning techniques,
by exploiting
the training set.
As in the previous experiment,
the features are extracted from the lexical
items
belonging to both the candidate BabelSynset and
its neighbours
7
.
Beside the algorithm,
a baseline
6
The manually annotated training set
is
published at
http://bit.ly/29J0ypx
7
This test is based on BabelNet 3.6; the data was extracted
using the Java API (Navigli and Ponzetto, 2012b)
is determined by calculating the ratio
nsb
nb+ns
for
each pair and setting a threshold of 0.04, that max-
imizes the F-measure on our dataset.
Table 1 reports on the 17 languages common to
both BabelNet and IMAGACT, detailing the rela-
tive number of verbs in each,
and constitutes the
quantitative data which the matching algorithms
can exploit.
Language
BN Verbs
IM Verbs
English (EN)
29,738
1,299
Polish (PL)
9,660
1,193
Chinese (ZH)
9,507
1,171
Italian (IT)
7,184
1,100
Spanish (ES)
6,159
736
Russian (RU)
4,975
34
Portuguese (PT)
4,624
776
Arabic (AR)
3,738
804
German (DE)
3,754
992
Norwegian (NO)
1,729
115
Danish (DA)
1,685
646
Hebrew (HE)
1,647
160
Serbian (SR)
858
1,124
Hindi (HI)
831
466
Urdu (UR)
233
78
Sanskrit (SA)
33
276
Oriya (OR)
6
160
Total
86,361
11,130
Table 1:
The 17 shared languages of
Babel-
Net (BN) and IMAGACT (IM) with verbal lemma
counts.
The basic features that we used for this experi-
ment are:
•
ns
:
the number
of
verbs connected to the
Scene;
•
nb
: the number of verbs connected to the BS;
•
nsb
:
the number of verbs that are shared be-
tween the Scene and the BS;
These 3 features have been calculated for each
candidate BS and for the ones which are seman-
tically related to it.
We took the 8 BabelNet se-
mantic relations available for verbs (see table 2)
and for each BS we extracted 8 groups of related
synsets,
each one containing the set
of BS con-
nected to the main one by the same relation. Then,
ns
,
nb
and
nsb
are calculated for each group by
summing the values of the BSs belonging to it.
CLIC_2016_Proceedings.indd 164
02/12/16 15.03
165
The feature set is comprised of 27 features: 3 fea-
tures for the main BS and 3 features for each Ba-
belNet relation.
The set of candidates consists of
all the possible BSs for each verb connected to the
scene.
A machine learning algorithm was trained
on the annotated dataset:
we used Support Vector
Machine (SVM) classifier with a RBF kernel.
Table 2 shows the list of relations between the
verbal
BSs ranked by their relevance values for
this task; this value is measured with Information
Gain on the annotated dataset.
BabelNet relations
IG value
Hyponym
0.057
Hypernym
0.026
Also See
0.019
Verb Group
0.019
Gloss Related
0.009
Entailment
0.003
Antonym
0.000
Cause
0.000
Table 2:
Relations between verbal BSs.
4.3
Results
The algorithm was run on the training set and eval-
uated on the test set; the results are reported in Ta-
ble 3.
Baseline
th
= 0
.
04
ML Algorithm
27 features
Pr
0.580
0.833
Re
0.529
0.441
Fm
0.553
0.577
Table 3:
Precision, Recall and F-measure of BSs
to scenes linking task calculated on the test set for
the algorithm and the baseline.
The results in terms of F-measure are not so sat-
isfying and the value obtained with the algorithm
is barely better than the baseline.
Despite this, it’s
important to consider the difference with the base-
line in terms of precision and recall,
since preci-
sion is more important for this task:
for this rea-
son, the algorithm provides a much more reliable
result compared to the baseline.
We also have to
point out that a low recall is mainly caused by mul-
tiple possiblities in the interpretation of a scene
from different
points of view:
for example,
the
scene linked to the English verb to throw described
by the sentence John throws the ball to Mark can
represent not only a sense of throw, but also senses
of other verbs,
like to play or to catch,
that refer
to different semantic concepts; in these cases, the
scene in IMAGACT is not
linked to the alterna-
tive verbs,
but it can be described with them (i.e.
John and Mark play with the ball,
Mark catches
the ball).
For this reason,
the manual annotation
provides more BS-to-scene relations than an algo-
rithm can foresee on the basis of a lexical match,
causing a low recall value.
Table 4 reports some statistics about
the link-
ing process; the entire results are browsable at the
page http://bit.ly/2a4FefT.
IM Scenes linked to BS
773
BS linked to Scenes
517
IM English Verbs related to Scenes
544
BabelNet English Verbs related to BS
1,100
Table 4:
IMAGACT-BabelNet linking numbers
Switching to Machine Learning had a strong
impact on this linking task.
The main advantage
from the previous linking experiment (Gregori et
al., 2015) is that now the number of BSs that can
be assigned to each scene is variable,
depending
on the different reference possibilities that the BSs
have. This is coherent with the BabelNet structure
where we find very general concepts,
that can be
represented by several action prototypes, and spe-
cific ones,
for which one prototype is enough to
provide a clear representation.
For example the BS ”bn:00090224v” (Put into
a certain place or abstract location) expresses a
general concept and is linked to 72 scenes,
com-
prising the actions involving one or more objects
or a body part, relating to different ways of putting
(like inserting, throwing, attaching,...) or to differ-
ent states of the Theme (e.g. solid or liquid). Con-
versely, the BS ”bn:00084326v” (Fasten with but-
tons) is much more specific and is linked to only
one scene (c17d7346) that represents a man that
fastens his jacket.
5
Conclusions
The experiment described in this paper shows that
is possible to obtain an extensive linking between
IMAGACT and BabelNet
through visual
entities
(see Figure 1 for a visual representation of a link-
ing example);
this can be advantageous for both
the resources.
BabelNet
can add a clear
video
representation of the verbal
synsets that
refer to
CLIC_2016_Proceedings.indd 165
02/12/16 15.03
166
Figure 1: IMAGACT scene to BabelNet synset linking example
actions;
IMAGACT can import
verb translation
candidates from many languages by exploiting the
BabelNet semantic network; their integration can
be exploited as a unified multimedial resource to
accomplish complex tasks that
combine natural
language processing and computer vision.
Finally, we feel important to note that this pro-
cedure is scalable and the statistical model can be
retrained at resource changes. This is a fundamen-
tal feature,
especially considering the continuous
update of IMAGACT languages and lemmas in-
ventory.
Acknowledgments
This research has been supported by the MOD-
ELACT Project,
funded by the Futuro in Ricerca
2012 programme (Project
Code RBFR12C608);
http://modelact.lablita.it.
References
[Bartolini et al.2014]
Roberto
Bartolini,
Valeria
Quochi,
Irene De Felice,
Irene Russo,
and Mon-
ica Monachini.
2014.
From synsets to videos:
Enriching italwordnet
multimodally.
In Nicoletta
Calzolari
(Conference
Chair),
Khalid
Choukri,
Thierry Declerck, Hrafn Loftsson, Bente Maegaard,
Joseph Mariani,
Asuncion Moreno,
Jan Odijk,
and
Stelios Piperidis,
editors,
Proceedings of the Ninth
International
Conference on Language Resources
and Evaluation (LREC’14),
Reykjavik,
Iceland,
may.
European Language Resources
Association
(ELRA).
[Castano et al.2008]
S. Castano, A. Ferrara, D. Lorusso,
and S. Montanelli.
2008.
On the ontology instance
matching problem.
In Database and Expert
Sys-
tems Application,
2008.
DEXA ’08.
19th Interna-
tional Workshop on, pages 180–184, Sept.
[De Felice et al.2014]
Irene De Felice,
Roberto Bar-
tolini,
Irene
Russo,
Valeria
Quochi,
and Mon-
ica
Monachini.
2014.
Evaluating
ImagAct-
WordNet
mapping for English and Italian through
videos.
In Roberto Basili,
Alessandro Lenci,
and
Bernardo Magnini, editors, Proceedings of the First
Italian Conference on Computational
Linguistics
CLiC-it 2014 & the Fourth International Workshop
EVALITA 2014, volume I, pages 128–131. Pisa Uni-
versity Press.
[Gregori et al.2015]
Lorenzo Gregori,
Andrea Amelio
Ravelli,
and Alessandro Panunzi.
2015.
Linking
dei contenuti multimediali tra ontologie multilingui:
i verbi di azione tra imagact e babelnet.
In C. Bosco,
F.M.
Zanzotto,
and S.
Tonelli,
editors,
Proceed-
ings of
the Second Italian Conference on Compu-
tational
Linguistics CLiC-it
2015,
pages 150–154.
Accademia University Press.
[Mathe et al.2008]
S.
Mathe,
A.
Fazly,
S.
Dickinson,
and S.
Stevenson.
2008.
Learning the abstract
motion semantics of verbs from captioned videos.
In Computer Vision and Pattern Recognition Work-
shops,
2008.
CVPRW ’08.
IEEE Computer Society
Conference on, pages 1–8, June.
[Moneglia et al.2012]
Massimo
Moneglia,
Francesca
Frontini, Gloria Gagliardi, Irene Russo, Alessandro
CLIC_2016_Proceedings.indd 166
02/12/16 15.03
167
Panunzi,
and Monica Monachini.
2012.
Imagact:
deriving an action ontology from spoken corpora.
Proceedings of the Eighth Joint ACL-ISO Workshop
on Interoperable Semantic Annotation (isa-8), pages
42–47.
[Moneglia et al.2014a]
Massimo
Moneglia,
Susan
Brown,
Francesca
Frontini,
Gloria
Gagliardi,
Fahad Khan,
Monica Monachini,
and Alessandro
Panunzi.
2014a.
The IMAGACT Visual Ontology.
An Extendable Multilingual
Infrastructure for
the
Representation of Lexical Encoding of Action.
In
Nicoletta
Calzolari
(Conference
Chair),
Khalid
Choukri,
Thierry Declerck,
Hrafn Loftsson,
Bente
Maegaard,
Joseph Mariani,
Asuncion Moreno,
Jan
Odijk,
and Stelios Piperidis,
editors,
Proceedings
of the Ninth International Conference on Language
Resources and Evaluation (LREC’14),
Reykjavik,
Iceland,
May.
European
Language
Resources
Association (ELRA).
[Moneglia et al.2014b]
Massimo
Moneglia,
Susan
Brown, Aniruddha Kar, Anand Kumar, Atul Kumar
Ojha,
Heliana Mello,
Niharika,
Girish Nath Jha,
Bhaskar Ray,
and Annu Sharma.
2014b.
Mapping
Indian Languages onto the IMAGACT Visual
On-
tology of Action.
In Girish Nath Jha,
Kalika Bali,
Sobha L,
and Esha Banerjee,
editors,
Proceedings
of WILDRE2 - 2nd Workshop on Indian Language
Data:
Resources
and
Evaluation at
LREC’14,
Reykjavik,
Iceland,
May.
European
Language
Resources Association (ELRA).
[Moneglia2014]
Massimo Moneglia.
2014.
Natural
Language Ontology of Action:
A Gap with Huge
Consequences for Natural Language Understanding
and Machine Translation.
In Zygmunt Vetulani and
Joseph Mariani, editors, Human Language Technol-
ogy Challenges for Computer Science and Linguis-
tics, volume 8387 of Lecture Notes in Computer Sci-
ence,
pages 379–395.
Springer
International
Pub-
lishing.
[Moro and Navigli2015]
Andrea
Moro
and
Roberto
Navigli.
2015.
SemEval-2015 Task 13:
Multilin-
gual
All-Words Sense Disambiguation and Entity
Linking.
In Proceedings of
the 9th International
Workshop on Semantic Evaluation (SemEval 2015),
pages 288–297,
Denver,
Colorado,
June.
Associa-
tion for Computational Linguistics.
[Nath et al.2014]
Rudra
Nath,
Hanif
Seddiqui,
and
Masaki Aono.
2014.
An efficient and scalable ap-
proach for ontology instance matching.
Journal of
Computers, 9(8).
[Navigli and Ponzetto2012a]
Roberto Navigli
and Si-
mone Paolo Ponzetto.
2012a.
BabelNet:
The au-
tomatic construction, evaluation and application of a
wide-coverage multilingual semantic network.
Arti-
ficial Intelligence, 193:217–250.
[Navigli and Ponzetto2012b]
Roberto Navigli
and Si-
mone Paolo Ponzetto.
2012b.
Multilingual
WSD
with just a few lines of code:
the BabelNet API.
In
Proceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2012),
Jeju, Korea.
[Otero-Cerdeira et al.2015]
Lorena
Otero-Cerdeira,
Francisco J.
Rodrguez-Martnez,
and Alma Gmez-
Rodrguez.
2015.
Ontology matching:
A literature
review.
Expert Systems with Applications, 42(2):949
– 971.
[Panunzi et al.2014]
Alessandro Panunzi,
Irene De Fe-
lice,
Lorenzo Gregori,
Stefano Jacoviello,
Monica
Monachini, Massimo Moneglia, Valeria Quochi, and
Irene Russo.
2014.
Translating Action Verbs us-
ing a Dictionary of Images:
the IMAGACT Ontol-
ogy.
In XVI EURALEX International Congress: The
User in Focus, pages 1163–1170, Bolzano / Bozen,
7/2014. EURALEX 2014, EURALEX 2014.
[Regneri et al.2013]
Michaela
Regneri,
Marcus
Rohrbach,
Dominikus Wetzel,
Stefan Thater,
Bernt
Schiele,
and Manfred Pinkal.
2013.
Grounding
action descriptions
in videos.
Transactions
of
the
Association
for
Computational
Linguistics,
1:25–36.
[Russo et al.2013]
Irene
Russo,
Francesca
Frontini,
Irene De Felice,
Fahad Khan,
and Monica Mona-
chini.
2013.
Disambiguation of Basic Action Types
through Nouns
Telic Qualia.
In Roser Saur, Nico-
letta Calzolari,
Chu-Ren Huang,
Alessandro Lenci,
Monica Monachini, and James Pustejovsky, editors,
Proceedings of the 6th International Conference on
Generative Approaches to the Lexicon.
Generative
Lexicon and Distributional Semantics, pages 70–75.
[Siemoneit et al.2015]
Benjamin
Siemoneit,
John Philip McCrae,
and Philipp Cimiano.
2015.
Linking four heterogeneous language resources as
linked data.
In Proceedings of
the 4th Workshop
on Linked Data in Linguistics:
Resources
and
Applications,
pages
59–63,
Beijing,
China,
July.
Association for Computational Linguistics.
CLIC_2016_Proceedings.indd 167
02/12/16 15.03
168
Sentiment Analysis: applicazione in un dominio psico-forense
Francesca Guglielmi
1
and Pierpaolo Basile
2
and Antonietta Curci
1
and Giovanni Semeraro
2
1
Dipartimento di Scienze della Formazione, Psicologia, Comunicazione, Universit
`
a di Bari Aldo Moro
2
Dipartimento di Informatica, Universit
`
a di Bari Aldo Moro
1
{
francesca.guglielmi,antonietta.curci
}
@uniba.it
2
{
pierpaolo.basile,giovanni.semeraro
}
@uniba.it
Abstract
English. This study aims to apply the sen-
timent analysis to a psycho-forensic con-
text through the analysis of narrative trans-
criptions related to the crimes committed
by violent
detainees.
We investigate the
presence of psychopathy through the Psy-
chopathic Personality Inventory-Revised
(PPI-R).
Psychopathy is a personality di-
sorder that
is characterized by emotional
detachment,
the lack of empathy and it is
often found in the prison population for
the brutality of
committed crimes.
Our
study explores possible associations bet-
ween psychopathy and emotional content
present in the narratives.
Results show a
neutral polarity for both psychopathic and
not
psychopaths offenders,
however it
is
possible to identify significant
emotional
characteristics that diversify the narrative
transcriptions.
Italiano.
Il presente studio ha l’obiettivo
di
applicare la sentiment
analysis ad un
contesto psico-forense attraverso l’anali-
si di resoconti narrativi relativi ai crimini
commessi da detenuti,
autori di reati vio-
lenti. Attraverso lo strumento Psycopathic
Personality Inventory-Revised (PPI-R),
`
e
stata indagata la presenza di
psicopatia,
disturbo di personalit
`
a che si caratterizza
per il distacco emotivo, l’assenza di empa-
tia e lo stile di vita antisociale riscontra-
bile nella popolazione carceraria per l’ef-
feratezza dei crimini commessi,
al fine di
esplorare eventuali associazioni tra il di-
sturbo e i contenuti emotivi presenti nelle
narrazioni.
Dai
risultati emerge un tono
affettivo neutro sia per gli offender psico-
patici
sia per gli
offender non psicopati-
ci, tuttavia
`
e possibile individuare peculia-
rit
`
a emotive significative che diversificano
i resoconti narrativi.
1
Introduzione
La psicopatia
`
e un disturbo di personalit
`
a caratte-
rizzato da deficit
emotivi,
stile di
vita antisocia-
le, mancanza di senso di colpa ed empatia.
Negli
psicopatici la coloritura affettiva che generalmen-
te serve a differenziare gli eventi emotivi da quel-
li neutri non esiste nella stessa misura degli altri
individui (Cleckley, 1941).
Gli
psicopatici
hanno
un’attenuata
risposta
emotiva agli eventi di cui fanno esperienza e nei
confronti
delle persone con cui
interagiscono.
I
tratti caratterizzanti la psicopatia, si riscontrano in
alcuni offender detenuti (Serin, 1996), proprio per
le peculiarit
`
a relative alla violenza degli atti espe-
riti
da queste persone (Yang et
al.,
2010).
Inol-
tre,
la callosit
`
a emotiva,
tratto caratterizzante il
disturbo,
pare possa essere associata ad una per-
cezione minimizzata dell’esperienza emotiva (po-
sitiva o negativa) dell’evento vissuto,
relativa sia
al momento in cui si
`
e verificato sia al richiamo
dell’evento stesso (Osumi and Ohira, 2010).
L’incapacit
`
a nell’elaborare e nel fare esperienza
del contenuto affettivo degli stimoli e degli even-
ti
pu
`
o avere delle conseguenze sulle capacit
`
a di
memoria e quindi sulla possibilit
`
a di elaborare e
di
recuperare l’informazione emotiva relativa al-
l’evento esperito.
Evidenze empiriche (Burrow et
al., 2014) sostengono che le persone psicopatiche
soffrono di
un deficit
emotivo che pu
`
o avere un
impatto sul loro modo di percepire il ricordo de-
gli eventi.
Alcuni clinici e ricercatori sostengono
CLIC_2016_Proceedings.indd 168
02/12/16 15.03
169
che gli psicopatici generalmente non sono in gra-
do di apprendere il significato emotivo degli even-
ti;
pertanto si ipotizza che i racconti degli offen-
der psicopatici siano scarni di dettagli emotivi ri-
spetto alle narrazioni degli offender non psicopati-
ci (Glass and Newman, 2006; Wilson et al., 2008;
Christianson et al., 1996)
La ricerca in questi
ambiti
necessita di
essere
implementata, infatti negli ultimi anni la ricerca di
base in psicologia cognitiva si
`
e ampliata median-
te l’adattamento delle procedure,
delle variabili e
il coinvolgimento di altri domini scientifici, tra cui
la psicolinguistica.
Tali
adattamenti
consentono
di allargare le conoscenze sulle caratteristiche di
personalit
`
a e le loro influenze sui comportamenti
in contesti diversificati, come quello penitenziario,
per rendere fruibile la messa in atto di programmi
di intervento mirati e adatti a supportare persone
con tali disturbi.
Il presente studio
`
e il risultato di
queste integrazioni di domini concettuali e di ri-
cerca, nella fattispecie si applica la sentiment ana-
lysis, una metodologia per l’elaborazione automa-
tica del testo al fine di estrarre informazioni sog-
gettive in un contesto psico-forense.
A 48 offen-
der detenuti,
autori di reati violenti,
`
e stato chie-
sto, attraverso un compito di free-recall, di narrare
il ricordo autobiografico relativo all’evento crimi-
noso commesso per il quale sono stati condannati,
tale ricordo
`
e stato trascritto dagli
sperimentato-
ri simultaneamente alla narrazione.
Inoltre, a cia-
scun partecipante
`
e stato somministrato il Psycho-
patic Personality Inventory-Revised (PPI-R) (Li-
lienfeld and Widows, 2005) per analizzare la pre-
senza di psicopatia. Ciascun resoconto narrativo
`
e
stato successivamente analizzato con la metodolo-
gia della sentiment analysis attraverso un algorit-
mo descritto in dettaglio nel paragrafo 2. I risultati
di questa analisi sono riportati nel paragrafo 3.
2
Metodologia
La metodologia da noi
proposta si
compone di
cinque distinte fasi:
1.
reperimento dei
resoconti
narrativi.
Ad un
campione composto da 48 uomini (
M
et`
a
=
38
,
69
;
Ds
= 8
,
5
) autori
di
reati
violenti,
detenuti presso l’Istituto penitenziario di Turi
(BA) e la Casa circondariale di Trani (BA)
`
e
stato chiesto di narrare, attraverso un compito
di free-recall, il ricordo autobiografico relati-
vo al crimine per il quale sono stati condan-
nati.
Le narrazioni sono state trascritte dagli
sperimentatori in simultanea;
2.
rilevazione della presenza/assenza di
psico-
patia misurata attraverso il PPI-R (Lilienfeld
and Widows, 2005) che valuta i tratti di per-
sonalit
`
a del soggetto attraverso l’indagine di
quei
comportamenti
e peculiarit
`
a cognitive,
emotive e percettive che costituiscono i tratti
tipici della psicopatia.
Il test
`
e composto da
154 item,
da cui si ricavano 8 scale di con-
tenuto,
aggregate in 3 fattori
sovraordinati:
Dominanza priva di
paura,
Impulsivit
`
a au-
to centrata e Freddezza emotiva.
Ogni item
prevede 4 alternative di risposta (vero, abba-
stanza vero, abbastanza falso, falso). Le som-
ministrazioni si sono tenute previa autorizza-
zione del P.R.A.P. della Regione Puglia e pre-
via autorizzazione individuale all’uso dei da-
ti personali nei limiti stabiliti dalla legge.
Le
somministrazioni si sono svolte in una cella
protetta, alla presenza di due somministratori
e una guardia penitenziaria;
3.
elaborazione
dei
resoconti
narrativi,
co-
me descritto nel
paragrafo 2.1,
per
l’estra-
zione automatica di
attributi
emotivi
e di
sentimento;
4.
analisi
dei
risultati
per
l’individuazione di
una correlazione tra i
punteggi
del
PPI-R e
gli attributi estratti dall’analisi automatica del
testo;
5.
analisi degli attributi estratti dall’elaborazio-
ne del
testo con tecniche di
apprendimento
automatico.
La metodologia proposta ha l’obiettivo di veri-
ficare se l’analisi automatica del testo pu
`
o rilevare
alcune caratteristiche emozionali o di sentimento
associabili alla psicopatia nei detenuti che hanno
commesso crimini particolarmente violenti.
2.1
Elaborazione del testo
Ogni trascrizione
`
e stata processata da una pipe-
line di strumenti per l’analisi automatica del lin-
guaggio per la lingua italiana.
In particolare, ogni
trascrizione
`
e sottoposta alle seguenti operazioni:
1.
Tokenizzazione e PoS-tagging:
il
testo
`
e
suddiviso in token (parole)
e ad ogni
to-
ken
`
e associato un tag che identifica la par-
te del discorso (sostantivo,
aggettivo,
verbo,
avverbio,
preposizione,
articolo,
...).
Queste
operazioni
sono realizzate attraverso il
tool
CLIC_2016_Proceedings.indd 169
02/12/16 15.03
170
open-source Apache OpenNLP
1
;
2.
Lemmatizzazione:
sfruttando le informa-
zioni
sul
PoS-tag,
riconduce ogni
parola al
suo lemma.
Questa operazione
`
e necessa-
ria per poter accedere a dizionari
elettroni-
ci,
ad esempio quelli
utilizzati
nelle opera-
zioni
successive per l’analisi
del
sentiment.
L’operazione
`
e stata realizzata attraverso l’u-
tilizzo della
risorsa
linguistica
Morph-it!
2
(Zanchetta and Baroni, 2005);
3.
Analisi
del
sentiment:
l’analisi
del
senti-
ment prevede l’associazione di uno score di
polarit
`
a ad ogni parola presente nella trascri-
zione, ed il calcolo di uno score di sentiment
sull’intera trascrizione. Lo score di sentiment
sull’intera trascrizione
`
e calcolato seguendo
due differenti approcci: 1) come media degli
score di
sentiment
associati
ad ogni
parola;
2) come differenza tra gli
score massimi
di
polarit
`
a positiva e negativa.
Questo processo
`
e realizzato utilizzando la risorsa linguistica
Sentix (Basile and Nissim, 2013).
Inoltre, la
polarit
`
a dei termini
`
e invertita se compaiono
in un contesto di
negazione.
Il
contesto di
negazione
`
e individuato dalla parola “non” e
si estende fino all’individuazione di uno dei
seguenti caratteri
{
.
:; !?
}
;
4.
Analisi
delle emozioni:
ad ogni
parola so-
no associate delle etichette emotive utiliz-
zando la risorsa linguistica WordNet-Affect
(Strapparava and Valitutti, 2004).
L’analisi
del
sentiment
e quella delle emozio-
ni necessitano di maggiori dettagli implementati-
vi.
Poich
´
e le risorse linguistiche utilizzate sono
dei dizionari basati sul significato si rende neces-
saria una strategia per poter accedere a questi di-
zionari attraverso il lemma.
Un lemma pu
`
o ave-
re pi
`
u significati; nel caso di lemma polisemico si
`
e scelto il significato pi
`
u frequente.
La frequen-
za dei
significati
per la lingua italiana
`
e calcola-
ta utilizzando la risorsa MultiSemCor (Bentivogli
and Pianta,
2005).
Lo stesso procedimento viene
applicato a WordNet-Affect in presenza di lemmi
polisemici.
2.2
Analisi con approcci di apprendimento
automatico
Al fine di analizzare l’associazione tra gli attribu-
ti linguistici e la psicopatia, abbiamo formalizzato
1
https://opennlp.apache.org/
2
http://sslmitdev-online.sslmit.unibo.
it/linguistics/morph-it.php
un problema di apprendimento di tipo binario in
cui ogni racconto
`
e classificato come psicopatico
o non psicopatico in base ai
risultati
del
PPI-R.
Ogni racconto
`
e descritto da una serie di attributi:
polarit
`
a media,
score massimo di
polarit
`
a positi-
va, score massimo di polarit
`
a negativa, differenza
tra gli score massimi di polarit
`
a e,
per ogni clas-
se emotiva prevista da WordNet-Affect, numero di
parole che ricadono in tale classe.
Lo scopo di questa analisi non
`
e quello di mi-
surare la bont
`
a predittiva degli attributi estratti dal
testo, ma di capire il potere discriminante di ogni
attributo. Per questo motivo si
`
e scelto l’algoritmo
C4.5 (Quinlan,
1993) basato sugli alberi di deci-
sione.
In particolare l’algoritmo genera un albe-
ro di decisione basandosi sul concetto di entropia
dell’informazione.
Ad ogni nodo dell’albero, l’algoritmo C4.5 sce-
glie l’attributo che divide pi
`
u efficacemente i dati
in una o nell’altra classe.
Il criterio di suddivisio-
ne
`
e il guadagno d’informazione (differenza di en-
tropia).
L’attributo con il pi
`
u alto guadagno d’in-
formazione viene scelto per prendere la decisione.
L’algoritmo C4.5 viene applicato in maniera ricor-
siva ai nuovi sottoinsiemi di dati che si vengano a
creare ad ogni passo.
L’idea
`
e che l’albero di
decisione possa dar-
ci
un’indicazione di
quali
siano gli
attributi
pi
`
u
discriminanti
per
l’individuazione
dei
racconti
appartenenti a soggetti affetti da psicopatia.
3
Analisi sperimentale
Il punteggio totale di psicopatia, che ha consentito
la discriminazione dei due gruppi: offender psico-
patici (n.
20) e offender non psicopatici (n.
28),
`
e stato calcolato attraverso moduli di autoscoring
sommando, per ciascun soggetto, i punteggi otte-
nuti nei tre fattori (Dominanza priva di paura, Im-
pulsivit
`
a auto centrata e Freddezza emotiva).
Ta-
le punteggio grezzo
`
e stato poi convertito in punti
t
,
quindi
standardizzato.
Attraverso il
t-test,
te-
st statistico parametrico che permette di verificare
se il
valore medio di
una distribuzione si
disco-
sta significativamente da un certo valore di
rife-
rimento ad un livello di significativit
`
a inferiore a
0,05, emerge che sia i punteggi totali di Psicopatia
(
t
(46)
=
−
9
,
86
),
sia dei
tre fattori:
Dominan-
za priva di paura (
t
(46) =
−
8
,
24
);
Impulsitvit
`
a
autocentrata (
t
(46) =
−
9
,
86
) e Freddezza emo-
tiva (
t
(46)
−
8
,
24
) hanno delle differenze signifi-
cative con valori di p
<
0,05.
Questo risultato la-
CLIC_2016_Proceedings.indd 170
02/12/16 15.03
171
Tabella 1:
Correlazione di Pearson tra gli indicatori della Sentiment Analysis e i fattori del PPI-R nel
gruppo di offender psicopatici (n = 20). (*) p
<
0.05
Sentiment
Analysis
Psicopatia: PPI-R
Polarit
`
a
Impulsivit
`
a
autocentrata
Dominanza
priva di paura
Freddezza
emotiva
Psicopatia
totale
M
pol
-0,260
0,103
0,097
-0,095
Max
pos
-0,006
0,507*
0,335
0,305
Max
neg
-0,116
0,104
-0,121
-0,054
Max
pos
−
Max
neg
0,069
0,291
0.311
0,249
scia ragionevolmente supporre che i due gruppi si
differenziano per i tratti caratterizzanti la psicopa-
tia relativi allo stile di vita antisociale, la callosita
emotiva e le caratteristiche legate alla mancanza di
paura, gestione dello stress e influenza sociale.
Successivamente, i resoconti narrativi sono sta-
ti
analizzati
mediante tecniche di
elaborazione
del linguaggio naturale al fine di estrarre attribu-
ti
emotivi
e di
polarit
`
a del
sentimento (positiva,
negativa e neutra).
Gli attributi cos
`
ı estratti sono
stati utilizzati per impostare il problema di appren-
dimento automatico descritto nel
paragrafo 2.2.
Per
realizzare ci
`
o
`
e stata utilizzata l’implemen-
tazione J48 dell’algoritmo C4.5 presente nel tool
open-source Weka
3
(Hall et al., 2009).
3.1
Risultati
Per analizzare l’associazione tra psicopatia e pun-
teggi ottenuti negli score della Sentiment Analysis
abbiamo utilizzato analisi correlazionali attraver-
so le quali
`
e emersa una correlazione significativa
tra
Max
pos
e il fattore Dominanza priva di pau-
ra del PPI (Tabella 1) nel gruppo composto da of-
fender psicopatici.
Questo risultato sembra soste-
nere l’ipotesi che la freddezza emotiva dello psi-
copatico predisponga ad una ricerca attiva di tut-
te quelle situazioni e sensazioni forti ed eccitanti
che possano in qualche modo indurre uno stato di
eccitazione in loro (Herv
´
e et
al.,
2007),
come il
commettere i
crimini
violenti
di
cui
si
sono resi
protagonisti e la loro la tendenza a correre rischi
(Ellis,
1987).
Al contrario nel gruppo composto
da offender non psicopatici non
`
e emersa alcuna
correlazione significativa.
Per quanto riguarda l’output fornitoci dall’albe-
ro di decisione,
si evince che la differenza di po-
larit
`
a
`
e l’attributo pi
`
u discriminante,
in grado di
riconoscere da solo quasi
il
50% degli
individui
3
http://www.cs.waikato.ac.nz/ml/weka/
affetti
da psicopatia.
Ancora pi
`
u interessante
`
e
il
valore per il
quale avviene la suddivisione del
campione.
In particolare, se la differenza di pola-
rit
`
a
`
e maggiore di -0,125, l’individuo viene classi-
ficato come affetto da psicopatia.
Questo risultato
`
e molto rilevante in quanto la differenza di pola-
rit
`
a nel campione assume valori nell’intervallo [-
0,625;
0,25].
Questo significa che le narrazioni
neutre, che hanno una differenza vicina allo zero,
risultano scritte da soggetti affetti da psicopatia, in
linea con l’ipotesi che gli psicopatici abbiano un
ricordo povero di
dettagli
emotivi
che lascia ra-
gionevolmente presupporre un’attenuata risposta
emozionale agli eventi.
`
E anche importante sottolineare come la pola-
rit
`
a sia sbilanciata verso la negativit
`
a.
Ci
`
o sug-
gerisce che, in assenza di psicopatia, il tipo di ri-
cordo associato all’evento criminoso risulta essere
negativo.
Continuando ad analizzare l’albero di
decisione si scopre che i nodi successivi si basano
sugli attributi di polarit
`
a massima positiva e nega-
tiva, e solo uno dei nodi fa riferimento all’etichetta
“piacere” di WordNetAffect.
4
Conclusioni
In questo lavoro abbiamo cercato di capire se i ri-
sultati prodotti da un algoritmo di sentiment analy-
sis possano in qualche modo essere associati alla
psicopatia.
In particolare,
abbiamo analizzato la
presenza di
psicopatia,
in un campione di
offen-
der detenuti
poich
`
e i
tratti
caratterizzanti
di
tale
disturbo,
distacco emotivo,
mancanza di senso di
colpa,
stile di vita antisociale,
`
e possibile riscon-
trarli negli offender detenuti per le peculiarit
`
a re-
lative alla violenza degli atti esperiti e allo stile di
vita condotto.
I risultati
ottenuti
dalla sentiment
analysis so-
no stati confrontati con quelli ottenuti attraverso il
test PPI-R che valuta i tratti di personalit
`
a del sog-
CLIC_2016_Proceedings.indd 171
02/12/16 15.03
172
getto attraverso l’indagine di quei comportamen-
ti e peculiarit
`
a cognitive, emotive e percettive che
costituiscono i tratti tipici della psicopatia.
I risultati ottenuti attraverso l’utilizzo di un ap-
proccio basato sull’induzione di alberi di decisio-
ne dimostrano una dipendenza tra la presenza di
psicopatia e la differenza tra la massima polarit
`
a
positiva e quella negativa individuate nella nar-
razione del
detenuto.
Inoltre,
`
e stata riscontrata
una correlazione tra lo score massimo di polarit
`
a
e il
fattore Dominanza priva di
paura attraverso
l’utilizzo di test statistici.
I risultati
ottenuti
sono incoraggianti
e dimo-
strano l’efficacia di ampliare la ricerca di base in
psicologia cognitiva con strumenti innovativi co-
me quello della sentiment analysis e in genere del-
l’analisi automatica del testo.
Lo studio qui ripor-
tato, seppur rilevante,
`
e comunque da considerarsi
preliminare per due ragioni: la ridotta dimensione
del
campione e l’utilizzo di
tecniche abbastanza
semplici per l’analisi del sentiment.
Acknowledgement
Questo
lavoro
`
e
parzialmente
supportato
dal
progetto “Multilingual
Entity Liking” finanzia-
to
dalla
Regione
Puglia
con
il
programma
FutureInResearch.
References
Valerio Basile and Malvina Nissim.
2013.
Sentiment
analysis on Italian tweets.
In Proceedings of the 4th
Workshop on Computational Approaches to Subjec-
tivity,
Sentiment and Social Media Analysis,
pages
100–107, Atlanta.
Luisa Bentivogli
and Emanuele Pianta.
2005.
Ex-
ploiting parallel
texts in the creation of
multilin-
gual
semantically annotated resources:
the Multi-
SemCor Corpus.
Natural
Language Engineering,
11(03):247–261.
Ashley N Burrow,
Nichole Currence,
Diana Lemus,
Amber E DeBono, Matthew T Crawford, and W Ri-
chard Walker.
2014.
Psychopaths view autobiogra-
phical memories as less memorable, important, and
emotional
than normal
individuals.
International
Journal of Humanities and Social Science, 4:1–9.
Sven-
˚
Ake Christianson, Adelle E Forth, Robert D Ha-
re,
Catherine Strachan,
Lars
Lidberg,
and Lars-
H
˚
akan Thorell.
1996.
Remembering details of
emotional
events:
A comparison between psycho-
pathic and nonpsychopathic offenders.
Personality
and Individual Differences, 20(4):437–443.
H Cleckley.
1941.
The mask of sanity. st. louis.
MO:
Mosby.
Lee Ellis.
1987.
Relationships of criminality and psy-
chopathy with eight other apparent behavioral ma-
nifestations of sub-optimal arousal.
Personality and
Individual Differences, 8(6):905–925.
Samantha J Glass and Joseph P Newman.
2006.
Re-
cognition of facial affect in psychopathic offenders.
Journal of abnormal psychology, 115(4):815.
Mark Hall,
Eibe Frank,
Geoffrey Holmes,
Bernhard
Pfahringer,
Peter
Reutemann,
and Ian H Witten.
2009.
The
WEKA data
mining software:
an
update.
ACM SIGKDD explorations
newsletter,
11(1):10–18.
Hugues Herv
´
e,
Barry S Cooper,
and JOHN C Yuille.
2007.
Memory formation in offenders:
Perspecti-
ves from a biopsychosocial model of eyewitness me-
mory.
Offenders’ memories of violent crimes, pages
38–74.
Scott
O Lilienfeld and Michelle R Widows.
2005.
PPI-R: Psychopathic personality inventory revised:
Professional
Manual.
Psychological
Assessment
Resources, Incorporated.
Takahiro Osumi
and Hideki
Ohira.
2010.
The
positive side of
psychopathy:
Emotional
detach-
ment
in psychopathy and rational
decision-making
in the ultimatum game.
Personality and individual
differences, 49(5):451–456.
J Ross Quinlan.
1993.
C4. 5:
programs for machine
learning.
Morgan Kaufmann Publishers.
Ralph C Serin.
1996.
Violent recidivism in criminal
psychopaths.
Law and Human Behavior, 20(2):207.
Carlo Strapparava and Alessandro Valitutti.
2004.
WordNet
Affect:
an
Affective
Extension
of
WordNet.
In LREC, volume 4, pages 1083–1086.
Kevin Wilson,
Sabrina Demetrioff,
and Stephen Por-
ter.
2008.
A pawn by any other
name?
so-
cial
information processing as a function of
psy-
chopathic traits.
Journal of research in personality,
42(6):1651–1656.
Yaling Yang, Adrian Raine, Patrick Colletti, Arthur W
Toga,
and Katherine L Narr.
2010.
Morphological
alterations in the prefrontal cortex and the amygdala
in unsuccessful psychopaths.
Journal of abnormal
psychology, 119(3):546.
Eros Zanchetta and Marco Baroni.
2005.
Morph-it!
A free corpus-based morphological resource for the
Italian language.
Corpus Linguistics 2005, 1(1).
CLIC_2016_Proceedings.indd 172
02/12/16 15.03
173
Comparing State-of-the-art Dependency Parsers
on the Italian Stanford Dependency Treebank
Alberto Lavelli
FBK-irst
via Sommarive, 18 - Povo
I-38123 Trento (TN) - ITALY
lavelli@fbk.eu
Abstract
English.
In the last
decade,
many accu-
rate dependency parsers have been made
publicly available.
It
can be difficult
for
non-experts to select a good off-the-shelf
parser among those available. This is even
more true when working on languages dif-
ferent from English, because parsers have
been tested mainly on English treebanks.
Our analysis is focused on Italian and re-
lies on the Italian Stanford Dependency
Treebank (ISDT).
This work is a contri-
bution to help non-experts understand how
difficult
it
is to apply a specific depen-
dency parser to a new language/treebank
and choose a parser that meets their needs.
Italiano.
Nell’ultimo decennio sono stati
resi disponibili molti analizzatori sintattici
a dipendenza.
Per i
non esperti
pu
`
o es-
sere difficile sceglierne uno pronto all’uso
tra quelli disponibili.
A maggior ragione
se si lavora su lingue diverse dall’inglese,
perch
´
e gli
analizzatori
sono stati
appli-
cati
soprattutto su treebank inglesi.
La
nostra analisi
`
e dedicata all’italiano e
si
basa sull’Italian Stanford Dependency
Treebank (ISDT).
Questo articolo
`
e un
contributo per
aiutare
i
non esperti
a
capire quanto
`
e difficile applicare un anal-
izzatore a una nuova lingua/treebank e a
scegliere quello pi
`
u adatto.
1
Introduction
In the last decade, there has been an increasing in-
terest in dependency parsing, witnessed by the or-
ganisation of various shared tasks,
e.g.
Buchholz
and Marsi (2006), Nivre et al. (2007), Seddah et al.
(2013),
Seddah et al. (2014).
Concerning Italian,
there have been tasks on dependency parsing in
the first four editions of the EVALITA evaluation
campaign (Bosco et al., 2008; Bosco et al., 2009;
Bosco and Mazzei,
2011; Bosco et al.,
2014).
In
the 2014 edition,
the task on dependency parsing
exploited the Italian Stanford Dependency Tree-
bank (ISDT),
a treebank featuring an annotation
based on Stanford Dependencies (de Marneffe and
Manning, 2008).
This paper
is a follow-up of
Lavelli
(2014b)
and reports
the experience in applying an up-
dated list
of
state-of-the-art
dependency parsers
on ISDT.
It
can be difficult
for
non-experts to
select
a good off-the-shelf
parser
among those
available.
This is even more true when working
on languages different
from English,
given that
parsers have been tested mainly on English tree-
banks (and in particular on the WSJ portion of
the PennTreebank).
This work is a contribution to
help practitioners understand how difficult it is to
apply a specific dependency parser to a new lan-
guage/treebank and choose a parser to optimize
their desired speed/accuracy trade-off.
As in many other NLP fields, there are very few
comparative articles where different parsers are di-
rectly run by the authors and their performance
compared (Daelemans and Hoste,
2002; Hoste et
al., 2002; Daelemans et al., 2003). Most of the pa-
pers simply present the results of a newly proposed
approach and compare them with the results re-
ported in previous articles.
In other cases, the pa-
pers are devoted to the application of the same tool
to different languages/treebanks. A notable excep-
tion is the study reported in Choi
et
al.
(2015),
where the authors present a comparative analysis
of ten leading statistical dependency parsers on a
multi-genre corpus of English.
It is important to stress that the comparison pre-
sented in this paper concerns tools used more or
less out of the box and that the results cannot be
used to compare specific characteristics like: pars-
ing algorithms, learning systems, . . .
CLIC_2016_Proceedings.indd 173
02/12/16 15.03
174
2
Parsers
The
choice
of
the
parsers
used in this
study
started from the ones already applied in a previous
study (Lavelli, 2014b), i.e.
MaltParser, the MATE
dependency parsers,
TurboParser,
and ZPar.
We
then identified a few other
freely available de-
pendency parsers
that
have shown state-of-the-
art
performance.
Some of
such parsers are in-
cluded in the study in Choi et al. (2015) and oth-
ers have been made publicly available more re-
cently.
The additional parsers included in this pa-
per are DeSR,
the Stanford Neural
Network de-
pendency parser, EmoryNLP, RBG, YARA Parser,
and LSTM parser.
Differently from what was done in the previous
study,
this time we have not included approaches
based on combination of parsers’ results,
such as
ensemble or stacking. They usually obtain top per-
formance (see e.g.
Attardi
and Simi
(2014) at
EVALITA 2014) but in this case we focus on sim-
plicity and ease of use rather than on absolute per-
formance.
Below you may find short descriptions
of the parsers reported in the paper.
MaltParser
(Nivre et
al.,
2006)
(version 1.8)
implements the transition-based approach to de-
pendency parsing,
which has two essential
com-
ponents:
(i) a nondeterministic transition system
for mapping sentences to dependency trees; (ii) a
classifier that
predicts the next
transition for ev-
ery possible system configuration.
MaltParser in-
cludes different
built-in transition systems,
dif-
ferent
classifiers
and techniques
for
recovering
non-projective dependencies with strictly projec-
tive parsers.
The MATE tools
1
include both a graph-based
parser
(Bohnet,
2010)
and
a
transition-based
parser
(Bohnet
and Nivre,
2012;
Bohnet
and
Kuhn,
2012).
For
the languages
of
the 2009
CoNLL Shared Task,
the
graph-based MATE
parser reached accuracy scores similar or above
the top performing systems with fast
processing
(obtained with the use of Hash Kernels and par-
allel
algorithms).
The transition-based MATE
parser is a model that takes into account complete
structures as they become available to rescore the
elements of a beam, combining the advantages of
transition-based and graph-based approaches.
TurboParser
(Martins
et
al.,
2013)
2
(version
1
https://code.google.com/p/mate-tools/
2
http://www.ark.cs.cmu.edu/
TurboParser/
2.3)
is
a
C++ package
that
implements
non-
projective graph-based dependency parsing ex-
ploiting third-order features.
The approach uses
AD
3
,
an accelerated dual
decomposition algo-
rithm extended to handle specialized head au-
tomata and sequential head bigram models.
ZPar (Zhang and Nivre,
2011) (version 0.75)
is a transition-based parser implemented in C++.
ZPar
supports
multiple languages
and multiple
grammar formalisms.
ZPar has been most heavily
developed for Chinese and English,
while it pro-
vides generic support for other languages. It lever-
ages a global
discriminative training and beam-
search framework.
DeSR (Attardi and Dell’Orletta,
2009) version
1.4.3 is a shift-reduce dependency parser,
which
uses a variant of the approach of Yamada and Mat-
sumoto (2003).
It
is capable of dealing directly
with non-projective parsing, by means of specific
non-projective transition rules (Attardi,
2006).
It
is highly configurable: one can choose which clas-
sifier (e.g.
SVM or Multi-Layer Perceptron) and
which feature templates to use, and the format of
the input, just by editing a configuration file.
EmoryNLP (Choi and McCallum, 2013)
3
(pre-
viously ClearNLP)
dependency parser
(version
1.1.1) uses a transition-based, non-projective pars-
ing algorithm showing a linear-time speed for both
projective and non-projective parsing.
The
Stanford
neural
network
dependency
parser (Chen and Manning, 2014)
4
is a transition-
based parser
which produces typed dependency
parses using a neural
network which uses word
embeddings as features besides forms and POS
tags. It also uses no beam.
RBG (Lei
et
al.,
2014;
Zhang et
al.,
2014b;
Zhang et al.,
2014a)
5
is based on a low-rank fac-
torization method that enables to map high dimen-
sional feature vectors into low dimensional repre-
sentations.
The method maintains the parameters
as a low-rank tensor
to obtain low dimensional
representations of words in their syntactic roles,
and to leverage modularity in the tensor for easy
training with online algorithms.
YARA Parser (Rasooli and Tetreault, 2015)
6
is
an implementation of
the arc-eager
dependency
model.
It
uses an average structured perceptron
3
http://nlp.mathcs.emory.edu/
4
http://nlp.stanford.edu/software/
nndep.shtml
5
https://github.com/taolei87/RBGParser
6
https://github.com/yahoo/YaraParser
CLIC_2016_Proceedings.indd 174
02/12/16 15.03
175
as classifier and a beam size of 64.
The feature
setting is from Zhang and Nivre (2011) with ad-
ditional Brown cluster features.
LSTM parser (Dyer et al., 2015; Ballesteros et
al., 2015)
7
is a transition based dependency parser
with state embeddings computed by LSTM RNNs
and an alternative char-based model
exploiting
character embeddings as features.
Both the mod-
els are applied in the experiments.
The list
of parsers is still
in progress because
the field of dependency parsing is in constant evo-
lution.
In mid-May,
SyntaxNet,
the dependency
parser by Google, was made publicly available; a
few days later BIST parser (that claims to be “A
faster and more accurate parser than Google’s Mc-
Parseface”) was announced to become public.
SyntaxNet
(Andor
et
al.,
2016)
8
,
BIST
parser
(Kiperwasser
and Goldberg,
2016)
9
,
and
spaCy
10
are not yet included in our study because
we are still trying to make them working in a sat-
isfactory way.
3
Data Set
The experiments reported in the paper
are per-
formed on the Italian Stanford Dependency Tree-
bank (ISDT) (Bosco et al.,
2013) version 2.0 re-
leased in the context of the EVALITA 2014 evalu-
ation campaign on Dependency Parsing for Infor-
mation Extraction (Bosco et
al.,
2014)
11
.
There
are three main novelties with respect
to the pre-
viously available Italian treebanks:
(i) the size of
the dataset, much bigger than the resources used in
the previous EVALITA campaigns; (ii) the annota-
tion scheme, compliant to de facto standards at the
level of both representation format (CoNLL) and
adopted tagset
(Stanford Dependency Scheme);
(iii) its being defined with a specific view to sup-
porting information extraction tasks, a feature in-
herited from the Stanford Dependency scheme.
The
training
set
contains
7,414
sentences
(158,561 tokens),
the development
set
564 sen-
tences (12,014 tokens),
and the test set 376 sen-
tences (9,066 tokens).
7
https://github.com/clab/lstm-parser
8
https://github.com/tensorflow/models/
tree/master/syntaxnet
9
https://github.com/elikip/bist-parser
10
https://spacy.io/,
https://github.com/
spacy-io/spaCy
11
http://www.evalita.it/2014/tasks/dep_
par4IE.
4
Experiments
The level
of interaction with the authors of the
parsers varied.
For
MaltParser,
MATE parsers,
TurboParser,
and ZPar we have mainly exploited
the experience gained in the context of EVALITA
2014 (Lavelli, 2014a).
Concerning MaltParser,
in addition to using
the best
performing configuration at
EVALITA
2014 (Nivre’s arc-eager,
PP-head),
we have used
MaltOptimizer
12
(Ballesteros and Nivre, 2014) to
identify the best configuration.
This was done to
be fair to the other parsers, given that MaltParser’s
best configuration was the result of extensive fea-
ture selection at the CoNLL 2006 shared task. Ac-
cording to MaltOptimizer,
the best
configuration
is Nivre’s arc-standard.
As for the MATE parsers, we have applied both
the graph-based and the transition-based parser.
TurboParser was applied using the three stan-
dard configurations (basic, standard, full).
Concerning ZPar,
the main difficulty emerged
in 2014 (i.e., the fact that sentences with more than
100 tokens needed 70 GB of RAM) is no longer
present and so its use is rather straightforward.
As for the new parsers, the only problems dur-
ing installation concerned an issue with the ver-
sion of the C++ compiler needed for successfully
compiling LSTM parser.
For some of the parsers there is the possibil-
ity of exploiting word embeddings (RBG,
Stan-
ford parser,
LSTM,
EmoryNLP) or Brown clus-
tering (YARA parser).
As for word embeddings
(WEs), we exploited the following (both built us-
ing word2vec):
•
word embeddings
of
size 300 learned on
WackyPedia/itWaC (a corpus of more than 1
billion tokens)
13
;
•
word
embeddings
of
size
50
produced
in
the
project
PAIS
`
A (Piattaforma
per
l’Apprendimento
dell’Italiano
Su
corpora
Annotati)
14
on a corpus of 250 million to-
kens.
In general,
WEs of size 300 produced an in-
crease in performance, while those of size 50 pro-
duced a decrease in performance (with the excep-
12
http://nil.fdi.ucm.es/maltoptimizer/
13
http://clic.cimec.unitn.it/
˜
georgiana.dinu/down/
14
http://www.corpusitaliano.it/en/
index.html
CLIC_2016_Proceedings.indd 175
02/12/16 15.03
176
LAS
UAS
LA
RBG (full, w/ WEs - size=300)
87.72
90.00
93.03
RBG (standard, w/ WEs - size=300)
87.63
89.91
93.03
RBG (full, w/o WEs)
87.33
89.94
92.41
RBG (standard, w/o WEs)
87.33
89.86
92.43
MATE transition-based
87.07
89.69
92.30
MATE graph-based
86.91
89.53
92.67
TurboParser (model type=full)
86.53
89.20
92.22
TurboParser (model type=standard)
86.45
88.96
92.29
ZPar
86.32
88.65
92.40
LSTM (EMNLP 2015, char-based w/ WEs - size=300)
86.07
88.96
92.15
RBG (basic, w/o WEs)
85.99
88.53
91.71
MaltParser (Nivre eager -PP head)
85.82
88.29
91.62
EmoryNLP (w/o WEs)
85.30
87.68
91.51
TurboParser (model type=basic)
84.90
87.28
91.26
DeSR (MLP)
84.61
87.18
90.79
MaltParser (Nivre standard - MaltOptimizer)
84.44
87.17
90.94
LSTM (ACL 2015, w/ WEs - size=300)
84.20
87.13
90.80
LSTM (EMNLP 2015, char-based w/o WEs)
84.13
87.32
90.75
YARA parser (w/o BCs)
83.87
86.79
90.34
LSTM (ACL 2015, w/o WEs)
83.86
86.95
90.56
Stanford NN dependency parser (w/ WEs - size=50)
83.68
86.50
90.85
Table 1:
Results on the EVALITA 2014 test set without considering punctuation,
in terms of Labeled
Attachment Score (LAS), Unlabeled Attachment Score (UAS) and Label Accuracy (LA).
tion of the Stanford NN dependency parser, which
produced results comparable to other parsers with
WEs of size 50 and absurdly low results with those
of size 300). We were not able to successfully run
the EmoryNLP parser with WEs. The use of WEs
needs further investigation.
As for the use of Brown clusters (BCs), we are
still
working to build suitable resources for Ital-
ian,
so the YARA Parser was used with standard
settings and without Brown clusters.
The
experiments
were
performed using the
splits provided by the EVALITA 2014 organisers:
training on the training set,
tuning (if any) using
the development set and final test on the test set.
In Table 1 we report
the parser results ranked
according to decreasing Labeled Accuracy Score
(LAS),
not
considering punctuation.
We have
grouped together the parsers if the differences be-
tween their results (in terms of LAS) are not statis-
tically significant
(computation performed using
D
EPEND
A
BLE
(Choi et al., 2015)).
The results obtained by the best
system sub-
mitted to the
official
evaluation at
EVALITA
2014 (Attardi and Simi,
2014) are:
87.89 (LAS),
90.16 (UAS). More details about the task and the
results obtained by the participants are available
in Bosco et al. (2014).
5
Conclusions
In the paper we have reported on work in progress
on the comparison between several state-of-the-art
dependency parsers on the Italian Stanford Depen-
dency Treebank (ISDT).
We are already working to widen the scope of
the comparison including more parsers and to per-
form an analysis of the results obtained by the dif-
ferent
parsers considering not
only their perfor-
mance but also their behaviour in terms of speed,
CPU load at training and parsing time, ease of use,
licence agreement, . . .
The next step would be to apply the parsers in
a multilingual
setting,
exploiting the availability
of treebanks based on Universal Dependencies in
many languages (Nivre et al., 2016)
15
.
Acknowledgments
We thank the authors of the parsers for making
them freely available,
for
kindly answering our
questions and for
providing useful
suggestions.
We thank the reviewers for valuable suggestions
to improve this article.
15
http://universaldependencies.org/
CLIC_2016_Proceedings.indd 176
02/12/16 15.03
177
References
Daniel
Andor,
Chris Alberti,
David Weiss,
Aliaksei
Severyn, Alessandro Presta, Kuzman Ganchev, Slav
Petrov,
and Michael Collins.
2016.
Globally nor-
malized transition-based neural
networks.
CoRR,
abs/1603.06042.
Giuseppe Attardi and Felice Dell’Orletta.
2009.
Re-
verse revision and linear tree combination for de-
pendency parsing.
In Proceedings of Human Lan-
guage Technologies:
The 2009 Annual Conference
of
the North American Chapter of
the Association
for Computational Linguistics, Companion Volume:
Short
Papers,
pages 261–264,
Boulder,
Colorado,
June. Association for Computational Linguistics.
Giuseppe Attardi and Maria Simi.
2014.
Dependency
parsing techniques for information extraction.
In
Proceedings of EVALITA 2014.
Giuseppe Attardi.
2006.
Experiments with a multi-
language non-projective dependency parser.
In Pro-
ceedings of the Tenth Conference on Computational
Natural Language Learning (CoNLL-X), pages 166–
170, New York City, June. Association for Compu-
tational Linguistics.
Miguel Ballesteros and Joakim Nivre.
2014.
MaltOp-
timizer: Fast and effective parser optimization.
Nat-
ural Language Engineering, FirstView:1–27, 10.
Miguel
Ballesteros,
Chris Dyer,
and Noah A.
Smith.
2015.
Improved transition-based parsing by mod-
eling characters instead of words with LSTMs.
In
Proceedings of
the 2015 Conference on Empirical
Methods in Natural
Language Processing,
pages
349–359, Lisbon, Portugal, September. Association
for Computational Linguistics.
Bernd Bohnet
and Jonas Kuhn.
2012.
The best
of
both worlds – a graph-based completion model for
transition-based parsers.
In Proceedings of the 13th
Conference of the European Chapter of the Associ-
ation for Computational
Linguistics,
pages 77–87,
Avignon,
France,
April.
Association for Computa-
tional Linguistics.
Bernd Bohnet and Joakim Nivre.
2012.
A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing.
In Pro-
ceedings of
the 2012 Joint
Conference on Empiri-
cal
Methods in Natural
Language Processing and
Computational
Natural
Language Learning,
pages
1455–1465, Jeju Island, Korea, July. Association for
Computational Linguistics.
Bernd Bohnet.
2010.
Top accuracy and fast
depen-
dency parsing is not a contradiction.
In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics (Coling 2010), pages 89–97, Bei-
jing, China, August. Coling 2010 Organizing Com-
mittee.
Cristina Bosco and Alessandro Mazzei.
2011.
The
EVALITA 2011 parsing task: the dependency track.
In Working Notes of EVALITA 2011, pages 24–25.
Cristina Bosco,
Alessandro Mazzei,
Vincenzo Lom-
bardo,
Giuseppe Attardi,
Anna Corazza,
Alberto
Lavelli, Leonardo Lesmo, Giorgio Satta, and Maria
Simi.
2008.
Comparing Italian parsers on a com-
mon treebank:
the EVALITA experience.
In Pro-
ceedings of LREC 2008.
Cristina Bosco,
Simonetta Montemagni,
Alessandro
Mazzei,
Vincenzo Lombardo,
Felice DellOrletta,
and Alessandro Lenci.
2009.
Evalita09 parsing
task:
comparing dependency parsers and treebanks.
In Proceedings of EVALITA 2009.
Cristina Bosco,
Simonetta Montemagni,
and Maria
Simi.
2013.
Converting Italian treebanks:
Towards
an Italian Stanford Dependency Treebank.
In Pro-
ceedings of the 7th Linguistic Annotation Workshop
and Interoperability with Discourse,
pages 61–69,
Sofia,
Bulgaria,
August.
Association for Computa-
tional Linguistics.
Cristina Bosco, Felice Dell’Orletta, Simonetta Monte-
magni, Manuela Sanguinetti, and Maria Simi.
2014.
The EVALITA 2014 dependency parsing task.
In
Proceedings of EVALITA 2014.
Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of
the Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
pages 149–164,
New York City,
June.
Association
for Computational Linguistics.
Danqi Chen and Christopher Manning.
2014.
A fast
and accurate dependency parser
using neural
net-
works.
In Proceedings of the 2014 Conference on
Empirical
Methods in Natural
Language Process-
ing (EMNLP),
pages 740–750,
Doha,
Qatar,
Octo-
ber. Association for Computational Linguistics.
Jinho
D.
Choi
and
Andrew McCallum.
2013.
Transition-based dependency parsing with selec-
tional
branching.
In Proceedings of
the 51st
An-
nual Meeting of the Association for Computational
Linguistics (Volume 1:
Long Papers),
pages 1052–
1062, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Jinho D. Choi, Joel Tetreault, and Amanda Stent.
2015.
It depends:
Dependency parser comparison using a
web-based evaluation tool.
In Proceedings of
the
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint
Conference on Natural
Language Processing (Vol-
ume 1:
Long Papers),
pages
387–396,
Beijing,
China, July. Association for Computational Linguis-
tics.
Walter Daelemans and V
´
eronique Hoste.
2002.
Eval-
uation of machine learning methods for natural lan-
guage processing tasks.
In Proceedings of the Third
International
Conference on Language Resources
and Evaluation (LREC 2002), Las Palmas, Spain.
CLIC_2016_Proceedings.indd 177
02/12/16 15.03
178
Walter Daelemans,
V
´
eronique Hoste,
Fien De Meul-
der,
and Bart Naudts.
2003.
Combined optimiza-
tion of feature selection and algorithm parameters
in machine learning of language.
In Proceedings of
the 14th European Conference on Machine Learning
(ECML 2003), Cavtat-Dubronik, Croatia.
Marie-Catherine de Marneffe and Christopher D. Man-
ning.
2008.
The Stanford typed dependencies rep-
resentation.
In Coling 2008:
Proceedings of
the
workshop on Cross-Framework and Cross-Domain
Parser Evaluation, pages 1–8, Manchester, UK, Au-
gust. Coling 2008 Organizing Committee.
Chris Dyer,
Miguel
Ballesteros,
Wang Ling,
Austin
Matthews,
and Noah A.
Smith.
2015.
Transition-
based dependency parsing with stack long short-
term memory.
In Proceedings of
the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing (Volume 1:
Long
Papers), pages 334–343, Beijing, China, July. Asso-
ciation for Computational Linguistics.
V
´
eronique Hoste,
Iris Hendrickx,
Walter Daelemans,
and Antal
van den Bosch.
2002.
Parameter
optimization for
machine-learning of
word sense
disambiguation.
Natural
Language Engineering,
8(4):311–325.
Eliyahu Kiperwasser and Yoav Goldberg.
2016.
Sim-
ple and accurate dependency parsing using bidi-
rectional
LSTM feature representations.
CoRR,
abs/1603.04351.
Alberto Lavelli.
2014a.
Comparing state-of-the-art
dependency parsers for the EVALITA 2014 depen-
dency parsing task.
In Proceedings of
EVALITA
2014.
Alberto Lavelli.
2014b.
A preliminary comparison
of state-of-the-art dependency parsers on the Italian
Stanford Dependency Treebank.
In Proceedings of
the first
Italian Computational
Linguistics Confer-
ence (CLiC-it 2014).
Tao Lei,
Yu Xin,
Yuan Zhang,
Regina Barzilay,
and
Tommi Jaakkola.
2014.
Low-rank tensors for scor-
ing dependency structures.
In Proceedings of
the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1381–1391, Baltimore, Maryland, June. Association
for Computational Linguistics.
Andre Martins,
Miguel Almeida,
and Noah A. Smith.
2013.
Turning on the turbo:
Fast third-order non-
projective turbo parsers.
In Proceedings of the 51st
Annual
Meeting of
the Association for Computa-
tional Linguistics (Volume 2:
Short Papers),
pages
617–622,
Sofia,
Bulgaria,
August.
Association for
Computational Linguistics.
Joakim Nivre,
Johan Hall,
and Jens Nilsson.
2006.
MaltParser:
A data-driven parser-generator for de-
pendency parsing.
In Proceedings of
the 5th In-
ternational Conference on Language Resources and
Evaluation (LREC), pages 2216–2219.
Joakim Nivre,
Johan Hall,
Sandra K
¨
ubler,
Ryan Mc-
Donald,
Jens Nilsson,
Sebastian Riedel,
and Deniz
Yuret.
2007.
The CoNLL 2007 shared task on de-
pendency parsing.
In Proceedings of
the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages
915–932,
Prague,
Czech Republic,
June.
Associa-
tion for Computational Linguistics.
Joakim Nivre,
Marie-Catherine de Marneffe,
et
al.
2016.
Universal Dependencies v1:
A multilingual
treebank collection.
In Proceedings of
the Tenth
International
Conference on Language Resources
and Evaluation (LREC 2016),
Portoro
ˇ
z,
Slovenia,
May.
European Language Resources
Association
(ELRA).
Mohammad Sadegh Rasooli
and Joel
R.
Tetreault.
2015.
Yara parser:
A fast and accurate dependency
parser.
CoRR, abs/1503.06733.
Djam
´
e Seddah,
Reut
Tsarfaty,
Sandra K
¨
ubler,
et
al.
2013.
Overview of
the
SPMRL 2013 shared
task:
A cross-framework evaluation of
parsing
morphologically rich languages.
In Proceedings
of
the Fourth Workshop on Statistical
Parsing of
Morphologically-Rich Languages,
pages 146–182,
Seattle, Washington, USA, October. Association for
Computational Linguistics.
Djam
´
e Seddah,
Sandra K
¨
ubler,
and Reut
Tsarfaty.
2014.
Introducing the SPMRL 2014 shared task
on parsing morphologically-rich languages.
In Pro-
ceedings of
the First
Joint
Workshop on Statisti-
cal Parsing of Morphologically Rich Languages and
Syntactic Analysis
of
Non-Canonical
Languages,
pages
103–109,
Dublin,
Ireland,
August.
Dublin
City University.
Yue Zhang and Joakim Nivre.
2011.
Transition-based
dependency parsing with rich non-local features.
In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 188–193, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Yuan Zhang,
Tao Lei,
Regina Barzilay,
and Tommi
Jaakkola.
2014a.
Greed is good if randomized: New
inference for dependency parsing.
In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural
Language Processing (EMNLP),
pages 1013–
1024,
Doha,
Qatar,
October.
Association for Com-
putational Linguistics.
Yuan
Zhang,
Tao
Lei,
Regina
Barzilay,
Tommi
Jaakkola,
and Amir Globerson.
2014b.
Steps to
excellence:
Simple inference with refined scoring
of dependency trees.
In Proceedings of
the 52nd
Annual
Meeting of
the Association for Computa-
tional Linguistics (Volume 1:
Long Papers),
pages
197–207,
Baltimore,
Maryland,
June.
Association
for Computational Linguistics.
CLIC_2016_Proceedings.indd 178
02/12/16 15.03
179
Taming Sense Sparsity:
a Common-Sense Approach
Antonio Lieto, Enrico Mensa and Daniele P. Radicioni
Dipartimento di Informatica
Universit
`
a degli Studi di Torino
Corso Svizzera 185, 10149 – Torino ITALY
{
lieto,mensa,radicion
}
@di.unito.it
Abstract
English. We present a novel algorithm and
a linguistic resource named C
L
OS
E
S
T
af-
ter ‘Common SEnse STrainer’.
The re-
source contains a list
of the main senses
associated to a given term, and it was ob-
tained by applying a simple set
of prun-
ing heuristics to the senses provided in the
NASARI vectors for the set of
15
K
most
frequent
English terms.
The preliminary
experimentation provided encouraging re-
sults.
Italiano.
In questo lavoro presentiamo
un algoritmo e una risorsa linguistica,
ClOSeSt,
che contiene i
sensi
pi
`
u rile-
vanti per i
15
K
termini pi
`
u frequenti del
dizionario inglese. L’algoritmo implemen-
tato utilizza una risorsa esistente che cod-
ifica conoscenza di
tipo enciclopedico,
e
poggia sulla nozione di senso comune per
filtrare i
possibili
sensi
associati
a cias-
cun termine.
La valutazione preliminare
ha fornito risultati incoraggianti in merito
alla qualit
`
a dei sensi estratti.
1
Introduction
Many NLP tasks involve word sense disambigua-
tion (WSD) and word sense induction (WSI), and
require using lexical
resources
such as
Word-
Net
(Miller,
1995)
and BabelNet
(Navigli
and
Ponzetto,
2010) that
provide a rich mapping of
terms
(or
word forms)
onto the corresponding
senses (word meanings).
These widely used re-
sources provide in fact subtle distinctions between
the possible senses of
a term.
It
is largely ac-
knowledged that while fine-grained sense distinc-
tions are necessary for some precise tasks (such
as machine translation),
for other sorts of appli-
cations (such as text categorization and informa-
tion extraction) coarse-grained sense inventories
are preferable (Palmer et al., 2004). In these cases,
fine-grained distinctions may be unnecessary and
even detrimental to WSD and WSI, so that in the
last few years many efforts concentrated on clus-
tering senses.
Most
works focused on produc-
ing coarser-grained sense inventories,
to the ends
of
grouping together
the closest
(partially over-
lapped) senses of a word;
to these ends,
various
techniques have been carried out,
that are briefly
surveyed in Section 2.
Differently from existing approaches,
we pro-
pose a simple yet effective method that relies on
recently developed resources that are assumed to
also grasp common-sense knowledge
(Camacho-
Collados et al.,
2015;
Lieto et al.,
2016a),
which
is
assumed to be
both widely accessible
and
elementary knowledge (Minsky,
2000),
and to
reflect
typicality traits
encoded as
prototypical
knowledge (Rosch, 1975).
The research question
presently addressed is thus:
To what
extent
can
we individuate few principal —common-sense—
senses for a term,
and in how far is it
possible
to approximate human performance?
Although
it
is known that
even human annotators provide
quite different response when annotating text with
senses (Palmer et al., 2004), we presently explore
the hypothesis that
wide-coverage resources are
sufficient to individuate the main senses associated
to English terms.
2
Related Work
In order
to attain coarse-grained senses,
differ-
ent
approaches
have been proposed,
based on
some sort
of semantic underspecification (Buite-
laar,
2000;
Ng et al.,
2003;
Palmer et al.,
2007),
on existing dictionaries and on exploiting hand-
crafted sense hierarchies (Navigli, 2006), on syn-
tactic
and semantic
properties
(such as
selec-
tional
restrictions on verb arguments) (Artale et
al.,
1998;
Palmer et
al.,
2004),
on linguistically
motivated heuristics
(Mihalcea
and Moldovan,
CLIC_2016_Proceedings.indd 179
02/12/16 15.03
180
2001), or on distributional similarity among word
senses (Agirre and De Lacalle, 2003).
Further ap-
proaches have been proposed that rely on an ad-
justable nearest
neighbour schema for clustering
senses according to the sense granularity actually
required by the application at
hand (McCarthy,
2006).
A popular testbed for experimenting these
and other approaches is represented by the sense-
annotated corpora Senseval-2 and 3 (Edmonds
and Cotton, 2001; Mihalcea and Edmonds, 2004).
The problem of annotating a term with the ap-
propriate sense is a challenging one, to such an ex-
tent that by no means “two lexicographers work-
ing independently are guaranteed to derive the
same set of distinctions for a given word” (Palmer
et al., 2004).
It has been raised that this issue can
be overcome to some extent by adopting a more
flexible annotation schema,
where senses are de-
scribed in a graded fashion:
in this way,
the ap-
plicability of a sense can be assessed on an ordi-
nal scale, rather than in ‘crisp’ fashion.
This sort
of annotation would allow to better interpret hu-
man annotations,
in particular for coarse-grained
groups (Erk et al.,
2013).
A related and comple-
mentary issue is that
of clusterability,
that
mea-
sures in how far word meanings can be partitioned.
In this setting,
whereas highly clusterable lem-
mas can be grouped based on traditional clustering
techniques,
less clusterable lemmas require more
sophisticated soft-clustering algorithms to compu-
tational systems,
and more time and expertise to
human annotators (McCarthy et al., 2016).
This work is framed in the context
of a long-
term project
aimed at
investigating conceptual
categorization (Lieto et
al.,
2015;
Lieto et
al.,
2016b)
based on a hybrid strategy (Evans and
Frankish,
2009)
complementing formal
ontolo-
gies with the geometrical framework of Concep-
tual Spaces (CS) (G
¨
ardenfors,
2014).
In particu-
lar,
we are building a knowledge base to collect
conceptual
information encoded in a CS-based
representational
format
to provide a uniform in-
terface between the linguistic and the concep-
tual
level,
where CSs
representations
are fully
endowed with BabelNet
identifiers (Lieto et
al.,
2016a).
1
This trait
will
make it
possible to link
the present work to existing initiatives like Senso
Comune (Oltramari and Vetere, 2008; Chiari et al.,
1
The integration of different semantic models such as CSs
and the distributional semantics underlying NASARI is still
an open issue; we provided an initial solution to this problem
in (Lieto et al., 2016a).
2010), that provides about
2000
fundamental Ital-
ian terms (De Mauro,
1999) with an ontological
description.
3
The C
L
OS
E
S
T
Algorithm
The rationale underlying the C
L
OS
E
S
T
algorithm
is that
the main (most
frequent)
senses gained
more room than marginal
senses in our
lexical
and conceptual
system and in general
in our ut-
terances. This phenomenon determines words and
phrases availability and saliency (Vossen and Fell-
baum,
2009),
that are arguably grasped by ency-
clopedic resources, as well.
Herein, more central
senses are typically featured by richer (i.e., longer
vectors) and less specific information,
richer se-
mantic connections with other concepts, and heav-
ier feature weights.
Although it may happen that
some sense spans over (or even subsumes) another
one, we are not primarily trying to cluster senses in
agglomerative fashion,
e.g.,
by resorting to some
superclass of the considered concept;
rather,
we
select
the most
relevant
ones (a term is seldom
associated to more than few,
say three or
four,
senses) and we discard the other ones.
The C
L
OS
E
S
T
algorithm takes in input a term
t
and provides a set
of possibly related senses.
2
The algorithm first retrieves the set of senses
S
=
{
s
1
, s
2
, . . . , s
n
}
that are possibly associated to
t
:
such set is obtained by directly querying NASARI.
The output of the algorithm is a result set
S

⊆
S
.
In order to attain
S

we devised a process of in-
cremental filtering, that is arranged into two main
phases:
1.
LS-Pruning.
Pruning of less salient
senses:
senses with associated poor information are
eliminated.
Senses salience is determined
both in absolute terms and in relation to the
most salient sense.
2.
OL-Pruning.
Pruning of overlapping senses:
if senses with significant overlap are found,
the less salient sense is pruned.
Senses
are
represented
as
NASARI
vectors,
that
are the vectorial
counterpart
of
BabelNet
synsets;
concepts
(basically,
WordNet
synsets
and Wikipedia pages) are described through vec-
tor
representations,
whose
features
are
synset
IDs themselves.
Feature weights are computed
2
The present
investigation is restricted to nouns,
but
no
theoretical
limitation prevents
us
from extending the ap-
proach to verbs and adjectives.
CLIC_2016_Proceedings.indd 180
02/12/16 15.03
181
through the metrics of lexical
specificity,
by ex-
ploiting a semantics-based dimensionality reduc-
tion (Camacho-Collados et al., 2015).
Each sense
is associated with exactly one NASARI vector, so
that pruning a sense amounts to pruning a vector.
LS-Pruning.
To analyze the senses in
S
,
we in-
spect each vector
v
ts
related to sense
s
for the term
t
.
The first pruning occurs when no enough infor-
mation is found, that is when
v
ts
contains less than
a fixed number of elements (Table 1). Then, in or-
der to determine the next vectors to be pruned, we
compute the weight of each vector (
W
(
v
ts
)
),
the
longest vector and the heaviest one among those
associated with
t
(
L
(
v
t
)
and
H
(
v
t
)
, respectively).
The weight of a NASARI vector
W
(
v
ts
)
is com-
puted by averaging the weight of the features (i.e.,
the synsets) contained herein.
The definitions for
these measures are illustrated in Equations 1–3.
L
(
v
t
) =
arg
max
s∈S
(
len
(
v
ts
))
(1)
W
(
v
ts
) =
1
len
(
v
ts
)
·

j
w
sj
(2)
H
(
v
t
) =
arg
max
s∈S

W
(
v
ts
)

.
(3)
The decision on whether to prune or not
a vec-
tor
is based on a simple criterion:
v
ts
∈
S
is
pruned if both its length is below a given frac-
tion of the length of the longest one L
(
v
t
)
, and its
weight is lower than a given fraction of the heavi-
est one, H
(
v
t
)
.
The parameter settings adopted in
the present work are illustrated in Table 1.
OL-Pruning.
The second phase of the algorithm
aims at
detecting overlapped senses.
The over-
lap between vectors that survived the LS-Pruning
is computed thanks to the information provided
in NASARI.
The heuristics
used in this
phase
is as follows:
the overlap between two vectors
Ovl
(
v
ti
, v
tj
)
is
computed as
a fraction of
the
length of the shortest vector between the two con-
sidered, as indicated in Equation 4).
Ovl
(
v
ti
, v
tj
) =
v
ti
∩
v
tj
len
(
shortest
(
v
ti
, v
tj
))
(4)
The overlapping is checked for every pair

v
i
, v
j

(with
i

=
j
)
and when an overlap is detected
higher than a fixed threshold (see Table 1),
the
shortest vector between the two is pruned.
At
the end of this phase,
we have the set
S

where only the most salient vectors survived and
where, among overlapped vectors, the most salient
one has been retained.
3.1
Building the C
L
OS
E
S
T
resource
Overall
the
system handled
about
2
.
69
M
NASARI vectors.
Some
207
K
vectors associated
to Named Entities were discarded, as not directly
related to common-sense concepts; the remaining
vectors contained overall
6
.
9
M
unique words.
The top (most
frequent)
15
K
nouns were ex-
tracted from the Corpus of Contemporary Amer-
ican English (COCA) which has been built from
composite and balanced sources,
including spo-
ken, fiction, magazine, newspaper, academic text.
3
Over
6
K
terms were discarded,
since they are
associated in NASARI
either
to
1
sense (about
1
K
terms) or to no sense at all (over
5
K
terms),
which actually reduced the input
size to about
8
.
7
K
terms; overall
32
.
6
K
senses were retrieved
(on average,
3
.
7
senses per term),
corresponding
to such input terms.
The figures featuring the processing phases are
reported in Table 1:
over
4
K
senses were filtered
in the first
step of the LS-Pruning phase,
based
on the length of the vector
v
ts
,
and
7
.
4
K
senses
were further discarded in the second step.
Finally,
in the OL-Pruning phase,
5
.
6
K
vectors were can-
celed based on overlapping accounts, thus overall
yielding
17
.
5
K
deleted and
15
.
1
K
survived vec-
tors.
4
The polysemy rate was reduced from the
3
.
74
senses per term initially featuring NASARI
down to
1
.
73
senses per term, which is in line with
the degree of polysemy detected in the Collins En-
glish Dictionary for English nouns by WordNet
authors (Fellbaum, 1990).
4
Evaluation
A preliminary experimentation has been devised
to assess the correctness and completeness of the
extracted senses:
that
is,
the question addressed
was whether i) all
senses extracted for the input
term are salient (and actually judged as the main
senses),
and ii) all
the relevant
senses were pre-
served in C
L
OS
E
S
T
.
To these ends,
15
volunteers
were recruited and interviewed through an on-line
questionnaire to evaluate,
on a human common-
sense judgement basis, the set of senses extracted
by the system for
20
terms.
3
http://corpus.byu.edu/full-text/.
4
C
L
OS
E
S
T
is available at http://goo.gl/7B61Oz.
CLIC_2016_Proceedings.indd 181
02/12/16 15.03
182
condition
threshold values
pruned senses
pruning phase
prune
v
ts
IF
len
(
v
ts
)
≤
α
α
= 5
4
,
389

LS-Pruning

len(v
ts
)
L (v
t
)
< β

AND

W (v
ts
)
W (H(v
t
))
< γ

β, γ
=
.
40
7
,
460
Ovl
(
v
ts
, v
tu
)
≥
δ
δ
=
.
20
5
,
676

OL-Pruning
filtered out senses
17,525
retained senses
15,134
Table 1: Pruning of senses in the three steps, along with the number of senses pruned at each step.
Stimuli.
The list of
20
terms was algorithmically
selected from the aforementioned COCA corpus
(see footnote 3) by selecting terms herein with in-
dex
1
,
51
,
101
,
and so forth.
In this way we se-
lected highly frequent terms that are expected to
be part
of common-sense for those who partici-
pated in our experimentation.
5
Experimental design and procedure. The partic-
ipants were asked a) to assess each and every sense
extracted by the system and associated to each in-
put term by indicating whether it was acceptable
as one of the principal senses for the term at hand.
Additionally,
they were requested b) to indicate
any further sense they reputed essential
in order
to complete the common-sense pool of senses for
the given term.
Results.
Overall
42
senses
(corresponding to
the
20
mentioned terms) were assessed through
the experimentation:
each sense was
rated
15
times,
thus resulting in
630
judgements:
24%
of
senses were not found appropriate, according to a
common-sense judgement,
thereby determining a
76%
accuracy as regards as question a). However,
if we consider senses refused by at least
10
par-
ticipants,
only
5
senses were refused (
12%
),
that
actually correspond to very specific senses (e.g.,
the sense ‘Net
(textile)’ for the term ‘network’;
‘Session (Presbyterianism)’,
‘session house’
for
the term ‘session’).
As regards as question b), results are more diffi-
cult to interpret, due to the sparsity of the answers:
out
of the
59
added senses,
only in
8
cases the
added sense has been indicated by two or three
participants (and never
more):
in such cases it
emerged,
for example,
that
the sense ‘manners’
5
The full list of the considered terms includes: time, side,
education, type, officer, ability, network, shoulder, threat, in-
vestigation,
gold,
claim,
learning,
session,
aid,
emergency,
bowl, pepper, milk, resistance. The printed version of the on-
line questionnaire is available at
the URL http://goo.
gl/w9TNQT.
was relevant
(and missing,
in the C
L
OS
E
S
T
re-
source) for the input term ‘education’;
the sense
‘social network’ is relevant for the term ‘network’;
and ‘meeting’ for ‘session’.
However,
although
encouraging
results
emerged from the experimentation,
further
ex-
periments
are needed to assess
the C
L
OS
E
S
T
resource in a more extensive and principled way,
also in consideration of
the many factors
that
were
presently neglected,
such as,
e.g.,
age,
education,
occupation of
the participants,
their
native language, etc..
5
Conclusions
In this paper
we have illustrated the C
L
OS
E
S
T
algorithm to extract
the most
salient
(under the
common-sense perspective) senses associated to
a
given
term;
also,
we
have
introduced
the
C
L
OS
E
S
T
resource, which has been built by start-
ing from the
15
K
top frequency English terms.
The resource currently provides senses in a flat
manner,
but,
if required,
senses can be organized
in a sorted fashion by extending the metrics used
for filtering.
Our work relies on a recently devel-
oped resource such as NASARI that
is multilin-
gual in nature.
6
Consequently, different from most
previous
approaches,
C
L
OS
E
S
T
can be linked
to various existing resources aimed at
grasping
common-sense to complete the ideal
chain con-
necting lexicon,
semantics and formal (ontologi-
cal) description.
The experimentation revealed a
reasonable agreement with human responses, and
pointed out some difficulties in fully assessing this
sort
of
resource.
These issues,
along with im-
provements to the heuristics implemented by the
algorithm and a different
evaluation based on a
shared NLP task, will be addressed in future work.
6
An interesting question may be raised on this point,
about the conceptual alignment in a inter-linguistic perspec-
tive, which is a well-known issue, e.g., for applications in the
legal field (Ajani et al., 2010).
CLIC_2016_Proceedings.indd 182
02/12/16 15.03
183
References
Eneko Agirre and Oier Lopez De Lacalle.
2003.
Clus-
tering WordNet
Word Senses.
In RANLP,
volume
260, pages 121–130.
Gianmaria Ajani,
Guido Boella,
Leonardo Lesmo,
Marco Martin, Alessandro Mazzei, Daniele P Radi-
cioni,
and Piercarlo Rossi.
2010.
Multilevel legal
ontologies.
In Semantic Processing of Legal Texts,
pages 136–154. Springer.
Alessandro Artale,
Anna
Goy,
Bernardo Magnini,
Emanuele Pianta,
and Carlo Strapparava.
1998.
Coping with WordNet Sense Proliferation.
In First
International Conference on Language Resources &
Evaluation.
Paul
Buitelaar.
2000.
Reducing Lexical
Semantic
Complexity with Systematic Polysemous
Classes
and Underspecification.
In NAACL-ANLP 2000
Workshop:
Syntactic and Semantic Complexity in
Natural
Language Processing Systems,
pages 14–
19. Association for Computational Linguistics.
Jos
´
e Camacho-Collados,
Mohammad Taher Pilehvar,
and Roberto Navigli.
2015.
NASARI: a Novel Ap-
proach to a Semantically-Aware Representation of
Items.
In Proceedings of NAACL, pages 567–577.
Isabella Chiari, Alessandro Oltramari, and Guido Vet-
ere.
2010.
Di Cosa Parliamo quando Parliamo Fon-
damentale?
Lessemi,
Accezioni,
Sensi
e Ontolo-
gie.
In Lessico e Lessicologia.
Atti
del
Convegno
della Societ di Linguistica Italiana, pages 177–194,
Roma, September. Bulzoni.
Tullio De Mauro.
1999.
Grande Dizionario Italiano
dell’Uso.
UTET, Turin, Italy.
Philip Edmonds and Scott Cotton.
2001.
SENSEVAL-
2:
Overview.
In Proceedings
of
SENSEVAL-
2 Second International
Workshop on Evaluating
Word Sense Disambiguation Systems,
pages 1–5,
Toulouse,
France,
July.
Association for Computa-
tional Linguistics.
Katrin Erk,
Diana McCarthy,
and Nicholas Gaylord.
2013.
Measuring word meaning in context.
Com-
putational Linguistics, 39(3):511–554.
Jonathan St BT Evans and Keith Ed Frankish.
2009.
In Two Minds: Dual Processes and Beyond.
Oxford
University Press.
Christiane Fellbaum.
1990.
English Verbs as a Se-
mantic Net.
International Journal of Lexicography,
3(4):278–301.
Peter G
¨
ardenfors.
2014.
The Geometry of Meaning:
Semantics Based on Conceptual Spaces.
MIT Press.
Antonio Lieto,
Daniele P.
Radicioni,
and Valentina
Rho.
2015.
A Common-Sense Conceptual
Cate-
gorization System Integrating Heterogeneous Prox-
ytypes
and the Dual
Process
of
Reasoning.
In
Proceedings of
the International
Joint
Conference
on Artificial
Intelligence (IJCAI),
pages 875–881,
Buenos Aires, July. AAAI Press.
Antonio Lieto,
Enrico Mensa,
and Daniele P.
Radi-
cioni.
2016a.
A Resource-Driven Approach for An-
choring Linguistic Resources to Conceptual Spaces.
In Proceedings of the 15th International Conference
of the Italian Association for Artificial Intelligence,
Genoa, Italy, December. Springer.
Antonio Lieto,
Daniele P Radicioni,
and Valentina
Rho.
2016b.
Dual
PECCS:
a Cognitive System
for Conceptual
Representation and Categorization.
Journal of Experimental & Theoretical Artificial In-
telligence, pages 1–20.
Diana McCarthy,
Marianna Apidianaki,
and Katrin
Erk.
2016.
Word Sense Clustering and Clusterabil-
ity.
Computational Linguistics.
Diana McCarthy.
2006.
Relating WordNet
Senses
for Word Sense Disambiguation.
Making Sense of
Sense:
Bringing Psycholinguistics and Computa-
tional Linguistics Together, 17.
Rada
Mihalcea
and
Phil
Edmonds.
2004.
SENSEVAL-3: Overview.
In Proceedings Senseval-
3 3rd International
Workshop on Evaluating Word
Sense Disambiguation Systems.
ACL,
Barcelona,
Spain.
Rada Mihalcea and Dan I Moldovan.
2001.
Automatic
Generation of a Coarse Grained WordNet.
In Pro-
ceedings of the NAACL Workshop on WordNet and
Other Lexical Resources.
George
A Miller.
1995.
WordNet:
a
Lexical
Database for English.
Communications of the ACM,
38(11):39–41.
Marvin Minsky.
2000.
Commonsense-based inter-
faces.
Communications of the ACM, 43(8):66–73.
Roberto Navigli
and Simone Paolo Ponzetto.
2010.
BabelNet:
Building a Very Large Multilingual Se-
mantic Network.
In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics,
pages 216–225. Association for Computa-
tional Linguistics.
Roberto Navigli.
2006.
Meaningful
Clustering of
Senses Helps Boost
Word Sense Disambiguation
Performance.
In Proceedings of
the 21st
Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the Association for Com-
putational Linguistics,
pages 105–112. Association
for Computational Linguistics.
Hwee Tou Ng, Bin Wang, and Yee Seng Chan.
2003.
Exploiting Parallel
Texts for
Word Sense Disam-
biguation:
An Empirical Study.
In Proceedings of
the 41st Annual Meeting on Association for Compu-
tational Linguistics-Volume 1,
pages 455–462.
As-
sociation for Computational Linguistics.
CLIC_2016_Proceedings.indd 183
02/12/16 15.04
184
Alessandro Oltramari and Guido Vetere.
2008.
Lexi-
con and Ontology Interplay in Senso Comune.
On-
toLex 2008 Programme, page 24.
Martha Palmer,
Olga Babko-Malaya,
and Hoa Trang
Dang.
2004.
Different Sense Granularities for Dif-
ferent Applications.
In Proceedings of Workshop on
Scalable Natural Language Understanding.
Martha Palmer, Hoa Trang Dang, and Christiane Fell-
baum.
2007.
Making Fine-Grained and Coarse-
Grained Sense
Distinctions,
both Manually and
Automatically.
Natural
Language
Engineering,
13(02):137–163.
Eleanor Rosch.
1975.
Cognitive Representations of
Semantic Categories.
Journal of Experimental Psy-
chology: General, 104(3):192–233.
Piek Vossen and Christiane Fellbaum,
2009.
Multi-
lingual FrameNets in Computational Lexicography:
Methods and Applications,
chapter Universals and
idiosyncrasies in multilingual WordNets.
Trends in
linguistics /
Studies and monographs:
Studies and
monographs. Mouton de Gruyter.
CLIC_2016_Proceedings.indd 184
02/12/16 15.04
185
Formatio formosa est. 
Building a Word Formation Lexicon for Latin 
Eleonora Litta, Marco Passarotti, Chris Culy 
CIRCSE Research Centre 
Università Cattolica del Sacro Cuore 
Largo Gemelli, 1 – 20123 Milan, Italy 
{eleonoramaria.litta, marco.passarotti}@unicatt.it, 
chrisculy@mac.com 
Abstract 
English. 
This 
paper 
presents 
the 
steps 
undertaken 
for 
building 
a 
word 
formation 
lexicon 
for 
Latin. 
The 
types 
of 
word 
formation rules are discussed and the semi-
automatic procedure to pair their input and 
output lexical items is evaluated. An on-line 
graphical query system to access the lexicon 
is described as well. 
Italiano. 
Questo 
articolo 
presenta 
le 
procedure 
di 
realizzazione 
di 
un 
lessico 
morfologico derivazionale per il latino. Sono 
descritti 
i 
tipi 
di 
regole 
di 
formazione 
di 
parola e viene valutata la qualità del sistema 
semi-automatico 
di 
individuazione 
delle 
parole in input e in output ad esse. Il sistema 
grafico d’interrogazione on-line 
dei dati è 
altresì presentato. 
1
Introduction 
In 
the 
area 
of 
Natural 
Language 
Processing 
(NLP), derivational morphology has always been 
neglected 
if 
compared 
to 
inflectional 
morphology, 
which 
plays 
a 
central 
role 
in 
fundamental annotation tasks like PoS tagging. 
Yet 
enhancing 
textual 
data 
with 
derivational 
morphology tagging promises to provide strong 
outcomes. First, it organises the lexicon at higher 
level than words, by building word formation 
based sets of lexical items sharing a common 
derivational 
ancestor. 
Secondly, 
derivational 
morphology acts like a kind of interface between 
morphology and semantics, since core semantic 
properties are shared at different extent by words 
built by a common word formation process. 
Lately, some lexical resources for derivational 
morphology have been made available. Among 
them are the lexical network for Czech DeriNet 
(Šev
č
íková 
and 
Žabokrtský, 
2014), 
the 
derivational 
lexicon 
for 
German 
DErivBASE 
(Zeller 
et 
al., 
2013) 
and 
that 
for 
Italian 
derIvaTario (Talamo et al., 2016). Furthermore, 
stemming 
is 
a 
technique 
largely 
used 
for 
detecting word formation processes (Goldsmith, 
2001), and language independent NLP tools were 
trained to extract derivation information from 
inflectional lexica (Baranes and Sagot, 2014). 
On the Classical languages front, although the 
number of resources and NLP tools for Ancient 
Greek and Latin is now manifold and varied 
(ranging 
from 
digital 
libraries, 
treebanks 
and 
computational lexica to PoS taggers and parsers), 
no lexical resource for derivational morphology 
is available yet, where words are connected by 
word 
formation 
processes. 
The 
first 
steps 
towards building such a word formation lexicon 
for Latin were made by Passarotti and Mambrini 
(2012), who described a model for the semi-
automatic 
extraction 
of 
word 
formation 
rules 
from 
the 
list 
of 
lemmas 
of 
Lexicon 
Totius 
Latinitatis by Forcellini (fifth edition; 1940) and 
the subsequent pairing of lexical entries and their 
derivational ancestor(s). 
The 
Word 
Formation 
Latin 
project 
has 
received 
funding 
from 
the 
EU 
Horizon 
2020 
Research and Innovation Programme under the 
Marie Sk
ł
odowska-Curie Individual Fellowship 
to expand on these efforts and create a word 
formation lexicon (working as an NLP tool as 
well) for Latin. In this paper, we describe the 
steps undertaken to build such a lexicon. 
The paper is organised as follows. Section 2 
presents the lexical basis supporting the lexicon; 
section 3 details the way the lexicon is built; 
section 
4 
describes 
how 
to 
access 
the 
data; 
section 5 concludes the paper and sketches the 
future work. 
CLIC_2016_Proceedings.indd 185
02/12/16 15.04
186
2
Lemlat 
The 
lexical 
basis 
used 
for 
building 
the 
word 
formation lexicon is the one provided by the 
morphological 
analyser 
for 
Latin 
Lemlat 
(Passarotti, 2004). Resulting from the collation 
of three Latin dictionaries (Georges and Georges, 
1913-1918; Glare, 1982; Gradenwitz, 1904), it 
counts 40,014 lexical entries and 43,432 lemmas 
(as more than one lemma can be included into 
the 
same 
lexical 
entry). 
Recently, 
the 
lexical 
basis of Lemlat was further enlarged by adding 
most of the Onomasticon (26,250 lemmas out of 
28,178) provided by Forcellini (1940). 
The basic component of the lexical look-up 
table used by Lemlat to morphologically analyse 
(and lemmatise) the input wordforms is the so-
called les (“LExical Segment”), which roughly 
corresponds to the invariable part of the inflected 
forms. In other words, the les is the sequence (or 
one of the sequences) of characters that remains 
the same in the inflectional paradigm of a lemma 
(hence, the les does not necessarily correspond to 
the word stem). For instance, puell is the les for 
the lemma puell–a (“girl”). 
Lemlat includes a 
LES
archive, in which each 
LES
is assigned a number of inflectional features 
among which are a tag for the gender of the 
lemma (for nouns only) and a code (
CODLES
) for 
its 
inflectional 
category. 
For 
instance, 
the 
CODLES
for the 
LES
puell is N1 (first declension 
regular nouns) and its gender is F (feminine). 
3
Building the Lexicon 
The word formation lexicon is built in two steps. 
First, word formation rules are detected. Then, 
they are applied to lexical data. 
3.1
Detecting Word Formation Rules 
Word 
formation 
rules 
(WFRs) 
are 
conceived 
according to the so-called Item-and-Arrangement 
model, 
outlined 
by 
Hockett 
(1954), 
which 
considers 
word 
forms 
either 
as 
simple 
morphemes (not derived word forms) or as a 
concatenation 
of 
morphemes 
(derived 
word 
forms). The following conditions on bases and 
affixes do hold: (1) Baudoin’s assumption that 
both bases and affixes are lexical elements (i.e. 
they are both morphemes); (2) as a consequence, 
they exist in the lexicon (Bloomfield’s “lexical 
morpheme” theory); (3) they are dualistic, i.e. 
they have both form and meaning (Bloomfield’s 
“sign-base” 
morpheme 
theory). 
The 
first 
two 
conditions motivate the fact that in our word 
formation lexicon affixes are recorded with the 
same status of lexical bases; the third condition 
concerns 
the 
semantic 
properties 
of 
WFRs 
mentioned in Section 1. 
WFRs fall into two main types: (1) derivation 
and 
(2) 
compounding. 
Derivation 
rules 
are 
further 
organised 
into 
two 
subcategories: 
(a) 
affixal, in its turn split into prefixal and suffixal, 
and 
(b) 
conversion, 
a 
derivation 
process 
that 
changes 
the 
PoS 
of 
the 
input 
word 
without 
affixation. 
Compounding 
and 
conversion 
WFRs 
are 
automatically 
detected, 
by 
considering 
all 
the 
possible 
combinations 
of 
main 
PoS 
(verbs, 
nouns, 
adjectives), 
regardless 
of 
their 
actual 
instantiations in the lexical basis. For instance, 
there are four possible types of conversion WFRs 
involving verbs: V-To-N (claudo 
→
clausa; “to 
close” 
→
“cell”), V-To-A (eligo 
→
elegans; “to 
pick out” 
→
“accustomed to select, tasteful”), N-
To-V (magister 
→
magistro; 
“master” 
→
“to 
rule”), A-To-V (celer 
→
celero; “quick” 
→
“to 
quicken”). 
Each 
compounding 
and 
conversion 
WFR type is further specified by the inflectional 
category of both input and output. For instance, 
A1-To-V1 
is 
the 
conversion 
WFR 
from 
first 
class adjectives to first conjugation verbs. 
Affixal WFRs are found both according to 
previous 
literature 
on 
Latin 
derivational 
morphology (Jenks, 1911; Fruyt, 2011; Oniga, 
1988) and in semi-automatic fashion. The latter 
is 
performed 
by 
extracting 
from 
the 
list 
of 
lemmas of Lemlat the most frequent sequences 
of characters occurring on the left (prefixes) and 
on the right (suffixes) side of lemmas. The PoS 
for WFR input and output lemmas as well as 
their inflectional category are manually assigned. 
Further affixal WFRs are found by confrontation 
with data. So far, we have detected 167 affixal 
WFRs: 71 prefixal and 96 suffixal. 
We recorded the rules in a table of a MySQL 
relational database where each WFR is classified 
by type 
and 
it is assigned the 
required 
PoS, 
inflectional category and gender for its input and 
output. 
3.2
Applying Word Formation Rules 
Each morphologically derived lemma is assigned 
a WFR. All those lemmas that share a common 
(not 
derived) 
ancestor 
belong 
to 
the 
same 
“morphological family”. For instance, lemmas 
formatio (“formation”), formo (“to form”) and 
formosus (“beautiful”, lit. “finely formed”) all 
belong 
to 
the 
morphological 
family 
whose 
ancestor is the lemma forma (“form”). 
CLIC_2016_Proceedings.indd 186
02/12/16 15.04
187
Lemmas 
and 
WFRs 
are 
paired 
by 
using 
a 
MySQL relational database whose main tables 
are 
the 
LES
archive of Lemlat, the list of its 
lemmas 
(each 
assigned 
its 
PoS, 
inflectional 
category and, for nouns only, gender) and the list 
of WFRs. 
A 
number 
of 
MySQL 
queries 
provide 
the 
candidate lemmas for each WFR. Some of these 
queries run on the list of lemmas, while others on 
the 
LES
archive. In particular, most candidate 
lemmas of prefixal WFRs are found by running 
queries on the list of lemmas, as such rules tend 
to just add the characters of the prefix to the 
input 
lemma, 
like 
in 
the 
case 
of 
accuso 
→
sub+accuso 
(“to 
blame” 
→
“to 
blame 
somewhat”). Instead, suffixal WFRs are mostly 
assigned 
to 
their 
candidate 
input 
and 
output 
lemmas by running queries on the 
LES
archive, 
because 
suffixes 
attach 
to 
LES
instead 
of 
modifying full lemmas, like in amo 
→
amabilis 
(“to 
love” 
→
“lovable”) 
where 
suffix 
–bil– 
attaches to 
LES
am (plus the thematic vowel –a–, 
used for first conjugation verbs) instead of full 
lemma 
amo. 
Also, 
there 
are 
suffixal 
WFRs 
whose input is the basis of the irregular perfect 
participle 
of 
the 
input 
verb, 
like 
in 
duco 
→
ductilis (“to lead” 
→
“that may be led”) where 
suffix –il– attaches to the basis of the irregular 
perfect participle of the verb duco (duct). Such 
irregular bases are recorded explicitly in the 
LES
archive with a specific 
CODLES
. 
3.3
State of Affair and Evaluation 
The procedure described above is not sufficient 
neither for detecting nor for applying the WFRs 
and, ultimately, for building the morphological 
families. Manual checking is largely needed for 
identifying 
false 
results 
and 
disambiguating 
duplication, 
as 
well 
as 
for 
filling 
lacunas 
resulting from the automatic process. 
For example, while looking for the candidates 
of the WFR that forms adjectives from nouns 
with the addition of the suffix –ax/–acis, two 
candidate input nouns are found for the adjective 
fugax (“swift, transitory”): fuga (“flight”) and 
fugium (rare, scarcely used in place of fuga). 
Such duplicate results need to be checked and 
disambiguated manually, as there must be only 
one input lemma for each output lemma resulting 
from a WFR of the derivation type, just like there 
must be only one WFR associated with each 
derived lemma. 
Morphotactically 
obscure 
word 
formation 
processes, like most compounding WFRs, are 
examples of lacunas of the automatic process of 
assigning WFRs, which are thus fully manually 
hard-coded. For instance, the compound lemma 
matricida 
(“matricide”) 
is 
derived 
by 
compounding 
the 
input 
lemmas 
mater 
(“mother”) and caedo (“to cut”), thus showing 
quite an obscure morphotactic configuration. 
So far, we have applied to data 134 WFRs (45 
prefixal, 
80 
suffixal, 
6 
conversion 
and 
3 
compounding), 
which 
corresponds 
to 
having 
assigned a WFR to 18,774 lemmas. Evaluation is 
performed by calculating the precision rate (Van 
Rijsbergen, 1979) of MySQL queries, i.e. the 
percentage of the correct candidate input-output 
pairs that are automatically assigned to a WFR 
by a query. 
As 
expected, 
precision 
is 
higher 
when 
morphotactic mutations are lower. Indeed, while 
precision rates for prefixal rules range between 
0.95 and 0.8, as they imply quite a few graphical 
mutations, precision for suffixal rules can vary 
heavily, ranging from 0.75 to as little as 0.3. 
Instead, the recall of queries has to be calculated 
later in the project, as currently we are unable to 
verify 
how 
many 
derived 
lemmas 
are 
not 
automatically picked up by queries. 
4
Accessing the Data 
The word formation lexicon can be accessed on-
line 
through 
a 
visualisation 
query 
system 
(http://wfl.marginalia.it). 
The 
lexicon 
can 
be 
browsed 
either 
by 
WFR, 
affix, 
or 
input 
and 
output PoS or lemma. Drop down menus provide 
the available options for each selection, like for 
instance the list of affixes and lemmas. 
Results are visualised as tree graphs, whose 
nodes are lemmas and edges are WFRs. Trees 
are interactive. Clicking on a node shows the full 
derivation tree (“word formation cluster”, which 
is 
calculated 
dynamically) 
for 
the 
lemma 
reported 
in 
that 
node. 
For 
example, 
figure 
1 
shows 
the 
currently 
available 
word 
formation 
cluster for the lemma 
amo. One can see that 
amabilis derives from amo and it is in turn the 
input for two other derived lemmas: amabilitas 
(“loveliness”) 
and 
inamabilis 
(“unlovely”). 
Clicking on an edge shows the lemmas built by 
the WFR concerned in that edge. Lemmas are 
provided both as a derivation graph and as an 
alphabetical list. For instance, clicking on the 
edge going from amo to amabilis in figure 1 
shows the lemmas built by the derivation WFR 
that builds second class adjectives (A2) from 
first conjugation verbs (V1) with suffix –bil–. 
CLIC_2016_Proceedings.indd 187
02/12/16 15.04
188
Figure 
2 
presents 
a portion of 
the 
derivation 
graph for this rule. 
Figure 1. Word formation cluster for amo. 
Figure 2. Derivation graph for a WFR. 
5
Conclusion and Future Work 
The 
building 
process 
of 
the 
word 
formation 
lexicon for Latin is ongoing. We still have to 
fully exploit the potential of querying the lexical 
basis 
of 
Lemlat 
to 
automatically 
detect 
candidates for WFRs. Furthermore, a substantial 
amount of manual work is needed to pick up 
morphotactically obscure formations, like those 
resulting from compounding. 
The 
word 
formation 
lexicon 
is 
meant 
to 
enhance Lemlat by providing its processing with 
word 
formation 
analysis 
of 
input 
data, 
thus 
building a wide lexical resource and NLP tool for 
Latin morphology, which will be made available 
through CLARIN infrastructure (www.clarin.eu). 
References 
Marion Baranes and Benoît Sagot. 2014. A Language-
Independent Approach to Extracting Derivational 
Relations 
from 
an 
Inflectional 
Lexicon. 
Proceedings of the Ninth International Conference 
on 
Language 
Resources 
and 
Evaluation 
(LREC'14). 
ELRA, 
Reykjavik, 
Iceland, 
2793–
2799. 
Egidio 
Forcellini. 
1940. 
Lexicon 
totius 
latinitatis. 
Typis Seminarii, Padova. 
Michele Fruyt. 2011. Word Formation in Classical 
Latin. J. Clarckson (ed.), A Companion to the Latin 
Language, 
Wiley-Blackwell, 
Chichester/Malden, 
Mass, 157–175. 
Karl 
Ernst 
Georges 
and 
Heinrich 
Georges. 
1913-
1918. 
Ausfuhrliches 
Lateinisch-Deutsches 
Handwôrterbuch. Hahn, Hannover. 
Peter GW. Glare. 1982. Oxford Latin Dictionary. At 
the Clarendon Press, Oxford. 
John Goldsmith. 2001. Unsupervised learning of the 
morphology of a natural language. Computational 
Linguistics, 27(2): 153–198. 
Otto Gradenwitz. 1904. Laterculi vocum latinarum. 
Hirzel, Leipzig. 
Charles 
F. 
Hockett. 
1954. 
Two 
Models 
of 
Grammatical Description. Words, 10: 210–231. 
Paul Rockwell Jenks. 1911. A manual of Latin word 
formation 
for 
secondary 
schools. 
DC 
Heath 
& 
Company, Harvard. 
Renato Oniga. 1988. I composti nominali latini: una 
morfologia generativa (Vol. 29). Pàtron, Bologna. 
Marco 
Passarotti. 
2004. 
Development 
and 
perspectives of the Latin morphological analyzer 
LEMLAT. Linguistica Computazionale, XX-XXI: 
397-414. 
Marco 
Passarotti 
and 
Francesco 
Mambrini. 
2012. 
First 
Steps 
towards 
the 
Semi-automatic 
Development of a Wordformation-based Lexicon 
of Latin. Proceedings of the Eighth International 
Conference 
on 
Language 
Resources 
and 
CLIC_2016_Proceedings.indd 188
02/12/16 15.04
189
Evaluation (LREC'12). 
ELRA, 
Istanbul, 
Turkey, 
852–859. 
Magda 
Šev
č
íková 
and 
Zden
ĕ
k 
Žabokrtský. 
2014. 
Word-Formation Network for Czech. Proceedings 
of the Ninth International Conference on Language 
Resources 
and 
Evaluation 
(LREC'14). 
ELRA, 
Reykjavik, Iceland, 1087–1093. 
Luigi 
Talamo, 
Chiara 
Celata 
and 
Pier 
Marco 
Bertinetto. 
2016. 
DerIvaTario: 
An 
annotated 
lexicon of Italian derivatives. Word Structure, 9(1): 
72–102. 
Cornelis 
Joost 
Van 
Rijsbergen. 
1979. 
Information 
retrieval. Butterworths, London, 2
nd
edition. 
Britta 
D. 
Zeller, 
Jan 
Snajder 
and 
Sebastian 
Padó. 
2013. 
DErivBase: 
Inducing 
and 
Evaluating 
a 
Derivational 
Morphology 
Resource 
for 
German. 
Proceedings 
of 
the 
Annual 
Meeting 
of 
the 
Association for Computational Linguistics. ACL, 
Sofia, Bulgaria, 1201-1211. 
CLIC_2016_Proceedings.indd 189
02/12/16 15.04
190
Sequenze N+pN (nome comune + nome proprio): descrizione linguisti-
ca da un corpus dell’italiano. 
Felicia Logozzo 
Università di Roma ‘Tor Vergata’ 
via Columbia, 1 – 00133 Roma 
logozzo@lettere.uniroma2.it 
Abstract 
English. 
This paper describes the most 
important N+pN (noun + proper noun) 
structures in Italian from the corpus of La 
Repubblica 2002-2005 
Italiano. Il contributo descrive le struttu-
re 
N+pN 
più 
significative 
estratte 
dal 
corpus de La Repubblica 2002-2005. 
1 
Introduzione 
I dati oggetto dell’analisi sono stati ricavati dal 
corpus de 
La Repubblica
2002-2005 (circa 20 
milioni di token), mediante T2K
1
(
Text to Know-
ledge
), 
sistema 
automatico 
per 
l’estrazione 
e 
l’organizzazione della conoscenza da testi. 
Al software è stato richiesto di selezionare le se-
quenze N+N (nome comune + nome comune) e 
N+pN (nome comune + nome proprio) con fre-
quenza pari o superiore a 18 occorrenze. 
Dei 
557 
risultati 
estratti 
(24.013 
occorrenze 
complessive) ne sono stai considerati validi 437 
(78%
2
circa); i restanti 120 sono prevalentemente 
sequenze N+A (nome + aggettivo) o A+N tra cui 
composti nominali con aggettivo
3
, sia con testa a 
sinistra (
maglia rosa, giudice istruttore, gruppo 
dirigente, piano regolatore 
ecc.), sia con testa a 
destra (
sostituto procuratore 
ecc.); tra questi ul-
timi, anche 
anni Sessanta, anni Novanta, anni 
Trenta, anni Venti, anni Quaranta
- classificati 
1
(Dell’Orletta et al., 2014). 
2
Sul corpus in questione, l’accuratezza del 
Part of 
Speech Tagger
impiegato risulta essere complessiva-
mente pari al 96,34% (cfr. Dell’Orletta, 2009). 
3
Per la classificazione dei composti, là dove non di-
versamente 
specificato, 
si 
fa 
riferimento 
a 
Bisetto 
(2004: 33-50). 
dal software come sequenze con nomi propri, per 
l’uso convenzionale della maiuscola. 
Il gruppo delle 437 sequenze potenzialmente 
utili 
ai fini dell’analisi N+N/N+pN si riduce ulterior-
mente, se si eliminano le 14 sequenze non com-
plete (
calo rispetto, tv via, pistola calibro, 
via G, 
via de’
), le 2 locuzioni avverbiali (
passo passo, 
fin fine
) e i 41 prestiti stranieri ed espressioni 
latine (
talk show, pole position, week end, par 
condicio, alter ego, call center, best seller, tour 
operator
ecc.). 
Escludendo infine un appellativo - 
signor Presi-
dente
- e la parte di polirematica - 
parola fine-
, 
l’insieme delle 380 sequenze rimanenti è costi-
tuito da 147 composti N+N e da 
231 sequenze 
N+pN, oggetto, queste ultime, di analisi specifica 
nel prossimo paragrafo. 
Quanto al primo gruppo, s
ono rappresentati nel 
corpus 
composti 
N+N
4
di 
tutte 
le 
categorie: 
coordinati endocentrici (
decreto legge
) ed eso-
centrici 
(
centro 
sinistra
), 
subordinati 
(
ufficio 
stampa
). Tra questi, ben 53 sequenze su 147 so-
no rappresentate da espressioni di spazio o di 
tempo, formate con pochi e diffusissimi elementi 
base (
centro, metà, mattina, pomeriggio, sera, 
inizio, fine,
punti cardinali
5
). 
Sebbene l’italiano non esprima 
tradizionalmente 
rapporti di subordinazione mediante giustapposi-
zione, 
ma 
prediliga 
sintagmi 
preposizionali 
e
4
Per i composti N+N dell'italiano, cfr. i lavori di 
Jan Radimský, in particolare Radimský (2013)
, sul 
corpus de 
La Repubblica,
e Radimský (2015). 
5
Sono esempi prototipici di basi di composti groun-
ding: ‘Le teste dei composti 
grounding in italiano 
esprimono concetti 
intrinsecamente relazionali, che 
richiedono una specificazione ulteriore per convoglia-
re un contenuto efficacemente informativo
; esempi 
tipici di teste grounding sono i portatori/contenitori di 
informazione, 
organizzazioni, 
luoghi, 
aggregatori, 
puntatori nel tempo e nello spazio, proprietà misurabi-
li’ (Baroni, Guevara e Pirrelli, 2009) 
CLIC_2016_Proceedings.indd 190
02/12/16 15.04
191
aggettivi relazionali, la 
composizione 
N+N 
è, 
com'è noto, molto più diffusa di quanto appaia 
dalle grammatiche descrittive, che non prevedo-
no, ad esempio, la categoria del nome attributivo, 
impiegata nella descrizione della lingua inglese, 
là dove convivono aggettivi denominali e nomi 
giustapposti corradicali con medesima funzione 
(
wool swater / woolen sweater
)
6
. 
Di contro, in alcuni dizionari
7
, per superare le 
difficoltà descrittive 
delle 
strutture 
N+N, 
basi 
nominali di composti, prevalentemente ma non 
esclusivamente 
coordinati, 
vengono 
registrati 
come aggettivi invariabili (
parola chiave, punti 
chiave, cifra record, tempo record, motore die-
sel, rabbino capo, ruolo chiave, città campione, 
uomo chiave, campo base, livelli record
). 
2 
Denominazione e composizione N+pN 
Il rapporto prevalente per le sequenze N+pN è 
senza 
dubbio 
quello 
identificativo/appositivo 
(129 su 231 sequenze, 5451 occorrenze su 9430). 
La lingua italiana prevede infatti che ad un nome 
proprio possa/debba essere affiancata la propria 
categoria di appartenenza mediante apposizione. 
N+pN 
I casi prototipici di identificazione-apposizione 
sono rappresentati da sequenze titolo+pN (
presi-
dente Bush, presidente Ciampi, ministro Tremon-
ti, sindaco Veltroni, ministro Castelli
ecc.) o no-
mi societari (
società Autostrade
) in cui 
pN è un N 
come confermano usi quali: 
‘Autostrade è una 
società privatizzata negli anni '90 che opera in 
un regime di concessione statale’ 
(il giornale.it).
A differenza degli esempi di cui sopra, in molti 
casi l’apposizione è indispensabile e fa parte in-
tegrante 
dell’espressione 
‘nome 
proprio’: 
è 
il 
caso, ad esempio, degli odonimi
8
che si compon-
gono obbligatoriamente con struttura N+pN (
via 
Cristoforo Colombo
≠ 
Cristoforo Colombo
). Se 
col tempo una specifica strada riesce ad acquisire 
una sufficiente notorietà, potrà essere identificata 
anche 
soltanto 
col 
nome 
proprio 
preceduto 
dall’articolo, segno – quest’ultimo - della pre-
6
Un’alternanza parzialmente ma non completamente 
sovrapponibile – non si tratta infatti di corradicali in 
senso stretto - si verifica in italiano in presenza di 
Scritture Brevi come in 
tv/televisivo
- 
programma tv / 
programma televisivo 
(già oggetto di analisi in Lo-
gozzo, in stampa). 
7
Sabatini-Coletti, per esempio. 
8
Per denominazione e composizione con toponimi e 
marchionimi cfr. Logozzo (2015). 
senza silenziosa dell’omesso nome comune (
la 
Colombo
). 
Gli odonimi infatti possono essere inclusi nella 
più generale categoria per cui vale l’espressione: 
N intitolato a pN 
premio Nobel, via Nazionale, palazzo Chigi, via-
le Mazzini, piazza Vittorio, piazza Navona, via 
Roma, corso Vittorio, teatro Politeama, palazzo 
Koch
. 
In sequenze di questo tipo, i 
nomi propri sono, 
per così dire, nomi di riuso; la relazione N+pN 
continua ad essere una relazione identificativo-
appositiva, 
ma 
inizia 
ad 
acquisire 
aspetti 
più 
complessi che la proiettano verso la subordina-
zione. 
Le vicende specifiche di ognuna di queste se-
quenze fa sì che sia sentita accettabile o meno 
l’equivalenza 
pN è un N
. Tutti d’accordo, per 
esempio, che 
il Nobel
sia un premio e che 
il Poli-
teama
sia un teatro; più difficile che 
via Naziona-
le
o 
via Roma
viaggino senza nome comune: 
via Nazionale è una via / Piazza Venezia è una 
piazza / palazzo Chigi è un palazzo 
?/* la Nazionale è una via / *(la) Venezia è una 
piazza / *il Chigi è un palazzo
In questi casi, la motivazione che lega N a pN, 
sfugge ad un’analisi esclusivamente linguistica. 
Se si considera ad esempio 
palazzo Chigi,
in 
rapporto ad altre sequenze dalla medesima strut-
tura, come 
palazzo Benetton e palazzo Fuksas
, 
emerge 
che 
solo 
conoscenze 
extralinguistiche 
permettono di sapere che i Chigi comprarono e 
abitarono l’omonimo palazzo nel 600; 
palazzo 
Benetton
è stato progettato da Fuksas su com-
missione appunto di Benetton, e poi rivenduto a 
H&M; 
palazzo 
Fuksas
è 
stato 
progettato 
anch’esso da Fuksas, a Pescara, e ospita la sede 
di una importante multinazionale. 
Si tratta sostanzialmente di strutture analizzabili 
solo a livello pragmatico
9
: col passare del tempo, 
l
a relazione di motivazione che lega N+pN (il 
fatto di aver comprato, commissionato o proget-
tato il palazzo) svanisce nella coscienza dei par-
lanti e l'intera sequenza N+pN diventa denomi-
nazione. Il processo è pressoché concluso nel 
caso di 
palazzo Chigi
, sentita quasi solo come 
denominazione; appena iniziato per 
palazzo Fuk-
sas
. 
A dispetto di quanto dichiarato dalle grammati-
che, è cristallizzata nella lingua dell’uso la giu-
stapposizione N+pN per l’espressione di relazio-
9
Cfr. Bartning (2001: 150 ss). 
CLIC_2016_Proceedings.indd 191
02/12/16 15.04
192
ni morfosintattiche diverse da quella identificati-
va-appositiva. 
Il corpus ci restituisce in tal senso 102 sequenze 
che coprono il 44% del totale delle sequenze 
N+pN. 
Rendere conto accuratamente delle strutture sog-
giacenti a ciascuna sequenza è questione com-
plessa; per questo, le sequenze estratte dal corpus 
verranno classificate mediante criteri volutamen-
te inclusivi, volti ad individuare analogie più che 
a differenziare, al solo fine dell’analisi del ruolo 
dei nomi propri. 
Il primo e più numeroso gruppo identificato (46 
sequenze per 1475 occorrenze) è quello delle 
sequenze che rimandano in qualche modo ad un 
rapporto di appartenenza in senso lato, morale, 
sociale o figurato
10
: 
N appartiene a pN 
commissario Ue, soldati Usa, coppa Italia, am-
ministrazione Usa, ispettori Onu, segretario Ds, 
vertice Rai, truppe Usa, segretario ds, dati Istat, 
paesi Ue, canone Rai, economia Usa, coppa Ue-
fa, comando Usa, presidente Ue, reti Mediaset, 
leader Cgil, deputato Ds, ambasciata Usa, capo-
gruppo Ds, militari Usa, commissione Ue, eser-
cito Usa, leader Ds, senatore Ds, presidenza Ue, 
ex dc, reti Rai, forze Usa, stabilimento Fiat, go-
verno Usa, norme Ue, giornalista Rai, agenti 
Cia, presidente Rai, vertice Ue, operai Fiat, con-
siglio 
Rai, 
consigliere 
Rai, 
base 
Usa, 
vertici 
Fiat, segretario Cgil, classifica Fifa, presidente 
ds, segretario Udc. 
Andando ad osservare il rapporto semantico e 
sintattico che intercorre tra N e pN, appare evi-
dente che si tratta di relazioni di subordinazione 
che potrebbero essere espresse in forma analitica 
mediante l’impiego di parole grammaticali – la 
preposizione ‘di’ primariamente – o di perifrasi 
verbali, riconducibili ai rapporti cosiddetti geni-
tivali. 
La mancanza della preposizione ‘di’ a collegare 
N e pN, fa sì che le strutture formalmente ap-
paiano come composti. Nello specifico, si tratterà 
di composti determinativi che ‘indicano una sot-
toclasse degli oggetti individuati dalla testa e nei 
10
‘What is normally called possession is the linguistic 
expression of the relation between two entities, a Pos-
sessor and a Possessum, such that one, the Possessor, 
is seen as being in some way related to the other, the 
Possessum, as having it near or controlling it. The 
kind of relation between the two can be of various 
sorts’ (Herslund and Baron, 2001: 2). 
quali il nome di destra si pone come una specifi-
cazione restrittiva del nome che lo precede’.
11
Sulla base dei dati emersi dal corpus, le strutture 
che consentono questo tipo di costruzioni sem-
brano essere piuttosto uniformemente costituite. 
La composizione N+pN per l’espressione di rela-
zioni di appartenenza concrete o figurate, è dun-
que ammessa in italiano seppure con restrizioni 
riguardanti, e la forma, e la sostanza del determi-
nante: quanto alla sostanza, entrano in composi-
zione nomi propri di enti, associazioni, istituzioni 
o marchionimi; quanto alla forma, sono rappre-
sentati determinanti di un’unica parola (
?/* depu-
tato Unione di Centro
), meglio se in forma di 
sigla (Scritture Brevi
12
). 
Alla base della grande produttività della compo-
sizione con Scritture Brevi vi è una motivazione 
semantica (il valore referenziale delle sigle coin-
volte che, in quanto nomi propri dotati di riferi-
mento, riducono le possibili ambiguità interpreta-
tive della relazione N+pN) e una motivazione 
formale: i composti sono strutturalmente formati 
da due elementi; la sigla permette di ridurre un 
nome proprio complesso, eventualmente costitui-
to da un’espressione con coordinazioni e subor-
dinazioni al suo interno (
Figc = Federazione 
Italiana Giuoco calcio
), ad elemento unico, evi-
tando così lunghe successioni asindetiche di ele-
menti 
(?/* 
Presidente 
Federazione 
Italiana 
Giuoco Calcio
)
13
. 
Non sembrano ammesse giustapposizioni di no-
mi propri che abbiano generato nella lingua ag-
gettivi relazionali denominali - si pensi agli etni-
ci derivati da nomi di stato/nazione - tranne nel 
caso in cui essi siano siglati; si ricrea in tal modo 
l’alternanza già vista per 
tv/televisivo 
(cfr. nota 
6)
:
soldati USA / soldati statunitensi 
ma non
*soldati Stati Uniti. 
La composizione N+pN del tipo appena analizza-
to può essere considerata produttiva perché si 
presta 
alla 
composizione 
occasionale, 
pratica 
originariamente non diffusa nella lingua italia-
na
14
, a differenza dell’inglese
15
che conia costan-
temente strutture pN+N. 
E’ importante, a questo proposito, distinguere 
l’imposizione 
di 
un 
nome 
proprio 
o 
di 
un’etichetta individuante (
Coppa Italia, via Mar-
chesi
) dalla composizione occasionale (
presiden-
te USA
). Se infatti nel primo caso le regole della 
11
(Bisetto, 2004: 40). 
12
Cfr. Chiusaroli (2012). 
13
Cfr. Logozzo (in stampa). 
14
Dardano (1978: 143) parla di ‘creazioni effimere’. 
15
Cfr. Bauer (1983: 202 ss). 
CLIC_2016_Proceedings.indd 192
02/12/16 15.04
193
grammatica si possono prescindere senza troppi 
imbarazzi e l’approccio di analisi può essere solo 
descrittivo, a posteriori, nel caso della composi-
zione occasionale è possibile azzardare ipotesi 
predittive, assumendo che certe strutture saranno 
più probabilmente scelte, rispetto ad altre, sulla 
base dell’uso. 
Merita un'attenzione particolare l'impiego degli 
antroponimi giustapposti in sequenze N+pN, per 
i quali il corpus ci restituisce i seguenti esempi: 
governo Berlusconi, amministrazione Bush, leg-
ge Gasparri, legge Cirami, riforma Moratti, go-
verno Sharon, lodo Schifani, legge Biagi, legge 
Bossi-Fini, governo Prodi, governo Blair, lodo 
Maccanico, 
governo 
Zapatero, 
riforma 
Dini, 
riforma Biagi, riforma Tremonti, governo Cuffa-
ro, legge Boato
Sulla base dei dati estratti, si evince che non sono 
ammessi antroponimi giustapposti ad esprimere 
vere e proprie relazione di possesso
16
(*auto An-
tonio, *giacca Marcello). 
Quando 
essi 
compaiono 
in 
sequenze 
N+pN, 
esprimono 
relazioni 
che 
oscillano 
dall’identificativo-appositivo 
al 
determinativo-
specificativo e richiedono di spostare l’analisi 
dalla 
semantica 
degli 
elementi 
coinvolti, 
alla 
pragmatica del discorso. 
E’ infatti invalso l’uso di attribuire una denomi-
nazione a leggi e riforme, impiegando antropo-
nimi come nomi propri di riuso. La riforma della 
scuola del 2003 è dunque ‘intitolata’ al Ministro 
(Moratti) che si è fatto promotore della stessa, 
così come si danno, per esempio, nomi ai governi 
(
Berlusconi 1, Berlusconi 4, Prodi 2
) in espres-
sioni in cui la relazione N+pN può essere al con-
tempo di subordinazione (
governo guidato da, 
nominato da, riforma ideata da, legge proposta 
da
) o di denominazione (
Il governo Berlusconi 3 
è durato dal 23 aprile 2005 al 17 maggio 2006 – 
Wikipedia.it). 
Come già detto a proposito degli odonimi di tipo 
N intitolato a pN
, gli antroponimi non entrano 
bene in predicazione, nemmeno in presenza di un 
articolo che sottintenda l’omissione di un nome 
comune, per le evidenti possibili ambiguità: 
la 
Bossi-Fini
è infatti una legge, ma 
la Moratti
non 
è una riforma. Un elemento determinativo ulte-
riore di pN, che escluda il riferimento diretto ad 
un essere umano, consente il superamento del 
problema, come, ad esempio, un altro antropo-
nimo in 
Bossi-Fini
, un cardinale in 
Berlusconi 3
. 
Al limite tra relazione identificativo-appositiva e 
specificativo-determinativa anche quella tra N e 
16
Cfr. Heine (2006). 
pN in 
gruppo Fiat, gruppo Parmalat, gruppo 
Telecom, gruppo Mediaset,
dal momento che, 
per esempio, Mediaset è una holding proprietaria 
di un gruppo di aziende, ma è anche l’etichetta 
dell’intero gruppo che prende il nome della capo-
fila. 
Denominate sulla base delle tematiche di cui si 
occupano, come testimonia la maiuscola dei de-
terminanti che le pone nel gruppo N+pN e non in 
quello N+N, le 
commissioni Giustizia, Lavoro, 
Bilancio e Affari (Costituzionali)
in cui però si 
mantiene un rapporto di subordinazione tra N e 
pN: 
*(La) Giustizia è una commissione / Quella 
della giustizia è una commissione.
Altre sequenze del corpus si possono raccogliere 
infine in una categoria aspecifica: 
si è verificato un N e riguarda pN 
processo Sme, caso Parmalat, crisi Fiat, caso 
Sofri, caso Fiat, caso Cirio, crac Parmalat, caso 
Moro, 
crac 
Cirio, 
caso 
Fazio, 
caso 
Catania, 
processo Imi-Sir, caso Sme, affare Sme 
Rientra in questo gruppo il tipo 
caso
+pN, ispira-
to forse al modello francese dell’
affaire Drey-
fus
17
, tipo estremamente produttivo in cui è pos-
sibile inserire anche il sottotipo 
crisi Fiat, crac 
Parmalat
. Sebbene rappresentato nel corpus da 
un’unica occorrenza (
omicidio Biagi
) è bene cita-
re in questo gruppo anche i genitivi oggettivi con 
antroponimi, che sembrano entrare in composi-
zione con specifiche teste (es: 
omicidio, rapi-
mento
) che permettono uno scioglimento del ti-
po: 
si è verificato un omicidio e ha riguardato 
Biagi
, probabilmente nel momento in cui un cer-
to episodio di cronaca è talmente di dominio 
pubblico da diventare un ‘caso’ quasi identifica-
bile con il solo pN. 
3 
Conclusioni 
La 
presenza 
dei 
nomi 
propri 
nelle 
sequenze 
N+pN fa sì che si abbia a che fare, nella maggior 
parte dei casi, con relazioni di denominazione 
con motivazione più o meno trasparente, analiz-
zabili, ora ricorrendo alla semantica degli ele-
menti coinvolti, ora, più frequentemente, ricor-
rendo alla conoscenza del mondo extralinguisti-
co. Completamente estranee alla denominazione, 
sono invece le sequenze del tipo 
commissario 
Ue, soldati USA
che rappresentano per l’italiano 
esempi 
di 
composizione 
N+pN
, 
alternativa 
all’impiego di aggettivi denominali o sintagmi 
preposizionali. 
17
Per l’influsso di modelli alloglotti sulle costruzioni 
N+pN cfr. Klajn (1972: 180 ss). 
CLIC_2016_Proceedings.indd 193
02/12/16 15.04
194
Bibliografia 
Baroni M., Guevara E. e Pirrelli V. 2009. 
Sulla tipo-
logia dei composti N+N in italiano:principi cate-
goriali ed evidenza distribuzionale a confronto,
in 
Ferrari G., Mosca M. e Benatti R. (a cura di) 
Lin-
guistica e modelli tecnologici di ricerca
. Bulzoni, 
Roma, 73-95. 
Bartning I. 2001. 
Towards a typology of French NP 
de NP structures or how much possession is there 
in complex noun phrases with 
de
in French?,
in 
Baron I., Herslund M. and Sørensen F. (a cura di) 
Dimensions of possessions
. Benjamins, Amsterdam 
– Philadephia, 147-167. 
Bauer L. 1983. 
English word formation.
Cambridge 
University Press, Cambridge. 
Bisetto A. 2004. 
Composizione con elementi italiani
, 
in Grossmann M. e Reiner F. (a cura di) 
La forma-
zione delle parole in italiano
. Max Niemeyer, Tü-
bingen, 33-50. 
Chiusaroli F. 2012. 
Scritture brevi oggi: tra conven-
zione e sistema
, in Chiusaroli F. e Zanzotto F.M. (a 
cura di) 
Scritture brevi di oggi
, Quaderni di Lin-
guistica Zero, Napoli, 4-44. 
Dardano 
M. 
1978. 
La 
formazione 
delle 
parole 
nell’italiano di oggi. 
Bulzoni, Roma. 
Dell’Orletta F., Venturi G., Cimino A. and Montema-
gni S. 2014. 
T2K²: a System for Automatically Ex-
tracting and Organizing Knowledge from Texts
in 
Proceedings of 9th Edition of International Con-
ference on Language Resources and Evaluation
(LREC 
2014), 
26-31 
May, 
Reykjavik, 
Iceland, 
2062-2070 
http://www.lrec-
conf.org/proceedings/lrec2014/pdf/
590_Paper.pdf
Dell’Orletta F. 2009. 
Ensemble system for Part-of-
Speech tagging
, in 
Evaluation of NLP and Speech 
Tools 
for 
Italian
. 
Reggio 
Emilia. 
http://www.evalita.it/sites/evalit
a.fbk.eu/files/proceedings2009/PoS
Tagging/POS_ILC.pdf
Heine 
B. 
2006. 
Possession
. 
Cambridge 
University 
Press, Cambridge 2006. 
Herslund M. and Baron I. 2001. 
Introduction: Dimen-
sions 
of 
possession
, 
in 
Baron 
I. 
Herslund 
M., 
Sørensen F. (a cura di), 
Dimensions of possessions
. 
Benjamins, Amsterdam – Philadephia, 1-25. 
Klajn I. 1972. 
Influssi inglesi nella lingua italiana
, 
Olschki, Firenze. 
Logozzo 
F. 
2015. 
Sull’apparente 
omissione 
della 
preposizione ‘di’ davanti a nomi propri, con parti-
colare riguardo a toponimi e marchionimi
. in 
Rivi-
sta italiana di onomastica
21 (1): 93-116. 
Logozzo F. (in stampa). 
Scritture brevi tra sintagmi 
nominali, 
preposizionali 
e 
aggettivali. 
Atti 
del 
convegno 
‘Scritture 
brevi 
e 
varietà 
diatecnica’, 
Procida 26-28 giugno 2014. 
Radimský J. 2013. 
Tight N-N compounds in the Ita-
lian la Repubblica corpus
, in Baptista, J., Monte-
leone, M. (a cura di) 
Actes du 32ème Colloque in-
ternational sur le lexique et la grammaire (10-14 
septembre 2013, Faro, Portugal)
, 41-47. 
Radimský J. 2015. 
Les composes de coordination en 
italien: esquisse d'une typologie
, in 
Studia Roman-
ica Posnaniensia
42 (1): 97-111. 
CLIC_2016_Proceedings.indd 194
02/12/16 15.04
195
Semantic priming effects in Italian verbs recognition: 
the role of grammatical classes and semantic categories 
Azzurra Mancuso 
University of Salerno 
Via Giovanni Paolo II, 132 
Fisciano, SA, 84084, Italy 
amancuso@unisa.it 
Maria De Martino 
University of Salerno 
Via Giovanni Paolo II, 132 
Fisciano, SA, 84084, Italy 
mdemartino@unisa.it 
Alessandro Laudanna 
University of Salerno 
Via Giovanni Paolo II, 132 
Fisciano, SA, 84084, Italy 
alaudanna@unisa.it 
Abstract 
English. 
The 
hypothesis 
that 
grammatical 
class information is represented in the mental 
lexicon and that it is activated during lexical 
access has generated a wide literature about 
the 
differences 
between 
nouns 
and 
verbs. 
However, 
the 
available 
evidences 
are 
dis-
cordant. 
In this study we tried to disentangle grammat-
ical class effects from semantic categories ef-
fects during visual word recognition by ex-
ploiting the semantic priming paradigm. 
Semantically related prime-target pair were 
arranged. They could share (verb-verb) or not 
(noun-verb) grammatical class information. A 
third 
condition 
was 
included 
where 
noun 
primes and verb targets had both an action as 
a referent (
delitti/uccide
, crimes/he-she kills). 
Only prime/target pairs sharing grammatical 
class information showed significant seman-
tic priming effects. 
Results are compatible with the hypothesis 
that grammatical class is an organizational 
criterion in the mental lexicon and it is acti-
vated during lexical access. 
Italiano. 
L’ipotesi 
secondo 
cui 
l’informazione 
di 
classe 
grammaticale 
sia 
rappresentata nel lessico mentale e attivata 
durante l’accesso lessicale ha dato origine a 
un’ampia letteratura sulle differenze tra nomi 
e verbi. La base empirica è, tuttavia, ancora 
incerta. 
In questo studio abbiamo usato il paradigma 
del priming semantico per distinguere il ruo-
lo della classe grammaticale da quello della 
categoria 
semantica 
di 
appartenenza 
delle 
parole in un compito di riconoscimento visi-
vo. 
Sono state impiegate coppie prime-target se-
manticamente 
collegate 
che 
condividevano 
(verbo-verbo) o meno (nome-verbo) la classe 
grammaticale. In una terza condizione ab-
biamo usato prime-nome e target -verbo che 
avevano entrambi un referente appartenente 
alla categoria semantica delle azioni (delit-
ti/uccide). 
L’effetto di priming semantico è risultato si-
gnificativo solo per le coppie prime-target 
che condividevano l’informazione di classe 
grammaticale. 
I dati sono compatibili con l’idea che la clas-
se grammaticale sia un criterio organizzativo 
nel lessico mentale e che sia attivata durante 
l’accesso lessicale.
1
Introduction 
Psychological and neural evidence revealed that 
the distinction between parts of speech, mainly 
nouns and verbs, occurring in all languages (Sa-
pir, 1921) affects speaker’s performance: gram-
matical class is preserved in speech errors (Gar-
rett, 1982) and nouns and verbs can be selective-
ly disrupted in aphasic populations (Collina, Ma-
rangolo, and Tabossi, 2001; Miceli, Silveri, Vil-
la, and Caramazza, 1984; Miceli, Silveri, Nocen-
tini, and Caramazza, 1988). 
An influential hypothesis states that the gram-
matical class is an organizing principle in the 
mental lexicon (Caramazza and Hillis, 1991) but 
the picture of empirical data is actually multifac-
eted and often inconsistent (for a review, see 
Vigliocco, Vinson, Druks, Barber, and Cappa, 
2011). 
For the sake of conciseness, here we focus on 
two examples of alternative interpretations about 
the role of grammatical class in lexical represen-
tation and processing of words. 
A first position, mostly grounded on word pro-
duction 
data 
(Pechmann, 
Garrett, 
and 
Zerbst, 
2004; Pechmann and Zerbst, 2002; Vigliocco, 
Vinson, and Siri, 2005), is that grammatical class 
information, although lexically represented, is 
CLIC_2016_Proceedings.indd 195
02/12/16 15.04
196
only 
retrieved 
under 
specific 
circumstances, 
namely in sentence or phrasal contexts (Levelt, 
Roelofs, and Meyer, 1999; Garrett, 1982). How-
ever, grammatical class effects are significantly 
reported in word production even in tasks not 
requiring 
syntactic 
integration 
(Mahon, 
Costa, 
Peterson, 
Vargas, 
and 
Caramazza, 
2007; 
De 
Simone and Collina, 2016). A stronger lexicalist 
view is held in the field of recognition and com-
prehension processes and conceives grammatical 
class as a feature of words that is automatically 
retrieved during lexical access. Comparisons be-
tween noun/verb homographs (
condannato
N 
(the convict) vs. 
condannato
V (past participle, 
convicted), Postiglione and Laudanna, 2016) and 
homonymic nominal and verbal forms (
saliva
N, 
spittle vs. 
saliva
V, he/she went up, Mancuso and 
Laudanna, 
2013) 
revealed 
the 
possibility 
that 
separate, grammatical class-specific representa-
tions are present in the lexicon. Also in this case, 
different patterns of data have been described 
(Vigliocco, Vinson, Arciuli and Barber, 2008). 
A possible reason for such a divergence relies on 
the fact that grammatical class effects are often 
not clearly distinguishable from the influence of 
confounding variables, i.e. the imageability of 
words, the number of inflectional alternatives for 
nominal and verbal stems, the argumental struc-
ture of nouns and verbs and so on. A challenging 
issue is that noun/verb distinction is not lexical in 
nature but relies on an object/action distinction 
(Vigliocco et al., 2005). 
Here we aim at verifying whether lexical access 
to input orthographic representations of Italian 
verbs can be affected by the pre-activation of 
grammatical 
class 
information. 
The 
semantic 
priming 
paradigm 
was 
exploited 
and 
the 
ex-
pected facilitation effect on target verbs elicited 
by semantically 
related primes was compared 
across prime/target pairs sharing or not grammat-
ical class information, i.e., noun/verb pairs vs. 
verb/verb pairs. In order to disentangle the possi-
ble confound between grammatical class (nouns 
vs. verbs) and semantic categories which nouns 
and verbs belong to (objects vs. actions), two 
different types of noun-verb pairs were used: 
object nouns denoting objects (
candela
, candle) 
vs. nouns denoting actions (
sberla
, slap). 
We reasoned as follows: if grammatical class 
informs 
input 
orthographic 
representations 
of 
words, its pre-activation through primes should 
speed up targets recognition even in a lexical 
decision task where any process of syntactic in-
tegration is not involved. On the contrary, se-
mantic priming effects are expected to equally 
affect prime/target pairs regardless their gram-
matical relation. No interaction between gram-
matical class and semantic relation is expected 
because the two variables are supposed to affect 
lexical selection with distinct modalities (Yudes, 
Domínguez, Cuetos, and de Vega, 2016). 
2
Experiment 
2.1
Method 
Participants
: Seventy-six undergraduate stu-
dents (36 females) from University of Salerno 
voluntarily took part in the experiment. They 
were 
all 
native 
speakers 
of 
Italian, 
free 
of 
speech-language and hearing disorders and they 
all 
had 
normal 
or 
corrected-to-normal 
vision. 
Their age ranged from 18 to 31 years (AV: 22 
years). They served for a session lasting about 30 
minutes. Each pair of participants constituted one 
data point in the statistical analyses. 
Materials: Sixty Italian unambiguous verbs 
were selected as targets and subdivided into 3 
lists on the basis of the type of prime word 
adopted: 
1.
Object Noun/Verb Condition, ON/V: 20 
targets 
were 
preceded 
by 
semantically 
related 
object 
nouns 
(
bottega
/
acquista
, 
atelier/he-she buys); 
2.
Action Noun/Verb Condition, AN/V: 20 
targets 
were 
preceded by 
semantically 
related 
action 
nouns 
(
furto
/
ruba
, 
theft/he-she steals); 
3.
Verb/Verb 
Condition, 
V/V: 
20 
targets 
were preceded by semantically related 
verbs (
colpiva
/
spara
, he-she struck/he-
she fires). 
The semantic distance between prime and target 
was calculated on the basis of an off-line rating 
(on a 7-points Likert scale), previously submitted 
to 54 participants (who did not take part into the 
experiment) and balanced among conditions. 
Each experimental list was matched with a con-
trol list: 
1.
Object 
Noun/Verb 
Control 
Condition, 
ON/V
C
: 20 targets were preceded by un-
related object nouns (
polmone/acquista
, 
lung/he-she buys); 
2.
Action 
Noun/Verb 
Control 
Condition, 
AN/V
C
: 20 targets were preceded by un-
related action nouns (
dormita/ruba
, the 
sleep/he-she steals); 
3.
Verb/Verb Control Condition, V/V
C
: 20 
targets
were preceded by unrelated verbs 
(
variava/spara
, 
he 
modified 
/he-she 
fires). 
CLIC_2016_Proceedings.indd 196
02/12/16 15.04
197
Targets of the three lists were matched for the 
following variables: 
- 
cumulative written frequency of the verb 
paradigm; 
- 
written form frequency; 
- 
length calculated in number of letters; 
- 
lexical decision latencies and percentage 
errors
1
. 
The mean values for the controlled parameters of 
targets are shown in Table 1. 
Paradigm 
Frequency 
Form 
Frequency 
Length 
LD 
latencies 
LD 
%errors 
ON/V 
236 
27 
6.8 
551ms 
4% 
AN/V 
V/V 
248 
238 
23 
28 
6.4 
6.5 
545ms 
553ms 
6% 
5% 
Table 1. Summary of targets characteristics 
Primes of the both experimental and control lists 
were matched for: 
- 
written form frequency; 
- 
length calculated in number of letters. 
The mean values for the controlled parameters of 
primes are shown in Table 2. Values for frequen-
cy were taken from the CoLFIS database (Ber-
tinetto, 
Burani, 
Laudanna, 
Marconi, 
Ratti, 
Rolando & Thornton, 2005). 
Form 
frequency 
(related 
prime) 
Length 
(related 
prime) 
Form 
frequency 
(unrelated 
prime) 
Length 
(unrelated 
prime) 
Prime/target 
Semantic 
distance 
ON/V 
20 
6.1 
17 
6.2 
5.5 
AN/V 
V/V 
16 
16 
7 
7.4 
17 
11 
7 
7.7 
5.3 
5.2 
Table 2. Summary of primes characteristics 
Procedure: 
The participants were tested indi-
vidually; an experimental session consisted of 
two parts: a practice and an experimental phase. 
A semantic priming lexical decision task was 
used as experimental paradigm. Participants were 
1
Prior to the study, a simple visual lexical decision experi-
ment was administered to 35 participants (who did not take 
part into the priming experiment), in order to verify whether 
targets of the three conditions were exactly balanced with 
each other. 
asked to be as fast and accurate as possible. They 
had to press on two buttons: the button corre-
sponding to their dominant hand for the decision 
‘word’, the other for the decision ‘non-word’. 
Stimuli appeared in lower case letters (12-point 
size) in the center of the computer screen. Each 
experimental 
trial 
was 
composed 
by: 
fixation 
point (200 ms), blank (300 ms), prime (200 ms), 
blank (50 ms), target (1 sec). If the participant 
did not respond within 1000 ms, the feedback 
“Fuori tempo”
(out of time) was given and the 
trial was recorded as an error. Following the par-
ticipant’s response (or non-response), the next 
trial was presented after a delay of 1 sec. 
Reaction times (ms) and accuracy constituted the 
dependent variables. 
Equipment: 
Response box, connected to a PC 
running the E-Prime software 2.0 (Psychology 
Software Tools, Inc., Pittsburgh, PA). 
2.2
Results 
A repeated measures ANOVA was performed 
on the averaged correct response latencies and on 
errors with the Condition (two levels (i.e., se-
mantically related vs. unrelated) and the Experi-
mental List (3 levels, ON/V, AN/V and V/V) as 
variables. Separate analyses were carried out for 
participants and items, yielding F1 and F2 statis-
tics, respectively. 
Data 
from 
two 
items 
(
bombarda
(he/she 
bombs) and 
contagia
(he/she infects) were ex-
cluded from the analyses because they elicited a 
number of errors exceeding the sample’s mean 
more than 2.5 standard deviations. 
Data on reaction times (reported in Table 3) 
revealed significant main effects of Condition 
[F1(1,75)=21.3, p<.01; F2(1, 55)=5,73, p<.05] 
and Experimental List [F1(2,150)=21.6, p<.01; 
F2(2, 55)=1.2, p<.1]. 
No significant interaction between the two var-
iables was observed. 
Interestingly, 
planned 
comparisons 
revealed 
that 
the 
observ
ed 
semantic 
priming 
effect 
is 
mainly 
elicited 
by 
prime/target 
pairs 
sharing 
grammatical class information: V/V Condition 
(p<.05). On the contrary, both conditions where 
primes 
do not 
share 
grammatical 
class 
infor-
mation with the targets (i.e.,
AN/V 
and ON/V) 
exhibit a weak semantic priming not reaching 
statistical significance. 
CLIC_2016_Proceedings.indd 197
02/12/16 15.04
198
Condition 
ON/V 
AN/V 
V/V 
Overall 
Related 
554 
(-5) 
545 
(-12) 
562 
(-18)** 
554 
(-11) 
Unrelated 
559 
557 
580 
565 
Table 3. Correct lexical decision response latencies as a 
function of the Condition and Experimental List 
On accuracy data (reported in Table 4) only a 
significant effect of the Experimental List was 
detected [
F1
(2,250) = 10.53, p< .01; 
F2
(2, 55) = 
3.98, p <.02]. 
Condition 
ON/V 
AN/V 
V/V 
Overall 
Related 
1.8% 
1.5% 
2.6% 
2% 
Unrelated 
1.6% 
1.6% 
3.2% 
2.1% 
Table 4. Lexical decision percentage of errors as a function 
of Condition and Experimental List 
3
Conclusion 
Our 
purpose 
here 
was 
to 
clarify 
whether 
grammatical 
class 
works 
as 
an 
organizational 
criterion of word representations within the men-
tal lexicon. In particular, we aimed at demon-
strating that words from different grammatical 
classes 
tend 
to 
be 
processed 
differently 
by 
speakers not only because of their differences in 
terms of semantic categories they belong to (ac-
tions vs. objects) or of semantic features (image-
ability) but also because their lexical representa-
tions 
specify 
their 
role 
as 
different 
parts 
of 
speech. 
From an empirical point of view, our purpose 
was to verify: 
- whether grammatical class information is au-
tomatically activated when orthographic repre-
sentations of Italian verbs are accessed; 
- whether grammatical class effects can be de-
tected in tasks that do not explicitly require syn-
tactic integration processes, that is during the 
processing of isolated words; 
- whether grammatical class effects are an epi-
phenomenon of the semantic categories to which 
nouns and verbs belong to or if they are truly 
grammatical in nature. 
We addressed the issue by exploiting the se-
mantic priming effect, a robust and well-known 
effect in word recognition consisting in the ad-
vantage in lexical decision tasks exhibited by 
target words when preceded by semantically re-
lated primes and compared to an unrelated base-
line. 
Our experimental design was suitable to inves-
tigate the problem for two main reasons: 
-
it allows to pre-activate a definite lin-
guistic 
feature, 
i.e. 
grammatical 
class 
(nouns vs. verbs) information and/or a 
semantic category (actions vs. objects), 
and to observe whether such a property 
can affect word processing; 
-
it rules out the intervention of any con-
found due to syntactic integration pro-
cess because it focus
es on lexical access 
to single word representations. 
With that aim, we manipulated the congruency of 
grammatical 
class 
in 
different 
kinds 
of 
prime/target pairs. The rationale of the experi-
ment was the following: if gram
matical class 
informs lexical representation of words, its pre-
activation through the prime should modulate the 
expected effects of semantic priming. 
In order to specifically disentangle the role of 
grammatical class from the influence of semantic 
category of referents of nouns and verbs, we ob-
served the effect in different conditions: gram-
matically 
congru
ent 
prime/target 
pairs, 
prime/target pairs from incongruent grammatical 
classes but both belonging to the semantic cate-
gory of actions, and prime/target pairs from in-
congruent grammatical classes and different se-
mantic categories (objects for nouns and actions 
for verbs). 
Our results showed that semantic priming is ef-
fective only for prime/target pairs sharing gram-
matical class information; much weaker effects 
were detected for noun/verb pairs, 
regardless of 
the semantic category of the referents. 
This 
patt
ern 
of 
data 
seems 
to 
indicate 
that 
grammatical class informs lexical representations 
in the orthographic input lexicon since its pre-
activation through the prime modulates the ex-
pected facilitation induced by semantically relat-
ed primes. In other words, gr
ammatical class is 
likely to be automatically activated during lexical 
access to written repr
esentation of Italian verbs 
and, in addition, it is effective during processing 
of verbal forms presented outside a sentence con-
text. This effect seems to have a truly grammati-
cal basis as it is not elicited by grammatically 
incongruent prime/target pairs. Moreover, in our 
experiment the congruency of grammatical class 
between prime and target does not interact with 
the semantic similarity between 
prime and target: 
CLIC_2016_Proceedings.indd 198
02/12/16 15.04
199
this suggests that the two sources of information 
affect the word recognition process with distinct 
modalities. 
This 
pattern 
of 
data, 
although 
preliminary, 
adds new challenging details to the debate about 
lexical representation of grammatical class in-
formation and provides evidence in favor of the 
lexicalist models that conceive grammatical class 
as an intrinsic property of the lexical representa-
tion 
consulted 
during 
lexical 
access 
which 
is 
necessarily and automatically accessed at least 
during written word recognition processes. 
Reference 
Bertinetto, P. M., Burani, C., Laudanna, A., Marconi, 
L., Ratti, D., Rolando, C., and Thornton, A. M. 
2005. 
Corpus e Lessico di Frequenza dell’Italiano 
Scritto 
(CoLFIS)
. 
http://linguistica.sns.it/CoLFIS/Home.htm 
Caramazza, A. and Hillis, A. E. 1991. Lexical organi-
zation of nouns and verbs in the brain. 
Nature
, 
349(6312):788-790. 
Collina, S., Marangolo, P., and Tabossi, P. 2001. The 
role of argument structure in the production of 
nouns and verbs. 
Neuropsychologia
, 39(11):1125-
1137. 
De Simone, F. and Collina, S. 2016. The Picture–
Word Interference Paradigm: Grammatical Class 
Effects in Lexical Production. 
Journal of Psycho-
lingustic Research, 
45(5):1003-19. 
Garrett, M. F. 1982. Production of speech: Observa-
tions from normal and pathological use. In A. W. 
Ellis (Ed.), 
Normality and pathology in cognitive 
functions
. Academic Press, London. 
Levelt, W. J., Roelofs, A., and Meyer, A. S. 1999. A 
theory of lexical access in speech production. 
Be-
havioral and brain sciences
, 22(01):1-38. 
Mahon, B. Z., Costa, A., Peterson, R., Vargas, K. A., 
and Caramazza, A. 2007. Lexical selection is not 
by competition: a reinterpretation of semantic in-
terference and facilitation effects in the picture-
word 
interference 
paradigm. 
Journal 
of 
Experi-
mental Psychology: Learning, Memory, and Cog-
nition,
33(3):503-535. 
Mancuso, A. and Laudanna, A. 2013. Revisiting the 
ambiguity 
effect 
in 
word 
recognition: 
part 
of 
speech and meaning dominance effects. 
Proceed-
ings of AMLaP, Architectures and Mechanisms for 
Language 
Processing
, 
Marseille, 
2-4 
September 
2013. 
Miceli, G., Silveri, M. C., Nocentini, U., and Cara-
mazza, A. 1988. Patterns of dissociation in com-
prehension 
and 
production 
of 
nouns 
and 
verbs. 
Aphasiology
, 2(3-4):351-358. 
Miceli, G., Silveri, M. C., Villa, G., and Caramazza, 
A. 1984. On the basis for the agrammatic's difficul-
ty in producing main verbs. 
Cortex
, 20(2):207-220. 
Pechmann, T. and Zerbst, D. 2002. The activation of 
word class information during speech production. 
Journal 
of 
Experimental 
Psychology: 
Learning, 
Memory, and Cognition,
28(1):233-243. 
Pechmann, T., Garrett, M., and Zerbst, D. 2004. The 
time course of recovery for grammatical category 
information during lexical processing for syntactic 
construction. 
Journal of Experimental Psychology: 
Learning, Memory, and Cognition
, 30(3):723-728. 
Postiglione, F. and Laudanna, A. 2016. Competition 
in lexical processing of Italian noun/verb homo-
graphs. 
Journal of Cognitive Psychology
, 28:1-16. 
Sapir, 
E. 
1921. 
Language. An 
Introduction 
to 
the 
Study of Speech
. Harcout, Brace, New York. 
Yudes, C., Domínguez, A., Cuetos, F., and de Vega, 
M. 2016. The time-course of processing of gram-
matical class and semantic attributes of words: Dis-
sociation 
by 
means 
of 
ERP. 
Psicológica
, 
37(2):105-126. 
Vigliocco, G., Vinson, D. P., and Siri, S. 2005. Se-
mantic similarity and grammatical class in naming 
actions. 
Cognition
, 94(3):91-100. 
Vigliocco, G., Vinson, D. P., Arciuli, J., and Barber, 
H. 2008. The role of grammatical class on word 
recognition. 
Brain and language
, 105(3):175-184. 
Vigliocco, G., Vinson, D. P., Druks, J., Barber, H., 
and Cappa, S. F. 2011. Nouns and verbs in the 
brain: a review of behavioral, electrophysiological, 
neuropsychological and imaging studies. 
Neurosci-
ence & Biobehavioral Reviews
, 35(3):407-426.
CLIC_2016_Proceedings.indd 199
02/12/16 15.04
200
Building a computational lexicon by using SQL
Alessandro Mazzei
Dipartimento di Informatica
Universit degli Studi di Torino
Corso Svizzera 185, 10149 Torino
mazzei@di.unito.it
Abstract
English.
This paper presents some issues
about
a computational
lexicon employed
in a generation system for Italian (Mazzei
et
al.,
2016).
The paper has three goals:
(i) to describe the SQL resources produced
during the construction of the lexicon; (ii)
to describe the algorithm for building the
lexicon;
(iii) to present
an ongoing work
for enhancing the lexicon by using the syn-
tactic information extracted from a tree-
bank.
Italiano.
Questo
lavoro
descrive
la
costruzione
di
un
lessico
com-
putazionale
per
la
generazione
auto-
matica dell’italiano (Mazzei et al., 2016).
Il
lavoro ha tre obiettivi:
(i)
descrivere
alcune risorse SQL prodotte funzional-
mente alla costruzione del
lessico;
(ii)
descrivere l’algoritmo per la costruzione
del
lessico;
(iii) presentare un lavoro in
divenire per migliorare il lessico che usa
l’informazione sintattica estratta da un
treebank.
1
Introduction
A number of free large multilingual resources cov-
ering Italian have been released, e.g.
MultiWord-
net,
UniversalWordnet,
BabelNet
(Pianta et
al.,
2002;
de Melo and Weikum,
2009;
Navigli
and
Ponzetto,
2012).
Moreover,
several
lexical
cor-
pora have been built specifically for Italian, as the
detailed map of
the Italian NLP resources pro-
duced within the PARLI project shows
1
.
Unfor-
tunately most resources are designed to represent
lexical semantics rather than morpho-syntactic re-
lations among the words. As a consequence, these
1
http://parli.di.unito.it/resources_
en.html
resources cannot be employed in statistical or rule-
based natural
language morho-syntactic analyzer
or generator.
A notable exception is the PAROLE-SIMPLE-
CLIPS lexicon, that is a four-level (i.e. phonologi-
cal, morphological, syntactical, semantic) general
purpose lexicon composed by
53
,
044
lemmata
(Ruimy et al., 1998).
Unfortunately, a strong lim-
itation for the usage of PAROLE-SIMPLE-CLIPS
is the licence,
since it
is not
freely available for
research or commercial use.
Rule-based
natural
language
realization
en-
gines,
that
are
systems
performing
linearisa-
tion and morphological
inflections
of
a proto-
syntactic input tree (Gatt and Reiter,
2009),
need
wide coverage morpho-syntactic information as
knowledge-base.
In other words,
to perform re-
alization,
that is the last step of natural language
generation (Reiter and Dale, 2000), one needs two
main kinds of linguistic knowledge:
(i) the gram-
matical/syntactical
knowledge that
specifies the
syntactic rules of the language and which is usu-
ally encoded into formal rules; (ii) the morpholog-
ical
and lexical
knowledge,
which is usually en-
coded into a computational lexicon.
In the port-
ing of the SimpleNLG system to Italian (hence-
forth SimpleNLG-IT)
(Mazzei
et
al.,
2016),
we
have used the grammar (Patota,
2006) as the lin-
guistic reference for the syntax: we have encoded
the Italian syntactic inflections and word ordering
by using IF-THEN-ELSE rules in Java.
However,
since Italian has a high number of irregularities
for verb and adjective inflections,
we needed for
a specifically designed computational lexicon too.
We needed for a lexicon that has both a good cov-
erage and a detailed account of the morphological
irregularities.
In order to build this specific lexicon,
that we
have called SimpleLEX-IT,
we have decided to
merge three free resources
for
Italian,
namely
Morph-it!
(Zanchetta and Baroni,
2005),
the Vo-
CLIC_2016_Proceedings.indd 200
02/12/16 15.04
201
cabolario di base della lingua italiana (De Mauro,
1985) and,
for some specific issues,
Wikipedia.
The differences between the three resources can be
referred to both the reasons for which the authors
developed them and the adopted methodology and
approach they applied in their development:
the
first is a hand-made list of basic words; the second
one is an extensional corpus based morphological
lexicon; the third one is a collection of encyclope-
dic entries about irregular verbs in Italian.
This paper is organized as follows: in Section 2
we describe the conversion of the three lexical re-
sources used into a relational
database;
in Sec-
tion 3 we provide some details about the algorithm
used to build SimpleLEX-IT; in Section 4 we de-
scribe a work in progress to enrich the lexicon by
using the syntactic information extracted from a
treebank;
finally,
Section 5 closes the paper with
conclusions.
2
Using relational database for
representing linguistic data
In order to merge different
lexical
resources we
needed to convert
them in a common compu-
tational
representation.
We
used a
relational
database
2
(SQL henceforth) since all the three re-
sources are originally provided as text files, orga-
nized as tables or simple list.
The first
resource that
we exploited for popu-
lating SimpleLEX-IT is Morph-it! (Zanchetta and
Baroni, 2005). The dataset released in the Morph-
it! project consists of a lexicon organized accord-
ing to the inflected word forms,
with associated
lemmas and morphological features.
The lexicon
is provided by the authors as a text file where the
values of the information about
each lexical
en-
try are separated by a tab key.
It is an alphabet-
ically ordered list of triples form-lemma-features.
An example of the annotation for the form corsi
(ran) is:
corsi correre-VER:ind past+1+s
where the features are the part
of speech (PoS,
VERb),
the mood of
the verb (indicative),
the
tense (past),
the person (1),
and the number
(singular).
The last
released version of Morph-
it!
(v.48,
2009-02-23) contains
505
,
074
differ-
ent
forms corresponding to
35
,
056
lemmas.
It
has been realized starting from a large newspa-
per corpus,
nevertheless it
is not
balanced and a
2
We used the PostgreSQL database .
small number of also very common Italian words
are not included in the lexicon, e.g.
sposa (bride),
ovest (west) or aceto (vinegar).
Morph-it!
repre-
sents extensionally the Italian language by listing
all
the morphological
inflections,
i.e.
adjective,
verbs,
nouns inflections are represented as a list
rather than by using morphological rules. We con-
verted Morph-it! in SQL by exploiting its original
feature structure:
we used one single attribute to
represent one single feature
3
.
We used one table
to collect all the lemmata and seven tables, with a
different number of attributes,
to collect the vari-
ous inflected forms:
•
the table lemmata is formed by
3
attributes:
a
lemma,
its PoS and its ID (integer).
This table
contains
34
,
725
records. A number of lemmata
belonging to the original
version of Morph-it!
have been excluded in our conversion:
proper
nouns, emoticons and cardinals beginning with
a digit (e.g. 15mila).
•
the
tables
det
demo table,
pro demo table,
pronou table are used to collect inflected form
of
demonstrative determiners (
116
records,
4
attributes:
ID word,
form,
ID lemma,
number,
gender),
demonstrative pronouns (
95
records,
5
attributes:
ID word,
form,
ID lemma,
num-
ber,
gender),
personal pronouns (
63
records,
7
attributes:
ID word,
form,
ID lemma,
person,
number, gender, clitics).
•
the
tables
adv table,
adj table,
nou table,
ver table are used to collect
inflected form of
adverbs (
1
,
594
records,
3
attributes:
ID word,
form,
ID lemma),
adjectives (
72
,
367
records,
6
attributes:
ID word,
form,
ID lemma,
kind,
number,
gender),
nouns
(
35
,
618
records,
5
attributes:
ID word,
form,
ID lemma,
num-
ber,
gender) and verbs (
392
,
139
,
8
attributes:
records: ID word, form, ID lemma, mode, time,
person, number, gender) respectively.
The second resource we exploited for
popu-
lating SimpleLEX-IT is the “Vocabolario di base
della lingua italiana” (VdB-IT henceforth),
a col-
lection of around
7
,
000
words created by the lin-
guist Tullio De Mauro and his team
4
(De Mauro,
1985).
The development
of this vocabulary has
been mainly driven by the distinction between the
3
Morph-IT! is provided with a script
that
allows for a
naive conversion into SQL that use one single table and one
single attribute for all the features.
4
The second edition of
the vocabulary has
been an-
nounced (Chiari and De Mauro,
2014) and it is going to be
released (p.c.).
CLIC_2016_Proceedings.indd 201
02/12/16 15.04
202
most frequent words (around
5
.
000
) and the most
familiar words (around
2
.
000
).
VdB-IT is there-
fore organized in the following three sections:
•
the vocabolario fondamentale (fundamental vo-
cabulary), which contains
2
,
000
words featured
by the highest
frequency into a balanced cor-
pus of Italian texts (composed of novels, movie
and theater scripts,
newspapers,
basic scholas-
tic books);
amore (love),
lavoro (work),
pane
(bread) are in this section.
•
the vocabolario di alto uso (vocabulary of high
usage), which includes other
2
,
937
words with
high frequency, but lesser than the vocabolario
fondamentale; ala (wing), seta (silk), toro (bull)
are in this section
•
the vocabolario di
alta disponibilit
`
a (vocabu-
lary of high availability), is composed of
1
,
753
words not
often used in written language,
but
featured by a high frequency in spoken lan-
guage, which are indeed perceived as especially
familiar by native speakers; aglio (garlic),
cas-
cata (waterfall),
passeggero (passenger) are in
this section.
The list of lemmata of VdB has been converted in
SQL by using one single table, called lemmadema
(
6540
records), which have two attributes, i.e.
an
ID (integer) and the lemma.
The third resource that
we used for
the lexi-
con creation is Wikipedia. Our reference grammar
(Patota, 2006) reports a partial list of the principal
Italian irregular verbs,
but we decided to use the
larger list of verbs reported in Wikipedia
5
(VerIrr
henceforth). Another linguistic distinction for Ital-
ian verbs reported in Wikipedia
6
(VerInc hence-
forth) has been exploited in the lexicon:
the in-
coativi verbs are a subclass of the third conjuga-
tion that have a special behavior in the present time
(e.g.
capire).
So,
in order to produce the correct
conjugation of these verbs in SimpleNLG-IT, they
needed to be marked in the lexicon.
Both these
lists of verbs have been converted in SQL by using
two distinct tables which have two attributes,
i.e.
an ID (integer) and the verb in the infinitive form.
The two tables are verbiirregolari
(
858
records)
and verbiincoativi (
726
records).
A notable advantage of the SQL representation
for linguistic resources is the possibility to extract
intrinsic information with simple queries.
Indeed,
5
https://it.wikipedia.org/wiki/Verbi_
irregolari_italiani
6
https://it.wikipedia.org/wiki/Verbi_
incoativi
we found that
Morph-it!
and VdB share
4
,
086
nouns and
1
,
448
verbs, but there are
245
lemmas
belonging to VdD and not belonging to Morph-it!:
most of these words are nouns, for instance lava-
piatti, chimica, incinta, but we found too a system-
atic difference for verbs.
Indeed, VdB consider as
proper reflexive a number of verbs,
for instance
avvantaggiarsi, sdraiarsi.
In contrast, these verbs
are are treated as improper reflexive in Morph-
it!, which annotates avvantaggiare and sdraiare as
their lemmata.
3
Building SimpleLEX-IT 1.0
In this section we describe the algorithm used
to build the computational
lexicon SimpleLEX-
IT,
which is
based on the three resources
de-
scribed in the Section 2,
and that
has been used
in SimpleNLG-IT.
A computational lexicon can be split in two ma-
jor classes:
open and closed classes.
The closed
class, that are usually composed by function words
(i.e.
prepositions, determiners, conjunctions, pro-
nouns,
etc.)
is one to which new words are very
rarely added.
In contrast,
the open classes,
that
is usually composed by lexical words (i.e.
nouns,
verbs, adjectives, adverbs), accept the addition of
new words.
We adopted the same strategy of
(Vaudry and Lapalme,
2013):
we built
by hand
the closed part of the Italian lexicon and we built
automatically the open part by using the available
resources.
In order to build the open class for SimpleLEX-
IT we needed both a large coverage and a detailed
account of morphological irregularities, also con-
sidering their
high frequency in Italian.
More-
over,
in order to have good time execution per-
formance in the realiser
(cf.
(De Oliveira and
Sripada,
2014)),
a trade-off between the size of
the lexicon and its usability for
our
task must
be achieved,
which consists in assuming a form
of word classification where fundamental
Italian
words are distinguished from the less-fundamental
ones.
In order to balance completeness and effi-
ciency in SimpleLEX-IT, we put in the lexicon the
open classes words belonging to the intersection
of VdB-IT and Morph-it!.
We reported in Algorithm 1 the process used
for the insertion and the annotation of the words
belonging to the open classes in SimpleLEX-IT.
Note that
in order to recognize proper reflexive
verbs,
we check if the infinitive form of the verb
CLIC_2016_Proceedings.indd 202
02/12/16 15.04
203
foreach adverb ∈ Morph-it! ∩ VdB-IT do
Add the adverb in normal form into SimpleLEX-IT
end
foreach adjective ∈ Morph-it! ∩ VdB-IT do
Add the adjective in normal form (masculine-singular) and in
feminine-singular, masculine-plural, feminine-plural forms, into
SimpleLEX-IT
end
foreach noun ∈ Morph-it! ∩ VdB-IT do
Add the noun in normal form (singular), the plural form, and the
gender into SimpleLEX-IT
end
foreach verb ∈ Morph-it! ∩ VdB-IT do
if verb ∈ VerIrr then
Add all the inflections for the indicativo presente,
congiuntivo presente, futuro semplice, condizionale,
imperfetto, participio passato, passato remoto into
SimpleLEX-IT
else
if verb ∈ VerInc then
Set active the incoativo feature in the entry
end
if the verb is properly reflexive (i.e. ”...rsi”) then
Set active the reflexive feature in the entry
end
Add the verb in normal form into SimpleLEX-IT
end
end
Algorithm 1:
The
algorithm for
building
the
adverbs,
adjectives,
nouns
and verbs
in
SimpleLEX-IT
has the postfix “rsi”, since MorphIT! contains this
inflection as its normal
form.
In Table 1 we re-
ported some statistics about SimpleLEX-IT com-
position.
Most
of
the lexicon is composed by
nouns (
58%
), followed by verbs (
21%
), adjectives
(
19%
), and adverbs (
2%
).
PoS
Number
%
Adverb
146
2
Verb (irr.)
283
4
Verb (reg.)
1168
17
Adjective
1333
19
Noun
4092
58
Total
7022
100
Table 1: Number of adverbs, adjectives, nouns and
verbs in SimpleLEX-IT.
4
Work in Progress: adding information
from a treebank
The Universal Dependency Treebank (UDT) is a
recent
project
that
releases freely available tree-
banks for
33
languages (in this work, version 1.2)
(Nivre et al., 2016). Each UDT is split in three sec-
tions, train, dev and test, which can be exploited in
the evaluation of NLP/NLG systems.
We are working on the idea of adding more in-
formation in SimpleLEX-IT by using UDT-IT, i.e.
the Italian section of UDT. A specific case that we
are currently considering regards auxiliary verbs.
The current
version of SimpleNLG-IT does not
manage auxiliary verbs: in order to produce some
complex verb tense,
e.g.
passato prossimo,
the
user needs to give in input to the realiser the cor-
rect auxiliary, i.e.
essere (to be, e.g.
Io sono nato
a Napoli) or avere (to have,
e.g.
Io ho amato la
scuola.).
Our reference grammar reports complex
rules based on lexical semantics in order to choose
the correct auxiliary verb and, unfortunately, these
rules have many exceptions. So, we can use UDT-
IT to empirically decide the correct
auxiliary in
SimpleNLG-IT.
By following this idea,
we con-
verted UDT-IT in SQL by exploiting its original
feature structuree.
We used one table to collect
information about the sentences, and one table to
collect information about the words:
•
the table sentence
ud is formed by
4
attributes:
an ID (integer), the original treebank (i.e.
TUT,
ISST,
etc.),
the original
ID,
the section (i.e.
DEV, TRAIN, TEST).
•
the table words ud is used to collect
all
the
words of the UDT-IT. It uses
21
attributes:
one
attribute id sentence, contains the id of the sen-
tence in the table sentence ud, and
20
attributes
correspond to the featured used in the UD anno-
tation.
In order to find the correct auxiliary for a specific
verb in UDT-IT,
we need to exclude passive,
re-
flexive and modal verb constructions in the query.
We found
512
verbs of
SimpleLEX-IT that
are
used in UDT-IT with an auxiliary.
It is interesting
to note that
60
verbs are used both with the aux-
iliary essere and with the auxiliary avere:
this is
grammatical for some verbs (e.g. vivere), but more
often we found an annotation error in the UDT-IT.
Finally, note that another possible use of UDT-
IT regards the evaluation of the lexicon.
In fu-
ture work we plan to quantify the coverage of
SimpleLEX-IT by using the TEST section of the
UDT-IT.
5
Conclusions
In this paper we have presented some issues about
the computational lexicon SimpleLEX-IT. We de-
scribed the algorithm used to build the lexicon,
three SQL resources produced as side effects of
the lexicon building and a work in progress about
the extraction of syntactic information from UD-
IT.
All
the resources described in this paper
can
be
downloaded
at
https://github.com/
alexmazzei/SimpleLEX-IT.
CLIC_2016_Proceedings.indd 203
02/12/16 15.04
204
References
Isabella Chiari and Tullio De Mauro.
2014.
The New
Basic Vocabulary of Italian as a linguistic resource.
In Roberto Basili,
Alessandro Lenci,
and Bernardo
Magnini, editors, 1th Italian Conference on Compu-
tational Linguistics (CLiC-it), volume 1, pages 93–
97. Pisa University Press, December.
Tullio De Mauro.
1985.
Guida all’uso delle parole.
Libri di base. Editori Riuniti.
Gerard de Melo and Gerhard Weikum.
2009.
Towards
a universal wordnet by learning from combined evi-
dence.
In Proceedings of the 18th ACM Conference
on Information and Knowledge Management (CIKM
2009), pages 513–522, New York, NY, USA. ACM.
Rodrigo De Oliveira and Somayajulu Sripada.
2014.
Adapting simplenlg for brazilian portuguese realisa-
tion.
In Proc. of INLG 2014.
Albert
Gatt
and Ehud Reiter.
2009.
SimpleNLG:
A
Realisation Engine for Practical
Applications.
In
Proc. of ENLG 2009, ENLG ’09.
Alessandro Mazzei,
Cristina Battaglino,
and Cristina
Bosco.
2016.
SimpleNLG-IT:
adapting Sim-
pleNLG to Italian.
In Proc. of INLG 2016.
TO AP-
PEAR.
Roberto Navigli
and Simone Paolo Ponzetto.
2012.
BabelNet:
The automatic construction,
evaluation
and application of a wide-coverage multilingual se-
mantic network.
Artificial
Intelligence,
193:217–
250.
Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin-
ter, Yoav Goldberg, Jan Hajic, Christopher D. Man-
ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,
Natalia Silveira,
Reut Tsarfaty,
and Daniel Zeman.
2016.
Universal
Dependencies v1:A Multilingual
Treebank Collection.
In Proc.
of
LREC’16,
may.
TO APPEAR.
Giuseppe Patota.
2006.
Grammatica di
riferimento
dell’italiano contemporaneo.
Guide linguistiche.
Garzanti Linguistica.
Emanuele Pianta,
Luisa Bentivogli,
and Christian Gi-
rardi.
2002.
Multiwordnet:
developing an aligned
multilingual
database.
In Proceedings of
the First
International Conference on Global WordNet,
Jan-
uary.
Ehud Reiter and Robert Dale.
2000.
Building Natural
Language Generation Systems.
Cambridge Univer-
sity Press, New York, NY, USA.
Nilda Ruimy,
Ornella Corazzari,
Elisabetta Gola,
An-
tonietta Spanu,
Nicoletta Calzolari,
and Antonio
Zampolli.
1998.
The European LE-PAROLE
project:
the Italian Syntactic Lexicon.
In Proceed-
ings of the First International Conference on Lan-
guage resources and Evaluation , pages 241–248.
Pierre-Luc Vaudry and Guy Lapalme.
2013.
Adapt-
ing simplenlg for bilingual
english-french realisa-
tion.
In Proc. of ENLG 2013.
Eros Zanchetta and Marco Baroni.
2005.
Morph-it!
a free corpus-based morphological resource for the
italian language.
Corpus Linguistics 2005, 1(1).
CLIC_2016_Proceedings.indd 204
02/12/16 15.04
205
Semantic Interpretation of Events in Live Soccer Commentaries
Anne-Lyse Minard
1,2
, Manuela Speranza
1
, Bernardo Magnini
1
, Mohammed R. H. Qwaider
1
1
Fondazione Bruno Kessler, Trento, Italy
2
Dept. of Information Engineering, University of Brescia, Italy
{
minard,manspera,magnini,qwaider
}
@fbk.eu
Abstract
English.
In the context of semantic inter-
pretation of live soccer commentaries in
Italian,
we propose an annotation schema
for
relevant
events
and their
argument
structure,
on whose basis we annotated a
reference evaluation corpus.
We inves-
tigated automatic event classification and
used Active Learning to reduce the cost of
acquiring domain-specific training data.
Italiano. Nel contesto dell’interpretazione
di commenti calcistici in diretta, proponi-
amo uno schema per
l’annotazione
di
eventi (e relativa struttura argomentativa),
sulla base del
quale abbiamo creato un
corpus di
valutazione di
riferimento.
Ci
siamo occupati della classificazione auto-
matica di eventi utilizzando Active Learn-
ing per ridurre lo sforzo per l’acquisizione
di dati annotati specifici del dominio.
1
Introduction
This work focuses on understanding the content
of live commentaries of sport games.
This form
of written reporting has become very popular in
recent years, and almost every national Italian on-
line newspaper has a section dedicated to live sport
commentaries.
Live commentaries have several
interesting properties:
(i) they are short
descrip-
tions of an event
written by professionals while
the event
is happening;
their form is much sim-
pler than a full spoken running commentary;
(ii)
they have a clear and simple structure,
typically
based on the timing of the sport event;
(iii) they
are often associated with metadata (e.g.
La Roma
passa in vantaggio [Roma takes the lead] is asso-
ciated with the metadata GOAL); (iv) finally, they
describe visual scenes,
which is relevant to auto-
matic alignment of multimedia content (e.g.
align
a sequence of frames in a video with the corre-
sponding commentary),
a topic of emerging in-
terest
in Computational
Linguistics (see,
for in-
stance,
(Song et al.,
2016)).
Our work is part of
a larger cross-disciplinary project, Understanding
Multimedia Content,
currently involving several
research groups at FBK.
In this
paper
we
first
define
an annotation
framework for the semantic interpretation of on-
line soccer
commentaries in Italian (Section 3),
which includes the detection and classification of
relevant
events,
as well
as the identification of
their argument structure. Based on this annotation
schema, which could also be used for the annota-
tion of tweets or other short online comments, we
manually annotated a collection of commentaries
in Italian to be used as a gold standard (Section
4).
As a first step towards a comprehensive sys-
tem for automatic interpretation of soccer events
we focused on event
detection and classification
(i.e.
event extraction),
and used Active Learning
to build a training corpus (Section 5).
We show
that this procedure is very effective, allowing our
system to reach an F1 of 77.25, with considerable
savings of annotation time (Section 6).
2
Related Work
Most
of the work on event
detection and classi-
fication focuses either on the news (UzZaman et
al.,
2012) or medical domains (Sun et al.,
2013).
For
Italian,
two corpora annotated with events
following the It-TimeML framework (Caselli
et
al., 2011a) are available:
EVENTI (Caselli et al.,
2014) and WItaC (Speranza and Minard, 2015).
Event detection and classification on news has
been of interest
for English,
Italian and Spanish
in the TempEval evaluation campaigns (Verhagen
et al.,
2010;
UzZaman et al.,
2012) and for Ital-
ian in the EVENTI task at
Evalita 2014 (Caselli
et
al.,
2014).
As part
of these evaluation cam-
paigns,
several
event
extraction systems,
mainly
CLIC_2016_Proceedings.indd 205
02/12/16 15.04
206
supervised,
have been implemented (Caselli
et
al.,
2011b; Jung and Stent,
2013; Bethard,
2013;
Mirza and Minard, 2014). The development of su-
pervised systems requires a significant amount of
training data, whose creation is very time consum-
ing.
The effort needed to annotate these data can
be reduced by using Active Learning methods, i.e.
methods where instances to be annotated are se-
lected according to their predicted impact on the
model learned for a specific task.
Active Learn-
ing has been used in various linguistic annotation
tasks, such as Named Entity Recognition (Shen et
al., 2004) and Part-of-Speech tagging (Ringger et
al., 2007).
The surging interest
of
the NLP community
for event detection and classification in the sport
domain,
on the
other
hand,
is
shown by the
hackathon recently organized on extraction of
soccer
events
from Tweets
in French,
English
and
Arabic
(http://hackatal.github.
io/2016/).
Fort
and Claveau (2012)
present
a corpus of
match commentaries and transcripts of video com-
mentaries of soccer games in French,
which has
been annotated with entities (e.g.
players,
refer-
ees),
events (e.g.
corner,
penalty) and some rela-
tions (e.g.
pass, replace player) and van Oorschot
et al. (2012) propose a method to extract relevant
events of games in Dutch using the quantity of
tweets posted per minute.
Event
extraction in the sport
domain is even
more important as far as analysis of video (Xu et
al.,
2008;
Han et al.,
2008) and audio (Cabasson
and Divakaran, 2003) data is concerned.
In the domain of automatic alignment of mul-
timedia content, the analysis of both texts, videos
and audio is necessary,
and the research focuses
on the alignment
of
the events detected in the
three media (Malmaud et al., 2015; Regneri et al.,
2013).
3
Task Definition and Annotation
Framework
In our annotation framework,
semantic interpre-
tation of soccer events consists of the following
steps:
(i) soccer event recognition and classifica-
tion, (ii) recognition and classification of the enti-
ties involved in the soccer event, and (iii) identifi-
cation of the argument relations between the soc-
cer event and the participant entities.
3.1
Event Recognition and Classification
Soccer
event
annotation is
inspired by the It-
TimeML definition of event and follows its min-
imal chunk rule, according to which only the head
of the event phrase is included in the annotated text
span (Caselli et al.,
2011a).
The main difference
with the It-TimeML framework is that we restrict
it to verbal and nominal events and to a semanti-
cally defined set of relevant events.
In particular,
we identified six semantic cate-
gories of events relevant to the soccer domain (and
a number of sub-categories):
Referee decision includes events that are
characterized as
such due to a referee’s
inter-
vention;
examples of subcategories are Yellow
card and Offside;
Kick includes
events
in which the
ball
is
kicked by a player; examples of subcategories are
Penalty,
Corner,
Pass (e.g.
apre in (1)),
Shot on goal, and Free kick;
Interruption includes events in which a
player interrupts the action of the opposing team
examples of subcategories are Clearance and
Intercept (e.g. anticipato in (1));
Possession includes events where the ball,
although moving, does not go from one player to
another;
as subcategories we find,
for example,
Dribbling and Holding possession;
Goal includes events where a team scores (we
did not devise subcategories for Goal);
No ball includes (i)
events where a player
doesn’t have the ball (e.g. inserimento in (1)), and
(ii) events not involving the ball, such as pushing
or knocking to the ground (no subcategorization).
(1)
71:
Griezmann
passa
a
Pogba
che
apre
per
Matuidi,
inserimento
in
area
del
centrocampista del Psg, che viene anticipato.
[Griezman for Pogba who in turn passes to
Matuidi,
the Psg midfield player
makes
a
forward run for the ball but gets beaten to it]
3.2
Entity Recognition and Classification
In order to annotate entities relevant
to the soc-
cer
domain,
we identified four
categories,
i.e.
Player,
Team,
Referee,
and Coach.
Enti-
ties include both named entities (e.g.
Griezmann
and Psg in (1)) and nominal entities (e.g.
centro-
campista [middle field player] in (1)) and textual
span is identified according to the minimal chunk
rule (as was done for events).
CLIC_2016_Proceedings.indd 206
02/12/16 15.04
207
3.3
Argument Structure Identification
The annotation of
the argument
structure of
an
event
is performed through the creation of links
called ARG rel between each event and its argu-
ments (which can be either entities or events).
In-
spired by PropBank (Bonial et al., 2010), we also
defined four numbered arguments to be assigned
to each ARG rel in the form of
an attribute:
ARG 0 and ARG 1 correspond to the required ar-
guments of a predicate, e.g.
agent and patient re-
spectively,
while ARG 2 and ARG 3 correspond
to arguments that
occur with high-frequency for
a certain predicate.
In (1),
for
instance,
we have an ARG rel
between passa and Griezmann (ARG 0)
and an
ARG rel between passa and Pogba (ARG 2).
4
Reference Annotated Corpus for Event
Interpretation
Based on the annotation schema described in Sec-
tion 3,
we manually annotated a corpus of nine
soccer
games (five games from the Euro 2016
competition and four
games
from Campionato
di
Serie A 2015-2016)
collected from La Re-
pubblica,
1
Tuttosport,
2
and Eurosport.
3
Anno-
tation was performed using the CAT tool
(Bar-
talesi Lenzi et al., 2012).
The result is a reference
corpus for the evaluation of semantic interpreta-
tion of soccer events consisting of around 13,500
tokens,
for a total of 1,372 annotated events and
1,600 argument relations (see Table 1).
We
computed the
inter-annotator
agreement
(IAA) over 46 commentaries annotated by two an-
notators (two halves from two different games). In
terms of Dice’s coefficient
(Dice,
1945) we ob-
tained an IAA of 0.70 and 0.96 (micro average)
for event and entity classification respectively, and
0.69 for relation recognition (between events and
entities marked by both annotators).
5
Event Extraction
In order to extract and classify soccer events in on-
line commentaries, we used a supervised machine
learning approach.
We had a system for event de-
tection (trained on news articles annotated follow-
ing It-TimeML) available, which did not perform
well
on the soccer domain (it
obtained an F1 of
40.8 and recall of 50.1 on our reference corpus).
1
http://www.repubblica.it/
2
http://www.tuttosport.com/
3
http://it.eurosport.com/
ref. corpus
training corpus
Games
9
101
Commentaries
652
1,377
Commentaries/game
72
14
Tokens
13,567
31,955
Tokens/com.
20.8
23.2
Goal
66
168
Kick
666
1,425
Interruption
274
390
Possession
71
181
Referee decision
254
807
No Ball Event
41
181
Player
1317
-
Referee
21
-
Coach
10
-
Team
291
-
ARG rel
1,600
-
Table 1: Dataset statistics.
As a consequence,
a training corpus specifically
developed for this task was needed.
We therefore exploited the T
EXT
P
RO
-AL Ac-
tive Learning platform (Magnini
et
al.,
2016)
which selects the most informative samples from
an unlabeled set.
More precisely,
T
EXT
P
RO
-AL
selects commentaries containing events that
the
system was not
able to recognize correctly,
pre-
annotates them and asks the annotator to check
them.
As illustrated in Figure 1, an AL cycle consists
of the following steps:
4
1.
Train a model
using the annotated commen-
taries
5
(step 3);
2.
Repeat
the following cycle until
the batch
6
is
full:
(a)
Select,
from an unlabeled database
of
commentaries (see Section 5.1),
a com-
mentary that matches the first event string
in the error queue
7
(i.e.
the event with the
lowest confidence) (step 4);
(b)
Pre-annotate the example (step 5);
(c)
Correct the annotation (done manually by
an annotator) (step 1);
(d)
Add the annotated example to the batch
(step 2a);
4
The AL cycle is repeated until a stopping criteria is veri-
fied; for instance, until the system reaches a pre-defined per-
formance.
5
At the beginning the training corpus is empty, so the first
commentary is randomly selected and added to the batch.
6
The batch size was set to 2 for the first 24 examples and
then to 10.
These values were chosen to enable frequent re-
training of the model and an update of the confidence scores
and system errors.
7
The error queue (or system global memory) contains the
history of the system errors corrected by the annotator.
CLIC_2016_Proceedings.indd 207
02/12/16 15.04
208
Figure 1:
Active Learning schema adopted to
build the training corpus.
(e)
Save in the error
queue the annotated
events with their model confidence score
(step 2b);
Our system is highly customizable:
the event
detection classification system can easily be sub-
stituted by a different system for different classifi-
cation tasks, like NER and PoS tagging.
5.1
Unlabeled Database
The unlabeled database used in the AL procedure
is composed of commentaries of 101 soccer games
from DirettaGoal,
8
La Repubblica,
9
Tuttosport,
10
and Eurosport.
11
We extracted the online com-
mentaries of all games of the Euro 2016 Cup and
of the final
6 rounds of Campionato di
Serie A
2015-2016. In total 6,573 commentaries were col-
lected, with 155,005 tokens.
5.2
Error Selection
The error-based selection process exploits the idea
that the corrections done by the annotator can be
used to select new examples more efficiently.
The
system has a memory in which the events con-
tained in the checked commentaries are stored,
together with the system’s confidence score and
the indication of whether the system was right or
wrong.
8
http://www.direttagoal.it/
9
http://www.repubblica.it/
10
http://www.tuttosport.com/
11
http://it.eurosport.com/
5.3
Event Detection and Classification
The system for event detection and classification
is based on machine learning,
using the SVM al-
gorithm implemented in TinySVM and included in
Yamcha (Kudo and Matsumoto, 2003). The task is
treated as a multi-class classification task,
where
each token has to be classified in one of the 7 pre-
defined classes.
12
The features used are those de-
fined in the system of Mirza and Minard (2014),
which took part
in the EVENTI
task at
Evalita
2014 (Caselli et al., 2014), obtaining an F1 of 0.86
for the task of event detection and an F1 of 0.67
for event classification.
5.4
Annotation Editor
For the manual revision of linguistic annotations
within the Active Learning method, we adapted an
existing editor,
MTEqual
13
(Girardi et al.,
2014),
originally developed for assessing the quality of
machine translation.
6
Evaluation
The AL system described in the previous section
was used by a non-expert annotator who annotated
events in soccer commentaries for seven working
days.
This resulted in a training corpus of 1,377
commentaries,
that is,
around 200 commentaries
per day (see Table 1).
The evaluation of our system was performed by
comparing it to the reference annotated corpus de-
scribed in Section 4.
The learning curve in Fig-
ure 2 represents the results obtained by the sys-
tem in terms of precision,
recall and F1-measure
as the training set was progressively extended.
At
the beginning the training set
was empty,
so the
performance of the system was null.
After the an-
notation of 200 commentaries, the system reached
53.27 F1, and after 800 commentaries it obtained
70.94 F1.
At
the end of our experiment,
almost
1,400 commentaries had been annotated and the
system’s performance was 76.65 F1 (73.42 of re-
call
and 80.16 of
precision).
The peak perfor-
mance is 77.25 F1 and was reached with 1,347
commentaries (i.e. almost 32,000 tokens).
7
Conclusion and Future Work
We presented a new annotation framework for the
interpretation of online soccer commentaries,
as
12
Referee decision,
Kick,
Interruption,
Possession,
Goal,
No Ball Event and O for tokens that are not part of an event.
13
https://github.com/hltfbk/MT-EQuAl
CLIC_2016_Proceedings.indd 208
02/12/16 15.04
209
Figure 2: Event extraction performance as the training set was extended.
well
as the reference annotated corpus we cre-
ated.
14
We also described our system for event
extraction from live soccer commentaries in Ital-
ian. It exploits the T
EXT
P
RO
-AL Active Learning
platform,
which allowed us to reach a significant
F1 (77.25) in seven working days of a non-expert
annotator.
The annotation was performed for Ital-
ian but the method and the annotation schema we
devised can be applied to other languages.
The
only language dependent component is the feature
extractor used by the event detection module.
As for ongoing work, we are working at param-
eter optimization on the Active Learning frame-
work (particularly,
we are interested in the rela-
tions between the size of the unlabeled dataset, the
frequency of the re-training,
and the confidence
score used by the selection procedure).
We also
plan to extend the current
system by adding the
detection of the argument structure of events.
Acknowledgments
We thank Valentino Frasnelli for his contribution,
which consisted of manually annotating the data.
This work has been partially funded by the Euclip
project, in collaboration with Euregio.
15
References
Valentina
Bartalesi
Lenzi,
Giovanni
Moretti,
and
Rachele Sprugnoli.
2012.
CAT:
the CELCT An-
14
Currently the annotated data are not be distributed due to
copyright issues.
15
http://www.euregio.it
notation Tool.
In Proceedings of
the 8th Interna-
tional Conference on Language Resources and Eval-
uation (LREC’12), pages 333–338, Istanbul, Turkey,
May.
European Language Resources
Association
(ELRA).
Steven Bethard.
2013.
Cleartk-timeml:
A minimalist
approach to tempeval 2013.
In Proceedings of the
Seventh International Workshop on Semantic Evalu-
ation, SemEval ’13, Atlanta, Georgia, USA.
Claire Bonial,
Olga Babko-Malaya,
Jinho D.
Choi,
Jena Hwang,
and Martha Palmer.
2010.
Propbank
annotation
guidelines,
version
3.0.
Techni-
cal
report,
Center
for
Computational
Language
and
Education
Research,
Institute
of
Cognitive
Science,
University
of
Colorado
at
Boulder.
http://clear.colorado.edu/compsem/
documents/propbank_guidelines.pdf.
Romain Cabasson and Ajay Divakaran.
2003.
Auto-
matic extraction of soccer video highlights using a
combination of motion and audio features.
In Stor-
age and Retrieval for Media Databases 2003, Santa
Clara, CA, USA, January 22, 2003, pages 272–276.
Tommaso Caselli,
Valentina Bartalesi
Lenzi,
Rachele
Sprugnoli,
Emanuele Pianta,
and Irina Prodanof.
2011a.
Annotating Events,
Temporal
Expressions
and Relations in Italian:
the It-TimeML Experi-
ence for the Ita-TimeBank.
In Linguistic Annotation
Workshop, pages 143–151.
Tommaso Caselli,
Hector
Llorens,
Borja
Navarro-
Colorado,
and Estela Saquete.
2011b.
Data-driven
approach using semantics for recognizing and clas-
sifying timeml events in italian.
In Recent Advances
in Natural Language Processing, RANLP 2011, 12-
14 September,
2011,
Hissar,
Bulgaria,
pages 533–
538.
Tommaso Caselli,
Rachele Sprugnoli,
Manuela Sper-
anza,
and Monica Monachini.
2014.
EVENTI
CLIC_2016_Proceedings.indd 209
02/12/16 15.04
210
EValuation of Events and Temporal INformation at
Evalita 2014.
In Proceedings of the Fourth Interna-
tional Workshop EVALITA 2014.
Lee Raymond Dice.
1945.
Measures of the amount
of ecologic association between species.
Ecology,
26(3):297–302, July.
Kar
¨
en Fort
and Vincent
Claveau.
2012.
Annotating
football
matches:
Influence of the source medium
on manual
annotation.
In Proceedings of
LREC
2012,
Istanbul,
Turkey,
may.
European Language
Resources Association (ELRA).
Christian Girardi, Luisa Bentivogli, Mohammad Amin
Farajian,
and Marcello Federico.
2014.
Mt-equal:
a toolkit for human assessment of machine transla-
tion output.
In COLING 2014,
25th International
Conference on Computational Linguistics, Proceed-
ings of the Conference System Demonstrations, Au-
gust 23-29, 2014, Dublin, Ireland, pages 120–123.
Yina Han,
Guizhong Liu,
and G
´
erard Chollet.
2008.
Goal event detection in broadcast soccer videos by
combining heuristic rules with unsupervised fuzzy
c-means
algorithm.
In Proceedings
of
ICARCV
2008, Hanoi, Vietnam, 17-20 December 2008, Pro-
ceedings, pages 888–891.
Hyuckchul Jung and Amanda Stent.
2013.
Att1: Tem-
poral
annotation using big windows and rich syn-
tactic and semantic features.
In Second Joint Con-
ference on Lexical
and Computational
Semantics
(*SEM),
Volume 2:
Proceedings of SemEval 2013,
pages 20–24, Atlanta, Georgia, USA, June. Associ-
ation for Computational Linguistics.
Taku Kudo and Yuji Matsumoto.
2003.
Fast Methods
for Kernel-based Text Analysis.
In Proceedings of
the 41st
Annual
Meeting on Association for Com-
putational Linguistics - Volume 1,
ACL ’03,
pages
24–31, Stroudsburg, PA, USA.
Bernardo Magnini,
Anne-Lyse Minard,
Mohammed
R.
H.
Qwaider,
and Manuela Speranza.
2016.
T
EXT
P
RO
-AL:
An Active Learning Platform for
Flexible and Efficient Production of Training Data
for NLP Tasks.
In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: System Demonstrations.
Jonathan Malmaud,
Jonathan Huang,
Vivek Rathod,
Nick Johnston,
Andrew Rabinovich,
and Kevin
Murphy.
2015.
What’s cookin’? interpreting cook-
ing videos using text,
speech and vision.
CoRR,
abs/1503.01558.
Paramita Mirza and Anne-Lyse Minard.
2014.
FBK-
HLT-time:
a complete Italian Temporal Processing
system for EVENTI-EVALITA 2014.
In Proceed-
ings of the Fourth International Workshop EVALITA
2014.
Michaela Regneri, Marcus Rohrbach, Dominikus Wet-
zel,
Stefan Thater,
Bernt
Schiele,
and Manfred
Pinkal.
2013.
Grounding action descriptions in
videos.
TACL, 1:25–36.
Eric
Ringger,
Peter
McClanahan,
Robbie
Haertel,
George Busby, Marc Carmen, James Carroll, Kevin
Seppi, and Deryle Lonsdale.
2007.
Active learning
for part-of-speech tagging:
Accelerating corpus an-
notation.
In Proceedings of the Linguistic Annota-
tion Workshop, LAW ’07, pages 101–108, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Dan Shen,
Jie Zhang,
Jian Su,
Guodong Zhou,
and
Chew-Lim Tan.
2004.
Multi-criteria-based active
learning for named entity recognition.
In Proceed-
ings of the 42Nd Annual Meeting on Association for
Computational
Linguistics,
ACL ’04,
Stroudsburg,
PA,
USA.
Association for Computational
Linguis-
tics.
Young Chol
Song,
Iftekhar Naim,
Abdullah Al
Ma-
mun,
Kaustubh Kulkarni,
Parag Singla,
Jiebo Luo,
Daniel Gildea,
and Henry A.
Kautz.
2016.
Unsu-
pervised alignment of actions in video with text de-
scriptions.
In Proceedings of the Twenty-Fifth Inter-
national Joint Conference on Artificial Intelligence,
IJCAI 2016,
New York,
NY,
USA,
9-15 July 2016,
pages 2025–2031.
Manuela Speranza and Anne-Lyse Minard.
2015.
Cross-language projection of
multilayer
semantic
annotation in the NewsReader Wikinews Italian Cor-
pus (WItaC).
In Proceedings of
the Second Ital-
ian Conference on Computational Linguistics CLiC-
it 2015.
Weiyi
Sun,
Anna
Rumshisky,
and
¨
Ozlem Uzuner.
2013.
Evaluating temporal relations in clinical text:
2012 i2b2 challenge.
JAMIA, 20(5):806–813.
Naushad UzZaman,
Hector Llorens,
James F.
Allen,
Leon Derczynski, Marc Verhagen, and James Puste-
jovsky.
2012.
Tempeval-3:
Evaluating events,
time expressions,
and temporal
relations.
CoRR,
abs/1206.5333.
Guido van Oorschot, Marieke van Erp, and Chris Dijk-
shoorn.
2012.
Automatic extraction of soccer game
events from twitter.
In Proceedings of the Workhop
on Detection,
Representation,
and Exploitation of
Events in the Semantic Web (DeRiVE 2012), volume
902, pages 21–30, Boston, USA, 11.
Marc Verhagen,
Roser Saur
´
ı,
Tommaso Caselli,
and
James Pustejovsky.
2010.
Semeval-2010 task 13:
Tempeval-2.
In Proceedings of the 5th International
Workshop on Semantic Evaluation,
SemEval
’10,
pages 57–62,
Stroudsburg,
PA,
USA.
Association
for Computational Linguistics.
Changsheng Xu,
Yifan Zhang,
Guangyu Zhu,
Yong
Rui,
Hanqing Lu,
and Qingming Huang.
2008.
Using webcast text for semantic event detection in
broadcast
sports video.
IEEE Trans.
Multimedia,
10(7):1342–1355.
CLIC_2016_Proceedings.indd 210
02/12/16 15.04
211
Emojitalianobot and EmojiWorldBot
New online tools and digital environments for translation into emoji
Johanna Monti
L’Orientale University
Naples, Italy
jmonti@unior.it
Federico Sangati
Independent Researcher
The Netherlands
federico.sangati@gmail.com
Francesca Chiusaroli
University of Macerata
Italy
f.chiusaroli@unimc.it
Martin Benjamin
EPFL
Lausanne, Switzerland
martin@kamusiproject.org
Sina Mansour
EPFL
Lausanne, Switzerland
mansour@ee.sharif.edu
Abstract
English.
Emojitalianobot and Emo-
jiWorldBot
are two new online tools
and digital
environments
for
transla-
tion into emoji
on Telegram,
the pop-
ular instant messaging platform.
Emo-
jitalianobot is the first open and free
Emoji-Italian and Emoji-English trans-
lation bot
based on Unicode descrip-
tions.
The bot was designed to sup-
port the translation of
Pinocchio into
emoji
carried out
by the followers
of
the
"Scritture
brevi"
blog
on Twit-
ter
and contains
a glossary with all
the uses
of
emojis
in the translation
of
the
famous
Italian novel.
Emo-
jiWorldBot,
an off-spring
project
of
Emojitalianobot,
is a multilingual
dic-
tionary that
uses
Emoji
as
a
pivot
language from dozens of
different lan-
guages.
Currently the emoji-word and
word-emoji
functions are available for
72 languages imported from the Uni-
code tables and provide users with an
easy search capability to map words
in each of
these languages to emojis,
and vice versa.
This paper presents the
projects, the background and the main
characteristics of these applications.
Italiano.
Emojitalianobot
e
Emoji-
WorldBot
sono
due
applicazioni
on-
line per
la traduzione in e da emoji
su Telegram,
la popolare
piattaforma
di
messaggistica istantanea.
Emojital-
ianobot `e il
primo bot aperto e gratuito
di
traduzione che contiene i
dizionari
Emoji-Italiano ed Emoji-Inglese basati
sule descrizioni Unicode.
Il
bot `e stato
ideato per coadiuvare la traduzione di
Pinocchio in emoji su Twitter da parte
dei
follower del
blog Scritture brevi
e
contiene pertanto anche il glossario con
tutti gli usi degli emoji nella traduzione
del celebre romanzo per ragazzi.
Emoji-
WorldBot,
epigono di
Emojitalianobot,
`e un dizionario multilingue che usa gli
emoji
come
lingua pivot
tra dozzine
di
lingue
differenti.
Attualmente
le
funzioni
emoji-parola
e
parola-emoji
sono disponibili
per
72 lingue impor-
tate dalle tabelle Unicode e forniscono
agli
utenti
delle
semplici
funzioni
di
ricerca per trovare le corrispondenze in
emoji delle parole e viceversa per cias-
cuna di
queste lingue.
Questo contrib-
uto presenta i
progetti,
il
background
e le principali
caratteristiche di
queste
applicazioni.
1
Introduction
Emojitalianobot
1
and EmojiWorldBot
2
are two
new translation bots
3
into and from emoji.
These two bots were designed starting from the
hypothesis of setting up an emoji multilingual
dictionary and translator through a process of
selection and assessment
of
conventional
se-
mantic values.
Translation cases
may show
how images can convey common and universal
meanings,
beyond specific peculiarities,
so as
they can stand as models in the perspective of
an interlanguage (Chiusaroli,
2015).
The two
1
https://telegram.me/emojitalianobot/
2
https://telegram.me/emojiworldbot
3
Computer programmes that carry out repetitive
tasks and in their more sophisticated form can also
simulate human behaviours.
CLIC_2016_Proceedings.indd 211
02/12/16 15.04
212
bots ease the use of emojis but also collect, re-
fine and make available valuable linguistic data
by means of
crowdsourcing and gamification
approaches.
This contribution presents the state-of-the-
art concerning the use of
crowdsourcing and
gamification approaches to linguistics in sec-
tion 2, the Emojitalianobot
and the Pinocchio
project in section 3, the EmojiWorldBot in sec-
tion 4 and finally conclusions and future work
in section 5.
2
Crowdsourcing and gamification
Crowdsourcing,
i.e.,
the act of
a company or
institution taking a function once performed
by employees and outsourcing it to an unde-
fined (and generally large) network of
people
in the form of
an open call
(Howe,
2006) is
becoming a widespread practice on the Inter-
net to develop linguistic resources (dictionar-
ies,
glossaries,
translation memories,
etc.)
or
services (translation,
localisation,
fansubbing,
etc.)
(Monti,
2012,
2014).
It allows the large
scale involvement of users who contribute with
their knowledge,
their ideas,
and their skills,
in this way performing an active role in the
achievement of
a common goal.
Crowdsourc-
ing can be used for the creation, maintenance
and sharing of lexical/terminological data such
as:
i.
lexical
resources for online dictionaries,
e.g.,
Wiki
platforms such as Wiktionary
4
and
Omegawiki
5
,
and recent forays by more tra-
ditional
dictionary publishing companies like
Collins,
Oxford,
and Macmillan;
ii.
termi-
nological
resources
for
online
terminological
databases, like TermWiki
6
, the terminological
counterpart of Wiktionary or TaaS
7
; iii.
lexical
and semantic resources for Natural
Language
Processing (NLP) tasks,
such as Word Sense
Disambiguation (WSA),
Sentiment
Analysis,
Computer Aided Translation, Machine Trans-
lation and so on, using platforms for distribut-
ing parts of large development projects to pro-
fessional
or occasional
lexicographers such as
Mechanical
Turk
8
.
To the best of our knowl-
edge only very few projects so far have been
tailored to mobile devices to gather linguistic
data in the field, (i) to collect dialect data as in
Dialectbot
9
, (ii) to document endangered lan-
4
https://en.wiktionary.org/
5
http://www.omegawiki.org/Meta:Main_Page
6
http://it.termwiki.com/
7
https://term.tilde.com/
8
https://www.mturk.com/mturk/welcome
9
https://telegram.me/dialectbot/
guages as in Aikuma
10
and Ma Iwaidja
11
,
or
(ii) to gather grammaticality judgments (Mad-
nani
et
al.,
2011).
The social
dimension of
these types of activities is sometimes connected
and fed by social communities, where users dis-
cuss problems, give suggestions, and exchange
ideas (Brabham,
2012;
McGonigal,
2011).
In
order to loyalize social
communities and im-
prove their engagement,
gamification is used
very often.
The use of
games is a very effec-
tive tool
for active participation since it pro-
vides a strong motivational
framework which
pushes people to act
for
good.
Some effec-
tive uses of
games are to create new habits
or modify wrong actions.
Wang et al.
(2013)
list Games with a purpose (GWAPs)
12
among
the different
types
of
crowdsourcing.
Some
good examples
of
games
with a purpose in
the lexicographic field are Phrase Detectives
13
and JeuxDeMots
14
.
The main advantage of
GWAPs is their high attractiveness,
because
people love playing games and it is easier to
obtain their contribution in this way in com-
parison to other forms of crowdsourcing.
The
difficulty in designing such games is to match
attractiveness with usefulness,
i.e.
an attrac-
tive game which produces valuable data.
3
Emojitalianobot and the
Pinocchio project
Emojitalianobot
is
the
first
open and free
Emoji-Italian translation bot
on Telegram.
It
was
developed to support
the translation
project of
Pinocchio in emoji
15
launched on
Twitter in February 2016 by F.
Chiusaroli,
J.
Monti
and F.
Sangati.
The translation of the
famous children’s novel was carried out by the
followers of
the Scritture brevi
blog
16
(by F.
Chiusaroli and F.M. Zanzotto) and the first fif-
teen chapters have been translated, which cor-
respond to the original novel published by Col-
lodi in 1881.
Every day tweets with sentences
taken from the novel
were posted on Twitter
and the followers suggested their translations
10
http://www.aikuma.org/aikuma-app.html
11
https://itunes.apple.com/au/app/
ma-iwaidja/id557824618?mt=8
12
When a player without any special
knowledge is
put into a gaming environment and has to make de-
cisions to win the game under the pressure of time or
any game mechanics’ constraints.
13
https://anawiki.essex.ac.uk/
phrasedetectives/
14
http://www.jeuxdemots.org/jdm-accueil.php
15
http://www.treccani.it/lingua_italiana/
speciali/ludolinguistica/Chiusaroli.html
16
https://www.scritturebrevi.it/
CLIC_2016_Proceedings.indd 212
02/12/16 15.04
213
in emoji;
at the end of
each day,
the official
version of
the translations was validated and
published.
17
Translators used Emojitalianobot
that contains (i) the Emoji-Italian dictionary,
(ii) the Emoji-English descriptions based on
Unicode and (iii) a glossary with all
the uses
of emoji
in the translation of Pinocchio.
The
project was associated with the Emojitalia dis-
cussion group on Telegram, where users met to
discuss problems,
solutions,
suggest improve-
ments of
the bot,
in addition to the transla-
tion choices
for
Pinocchio and communicate
in emoji.
The Pinocchio translation project
therefore allowed to crowdsource different lin-
guistic data connected with the use of emojis
as actual means of communication and not just
simple graphics to express amusement or in-
terest.
In this respect the main findings of the
project are twofold:
the need to recur to com-
pound multi-emoji expressions in order to ex-
press concepts which are not represented in the
current set,
as well
as a related simple gram-
mar to express syntactic relations among emo-
jis, past and future tenses, etc.
Unlike previous
literary translation project in emojis,
such as
the translations of Moby Dick or Alice in Won-
derland, this is the first attempt of a collective
shared emoji code (vocabulary and grammar)
based on a word for word translation totally in
emojis.
Emojitalianobot
is an ideal test bench
to experiment with new approaches like crowd-
sourcing and gamification in the field of Natu-
ral Language Processing (NLP). The Pinocchio
project, games and features available in the bot
to learn or guess the meaning of emoji are de-
vised indeed both to enjoy the bot while using
it and at the same time to give the opportu-
nity to users to develop linguistic descriptions
of
emoji
tailored on their actual
perceptions.
The most important reward for playing with
the bot
is
the awareness
of
helping develop
a linguistic resource for one’s mother tongue,
and the pride in contributing to it.
Since its release on Telegram,
the project
was an instant success,
becoming a viral
web
phenomenon thanks to the Scritture brevi com-
munity and the Pinocchio translation in emo-
jis,
so that the bot has now almost 750 users.
The Pinocchio translation project
in emojis
counts 611 tweets , 980 glossary entries which
correspond to 2127 words,
of
which 185 are
multi-emojis,
i.e.
compound emojis,
such as
17
The translation of Pinocchio in emoji
can be fol-
lowed on Twitter using #emojitaliano.
for the Italian word peggio (worst).
4
EmojiWorldBot
On the basis of (both linguistic and technologi-
cal) experience with Emojitalianobot, the three
Italian researchers together with Martin Ben-
jamin and Sina Mansour of the Kamusi Project
International
18
and EPFL (Switzerland)
de-
signed a new bot on Telegram in April
2016:
EmojiWorldBot, a multilingual dictionary that
uses Emoji as a pivot language from dozens of
different languages.
Currently the emoji-word
and word-emoji
functions are available for 70
languages imported from the Unicode tables
19
and provide users with an easy search capabil-
ity to map words in each of these languages to
emojis,
and vice versa.
Looking at the UNI-
CODE descriptions (see Fig.
1) it is apparent
that emojis are not annotated in a coherent
way across languages, so some languages have
more descriptions and some others,
especially
underrepresented languages, have less or in the
most cases some languages are not represented
at all.
Figure 1:
Annotations in Romance languages
Our first goal with EmojiWorldBot is there-
fore to reach a uniform and comprehensive list
of tags across multiple languages with a precise
mapping between any language pair,
which
may serve to bootstrap a massive multilingual
dictionary.
The bot currently features:
•
emoji-to-word and word-to-emoji transla-
tion for more than 70 languages
•
Eggs,
a tagging game for people to con-
tribute to the expansion of
these dictio-
naries or the creation of new ones for any
additional
language.
Users
can suggest
additional
tags
for
single emojis
in any
language (for example adding egg to the
tag list for
in English).
18
https://kamusi.org/
19
http://www.unicode.org/cldr/charts/29/
annotations/
CLIC_2016_Proceedings.indd 213
02/12/16 15.04
214
•
inline queries:
type EmojiWorldBot and a
word, and it will suggest a set of emojis for
that word you can send in any Telegram
conversation
•
the possibility to add new languages.To
date 56 new languages were added, such as
Latin,
Esperanto,
Sardinian among oth-
ers.
The basic idea of the Eggs game is to collect
new tags to associate with emojis as shown in
Fig.
2.
Figure 2:
Eggs game
With
fewer
than
2000
official
emojis,
stretching the boundaries of their communica-
tive potential
makes them more useful.
How-
ever,
it also makes the dictionary more essen-
tial, so that someone who receives
in a chat
in any language might
look to see if
it
sig-
nifies something other than an eggplant.
In
the future,
Eggs
will
experiment with multi-
emoji
terms (METs),
building on the work of
the Pinocchio translation project to Emoji, in
an effort
to build a larger
pictorial
vocabu-
lary that is comprehensible across languages
(Chiusaroli,
2015).
A new version of
the bot
is already under development.
It will
feature
Ducks,
a second game where users are asked
to map tags from a source language (e.g.
En-
glish) to a target language (e.g.
Swahili).
In
the example of
Figure 1,
several
Romanian
users would be shown the sense-specific defini-
tion of grin from Wordnet and all of the emo-
jis that have been attached to that definition,
and be asked which of the options among fat
,
˘a
ˆıncˆ
antat˘
a fat
,
˘a and ˆıncˆ
antare, if any, is a good
translation.
The game would also be played
for face and grinning face.
In this way,
all
of
the one-to-one relationships should be discov-
ered, and all instances of a term that does not
have a translation equivalent on the other side
will
be revealed.
When it is known that no
match from English exists, Ducks presents the
definition,
the emojis,
and the English term,
and asks the user to type in the best equiv-
alent in their language.
This is the method
that will be most efficacious for new languages,
bypassing the need to disentangle the many-
to-many associations introduced through term
clustering in the CLDR annotations.
It should
be noted that
many terms
will
be removed
from the game cycle through comparisons with
Wordnets for available languages.
For exam-
ple,
самолет appears in conjunction with En-
glish airplane in both the Emoji
annotations
and the Bulgarian Wordnet that are linked to
the same English Princeton Wordnet (PWN)
sense, which gives sufficient confirmation with-
out needing a mass of
human players.
As of
this writing, the project is in the process of im-
porting and aligning Wordnet data for some 50
languages.
In future work,
terms from Word-
net synsets will
be tested against the emojis
with which they theoretically share a sense,
e.g.
asking crowd members whether
applies
to other members of the PWN synset for bus
(autobus,
coach,
jitney,
motorbus,
etc.),
but
the mechanism for doing so has not been fi-
nalized.
In this way EmojiWorldBot
employs
crowd methods as part of an arsenal intended
to conquer the walls of collecting data for nu-
merous diverse languages.
Data validation will
be achieved via a consensus
model
through
which answers are accepted as correct if
the
same result is provided by a threshold number
of respondents.
The new version of the bot will
allow to:
•
add new terms to the current languages
(including the names of the countries for
national flags)
•
compare definitions across languages.
From the computational
point
of
view,
this
project,
as the Emojitalianobot,
attempts to
address the data chasm for natural
language
processing
for
most
languages
by distilling
data collection to simple
micro-tasks
(Ben-
jamin, 2015) using techniques adapted to least-
common-denominator technology.
5
Conclusions
We
described the
Emojitalianobot
and the
EmojiWorldBot
projects.
Combining crowd-
CLIC_2016_Proceedings.indd 214
02/12/16 15.04
215
sourcing, gamification a nd a s martphone app 
is a powerful strategy to collect, improve and 
refine v aluable l inguistic d ata e asily a nd i n a 
short time particularly for less-resourced lan-
guages (Benjamin and Radetzky, 2014).These 
may be the first crowdsourcing projects of this 
type to use bots for linguistic data collection 
and 
validation 
and 
are 
unique 
in 
their 
at-
tempts at engaging participants for different 
languages.
References
Martin Benjamin. 2015. Crowdsourcing micro-
data for cost-effective and reliable lexicogra-
phy.
In Proceedings of
AsiaLex 2015 Hong
Kong, EPFL-CONF-215062, pages 213–221.
Martin Benjamin and Paula Radetzky.
2014.
Multilingual
lexicography with a focus on
less-resourced languages:
Data mining,
ex-
pert input, crowdsourcing, and gamification.
In 9th edition of
the Language Resources
and Evaluation Conference,
EPFL-CONF-
200375.
Daren C Brabham.
2012.
A model
for lever-
aging online communities.
The participatory
cultures handbook, 120.
Francesca Chiusaroli.
2015.
La scrittura in
emoji
tra dizionario e traduzione.
CLiC it,
page 88.
Jeff Howe.
2006.
The rise of
crowdsourcing.
Wired magazine, 14(6):1–4.
Nitin
Madnani,
Joel
Tetreault,
Martin
Chodorow,
and
Alla
Rozovskaya.
2011.
They can help:
Using
crowdsourcing
to
improve the evaluation of grammatical error
detection systems.
In Proceedings
of
the
49th
Annual
Meeting
of
the
Association
for
Computational
Linguistics:
Human
Language
Technologies:
short
papers-
Volume 2,
pages
508–513.
Association for
Computational Linguistics.
Jane McGonigal. 2011.
Reality is broken:
Why
games
make
us
better
and how they can
change the world.
Penguin.
Johanna Monti. 2012.
Translators’ knowledge
in the cloud:
The new translation technolo-
gies.
In International
Symposium on Lan-
guage and Communication:
Research Trends
and Challenges(ISLC).
Johanna Monti.
2014.
Dictionaries
in the
cloud:
state of
the art,
trends
and chal-
lenges.
Les Cahiers du dictionnaire, (6):95–
110.
Aobo Wang,
Cong Duy Vu Hoang,
and Min-
Yen Kan. 2013. Perspectives on crowdsourc-
ing annotations
for
natural
language pro-
cessing.
Language resources and evaluation,
47(1):9–31.
CLIC_2016_Proceedings.indd 215
02/12/16 15.04
216
KD Strikes Back: from Keyphrases to Labelled Domains Using External
Knowledge Sources
Giovanni Moretti
1
, Rachele Sprugnoli
1-2
, Sara Tonelli
1
1
Fondazione Bruno Kessler, Trento
2
Universit
`
a di Trento
{
moretti,sprugnoli,satonelli
}
@fbk.eu
Abstract
English.
This
paper
presents
L-KD,
a
tool
that
relies
on available
linguis-
tic and knowledge resources to perform
keyphrase clustering and labelling.
The
aim of L-KD is to help finding and trac-
ing themes in English and Italian text data,
represented by groups of keyphrases and
associated domains. We perform an evalu-
ation of the top-ranked domains using the
20 Newsgroup dataset,
and we show that
8 domains out of 10 match with manually
assigned labels.
This confirms the good
accuracy of this approach, which does not
require supervision.
Italiano.
In questo lavoro descriviamo L-
KD,
un sistema che utilizza risorse lin-
guistiche e basate su conoscenza per ra-
gruppare concetti-chiave e categorizzarli.
L’obiettivo di
L-KD
`
e quello di
support-
are gli
utenti
nel
rilevare la presenza di
specifici
temi
in documenti
italiani
e in-
glesi,
rappresentandoli
attraverso gruppi
di
concetti-chiave e relativi
domini.
Ab-
biamo valutato l’affidabilit
`
a del
sistema
analizzando i domini pi
`
u rilevanti nel 20
Newsgroup dataset,
e dimostrando che 8
su 10 domini
nel
gold standard sono as-
segnati
correttamente anche dal
sistema.
Questa valutazione
conferma le
buone
performance di L-KD, senza il bisogno di
supervisione.
1
Introduction
With the increasing availability of large document
collections in digital format, companies, organiza-
tions but also non-expert users face everyday the
need to efficiently extract and categorize relevant
information from large corpora.
The possibility
to extract key-concepts and assign them to a do-
main without
the need of supervision would al-
low them to systematically track the flow of in-
formation and retain only relevant content at two
granularity levels:
key-concepts,
and domains to
which these key-concepts can be ascribed.
Al-
though topic models (Blei et al., 2003) can be used
to this purpose,
they have two main drawbacks:
the number of topics for a corpus is arbitrary and
topics are often not labelled.
In this work,
we present
a solution to the afore-
mentioned research problem by presenting L-
KD (Labelled-KD),
a tool
to perform keyphrase
clustering and labelling through the exploitation
of
external
linguistic and knowledge resources.
The tool
takes advantage of
the availability of
Keyphrase
Digger
1
(KD),
a
multilingual
rule-
based system that
detects a weighted list
of
n-
grams representing the most important concepts in
a text (Moretti et al.,
2015).
These key-concepts
are then linked to WordNet
Domains (Magnini
and Cavaglia,
2000) in order to create clusters of
key-concepts labelled by domain.
The problem
of ambiguous concepts,
i.e.
possibly belonging
to more than one WordNet domain,
is tackled by
using ConceptNet 5 (Speer and Havasi,
2013),
a
multilingual
knowledge source containing single
and multi-word concepts linked to each other by
a broad set
of relations covering different
types
of associations.
The outcome of this study is the
L-KD tool,
supporting both English and Italian,
which we make available to the research commu-
nity
2
. L-KD takes in input a document in plain text
format, and outputs the ranked list of semantic do-
mains discussed in the documents, each associated
with a set of keyphrases.
1
http://dh.fbk.eu/technologies/kd
2
https://dh.fbk.eu/technologies/l-kd
CLIC_2016_Proceedings.indd 216
02/12/16 15.04
217
2
Related Works
In the last
years,
a number
of
works
dealing
with the unsupervised clustering of
keyphrases
has been presented (Hasan and Ng,
2014).
Liu
et
al.
(2009)
use Wikipedia and co-occurrence-
based statistics
to semantically cluster
similar
keyphrases in a set of unweighted topics.
In order
to improve this approach by weighting topics, Liu
et al.
(2010) and Grineva et al.
(2009) propose a
topic-decomposed PageRank and a network anal-
ysis algorithm respectively to perform hierarchical
clustering.
Our method is simpler than the previ-
ously mentioned studies,
and relies on available
resources to label the clusters.
Indeed, the lists of
terms listed in the topics are not
always easy to
interpret
(Aletras et
al.,
2015),
and adding a la-
bel that captures the meaning of each cluster is a
way to enhance its understanding.
The problem
of interpretation affects also the output
of topic
modelling algorithms,
i.e.
unsupervised statisti-
cal
methods such as Latent
Dirichlet
Allocation
(Blei
et
al.,
2003).
Many techniques have been
developed to automatically label topics for exam-
ple by using probabilistic approaches (Mei et al.,
2007),
Wikipedia links (Xu and Oard,
2011) and
DBpedia structured data (Hulpus et al., 2013).
As
for the automatic labelling of keyphrase clusters,
Carmel et al. (2009) adopt Wikipedia as an exter-
nal
resource to extract
candidate labels.
To the
best
of our knowledge,
no available system per-
forms this task by combining WordNet Domains
and ConceptNet 5.
3
System Overview
Figure 1:
General workflow underlying L-KD for
English documents with the steps involving the
use of Stanford CoreNLP, KD, WordNet Domains
(WND) and ConceptNet 5 (CN5).
Figure 2:
Excerpt of the expansion of an ambigu-
ous keyphrase using ConceptNet 5 (top) and top
domains assigned to this expansion (bottom).
L-KD performs several steps (see Fig.
1) to se-
mantically cluster keyphrases and label each clus-
ter:
1)
Text
preprocessing:
Stanford CoreNLP
(Manning et al.,
2014) is used to split sentences,
tokenize, lemmatize and tag the part-of-speech of
the input English text. For Italian texts, we rely on
Tint
3
, a suite of NLP tools (Aprosio and Moretti,
2016) based on the Stanford CoreNLP pipeline.
2)
Keyphrase extraction and ranking:
L-
KD integrates KD,
a keyphrase extraction tool
that combines statistical and linguistic knowledge,
given by recurrent
relevant
PoS patterns,
to ex-
tract single words and multi-token expressions en-
coding the main concepts of a document.
A de-
tailed description of KD functionalities is given in
Moretti et al.
(2015).
The output of this step is a
weighted and ranked list of keyphrases.
3) Domain mapping:
L-KD maps the lemma
forms of
keyphrases with the lemmas in WND
aligned to WordNet
3.0
4
.
For
Italian we rely
on the data available through the Open Multi-
lingual
WordNet
project
(Bond and Paik,
2012)
as a bridge between lemmas and WND.
In case
of multi-token expressions (e.g.
“federal govern-
ment”), the system looks for a perfect match. If no
match is found, the tokens are splitted and only the
nouns are searched in WND (e.g.
“government”).
A list
of domain-keyphrases associations is cre-
ated,
as well
as a list
of ambiguous keyphrases.
The latter comprises those that are assigned to the
Factotum domain and those that
could belong
to several domains, if none of them contains
>
3
keyphrases. This threshold was manually set in or-
der to identify domains that are likely to be little
relevant.
4) Expansion of ambiguous keyphrases:
The
lemmas of ambiguous keyphrases are aligned with
3
http://tint.fbk.eu/
4
Courtesy of Carlo Strapparava.
CLIC_2016_Proceedings.indd 217
02/12/16 15.04
218
the lemmas in ConceptNet
5 and are expanded
by retrieving all
the connected concepts follow-
ing ConcepNet
5 relations.
L-KD relies on a
subset
of relations including hierarchical
(HasA,
PartOf,
MadeOf,
IsA, DerivedFrom) and synony-
mous (Synonym, RelatedTo) ones (Mukherjee and
Joshi,
2013).
Functional relations such as Capa-
bleOf
and UsedFor are not
taken into consider-
ation because the concepts evoked by these rela-
tions may be too far from the original
meaning
of
the key-concept.
The upper
part
of
Fig.
2
shows how “nature”,
an ambiguous keyphrase,
is
expanded following this procedure.
Examples of
the relations that lead to this expansion are the fol-
lowing:
- nature
⇒
RelatedTo
⇒
flora
- nature
⇒
IsA
⇒
great
place
- nature
⇒
HasA
⇒
many wonder
5) Domain mapping of expanded keyphrases:
All the lemmas included in the expansion created
in the previous step are mapped to domains us-
ing WND.
The lower part
of Fig.
2 reports the
top domains related to the expansion of “nature”
together
with the number
of
lemmas associated
with them,
e.g.
19 lemmas are mapped to the
Biology domain.
A relevance score (i.e.
num-
ber
of
keyphrases associated with a domain)
is
computed for the domains retrieved for each ex-
panded keyphrase.
Domains are then compared
with the ones found in Step (3) starting from the
domain with the highest
score.
If
it
is already
present in the domain-keyphrases list compiled in
Step (3), then the keyphrase is associated with this
domain, otherwise the other domains are checked.
If the domain is not present in the list, it is added to
the list with its associated keyphrase. The final rel-
evance score of the domains is recalculated at the
end of this step. Four sub-domains of Factotum,
i.e.
Time
Period,
Person,
Metrology and
Numbers, which are very generic, usually have a
high relevance because they tend to include many
keywords.
Therefore,
we introduce a final
re-
weighting step to deboost them.
6)
Final
ranking.
L-KD creates
a
final
ranked list of domains associated with clusters of
keyphrases. The ranking is based on the relevance
score of the domains as described in the previous
step and on the rank of keyphrases as given by KD
in step (2).
4
Evaluation
We
evaluated L-KD using the
20 Newsgroup
dataset (Joachims, 1996), a corpus of 20,000 doc-
uments extracted from UseNet discussion groups.
This dataset
is freely available online
5
and has
been often employed to train and test text catego-
rization algorithms (Moschitti
and Basili,
2004).
Specifically,
each of
its documents was manu-
ally assigned to one out of twenty different cate-
gories,
which can be easily mapped to WND la-
bels.
Although L-KD can assign a ranked list of
domains to one or more documents,
thus provid-
ing a richer representation of the document(s) con-
tent,
we did not
find a suitable gold standard to
evaluate the rank.
Therefore,
we limit
our eval-
uation to the top-ranked domain extracted by the
tool.
We also decided to group Newsgroup cate-
gories that are strictly related to each other:
e.g.
documents in talk.religion.misc,
alt.atheism,
and
soc.religion.christian all
discuss religious issues
and for this reason their texts are collapsed in a
single category.
Table
1
reports
the
results
of
L-KD on
the
documents included in each category or
group
of
categories.
The second column shows
the
top two domains
retrieved by the system and
the third column presents some of the extracted
keyphrases.
Only in 2 cases
out
of
10,
the
first
ranked domain does
not
perfectly match
the original
category:
indeed Law is
the top
domain of
sci.eletronics
and of
the documents
related
to
political
themes
(talk.politics.misc,
talk.politics.guns,
talk.politics.mideast).
We can
notice that Law is a very frequent domain because
it
contains generic and recurring words such as
“article”, “opinion” and “information”.
In the rest
of the cases (8 out of 10), the match between the
first
ranked domain and the original
category is
perfect:
for example,
the domain with the high-
est rank for documents discussing computer tech-
nologies is Computer
Science. In many cases
also the second domain is extremely relevant.
For
instance,
misc.forsale contains messages of peo-
ple searching or
selling goods with a focus on
computer devices and components:
the first
re-
trieved domain is Commerce and the second one
is Computer Science. Each domain is associ-
ated with pertinent keyphrases such as “best offer”
for the first domain and “floppy drive” for the sec-
ond.
5
http://qwone.com/
˜
jason/20Newsgroups/
CLIC_2016_Proceedings.indd 218
02/12/16 15.04
219
ORIGINAL CATEGORIES
TOP DOMAINS
KEYPHRASES
sci.med
Medicine
doctor, infectious disease, side effect
School
course, science, study
sci.space
Astronomy
solar system, physical universe, satellite
Transport
spacecraft, shuttle, high-speed collision
sci.crypt
Computer Science
internet, e-mail, bit
Law
security, second amendment, criminal
sci.electronics
Law
article, opinion, information
Electricity
amateur radio, voltage, wire
talk.religion.misc - alt.atheism -
soc.religion.christian
Religion
christian, atheist, objective morality
Law
law, evidence, private activities
rec.sport.baseball - rec.sport.hockey
Sport
game, playoff, second period
Play
player, baseball
rec.autos - rec.motorcycles
Transport
car, mph, front wheel
Law
article, opinion
comp.graphics - comp.os.mswindows.misc -
Computer Science
software, hard drive, anonymous ftp
comp.sys.ibm.pc.hardware - comp.windows.x
Publishing
article, opinion
- comp.sys.mac.hardware
talk.politics.misc - talk.politics.guns -
talk.politics.mideast
Law
opinion, second amendment
Transport
road, ways of escape
misc.forsale
Commerce
best offer, price, excellent condition
Computer Science
hard drive, floppy drive, email
Table 1:
Results of L-KD on the 20 Newsgroup dataset.
The original categories are compared with the
top domains extracted by the systems.
Examples of keyphrases are provided for each domain.
Perfect
matches between the main theme of the original classification and L-KD top domains are in bold.
5
Use Case: the De Gasperi Project
L-KD has been recently applied to the analysis
of the complete corpus of public writings by Al-
cide De Gasperi
(De Gasperi,
2006) in the con-
text
of a research project,
whose goal
is to give
insight into De Gasperi’s communication strategy
with the help of innovative tools for text
analy-
sis.
We processed the 2,762 documents (around
3,000,000 tokens)
in the corpus,
published be-
tween 1901 and 1954,
to analyse which domains
appeared in the collection and how they changed
over time.
The advantage of L-KD is that it can
provide both a distant view, by computing aggre-
gated information on the domains,
and a close
reading of
the documents,
showing which key-
concepts are mapped to which domain.
As an ex-
ample, we report in Fig.
3 the analysis related to
two documents, entitled “Rene de la Tour du Pin”
and “I cattolici nell’evoluzione sociale’.
For each
of them,
the dendogram shows the three top do-
mains and the associated key-concepts.
The pro-
posed analysis was validated at different granular-
ities by two history scholars,
who confirmed the
consistency of
L-KD analysis and found corre-
spondences between the top domains and relevant
events in De Gasperi’s life.
Figure 3:
Dendogram related to two documents
from De Gasperi’s corpus
6
Tool Availability
L-KD is available as a web application
6
through
which users can copy&paste a document and run
the tool processing it on the fly.
This application
makes L-KD easily accessible also by users with-
out a technical background.
6
http://dhlab.fbk.eu:8080/L_KD/
CLIC_2016_Proceedings.indd 219
02/12/16 15.04
220
In the application some parameters
are given,
while others can be changed by the user accord-
ing to his/her
needs.
As for
the fixed parame-
ters, proper names are always discarded so to ex-
clude them from the list of keyphrases: this setting
is justified by the fact
that
WordNet,
and conse-
quently WND, contains few proper nouns
7
while
we want to maximize the mapping.
For the same
reason,
short
keyphrases,
i.e.
single words and
multi-token expressions with a maximum length
of 4 words
8
,
are preferred.
On the contrary,
the
minimum number of occurrences for a word or ex-
pression to be considered as a candidate keyphrase
and the number of keyphrases to be extracted can
be customized by the user.
For example,
in case
of short documents,
a low number of keyphrases
(e.g. up to 20) can be set together with a minimum
frequency of 1 or 2 (in a short text repetitions are
less likely to occur).
For long documents more
keyphrases can be extracted:
in this way it would
be easy to find clusters covering multiple themes.
7
Conclusions and Future Works
This paper
presents L-KD,
a tool
that
extracts
keyphrases from text data,
clusters them accord-
ing to the domain and assigns a label to each clus-
ter.
The process underlying L-KD is based on the
exploitation of external linguistic and knowledge
resources, i.e. WordNet Domains and ConceptNet
5.
Our tool can process both English and Italian
texts of different length and content, from a single
news article to an entire book, from single-theme
to multi-theme documents.
In the future we will explore different research
directions.
First
of all
we want
to evaluate the
tool
on Italian data,
even if we have not
found
a suitable gold standard so far.
Resorting to
crowd-sourcing may be a viable solution.
We ex-
pect
lower performances than the ones obtained
for English,
given that
the current
mapping be-
tween Open Multilingual WordNet and WordNet
3.0 covers only the 32.5% of the English synsets:
this consequently affects the mapping on the do-
mains of WND. Moreover, the coverage of Italian
in ConcepNet 5 is limited.
As for the availability
of L-KD,
we plan to release the tool as a stand-
alone module. It will also be integrated in the AL-
CIDE platform (Moretti et al., 2016) that supports
7
Only the 9.4% of synsets are tagged as being instances,
i.e. proper nouns, in WordNet 3.0 (Abrate et al., 2012).
8
In WordNet
3.0 only the 0.2% of noun synsets have a
length greater than 4 words.
the analysis of large document collections for hu-
manities studies.
Acknowledgments
The research leading to this paper was partially
supported by the EU Horizon 2020 Programme via
the SIMPATICO Project
(H2020-EURO-6-2015,
n.
692819).
We thanks Alessio Palmero Aprosio
for his help in the evaluation process.
References
Matteo Abrate,
Clara Bacciu,
Andrea Marchetti,
and
Maurizio Tesconi.
2012.
WordNet
atlas:
a web
application for visualizing WordNet as a zoomable
map.
In GWC 2012 6th International Global Word-
net Conference, page 23.
Nikolaos Aletras, Timothy Baldwin, Jey Han Lau, and
Mark Stevenson.
2015.
Evaluating topic represen-
tations for exploring document collections.
Journal
of the Association for Information Science and Tech-
nology.
Alessio
Palmero
Aprosio
and
Giovanni
Moretti.
2016.
Italy goes
to Stanford:
a collection of
CoreNLP modules
for
Italian.
arXiv
preprint
arXiv:1609.06204.
David M Blei,
Andrew Y Ng,
and Michael
I Jordan.
2003.
Latent
dirichlet
allocation.
Journal
of
ma-
chine Learning research, 3(Jan):993–1022.
Francis Bond and Kyonghee Paik.
2012.
A survey of
WordNets and their licenses.
Small, 8(4):5.
David Carmel,
Haggai
Roitman,
and Naama
Zw-
erdling.
2009.
Enhancing cluster labeling using
wikipedia.
In Proceedings of the 32nd international
ACM SIGIR conference on Research and develop-
ment in information retrieval, pages 139–146. ACM.
A.
De Gasperi.
2006.
Scritti
e discorsi
politici.
In
E.
Tonezzer,
M.
Bigaran,
and M.
Guiotto,
editors,
Scritti e discorsi politici, volume 1. Il Mulino.
Maria Grineva,
Maxim Grinev,
and Dmitry Lizorkin.
2009.
Extracting key terms from noisy and multi-
theme documents.
In Proceedings of the 18th inter-
national conference on World wide web, pages 661–
670. ACM.
Kazi Saidul Hasan and Vincent Ng.
2014.
Automatic
keyphrase extraction: A survey of the state of the art.
In Proceedings of the 52nd Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1262–1273. Association for
Computational Linguistics.
Ioana Hulpus,
Conor
Hayes,
Marcel
Karnstedt,
and
Derek Greene.
2013.
Unsupervised graph-based
topic labelling using dbpedia.
In Proceedings of the
CLIC_2016_Proceedings.indd 220
02/12/16 15.04
221
sixth ACM international conference on Web search
and data mining, pages 465–474. ACM.
Thorsten Joachims.
1996.
A Probabilistic Analysis of
the Rocchio Algorithm with TFIDF for Text Catego-
rization.
Technical report, DTIC Document.
Zhiyuan Liu,
Peng Li,
Yabin Zheng,
and Maosong
Sun.
2009.
Clustering to find exemplar terms for
keyphrase extraction.
In Proceedings of
the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 1-Volume 1, pages 257–
266. Association for Computational Linguistics.
Zhiyuan
Liu,
Wenyi
Huang,
Yabin
Zheng,
and
Maosong Sun.
2010.
Automatic keyphrase extrac-
tion via topic decomposition.
In Proceedings of the
2010 conference on empirical
methods in natural
language processing,
pages 366–376.
Association
for Computational Linguistics.
Bernardo Magnini and Gabriela Cavaglia.
2000.
Inte-
grating Subject Field Codes into WordNet.
In Pro-
ceedings of the Second International Conference on
Language Resources and Evaluation (LREC-2000).
Christopher D Manning, Mihai Surdeanu, John Bauer,
Jenny Rose Finkel, Steven Bethard, and David Mc-
Closky.
2014.
The Stanford CoreNLP Natural Lan-
guage Processing Toolkit.
In ACL (System Demon-
strations), pages 55–60.
Qiaozhu Mei,
Xuehua Shen,
and ChengXiang Zhai.
2007.
Automatic labeling of
multinomial
topic
models.
In Proceedings of the 13th ACM SIGKDD
international
conference on Knowledge discovery
and data mining, pages 490–499. ACM.
Giovanni Moretti, Rachele Sprugnoli, and Sara Tonelli.
2015.
Digging in the dirt:
Extracting keyphrases
from texts with kd.
In Proceedings of CLiC-it 2016,
page 198.
Giovanni Moretti, Rachele Sprugnoli, Stefano Menini,
and Sara Tonelli.
2016.
ALCIDE: Extracting and
visualising content from large document collections
to support
Humanities studies.
Knowledge-Based
Systems, 111:100–112.
Alessandro Moschitti and Roberto Basili.
2004.
Com-
plex linguistic features for
text
classification:
A
comprehensive study.
In European Conference on
Information Retrieval, pages 181–196. Springer.
Subhabrata Mukherjee and Sachindra Joshi.
2013.
Sentiment Aggregation using ConceptNet Ontology.
In Proceedings of the Sixth International Joint Con-
ference on Natural Language Processing (IJCNLP),
pages 570–578.
Robert Speer and Catherine Havasi.
2013.
ConceptNet
5:
A large semantic network for relational
knowl-
edge.
In The Peoples Web Meets NLP, pages 161–
176. Springer.
Tan Xu and Douglas W Oard.
2011.
Wikipedia-based
topic clustering for microblogs.
Proceedings of the
American Society for Information Science and Tech-
nology, 48(1):1–10.
CLIC_2016_Proceedings.indd 221
02/12/16 15.04
222
La leggibilità dei testi di ambito medico rivolti al paziente: 
il caso dei bugiardini di farmaci senza obbligo di prescrizione medica 
Franca Orletti 
Dipartimento di Studi Umanistici Univer-
sità di Roma Tre 
franca.orletti@uniroma3.it 
Felice Dell’Orletta 
Istituto di Linguistica Computazionale “Anto-
nio Zampolli” (ILC–CNR) 
ItaliaNLP Lab - 
www.italianlp.it
felice.dellorletta@ilc.cnr.it
Rossella Iovino 
Dipartimento di Studi Umanistici Università di Roma Tre 
rossella.iovino@uniroma3.it
Abstract 
English.
In this paper we present the first re-
sults of an exploratory analysis of simplifica-
tion 
of the 
package 
leaflets 
of 
medicines, 
considered 
representative 
texts 
of 
doctor-
patient communication. It will be shown how 
natural language processing tools can be used 
to reconstruct the linguistic profile of these 
texts and to guide their simplification. 
Italiano. 
In 
questo 
articolo 
presentiamo 
i 
primi 
risultati di un lavoro 
esplorativo di 
analisi e semplificazione dei foglietti illustra-
tivi dei medicinali, considerati testi rappre-
sentativi 
della 
comunicazione 
medico-
paziente. Verrà mostrato come strumenti per 
il trattamento automatico del linguaggio na-
turale (TAL) possono essere utilizzati per ri-
costruire il profilo linguistico di questi testi e 
per guidarne la semplificazione. 
1
Introduzione 
Questo contributo intende affrontare la questione 
della semplificazione linguistica dei testi di am-
bito medico rivolti direttamente ai pazienti, come 
è il caso dei bugiardini di farmaci senza obbligo 
di prescrizione medica. Nonostante le iniziative 
ufficiali prese dall’AIFA, come quella della rea-
lizzazione della Banca Dati Farmaci per aiutare 
gli utenti a usare correttamente i farmaci com-
prendendone i benefici e gli eventuali effetti in-
desiderati, è noto che la lingua utilizzata in questi 
e altri testi di ambito medico (e non solo) è com-
plessa e spesso non adeguata alle competenze dei 
cittadini. Si spiegano così anche le numerose ini-
ziative 
di 
semplificazione 
linguistica 
diffusesi 
negli Stati Uniti e in Europa (compresa l’Italia) 
volte 
alla 
semplificazione 
linguistica 
dei 
testi 
istituzionali (cfr., tra gli altri, De Mauro 1980, 
Fioritto 1997, Cortelazzo 1999, De Mauro e Ve-
dovelli 1999, Piemontese 2003, Fortis 2003). 
In questo lavoro, dopo aver illustrato breve-
mente i principali aspetti di complessità della 
lingua di ambito medico e aver presentato il 
cor-
pus
di bugiardini, ci si soffermerà sul contributo 
offerto 
alla 
semplificazione 
linguistica 
dagli 
strumenti di Trattamento Automatico del Lin-
guaggio; 
in 
particolare, 
si 
farà 
riferimento 
al 
software READ-IT (sezione 2). Il software è sta-
to impiegato per monitorare (misurandone il li-
vello di leggibilità) alcune caratteristiche lingui-
stiche del bugiardino di VIVIN C®, scelto per-
ché vendibile senza obbligo di prescrizione me-
dica (sezione 2.1). READ-IT può costituire un 
valido aiuto per chi scrive testi di pubblica utili-
tà: 
la misurazione 
della complessità del 
testo 
consente interventi di riscrittura nella direzione 
della massima leggibilità (sezione 3.2). Saranno, 
infine delineate delle conclusioni (sezione 4). 
2
La 
comunicazione 
scritta 
medico-
paziente 
Nella complessa relazione tra medico e paziente, 
la lingua non è soltanto funzionale alla comuni-
cazione, ma è utile al medico per ribadire il suo 
prestigio e la sua distanza sociale ed epistemica 
rispetto al paziente (Freidson 1970, Heritage e 
Maynard 2006, Heritage 2012). 
La lingua medica, e soprattutto la componente 
tecnica che la caratterizza e che la qualifica come 
una lingua settoriale (Beccaria 1973) o lingua 
specialistica (Berruto 1993, Sobrero 1993), è uno 
strumento che aiuta il medico a esercitare la pro-
pria “visione professionale”, proiettata sulla real-
CLIC_2016_Proceedings.indd 222
02/12/16 15.04
223
tà quando questa è osservata dalla prospettiva 
dello specialista (Goodwin 1994; Orletti 2000). 
Questo è evidente nelle difficoltà che i pazienti 
incontrano nella comprensione della comunica-
zione di argomento medico, che viene percepita 
come difficile da molti punti di vista. 
Il maggiore aspetto di difficoltà della lingua 
medica è connaturato proprio al suo essere una 
varietà di lingua utilizzata in una specifica situa-
zione comunicativa collegata a un preciso ambito 
tematico. Oltre a ciò sono stati messi in evidenza 
in letteratura altri aspetti di complessità della 
lingua medica. Sul piano lessicale si osserva una 
notevole stratificazione che caratterizza questa 
varietà settoriale (Serianni 2005): vi si trovano, 
infatti, 
grecismi, 
latinismi, 
arabismi, 
anglismi 
usati spesso come tecnicismi. Su quello morfo-
sintattico sono significativi i processi di forma-
zione delle parole che prevedono, ad esempio, 
una specializzazione dei suffissi (es. -
ite
per i 
processi infiammatori, -
osi
per le affezioni di 
carattere degenerativo), la presenza di acronimi 
(es. TAC = Tomografia Assiale Computerizzata) 
e di eponomi per indicare patologie (es. 
morbo di 
Parkinson
) oppure parti del corpo (es. 
tube di 
Falloppio
), 
nonché 
di 
composti 
con 
elementi 
neoclassici (es. 
pediatria
) (Iacobini 2004, Thorn-
ton 2004). Interessanti sono poi le osservazioni 
di natura sintattica e testuale (Serianni 2001), che 
riguardano la preferenza per aggettivi di relazio-
ne (
stato febbrile
), l’anteposizione del soggetto 
nelle frasi passive (
cautela deve essere prestata
), 
il frequente ricorso a strutture frasali impersonali 
(
si deve prestare attenzione
), la preferenza per 
nomi astratti, nominalizzazioni (
l’uso della dose 
minima di farmaco per il trattamento più breve 
possibile
) e forme nominali del verbo (
antireu-
matico non steroideo appartenente alla classe 
dei 
derivati 
dell’acido 
propionico
). 
Tutto 
ciò 
risponde alle esigenze di sintesi e compattezza 
che accomunano lo stile dei testi di ambito medi-
co 
a 
quello 
dei 
testi 
specialistici 
in 
generale 
(Dardano 1986), contribuendo a renderli difficili, 
in quanto brevità non sempre è sinonimo di sem-
plicità (Orletti 2015). Questi presentano, infatti, 
una struttura codificata (Cortelazzo 2010) molto 
vincolata (Sabatini 1990). 
Data la complessità della lingua medica, che si 
realizza a livelli linguistici diversi, per l’analisi 
dei 
bugiardini 
è 
stato 
utilizzato 
il 
software 
READ-IT, sviluppato dall’
Italian Natural Lan-
guage Processing Laboratory
(ItaliaNLP Lab) 
dell’Istituto di Linguistica Computazionale “An-
tonio 
Zampolli” 
(ILC) 
del 
CNR 
di 
Pisa 
(Dell’Orletta, Montemagni, Venturi, 2011). Que-
sto software è in grado di computare parametri 
linguistici molto più articolati rispetto a software 
tradizionali che restituiscono indici di leggibilità 
basati per lo più sulla lunghezza di frasi e parole. 
READ-IT implementa, infatti, un indice di leggi-
bilità “avanzato” basato su una analisi linguistica 
multi-livello del testo. In aggiunta all’analisi a 
livello semantico-lessicale, READ-IT è in grado 
di fornire una descrizione linguistica anche a li-
vello morfologico e sintattico. Oltre a ciò, ai fini 
della riscrittura semplificata del testo, READ-IT 
offre la possibilità di avere un indice della leggi-
bilità del testo non solo a livello dell’intero do-
cumento, ma anche della singola frase, favorendo 
così interventi analitici. 
2.1
Il corpus: alcuni dati quantitativi 
Il 
corpus
è costituito da 7335 bugiardini estratti 
dal portale di informazione sanitaria e farmaceu-
tica www.torrinomedica.it. Dal 
corpus
sono stati 
selezionati circa 100 bugiardini relativi ad alcuni 
tra i farmaci vendibili senza obbligo di prescri-
zione medica tra più diffusi in commercio, per un 
totale di 189315 
token
e 16937 frasi. 
La scelta è ricaduta sui farmaci vendibili sen-
za prescrizione medica perché, essendo accessi-
bili direttamente ai cittadini, dovrebbero presen-
tare bugiardini quanto più possibile comprensibi-
li per garantire un corretto uso autonomo del 
farmaco. 
Per dare un’idea della difficoltà dei testi presi 
in esame, i 100 bugiardini sono stati analizzati 
automaticamente 
e 
arricchiti 
con 
annotazione 
morfo-sintattica e sintattica. A tal fine è stata 
utilizzata una piattaforma di strumenti per il trat-
tamento 
automatico 
dell’italiano: 
per 
l’annotazione morfo-sintattica, lo strumento uti-
lizzato è descritto in Dell’Orletta (2009), mentre 
per 
l’analisi 
sintattica 
a 
dipendenze, 
abbiamo 
utilizzato DeSR (Attardi 
et al
. 2009). Il testo lin-
guisticamente 
annotato 
costituisce 
il 
punto 
di 
partenza per le analisi successive volte a definire 
il profilo linguistico sottostante al testo a partire 
dal quale, e attraverso il confronto con il profilo 
linguistico di altri 
corpora
di riferimento, è pos-
sibile ricostruirne un quadro della complessità. I 
corpora
utilizzati nel confronto appartengono a 
due generi testuali diversi: quello giornalistico 
(Piemontese 1996 e Marinelli 
et al
. 2003) e quel-
lo contenente materiali didattici (Dell’Orletta 
et 
al
. 2011). Per ognuno dei due generi si indivi-
duano due classi: testi semplici e difficili. Per i 
testi giornalistici, quelli facili sono i testi estratti 
dal mensile 
2Parole
(2P) di “facile lettura”, che 
si presta alla comprensione anche da parte di per-
CLIC_2016_Proceedings.indd 223
02/12/16 15.04
224
sone con deficit cognitivi, e quelli difficili sono 
quelli estratti da 
Repubblica 
(R); mentre nei testi 
didattici sono inclusi quelli per le scuole elemen-
tari (MDE) e superiori (MDS). 
I risultati quantitativi del confronto tra i 
cor-
pora
sono riassunti nelle Tabelle 1 e 2, in cui 
sono forniti risultati dei confronti quantitativi tra 
il 
corpus 
di riferimento e, rispettivamente, i 
cor-
pora
ritenuti facili e difficili: 
Facili 
Corpus 
2P 
MDE 
Tokens frase 
11.18 
12.14 
18.36 
Altezza alberi 
3.21 
5.29 
5.54 
Lunghezza link 
4.4 
7.91 
8.89 
Tokens clausola 
17.3 
9.81 
8.09 
Tabella 1: Confronto quantitativo con 
corpora
facili 
Difficili 
Corpus 
R 
MDS 
Tokens frase 
11.18 
28.94 
22.76 
Altezza alberi 
3.21 
6.51 
7.36 
Lunghezza link 
4.4 
10.28 
12.5 
Tokens clausola 
17.3 
10.12 
9.2 
Tabella 2 Confronto quantitativo con corpora 
difficili 
Le frasi del 
corpus 
di bugiardini analizzati ri-
sultano essere piuttosto brevi con un numero di 
token
per frase pari a 11.18, valore ancora più 
basso di quelli riscontrati nei due 
corpora 
di con-
trollo 
ritenuti 
facili 
(12.14 
per 
2P
18.36 
per 
MDE). La brevità delle frasi, insieme al fatto che 
molte di esse sono prive di verbo, condiziona di 
conseguenza almeno altri due parametri quantita-
tivi: la media dell’altezza degli alberi sintattici 
che nel 
corpus
di riferimento è pari a 3.21, valore 
molto basso rispetto a 
corpora
facili come 2P 
(5.29) e MDE (5.54); e la lunghezza media dei 
link sintattici più lunghi (calcolata in termini di 
token
che intercorrono tra la 
testa
ed il 
dipenden-
te
) di ogni frase che è di 4.4 nel 
corpus
di riferi-
mento rispetto a 7.91 per 2P, 10.28 per R, 8.89 
per MDE e 12.5 per MDS. La situazione si capo-
volge completamente quando si valuta il numero 
medio di 
token
per clausola verbale. Notiamo 
subito come in presenza di strutture verbali il 
testo diventi estremamente complesso mostrando 
un numero medio di 17.36 
token
, che è molto 
alto se viene confrontato con i valori estratti dai 
corpora
di riferimento considerati difficili: 10.12 
per R e 9.2 per MDS. 
Interessante è poi la distribuzione del lessico, 
riassunta nella Tabella 3: 
Parole del corpus presenti in VdB 
41.12% 
Diz. 
fondamentale 
Diz. 
alto uso 
Diz. 
alta dispon. 
66.48% 
25.84% 
7.67% 
Parole del corpus R in VdB 
67.09% 
Diz. 
fondamentale
Diz. 
alto uso
Diz. 
alta dispon.
75.5% 
18.95% 
5.8% 
Tabella 3 Distribuzione del lessico 
la media di parole trovate nel Vocabolario di 
Base 
(VdB, 
De 
Mauro 
1980) 
è 
soltanto 
del 
41.12%, di cui il 66.48% appartiene al Diziona-
rio Fondamentale, il 25.84% al Dizionario di Al-
to Uso e il 7.67% al Dizionario di Alta Disponi-
bilità. Il 
corpus 
R, pur ritenuto difficile, ha un 
valore più alto di parole appartenenti al VdB 
(67.09%), di cui il 75.5% appartiene al Diziona-
rio fondamentale, il 18.95% al Dizionario di Alto 
Uso e il 5.28% al Dizionario di Alta Disponibili-
tà. Questo qualifica il lessico dei bugiardini ana-
lizzati come molto difficile. Ciò è dovuto al fatto 
che molte delle parole non contenute nel VdB 
coincidono con termini tecnici, termini astratti, 
termini 
appartenenti 
al 
lessico 
specialistico, 
compresi i prestiti da altre lingue moderne e i 
latinismi, alcuni dei quali sono utilizzati come 
tecnicismi e altri come espressioni utili per in-
nalzare il registro linguistico (Orletti e Iovino in 
stampa). 
3
Il software READ-IT per la semplifi-
cazione dei testi: esempi di riscrittura 
L’applicazione 
di 
READ-IT 
a 
supporto 
della 
semplificazione dei testi dei bugiardini è stata 
sperimentata sul bugiardino di VIVIN C®. 
READ-IT è in grado di valutare la leggibilità 
su due livelli: il documento e la singola frase. Per 
quanto riguarda il documento, il software misura 
la difficoltà del testo, espressa in percentuale, 
rispetto a quattro configurazioni diverse: 
base
(che tiene in considerazione la lunghezza delle 
frasi e delle parole), 
lessicale
(composizione del 
vocabolario), 
sintattico 
(misura delle categorie 
CLIC_2016_Proceedings.indd 224
02/12/16 15.04
225
morfo-sintattiche e struttura sintattica) e 
globale
(misura riassuntiva della leggibilità sulla base 
della combinazione di tutti i tratti). 
L’analisi effettuata con READ-IT restituisce 
una situazione di forte complessità per il testo del 
bugiardino di VIVIN C®, come si evince dai dati 
nella Tabella 4: 
Livello globale 
100% 
Livello base 
43.8% 
Livello lessicale 
99.7% 
Livello sintattico 
97% 
Tabella 4 Complessità linguistica bugiardino 
VIVIN C® 
la leggibilità del testo mostra, infatti, una dif-
ficoltà globale del 100%. Più in dettaglio, è inte-
ressante notare come prendendo in considerazio-
ne solo le caratteristiche di base il livello di 
complessità del testo è solo del 43.8%, mentre è 
molto più alto a livello lessicale (99.7%) e sintat-
tico (97%). 
Allo scopo di semplificare il testo preso in 
esame, la capacità di READ-IT di analizzare la 
leggibilità rispetto alle singole frasi riveste un 
ruolo centrale. 
Attraverso l’identificazione 
dei 
luoghi di complessità che necessitano di revisio-
ne e semplificazione, accompagnata da una clas-
sificazione del tipo di difficoltà riscontrata (di 
naturale 
lessicale 
vs 
grammaticale), 
READ-IT 
può essere utilizzato come guida alla semplifica-
zione del testo. Ad esempio la prima frase del 
testo del bugiardino preso in esame è la seguente: 
1.
Mal di testa e di denti, nevralgie, dolori 
mestruali, dolori reumatici e muscolari. 
L’indice di difficoltà globale della frase della 
frase è pari a 89.4%. A livello base, lessicale e 
sintattico la complessità è confermata con per-
centuali, 
rispettivamente, 
del 
71.8%, 
64.8%, 
71.2%. Per quanto riguarda più in dettaglio il 
livello lessicale, delle 10 parole di cui è compo-
sta, se non si contano le ripetizioni, soltanto 5 si 
trovano nel VdB (
di
, 
testa
, 
e
, 
mal(e)
,
dente
, 
dolo-
re
) di cui due sono parole funzionali (la congiun-
zione 
e 
e la preposizione 
di
). 
È possibile fare una serie di osservazioni sulle 
caratteristiche della frase selezionata. Innanzitut-
to, come si è già accennato, si nota l’assenza del 
verbo. Se da un lato questo si spiega con il titolo 
del paragrafo in cui la frase è inserita (
Indicazio-
ni terapeutiche
), dall’altro lato sarebbe auspica-
bile evitare frasi nominali soprattutto in presenza 
di un titolo a sua volta poco chiaro contenente un 
aggettivo relazionale che si qualifica come un 
tecnicismo. La presenza di aggettivi relazionali, 
tipici di molti linguaggi scientifici, è notevole 
nella frase in esame, dal momento che se ne tro-
vano ben 3: 
mestruali
, 
reumatici
, 
muscolari
. Se il 
concetto di 
dolori mestruali 
e di 
dolori muscolari
può risultare comprensibile perché utilizzato an-
che nella lingua d’uso, lo stesso non vale per 
do-
lori reumatici
, laddove non è così noto che i 
reumatismi
o 
malattie reumatiche 
causino scom-
pensi a livello dell’apparato locomotore e dei 
tessuti di sostegno del corpo. Interessante è an-
che l’alternanza tra espressioni della lingua d’uso 
come 
mal di testa 
(in luogo del tecnicismo 
emi-
crania
), e 
mal di denti
(piuttosto che 
odontalgia
) 
e tecnicismi come 
nevralgie
. Alla luce di quanto 
osservato, una possibile proposta di riscrittura 
semplificata della frase comprensiva del titolo 
può essere la seguente: 
2.
A cosa serve questa medicina
. 
Potete prendere la medicina in caso di 
mal di testa e mal di denti, infiammazio-
ni dei nervi, dolori da ciclo mestruale, 
dolori alle articolazioni e dolore ai mu-
scoli.
Nella proposta di riscrittura si è fatto ricorso a 
diverse strategie 
di 
semplificazione linguistica 
sebbene non tutte siano esenti da problemi. Ad 
esempio, si è adottata una varietà meno formale 
della lingua, evitando oltre ai tecnicismi specifici 
(es. 
nevralgie
), anche quelli collaterali (Serianni, 
2005) (es. 
assumere 
vs. 
prendere
). Problematica 
risulta essere talvolta la sostituzione dei tecnici-
smi specifici, spesso acclimatati nella lingua cor-
rente, con termini di più largo uso la cui verbosi-
tà (
infiammazione ai nervi
vs 
nevralgie
) può co-
stituire un ulteriore aspetto di difficoltà. 
Inoltre, sono state evitate le frasi nominali, le 
frasi 
impersonali 
e 
quelle 
passive, 
rendendo 
esplicito l’agente. Infine, una maggiore informa-
lità è stata raggiunta attraverso una allocuzione 
diretta al destinatario del medicinale mediante 
l’uso dell’allocutivo 
voi 
(
potete prendere
). Va da 
sé 
che 
la 
proposta 
di 
riscrittura 
prevede 
l’impiego di un maggior numero di parole, in 
quanto gli aggettivi relazionali sono sostituiti da 
sintagmi e le ellissi sintattiche sono evitate. La 
semplificazione del testo in seguito alla riscrittu-
ra 
risulta 
comunque evidente dal 
riscontro di 
READ-IT che stima la difficoltà del testo a livel-
lo globale a solo il 10% rispetto al 89.4% del 
testo originale. 
CLIC_2016_Proceedings.indd 225
02/12/16 15.04
226
La seconda e ultima frase della sezione “Indi-
cazioni terapeutiche” è la seguente: 
3.
Terapia sintomatica degli stati febbrili e 
delle sindromi influenzali e da raffred-
damento. 
Anche in questo caso, delle 11 parole contenu-
te nella frase, soltanto 3 (
degli
, 
e
, 
stato
ammesso 
che l’accezione del termine 
stato
nel VdB non 
coincida con il participio passato del verbo 
esse-
re
né con Stato) appartengono al VdB e questo è 
un fattore significativo per la stima della difficol-
tà 
del 
testo 
pari 
al 
96.3%. 
Come 
si 
è 
visto 
nell’esempio precedente anche in questo caso si 
segnala il ricorso ad aggettivi relazionali: se ne 
trovano 3 (
sintomatica
, 
febbrili
, 
influenzali
), che 
esprimono significati diversi (Pustejovsky 1995), 
contribuendo ad accentuare la difficoltà di com-
prensione. Se da una parte la 
terapia sintomatica 
è finalizzata a guarire i sintomi, dall’altra, gli 
stati febbrili 
sono causati dalla febbre così come 
le 
sindromi influenzali
dall’influenza. In questo 
caso, il valore causale dell’aggettivo relazionale 
è segnalato dalla congiunzione con il sintagma 
ellittico di testa 
(sindromi) da raffreddamento
. 
Alla luce di ciò, si può proporre la riscrittura se-
guente, che vede l’uso esclusivo di parole del 
VdB: 
4.
Terapia per curare i sintomi della feb-
bre, dell’influenza e del raffreddore. 
La difficoltà del testo riscritto ammonta al 
76.3% rispetto al 96.3% del testo originale. 
Dopo aver preso in considerazione due frasi 
risultate difficili in seguito al monitoraggio lin-
guistico, ne viene descritta ora una ritenuta faci-
le. La sezione successiva del bugiardino è dedi-
cata a “Posologia e modo di somministrazione”. 
Il termine posologia è un calco dal greco 
posos
“quanto” + 
logia
e sta ad indicare le dosi e le 
modalità di assunzione del farmaco. La frase, 
riportata in 5, in cui sono fornite le istruzioni per 
assumere il farmaco viene valutata da READ-IT 
con un basso indice di difficoltà (17.7%): 
5.
Sciogliere 
in 
mezzo 
bicchiere 
d'acqua 
non gassata una o due compresse di VI-
VIN C. L’assunzione del prodotto deve 
avvenire a stomaco pieno. 
In effetti, l’unico intervento di riscrittura di 
questo testo potrebbe riguardare la sostituzione 
del nome deverbale 
assunzione
con l’infinito del 
verbo corrispondente o meglio del verbo 
prende-
re 
oppure con la seconda persona plurale (
assu-
mete/prendete
)
come già proposto in (2), anche 
se l’infinito si giustificherebbe con la presenza 
dell’analogo 
sciogliere
nella frase precedente. In 
luogo di 
L’assunzione del prodotto deve avvenire 
a stomaco pieno
si può optare, quindi, per 
pren-
dere/prendete il prodotto 
o 
il farmaco
a stomaco 
pieno
, con una riduzione del numero delle parole 
(da 9 a 6). 
4
Conclusione 
Questo articolo presenta un lavoro esplorativo di 
analisi di un 
corpus
di foglietti illustrativi dei me-
dicinali senza obbligo di prescrizione medica. 
L’obiettivo era 
valutare l’uso di strumenti di 
TAL per il monitoraggio di questi testi a supporto 
della loro 
semplificazione manuale che prevede 
interventi linguistici volti alla semplificazione del-
la lingua a livello lessicale, con l’
eliminazione di 
tecnicismi, 
nomi 
astratti 
e 
deverbali, 
e 
morfo-
sintattico, con la preferenza per l’allocutivo 
voi
e 
l’eliminazione 
di 
frasi 
nominali, 
impersonali 
e 
passive a vantaggio di strutture transitive in cui 
tanto 
il 
recupero 
dell’agente 
quanto 
l’esplicitazione delle relazioni sintattiche tra gli 
elementi costitutivi della frase risultino facili e 
accessibili a tutte le categorie di utenti. 
Bibliografia 
Attardi, G., Dell’Orletta, F., Simi, M. and Turian, J. 
2009. 
Accurate 
Dependency 
Parsing 
with 
a 
Stacked Multilayer Perceptron. In Proceedings of 
EVALITA’09, 1-8, Reggio Emilia (Italia) 
Beccaria, S.L. (1973). I linguaggi settoriali in Italia, 
Milano, Bompiani. 
Berruto, G. (1993). “Varietà diamesiche, diastratiche, 
diafasiche”, 
in 
Sobrero 
A. 
(ed.), 
Introduzione 
all’italiano contemporaneo. La variazione e gli usi, 
2 voll, Roma-Bari, Laterza, 37-92. 
Cortelazzo M., con la collaborazione di Federica Pel-
legrino e Matteo Viale (a cura di), 1999, Semplifi-
cazione del linguaggio amministrativo. Esempi di 
scrittura per le comunicazioni ai cittadini, Padova, 
Comune di Padova. 
Cortelazzo, 
M. 
(2010), 
“Linguaggio 
giuridico-
amministrativo”, Enciclopedia dell’italiano Trec-
cani. 
Dardano, M. (1986), 
Il linguaggio dei giornali italia-
ni
, Roma-Bari, Laterza. 
De Mauro, T. (1987), 
Guida all’uso delle parole
, 
Roma-Bari, Laterza. 
De Mauro T., Vedovelli M. (a cura di), 1999, 
Dante, 
il gendarme e la bolletta. La comunicazione pub-
blica 
in 
Italia 
e 
la nuova bolletta 
Enel
, 
Bari-
Roma, Laterza. 
CLIC_2016_Proceedings.indd 226
02/12/16 15.04
227
Dell’Orletta, F. 2009. 
Ensemble system for Part-of-
Speech tagging
. In Proceedings of EVALITA’09, 
pp. 1-8, Reggio Emilia (Italia). 
Dell’Orletta, F. Montemagni, S., Vecchi, E., M., and 
Giulia 
Venturi. 
2011. 
Tecnologie 
linguistico–
computazionali per il monitoraggio della compe-
tenza linguistica italiana degli alunni stranieri nel-
la scuola primaria e secondaria. In G. C. Bruno, I. 
Caruso, M. Sanna, I. Vellecco (eds.), Percorsi mi-
granti: 
uomini, 
diritto, 
lavoro, 
linguaggi, 
McGraw–Hill, 319–336. 
Fioritto, A. 1997, 
Manuale 
di stile. Strumenti per 
semplificare il linguaggio delle amministrazioni 
pubbliche, Bologna, il Mulino. 
Fortis, D. 2003, Il plain language, quando le istituzio-
ni si fanno capire, I quaderni del MdS; Raso, T. 
2003. La scrittura burocratica. Carocci. Roma; 
Freidson, 
E. 
(1970) 
Professional 
Dominance: 
The 
Social 
Structure 
of 
Medical 
Care, 
New 
York, 
Atherton Press. 
Goodwin, C. (1994), “Professional vision”, American 
Anthropologist, 96 (3) 606-33. 
Heritage, 
J. 
(2012), 
“Epistemics 
in 
action: 
Action 
formation and territories of knowledge”, Research 
on Language and Social Interaction, 45, 1-25. 
Heritage, J. e D. Maynard (eds) (2006), Communica-
tion in medical care: interaction between primary 
care physicians and patients, Cambridge, CUP. 
Iacobini, 
C. 
(2004), 
“Composizione 
con 
elementi 
neoclassici”, in M. Grossmann e F. Rainer (eds), 
La formazione delle parole in italiano, Tübingen, 
Niemeyer, pp. 69-95. 
Marinelli, R., Biagini, L., Bindi, R., Goggi, S., Mo-
nachini, M., Orsolini, P., Picchi, E., Rossi, S., 
Calzolari, N., Zampolli, A. 
(2003). The Italian 
PAROLE corpus: an overview. In Zampolli A. et 
al. (eds.), Computational Linguistics in Pisa, Spe-
cial Issue, XVI–XVII, Pisa-Roma, IEPI. Tomo I, 
401–421. 
Orletti, F. (2000), La conversazione diseguale. Potere 
e interazione, Roma, Carocci. 
Orletti, F. (2015), “Quando breve non è semplice: 
sul rapporto tra scritture brevi e semplicità”, Con-
vegno interannuale PRIN SCRIBE S
critture brevi, 
forme, modelli e applicazioni per l'analisi e per il 
dizionario
, Macerata 28-30 maggio 2015. 
Orletti, F. e Iovino, R. (in stampa), Il parlar chiaro 
nella comunicazione medica. Fra etica e linguisti-
ca, Roma, Carocci. 
Piemontese, M.E. (1996), Capire e farsi capire. Teo-
rie e tecniche della scrittura controllata, Tecnodid, 
1996. 
Pustejovsky, J. (1995) The Generative Lexicon, Cam-
bridge, Mass, The MIT Press. 
Sabatini, F. 1990. Analisi del linguaggio giuridico. Il 
testo normativo in una tipologia generale dei testi , 
in M. D'Antonio (cur.), Corso di studi superiori 
legislativi (1988-1989) , Padova, Cedam, pp. 675-
724. 
Serianni, L. (2001), Italiani scritti, Bologna, il Muli-
no. 
Serianni, L. (2005), Un treno di sintomi. I medici e le 
parole: percorsi linguistici nel passato e nel pre-
sente. Milano, Garzanti. 
Sobrero, A.A. (1993), “Lingue speciali”, in Sobrero 
A. (ed.), Introduzione all’italiano contemporaneo. 
La variazione e gli usi, 2 voll, Roma-Bari, Laterza, 
237-278. 
Thornton, A. (2004), “Conversione”, in M. Gross-
mann e F. Rainer (eds), La formazione delle paro-
le in italiano, Tübingen, Niemeyer, pp. 499-533. 
CLIC_2016_Proceedings.indd 227
02/12/16 15.04
228
FB-NEWS15: A Topic-Annotated Facebook Corpus for
Emotion Detection and Sentiment Analysis
Lucia C. Passaro, Alessandro Bondielli
and Alessandro Lenci
CoLing Lab, Dipartimento di Filologia, Letteratura e Linguistica
University of Pisa (Italy)
lucia.passaro@for.unipi.it
alessandro.bondielli@gmail.com
alessandro.lenci@unipi.it
Abstract
English.
In this paper we present the FB-
NEWS15 corpus,
a new Italian resource
for sentiment analysis and emotion detec-
tion.
The corpus has been built by crawl-
ing the Facebook pages of the most impor-
tant
newspapers in Italy and it
has been
organized into topics using LDA.
In this
work we provide a preliminary analysis
of the corpus, including the most debated
news in 2015.
Italiano.
In questo lavoro presentiamo il
corpus FB- NEWS15,
un corpus italiano
creato per scopi di sentiment analysis ed
emotion detection.
Il corpus
stato costru-
ito scaricando le pagine Facebook delle
maggiori testate giornalistiche in Italia e
successivamente organizzato in topic uti-
lizzando LDA. In questo articolo forniamo
una analisi preliminare del corpus, e mos-
triamo le notizie pi discusse nel 2015.
1
Introduction
The use of Social
Networks (SN) platforms like
Facebook and Twitter has developed overwhelm-
ingly in recent years.
SN are exploited for differ-
ent purposes ranging from the sharing of contents
among friends and useful
contacts to the news-
gathering about different domains such as politics
and sports (Ahmad,
2010;
Ahmad,
2013;
Shef-
fer and Schultz,
2010).
Many journalists indeed
use SN platforms for professional reasons (Oriella,
2013; Hermida, 2013).
Several recent studies provide insights on how
the popularity of blogs and other user generated
content impacted the way in which news are con-
sumed and reported.
Picard (2009) states that SN
platforms provide an easy and affordable way to
take part in discussions with larger groups of peo-
ple and,
consequently,
the bond between SN and
information is becoming increasingly stronger.
Mass information is gradually moving towards
general platforms, and official websites are losing
their lead position in providing information.
As
noted by Newman et al.
(2012),
even though the
use of internet in the years 2009-2012 has grown,
the same is not reflected in the consumption of on-
line newspapers, probably because of the increas-
ing use of SN for news diffusion and gathering.
If
on the one hand this apparent
decline of
the
traditional
news platforms may lead to a decline
in quality and news coverage (Chyi and Lasorsa,
2002),
on the other hand the rise of SN as plat-
forms to spread news promotes a more fervid de-
bate between users (Shah et al., 2005).
This issue
is central for the present work. In fact, user’s com-
ments very often contain their own opinions about
a certain issue.
In addition,
because of the col-
loquial style of the comments,
they contain large
amounts of
words and collocations with a high
subjective content, mostly concerning the author’s
emotive stance.
Facebook is one of the most popular online SN
in the world with 1 billion active users per month
and it
offers the possibility to collect
data from
people of
different
ages,
educational
levels and
cultures. From a linguistic point of view, previous
studies (Lin and Qiu, 2013) demonstrated that the
language in Facebook is more emotional and in-
terpersonal compared for example to the language
in Twitter.
Probably, this is due to the fact that in
Facebook there is a stronger psychological close-
ness between the author and audience because of
the different structure (bidirectional vs.
unidirec-
tional graphs) of the SNs.
In this
paper
we
present
the
FB-NEWS15
corpus,
a
new Italian
resource
for
sentiment
analysis
and
emotion
detection.
The
FB-
NEWS15 corpus
can be freely downloaded at
CLIC_2016_Proceedings.indd 228
02/12/16 15.04
229
colinglab.humnet.unipi.it/resources/
under
the
Creative
Commons
Attribution
License
creativecommons.org/licenses/by/2.0
.
1
The debate among users in commenting news
and posts on Facebook offers a lot
of subjective
material to study the way in which people express
their own opinions and emotions about
a target
event.
In fact,
in FB-NEWS15 we find linguistic
items expressing the whole range of positive and
negative emotions.
In analyzing a news corpus,
however, it is not simple to aggregate the posts on
the basis of a certain fact,
since several posts re-
late to the same event. For this reason, we decided
to organize the corpus into clusters of topically re-
lated news identified with Latent
Dirichlet
Allo-
cation (LDA:
Blei
et
al.
(2003)).
This approach
allow us to infer the most debated news in the cor-
pus, and, in a second step, to discover the readers’
sentiment about a particular topic.
The paper is organized as follows:
Section 2
describes the creation of the corpus,
from crawl-
ing (2.1) to linguistic annotation (2.2), and finally
provides basic corpus statistics (2.3). Section 3 re-
ports on the automatic topic extraction with LDA.
2
FB-NEWS15
For
the creation of
the corpus we followed the
most important Italian newspapers. Since we were
interested in building a corpus as heterogeneous
as possible,
we decided to focus on major news-
papers with different
political
orientations,
and
which have in general heterogeneous readers.
Facebook allow users to post states, links, pho-
tos and videos on their own wall. In general, users
can be divided into two macro-categories:
Peo-
ple and Pages.
People are often individuals,
and
the interaction with them is usually bidirectional
(user A can read what user B publishes if A and
B have a friendship relation).
Conversely,
Pages
are typically used to represent organizations, pub-
lic figures (web stars),
companies or,
as in our
case,
newspapers.
In this case,
the relationship
is unidirectional,
in the sense that user A can ac-
cess the timeline of the page P by putting a ”Like”
on P. Unlike a single-user, who usually publishes
photos, videos and links about his private life, the
timeline of a newspaper Facebook page, in general
contains news titles with a link to the official web-
site of the newspaper, where the user can read the
1
All data collected have been processed anonymously for
scientific purposes, without storing personal information.
full article.
The corpus keeps tracks of the three-
fold hierarchical structure of Facebook, which in-
cludes the news posts by the newspaper, the users’
comments to the posts and the replies to the com-
ments.
In this context, it is clear that the emotive
content of the post is often neutral,
but this post
can inspire long discussions among readers, which
can become useful material for sentiment analysis
and emotion detection. Figure 1 shows a post, with
some of its comments and replies.
Figure 1:
Example of post in Facebook with the
relative comments and replies.
In order to create the FB-NEWS15, we decided
to download the timeline of the following news-
papers,
from 1 January 1 to 31 December 2015:
La Repubblica, Il Giornale, L’Avvenire, Libero, Il
Fatto Quotidiano, Rainews24, Corriere Della Sera,
Huffington Post Italia.
2.1
Crawling
Facebook offers developers Application Program-
ming Interfaces
(APIs)
for
creating apps
with
Facebook’s native functionalities.
In order to de-
velop the crawler,
we exploited the Graph API,
which provides a simple view of
the Facebook
social graph by showing the objects in the graph
and the connections between them.
The Graph
API allows us to navigate through the graph of
the social network, which is organized into nodes
CLIC_2016_Proceedings.indd 229
02/12/16 15.04
230
<doc user="<newspaper(string)>"
id="<id_post(string)>"
type="post"
parent_post=""
parent_comment=""
date="AAAA-MM-DD HH:MM:SS"
location=""
likes="662"
comments="54"
shares="322">
Un business truffaldino [E ora
finitela con l’eco-balla dei
controlli sulle emissioni]
</doc>
Figure 2: Example of crawled text.
(Users, Pages, Photos and Comments) and Edges
(Connections such as Friendship or Likes).
The
graph is navigated by exploiting HTTP requests,
that may be implemented using any programming
language.
The native APIs offered by Facebook
has some drawbacks:
i) the maintenance of the
app,
since the APIs change over time,
making it
necessary to update the code of the crawler;
ii)
only public data can be accessed without requir-
ing the user’s consent;
iii) Facebook places limi-
tations on the number of requests through a given
period of time. For each post, comment and reply,
we stored the message (text),
the story (presence
of photos and links tags),
its timestamp,
the type
(post, comment, reply), the parent post/comment,
the number of likes, shares and replies (Figure 2).
2.2
Linguistic annotation
A very basic preprocessing phase has been ap-
plied to the corpus before linguistic annotation,
to replace urls with the tag
URL .
The text has
been subsequently feed to a pipeline of general-
purpose NLP tools.
In particular,
it
has been
POS-tagged with the Part-Of-Speech tagger
de-
scribed in (Dell’Orletta,
2009) and dependency-
parsed with the DeSR parser (Attardi et al., 2009).
In addition,
complex terms like forze dell’ordine
(security force) or toccare il fondo (hit rock bot-
tom) have been identified using the EXTra term
extraction tool (Passaro and Lenci, 2015).
2.3
Corpus Analysis
Except
for
Avvenire and Rainews24,
for
which
we downloaded very few data,
the other
news-
papers are attested in the corpus in a balanced
way.
In general,
the number of posts is very low
compared to the number of comments and replies.
The average number of posts for each newspaper
is 27,341.25,
while for comments and replies is
respectively 2,016,243.38 and 576,498.5.
Table
1shows the number of texts (including posts, com-
ments and replies) in FB-NEWS15 for each News-
paper and Figure 2.3 shows their cumulative dis-
tribution for each Newspaper.
N
EWSPAPER
N.
OF
T
EXTS
La Repubblica
4558,829
Avvenire
91,824
Il Giornale
3,497,610
Libero
2,436,246
Il Fatto Quotidiano
4,900,314
Rainews24
369,834
Huffington Post
1,552,042
Corriere della Sera
3,553,966
O
VERALL
20,960,665
Table 1:
Number of texts aggregated by Newspa-
per in FB-NEWS.
Table 2 shows the total
number of tokens for
each page and the average number of texts,
pro-
duced for each post for each page.
We can notice
that
the most
followed newspapers on Facebook
are Il Fatto Quotidiano and La Repubblica.
N
EWSPAPER
T
OKENS
T
EXTS
/P
OSTS
La Repubblica
96,059,756
182.61
Avvenire
2,611,899
12.65
Il Giornale
64,345,260
77.93
Libero
41,166,457
81.87
Il Fatto Quotidiano
99,025,541
193.33
Rainews24
7,735,908
10.21
Huffington Post
32,587,065
84.06
Corriere della Sera
64,197,579
95.01
O
VERALL
407,729,465
94.83
Table 2: Tokens and Texts/Posts ratio for page.
3
Topics in FB-NEWS15
FB-NEWS15 contains texts referring to a large
variety of events.
In order to organize the cor-
pus into clusters of thematically related news, we
used LDA (Blei
et
al.,
2003).
LDA represents
documents as random mixtures over latent topics,
where each topic is characterized by a distribu-
tion over words.
These random mixtures express
a document semantic content, and document sim-
ilarity can be estimated by looking at how similar
the corresponding topic mixtures are. For the topic
identification we used the software Mallet
(Mc-
Callum, 2002).
CLIC_2016_Proceedings.indd 230
02/12/16 15.04
231
Figure 3: Cumulative distribution of posts, comments and replies in FB-NEWS15 for each Newspaper.
3.1
Selecting the vocabulary
Since we were interested in extracting the topics
from the news articles, we have built the model on
the portion of FB-NEWS15 containing the posts
(FB-NEWS15
posts) published by the newspaper.
In particular,
we used entropy (Dumais,
1990) as
a global term weighting and we selected for train-
ing the terms (nouns,
adjectives,
verbs and com-
plex terms) with a high informative value (thresh-
old fixed to 0.3), while using the remaining words
as stopwords in Mallet (McCallum, 2002).
3.2
Extracting topics from posts
In order to determine the most debated topics in
2015,
we used LDA to assign 50 topics to the
posts in FB-NEWS15
posts and we navigated the
graph to assign the topics to the comments and the
replies.
Later,
we restricted the topics associated
to a post
P
to the topics
T
having a probability
higher than the 90
th
percentile of the topic dis-
tribution of
P
.
In this way,
each post
has been
assigned, on average, to 3.06 topics. Finally, com-
ments and replies have inherited the probability of
belonging to the topic
T
from their parent
post.
Among the extracted topics ranked according to
the sum of these probabilities we can find national
and foreign politics, terrorism and church but also
food,
football,
cinema and weather forecast.
We
report some topics below, with the number of texts
and the relative ranking (i.e., rank 1 is given to the
topic with the higher number of texts).
N
ATIONAL
P
OLITICS
(2,516,640
TEXTS
,
R
ANK
1):
{
Renzi,
presidente,
premier,
Mattarella, riforma, Alfano, senato, camera,
Boschi,
aula
}
(Renzi,
president,
Mattarella,
reform,
Alfano,
senate,
chamber,
Boschi,
hall)
S
CHOOL
(1,707,145
TEXTS
, R
ANK
2):
{
scuola,
giovane,
studente,
protesta,
corso,
man-
care,
sospendere,
inglese,
spiegare,
lezione
}
(school, young, protest, class, lack, suspend,
English, explain, lesson)
C
RIME
(1,543,735
TEXTS
,
R
ANK
7):
{
uccidere,
polizia,
arrestare,
fermare,
sparare,
uomo,
poliziotto,
colpo,
ferire,
agente
}
(kill,
police,
detain,
stop,
open
fire,
man,
policeman,
bump,
wound,
police
officer)
I
SIS
(1,267,749
TEXTS
,
R
ANK
16):
{
Isis,
guerra,
siria,
minaccia,
U.S.A.,
Libia,
colpire, islamico, usare, jihadisti
}
(Isis, war,
Syria, threat, U.S.A., Libya, damage, islamic,
use, jihadist)
F
OOD
(949,520
TEXTS
, R
ANK
40):
{
mangiare,
ricetta,
cibo,
preparare,
consiglio,
evitare,
perfetto,
trucco,
salute,
semplice
}
(eat,
CLIC_2016_Proceedings.indd 231
02/12/16 15.04
232
recipe,
food,
prepare,
advice,
avoid,
perfect,
trick, health, simple)
F
OOTBALL
(606,560
TEXTS
,
R
ANK
50):
{
seguire la diretta, guardare il video, campo,
calcio, serie, Napoli, Milan, segnare, battere,
partita
}
(follow the live,
look at
the video,
football
field,
football,
league,
Naples,
Mi-
lan)
4
Conclusions and ongoing work
As one of the most
widespread social
networks,
Facebook offers the possibility to collect opinion-
ated pieces of texts from people of different ages,
cultures and education.
The composition of FB-
NEWS15, in which each comment is explicitly as-
sociated with a particular post, allows us to study
the differences in terms of
readers’
perceptions
about a particular topic. Differently from other so-
cial media like Twitter,
Facebook contains larger
texts including lot
of subjective expressions that
are very useful for the construction of sentiment
and emotive lexicons.
Starting from previous works (Passaro et
al.,
2015;
Passaro and Lenci,
2016),
we plan to use
this corpus to build lexical resources for sentiment
analysis and emotion detection, which will include
both words and complex terms.
In addition,
we
plan to optimize the topic modeling phase and to
investigate the possibility of using the extracted
topics as a prior for inferring the sentiment orien-
tation of a particular comment.
References
A. Ahmad.
2010.
Is twitter a useful tool for journal-
ists? Journal of Media Practice, 11(2):145–155.
A.
Ahmad.
2013.
Whats in a tweet?
foreign corre-
spondents use of social media.
Journalism Practice,
7(1):33–46.
G.
Attardi,
F.
Dell’Orletta,
M.
Simi,
and J.
Turian.
2009.
Accurate dependency parsing with a stacked
multilayer perceptron.
In EVALITA 2009
Evalu-
ation of
NLP and Speech Tools for Italian 2009,
LNCS, Reggio Emilia (Italy). Springer.
D. M. Blei, A. Y. Ng, and M. I. Jordan.
2003.
Latent
dirichlet allocation.
The Journal of Machine Learn-
ing Research, 3:993–1022.
H.
Chyi
and D.
L.
Lasorsa.
2002.
An explorative
study on the market
relation between online and
print
newspapers.
Journal
of
Media Economics,
15(2):91–106.
F.
Dell’Orletta.
2009.
Ensemble system for part-of-
speech tagging.
In EVALITA 2009
Evaluation of
NLP and Speech Tools for Italian 2009, LNCS, Reg-
gio Emilia (Italy). Springer.
S. T. Dumais.
1990.
Enhancing performance in latent
semantic indexing (lsi) retrieval.
Technical Report
TM-ARH-017527.
A.
Hermida.
2013.
#journalism.
reconfiguring jour-
nalism research about
twitter,
one tweet
at
a time.
Digital Journalism.
H.
Lin and L.
Qiu.
2013.
Two sites,
two voices:
Linguistic differences between facebook status up-
dates and tweets.
In P. L. Patrick Rau, editor, Cross-
Cultural
Design.
Cultural
Differences in Everyday
Life: 5th International Conference, CCD 2013, Held
as Part of HCI International 2013, volume 2, pages
432–440, Las Vegas (USA). Springer Berlin Heidel-
berg.
Andrew Kachites
McCallum.
2002.
Mal-
let:
A machine
learning
for
language
toolkit.
http://mallet.cs.umass.edu.
N. Newman, W. H. Dutton, and G. Blank.
2012.
Social
media in the changing ecology of news:
The fourth
and fifth estate in britain.
Internet Science, 7(1):6–
22.
Oriella.
2013.
The new normal for news. have global
media changed forever?
The 6th Annual
Oriella
Digital Journalism Survey.
L.
C.
Passaro and A.
Lenci.
2015.
Extracting terms
with extra.
In Proceedings of
the EUROPHRAS
2015 Computerised and Corpus-based Approaches
to Phraseology: Monolingual and Multilingual Per-
spectives, pages 188–196, Malaga (Spain).
Lucia C. Passaro and Alessandro Lenci.
2016.
Eval-
uating context selection strategies to build emotive
vector space models.
In Proceedings of the Tenth In-
ternational Conference on Language Resources and
Evaluation (LREC 2016).
European Language Re-
sources Association (ELRA), may.
L. C. Passaro, L. Pollacci, and A. Lenci.
2015.
Item:
A vector space model to bootstrap an italian emotive
lexicon.
In Proceedings of the second Italian Con-
ference on Computational Linguistics CLiC-it 2015,
pages 215–220, Trento (Italy).
R. Picard.
2009.
Blogs, tweets, social media, and the
news business.
Nieman Reports, 63(3):10–12.
D. V. Shah, J. Cho, W. P. Eveland, and N. Kwak.
2005.
Information and expression in a digital age.
Com-
munication Research, 32(10):531–565.
M.
L.
Sheffer and B.
Schultz.
2010.
Paradigm shift
or passing fad? twitter and sports journalism.
Inter-
national journal of Sport Communication, 3(4):472–
484.
CLIC_2016_Proceedings.indd 232
02/12/16 15.04
233
May the Goddess of Hope Help Us. 
Homonymy in Latin Lexicon and Onomasticon 
Marco Passarotti 
CIRCSE Research Centre 
Università Cattolica del Sacro Cuore 
Largo Gemelli, 1 – 20123 Milan, Italy 
marco.passarotti@unicatt.it 
Marco Budassi 
Università di Pavia 
Corso Strada Nuova, 65 
27100 Pavia, Italy 
marcobudassi@hotmail.it 
Abstract 
English. We present a study on the degree of 
homonymy 
between 
the 
lexicon 
of 
a 
morphological 
analyser 
for 
Latin 
and 
an 
Onomasticon. To understand the impact of 
homonymy, 
we 
discuss 
an 
experiment 
on 
four Latin texts of different era and genre. 
Italiano. L’articolo presenta uno studio sul 
grado 
di 
omonimia 
tra 
il 
lessico 
di 
un 
analizzatore morfologico per il latino e un 
Onomasticon. 
Al 
fine 
di 
comprendere 
l’impatto dell’omonimia, viene descritto un 
esperimento condotto su quattro testi latini di 
diversa epoca e genere. 
1
Introduction 
Ambiguity affects linguistic analysis at various 
levels. 
In 
particular, 
homonymy 
plays 
a 
substantial role in the analysis of single words. 
Indeed, 
when 
considered 
out 
of 
context, 
one 
same word can be assigned different Parts of 
Speech (PoS), morphological features, lemmas 
and meanings. Contextual disambiguation is the 
task of Natural Language Processing (NLP) tools 
like 
PoS-taggers, 
morphological 
analysers, 
lemmatisers and word-sense disambiguators. 
The 
problem 
of 
ambiguity 
is 
particularly 
remarkable 
for 
NLP 
when 
Named 
Entity 
Recognition 
(NER) 
is 
concerned. 
In 
order 
to 
automatically classify the textual occurrences of 
(multi)words into categories such as names of 
persons, locations and organisations, NER faces 
that specific kind of ambiguity consisting in the 
homonymy 
between 
proper 
names 
and 
other 
words in the lexicon (Nadeau and Sekine, 2007). 
For instance, the word mark in English can be a 
proper name, a noun or a verb. Although such 
homonymy 
is 
often 
tackled 
by 
using 
the 
upper/lowercase distinction for the initial letter 
of words, this solution is neither decisive (as 
uppercase 
letters 
can 
also 
be 
motivated 
by 
punctuation) nor always available. The latter is 
especially true for historical languages, as a large 
amount of texts in such languages comes with no 
upper/lowercase distinction and it may follow 
different editorial criteria. 
The recent extension of the lexical basis of the 
morphological analyser and lemmatiser for Latin 
Lemlat with an Onomasticon (i.e. a list of proper 
names) makes it possible to evaluate the degree 
of homonymy of proper names in Latin and, 
thus, 
to 
understand 
the 
extent 
of 
the 
disambiguation 
task 
(Passarotti 
and 
Ruffolo, 
2004). To this aim, in this paper we explore the 
lexical basis of Lemlat as providing the empirical 
evidence supporting our analysis on homonymy 
between names in the Onomasticon and words in 
the Latin lexicon. 
2
Lemlat 
Together 
with 
Morpheus 
(Crane, 
1991) 
and 
Whitaker’s Words, Lemlat (Passarotti, 2004) is 
one of the most widespread tools for automatic 
analysis 
of 
Latin 
morphology 
available. 
The 
original lexical basis of Lemlat (L) results from 
the collation of three Latin dictionaries (Georges 
and 
Georges, 
1913-1918; 
Glare, 
1982; 
Gradenwitz, 
1904). 
It 
counts 
40,014 
lexical 
entries and 43,432 lemmas (as more than one 
lemma can be included into the same lexical 
entry). Such lexical basis was recently merged 
with 
most 
of 
the 
Onomasticon 
(O) 
(26,250 
lemmas 
out 
of 
28,178) 
provided 
by 
the 
5th 
edition of Lexicon Totius Latinitatis (Forcellini, 
1940) (Budassi and Passarotti, 2016). 
CLIC_2016_Proceedings.indd 233
02/12/16 15.04
234
Since the large majority of lemmas in O are 
nouns (19,599 out of 26,250), we will focus on 
them here, first by comparing their distribution in 
L and O. Table 1 shows the number of nouns and 
their percentage (on the total of nouns) in L and 
O by inflectional category. 
Infl. Cat.
Lemlat 
Onomasticon 
I decl. 
5,009 (22.26%)
6,651 (33.94%) 
II decl. 
7,466 (33.17%) 
7,235 (36.92%) 
III decl. 
8,677 (38.54%)
4,464 (22.77%) 
IV decl. 
980 (4.35%)
58 (0.29%) 
V decl. 
101 (0.45%)
6 (0.03%) 
Uninfl. 
278 (1.23%)
1,185 (6.05%) 
TOTAL 
22,511
19,599 
Table 1. Nouns in L and O. 
While 
third 
declension 
nouns 
are 
more 
frequent in L than in O, the opposite holds for 
first declension and (to a lesser extent) second 
declension nouns. The main difference between 
L and O concerns uninflected nouns, which are 
much more in O than in L because of the large 
number of loans recorded in O. 
Also gender-based distribution of nouns by 
inflectional 
category 
shows 
substantial 
differences between L and O. Among the most 
relevant is that O includes more first declension 
masculine nouns than L (1,626 vs. 562). Instead, 
the number of second declension neuter nouns is 
larger in L than in O (4,005 vs. 1,523), because 
O tends to include more proper names of persons 
than of places, the latter being often assigned the 
neuter gender. As for third declension, feminine 
nouns are more than masculine in L (5,112 vs. 
2,590), while the opposite holds in O (2,847 
masculine vs. 1,185 feminine). 
3
Mining Nominal Homonymy 
To categorise nominal homonymy in L and O, 
we defined three kinds of homonymy: (a) Full 
Homonymy (FH): words with the same lemma, 
PoS, inflectional category and gender in L and 
O; (b) Partial Homonymy (PH): words with the 
same lemma in L and O, but with different PoS, 
inflectional category or gender (the last for nouns 
only); (c) Mixed Homonymy (MH): words with 
the same lemma in L and O and with more than 
one PoS, inflectional category or gender, thus 
resulting partly into FH and partly into PH. 
An example of FH in our data is the word 
spes, which means “hope” in L and “the Goddess 
of Hope” in O. PH is represented, for instance, 
by the word augustus, which is an adjective in L 
(“majestic”) and a noun in O (a cognomen given 
to Octavius Caesar as emperor). The word spina 
is 
a 
case 
of 
MH, 
being 
a 
first 
declension 
feminine noun in L (“thorn”) and both a first 
declension 
feminine 
noun 
(an 
old 
town 
in 
Aemilia) and a third declension masculine noun 
with genitive in –anis (a river God) in O, the 
former thus showing FH and the latter PH. 
Table 2 presents the rates of homonymy in L 
and O by each kind per inflectional category. 
The total number of homonyms is provided as 
well 
(column 
“H”). 
This 
corresponds 
to 
the 
number of nouns of an inflectional category that 
are 
graphically 
identical 
in 
L 
and 
O. 
For 
instance, the first row of table 2 shows that there 
are 
556 
lemmas 
recorded 
as 
first 
declension 
nouns (in L or O) that are identical to a lemma 
occurring in the other section of the lexical basis 
of Lemlat. 383 lemmas out of these show FH, i.e. 
they share not only the same graphical form but 
also 
the 
same 
PoS, 
inflectional 
category 
and 
gender in L and O (column “FH”). Instead, 163 
lemmas occur as graphically identical in L and O 
but do not have in common at least one among 
PoS, 
inflectional 
category 
or 
gender 
(column 
PH”). Finally, 10 lemmas show MH. 
Infl. Cat.
H 
FH 
PH 
MH 
I decl. 
556
383 
163 
10 
II decl. 
752
307 
389 
56 
III decl. 
584
334 
226 
24 
IV decl. 
85
9 
73 
3 
V decl. 
6
5 
1 
0 
Uninfl. 
60
0 
60 
0 
TOTAL 
2,043
1,038 
912 
93 
Table 2. Kinds of homonymy. 
Most of the PH instances for first declension 
lemmas are due to different gender. An example 
is the first declension noun caligula, which is 
feminine in L (“a small military boot”) while it is 
masculine in O (a cognomen). Second declension 
shows several cases of PoS change, like in the 
case 
of 
severus, 
which 
is 
an 
adjective 
in 
L 
(“serious”) and a noun in O (a proper name). 
Instead, a large number of verb-noun changes 
holds for third declension. This mostly occurs for 
imparisyllable 
nouns 
ending 
in 
–o, 
like 
cato, 
which is a first conjugation verb in L (“to see”) 
and a noun in O (a proper name). 
CLIC_2016_Proceedings.indd 234
02/12/16 15.04
235
PH does not raise any tricky issue for NLP, 
the task of PoS/morphological taggers being just 
that 
of 
disambiguating 
contextually 
PoS 
and 
morphological 
features. 
Conversely, 
FH 
(including the FH-like part of MH) represents a 
challenging 
question 
for 
NLP. 
Indeed, 
if 
upper/lowercase distinction is not available in 
input 
data, 
only 
context-based 
semantic 
properties can disambiguate between candidate 
lemmas 
affected 
by 
FH. 
For 
instance, 
in 
the 
clause 
“spes 
est 
expectatio 
boni” 
(“hope 
is 
expectation of good”, Cicero, Tusculanae, 4, 37, 
80) there is nothing but semantics to help us to 
understand that the word spes is an occurrence of 
the noun from L instead of the proper name from 
O. In order to evaluate the extent of homonymy 
in real texts and to understand how much big the 
impact of FH is, we performed the experiment 
discussed in the next section. 
4
Homonymy in Texts. A Case-study 
We run Lemlat on four Latin texts of similar size 
and different genre and era.
1
Table 3 shows the 
number of distinct words out of the total (column 
“Types”) 
analysed 
by 
the 
original 
version 
of 
Lemlat 
(column 
“Lemlat”) 
and 
by 
the 
one 
enhanced 
with 
the 
Onomasticon 
(column 
“LemlatO
N
”). 
Text
Types 
Lemlat 
LemlatO
N
Improv. 
(1) 
3,092 
2,888 
3,039 
+151 
(2) 
5,057 
4,717 
5,005 
+288 
(3) 
3,542 
3,357 
3,487 
+130 
(4) 
4,589 
4,292 
4,537 
+245 
Table 3. Results of Lemlat(O
N
) on four texts. 
Beside the words analysed by LemlatOn only 
(column “Improv.”), there is a certain degree of 
overlapping between Lemlat and LemlatOn. The 
words falling in this ‘grey zone’ are those that 
are analysed both by Lemlat and by LemlatOn, 
as they are lemmatised both under a lemma from 
L and under one from O. Among these words, 
those affected by homonymy are to be found. 
1
(1) Caesar, De Bello Gallico, 1 (Classical Lat., prose); (2) 
Virgil, Aeneid, 1 & 2 (Classical Lat., poetry); (3) Tertullian, 
Apologeticum (Late Lat., prose); (4) Claudian, De Raptu 
Proserpinae 
(Late 
Lat., 
poetry). 
All 
the 
texts 
were 
downloaded 
from 
the 
Perseus 
Digital 
Library
(www.perseus.tufts.edu). 
Text 
L/O 
H 
FH 
PH 
MH 
(1) 
618 
405 
303 
88 
14 
(2) 
1,207 
799 
546 
186 
67 
(3) 
686 
486 
330 
120 
36 
(4) 
1,062 
706 
469 
177 
60 
Table 4. Overlapping and homonymy rates. 
Column “L/O” in table 4 reports the number 
of words for each text that are analysed both by 
Lemlat and by LemlatO
N
. The other columns 
show the homonymy rates by the kinds described 
in Section 3. For instance, in the text of Caesar 
(1) there are 618 words analysed by both the 
versions of Lemlat (L/O). 405 out of them share 
the same lemma in at least one analysis (H). This 
is further detailed: 303 out of 405 show FH, 88 
PH and 14 MH. An example of a word analysed 
by both the versions of the tool that does not 
share the same lemma in all analyses is acie, 
which is lemmatised under acies (“dagger”) by 
Lemlat (fifth declension feminine noun) and also 
under 
the 
proper 
name 
acius 
by 
LemlatO
N
(second declension masculine noun). The word 
constantia is an example of H: it is lemmatised 
as a form of both lemmas consto (“to agree”; 
first 
conjugation 
verb) 
and 
constantia 
(“steadiness”; second declension feminine noun) 
by Lemlat, and also as a form of both proper 
names constantius (second declension masculine 
noun) 
and 
constantia 
(second 
declension 
feminine 
noun) 
by 
LemlatO
N
. 
The 
word 
constantia 
is 
also 
an 
example 
of 
FH, as 
the 
analyses provided by the two versions of Lemlat 
that share the same lemma have in common even 
the same inflectional category and gender. PH is 
shown by the word crassi, which is assigned the 
same lemma (crassus) both by Lemlat and by 
LemlatO
N
, but while it is a first class adjective in 
the former (“solid”), it is a second declension 
masculine noun in the latter (a proper name). An 
example of MH is the word amico, which 
is 
lemmatised under the lemma amicus (“friend”) 
both 
by 
Lemlat 
and 
LemlatO
N
. 
The 
lemma 
amicus 
is 
both 
an 
adjective 
and 
a 
second 
declension masculine noun in Lemlat, but only 
the 
latter 
analysis 
is 
shared 
with 
LemlatO
N
, 
because the lemma amicus in the Onomasticon is 
recorded 
only 
as 
a 
noun 
and 
not 
also 
as 
an 
adjective. 
Thus, 
when 
the 
word 
amico 
is 
assigned PoS noun it shows FH, while when it is 
assigned PoS adjective it shows PH. 
The 
proportions 
between 
the 
kinds 
of 
homonymy remain quite similar for all the texts. 
CLIC_2016_Proceedings.indd 235
02/12/16 15.04
236
Words affected by H tend to be more than half of 
L/O; among them the large majority is affected 
by FH. By comparing columns “FH” and “MH” 
in table 4 with column “Types” in table 3, one 
can see that slightly more than 10% of the words 
of all the texts is affected by FH. This is the 
percentage rate of words whose lemmatisation 
cannot 
be 
disambiguated 
by 
a 
PoS 
tagger, 
because semantic features only are here at work 
to 
choose 
between 
candidate 
lemmas. 
For 
instance, 
if 
a 
PoS 
tagger 
assigns 
to 
one 
occurrence of the word constantia PoS noun and 
gender feminine, it cannot disambiguate between 
the two (fully morphologically identical) lemmas 
constantia provided by LemlatO
N
. 
If we focus on textual occurrences (tokens) 
instead of distinct words (types), the rates of FH 
(+MH) 
range 
between 
8.44% 
(Caesar) 
and 
13.19% (Tertullian), as shown by table 5. This 
result represents the extent of the impact of FH 
on the texts that we used in the case-study. 
Text
Tokens 
FH+MH 
(1) 
8,171 
690 (8.44%) 
(2) 
10,045 
1,325 (13.19%) 
(3) 
7,317 
668 (9.13%) 
(4) 
6,991 
797 (11.4%) 
Table 5. Token-based homonymy rates. 
Most of the words showing FH can be easily 
disambiguated (at least, manually) according to 
peculiarities 
of 
single texts. 
For 
instance, 
the 
word amicitiam (from Caesar’s text) belongs to 
lemma amicitia both in L (“friendship”) and in O 
(“the Goddess of Friendship”), thus showing FH. 
However, it is more likely that the former is the 
one 
occurring 
in 
Caesar 
than 
the 
latter. 
Conversely, 
in 
the 
same 
text 
the 
word 
galli 
(lemma gallus) is more likely a proper name 
from O (“Gauls”) than a noun from L (“cock”). 
5
Conclusion 
We 
presented 
a 
study 
about 
the 
degree 
of 
homonymy 
between 
the 
lexical 
basis 
of 
a 
morphological 
analyser 
for 
Latin 
and 
an 
Onomasticon recently added in the tool. We have 
shown the impact of nominal homonymy on a 
number of Latin texts of different era and genre. 
Since 
the 
analysis 
of 
many 
homonymous 
words can be disambiguated according to the 
features of single texts (and authors), in the near 
future 
we 
foresee 
to 
enhance 
such 
words 
in 
Lemlat with information about their distribution 
in a number of manually tagged reference texts. 
References 
Marco Budassi and Marco Passarotti. 2016. Nomen 
Omen. 
Enhancing 
the 
Latin 
Morphological 
Analyser 
Lemlat 
with 
an 
Onomasticon. 
Proceedings of the 10
th
Workshop on Language 
Technology for Cultural Heritage, Social Sciences 
and Humanities (LaTeCH 2016). The Association 
for Computational Linguistics, Berlin, Germany, 
90–94. 
Gregory 
Crane. 
1991. 
Generating 
and 
Parsing 
Classical 
Greek. 
Literary 
and 
Linguistic 
Computing, 6(4):243–245. 
Egidio Forcellini. 1940. Lexicon Totius Latinitatis / 
ad 
Aeg. 
Forcellini 
lucubratum, 
dein 
a 
Jos. 
Furlanetto emendatum et auctum; nunc demum Fr. 
Corradini et Jos. Perin curantibus emendatius et 
auctius meloremque in formam redactum adjecto 
altera 
quasi 
parte 
Onomastico 
totius 
latinitatis 
opera 
et 
studio 
ejusdem 
Jos. 
Perin. 
Typis 
Seminarii, Padova. 
Karl 
Ernst 
Georges 
and 
Heinrich 
Georges. 
1913-
1918. 
Ausführliches 
Lateinisch-Deutsches 
Handwörterbuch. Hahn, Hannover. 
Peter G.W. Glare. 1982. Oxford Latin Dictionary. 
Oxford University Press, Oxford. 
Otto Gradenwitz. 1904. Laterculi Vocum Latinarum. 
Hirzel, Leipzig. 
David Nadeau and Satoshi Sekine. 2007. A survey of 
named 
entity 
recognition 
and 
classification. 
Lingvisticae Investigationes, 30(1):3–26. 
Marco 
Passarotti. 
2004. 
Development 
and 
perspectives of the Latin morphological analyser 
LEMLAT. 
Linguistica 
Computazionale, 
XX-
XXI:397–414. 
Marco Passarotti and Paolo Ruffolo. 2004. L’utilizzo 
del 
lemmatizzatore 
LEMLAT 
per 
una 
sistematizzazione 
dell’omografia 
in 
latino. 
Euphrosyne, XXXII:99–110. 
CLIC_2016_Proceedings.indd 236
02/12/16 15.04
237
Imparare a quantificare guardando
Sandro Pezzelle
CIMeC
Ionut Sorodoc
EM LCT
Aurelie Herbelot
CIMeC
Raffaella Bernardi
CIMeC, DISI
Universit
`
a degli Studi di Trento
{
nome.cognome@unitn.it
}
Abstract
English. In this paper, we focus on lingui-
stic questions over images which may be
answered with a quantifier (e.g.
How ma-
ny dogs are black? Some/most/all of them,
etc.).
We show that
in order to learn to
quantify,
a multimodal
model
has to ob-
tain a genuine understanding of linguistic
and visual inputs and of their interaction.
We propose a model that extracts a fuzzy
representation of the set of the queried ob-
jects (e.g. dogs) and of the queried proper-
ty in relation to that set (e.g. black with re-
spect to dogs),
outputting the appropriate
quantifier for that relation.
Italiano.
In questo lavoro studiamo le
domande del
tipo “Quanti
cani
sono ne-
ri?”,
la cui
risposta
`
e un quantificatore
(es.
“alcuni”/”tutti”/”nessuno”).
Mo-
striamo che al fine di imparare a quanti-
ficare, un modello multimodale deve otte-
nere una rappresentazione profonda della
domanda linguistica, dell’immagine e del-
la loro interazione.
Proponiamo un mo-
dello che estrae una rappresentazione ap-
prossimativa dell’insieme degli
oggetti
e
della propriet
`
a sui quali verte la domanda.
1
Introduzione
La linguistica computazionale ed i sistemi di vi-
sione artificiale stanno attraversando un momento
particolarmente favorevole, ben rappresentato dal-
lo sviluppo di modelli multimodali capaci di svol-
gere compiti che sembravano fuori portata fino a
pochissimi
anni
fa,
e che adesso si
trovano in-
tegrati in molte applicazioni destinate all’utilizzo
da parte degli utenti.
Il compito di “Visual Que-
stion Answering” (VQA), finalizzato a rispondere
a domande a partire da input visivi, e la generazio-
ne automatica di didascalie (“caption generation”)
sono solo alcuni dei compiti in cui maggiormen-
te si
`
e assistito a un rapido e inarrestabile miglio-
ramento.
Oltre a sfociare in dirette applicazioni
nel mondo reale,
dove i contenuti visivi giocano
un ruolo cruciale, la performance di questi model-
li
di
lingua e visione rappresenta anche un indi-
catore della misura in cui essi riescono a cattura-
re il
significato,
fornendoci
importanti
intuizioni
teoriche.
I recenti miglioramenti nel campo delle appli-
cazioni VQA sono da attribuire principalmente al-
la nuova generazione di
reti
neurali
artificiali
di
apprendimento profondo (“deep learning neural
networks”), insieme alla crescente disponibilit
`
a di
grandi dataset di immagini.
Questi modelli hanno
dimostrato che anche reti neurali (RN) molto sem-
plici
possono catturare interazioni
complesse tra
le propriet
`
a di un dataset, spesso superando in per-
formance modelli molto pi
`
u complessi.
Ad esem-
pio,
(Zhou et al., 2015) ha recentemente dimostra-
to che un semplice modello bag-of-words (BoW)
pu
`
o ottenere performance all’avanguardia in uno
dei
pi
`
u importanti
dataset
di
VQA (Antol
et
al.,
2015).
Gli
autori
dello studio,
tuttavia,
obietta-
no che la performance del modello
`
e da attribuire
pi
`
u alla eccellente abilit
`
a della rete di memorizza-
re correlazioni che a una reale capacit
`
a di ragiona-
mento e comprensione,
e concludono sostenendo
la necessit
`
a di passare al secondo obiettivo. Il loro
studio dimostra anche quanto difficile sia valutare
se un modello sia in grado di afferrare realmente il
significato di immagini e parole.
Nel presente la-
voro proponiamo un compito che riteniamo essere
utile per la comunit
`
a ai fini del raggiungimento di
questo obiettivo.
Nel compito di VQA, le valutazioni dei modelli
si basano su domande che riguardano le propriet
`
a
di
oggetti
specifici,
come la posizione,
il
colore,
ecc.,
mentre nel compito di generazione di dida-
CLIC_2016_Proceedings.indd 237
02/12/16 15.04
238
scalie viene presa in considerazione l’intera im-
magine. In entrambi i casi,
`
e ovviamente possibile
imparare correlazioni
tra le parole presenti
nella
domanda,
le parole presenti nella risposta e l’im-
magine stessa (o parti
di
essa).
Presentata a un
modello RN insieme alla domanda Cosa sta man-
giando?,
ad esempio,
l’immagine di una persona
che mangia una torta attiver
`
a sicuramente l’asso-
ciazione tra il verbo mangiare e propriet
`
a (sia lin-
guistiche che visive) collegate al cibo, producendo
la risposta corretta.
Per testare un modello al di l
`
a
di questo semplice meccanismo, emerge la neces-
sit
`
a di proporre un compito in cui una particola-
re associazione tra domanda e immagine non dia
come risultato sempre la stessa risposta.
Le domande riguardanti il “numero” sono sta-
te studiate solo marginalmente in letteratura,
e la
performance dei sistemi di VQA su queste doman-
de si
`
e dimostrata abbastanza scarsa (Ren et
al.,
2015;
Antol et al.,
2015).
Inoltre,
i lavori prece-
denti si sono concentrati quasi esclusivamente sul-
la modellizzazione di cardinali esatti, analizzando
quindi solo parzialmente il fenomeno della quanti-
ficazione.
Nel presente articolo investighiamo un
nuovo tipo di domanda che richiede un certo gra-
do di comprensione dei quantificatori generalizzati
(few, most, all, ecc.).
Il motivo per cui siamo inte-
ressati
a queste domande
`
e che,
per rispondervi,
non
`
e sufficiente identificare l’area di
un’imma-
gine correlata alla domanda.
La domanda In che
proporzione i cani sono neri?, ad esempio, richie-
de qualcosa di
pi
`
u dell’identificazione delle pro-
priet
`
a cane e nero nell’immagine: la rete deve es-
sere in grado di riflettere sulla relazione tra que-
ste propriet
`
a, e di generare uno dei quantificatori,
che sono potenzialmente simili
tra di
loro.
L’a-
bilit
`
a di identificare i membri di un insieme e le
loro propriet
`
a condivise richiede un certo grado di
ragionamento pi
`
u profondo che,
sosteniamo,
non
pu
`
o essere ottenuto con un semplice meccanismo
di memorizzazione.
In ci
`
o che segue,
consideriamo il
compito di
VQA come un problema di
“fill
in the blank”
(riempire uno spazio vuoto con la parola corret-
ta),
e poniamo la domanda In che proporzione i
cani sono neri? nella seguente forma:
cani so-
no neri.
Le possibili risposte sono selezionate al-
l’interno di un insieme di quantificatori linguistici,
ovvero no, few, some, most e all.
Per assegnare il
quantificatore corretto,
il
modello deve essere in
grado di porre l’attenzione sugli oggetti rilevanti
(il
restrittore del
quantificatore) e di
quantificare
gli
oggetti
che,
all’interno di
questo dominio ri-
stretto, possiedono la propriet
`
a richiesta (la porta-
ta del quantificatore).
Mostriamo che un sempli-
ce modello BoW non
`
e sufficiente per compiere
efficacemente questo compito,
e proponiamo un
modello RN alternativo e linguisticamente moti-
vato, la cui performance risulta essere superiore al
modello di (Zhou et al., 2015).
2
Dati
Abbiamo usato scenari
contenenti
ognuno sedici
immagini estratte da ImageNet.
ImageNet ci for-
nisce immagini annotate manualmente con un’eti-
chetta identificativa dell’oggetto (e.s.,
dog,
wine,
pizza,
ecc.)
e diverse propriet
`
a associate ad esso
(e.s., black, furry, ecc.)
Abbiamo selezionato tut-
te le immagini di ImageNet annotate con almeno
una propriet
`
a per un totale di 9600 immagini rap-
presentanti 203 tipi di oggetti e 24 propriet
`
a.
Ab-
biamo poi selezionato le immagini utili per la co-
struzione del nostro dataset,
mantenendo solo gli
oggetti che compaiono in un numero significativo
di
immagini
e che vengono menzionati
frequen-
temente nel corpus UkWaC.
1
Questo ci permette
di
ottenere rappresentazioni
visive e linguistiche
adeguate.
Applicando questa selezione,
abbiamo
ottenuto 161 oggetti e 7124 immagini,
2
che sono
state successivamente assemblate in scenari “plau-
sibili”.
A tal fine abbiamo calcolato la probablit
`
a
con cui due oggetti possano far parte di una stessa
scena utilizzando la loro co-occorrenza nelle dida-
scalie disponibili in MS-COCO (Lin et al., 2014)
– ad esempio, un cane e un divano hanno pi
`
u pos-
sibilit
`
a di co-occorrere in una stessa scena rispetto
a un elefante e un divano.
Abbiamo usato quindi
la seguente misura:
P MI
(
o
1
, o
2) =
log
f
(
o
1
, o
2)
∗
N
f
(
o
1)
∗
f
(
o
2)
(1)
1
Abbiamo scelto oggetti con almeno 16 immagini e che
occorrono nel corpus almeno 150 volte.
2
Ognuno dei 161 oggetti
`
e rappresentato da una media di
48 immagini uniche (sd=99), con una distribuzione che va da
13 (pasta) a 1104 (dog).
Ogni oggetto
`
e associato a un nu-
mero di propriet
`
a che varia da un minimo di 2 (es.
lion) ad
un massimo di 18 (es.
dog) con una media pari a 8 (sd=3.4).
All’interno delle 7124 immagini uniche,
la coppia oggetto-
propriet
`
a pi
`
u frequente
`
e furry dog con 769 occorrenze, men-
tre le meno frequenti (es. pink salmon) occorrono in una sola
immagine (media=13.5, sd=37).
Infine, la propriet
`
a pi
`
u fre-
quente, furry, compare in 2936 immagini uniche, seguita da
brown (2782) e smooth (2266).
La meno frequente
`
e vio-
let,
che occorre in 24 immagini.
La frequenza media
`
e 801
(sd=837).
CLIC_2016_Proceedings.indd 238
02/12/16 15.04
239
in cui
o
1
e
o
2
sono due oggetti,
f
(
o
1
, o
2)
conta
quante volte le etichette di
o
1
and
o
2
appaiono
nelle didascalie delle stesse immagini,
f
(
o
)
con-
ta quante volte
o
appare nella didascalia di
MS-
COCO in totale,
e
N
`
e il numero delle parole in
tutte le didascalie.
Le etichette che non sono usa-
te nelle didascalie ricevono un valore uniforme-
mente distribuito in relazione a tutti
gli
altri
og-
getti. 10,000 scenari sono stati generati secondo la
procedura seguente:
•
scegliamo un’etichetta a caso dall’insieme di
161 oggetti (e.s., dog);
•
scegliamo una propriet
`
a
p
dall’insieme delle
24 propriet
`
a (e.s., black);
•
selezioniamo
n
1
immagini
che contengono
oggetti
con l’etichetta
l
e
n
2
immagini
che
contengono oggetti
con l’etichetta
l
e pro-
priet
`
a
p
, cosi che
0
≤
n
1
≤
16
and
0
≤
n
2
≤
n
1
;
•
riempiamo le rimanenti
celle dello scena-
rio (
16
−
n
1
) con le immagini
non etichet-
tate con
l
ed usando la distanza PMI
per
scegliere oggetti che possano plausibilmente
co-occorrere con l’oggetto target;
•
usando la proporzione tra
n
1
e
n
2
, calcoliamo
quale quantificatore assegnare allo scenario
assemblato, seguendo regole pre-definite: no
e all sono assegnati quando, rispettivamente,
nessun
n
1
o tutti
gli
n
1
hanno la propriet
`
a
p
.
Per most
e few usiamo le stime riporta-
te in (Khemlani
et
al.,
2009),
e assegniamo
il primo quando la proporzione
`
uguale o su-
periore al 70%,
e il secondo quando la pro-
porzione
`
e al pi
´
u 17%.
Tutte le proporzioni
che cadono tra questi
due valori
sono asse-
gnate a some. Ad esempio, se
n
1
= 6
oggetti
con l’etichetta
l
, assegniamo no a casi in cui
n
2
= 0
, few quando
n
2
= 1
(1/6=0.1667), so-
me quando
2
≤
n
2
≤
4
, most quando
n
2
= 5
(
5
/
6 = 0
.
833
), e all quando
n
2
= 6
;
•
da
l
e
p
generiamo la domanda (es.
How
many dogs are black?).
Come mostrato nell’esempio sopra descritto,
nel
generare gli
scenari
abbiamo posto come re-
strizione che il numero di immagini
n
1
etichettate
con il restrittore sia uguale o maggiore a
6
.
Sul-
la base delle proporzioni
che abbiamo usato per
definire i
quantificatori,
infatti,
tale numero rap-
presenta il valore minimo per coprire tutti i
5
ca-
si di quantificazione.
Questo significa che i mo-
delli
non possono migliorare la loro accuratezza
semplicemente imparando la correlazione tra valo-
ri bassi di
n
1
e la non plausibilit
`
a di few/most negli
scenari associati.
Inoltre, gli scenari sono unifor-
memente distribuiti tra i
5
quantificatori.
Di con-
seguenza,
ogni quantificatore descrive circa 2000
scenari.
3
Rappresentazioni visive
Per ogni immagine in
ciascuno scenario abbiamo estratto una rappre-
sentazione visiva usando una tecnica che si basa
su reti
neurali
convoluzionali
(CNN) (Simonyan
and Zisserman,
2014).
In particolare,
abbiamo
usato il
modello VGG-19 preaddestrato sui
dati
di ImageNet ILSVRC (Russakovsky et al.,
2015)
e il
pacchetto MatConvNet
(Vedaldi
and Lenc,
2015) per l’estrazione delle features.
Ogni
im-
magine
`
e rappresentata da un vetttore di 4096 di-
mensioni estratto dal settimo layer totalmente con-
nesso (“fully-connected layer”) e successivamen-
te ridotto a un vettore di 400 dimensioni usando
la tecnica SVD.
Questi vettori di 400 dimensioni
rappresentano l’input visuale dei nostri modelli.
Rappresentazioni
linguistiche
La domanda
`
e
espressa mediante due parole:
parola
1
,
il restrit-
tore del quantificatore,
e
parola
2
,
la sua portata.
Ogni parola
`
e rappresentata da un vettore di 400
dimensioni costruito usando l’architettura CBOW
del pacchetto word2vec (Mikolov et al., 2013) e i
migliori parametri di (Baroni et al., 2014).
Il cor-
pus usato per costruire lo spazio semantico,
con-
tentente circa 2.8 miliardi di tokens,
`
e una conca-
tenzione di
UKWaC,
un ampio estratto in ingle-
se di Wikipedia 2009 e il British National Corpus
(BNC).
3
Modelli
iBOWIMG
`
e il modello di domanda e risposta
su immagini
(VQA) di
(Zhou et
al.,
2015) adat-
tato al
nostro compito,
cio
`
e l’apprendimento dei
quantificatori.
Le domande sono rappresentate da
un vettore che mette insieme tutte le parole del vo-
cabolario indicando con “1” quelle presenti (“one-
hot bag-of-words”) ed elaborando un vettore basa-
to su propriet
`
a salienti delle parole (“word featu-
re embedding”). La rappresentazione linguistica
`
e
3
Sia i
codici
che il
dataset
usati
nel
presente lavoro
saranno resi disponibili per studi successivi.
CLIC_2016_Proceedings.indd 239
02/12/16 15.04
240
concatenata con quella visiva.
Il vettore
`
e quindi
usato come input da un classificatore (softmax) che
sceglie la risposta considerando tutto il vocabola-
rio.
L’ultimo passaggio pu
´
o esser visto come un
modello di regressione logistica multi-classe.
Per
adattarlo al
nostro scopo,
abbiamo modificato il
modello originario in due modi. Abbiamo conver-
tito lo scenario in una singola immagine,
conca-
tenando i vettori delle sedici immagini ottenendo
un vettore di
6400
dimensioni.
Inoltre, la risposta
deve essere scelta tra cinque casi (i cinque quanti-
ficatori),
per cui il vocabolario in output consiste
di cinque nodi.
Rete neurale dei quantificatori (RNQ)
Questo
modello sfrutta i vantaggi delle reti neurali e riesce
ad imaparare anche dai propri errori tramite bac-
kpropagation.
Inoltre,
disponendo di celle in cui
archiviare le rappresentazioni vettoriali delle sin-
gole entit
`
a,
riesce ad ottenere un’astrazione dello
scenario alla quale contribuiscono tutte gli ogget-
ti
dello scenario.
I passi
della rete nurale sono
i
seguenti:
(1) i
vettori
visuali
e linguistici
sono
transformati in uno spazio di trecento dimensioni
(
V
1
). (2) I vettori visuali delle sedici immagini so-
no archiviati nelle celle della “memoria”: per ogni
cella calcoliamo la somiglianza tra ciascun vetto-
re visuale e il vettore linguistico rappresentante il
nome della domanda (e.s.
cane);
a tal scopo uti-
lizziamo la norma euclidea.
Il risultato
`
e un vet-
tore “di
somiglianza” di
sedici
dimensioni
(
S
1
).
(3) Calcoliamo quindi i vettori pesati di ogni en-
tit
`
a moltiplicando le celle della memoria
V
1
con i
valori corrispondenti di somiglianza in
S
1
.
Que-
sto ci d
`
a la rappresentazione di quanta “caninit
`
a”
ci sia in ognuno degli oggetti. (4) Sunto 1
`
e cal-
colato sommando le celle della memoria con i vet-
tori
pesati
e rappresenta quanta “caninit
`
a” ci
sia
in un certo scenario.
(5) Calcoliamo il
prodotto
scalare tra i vettori pesati (
W
1
) e il vettore lingui-
stico della propriet
`
a (e.s.
nero),
e normalizziamo
i
valori
con la norma euclidea.
Il
risultato
`
e un
vettore di somiglianza di sedici dimensioni (
S
2
).
Un secondo vettore pesato
W
2
`
e ottenuto molti-
plicanto
W
1
e
S
2
.
Questo ci
da la quantit
`
a di
“caninit
`
a nera” in ogni oggetto.
(6) Sunto 2
`
e
ottenuto sommando i nuovi vettori pesati che sono
archiviati nelle celle della memoria e rappresenta
quanta “caninit
`
a nera” ci sia in un certo scenario.
(7) Sunto 1 e Sunto 2 sono concatenati in un
singolo vettore di
seicento dimensioni
che viene
poi trasformato linearmente in un vettore di cinque
dimensioni.
(8) Applichiamo quindi un classifica-
tore (softmax) che prende come input il vettore di
cinque dimensioni e restituisce per ogni quantifi-
catore la probabilit
`
a che esso sia la risposta giusta.
La rete neurale impara la proporzione tra il nome
e la propriet
`
a che caratterizza la relazione espressa
dal quantificatore.
4
Risultati
Il
modello a rete neurale RNQ ottiene un’accu-
ratezza del
38.9% contro il
30.8% del
modello
iBOWIMG. Il modello RNQ va molto bene con no
e all
e va abbastanza bene con few e most.
Ma
la sua accuratezza diminuisce per some (18.16%),
incidendo negativamente sul
risultato complessi-
vo.
Una diversa analisi emerge invece dai risulta-
ti dell’altro modello,
che va abbastanza bene nel
predire no e all,
ma va molto male negli altri ca-
si.
Per esso,
few,
most
e some sono ugualmente
difficili da imparare.
Sono da rimarcare i suoi er-
rori in particolare nell’apprendere few e most
(si
veda la Tabella 1).
Questi quantificatori richiedo-
no una comprensione pi
`
u precisa delle proporzioni
tra nome e propriet
`
a di quanta non ne richiedano
no e all.
Pensiamo,
quindi,
che ci
`
o dimostri i li-
miti di un modello che non impara ad astrarre ed
elaborare le proporzioni.
Il modello RNQ compie
errori comprensibili, confondendo ad esempio few
con no ma non con some,
most e all.
Ci
`
o dimo-
stra che questo modello ha imparato a quantificare
e non semplicemente a tener traccia delle corre-
lazioni nel dataset.
Al contrario,
l’altro modello
confonde few con no e con all in numero uguale.
In generale, il modello RNQ risulta essere piut-
RNQ
some
all
no
few
most
some
73
88
57
89
95
all
29
211
20
19
125
no
32
28
240
70
32
few
46
53
104
129
68
most
49
148
31
38
126
iBOWIMG
some
all
no
few
most
some
89
77
50
108
78
all
45
163
63
46
87
no
30
69
199
59
52
few
82
81
100
85
52
most
75
110
63
64
80
Tabella 1: Matrice di confusione.
CLIC_2016_Proceedings.indd 240
02/12/16 15.04
241
0
500
1000
1500
2000
black
blue
brown
furry
gray
green
long
metallic orange
pink rectangular red
rough
round
shiny
smooth spotted square striped
violet
wet
white wooden yellow
property
frequency
prediction
correct
wrong
Figura
1:
Risposte
corrette
e
risposte
sbagliate
del
modello in relazione
alla
frequenza
della
combinazione nome-propriet
`
a.
tosto immune a possibili effetti collegati alla fre-
quenza con cui ciascuna delle
24
propriet
`
a occor-
re nel dataset.
Si potrebbe pensare che combina-
zioni molto frequenti vengano imparate meglio di
combinazioni poco frequenti,
ma questo si rivela
essere vero solo per pochi
casi,
su cui
spiccano
red e rectangular.
Nella maggior parte dei casi, il
modello si comporta in modo simile, in termini di
riposte giuste/sbagliate,
di fronte a combinazioni
poco o molto frequenti.
Nel caso di alcuni colori
(black, blue e violet), notiamo un’accuratezza pi
`
u
alta per combinazioni poco frequenti rispetto a ca-
si molto frequenti (vedi Figura 1).
Possiamo dire
che la performance del modello RNQ non dipende
da effetti di frequenza delle combinazioni presen-
ti
nel
dataset.
Di
nuovo,
quindi,
non si
tratta di
imparare correlazioni presenti nel dataset, ma per
svolgere il compito di quantificazione
`
e necessa-
ria una comprensione pi
`
u profonda dello scenario
visivo e della domanda.
Ringraziamenti
Il secondo autore ringrazia l’Erasmus Mundus Eu-
ropean Masters Program in Language and Com-
munication Technologies (EM LCT). Gli altri au-
tori
sono stati
finanziati
dal
progetto COMPO-
SES (ERC 2011 Starting Independent
Research
Grant n.
283554).
Ringraziamo NVIDIA Corpo-
ration per la donazione delle GPU usati per questa
ricerca.
References
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
garet
Mitchell,
Dhruv Batra,
C.
Lawrence Zitnick,
and Devi Parikh.
2015.
VQA: Visual question an-
swering.
In International Conference on Computer
Vision (ICCV).
Marco Baroni, Georgiana Dinu, and Germ
´
an Kruszew-
ski.
2014.
Don’t count, predict! a systematic com-
parison of
context-counting vs.
context-predicting
semantic vectors.
In ACL (1), pages 238–247.
Sangeet Khemlani, Sarah-Jane Leslie, and Sam Gluck-
sberg.
2009.
Generics, prevalence, and default infe-
rences.
In Proceedings of the 31st annual conferen-
ce of the Cognitive Science Society, pages 443–448.
Cognitive Science Society Austin, TX.
Tsung-Yi Lin,
Michael Maire,
Serge Belongie,
James
Hays,
Pietro Perona,
Deva Ramanan,
Piotr Dollar,
and C.
Lawrence Zitnick.
2014.
Microsoft
coco:
Common objects in context.
In Microsoft COCO:
Common Objects in Context.
Tomas Mikolov,
Kai
Chen,
Greg Corrado,
and Jef-
frey Dean.
2013.
Efficient
estimation of
word
representations
in vector
space.
arXiv preprint
arXiv:1301.3781.
M. Ren, R. Kiros, and R. Zemel.
2015.
Image question
answering:
A visual
semantic em- bedding model
and a new dataset.
In In International Conference
on Machine Learningt Deep Learning Workshop.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej
Karpathy,
Aditya Khosla,
Michael Bernstein,
et al.
CLIC_2016_Proceedings.indd 241
02/12/16 15.04
242
2015.
Imagenet large scale visual recognition chal-
lenge.
International
Journal
of
Computer Vision,
115(3):211–252.
Karen Simonyan and Andrew Zisserman.
2014.
Very
deep convolutional
networks for large-scale image
recognition.
arXiv preprint arXiv:1409.1556.
Andrea Vedaldi
and Karel
Lenc.
2015.
MatConv-
Net – Convolutional Neural Networks for MATLAB.
Proceeding of the ACM Int. Conf. on Multimedia.
B. Zhou, Y. Tian, S. Suhkbaatar, A. Szlam, and R. Fer-
gus.
2015.
Simple baseline for
visual
question
answering.
Technical
report,
arXiv:1512.02167,
2015.
CLIC_2016_Proceedings.indd 242
02/12/16 15.04
243
La Modellazione Diacronica di Risorse Termino-Ontologiche nell’Ambito
delle Digital Humanities: Esperimenti su Clavius
Silvia Piccini, Andrea Bellandi, Giulia Benotto, Emiliano Giovannetti
Istituto di Linguistica Computazionale A. Zampolli
Via G. Moruzzi, 1 - CNR Pisa, Italy
name.surname@ilc.cnr.it
Abstract
English.
In
this
work,
we
present
an
experiment
in
the
modeling
of
a
diachronic
termino-ontological
resource
named CLAVIUS through both the N-ary
relations
model
and the 4D-fluents
ap-
proach.
Some of the salient differences of
these two models are discussed. The over-
all objective of this research is to illustrate
the main advantages and disadvantages in
the adoption of a given model to build di-
achronic resources.
Italiano.
In
questo
lavoro,
si
illus-
tra un esperimento di
modellazione
di
una risorsa termino-ontologica diacron-
ica
(CLAVIUS)
secondo
due
approcci,
quello N-ario e quello dei 4D-fluents.
Le
differenze salienti
dei
due approcci
ver-
ranno presentate e discusse.
L’obiettivo
generale della ricerca qui
introdotta è
quello di mostrare i principali vantaggi e
svantaggi
che l’adozione di
un determi-
nato modello può comportare nella model-
lazione di risorse diacroniche.
1
Introduzione
Pànta rei è la celebre espressione attribuita da Pla-
tone ad Eraclito.
Tutto è sottoposto alla inesora-
bile legge del
mutamento:
la realtà,
le categorie
attraverso le quali la organizziamo e le parole che
usiamo per parlare di essa.
Quali
sono
gli
strumenti
a
disposizione
dell’umanista
digitale
di
oggi,
che
si
trovi
a
dover rappresentare in modo esplicito e formale
tale
evoluzione
diacronica
dei
concetti
e
dei
termini
in
un
determinato
ambito,
in
modo
che tale formalizzazione sia computabile ad un
calcolatore?
In questi
ultimi
anni,
ed in particolar
modo
nell’ambito delle Digital
Humanities,
si
è sotto-
lineata l’importanza di operare con tecnologie che
siano alla base del
Semantic Web e dei
Linked
Open Data per garantire interoperabilità e riuso
delle risorse all’interno della comunità scientifica
(Ciotti,
2014).
In questa ottica, le ontologie - e l’OWL, il loro
linguaggio di rappresentazione standard - giocano
un ruolo fondamentale.
Tuttavia, il carattere fon-
damentalmente statico di questi ultimi e la neces-
sità di modellare aspetti di evoluzione temporale
sembrano a prima vista inconciliabili.
Le riflessioni
che presentiamo in questo arti-
colo nascono dalle esperienze condotte in seno
al
Progetto Clavius on the Web
1
.
Tra gli
obi-
ettivi
del
Progetto,
infatti,
vi
è anche quello di
creare una risorsa termino-ontologica (RTO) che
rappresenti l’evoluzione delle teorie matematico-
astronomiche dall’antichità al XVI - XVII secolo,
così come viene descritta da Clavius nei suoi Eu-
clidis Elementorum Libri
XV.
Accessit
XVI
e In
sphaeram Ioannis de Sacro Bosco Commentarius.
2
Il Contesto
Come sottolineato nell’Introduzione, il linguaggio
OWL (e la sua estensione OWL2) è lo standard
W3C per la creazione e condivisione di ontologie
nel Semantic Web.
In particolare,
OWL DL implementa la log-
ica descrittiva
SHOIN
(
D
n
)
,
che garantisce una
maggiore espressività rispetto a RDF e RDFS,
senza compromettere la decidibilità e il meccan-
ismo inferenziale.
Tuttavia, OWL è un linguaggio statico; in esso
le proprietà e le relazioni
tra entità sono fonda-
mentalmente binarie, espresse sotto forma di triple
<Subject predicate Object>.
Tale restrizione sin-
tattica rende più complessa la rappresentazione
1
http://claviusontheweb.it (ultimo accesso: 13/10/2016)
CLIC_2016_Proceedings.indd 243
02/12/16 15.04
244
di
entità
temporali,
caratterizzate
da
relazioni
ternarie.
Diversi
approcci
sono stati
proposti
in let-
teratura per
superare tale limite e rappresentare
l’evoluzione
diacronica
dei
concetti
(Krieger,
2014;
Welty et
al.,
2006).
Tra questi
vi
sono:
i) il
versioning,
che consiste nel
creare una ver-
sione differente dell’ontologia,
una per
ciascun
istante temporale (Grandi
and Scalas,
2009),
ii)
l’estensione delle triple RDF con argomenti sup-
plementari
temporali
(Krieger,
2012),
iii)
la
reficazione,
che trasforma le proprietà in classi
(Manola and Miller,
2004),
iv)
il
modello N-
ario (Noy and Rector,
2006),
v) il modello per-
durantista o dei
4D-fluents (Welty et
al.,
2006),
vi) la codifica dell’estensione temporale attraverso
nuove proprietà sintetiche (Gangemi,
2011). Allo
stato dell’arte,
i
due principali
approcci
adottati
nella modellazione di risorse diacroniche (solita-
mente ontologie) sono il
modello delle relazioni
N-arie e il
modello dei
perduranti.
Nel
primo,
per
ogni
relazione
temporale
viene
introdotto
un nuovo oggetto,
istanza della classe EVENT.
La durata della relazione coincide con la durata
dell’evento.
In questo modello, pertanto, una pro-
prietà n-aria è rappresentata come una classe,
le
cui
istanze corrispondono alle istanze della pro-
prietà.
Nel
modello 4D-fluents,
invece,
le entità
coinvolte in relazioni temporali sono rappresentate
da oggetti
4-dimensionali
detti
timeslices.
Ogni
timeslice rappresenta una sorta di “fotogramma”,
in cui l’entità ad esso riferita ha natura immutabile
(perdurante) in quello specifico istante o intervallo
di tempo.
3
La risorsa CLAVIUS
Clavius costituisce una RTO. In accordo con le più
recenti acquisizioni teoriche (Roche,
2007; Tem-
merman et al., 2005), in essa infatti sono formal-
izzate come indipendenti
due componenti
stret-
tamente legate tra di
loro:
la componente ter-
minologica nella quale vengono strutturati
i
ter-
mini
presenti
in un testo e la componente on-
tologica attraverso la quale vengono formaliz-
zati
i
concetti
evocati
da quei
termini.
Il
livello
più alto dell’ontologia è rappresentato così
dalle
due classi
OWL disgiunte CONCEPT e TERM.
La superclasse CONCEPT sussume due sotto-
classi,
ASTRONOMICAL CONCEPT e MATH-
EMATICAL CONCEPT,
che a loro volta sus-
sumono
rispettivamente
tutti
i
concetti
astro-
nomici
e
matematici.
La
superclasse
TERM
si
articola,
invece,
in due sottoclassi
ASTRO-
NOMICAL TERM e MATHEMATICAL TERM.
Quest’ultima sussume le classi
OWL disgiunte
LATIN TERM e GREEK TERM, di cui i termini
latini e greci costituiscono le istanze. Nella risorsa
la parte concettuale è espressa in inglese mentre
la parte terminologica è costituita dai termini la-
tini,
legati ai concetti che essi evocano attraverso
la relazione denotes e la sua inversa isDenotedBy.
L’ontologia è attualmente composta da 106 classi
organizzate in quattro livelli
gerarchici,
un in-
sieme di 10 Data Properties e 18 Object proper-
ties, che permettono di dare una rappresentazione
precisa dei concetti e termini.
Le relazioni sono
suddivise in:
relazioni
lessicali,
paradigmatiche
tra i
termini
(iperonimia,
iponimia,
meronimia,
olonimia, sinonimia e antonimia); relazioni inter-
livello tra termini e concetti; relazioni concettuali,
molte delle quali sono state introdotte per dare una
definizione più precisa del
dominio matematico-
astronomico (Piccini
et
al.,
2016).
Per
quanto
concerne la modellazione degli
aspetti
temporali
è stata importata l’ontologia OWL-Time,
che si
basa sulle relazioni binarie tra intervalli introdotte
in (Allen and Ferguson,
1997) ed è stata integrata
una serie di regole Semantic Web Rule Language
(SWRL),
elaborate in (Batsakis et al.,
2016).
In
questo modo possono essere rappresentate e trat-
tate dai motori inferenziali sia informazioni tem-
porali
quantitative (informazioni
temporali
pre-
cise), sia informazioni temporali qualitative (delle
quali,
cioè,
non si
possono specificare con esat-
tezza l’istante iniziale e finale).
Queste ultime, in
particolare, sono molto frequenti nel testo di Clav-
ius,
e più in generale,
nella letteratura,
dove non
è sempre possibile definire con esattezza la data
di inzio e di fine nella quale si è verificato o sus-
siste un determinato fatto
2
.
Le relazioni tra le en-
tità ontologiche sono state temporalizzate in base
alla loro validità nel
tempo,
seguendo i
due ap-
procci, quello N-ario e quello perdurantista, come
descritto nella Sezione 2.
4
Comparazione della risorsa nei due
modelli
In questa Sezione sono definiti
i
criteri
di
com-
parazione dei
due modelli
e vengono presentati
2
La rappresentazione di tali informazioni temporali è in-
dipendente dai
modelli
ivi
trattati
e non verrà pertanto dis-
cussa.
CLIC_2016_Proceedings.indd 244
02/12/16 15.04
245
Figure 1:
I due modelli a confronto.
In rosso i nuovi oggetti da creare nei diversi modelli.
Le linee
tratteggiate rappresentano la relazione di instance of.
i
vantaggi
e le criticità di
entrambi
nella loro
applicazione alla risorsa Clavius
in OWL.
Un
primo criterio di
comparazione riguarda il
nu-
mero di
assiomi
logici
necessari
alla rappresen-
tazione delle relazioni
temporali.
Come illus-
trato in precedenza,
infatti,
entrambi
i
modelli
richiedono l’introduzione di
nuove entità tempo-
rali (eventi o timeslice).
A titolo d’esempio,
pre-
sentiamo il mutamento nel tempo del concetto de-
notato dal
termine primum mobile.
Il
numero
delle sfere ed il loro relativo ordine costituisce un
problema ampiamente dibattuto nell’astronomia
del Seicento.
Secondo la visione aristotelica del
kosmos il
movimento dei
sette cieli
attorno alla
terra era dovuto ad una sfera, la più esterna, detta
primum mobile.
Mano a mano che nei
secoli
si
vennero a scoprire maggiori dettagli sul moto dei
pianeti, divenne necessario aggiungere altre sfere:
così con Tolomeo il loro numero salì a 9, nelle tav-
ole alfonsine a 10, quindi a 11 ed infine a 12 con
Magini.
Alla introduzione di
una ulteriore sfera
sul
piano concettuale corrisponde un mutamento
nel codominio della relazione interlivello denotes
il cui dominio è rappresentato dal termine primum
mobile:
i) primum_mobile denotes eighth_sphere
(dal 300 a.C. al 152 d.C.), ii) primum_mobile de-
notes ninth_sphere (dal 152 d.C. al 1252 d.C.), iii)
primum_mobile denotes tenth_sphere (dal
1252
d.C. al 1589 d.C.). La Figura 1 mostra un esempio
di rappresentazione di questi statements.
Le classi, le proprietà e le istanze in rosso, rap-
presentano le entità ontologiche che debbono es-
sere introdotte per tradurre in linguaggio formale
tali statements. Si nota come il modello dei perdu-
ranti sia soggetto ad una maggiore proliferazione
delle entità: accanto alla classe TIMESLICE sono
stati
introdotti
una nuova Object
property (has-
TimeSlice),
istanziata sei
volte,
e sei
nuovi
indi-
vidui della classe TIMESLICE (le parti temporali
degli individui coinvolti nella temporalizzazione).
Il
modello N-ario,
d’altro canto,
risulta più
snello, richiedendo solo la creazione di tre eventi,
uno per
ogni
statement.
Tuttavia,
tale model-
lazione modifica,
da un punto di
vista intuitivo,
la semantica della relazione denotes, spezzando e
duplicando la proprietà per legare l’evento ai due
individui coinvolti nella temporalizzazione. In en-
trambi i modelli il dominio e il codominio di una
proprietà temporale vengono modificati: nel mod-
ello N-ario si aggiunge ad essi la classe EVENT,
nel modello dei perduranti si sostituiscono le classi
originarie con la classe TIMESLICE.
Precisiamo
che la nostra analisi
è limitata ai
modelli
delle
relazioni da temporalizzare,
ed è quindi indipen-
dente sia rispetto al modo in cui gli intervalli e gli
istanti temporali sono rappresentati (OWL-TIME
in Figura 1), sia rispetto a come i costrutti e le re-
gole di OWL (“SWRL rules” in Figura 1) vengono
CLIC_2016_Proceedings.indd 245
02/12/16 15.04
246
Table 1: Confronto tra i modelli
modello n-ario
modello 4D-fluents
Metriche dell’ontologia
numero di classi
106
106
numero di individui
244
265
numero di istanze di object property
117
159
Temporalizzazione del predicato
pred
:
X
→
Y
pred
n−ary
:
pred
perd
:
X

Event
→
Y

Event
T imeSlice
→
T imeSlice
Interrogazione
query SPARQL: lunghezza del path
2
3
query SPARQL: numero di variabili
2
3
Tools
Availability
yes
no
∗
combinati per fornire una procedura di reasoning
solida e completa.
Per una trattazione accurata
di
queste problematiche rimandiamo a (Batsakis
et al.,
2016).
In relazione ad una maggiore pro-
liferazione di entità, inoltre, l’interrogazione della
risorsa può diventare più complessa e quindi mag-
giormente prona ad errori.
Per quanto riguarda
l’interrogazione,
abbiamo considerato una sem-
plice query di
interrogazione della risorsa per
conoscere quali sono i concetti che il termine pri-
mum_mobile ha denotato nel
tempo.
Le query
sono state implementate tramite il
linguaggio di
interrogazione SPARQL nei
due modelli.
Per il
modello N-ario abbiamo:
SELECT ?concept
WHERE { n-ary:primum_mobile a n-ary:TERM .
n-ary:primum_mobile n-ary:denotes ?event .
?event a n-ary:EVENT .
?event n-ary:denotes ?concept }
Per il modello dei perduranti abbiamo:
SELECT ?concept
WHERE { ?ts@t1 4d:denotes ?ts@t2 .
?ts@t1 a 4d:TIMESLICE .
?ts@t2 a 4d:TIMESLICE .
4d:primum_mobile a 4d:TERM .
4d:primum_mobile 4d:hasTimeSlice ?ts@t1 .
?concept 4d:hasTimeSlice ?ts@t2 }
Da una analisi dei due codici si evince che per
interrogare il secondo modello occorre un numero
maggiore di
variabili
nella query e che il
path
dell’interrogazione del
grafo è più lungo e coin-
volge un maggior numero di
entità ontologiche.
Questo implica che,
in termini
di
scalabilità ed
efficienza nel processo di interrogazione,
il mod-
ello N-ario potrebbe risultare migliore.
Come ul-
timo criterio abbiamo considerato la disponibil-
ità di
strumenti
che supportino l’umanista nella
creazione di
RTO diacroniche senza richiedere
la conoscenza dei modelli matematici sottostanti.
Per quanto riguarda il modello N-ario è disponi-
bile il plug-in di Protégé CHRONOS-ED (Preven-
tis et
al.,
2012).
Il
plug-in per
il
modello 4D-
fluents,
al
contrario,
risulta ad oggi
non funzio-
nante nelle ultime versioni di Protégé (vedi aster-
isco in Tabella 1).
I risulati dell’analisi compara-
tiva sono riassunti nella Tabella 1.
5
Discussione e lavori futuri
La modellazione della risorsa diacronica termino-
ontologica CLAVIUS attraverso il
modello a re-
lazioni
N-arie e quello 4D-fluents ha consentito
di
valutare,
empiricamente,
quelle che sono le
differenze salienti
tra i
due paradigmi
temporali.
Per quanto riguarda l’aspetto di authoring, di pri-
mario interesse in questo lavoro in quanto fun-
zionale alla necessità di un umanista digitale nella
costruzione (tipicamente manuale) di una risorsa
diacronica, i risultati hanno evidenziato come, ad
oggi,
l’approccio a relazioni
N-arie risulti
il
più
vantaggioso, in termini sia di numero di entità on-
tologiche coinvolte, sia di complessità delle query
SPARQL sia di disponibilità di strumenti di sup-
porto. Si intende approfondire questa ricerca pren-
dendo in considerazione gli
aspetti
che,
natural-
mente,
seguono quelli
più essenziali
di
formal-
izzazione della terminologia e della conoscenza.
In primis,
verrà studiato l’impatto determinato
dall’adozione di
un certo modello sui
meccan-
ismi
di
reasoning,
e quindi,
sulla possibilità da
parte di un motore inferenziale di derivare nuova
conoscenza a partire da quella rappresentata es-
plicitamente nella risorsa.
CLIC_2016_Proceedings.indd 246
02/12/16 15.04
247
References
James F.
Allen and George Ferguson.
1997
Actions
and Events in Interval
Temporal
Logic.
In:
Spa-
tial and Temporal Reasoning. O. Stock, ed., Kluwer,
Dordrecht, Netherlands, pp. 205-245.
Sotiris Batsakis,
Euripides Petrakis,
Ilias Tachmazidis
and Grigoris Antoniou 2016.
Temporal Representa-
tion and Reasoning in OWL 2.
Semantic Web jour-
nal, ISSN 1570-0844.
Fabio Ciotti.
2014 Digital Literary and Cultural Stud-
ies: State of the Art and Perspectives.
Between, vol.
4, no. 8.
Noy N. Fridman, William Grosso, and Mark A. Musen
2000.
Knowledge-Acquisition Interfaces for Do-
main Experts: An Empirical Evaluation of Protege-
2000.
SEKE2000 Proceedings. Chicago.
Aldo Gangemi.
2011
SuperDuper
schema:
an
OWL2+RIF DnS pattern.
KCAP 2011 Deep Knowl-
edge Representation Challenge Workshop.
Fabio Grandi,
and Maria Rita Scalas.
2009
The
Valid Ontology:
A simple OWL temporal
version-
ing framework.
Advances in Semantic Process-
ing, SEMAPRO’09. Third International Conference
IEEE, 2009. pp. 98-102.
Hans U. Krieger.
2014 A detailed comparison of seven
approaches
for
the annotation of
time-dependent
factual knowledge in RDF and OWL.
Proceedings
10th Joint
ISO-ACL SIGSEM Workshop on Inter-
operable Semantic Annotation, p. 1.
Hans U.
Krieger.
2012
A temporal
extension of
the
Hayester Horst entailment rules and an alternative
to W3C’s n-ary relations.
Proceedings of the 7th
International Conference on Formal Ontology in In-
formation Systems (FOIS), pp. 323–336.
Frank Manola and Eric Miller.
2004
RDF primer.
Technical report, W3C.
Natasha Noy and Alan Rector.
2006
Defining N-
ary Relations on the Semantic Web.
W3C Work-
ing Group Note 12,
https://www.w3.org/TR/swbp-
n-aryRelations/
Piccini,
S.,
Bellandi,
A.,
and Benotto,
G.
2016
Formalizing and Querying a Diachronic Termino-
Ontological
Resource:
the CLAVIUS Case Study.
Proceedings
of
From Digitization to Knowledge
2016 workshop (D2K),
July 11,
2016,
Krakow
(Poland).
Preventis A.,
Marki
P.,
Petrakis E.G.M.,
Batsakis S.
2016 Chronos: A Tool for Handling Temporal On-
tologies in Protégé.
Proceedings of the 24th Inter-
national Conference on Tools with Artificial Intelli-
gence, Athens, Greece.
Christophe Roche.
2007 Le terme et le concept: fonde-
ments d’une ontoterminologie.
Actes de la première
conférence TOTh, pp.1–22, Annecy.
Evren Sirin,
Bijan Parsia,
Bernardo C.
Grau,
Aditya
Kalyanpur,
Yarden Katz
2007.
Pellet:
A practical
owl-dl reasoner.
Web Semantics:
science, services
and agents on the World Wide Web, 5.2 51-53.
Rob
Shearer,
Boris
Motik,
and
Ian
Horrocks.
2008
HermiT: A Highly-Efficient
OWL Reasoner.
OWLED, Vol. 432.
Rita Temmerman,
Koen Kerremans,
and Veerle Van-
dervoort
2005
La termontographie
en con-
texte(s).
In Blampain, D., Thoiron, P., Van Campen-
houdt,
M.
(eds).
Mots,
Termes et Contextes.
Actes
des septièmes Journées scientifiques du réseau de
chercheurs
Lexicologie
Terminologie
Traduction.
Bruxelles, 429- 439.
Chris Welty, Richard Fikes, and Selene Makarios 2006
A reusable ontology for fluents in OWL.
Proceed-
ings of the 4th International Conference on Formal
Ontology in Information Systems (FOIS), Vol. 150.
pp. 226–336
CLIC_2016_Proceedings.indd 247
02/12/16 15.04
248
Studio sull’ordine dei costituenti nel confronto tra generi e complessità
Giulia Pieri
•
, Dominique Brunato

, Felice Dell’Orletta

•
Università di Pisa, Emm&mmE Informatica
giulia.pieri@mminformatica.it

Istituto di Linguistica Computazionale “Antonio Zampolli” (ILC–CNR)
ItaliaNLP Lab - www.italianlp.it
{dominique.brunato, felice.dellorletta}@ilc.cnr.it
Abstract
Italiano.
In questo articolo presentiamo
uno studio sull’ordine dei
costituenti
in
italiano basato su corpora annotati in ma-
niera automatica fino all’analisi sintattica
a dipendenze.
L’indagine comparativa ha
permesso di valutare l’influenza sia del ge-
nere testuale sia della complessità lingui-
stica nella distribuzione dei
fenomeni
di
marcatezza sintattica.
English.
In this paper we present a study
on the order of constituents in Italian ba-
sed on automatically dependency–parsed
corpora.
The comparative investigation
has allowed to evaluate the influence of the
textual genre and the linguistic complexi-
ty on the distribution of
phenonemena of
syntactic markedeness.
1
Introduzione
Sebbene non esista una metrica universalmente
valida con la quale poter
classificare le lingue
secondo una scala di
complessità (McWorther,
2001),
esistono alcuni indicatori che,
a diversi li-
velli
linguistici,
possono essere assunti
come in-
dici
di
complessità ‘universalmente’ validi
(Fio-
rentino, 2009).
Sul piano sintattico, uno di essi è
rappresentato dall’ordine dei costituenti, per cui le
lingue che ammettono un ordine libero sono consi-
derate più complesse di quelle a ordine fisso. Nel-
la letteratura linguistica e psicolinguistica la fles-
sibilità dell’ordine viene ricondotta, a sua volta, a
fattori
diversi
che tengono in considerazione,
da
un lato,
i
principi
semantici
e pragmatici
deter-
minati
dalla struttura dell’informazione (Diessel,
2005), dall’altro i vincoli di performances, per cui
le strutture non marcate sono quelle cognitivamen-
te meno costose che permettono al parlante di ela-
borare l’informazione più velocemente (Hawkins,
1994;
Gibson,
1998;
Gibson,
2000).
Esaminan-
do in maniera comparativa due treebank del
La-
tino e del
Greco antico,
lo studio di
(Gulordava
e Merlo,
2015) ha dimostrato come la flessibili-
tà dell’ordine sintattico, misurata come la distanza
tra l’effettiva lunghezza delle dipendenze di
una
frase e la sua lunghezza ottimale (Gildea e Tem-
perley, 2010), sia un elemento di complessità che
si può desumere tanto dalla minor precisione del
parsing automatico nell’analisi
di
queste lingue,
quanto dalla tendenza che si riscontra nel tempo
verso modelli di ordine fisso dei costituenti.
Questo articolo propone uno studio quantitativo
per l’italiano,
lingua di tipo VO (o a testa inizia-
le) e relativamente poco flessibile, volto a indagare
se, e in che misura, la disposizione naturale o non
marcata dei costituenti nella frase sia influenzata
dal genere testuale e dalla complessità della lingua
usata nel testo.
A questo scopo sono stati compa-
rati due generi linguistici, narrativo e giornalistico,
a loro volta distinti in due varietà linguistiche dif-
ferenti per grado di complessità,
dove tale grado
è definito in relazione al lettore di riferimento.
A
differenza delle analisi tradizionali di tipo corpus–
based sull’ordine dei costituenti in italiano, tutti i
dati qui discussi sono ricavati da corpora annota-
ti in maniera automatica fino al livello di analisi
sintattica a dipendenze. Anche se la ricostruzione
della struttura sintattica da parte di un parser sta-
tistico è soggetta inevitabilmente ad alcuni errori
(Montemagni, 2013), che aumentano per i testi di
un dominio distante da quello del training (Gildea,
2001), la varietà dei fenomeni che si possono mo-
nitorare con affidabilità a partire da un’analisi lin-
guistica automatica è molto ampia e complessa. La
prospettiva linguistico–computazionale apre dun-
que prospettive di
ricerca promettenti
per la co-
struzione e la validazione su larga scala di model-
li teorici sul funzionamento dei sistemi linguistici
sia in chiave tipologica sia rispetto ai tradizionali
assi di variazione linguistica.
CLIC_2016_Proceedings.indd 248
02/12/16 15.04
249
In quanto segue,
verranno prima presentati
i
corpora utilizzati
in questo studio e successiva-
mente la metodologia di
monitoraggio sui
cui
si
è basata l’estrazione delle caratteristiche linguisti-
che oggetto di
indagine (Paragrafo 2.1);
nel
Pa-
ragrafo 3 discuteremo i principali risultati ottenu-
ti e infine trarremmo alcune conclusioni di questa
ricerca.
2
I corpora
I corpora esaminati appartengono a due diversi ge-
neri testuali, narrativo e giornalistico.
Per ciascun
genere sono state selezionate due collezioni di te-
sti rappresentative di due varietà di lingua che si
possono collocare a due poli opposti per comples-
sità linguistica, dove il grado di complessità è de-
finito in base al destinatario previsto; ogni macro-
raccolta,
dunque,
contiene una collezione di testi
“complessi” e una di testi “semplici”.
I due corpora narrativi, Terence e Teacher, rappre-
sentano la prima risorsa italiana per lo studio del-
la semplificazione automatica e semi-automatica
dei
testi
(Brunato et
al.,
2015).
Entrambi
sono
costituiti
da testi
nella versione originale e nella
rispettiva versione semplificata,
allineate per cia-
scun corpus a livello di frase. Le versioni semplifi-
cate derivano da due differenti strategie di sempli-
ficazione manuale:
la strategia “strutturale”,
che
implica una semplificazione cumulativa (ovvero
su diversi livelli linguistici) prodotta da esperti nel
caso di
Terence,
e la strategia “intuitiva”,
che si
avvale invece dell’intuizione e dell’esperienza del-
l’insegnante nel
caso di
Teacher.
In particolare,
Terence si compone di 32 racconti brevi per l’in-
fanzia e delle rispettive versioni semplificate rivol-
te a bambini dai 7 agli 11 anni con deficit uditivi o
con difficoltà nella comprensione dei testi
1
.
Tea-
cher è un corpus formato da 24 coppie di testi ori-
ginali e semplificati raccolti da siti web educativi
specializzati che forniscono risorse gratuite per gli
insegnanti; in questo caso, il target della semplifi-
cazione sono principalmente studenti di lingua ita-
liana L2.
Per il genere giornalistico, invece, il materiale ana-
lizzato è costituito da due corpora che raccolgono
rispettivamente testi
esemplificativi
di
una varie-
tà complessa,
Repubblica,
e di
una varietà sem-
plice,
Due Parole.
Il primo (Rep) consiste in un
ampio corpus di testi giornalistici (pari a 232.908
1
Questo corpus deriva dall’omonimo progetto dell’Unio-
ne Europea (Terence Consortium, 2012).
tokens) che include tutti gli articoli pubblicati dal
2000 al 2005 sul quotidiano La Repubblica, che si
rivolge ad una platea di lettori con un profilo cul-
turale medio-alto.
Il
secondo (2Par) è un corpus
di
73.314 tokens che trae il
nome dall’omonimo
quotidiano Due Parole, un mensile di facile lettu-
ra curato da linguisti esperti in semplificazione dei
testi
che hanno utilizzato un linguaggio control-
lato per un pubblico adulto con un basso livello
di
alfabetizzazione o con lievi
disabilità intellet-
tuali (Piemontese, 1996).
Il corpus qui analizzato
comprende tutti gli articoli scritti tra il 2001 e il
2006.
È importante sottolineare che,
a differen-
za dei corpora di narrativa, il corpus giornalistico
non è parallelo,
in quanto i relativi testi “sempli-
ci” (quelli di Due Parole) non sono il risultato di
un processo di
semplificazione dei
testi
originali
di Repubblica.
2.1
Analisi linguistica dei corpora
Come passo preliminare allo studio dei
fenome-
ni
di
ordinamento sintattico riportati
in Sezione
3,
i corpora sono stati arricchiti automaticamente
con annotazione morfo–sintattica e sintattica uti-
lizzando la catena di
analisi
linguistica LinguA
2
,
che integra il
Part–of–Speech tagger descritto in
(Dell’Orletta,
2009) e il parser a dipendenze De-
SR (Attardi et al., 2009). L’annotazione linguisti-
ca multi–livello ha permesso di analizzare gli stes-
si tramite MONITOR–IT: questo strumento, adot-
tando la metodologia di monitoraggio descritta in
Montemagni (2013), consente di ricavare la distri-
buzione di un’ampia gamma di caratteristiche les-
sicali,
morfo–sintattiche e sintattiche rintracciate
automaticamente in un corpus a partire dall’output
dei diversi livelli di annotazione linguistica.
3
Analisi dei dati
Per gli scopi di questa indagine sono di interesse
caratteristiche di ordine sintattico che fanno rife-
rimento alla posizione lineare di un elemento ri-
spetto alla “testa” da cui è retto in una rappresen-
tazione sintattica a dipendenze.
Gli elementi con-
siderati sono stati:
il soggetto,
l’oggetto,
l’avver-
bio,
l’aggettivo e la clausola subordinata,
di
cui
sono state calcolate:
i) le occorrenze nella posi-
zione “canonica” rispetto alla matrice prevalente
SVO dell’italiano (preposta o posposta alla testa
a seconda dell’elemento indagato) e nella posizio-
ne opposta, dunque “marcata” sintatticamente e/o
2
http://linguistic-annotation-tool.italianlp.it/
CLIC_2016_Proceedings.indd 249
02/12/16 15.04
250
Corpus
Oggetto
Soggetto
Aggettivo
Avverbio
Pre-V
Post-V
Pre-V
Post-V
Pre-N
Post-N
Pre-V
Post-V
%
AvD
%
AvD
%
AvD
%
AvD
%
AvD
%
AvD
%
AvD
%
AvD
TT orig
9.18
1.93
90.82
2.52
85.38
2.56
14.62
2.88
53.91
1.11
46.09
1.2
55.49
2.4
44.51
1.61
Rep
8.37
2.43
91.63
2.72
80.14
3.87
19.86
3.45
41.87
1.19
58.13
1.32
56.11
2.66
43.89
1.47
TT sempl
7.87
1.93
92.13
2.43
84.28
2.23
15.72
2.63
56.53
1.12
43.47
1.16
56.24
2.19
43.76
1.47
2Par
3.47
1.6
96.53
2.56
89.11
3.07
10.89
3.5
24.97
1.09
75.03
1.12
56.69
3.84
43.31
1.4
Tabella 1:
Ordine relativo dei costituenti (%) e distanza media (AvD) rispetto alla testa verbale (V) o nominale (N).
pragmaticamente; ii) la distanza (in numero di to-
kens) del
dipendente dalla testa sintattica in en-
trambe le posizioni.
Per ognuno di questi dati,
il
confronto tra i
corpora è avvenuto su due livel-
li:
la variazione di genere e il grado di comples-
sità.
Infatti,
scopo dello studio è stato verificare
quali sono gli ordini degli elementi che vengono
condizionati dal genere testuale e quali dipendo-
no dal grado di complessità:
l’ipotesi di partenza
era che fosse possibile ritrovare una somiglianza
dell’ordine degli elementi in relazione al genere,
ma soprattutto verificare che,
indipendentemente
dal genere, i testi semplici sono più fedeli a segui-
re l’ordine canonico degli elementi, mentre i testi
complessi presentano una più alta percentuale di
casi di ordine marcato.
La Tabella 1 mostra i
risultati
del
monitorag-
gio relativi all’oggetto, al soggetto, all’aggettivo e
all’avverbio
3
.
Partiamo dall’analisi degli elemen-
ti che,
nel confronto complessivo tra corpora,
di-
mostrano una tendenza più netta a ricorrere nella
posizione canonica:
l’oggetto e il
soggetto.
Nel
caso dell’oggetto,
si
osserva che i
testi
giornali-
stici
si
attengono maggiormente all’ordine cano-
nico,
mentre nei
testi
narrativi
aumentano lieve-
mente le occorrenze dell’oggetto in posizione pre-
verbale.
L’ordine marcato con anteposizione del-
l’oggetto alla testa verbale è inoltre influenzato dal
grado di complessità della lingua: in ciascun gene-
re infatti,
quest’ordine ricorre in percentuale mi-
nore nei testi semplici e tale differenza è evidente
soprattutto in 2Par che registra poco più del 3%
di oggetti in posizione preverbale.
Anche rispet-
to alla posizione del
soggetto,
è possibile notare
un’influenza sia del genere sia della complessità.
In questo caso,
però,
sono i
testi
narrativi
origi-
nali a rispettare maggiormente l’ordine canonico
soggetto–verbo (85,38%) rispetto a quelli
di
Re-
3
Per rendere possibile il confronto tra gradi di complessi-
tà, i corpora Terence e Teacher sono stati uniti così da ottenere
due corpora, l’uno composto di tutti i testi narrativi originali
(TT orig), pari a 26.311 tokens, e l’altro di tutti i relativi testi
semplificati (TT semp), pari a 24.083 tokens.
pubblica (80,14%).
La variazione rispetto al gra-
do di complessità produce invece risultati coeren-
ti
alle aspettative solo per la prosa giornalistica,
dove lo scarto tra Rep e 2Par è quasi di 10 punti
percentuali in favore dell’ordine canonico (2Par:
89,11%).
Al
contrario,
la semplificazione dei
te-
sti narrativi ha prodotto un aumento, seppure mi-
nimo,
di
soggetti
postverbali
(TT orig:
14,62%;
TT semp:
15,72%).
Pur considerando che i testi
narrativi originali sono comunque più semplici di
quelli di Repubblica, proprio perché rivolti a bam-
bini, questo dato potrebbe segnalare che forme di
marcatezza sintattica sono talvolta preferite come
esito della semplificazione,
perché permettono di
ottenere un testo narrativo più coeso, mantenendo-
ne la progressione tematica. Interessanti sono an-
che i dati sulla distanza lineare tra soggetto e ver-
bo che, in entrambi i generi della varietà semplice,
aumenta quando il soggetto è in posizione postver-
bale.
Si può ipotizzare,
tuttavia,
che la presenza
dei tratti di accordo sul verbo in una lingua come
l’italiano renda meno difficoltosa la ricostruzione
della dipendenza soggetto–verbo, anche quando il
soggetto è in posizione marcata.
A differenza del soggetto e dell’oggetto,
l’agget-
tivo in italiano ha una posizione meno rigida nel
sintagma nominale.
Infatti,
anche se la posizione
non marcata è generalmente postnominale,
essa
varia in base alla funzione semantica che l’agget-
tivo svolge rispetto al nome (Cinque, 2010).
Que-
sta flessibilità trova conferme nell’analisi empiri-
ca, tuttavia con differenze rispetto al genere:
i te-
sti
giornalistici,
infatti,
privilegiano l’ordine ten-
denzialmente non marcato mentre quelli
narrati-
vi
mostrano la tendenza opposta.
Anche in que-
sto caso, sul piano della variazione testi comples-
si/testi semplici, l’effetto è marcato solo per il ge-
nere giornalistico (Rep: 58,13; 2Par: 75,03).
Considerazioni analoghe possono essere avanzate
per l’avverbio, la cui posizione in italiano, pur es-
sendo tendenzialmente postverbale, gode di ampia
flessibilità in relazione alla classe semantica di ap-
CLIC_2016_Proceedings.indd 250
02/12/16 15.04
251
partenenza (Bonvino et al., 2008). In tutti e quattro
i corpora è preferita la posizione preposta al verbo,
che è anche quella a generare link sintattici
me-
diamente più lunghi (si veda il dato riportato nella
terzultima colonna).
Si tratta di un dato significa-
tivo,
soprattutto se si considera che il valore me-
dio più elevato è riportato proprio dai testi di 2Par
(3.84 tokens). Come per il caso del soggetto,
an-
che questo dato suggerisce la necessità di raffinare
una nota misura di complessità sintattica quale la
distanza dei link sintattici,
tenendo in considera-
zione proprietà semantiche e morfologiche degli
elementi coinvolti nella relazione di dipendenza.
Infine,
abbiamo condotto uno studio più detta-
gliato sulla subordinazione (Tabella 2).
Anche in
questo caso sono state estratte sia le distribuzioni
percentuali della subordinata in posizione preposta
e posposta alla reggente sia la distanza (in nume-
ro di tokens) che separa la part–of–speech che in-
troduce la subordinata
4
dal verbo della reggente.
Inoltre, questo dato è stato ulteriormente raffinato
andando a calcolare la lunghezza totale (in tokens)
dell’intera clausola subordinata e la sua profon-
dità media,
quest’ultima computata come nume-
ro di relazioni di dipendenza che intercorrono tra
la radice del sotto–albero della subordinata e una
parola senza dipendenti (foglia).
Corpus
Subordinata
Pre-Principale
%
AvD
Length
Depth
TT orig
10.12
9.71
8.93
3.86
Rep
15.37
11.51
9.49
4.16
TT sempl
11.03
8.0
7.19
3.63
2Par
15.71
10.26
7.43
3.72
Post-Principale
TT orig
89.88
3.27
8.62
4.19
Rep
84.63
3.44
12.07
5.28
TT sempl
88.97
2.94
7.91
4.12
2Par
84.29
3.0
8.39
4.36
Tabella 2:
Ordine della clausola subordinata rispetto alla
principale.
Per ciascuna posizione,
vengono riportate la di-
stribuzione percentuale (%), la distanza media dalla principa-
le (AvD), la lunghezza media (Length) e la profondità media
(Depth) dell’intera subordinata.
I risultati
indicano una netta preferenza per la
posizione posposta rispetto alla principale. Il dato
è coerente con le previsioni dei modelli di proces-
sing secondo cui questo ordinamento comporta un
impegno cognitivo minore da parte del parlante e
dell’ascoltatore perché consente di minimizzare i
4
Sono state considerate sia le subordinate esplicite, intro-
dotte da una congiunzione subordinante, sia quelle implicite,
introdotte da un verbo di modo infinito o da una preposizione.
domini di riconoscimento delle relazioni sintatti-
che (Hawkins,
1994).
Anche se meno frequenti,
i casi di anteposizione della subordinata si verifi-
cano maggiormente nel genere giornalistico, addi-
rittura nella varietà semplice (2Par: 15.71% Rep:
15.37%).
Questi
dati
sono riconducibili
alle teo-
rie che chiamano in causa l’interazione tra sintassi
e fattori
pragmatici
e semantici,
per cui
il
gene-
re giornalistico sarebbe più propenso ad anteporre
la subordinata alla principale poiché costituisce lo
sfondo tematico dell’evento principale e conferi-
sce la funzione di collegamento tematico e intro-
duzione per l’informazione nuova (Diessel, 2005).
Come prevedibile,
l’anteposizione della subordi-
nata determina dipendenze sintattiche mediamente
più lunghe; la difficoltà di processing che ne deri-
va è compensata dall’uso di subordinate più sem-
plici,
non solo in termini di lunghezza totale ma
soprattutto strutturalmente:
in tutti i corpora,
in-
fatti, le “catene” subordinanti hanno una profondi-
tà media minore quando la subordinata precede la
principale.
4
Conclusione
Questo articolo ha proposto uno studio comparati-
vo su un particolare fenomeno relativo alla com-
plessità sintattica,
ovvero l’ordine dei
costituen-
ti
in italiano.
Il
confronto è stato condotto su
due livelli:
la variazione di
genere e il
grado di
complessità.
Per quanto riguarda il
primo,
è stato possibi-
le constatare che i
testi
giornalistici
sono quelli
che maggiormente si attengono all’ordine canoni-
co degli elementi, mentre i testi narrativi hanno ri-
portato una frequenza superiore di ordini marcati.
Dal
punto di
vista della complessità,
è chiara la
tendenza in entrambi
i
generi
a utilizzare l’ordi-
ne canonico come esito della semplificazione, sia
a seguito di un processo di semplificazione di un
testo originale,
sia quando il testo nativamente è
concepito come testo semplice.
Indipendentemente dal genere, il fenomeno che
è risultato più legato alla complessità riguarda l’u-
so delle subordinate.
In entrambi i generi preval-
gono nettamente subordinate posposte alla prin-
cipale in quanto più facili
da processare e quan-
do questa posizione non è rispettata si
registra
una tendenza alla semplificazione della subordina-
ta stessa sia in termine di numero di parole, ma so-
prattutto strutturalmente,
in termini di profondità
del sottoalbero sintattico.
CLIC_2016_Proceedings.indd 251
02/12/16 15.04
252
Va infine ricordato che tutte le osservazioni ri-
portate in questo studio sono basate su testi lingui-
sticamente annotati
in maniera automatica,
dun-
que soggetti
a errore.
Nonostante ciò,
ci
aspet-
tiamo che almeno limitatamente all’analisi di testi
dello stesso dominio e varietà di lingua,
le distri-
buzioni degli errori siano simili, permettendo dun-
que un confronto interno rispetto ai parametri lin-
guistici indagati.
L’affidabilità dei dati discussi è
inoltre corroborata dal fatto che sono stati conside-
rati testi standard, linguisticamente vicini a quelli
sui quali gli strumenti di annotazione automatica
sono tipicamente addestrati. D’altra parte, proprio
perché la distribuzione degli errori potrebbe varia-
re al variare del dominio dei testi, tra gli sviluppi
di questo lavoro intendiamo condurre delle anali-
si a campione per verificare l’impatto dell’errore
sui confronti ottenuti rispetto alle diverse strutture
esaminate.
References
Giuseppe Attardi, Felice Dell’Orletta, Maria Simi, Jo-
seph Turian.
2009.
Accurate dependency parsing
with a stacked multilayer perceptron.
In Procee-
dings of
EVALITA 2009 - Evaluation of
NLP and
Speech Tools for Italian 2009,
Reggio Emilia, Italia,
Dicembre 2009.
Elisabetta Bonvino,
Mara Frascarelli,
Paola Pietran-
drea.
2008.
Semantica, sintassi e prosodia di alcune
espressioni avverbiali nel parlato spontaneo.
La co-
municazione parlata,
Massimo Pettorino,
Antonel-
la Giannini,
Marianna Vallone,
Renata Savy (Eds),
Napoli, Liguori,
565–607.
Dominique Brunato, Felice Dell’Orletta, Giulia Ventu-
ri,
Simonetta Montemagni.
2015.
Design and an-
notation of the first italian corpus for text simplifica-
tion.
In Proceedings of LAW IX - The 9th Linguistic
Annotation Workshop.
Denver,
Colorado,
Giugno
2015.
Guglielmo Cinque.
2010.
The syntax of adjectives: A
comparative study.
In MIT Press.
Felice Dell’Orletta.
2009.
Ensemble system for part-
of-speech tagging.
In Proceedings of EVALITA 2009
- Evaluation of
NLP and Speech Tools for Italian
2009,
Reggio Emilia, Italia, Dicembre 2009.
Holger Diessel.
2005.
Competing motivations for the
ordering of main and adverbial clauses.
Linguistics,
43 (3): 449–470.
Giuliana Fiorentino.
2009.
Complessità linguistica e
variazione sintattica.
Studi
Italiani
di
Linguistica
Teorica e Applicata (SILTA), (2), 281-312.
Edward
Gibson.
1998.
Linguistic
complexity:
Locality of
syntactic
dependencies.
Cognition,
68:1–76.
Edward Gibson.
2000.
The dependency Locality
Theory: A distance–based theory of linguistic com-
plexity.
Image,
Language and Brain,
In W.O.A.
Marants and Y. Miyashita (Eds.),
Cambridge, MA:
MIT Press, 95–126.
Daniel
Gildea.
2001.
Corpus variation and parser
performance.
Proceedings of
Empirical
Methods
in Natural
Language Processing (EMNLP 2001),
Pittsburgh, PA.
Daniel Gildea, David Temperley.
2010.
Do Grammars
Minimize Dependency Length?
Cognitive Science,
34(2):286–310.
Kristina Gulordava,
Paola Merlo.
2015.
Diachronic
Trends in Word Order
Freedom and Dependency
Length in Dependency-Annotated Corpora of Latin
and Ancient Greek.
In Proceedings of the Third In-
ternational
Conference on Dependency Linguistics
(Depling 2015),
Uppsala,
Sweden,
August
24–26
2015, pp. 121–130.
John A. Hawkins
1994.
A performance theory of or-
der and constituency. Cambridge studies in Lingui-
stics.
Cambridge studies in Linguistics, Cambridge
University Press.,
Numero 73.
John.
H.
McWorther.
2001.
The
world’s
sim-
plest
grammars are creole grammars.
Linguistic
Typology, 5, 125-166.
Simonetta Montemagni.
2013.
Tecnologie linguistico-
computazionali
e monitoraggio della lingua italia-
na.
Studi Italiani di Linguistica Teorica e Applicata
(SILTA),
(1), 145-172.
Maria Emanuela Piemontese.
1996.
Capire e farsi
capire. Teorie e tecniche della scrittura controllata.
Napoli, Tecnodid.
Terence Consortium.
2012.
Story simplification: User
guide.
Restricted Distribution.
CLIC_2016_Proceedings.indd 252
02/12/16 15.04
253
Grounding the Lexical Sets of Causative-Inchoative Verbs with Word
Embedding
Edoardo Maria Ponti
University of Cambridge
ep490@cam.ac.uk
Elisabetta Jezek
Università degli Studi di Pavia
jezek@unipv.it
Bernardo Magnini
Fondazione Bruno Kessler
magnini@fbk.eu
Abstract
English.
Lexical
sets contain the words
filling the argument
positions of
a verb
in one of
its senses.
They can be ex-
tracted from corpora automatically.
The
purpose of this paper is demonstrating that
their vector representation based on word
embedding provides insights onto many
linguistic phenomena,
such as causative-
inchoative verbs.
A first experiment aims
at investigating the internal structure of the
sets,
which are known to be radial
and
continuous categories cognitively.
A sec-
ond experiment
shows that
the distance
between the intransitive subject
set
and
transitive object set is correlated with the
spontaneity of the event expressed by the
verb,
defined according to morphological
coding and frequency.
Italiano.
I
set
lessicali
contengono le
parole che occupano le posizioni
argo-
mentali
di
un verbo in una delle sue ac-
cezioni, e possono essere estratti in modo
automatico dai
corpora.
L’obiettivo di
questo articolo è dimostrare che la loro
rappresentazione vettoriale illumina al-
cuni
fenomeni
linguistici,
come i
verbi
ad alternanza causativo-incoativa.
Un
esperimento
investiga
la
struttura
in-
terna degli
insiemi,
che a livello cog-
nitivo sono ritenuti
categorie
radiali
e
continue.
Inoltre,
un secondo esperi-
mento mostra che la distanza fra l’insieme
dei
soggetti
intransitivi
e l’insieme degli
oggetti
transitivi
è correlata alla spon-
taneità dell’evento espresso dal
verbo,
definita secondo la marca morfologica e
la frequenza.
1
Introduction
Lexicographic attempts to cope with verb sense
disambiguation
often
rely
on
“lexical
sets”
(Hanks, 1996), which represent the lists of corpus-
derived words that appear as arguments for each
distinct verb sense.
The arguments are the “slots”
that have to be filled to satisfy the valency of a verb
(subject,
object,
etc.).
For example,
{gun,
bullet,
shot, projectile, rifle...} is the lexical set of the ob-
ject
for the sense ‘to shoot’ of to fire.
In previ-
ous works,
e.g.
Montemagni
et
al.
(1995),
lexi-
cal
sets were collected manually and were com-
pared through set analysis.
The measure of simi-
larity between two sets was proportional to the ex-
tent of their intersection.
We believe that possible
improvements may stem from deriving the lexical
sets automatically and from exploiting the seman-
tic information of the fillers fully.
In this work,
we devise an extraction method from a huge cor-
pus and use a distributional semantics approach to
perform our analyses. More specifically, we repre-
sent fillers as word vectors and compare them with
spatial distance measures.
In order to test the rel-
evance for linguistic theory of this approach,
we
focus on a case study,
namely the properties of
verbs undergoing the causative-inchoative alterna-
tion.
Section 1.1.
outlines a framework for word
embeddings and section 1.2 introduces the case
study. Section 2 presents the method and the data,
whereas section 3 reports the results of a couple of
experiments.
1.1
Word Embedding
The full exploitation of the semantic information
inherent to argument fillers for verbs can take ad-
vantage from some recent developments in distri-
butional semantics.
Recently, efficient algorithms
have been devised mapping each word of a vocab-
CLIC_2016_Proceedings.indd 253
02/12/16 15.04
254
ulary into a corresponding vector of n real num-
bers,
which can be thought as a sequence of co-
ordinates in a n-dimensional
space (Mikolov et
al.,
2013).
This mapping is yielded by unsuper-
vised machine learning,
based on the assumption
that the meaning of a word can be inferred by its
context, i.e. its neighbouring words in texts.
This
model has some relevant properties:
the geomet-
ric closeness of
two vectors corresponds to the
similarity in meaning of the corresponding words.
Moreover, its dimensions have possibly a semantic
interpretation.
1.2
Causative-Inchoative Alternation
A possible testbed for the usefulness of represent-
ing the argument
fillers as vectors are the verbs
showing the so called causative-inchoative alter-
nation.
These verbs appear either as transitive or
intransitive. In the first case, an agent brings about
a change of state;
in the second,
the change of a
patient is presented as spontaneous (e.g. to break,
as in “Mary broke the key” vs. “the key broke”).
The two alternative forms of these verbs can
be morphologically asymmetrical:
in this case,
one has a derivative affix and the other does not.
The first
is labelled here as “marked”,
the sec-
ond as “basic”. Italian verbs with an asymmetrical
alternation derive from the phenomenon of anti-
causativization.
The intransitive form is marked
since it
is sometimes preceded by the clitic si
(Cennamo and Jezek,
2011).
Haspelmath (1993)
maintain that
verbs that
show a preference for
a marked causative form (and a basic inchoative
form) cross-linguistically denote a more “sponta-
neous” situation.
Spontaneity is intended by the
author as the likelihood of the occurrence of the
event
without the intervention of an agent.
This
work is non-committal
with respect
to whether
spontaneity be an actual semantic factor.
Rather,
it
is considered a notion useful
for labelling the
observed variations in morphology and frequency.
In this
way,
a correlation between the form
and the
meaning of
these
verbs
was
demon-
strated.
Moreover,
Samardzic and Merlo (2012)
and Haspelmath et
al.
(2014)
argue that
verbs
that
appear
more frequently (intra-
and cross-
linguistically) in the inchoative form tend to mor-
phologically derive the causative form,
too.
This
time, the correlation holds between form and fre-
quency.
Vice versa,
situations entailing agentive
participation prefer to mark the inchoative form
and occur more frequently in the causative form.
2
Previous Work
In the literature,
many methods are available for
the automatic detection of verb classes,
such as
causative-inchoative verbs.
They exploit features
based on argument alternations,
such as subcate-
gorization frames (Joanis et al., 2008). The identi-
fication of verb classes displaying a diathesis alter-
nation was also performed through the analysis of
selectional preferences.
Most notably,
the lexical
items were compared via distributional semantics
(McCarthy, 2000).
These features were usually induced from au-
tomatic parses of heterogeneous and wide corpora
(Schulte Im Walde,
2000).
In particular,
the ex-
traction of subcategorization frames was refined
including e.g.
noise filters
based on frequency
(Korhonen et al.,
2000).
Our work is inspired by
these attempts to automatically induce lexical in-
formation regarding verbs, but its direction of re-
search is reversed.
Indeed,
rather than classify-
ing verb classes given this information, it analyses
this information given a verb class in order to shed
light on its properties from the perspective of lin-
guistic theory.
3
Data and Method
The data are sourced from a sample of ItWac,
a
wide Italian corpus gathered through web crawling
(Baroni et al., 2009).
This sample was further en-
riched with morpho-syntactic information through
the
MATE
-tools parser
(Bohnet,
2010)
1
and fil-
tered by sentence length (
<
100
).
Eventually,
sentences in the sample amounted to 2,029,454
items.
A target group of 20 causative-inchoative
verbs was taken from Haspelmath et
al.
(2014):
they are listed here based on the reported transi-
tive/intransitive frequency ratio,
from the highest
to the lowest.
close > open > improve > break > fill > gather > connect
> split > stop > go out > rise > rock > burn > freeze >
turn > dry > wake > melt > boil > sink
The
extraction step consisted in identifying
their argument
fillers inside the sentences in the
sample.
In particular,
the arguments considered
were the subjects of intransitives (S) and objects
1
LAS scores for the relevant dependency relations: 0.751
with dobj
(direct
object),
0.719 with nsubj
(subject),
0.691
with nsubjpass (subject of a passive verb).
CLIC_2016_Proceedings.indd 254
02/12/16 15.04
255
Figure 1: Distance of vectors from their centroid.
(O) (Dixon, 1994).
2
These arguments are relevant
because they are deemed to share the same fillers
(Pustejovsky, 1995).
These operations resulted in a database where
each verb lemma had a single entry and was as-
sociated with a list of fillers, divided by argument
type.
With this procedure,
lexical
sets were ex-
tracted automatically,
although they were not di-
vided by verb sense.
Afterwards,
each of the ar-
gument fillers was mapped to a vector relying on a
space model pre-trained through Word2Vec (Dinu
et al., 2015).
3
4
Experiments
In order to bring to light
the linguistic informa-
tion concealed in the automatically extracted lexi-
cal sets, we devised two experiments. One investi-
gates the internal structure of lexical sets.
In fact,
previous works based on set theory treated them as
categoric sets, of which a filler is either a member
or not. Research in psychology, however, has long
since demonstrated that the members of a linguis-
tic set are found in a radial continuum where the
most central one is the prototype for its category,
and those at the periphery are less representative
(Rosch, 1973; Lakoff, 1987).
4
Word vectors allow
to capture this spatial continuum.
2
Subjects of forms with si were treated as intransitive sub-
jects. Subjects of passive verbs were treated as objects.
3
It
was generated by a
CBOW
algorithm with negative
sampling,
300 dimensions,
a context window of 10 tokens,
pruning of infrequent words and sub-sampling.
4
For previous work on lexical sets considering prototyp-
icality in the context of the notion of shimmering, see Jezek
and Hanks (2010).
Once the fillers have been mapped to their re-
spective vectors,
a lexical set appears as a group
of points in a multi-dimensional model.
The cen-
tre of this group is the Euclidean mean among the
vectors, which is a vector itself and is called cen-
troid. In the first experiment, we calculated the co-
ordinates of the centroid of the lexical sets S and O
for any selected verb
5
.
Then we evaluated the co-
sine similarity of every vector member of the sets
from its centroid.
The value of this metric goes
from 0 (overlap) to 1 (maximum distance) and is
useful to evaluate how far a filler is from its pro-
totype.
We obtained two sets of cosine similarity
values for each verb: these can be plotted as boxes
and whiskers, like in Figure 1.
The example rep-
resents those of dividere ‘to split’.
The rectangles
stand for the values in the second and third quar-
tiles, whereas the horizontal line for the median
6
.
From all these distance values, we picked the me-
dian value for each lexical set.
The plot of these
medians for the S set and the O set of each verb or-
dered according to Haspelmath’s ranking is shown
in Figure 2.
Two main results can be observed from these
plots:
the S lexical
set
lies in a more compact
range of distances,
whereas O is more scattered.
On the other hand,
the vectors of S tend farther
from the centroid.
This is demonstrated by the
ranges where their distance values fall.
Moreover,
the averages of medians for the ten verbs on the
left part of the scale (frequently transitive) and for
the ten verbs on the right (frequently intransitive)
were compared.
The average median in S was
0.696567 for the former and 0.585263 for the lat-
ter.
The average median in O was 0.556878 for
the former and 0.522418 for the latter. This shows
that the variation in O appears to be random.
On
the other hand, the median of the distances in S is
normally lower for verbs that lie in the bottom half
of the Haspelmath’s scale.
The second experiment consisted in estimating
the cosine distance between the centroid of S and
the centroid of O for each verb. This operation was
aimed at finding to which extent the lexical sets of
S and O overlap. In fact, Montemagni et al. (1995)
and McCarthy (2000) assessed in a corpus some
asymmetries between these lexical sets,
which in
principle should share all their members.
5
Every filler was weighted proportionally to its absolute
frequency.
6
The median is the value separating the higher half of the
ordered values from the lower half.
CLIC_2016_Proceedings.indd 255
02/12/16 15.04
256
Figure 2: Medians of S (left) and O (right) distances for verbs ranked by position in Haspelmath’s scale.
Inspecting our results,
the distance between S
and O seems to behave as a measure of
spon-
taneity, intended as cross-linguistic frequency and
morphological markedness of a verb: the more the
centroids tend to be set apart,
the more the verb
tends to have a morphologically unmarked and
more frequent intransitive form.
In fact, we com-
pared the ranking of 20 alternating verbs accord-
ing to the ratio of their cross-linguistic frequency
of transitive and intransitive forms (Haspelmath et
al., 2014) and a ranking based on the centroid dis-
tances of the same verbs.
Both these rankings are
plotted in Figure 3:
every verb is associated with
its position in the two scales.
Figure
3:
Ranking
based
on
cross-linguistic
form frequencies (green triangles) against ranking
based on distance of the centroids of S and O in
Italian (blue squares).
Both scales display a common tendency. In par-
ticular a Spearman’s ranking test
was performed
over them, yielding a mild positive correlation of
ρ
= 0
.
56391
with a quite strong confidence,
i.e.
with
p <
0
.
01
.
7
5
Discussion
The
representation
of
lexical
sets
of
Italian
causative-inchoative verbs as vectors was demon-
strated to provide insights into their internal struc-
ture and their relation with spontaneity defined ac-
cording to morphological
coding and frequency.
The distances of the objects appeared to be dis-
tributed more uniformly,
whereas
those of
the
intransitive subjects more densely and remotely
from the centroid.
This difference cannot
stem
from the frequency of anaphoric fillers (contrary
to transitive subjects),
since both these argument
positions share the discursive function of introduc-
ing new referents, and are hence occupied by fully
referential fillers (Du Bois, 1985).
Moreover,
the medians of the distances of the
subject
fillers from their centroid were shown to
vary.
An interpretation is that
they are sensi-
ble to the frequency scale:
this implies that
fre-
quently transitive (hence, non-spontaneous) verbs
have semantically less homogeneous sets of ref-
erents,
since they are farther from the prototype.
Possibly this discovery can be related with the
fact that non-spontaneous verbs impose less selec-
tional restrictions on subjects (McKoon and Mac-
farland, 2000).
The lack of a perfect correlation between these
vector distance and frequency measures is maybe
due to errors in the automatic extraction and data
sparseness for the former, or an insufficient sample
7
An alternative measure was considered for the ranking:
the cardinality of the S-O intersection weighted by the set
union.
In this case, Spearman correlation was ρ = 0.42255,
but it was not significant because p ≈ 0.06.
CLIC_2016_Proceedings.indd 256
02/12/16 15.04
257
of languages in the typological survey of Haspel-
math et
al.
(2014) for the latter.
A possible in-
terpretation of the correlation is that
the entities
capable of bringing about
a change of state and
those that
undergo it
are indiscernible only for
non-spontaneous verbs.
Studies on causer entities
related them not only with the feature of agentiv-
ity, but also in general with the so-called ‘teleolog-
ical capability’ (Higginbotham, 1997).
6
Conclusion
Our work provided evidence that
lexical
sets of
Italian causative-inchoative verbs are continuous
and radial
categories,
whose distribution around
the prototype vary to a great
extent.
It
is sensi-
tive to the grammatical role and sometimes to the
position of the verb in the so-called spontaneity
scale.
Moreover, a correlation was discovered be-
tween the distance between transitive object
and
intransitive subject lexical sets of a given verb and
its cross-linguistic tendency to appear more fre-
quently as intransitive or as transitive.
Figure 4
is a synopsis of this result
in the context
of the
correlations established in previous works.
Frequently Intransitive
Spontaneous
Unmarked Intransitive
Distant S and O centres
?
ρ
=0.56
τ
=0.65
Figure 4:
Synopsis of
correlations among fea-
tures of causative-inchoative verbs.
The measures
are based on Kendall Tau test (
τ
) and Spearman’s
ranking test (
ρ
).
In Figure
4,
solid lines
stand for
correla-
tions proven based on cross-linguistic evidence
(frequency-form)
and evidence from the Italian
language (frequency-lexical sets). The dotted line,
on the other hand,
suggests the existence of and
underlying motivation for the correlations,
which
nonetheless remains unproven and undetermined
in its nature. Its possible validation is left to future
research.
Future works should also choose different pre-
trained vector models, in order to try and replicate
these results.
In particular, the new vector models
could be optimized for similarity through semantic
lexica (Faruqui et al., 2015) or based on syntactic
dependencies (Séaghdha, 2010).
The experiments
in this work may be extended to other languages,
either individually or through a multi-lingual word
embedding (Faruqui and Dyer, 2014).
References
Marco Baroni,
Silvia Bernardini,
Adriano Ferraresi,
and Eros
Zanchetta.
2009.
The wacky wide
web:
a collection of very large linguistically pro-
cessed web-crawled corpora.
Language resources
and evaluation, 43(3):209–226.
Bernd Bohnet.
2010.
Very high accuracy and fast de-
pendency parsing is not a contradiction.
In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 89–97. Association for
Computational Linguistics.
Michela Cennamo and Elisabetta Jezek.
2011.
The
anticausative alternation in italian.
I luoghi
della
traduzione, pages 809–823.
Georgiana Dinu,
Angeliki Lazaridou,
and Marco Ba-
roni.
2015.
Improving zero-shot learning by miti-
gating the hubness problem.
workshop contribution
at ICLR 2015.
Robert MW Dixon.
1994.
Ergativity.
Cambridge Uni-
versity Press.
John W Du Bois.
1985.
Competing motivations.
Iconicity in syntax, pages 343–365.
Manaal
Faruqui
and Chris Dyer.
2014.
Improving
vector space word representations using multilingual
correlation.
Manaal Faruqui,
Jesse Dodge,
Sujay K.
Jauhar,
Chris
Dyer,
Eduard Hovy,
and Noah A.
Smith.
2015.
Retrofitting word vectors to semantic lexicons.
In
Proceedings of NAACL.
Patrick Hanks.
1996.
Contextual dependency and lex-
ical sets.
International Journal of Corpus Linguis-
tics, 1(1):75–98.
Martin Haspelmath,
Andreea Calude,
Michael
Spag-
nol,
Heiko Narrog,
and Elif Bamyaci.
2014.
Cod-
ing causal–noncausal
verb alternations:
A form–
frequency correspondence explanation.
Journal of
Linguistics, 50(03):587–625.
Martin Haspelmath.
1993.
More on the typology of
inchoative/causative verb alternations.
Causatives
and transitivity, 23:87.
James Higginbotham.
1997.
Location and causation.
Ms., University of Oxford.
Elisabetta Jezek and Patrick Hanks.
2010.
What lex-
ical sets tell us about conceptual categories.
Lexis,
4(7):22.
Eric Joanis,
Suzanne Stevenson,
and David James.
2008.
A general
feature
space
for
automatic
verb classification.
Natural Language Engineering,
14(03):337–367.
Anna Korhonen,
Genevieve Gorrell,
and Diana Mc-
Carthy.
2000.
Statistical
filtering and subcatego-
rization frame acquisition.
In Proceedings of
the
2000 Joint SIGDAT conference on Empirical meth-
ods in natural language processing and very large
corpora, pages 199–206. Association for Computa-
tional Linguistics.
George Lakoff.
1987.
Women,
fire,
and danger-
ous things: What categories reveal about the mind.
Cambridge University Press.
Diana McCarthy.
2000.
Using semantic preferences to
identify verbal participation in role switching alter-
nations.
In Proceedings of the 1st North American
chapter of
the Association for Computational
Lin-
guistics conference, pages 256–263.
Gail McKoon and Talke Macfarland.
2000.
Externally
and internally caused change of state verbs.
Lan-
guage, pages 833–858.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean.
2013.
Efficient estimation of word represen-
tations in vector space.
In Workshop at ICLR.
Simonetta Montemagni,
Nilda Ruimy,
and Vito Pir-
relli.
1995.
Ringing things which nobody can ring.
a corpus-based study of the causative-inchoative al-
ternation in italian.
Textus online only. 8 (1995), N.
2, 1995, 8(2):1000–1020.
James Pustejovsky.
1995.
The generative lexicon.
The
MIT Press.
Eleanor H Rosch.
1973.
Natural categories.
Cognitive
psychology, 4(3):328–350.
Tanja Samardzic and Paola Merlo.
2012.
The mean-
ing of lexical causatives in cross-linguistic variation.
Linguistic Issues in Language Technology, 7(12):1–
14.
Sabine Schulte Im Walde.
2000.
Clustering verbs se-
mantically according to their alternation behaviour.
In Proceedings of the 18th conference on Computa-
tional linguistics-Volume 2, pages 747–753.
Diarmuid O Séaghdha.
2010.
Latent
variable mod-
els of selectional preference.
In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 435–444.
CLIC_2016_Proceedings.indd 257
02/12/16 15.04
258
Panta rei: Tracking Semantic Change with Distributional Semantics in 
Ancient Greek 
Martina A. Rodda 
Scuola Normale Superiore 
Piazza dei Cavalieri, 7 
56126 Pisa – ITALY 
martina.rodda@sns.it 
Marco S.G. Senaldi 
Scuola Normale Superiore 
Piazza dei Cavalieri, 7 
56126 Pisa – ITALY 
marco.senaldi@sns.it 
Alessandro Lenci 
CoLing Lab 
Università di Pisa 
via S. Maria 36 
alessandro.lenci@unipi.it 
Abstract 
English.
We present a method to explore 
semantic change as a function of varia-
tion in distributional semantic spaces. In 
this paper we apply this approach to au-
tomatically identify the areas of semantic 
change in the lexicon of Ancient Greek 
between the pre-Christian and Christian 
era. Distributional Semantic Models are 
used to identify meaningful clusters and 
patterns of semantic shift within a set of 
target words, defined through a purely 
data-driven approach. The results empha-
size the role played by the diffusion of 
Christianity and by technical languages 
in determining semantic change in An-
cient Greek and show the potentialities of 
distributional 
models 
in 
diachronic 
se-
mantics. 
Italiano.
Si presenta un metodo per in-
dagare il cambiamento semantico come 
funzione della variazione all’interno di 
spazi semantici. Questo approccio è ap-
plicato per identificare automaticamente 
aree di cambiamento semantico nel lessi-
co greco antico tra età pre-cristiana e 
cristiana. 
Modelli 
della Semantica 
Di-
stribuzionale sono usati per identificare 
cluster e pattern di cambiamento seman-
tico in una lista di parole target, definita 
con un approccio puramente data-driven. 
I risultati mostrano il ruolo della diffu-
sione del Cristianesimo e dei linguaggi 
tecnici nel determinare cambiamenti se-
mantici in greco antico, nonché le poten-
zialità dei modelli distribuzionali nella 
semantica diacronica.
1
Introduction and Related Work 
Distributional Semantics is grounded on the as-
sumption that the meaning of a word can be de-
scribed as a function of its collocates in a corpus. 
This suggests that diachronic meaning shifts can 
be traced through changes in the distribution of 
these collocates over time (Sagi et al., 2011). 
While some studies focused on testing the ex-
planatory power of this method over frequency- 
and syntax-based approaches (Wijaya and Ye-
niterzi, 2011; Kulkarni et al., 2015), more ad-
vanced contributions to the field explored how 
distributional models can be used to test compet-
ing hypotheses about semantic change (Xu and 
Kemp, 2015), or to investigate the productivity 
of constructions in diachrony (Perek, 2016). The 
results attest the explanatory power of distribu-
tional methods in modeling diachronic shifts in 
meaning. 
In this paper, we propose a method to identify 
semantic change through the 
Representational 
Similarity 
Analysis
(RSA; 
Kriegeskorte 
and 
Kievit, 2013) of distributional vector spaces built 
from diachronic corpora. RSA is a method exten-
sively used in neuroscience to test cognitive and 
computational models by comparing the geome-
try 
of 
their 
representation 
spaces 
(Edelman, 
1998). Stimuli are represented with a representa-
tional dissimilarity matrix that contains a meas-
ure of the dissimilarity relations of the stimuli 
with each other. Different matrices are compared 
to evaluate the correspondence of the representa-
tional spaces built from different sources (e.g., 
behavioral and 
neuroimaging 
data). We argue 
that this method can be applied to compare dis-
tributional representations of the lexicon at dif-
ferent temporal stages. The hypothesis is that the 
elements in the lexical spaces showing larger ge-
ometrical variations in time correspond to the 
lexical areas that have undergone major semantic 
CLIC_2016_Proceedings.indd 258
02/12/16 15.04
259
changes. To the best of our knowledge, this is the 
first time RSA is used in diachronic distribution-
al semantics. 
Here we present a case study that applies RSA 
to track patterns of semantic change within the 
lexicon of Ancient Greek. We focus on the first 
few centuries AD, when the rise of Christianity 
caused a deep and widespread cultural shift with-
in the Hellenic world. We predict that this shift 
will be reflected in the Greek lexicon of the time. 
In 
addition 
to 
past 
studies 
(Boschetti, 
2009; 
O’Donnell, 2005 is a general introduction), we 
apply a bottom-up approach to the detection of 
semantic change, with no prior definition of a list 
of lemmas to be analyzed. The goal is to develop 
a quantitative “discovery procedure” to detect 
lexical semantic changes. 
From a methodological standpoint, this study 
aims to show how Distributional Semantics can 
be applied fruitfully to such a small and literary 
corpus as the collection of Ancient Greek texts. 
The results will also highlight the ways in which 
Distributional Semantics can complement the in-
tuition of the researcher in analyzing semantic 
change in Ancient Greek, providing a useful tool 
for future studies in Classics. 
2
Materials and Methods 
The corpus used for this study is based on the 
TLG-E (
Thesaurus Linguae Graecae
) collection 
of Ancient Greek literary texts. The database was 
divided into two sub-corpora, the first of which 
contains texts from the 7
th
to the 1
st
century BC 
(pre-Christian era), while the second one spans 
from the 1
st
to the 5
th
century AD (early Christian 
era). 
The 
pre-Christian 
sub-corpus 
contains 
6,795,253 tokens, while the Christian sub-corpus 
totalizes 29,051,269 tokens. 
The texts were lemmatized using 
Morpheus
(Crane, 1991). Any issues with the lemmatization 
should not have a significant impact on the re-
sults unless otherwise stated (cf. Boschetti, 2009, 
page 60 for a discussion). After filtering for stop-
words (mainly particles, pronouns and connec-
tives) and lemmas occurring with a frequency 
below 100 tokens, the pre-Christian and Chris-
tian sub-corpus contain, respectively, 4,109 and 
10,052 lemmas, which were used both as targets 
and dimensions in our vector spaces. 
A vector space model was then built for each 
sub-corpus using the DISSECT toolkit (Dinu et 
al., 
2013). 
Henceforth, 
we 
refer 
to 
the 
pre-
Christian era model as the 
BC-Space
, and to the 
Cristian 
era 
model 
as 
the 
AD-Space
. 
Co-
occurrences were computed within a window of 
11 words (5 content words to the right and to the 
left of each target word). Association scores were 
weighted using positive point-wise mutual in-
formation (PPMI) (Evert, 2008); the resulting 
matrices were reduced to 300 latent dimensions 
using Singular Value Decomposition (SVD). 
2.1
RSA of the distributional vector spaces 
We have adapted the RSA method to discover 
semantic changes between the two vector spaces: 
1. we identified the words occurring in both sub-
corpora with a frequency higher than 100 tokens, 
obtaining 3,977 lemmas; 
2. we built a repr
esentational similarity matrix 
(RSM) from the BC-Space (RSM
BC
) and one 
from the AD-Space (RSM
AD
). Each RSM is a 
square matrix indexed horizontally and vertically 
by the 3,977 lemmas and containing in each cell 
the cosine similarity of a lemma with the other 
lemmas in a vector space (this is a minor varia-
tion with respect to the original RSA method, 
which 
instead 
uses 
dissimilarity 
matrices). 
A 
RSM is a global representation of the semantic 
space geometry in a given period: vectors repre-
sent lemmas in terms 
of their position relative to 
the other lemmas in the semantic space; 
3. for each lemma, we computed the Pearson cor-
relation coefficient between its vector in RSM
BC
and the corresponding vector in RSM
AD
. 
The Pearson coefficient measures the degree of 
semantic shift across the two temporal slices. 
The 
lower 
the 
correlation, 
the 
more 
a 
word 
changed its meaning. 
3
Discussion of Results 
The following section focuses on the words that 
underwent the 
biggest 
changes, 
i.e. 
those 
for 
which the correlation scores are lower. The pri-
mary 
goal will be to 
establish 
whether 
these 
words can be clustered into meaningful groups. 
This would allow us to pinpoint the areas within 
the lexicon of Ancient Greek that have under-
gone a significant semantic shift during the early 
centuries of Christianity. 
3.1
Qualitative Analysis 
The 50 lemmas with the lowest correlation coef-
ficients were scrutinized in order to establish 
whether meaningful subgroups emerge. (This list 
of words is not reproduced here due to space 
constraints. They are a subset of the 200 words 
used to build the plot in section 4.3.) The find-
ings in this section, while inevitably limited by 
CLIC_2016_Proceedings.indd 259
02/12/16 15.04
260
the intuition of the researcher, will provide the 
starting point for a more sophisticated analysis to 
be performed in the following sections. 
The 
lemmas 
under 
consideration 
form 
a 
somewhat 
heterogeneous 
collection, 
including 
concrete 
nouns 
and 
relatively 
common 
verbs 
such as ζυγόν (zygón “yoke”) and ἕπομαι (hé-
pomai “follow”), as well as some proper nouns. 
This 
notwithstanding, 
a 
promising 
subset 
of 
words emerges even at this preliminary stage. 
These are a number of nouns designating emi-
nently 
Christian 
concepts, 
such 
as 
παραβολή 
(parabolé “parable”, previously “comparison”), 
λαός (laós, used for the Christian community as 
opposed to non-Christians, previously “people”), 
κτίσις (ktísis “creation”, previously “founding, 
settling”). 
These findings are in line with the idea that the 
diffusion of Christianity played a substantial role 
in semantic change in the first centuries AD (cf. 
Boschetti, 2009). Other Christian terms, such as 
θεός (theós “God”), ἄγγελος (ángelos “angel”, 
previously “messenger”), πατήρ (patér “father”), 
υἱός (hyiós “son”), also occur among the 100 
words with the lowest correlation coefficients. 
Another group of lemmas comprises technical 
terms whose usage seems to have undergone a 
specialization or 
a 
shift from one 
domain of 
knowledge to another. These include words such 
as ὑπόστασις (hypóstasis “substance”, previously 
“sediment, 
foundation”), 
δύναμις 
(dýnamis 
“property (of beings)”, previously “power”), or 
ῥητός (rhetós “literal” as opposed to “allegori-
cal”, previously “stated”). 
3.2
Analysis of Nearest Neighbors 
To corroborate the intuitions detailed above, the 
10 
nearest neighbors for each 
of 
the 
last 50 
words according 
to the 
correlation coefficient 
were retrieved using DISSECT. The process was 
repeated 
for 
each 
sub-corpus 
and 
the 
results 
compared in order to look for visible shifts, es-
pecially those involving different semantic do-
mains. A few examples of the results should suf-
fice to confirm the findings in the last section. 
For instance, among the nearest neighbors for 
πνεῦμα (pnêuma “spirit”, previously “breath”) in 
the AD-Space we find such words as θεάομαι 
(theáomai 
“contemplate”), 
ἀληθινός 
(alethinós 
“true”), κτίσις, υἱός, θεός and so forth, while in 
the 
BC-Space the 
strongest similarity 
is 
with 
terms pertaining to the domain of physics, such 
as 
ἀήρ 
(aér 
“air”), 
ὑγρός 
(hygrós 
“moist”), 
θερμός (thermós “hot”). Another clear-cut exam-
ple is that of δύναμις, whose neighbors change 
from military terms such as πολιορκία (poliorkía 
“siege”) 
and 
στρατόπεδον 
(stratópedon 
“en-
campment, army”) to the physical and philosoph-
ical domain, with the closest term being ἐνέργεια 
(enérgeia 
“activity, 
actuality”, 
an 
antonym 
of 
δύναμις in its philosophical sense of “potentiali-
ty”). The case of δύναμις also shows how nearest 
neighbor analysis can reveal shifts in the usage 
of heavily polysemous words. 
Not all changes observed through the analysis 
of nearest neighbors, however, are so easily pre-
dictable. Thus, for instance, the neighbors for 
μοῖρα (môira, another highly polysemous word 
with meanings spanning from “part” to “desti-
ny”) in the AD-Space come exclusively from the 
domain of astronomy, showing a strong speciali-
zation towards a technical usage (“degree” or 
“division” 
of the Zodiac). Another remarkable 
result 
comes 
from 
a 
geographical 
adjective, 
Ποντικός 
(Pontikós 
“coming 
from 
Pontus”), 
whose nearest neighbors shift from proper names 
and philosophical terms in the pre-
Christian age 
(an association due, without doubt, to the usage 
of “Ponticus” as an epithet for authors, e.g. Her-
aclides) to names of currency and trade wares, 
probably as a reflection of the integration of Pon-
tus as a Roman province (with the obvious reper-
cussions on trade) in the 1
st
century AD. 
3.3
t-SNE Plot 
As a final analysis, we embedded the RSM
AD
vectors for the 200 words with the lowest corre-
lation coefficient with the corresponding RSM
BC
vectors in a two-dimensional space with t-SNE 
(Figure 1), a technique for dimensionality reduc-
tion and data visualization that overcomes some 
of the limitations of standard multidimensional 
scaling (van der Maaten and Hinton, 2008). This 
procedure allows for easy identification of clus-
ters, thus revealing the semantic relation between 
the most recent meanings of the words that un-
derwent the greatest semantic change. 
A number of small clusters can be observed in 
the plot. Near the left periphery, the most rele-
vant group is composed of terms pertaining to 
Christian theology (from κύριος kýrios “Lord”, 
λαός and θεός, to παρουσία parousía “Advent” 
and ποιμήν poimén “shepherd”). The position of 
ψῦχος (psŷkhos “cold”) nearby is due to the mis-
lemmatization of some inflected forms of ψυχή 
(psyché “soul”) under this lemma, as revealed by 
nearest 
neighbor 
analysis. 
To 
the 
left 
of 
this 
group, 
a 
small 
cluster 
of 
terms 
pertaining 
to 
Christian exegesis (ῥητός, παραβολή, διασαφέω 
diasaphéo 
“illustrate”) 
can 
be 
recognized.
CLIC_2016_Proceedings.indd 260
02/12/16 15.04
261
The upper portion of the plot houses technical 
terms from the domains of medicine (the upper-
most groups), astronomy and geometry, while 
philosophical terminology is found in the outer 
right area. Some smaller groups are also noticea-
ble, 
such 
as 
μνᾶ 
(mnâ 
“mina”) 
and 
δραχμή 
(drakhmé “drachma”), both units of currency, on 
the left, and πρώτιστος (prótistos “the very first”) 
and Τίμαιος (the proper name Tímaios, Latin 
Timaeus), both connected to (Neo-)Platonic phi-
losophy, on the right. 
All in all, despite a certain amount of noise, 
the plot in Figure 1 supports the findings detailed 
so far. We can see how the main semantic chang-
es in the Greek lexicon between the pre-Christian 
and Christian era affected the domains of religion 
(in a broader sense) and/or technical language. 
Within these domains, some more fine-grained 
relations between words that underwent signifi-
cant semantic shifts can be observed. 
4
Conclusion 
This paper shows how Distributional Semantics 
can be used as an exploratory tool to detect se-
mantic change. In this case study on Ancient 
Greek, the proposed method based on distribu-
tional RSA not only confirms the hypothesis that 
the diffusion of Christianity was a crucial cause 
of semantic change in the Greek lexicon, but also 
allows for the identification of unexpected pat-
terns of evolution, such as the apparent speciali-
zation in the usage of technical terms. This last 
phenomenon could also be influenced by the fact 
Figure 1. Relative positions within the AD-Space of the 200 words with the lowest correlation scores. 
Dimensionality reduction was performed using t-SNE (van der Maaten and Hinton, 2008). 
CLIC_2016_Proceedings.indd 261
02/12/16 15.05
262
that the AD-corpus is richer in philosophical and 
technical 
treatises; 
however, 
a 
documented 
change in the proportion of different possible us-
ages of a word is in itself a very informative re-
sult, especially in a field such as Classics, where 
the analysis of (literary) texts is paramount. Fur-
ther research should undoubtedly highlight the 
effect of corpus composition. A focus on shorter 
periods of time might be of interest, since, for 
instance, the rise of technical prose writing is a 
characteristic 
of 
the 
Hellenistic 
Age 
(cf. 
e.g. 
Gutzwiller 2007, pages 154-167). 
From a 
methodological standpoint, the fact 
that the results obtained from such a small corpus 
of purely literary texts are both meaningful and 
informative is of great relevance. Furthermore, 
the 
choice 
to 
adopt 
a 
data-driven 
approach 
proved fruitful, in that it brought to light direc-
tions of change that were not expected 
a priori
. 
For traditional research in Classics, a computa-
tional approach to the lexicon of Ancient Greek 
is 
compelling 
because 
it 
provides 
new 
infor-
mation about a language for which the judgments 
of native speakers are unavailable (cf. Perek, 
2016). The results of this study show how Distri-
butional Semantics can complement the asser-
tions of the philologist, as well as help discover 
patterns of lexical change that would otherwise 
be impossible to grasp beyond an intuitive level. 
References 
Boschetti, Federico. 2009. A Corpus-based Approach 
to Philological Issues. PhD Thesis, University of 
Trento, Trento. 
Crane, Gregory. 1991. Generating and parsing Classi-
cal 
Greek. 
Literary 
and 
Linguistic 
Computing
, 
6(4):243–245. 
Dinu, Georgiana, Nghia The Pham and Marco Baroni. 
2013. DISSECT – DIStributional SEmantics Com-
position Toolkit. In 
Proceedings of the 51st Annual 
Meeting of the Association for Computational Lin-
guistics: System Demonstrations
, pages 31–36, So-
fia. 
Edelman, Shimon. 1998. Representation is representa-
tion of similarities. 
Behavioral and Brain Sciences
, 
21:449–467. 
Evert, Stefan. 2008. Corpora and collocations. In An-
ke Lüdeling and Merja Kytö, editors, 
Corpus Lin-
guistics. An International Handbook
, pages 1212–
1248, Berlin. 
Gutzwiller, Kathryn J. 2007. 
A guide to Hellenistic 
literature
(Blackwell guides to Classical literature). 
Blackwell Publishing, Oxford. 
Kriegeskorte, Nikolaus and Roger A. Kievit. 2013. 
Representational geometry: integrating cognition, 
computation, and the brain. 
Trends in Cognitive 
Sciences
, 17(8):401–412. 
Kulkarni, Vivek, Rami Al-Rfou, Bryan Perozzi and 
Steven Skiena. 2015. Statistically significant detec-
tion of linguistic change. In 
Proceedings of the 
24th International Conference on World Wide Web
(WWW ‘15), pages 625–635, Firenze. 
Van der Maaten, Laurens and Geoffrey Hinton. 2008. 
Visualizing data using t-SNE. 
Journal of Machine 
Learning Research
, 9:2579–2605. 
O’Donnell, Matthew Brook. 2005. 
Corpus Linguistics 
and the Greek of the New Testament
(New Testa-
ment 
Monographs, 
6). 
Sheffield 
Phoenix 
Press, 
Sheffield. 
Perek, Florent. 2016. Using distributional semantics 
to study syntactic productivity in diachrony: A case 
study. 
Linguistics
, 54(1):149–188. 
Sagi, Eyal, Stefan Kaufmann and Brady Clark. 2011. 
Tracing 
semantic 
change 
with 
Latent 
Semantic 
Analysis. In Kathryin Allan and Justyna A. Robin-
son, editors, 
Current Methods in Historical Seman-
tics
, pages 161–183, Boston, MA. 
Wijaya, Derry Tanti and Reyyan Yeniterzi. 2011. Un-
derstanding semantic change of words over centu-
ries. 
In 
Proceedings 
of 
the 
2011 
International 
Workshop on DETecting and Exploiting Cultural 
diversiTy on the Social Web
(DETECT ‘11), pages 
35–40, Glasgow. 
Xu, Yang and Charles Kemp. 2015. A computational 
evaluation of two laws of semantic change. In 
Pro-
ceedings of the 37th Annual Meeting of the Cogni-
tive Science Society
(CogSci 2015), Pasadena, CA. 
CLIC_2016_Proceedings.indd 262
02/12/16 15.05
263
Sardinian on Facebook: Analysing Diatopic Varieties through Translated
Lexical Lists
Irene Russo
ILC CNR
Pisa
irene.russo@ilc.cnr.it
Simone Pisano
Universit
`
a Guglielmo Marconi
Roma
s.pisano@unimarconi.it
Claudia Soria
ILC CNR
Pisa
claudia.soria@ilc.cnr.it
Abstract
English.
Presence of regional and minor-
ity languages over digital media is an in-
dicator of their vitality.
In this paper,
we
want to investigate quantitative aspects of
the use on Facebook of the Sardinian lan-
guage.
In particular,
we want
to focus
on the co-existence of diatopic varieties.
We extracted linguistic data from public
pages and,
through the translation of the
most frequent words, we find out similari-
ties and differences between varieties.
Italiano. La presenza e l’ uso delle lingue
regionali e minoritarie sui mezzi digitali
`
e
un indicatore della loro vitalit
`
a.
In questo
lavoro vogliamo concentrarci sugli aspetti
quantitativi del sardo usato su Facebook.
In particolare, vogliamo analizzare le va-
riet
`
a diatopiche estraendo i
dati
linguis-
tici
dalle pagine pubbliche.
Mediante la
traduzione delle parole pi
`
u frequenti
ab-
biamo trovato similarit
`
a e differenze tra le
variet
`
a.
1
Introduction
Everyday life makes an increasingly extensive use
of digital
devices that
involve language use;
for
this reason, usability of a language over digital de-
vices is a sign for that
language of being mod-
ern,
relevant
to current
lifestyles and capable of
facing the needs of the XXI century.
A positive
correlation between presence in new technologies
and better appreciation of a language has been re-
peatedly observed in the literature, see for instance
(Eisenlohr,
2004) and (Crystal,
2010).
Regional
and minority languages (RMLs henceforth)
are
usually very poorly represented digitally (Soria,
2016).
Since poor digital
representation of regional
and
minority languages further prevents their usability
on digital media and devices,
it is extremely im-
portant to enhance every bottom-up effort that can
boost the quantity of available digital content.
In
fact, if the perception of the marginal role and lim-
ited applicability of RMLs persists,
their attrac-
tiveness diminishes.
An increase in quantity of digital
content
avail-
able online represents today an opportunity for re-
gional
and minority languages.
Online speakers
can make visible the existence of a community that
uses the language to interact; they can use online
communication to converge toward a standard and
they can instruct less skilled speakers toward bet-
ter mastering of the rules of the language,
espe-
cially when the language is not formally included
in education.
From the perspective of computa-
tional
linguistics,
the presence of digital
content
written in RMLs means that corpora can be built
for them and basic tools (lemmatizers, spell check-
ers, lexicons etc.) can be developed.
The presence of RMLs over digital media and their
usability through digital devices is often limited to
instances of digital
activism and/or by means of
cultural initiatives focused on the preservation of
cultural heritage.
In this paper we promote the first
study we are
aware of about the use on social networks (more
specifically,
Facebook)
of
Sardinian,
an Italian
minority language characterised by the coexist-
ence of varieties and the difficulties for the pro-
moted standard to emerge as unifying factor.
Our
starting hypothesis concerned the vitality on so-
cial networks of a language that is mainly spoken.
With the help of a Sardinian linguist,
we identi-
CLIC_2016_Proceedings.indd 263
02/12/16 15.05
264
fied a small set of FB public groups where specific
varieties of Sardinian are chosen as their main lan-
guage plus groups where generic,
not further de-
fined Sardinian is used to communicate.
We ex-
tracted messages from these pages and created a
frequency lexicon for each variety.
The most fre-
quent
150 words have been translated by a Sar-
dophone expert
linguist
with the aim of finding
differences and commonalities between varieties.
This preliminary analysis is the first
step toward
the use of
computational
linguistics methodolo-
gies in the promotion of a standard for Sardinian
based on quantitative data.
2
Sardinian today: Main Varieties and
Standardization Efforts
Sardinian is an autonomous Romance language
spoken in the island of Sardinia.
According to
(Lupinu,
2007)
it
is
known by approximately
68,4% of
the population of
the island.
Ethno-
logue
1
lists four varieties for Sardinian:
North-
western Sardinian or Sassarese (100,000 speakers
ca.), Campidanese (500,000 speakers ca.), Central
Sardinian or Logudorese (500,000 speakers ca.)
and Gallurese (100.000 speakers ca.)
The most
important
differences from a lexical,
phonological
and morphological
point
of
view
within Sardinian can be found between Central-
Southern and Central-Northern dialects.
Scholars use to divide Sardinian in two main vari-
eties:
Logudorese and Campidanese, the first one
spoken in the North and in the center of the island
and the second one spoken in the South.
Logudorese and Campidanese can be related to
two different
pre-existing written standards:
the
so-called Logudorese (or Logudorese illustre) was
used for the first time in a short poem at the end of
the XV century (Manca,
2002),
whereas what is
known as Campidanese was the language of some
religious plays at the end of the XVII Century (De
Martini Abdullah Luca, 2006).
Today, Sardinian lacks of a generally agreed stan-
dard variety, although standardization efforts char-
acterised the recent history of the Region.
The first
attempt
to introduce a written system
based on an integration of phonetic,
lexical
and
morphological features of modern Sardinian vari-
eties was made in 2001,
when the basic rules of
LSU (Limba Sarda Unificada,Unified Sardinian
Language) were presented (Blasco Ferrer,
2001).
1
www.ethnologue.com
This proposal was sharply criticised by some sec-
tors of the public opinion and strong disapproval
came even from a part
of native speakers,
espe-
cially from the South,
who considered this stan-
dard too much different
from the language they
spoke.
It
is a fact
that
it
never became a model
of official Sardinian.
In 2006,
another model
of written language was
made official by the Regional Committee resolu-
tion n
◦
16/14.
This standard,
called LSC (Limba
Sarda Comuna,
Common Sardinian Language)
2
made the effort of taking into account also the dia-
lects of the transition region of the center men-
tioned earlier.
Although regional
administration
recommended its use for written public documents
it
is still
reluctantly accepted by some speakers,
who perceive it
as too distant
from the varieties
they speak.
In 2010,
the Provincial
Council
of Cagliari
took
a different
course choosing with the Provincial
Committee
resolution n
◦
17 a
linguistic
norm
3
based on literary language of Southern poets and
writers,
in order to draw up acts,
documents and
even textbooks for primary children.
All
these
standardization
efforts,
politically
guided or emerged bottom-up,
clearly show that
Sardinian speakers are aware of the role of stan-
dard orthography and grammar for the vitality and
the survival of their language.
On the one hand,
they want
to promote the idea of a unique lan-
guage as a matter of identity;
on the other,
they
dont
want
to lose local
peculiarities by adopting
standard rules that inevitably hide some local dif-
ferences.
Social media are widely used by Sardinian speak-
ers and they represent an interesting scenario for
written but informal use of the language.
An in-
depth analysis of
the type of
language used by
Sardinian speakers on social
media is still
miss-
ing.
Certainly,
use of everyday Sardinian in spo-
ken and written (online) informal communication,
is a sign of vitality of the language.
Interaction
is a powerful instrument for standardization,
and
the interactive modality offered by social
media
could reveal the emergence of coordination strate-
2
Regione Autonoma della Sardegna (2006), Limba Sarda
Comuna.
Norme linguistiche di riferimento a carattere sper-
imentale per la lingua scritta dellAmministrazione regionale,
Cagliari, Regione Autonoma della Sardegna.
3
Arr
`
egulas po sortografia, sa fon
`
etica, sa morfologia e su
fuedd
`
ariu de sa bariedadi
Campidanesa de sa l
`
ıngua sarda
(Rules for orthography, phonetic, morphology and the vocab-
ulary of Campidanese variety of Sardinian language)
CLIC_2016_Proceedings.indd 264
02/12/16 15.05
265
gies toward a standard in speakers community as
a natural
need (Burghardt,
2016).
To check this
hypothesis,
we started to analyse the use of dif-
ferent varieties of Sardinian that is being made on
Facebook.
According to the preliminary data of a
recent survey, Facebook is the social media that is
most used by Sardinian speakers, and where Sar-
dinian is actively and extensively used
4
.
3
Data Extraction and Analysis
We selected public pages
and communities
on
Facebook that are rich in content and interactions
between users.
With the help of a Sardinian lin-
guist we identified four mutually exclusive sets:
•
pages where people communicate in LSC;
•
pages
where people communicate in Sar-
dinian without
further
specification of
the
chosen variety;
•
pages where people communicate in Campi-
danese;
•
pages where people communicate choosing a
local variety (in our case Nugoresu, local va-
riety of Logudorese).
All
the messages have been extracted from the
json of the pages obtained through Facebook API.
Lowercase texts have been tokenized splitting on
whitespaces.
Four frequency lists have been cre-
ated,
emoticons and symbols have been deleted.
The 150 most
frequent
words have been trans-
lated in Italian by a Sardinian linguist
that
pro-
vided also PoS and morphological annotation plus
all the available translations in case of polysemous
words. We left in these lists Italian words because
every cleaning procedure (lists of Italian words,
PoS for
Italian etc.)
was risky:
very frequent
words in Sardinian can be found in Italian too (e.g.
a, chi, bonus, cosa) with a different meaning.
Table 1 reports basic statistics about public pages
and communities in the four sets listed above. Act-
ive users are the ones who wrote at least one mes-
sage on the page. Number of active users and mes-
sages varies for each set but it was not possible to
get a balanced sample.
In Table 2 the number
of
tokens and types for
4
Preliminary data of
the DLDP Survey (www.dldp.eu)
”Su Sardu: una limba digitale?”.
In July 2016, Facebook ap-
pears to be used by 98,1% of the respondents. Of those, 44%
use Sardinian for writing and reading posts and messages,
and 32,5% only for reading.
the four sets of Facebook groups analysed are re-
ported. In Table 3 each possible pair of varieties is
compared by checking the overlapping of trans-
lations into Italian.
The second column reports
how many Italian types are in common between
two varieties.
For example,
among the most fre-
quent 150 LSC word forms and the 150 most fre-
quent Sardu word forms, 61 words have the same
Italian translation.
The third column contains the
number of words with the same word forms in the
two varieties compared,
e.g.
the Italian adjective
grande has the same word form (mannu) in Nu-
goresu and Campidanese. This is a first attempt to
understand if two varieties are close orthograph-
ically,
considering the orthographic forms of the
analysed words. We also report the number of con-
tent words found in each pair because we believe
that in the future the overlapping at orthographic
level
should be analysed taking into account
the
distinction between content and function words.
The fourth column contains the number
of
the
word forms related to the types in common which
are different in the two varieties e.g.
for the Ital-
ian word
`
e,
third singular person of verb to be in
the present form, LSC has just one word est, while
Campidanese has est and esti.
In this case esti is
counted as a different form and is included in the
table under the fourth column.
Table 4 summarises for each pair how variability
patterns are distributed, where pattern 1 to 2 means
that there is one word form for variety a that cor-
respond to two word forms for variety b. We know
that the group Sardu contains data from more than
one variety and we plan as future work a more de-
tailed analysis.
For the moment we note a clear
overlapping because speakers of LSC contribute
with posts and comments on pages where people
communicate in Sardinian.
For the same reason,
when Sardu is one of the item in the pair we no-
tice more variability patterns (see Table 4).
Concerning the comparisons between LSC and the
two main varieties Campidanese and Logudorese,
represented in our data by the local
variety Nu-
goresu,
we found evidence of
the distance be-
tween the two main varieties with an overlapping
of 41,5% in terms of word forms.
LSC and Cam-
pidanese have an overlapping of 64,2% while LSC
and Nugoresu have an overlapping of 83%.
LSC
emerges as a variety that
tried to set
a linguistic
common ground and achieved this result,
even if
there is a bias toward Logudorese variety,
one of
CLIC_2016_Proceedings.indd 265
02/12/16 15.05
266
page name
type
#users
#active users
#messages
#variety
LSC, Limba Sarda Comuna: Sotziedade pro sa limba sarda comuna
Community
590
27
160
LSC
Iscritores in limba sarda
Public Group
331
49
916
LSC
Amigosde-sa-Limba-Sarda-Comuna
Community
1673
13
40
LSC
Solu in sardu
Public Group
15890
5701
373430
generic Sardinian
Solu poesias
Public Group
2018
158
1679
generic Sardinian
Scrieusu in campidanesu
Public Group
1984
576
17960
Campidanese
Cabuderra lngua e cultura
Public Group
116
1
18
Campidanese
Sos chi li piacheta faveddare e a iscrivere nugoresu
Public Group
984
438
1157
Nugoresu
Table 1: Basic statistics about data extracted.
FBgroup
tokens
types fr
>
10
LSC
71018
847
Sardu
3300408
18248
Campidanese
257110
2285
Nugoresu
379802
3412
Table 2: Basic statistics about token and types.
the complaints of Campidanese speakers (see par.
2).
4
Conclusion and Future Work
In this paper we address the following open ques-
tion:
could quantitative analysis of written data
help Sardinian community to find out a common
core (not specific of a variety) that could reinvig-
orate the idea of a standard? We plan future work
on this issue, with the awareness that digital con-
tent on social media is both an opportunity and a
challenge for this kind of analyses.
This paper is a first analysis of diatopic varieties
of Sardinian through orthographical comparisons
of word forms with the same meaning.
Thanks to
translated lists it was possible to look at common-
alities and differences between varieties.
Social
media are a source of real data about language uses
and the best observatory for regional and minority
languages. Concerning Sardinian Facebook offers
the possibility to test the distance between the pro-
posed orthographic standard and the existing vari-
eties.
We will test the interplay between varieties
with other methodologies to measure the distance
and to find out
usage patterns (e.g.
Levenshtein
distance for similar words).
This
work is
being carried out
in the frame-
work of the project DLDP (Digital Language Di-
versity Project,
http://www.dldp.eu).
DLDP is a
three year project funded under the Erasmus+ pro-
gramme.
It aims at addressing the problem of low
digital
representation of EU regional
and minor-
ity languages by giving their speakers the intel-
lectual
and practical
skills to create,
share,
and
reuse online digital content. DLDP fully embraces
a bottom-up approach to language revitalization
by addressing the speakers cognitive and practical
skills as the cornerstone of effective revitalization
initiatives.
Acknowledgments
This work is partially funded by the Erasmus +
DLDP Project
(Grant
Agreement
no.
2015-1-
IT02-KA204-015090).
The opinions expressed
reflect
only the authors view and the Erasmus+
National Agency and the Commission are not re-
sponsible for any use that may be made of the in-
formation contained.
References
Blasco Ferrer E.,
Bolognesi,
R.
et
al.
2001.
Limba
Sarda Unificada.
Sintesi
delle norme di
base:
or-
tografia, fonetica, morfologia, lessico.
Cagliari, Re-
gione Autonoma della Sardegna.
Burghardt, M., Granvogl, D. and Wolff, C.
2016.
Cre-
ating a Lexicon of Bavarian Dialect
by Means of
Facebook Language Data and Crowdsourcing.
Pro-
ceedings of LREC-2016. Portoroz, Slovenia.
Crystal,
D.
2010.
Language Death.
Cambridge Uni-
versity Press.
De Martini Abdullah Luca (ed.)
2001.
Libro de Co-
medias (by Antonio Maria da Esterzili).
Cagliari,
Cuec.
Eisenlohr,
P.
2004.
Language revitalization and new
technologies: Cultures and electronic mediation and
the refiguring of communities.
Annual
Review of
Anthropology.
18(3):339361.
Lupinu, G., Mongili, A. , Oppo, A. , Spiga, R. , Perra,
S.
,
Valdes,
M.
2007.
Le lingue dei
sardi:
una
ricerca sociolinguistica.
Assessorato alla Pubblica
istruzione, beni culturali, informazione, spettacolo e
sport, Regione Autonoma della Sardegna.
De Martini Abdullah Luca (ed.)
2002.
Sa Vitta et sa
Morte, et Passione de sanctu Gavinu, Prothu et Jan-
uariu (by Antonio Cano).
Cagliari, Cuec.
CLIC_2016_Proceedings.indd 266
02/12/16 15.05
267
common types
types with same word forms
types with different word forms
LSC-Sardu
61
60 (21 content words)
32 (11 content words)
LSC-Campidanese
67
43 (14 content words)
44 (17 content words)
LSC-Nugoresu
65
54 (14 content words)
39 (17 content words)
Sardu-Campidanese
65
47 (15 content words)
64 (26 content words)
Sardu-Nugoresu
70
64 (16 content words)
65 (33 content words)
Campidanese-Nugoresu
81
34 (12 content words)
82 (27 content words)
Table 3: Comparison between Sardinian varieties.
1 to 2
1 to 3
1 to 4
LSC - Sardu
8
4
1
LSC - Campidanese
3
0
0
LSC - Nugoresu
7
1
1
Sardu - Campidanese
5
1
5
Sardu - Noguruse
8
3
5
Campidanese - Nugoresu
2
0
1
Table 4: Comparison between Sardinian varieties.
Soria, C., Russo, I. , Quochi, V., Hicks, D., Gurrutxaga,
A., Sarhimaa, A. and Tuomisto, M.
2016.
Fostering
digital
representation of EU regional
and minority
languages:
the Digital Language Diversity Project.
Proceedings of LREC-2016. Portoroz, Slovenia.
Virdis,
M.
1988.
Sardisch:
Areallinguistik /
Aree
linguistiche.
Holtus G.,
Metzeltin,
M.,
Schmitt,
C. (eds.), Lexicon der Romanistischen Linguistik 4,
Tubingen, Max Niemeyer, pp. 897-913.
Wagner, M. L.
1997.
La lingua Sarda. Storia, spirito e
forma.
Nuoro, Ilisso.
CLIC_2016_Proceedings.indd 267
02/12/16 15.05
268
Determining the Compositionality of Noun-Adjective Pairs with Lexical
Variants and Distributional Semantics
Marco S. G. Senaldi
Laboratorio di Linguistica
Scuola Normale Superiore
Pisa, Italy
marco.senaldi@sns.it
Gianluca E. Lebani, Alessandro Lenci
Computational Linguistics Laboratory
Department of Philology, Literature, and Linguistics
University of Pisa, Italy
gianluca.lebani@for.unipi.it
alessandro.lenci@unipi.it
Abstract
English.
In this work we employed a set
of
26 Italian noun-adjective expressions
to test compositionality indices that com-
pare the distributional vector of an expres-
sion with the vectors of
its lexical
vari-
ants.
These were obtained by replacing
the components of the original expression
with semantically related words.
Our in-
dices performed comparably or better than
other compositionality measures reported
in the distributional literature.
Italiano.
In questo lavoro si
`
e utilizzato
un set
di
26 espressioni
italiane nome-
aggettivo per testare degli indici di compo-
sizionalit
`
a che confrontano il vettore dis-
tribuzionale di
un’espressione con i
vet-
tori
delle sue varianti
lessicali.
Queste
sono state ottenute sostituendo i
compo-
nenti dell’espressione di partenza con pa-
role semanticamente correlate.
La per-
formance dei nostri indici si
`
e dimostrata
comparabile o superiore a quella di altri
indici
di
composizionalit
`
a riportati
nella
letteratura distribuzionale.
1
Introduction and previous research
While a white car is white and is a car, a red her-
ring in a sentence like I thought he was the cul-
prit,
but
he was a red herring is neither red nor
a herring,
but
indicates something that
distracts
someone from a relevant
issue.
The former ex-
pression is compositional,
since its meaning de-
rives from the composition of the meanings of its
subparts (Werning et al., 2012). The latter, by con-
trast,
is an idiom,
a non-compositional,
figurative
and proverbial word combination belonging to the
wider class of Multiword Expressions (Nunberg
et
al.,
1994;
Cacciari,
2014).
The composition-
ality of a given expression entails salva-veritate-
interchangeability and systematicity (Fodor
and
Lepore, 2002).
First of all, if we replace the con-
stituents of a compositional expression with syn-
onyms or similar words (e.g.,
from white car to
white automobile),
the whole meaning is not
al-
tered.
Secondly,
if we can understand the mean-
ing of white car and red herring used in the lit-
eral sense, we can also understand what white her-
ring and red car mean.
Both these properties are
not valid for idioms, which always exhibit lexical
fixedness to some extent: variants of idiomatic red
herring like red fish or white herring can just have
a literal reading.
Computational
studies to date have proposed
several
techniques to automatically measure id-
iomaticity.
Of
note,
Lin (1999)
and Fazly et
al.
(2009)
label
a given word combination as
idiomatic if
the Pointwise Mutual
Information
(PMI) (Church and Hanks, 1991) between its com-
ponent
words is higher
than the PMIs between
the components of a set of lexical variants of this
combination.
These variants are obtained by re-
placing the component
words of the original
ex-
pressions with semantically related words.
Other
researches have exploited Distributional Semantic
Models (DSMs) (Sahlgren, 2008; Turney and Pan-
tel, 2010), comparing the vector of a given phrase
with the single vectors of its subparts (Baldwin
et
al.,
2003;
Venkatapathy and Joshi,
2005;
Fa-
zly and Stevenson, 2008) or comparing the vector
of a phrase with the vector deriving from the sum
or the products of their components (Mitchell and
Lapata, 2010; Kr
ˇ
cm
´
a
ˇ
r et al., 2013).
In a previous contribution (Senaldi et al., 2016),
CLIC_2016_Proceedings.indd 268
02/12/16 15.05
269
we started from a set
of Italian verbal
idiomatic
and non-idiomatic phrases
(henceforth our
tar-
gets) and generated lexical variants (simply vari-
ants henceforth)
by replacing their
components
with semantic neighbours extracted from a lin-
ear
DSM and Italian MultiWordNet
(Pianta et
al.,
2002).
Then,
instead of
measuring the as-
sociational
scores between their subparts like in
Lin (1999) and Fazly et al.
(2009),
we exploited
Distributional Semantics to observe how different
the context
vectors of our targets were from the
vectors of their variants.
Our proposal
stemmed
from the consideration that a high PMI value does
not necessarily imply the idiomatic or multiword
status of an expression,
but
just
that
its compo-
nents co-occur more frequently than expected by
chance,
as in the case of read and book or solve
and problem, which are all instances of composi-
tional pairings. By contrast, what watertightly dis-
tinguishes an idiomatic from a collocation-like yet
still
compositional
expression is their context
of
use.
Comparing the distributional contexts of the
original expressions and their alternatives should
therefore represent
a more precise refinement
of
the PMI-based procedure.
Actually, idiomatic ex-
pressions vectors were found to be less similar
to their variants vectors with respect to composi-
tional expressions vectors.
In some of our mod-
els,
we also kept
track of the variants that
were
not
attested in our corpus by representing them
as orthogonal
vectors to the vector of the origi-
nal expression, still achieving considerable results.
Noteworthily,
most
researches conducted so far
have focused on verbal idioms, while the analysis
of NP idioms like red herring or second thoughts
has been usually left aside.
2
Applying variant-based distributional
measures to noun-adjective pairs
In the present
study,
we firstly aimed to extend
the variant-based method tested in Senaldi
et
al.
(2016) on verbal idioms to noun-adjective expres-
sions,
which are mostly neglected in the idiom
literature.
In the second place,
our former work
lacked a comparison against conventional additive
and multiplicative compositionality indices pro-
posed in the distributional literature (Mitchell and
Lapata,
2010;
Kr
ˇ
cm
´
a
ˇ
r et al.,
2013).
Finally,
be-
side using a linear DSM and Italian MultiWord-
Net (Pianta et al., 2002) to extract our variants, we
also experimented with a DSM (Pad
´
o and Lapata,
2007;
Baroni and Lenci,
2010) which kept track
of the syntactic dependency relations between a
given target and its contexts.
3
Data extraction
3.1
Extracting the target expressions
All in all, our dataset was composed of 26 types of
Italian noun-adjective and adjective-noun combi-
nations. Of these, 13 were Italian idioms extracted
from the itWaC corpus (Baroni et al., 2009), which
totalizes about
1,909M tokens.
The frequency
of these targets varied from 21 (alte sfere ‘high
places’,
lit.
‘high spheres’) to 194 (punto debole
‘weak point’). The remaining 13 items were com-
positional
pairs of comparable frequencies (e.g.,
nuova legge ‘new law’).
3.2
Extracting lexical variants
Linear DSM variants.
For both the noun and the
adjective of our targets,
we extracted its top co-
sine neighbors in a linear DSM created from the
La Repubblica corpus (Baroni et al., 2004) (about
331M tokens).
In Senaldi et al. (2016) we exper-
imented with different thresholds of selected top
neighbors (3, 4, 5 and 6). Since the number of top
neighbors that were extracted for each constituent
did not significantly affect our performances,
for
the present study we decided to use the maximum
number
(i.e.,
6).
All
the content
words occur-
ring more than 100 times were represented as tar-
get vectors, ending up with 26,432 vectors, while
the top 30,000 content words were used as dimen-
sions.
The co-occurrence counts were collected
with a context window of
±
2 content words from
each target word.
The obtained matrix was then
weighted by Positive Pointwise Mutual Informa-
tion (PPMI) (Evert, 2008) and reduced to 300 la-
tent
dimensions via Singular
Value Decomposi-
tion (SVD) (Deerwester et al., 1990). The variants
were finally obtained by combining the adjective
with each of the noun’s top 6 neighbors, the noun
with all the top 6 neighbors of the adjective and
finally all the top 6 neighbors of the adjective and
the noun with each other, ending up with 48 Linear
DSM variants per target.
Structured DSM variants.
While unstructured
DSMs
just
record the words
that
linearly pre-
cede or follow a target lemma when collecting co-
occurrence counts, structured DSMs conceive co-
occurrences as
< w
1
, r, w
2
>
triples, where r rep-
CLIC_2016_Proceedings.indd 269
02/12/16 15.05
270
resents the dependency relation between
w
1
and
w
2
(Pad
´
o and Lapata,
2007;
Baroni
and Lenci,
2010).
Since we wanted to experiment with dif-
ferent kinds of distributional information to gener-
ate our variants,
following the method described
in Baroni
and Lenci
(2010) we created a struc-
tured DSM from La Repubblica (Baroni
et
al.,
2004),where all the content words occurring more
than 100 times were kept
as targets and the co-
occurrence matrix was once again weighted via
PPMI and reduced to 300 latent dimensions.
For
each target, we generated 48 lexical variants with
the same procedure described for the linear DSM
variants.
iMWN variants. For each noun, we extracted the
words occurring in the same synsets and its co-
hyponyms in Italian MultiWordNet (iMWN) (Pi-
anta et
al.,
2002).
As for the adjectives,
we ex-
perimented with two different approaches, extract-
ing just their synonyms in the first case (iMWN
syn
variants) and adding also the antonyms in the sec-
ond case (iMWN
ant
variants). The antonyms were
translated from the English WordNet
(Fellbaum,
1998).
For each noun and adjective,
we kept its
top 6 iMWN neighbors in terms of cosine simi-
larity in the same DSM used to acquire the linear
DSM variants.
Once again, this method provided
us with 48 iMWN variants per target.
4
Gold standard idiomaticity judgments
To validate our
computational
indices,
we pre-
sented 9 linguistics students with our 26 targets
and asked them to rate how idiomatic each expres-
sion was on a 1-7 scale, with 1 standing for “totally
compositional” and 7 for “totally idiomatic”.
The
targets were presented in three different random-
ized orders, with three raters per order.
The mean
score given to our idioms was 6.10 (SD = 0.77),
while the mean score given to compositional ex-
pressions was 2.03 (SD = 1.24).
This difference
was proven by a t-test
to be statistically signifi-
cant (
t
= 10.05,
p <
0.001).
Inter-coder reliabil-
ity, measured via Krippendorff’s
α
(Krippendorff,
2012) was 0.76.
Following established practice,
we took such value as a proof of reliability for the
elicited ratings (Artstein and Poesio, 2008).
5
Calculating compositionality indices
For
each of
our
26 targets,
we extracted from
itWaC all the attested occurrences of the 48 linear
DSM, structured DSM, iMWN
syn
and iMWN
ant
variants.
We then computed two kinds of vector-
based compositionality indices:
5.1
Variant-based indices
For
every variant
type (linear
DSM,
structured
DSM, iMWN
syn
and iMWN
ant
) we built a DSM
from itWaC representing the 26 targets and their
variants as vectors. While the dimension of the La
Repubblica corpus seemed to be enough for the
variants extraction procedure, we resorted to five-
times bigger
itWaC to represent
the variants as
vectors and compute the compositionality scores
to avoid data sparseness and have a considerable
number of variants frequently attested in our cor-
pus.
We also thought
that
using two different
corpora had the additional advantage of showing
the variants method to be generalizable to corpora
of different text genres.
Co-occurrence statistics
recorded how many times each target
or variant
construction occurred in the same sentence with
each of the 30,000 top content words in the cor-
pus.
The matrices were then weighted with PPMI
and reduced to 150 dimensions via SVD.
We fi-
nally calculated four different indices:
Mean.
The mean cosine similarity between the
vector of a target construction and the vectors of
its variants.
Max. The maximum value among the cosine simi-
larities between a target vector and its variants vec-
tors.
Min. The minimum value among the cosine simi-
larities between a target vector and its variants vec-
tors.
Centroid.
The cosine similarity between a target
vector and the centroid of its variants vectors.
Since some of our targets had many variants that
were not found in itWaC, each measure was com-
puted twice:
in the first
case we simply did not
consider the non-occurring variants (no models);
in the second case, we conceived them as orthogo-
nal vectors to the target vector (orth models).
For
the Mean, Max and Min indices, this meant to au-
tomatically set to 0.0 the target-variant cosine sim-
ilarity.
For the Centroid measure,
we first
com-
puted the cosine similarity between the target vec-
tor and the centroid of its attested variants (
cs
a
).
From this initial cosine value we then subtracted
the product
between the number of non-attested
variants (
n
),
cs
a
and a costant factor
k
. This factor
k
, which was set to 0.01 in previous investigations,
CLIC_2016_Proceedings.indd 270
02/12/16 15.05
271
represented the contribution of each zero variant in
reducing the target-variants similarity towards 0.0.
k
was multiplied by the original cosine since we
hypothesized that zero variants contributed differ-
ently in lowering the target-variants similarity, de-
pending on the construction under consideration:
Centroid
=
cs
a
−
(
cs
a
·
k
·
n
)
5.2
Addition-based and multiplication-based
indices
The indices in Section 5.1 were compared against
two of
the
measures
described in Kr
ˇ
cm
´
a
ˇ
r
et
al.
(2013).
We
trained
a
DSM on
itWaC
that
represented
all
the
content
words
with
tokenf requency
>
300
and our 26 targets as
row-vectors and the top 30,000 content words as
contexts.
The co-occurrence window was still the
entire sentence and the weighting was still
the
PPMI.
SVD was carried out
to 300 final
dimen-
sions. Please note that the context vector of a given
word did not include the co-occurrences of a target
idiom or target compositional expression that was
composed of that word (e.g.
the vector for punto
did not include the contexts of punto debole).
We
then computed the following measures:
Additive.
The cosine similarity between a target
vector and the vector resulting from the sum of the
vectors of its components.
Multiplicative.
The cosine similarity between
a target
vector and the vector resulting from the
product of the vectors of its components.
6
Results and discussion
Our 26 targets were sorted in ascending order for
each compositionality score.
In each ranking, we
predicted idioms (our positives) to be placed at the
top and compositional phrases (our negatives) to
be placed at
the bottom,
since we expected id-
iom vectors to be less similar to the vectors of
their variants.
First
and foremost,
we must
no-
tice that
three idioms for every type of variants
(Linear DSM,
Structured DSM and iMWN) ob-
tained a 0.0 score for all the variant-based indices
since no variants were found in itWaC. Neverthe-
less,
we kept
this information in our ranking as
an immediate proof of the idiomaticity of such ex-
pressions.
These were punto debole ‘weak point’,
passo falso ‘false step’ and colpo basso ‘cheap
shot’ for the Structured DSM spaces,
punto de-
bole,
pecora nera ‘black sheep’ and faccia tosta
Top IAP Models
IAP
F
ρ
Additive
0.85 0.77 -0.62
∗∗∗
Structured DSM Mean
orth
0.84 0.85 -0.68
∗∗∗
iMWN
syn
Centroid
orth
0.83 0.85
-0.57
∗∗
iMWN
ant
Centroid
orth
0.83 0.77
-0.52
∗∗
iMWN
ant
Mean
orth
0.83 0.69 -0.64
∗∗∗
Top F-measure Models
IAP
F
ρ
Structured DSM Mean
orth
0.84 0.85 -0.68
∗∗∗
iMWN
syn
Centroid
orth
0.83 0.85
-0.57
∗∗
Additive
0.85 0.77 -0.62
∗∗∗
iMWN
ant
Centroid
orth
0.83 0.77
-0.52
∗∗
iMWN
syn
Centroid
no
0.82 0.77
-0.57
∗∗
Top
ρ
Models
IAP
F
ρ
Structured DSM Mean
orth
0.84 0.85 -0.68
∗∗∗
Linear DSM Mean
orth
0.75 0.69 -0.66
∗∗∗
iMWN
syn
Mean
orth
0.77 0.77 -0.65
∗∗∗
iMWN
syn
Mean
no
0.70 0.69 -0.65
∗∗∗
iMWN
ant
Mean
orth
0.83 0.69 -0.64
∗∗∗
Multiplicative
0.58 0.46
0.03
Random
0.50 0.31
0.05
Table 1:
Best
models ranked by IAP (top),
F-
measure at the median (middle) and Spearman’s
ρ
correlation with the speakers’ judgments (bottom)
against
the multiplicative model
and the random
baseline (** =
p <
0.01, *** =
p <
0.001).
‘cheek’ for the iMWN spaces and punto debole,
passo falso and zoccolo duro ‘hard core’ for the
Linear DSM spaces.
Table 1 reports the 5 best
models for Interpo-
lated Average Precision (IAP),
the F-measure at
the median and Spearman’s
ρ
correlation with our
gold standard idiomaticity judgments respectively.
Coherently with Fazly et al. (2009), IAP was com-
puted as the average of the interpolated precisions
at
recall
levels of
20%,
50% and 80%.
Inter-
estingly,
while Additive was the model
that
best
ranked idioms before non-idioms (IAP),
closely
followed by our variant-based measures,
and fig-
ured among those with the best
precision-recall
trade-off
(F-measure),
Multiplicative performed
comparably to the Random baseline.
The best
correlation with idiomaticity judgments was in-
stead achieved by one of our variant-based mea-
sures (-0.68).
Additive did not
belong to the 5
models with top correlation,
but
still
achieved a
high significant
ρ
score (-0.62).
It’s worth not-
ing that all these correlational indices are negative:
the more the subjects perceived a target to be id-
CLIC_2016_Proceedings.indd 271
02/12/16 15.05
272
iomatic, the less its vector was similar to its vari-
ants. Max and Min never appeared among the best
performing measures,
with all
top models using
Mean and Centroid.
Moreover,
the DSM models
that worked the best for IAP and F-measure both
used dependency-related distributional
informa-
tion, with linear DSM models not reaching the top
5 ranks.
This difference was nonetheless ironed
out when looking at the Top
ρ
models. Differently
from what we observed for verbal idioms (Senaldi
et al., 2016), the majority of our best models, and
de facto all the Top
ρ
models, encoded zero vari-
ants as orthogonal vectors (orth models).
Finally,
the presence of antonymy-related information for
iMWN models did not appear to influence the per-
formances considerably.
7
Conclusions
In this contribution we applied to adjective-noun
constructions the variant-based distributional mea-
sures we had previously tested on verbal
idioms
(Senaldi et al.,
2016),
obtaining effective perfor-
mances.
Interestingly,
our
measures performed
comparably to or
even better
than the Additive
method proposed in the distributional
literature
(Kr
ˇ
cm
´
a
ˇ
r et al., 2013), while the Multiplicative one
performed considerably worst than all our models,
together with the Random baseline.
Future work will concern testing whether these
variant-based measures
can be succesfully ex-
ploited to predict psycholinguistic data about the
processing of idiom compositionality and flexibil-
ity, together with other corpus-based indices of id-
iomaticity.
References
Ron Artstein and Massimo Poesio.
2008.
Inter-coder
agreement for computational linguistics.
Computa-
tional Linguistics, 34(4):555–596.
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows.
2003.
An empirical model of
multiword expression decomposability.
In Proceed-
ings of
the ACL-SIGLEX Workshop on Multiword
Expressions:
Analysis,
Acquisition and Treatment,
pages 89–96.
Marco Baroni
and Alessandro Lenci.
2010.
Dis-
tributional
memory:
A general
framework
for
corpus-based semantics.
Computational
Linguis-
tics, 36(4):673–721.
Marco Baroni,
Silvia Bernardini,
Federica Comastri,
Lorenzo Piccioni, Alessandra Volpi, Guy Aston, and
Marco Mazzoleni.
2004.
Introducing the La Re-
pubblica Corpus:
A Large,
Annotated,
TEI(XML)-
Compliant
Corpus of Newspaper Italian.
In Pro-
ceedings of the 4
th
International Conference on Lan-
guage Resources and Evaluation, pages 1771–1774.
Marco Baroni,
Silvia Bernardini,
Adriano Ferraresi,
and Eros Zanchetta.
2009.
The wacky wide web:
a collection of
very large linguistically processed
web-crawled corpora.
Language Resources
and
Evaluation, 43(3):209–226.
Cristina Cacciari.
2014.
Processing multiword id-
iomatic strings:
Many words in one?
The Mental
Lexicon, 9(2):267–293.
Kenneth W.
Church and Patrick Hanks.
1991.
Word
association norms, mutual information, and lexicog-
raphy.
Computational Linguistics, 16(1):22–29.
Scott
Deerwester,
Susan T.
Dumais,
George W.
Fur-
nas,
Thomas K.
Landauer,
and Richard Harshman.
1990.
Indexing by latent semantic analysis.
Jour-
nal of the American society for information science,
41(6):391.
Stefan Evert.
2008.
Corpora and collocations.
In Anke
L
¨
udeling and Merja Kyt
¨
o,
editors,
Corpus Linguis-
tics.
An International
Handbook,
volume 2,
pages
1212–1248. Mouton de Gruyter.
Afsaneh Fazly and Suzanne Stevenson.
2008.
A distri-
butional account of the semantics of multiword ex-
pressions.
Italian Journal of Linguistics, 1(20):157–
179.
Afsaneh Fazly,
Paul
Cook,
and Suzanne Stevenson.
2009.
Unsupervised type and token identification of
idiomatic expressions.
Computational
Linguistics,
1(35):61–103.
Christiane Fellbaum, editor.
1998.
WordNet: An Elec-
tronic Lexical Database.
MIT Press.
Jerry A. Fodor and Ernest Lepore.
2002.
The compo-
sitionality papers.
Oxford University Press.
Klaus Krippendorff.
2012.
Content analysis: An intro-
duction to its methodology.
Sage.
Lubom
´
ır Kr
ˇ
cm
´
a
ˇ
r, Karel Je
ˇ
zek, and Pavel Pecina.
2013.
Determining Compositionality of Expresssions Us-
ing Various Word Space Models and Measures.
In
Proceedings of the Workshop on Continuous Vector
Space Models and their Compositionality, pages 64–
73.
Dekang Lin.
1999.
Automatic identification of non-
compositional phrases.
In Proceedings of the 37
th
Annual
Meeting of
the Association for Computa-
tional Linguistics, pages 317–324.
Jeff Mitchell and Mirella Lapata.
2010.
Composition
in Distributional
Models of Semantics.
Cognitive
Science, 34(8):1388–1429.
CLIC_2016_Proceedings.indd 272
02/12/16 15.05
273
Geoffrey Nunberg,
Ivan Sag,
and Thomas
Wasow.
1994.
Idioms.
Language, 70(3):491–538.
Sebastian
Pad
´
o
and
Mirella
Lapata.
2007.
Dependency-based construction of semantic space
models.
Computational Linguistics, 33(2):161–199.
Emanuele Pianta,
Luisa Bentivogli,
and Christian Gi-
rardi.
2002.
Multiwordnet: Developing and aligned
multilingual
database.
In Proceedings of
the First
International Conference on Global WordNet, pages
293–302.
Magnus Sahlgren.
2008.
The distributional hypothe-
sis.
Italian Journal of Linguistics, 20(1):33–54.
Marco S. G. Senaldi, Gianluca E. Lebani, and Alessan-
dro Lenci.
2016.
Lexical
variability and compo-
sitionality:
Investigating idiomaticity with distribu-
tional semantic models.
In Proceedings of the 12
th
Workshop on Multiword Expressions, pages 21–31.
Peter D. Turney and Patrick Pantel.
2010.
From Fre-
quency to Meaning:
Vector Space Models of Se-
mantics.
Journal of Artificial Intelligence Research,
37:141–188.
Sriram Venkatapathy and Aravid Joshi.
2005.
Measur-
ing the relative compositionality of verb-noun (V-N)
collocations by integrating features.
In Proceedings
of Joint Conference on Human Language Technol-
ogy and Empirical
Methods in Natural
Language
Processing, pages 899–906.
Markus
Werning,
Wolfram Hinzen,
and
Edouard
Machery,
editors.
2012.
The Oxford Handbook of
Compositionality.
Oxford University Press.
CLIC_2016_Proceedings.indd 273
02/12/16 15.05
274
Subjective Well-Being and Social Media: A Semantically Annotated
Twitter Corpus on Fertility and Parenthood
Emilio Sulis, Cristina Bosco, Viviana Patti
Dipartimento di Informatica
University of Turin
Italy
{
bosco,patti,sulis@di.unito.it
}
Mirko Lai
Delia Iraz
´
u Hern
´
andez Far
´
ıas
University of Turin, Italy
Univ. Polit
`
ecnica de Val
`
encia, Spain
{
hernande,lai
}
@unito.it
Letizia Mencarini
Dondena Centre for Research on
Social Dynamics and Public Policy
Bocconi University, Italy
letizia.mencarini@unibocconi.it
Michele Mozzachiodi
Daniele Vignoli
University of Florence, Italy
{
mozzachiodi,vignoli
}
@disia.unifi.it
Abstract
English.
This article describes a Twit-
ter corpus of social media contents in the
Subjective Well-Being domain.
A multi-
layered manual
annotation for
exploring
attitudes on fertility and parenthood has
been applied.
The corpus
was
further
analysed by using sentiment
and emo-
tion lexicons in order
to highlight
rela-
tionships between the use of affective lan-
guage and specific sub-topics in the do-
main.
This analysis is useful
to identify
features for the development
of an auto-
matic tool for sentiment-related classifica-
tion tasks in this domain.
The gold stan-
dard is available to the community.
Italiano.
L’articolo descrive la creazione
di un corpus tratto da Twitter sui temi del
Subjective Well-Being, fertilit
`
a e genitori-
alit
`
a.
Un’analisi lessicale ha mostrato il
legame tra l’uso di linguaggio affettivo e
specifiche categorie di messaggi.
Questo
esame
`
e utile per se e per l’addestramento
di sistemi di classificazione automatica sul
dominio.
Il gold standard
`
e disponibile su
richiesta.
1
Introduction
The key research questions we address in this pa-
per concern how subjective well-being drives fer-
tility trends (and vice versa).
We developed a
Twitter Italian corpus annotated with a novel se-
mantic annotation scheme for marking informa-
tion not
only about
sentiment
polarity,
but
also
about the specific semantic areas/sub-topics which
are the target of sentiment in the fertility-SWB do-
main.
The relationship between big data and of-
ficial
statistics is increasingly a subject
of atten-
tion (Mitchell et al.,
2013;
Reimsbach-Kounatze,
2015;
Sulis
et
al.,
2015;
Zagheni
and Weber,
2005).
In this work we focus on Twitter
data
for
two main reasons.
First,
Twitter
individu-
als’
opinions are posted spontaneously (not
re-
sponding to a question) and often as a reaction
to some emotional driven observation.
Moreover,
using Twitter we can incorporate additional mea-
sures
of
attitudes
towards
children and parent-
hood,
with a wider
geographical
coverage than
what is the case for traditional survey.
Sentiment
analysis in Twitter
has been also used to mon-
itor
political
sentiment
(Tumasjan et
al.,
2010),
to extract
critical
information during times
of
mass emergency (Verma et
al.,
2011;
Buscaldi
and Hern
´
andez Far
´
ıas,
2015),
or to analyse user
stance in political debates on controversial topics
(Stranisci et al., 2016; Bosco et al., 2016; Moham-
mad et al.,
2015).
A comprehensive overview of
sentiment
analysis with annotated corpora is of-
fered in (Nissim and Patti,
2016).
Focusing on
Italian,
among the existing resources we mention
the Senti-TUT corpus (Bosco et
al.,
2013)
and
the TWITA corpus (Basile and Nissim, 2013) that
were recently exploited in the SENTIment
PO-
Larity Classification (SENTIPOLC)
shared task
(Basile et al., 2014).
The corpus described in this
paper enriches the scenario of datasets available
for Italian,
enabling also a finer grained analysis
of sentiment related phenomena in a novel domain
related to parenthood and fertility.
2
Dataset and Methodology
As a reference dataset,
we adopted all the tweets
posted in Italian language in 2014 (TWITA14
CLIC_2016_Proceedings.indd 274
02/12/16 15.05
275
henceforth),
which were retrieved through the
Twitter
Streaming API
and applying the Italian
filter proposed within the TWITA project (Basile
and Nissim,
2013).
The TWITA14 dataset
in-
cluded 259,893,081 tweets (4,766,342 geotagged).
We applied a multi-step methodology in order to
filter and select those relevant tweets concerning
fertility and parenthood.
2.1
Filtering steps on the dataset
A number
of
filtering steps
have been applied
for selecting from TWITA14 a corpus of tweets
where users talk about
fertility and parenthood
(TW-SWELLFER corpus, henceforth).
We could
not
rely on the exploitation of one or few hash-
tags or other elements that allow identifying posts
on fertility and parenthood.
In fact,
these top-
ics are somehow spread in the dataset
and mes-
sages may contain relevant
information on such
subjects even if the main topic of the post is dif-
ferent. Therefore, we are facing a situation where,
on the one hand,
the set
of the data that
are po-
tentially relevant for our specific analysis is wider
than usual;
on the other
hand,
it
is more diffi-
cult
to identify the presence of
information re-
lated to the topics we are interested in.
This
leaded us to adopt a multi-step thematic filtering
approach.
In a first
step (Keyword-based filter-
ing step), eleven hashtags
1
and other 19 keywords
have been chosen for selecting tweets of interest,
including 8 roots to consider diminutives,
singu-
lars and plurals.
This list is the result of a com-
bination of
a manual
content
analysis on 2,500
tweets sampled at
completely random (taken as
a starting point) and a linguistic analysis on syn-
onyms.
We obtain a total
amount
of
3.9 mil-
lion tweets.
A second filtering step consisted in
removing noisy tweets from corpus (User-based
filtering step),
as
the off-topic ones
(messages
not
concerning individual
expression on fertility
and parenthood topics).
Tweets posted by com-
pany/institutions/newspapers accounts have been
deleted.
Finally, duplicated tweets not marked as
RT were deleted (Duplicate-based filtering step).
The resulting TW-SWELLFER corpus consists of
2,760,416 tweets.
1
#pap
`
a,
#mamma,
#babbo,
#incinta,
#primofiglio,
#sec-
ondofiglio,
#futuremamme,
#maternit
`
a,
#paternit
`
a,
#allatta-
mento, #gravidanza
2.2
Annotation scheme
Given the TW-SWELLFER dataset, we developed
and applied an annotation model aimed at studying
not only the sentiment expressed in the tweets, but
also specific parenthood-related topics discussed
in Twitter
that
are the target
of
the sentiment.
To build our
annotation model,
we relied on a
standard annotation scheme on sentiment
polar-
ity (POLARITY),
by exploiting the same labels
POS, NEG, NONE and MIXED provided the or-
ganizers of the shared task for sentiment analysis
in Twitter for Italian (Basile et
al.,
2014).
Also
the presence/absence of irony has been marked in
order to be able to reason on sentiment
polarity
also in case of use of figurative devices.
Annotat-
ing the presence of ironic devices is a challenging
task because the inferring process of this figure of
speech does not always lie on semantic and syn-
tactic elements of texts (Ghosh et al., 2015; Reyes
et al., 2013; Hern
´
andez Far
´
ıas et al., 2016), but of-
ten requires contextual knowledge (Wilson, 2006).
In order to mark irony,
we introduced two polar-
ized ironic labels:
HUMNEG,
for ironic tweets
with negative polarity,
and HUMPOS for ironic
tweets with positive polarity.
Finally,
a set of la-
bels marks the specific semantic areas (or SUB-
TOPICS) of the tweets related to the parenthood
domain. This part of the annotation scheme is very
important
since somehow provides us with a se-
mantic grid in order to analyse which are the as-
pects of parenthood that are discussed on Twitter.
For the annotation of sub-topics we considered 7
labels,
suggested by a group three experts on the
SWELLFER (subjective well-being and fertility)
domain, after a manual analysis of a subset of the
tweets:
•
TOBEPA -
To be parents.
This tag is in-
troduced to mark when the user generically
comments about his status of parent.
•
TOBESO - To be sons.
This tag marks the
sons point of view,
i.e.
on when the user is
a son that comments on the parent-son rela-
tionship.
•
DAILYLIFE - Daily life. This tag marks mes-
sages commenting on recurring situation in
everyday life for what concerns the relation-
ship between parents and children.
•
JUDGOTHERPA - Judgment over other par-
ents
behaviour.
The tag allows
to mark
CLIC_2016_Proceedings.indd 275
02/12/16 15.05
276
comments on educations of children,
for in-
stance comments of behaviours which does
not seems to be appropri - ated for the parent
role.
•
FUTURE - Children’ future. This tag is used
for
tweets where parents do express senti-
ments about the future of children.
•
BECOMPA - To become parents.
This tag is
introduced to mark tweets where users speak
about the prospect or fear of being parents.
•
POL - Political side. This tag is introduced to
mark tweets talking about laws having impact
on being parents.
Finally,
two additional
tags (IN-TOPIC/OFF-
TOPIC) have been added to allow annotators to
mark if the tweet is relevant.
The addition of this
tag was necessary because of the noise still present
in the dataset.
Moreover, in this way, the manual
annotation will produce also data to be used in or-
der to create a supervised topic classifier from the
whole TW-SWELLFER corpus.
This opens the
way to the exploitation of the corpus for a fine-
grained sentiment analysis,
by identifying differ-
ent aspects and topics of the Twitter debate on par-
enthood and the sentiment expressed towards each
aspect/topic.
2.3
Manual annotation
A random sample of
5,566 tweets
from TW-
SWELLFER has been collected.
On this sample
we applied crowdsourcing for manual annotation
via the Crowdflower platform already used in lit-
erature (Nakov et al., 2016).
We relied on Crowd-
Flower controls to exclude unreliable annotators
and spammers based on hidden tests,
which we
created by developing a set of gold-standard test
questions equipped with gold reasons
2
. The anno-
tator’s task was, first, to mark if the post is IN- or
OFF-TOPIC (or unintelligible),
and then to mark
for IN-TOPIC posts, on the one hand, the polarity
and presence of irony, on the other hand, the sub-
topics. Precise guidelines were provided to the an-
notators.
Overall, for each tweet at least three in-
dependent annotations were provided
3
. In order to
2
Test questions resulted from the agreement of three ex-
pert annotators.
3
We selected the CrowdFlower’s dynamic judgment
op-
tion:
having the goal of collecting at least 3 reliable annota-
tions for each tweet, the system was collecting up to a max-
imum of 5 annotations (to deal with cases when row’s con-
select the true label we used majority voting.
In-topic vs off-topic:
manual annotation on this
aspect
resulted in 2,355 in-topic tweets (42.3%)
and 3,136 off-topic (56.3%);
the remaining 75
tweets were unknown or null (cases of disagree-
ment).
Thanks to the preliminary filtering steps,
the proportion of
in-topic tweets is pretty high
compared to common results from different Twit-
ter based content and opinion analysis (Ceron et
al., 2014).
Polarity,
irony,
sub-topics (in-topic tweets):
at
the end of the manual annotation process we col-
lected 1,545 labeled with the same tags for all the
layers.
Notice that in the analysis in the next section will
report results also on tweets labeled as IN-TOPIC
after the manual annotation (2,355), but where an-
notators did not
agree on the polarity,
irony and
subtopics
labels.
We refer
to those tweets
as
NULL messages.
Summarizing, the TWSWELLFER-GOLD cor-
pus includes 1,545 IN-TOPIC tweets labeled with
the same tags
for
all
the layers
(POLARITY,
IRONY and SUBTOPICS).
3
Analysis of the gold standard
Figure 1: TW-SWELLFER: Distribution of polar-
ity tags in IN-TOPIC messages
Regarding IN-TOPIC tweets,
the 26.4% has
been labeled as positive and 22.3% as negative
(See Fig.1),
giving us a guidance on what might
be the general
feeling in Twitter
about
the re-
search topics on happiness and parenthood.
The
irony issue is limited to a 15.7% of all the mes-
sages and negative irony prevails (10.1% of neg-
ative ironic tweets and 5.6% of
positive ironic
tweets),
while neutral
tweets are just
the 8.3%.
fidence score is low).
In our jobs we set
0.7 as minimum
accuracy threshold.
CLIC_2016_Proceedings.indd 276
02/12/16 15.05
277
The amount
of mixed tweets is limited to 1.2%
(remaining 26% are labelled as NULL because
of annotators disagreement).
Regarding these re-
sults,
it
appears that
positive and negative feel-
ings towards family,
parenthood and fertility ap-
pear more or less equally spread through Twitter
Italy.
Even if
the positive posts are a little bit
more than the negative ones,
ironic tweets must
be considered:
most
of them are negative ironic
posts (i.e.,
insulting/damaging the target) balanc-
ing the slight difference between pure positive and
negative tweets. Furthermore, this particular topic,
combined with the Twitter nature which provides
short direct message, discourages people to stand
in the grey (neutral) area, as could happens in other
cases:
about the 90% of the tweets shows an ex-
plicit polarity, meaning people take a side and ex-
press their opinions.
Figure 2:
TW-SWELLFER:
Distribution of sub-
topic tags in IN-TOPIC messages
Which are these opinions and about what? Go-
ing further with the analysis and looking also at the
contents,
so taking into consideration the “topic
specification attribute and its values (Fig.
2),
the
largest category refers to sons tweets (TOBESO)
(40.3%),
in which children are discussing and
posting about being children and/or about relating
themselves with parents.
Parents tag (TOBEPA)
settles on 15% and becoming tag (BECOMEPA)
on 10%. Remaining categories have minor impact,
all being in between 1% and 6%.
3.1
Sentiment and emotion analysis
The exam of the corpus includes a lexical analy-
sis on different
aspects of affect:
sentiment
and
emotions.
The distribution of terms in each group
of messages reveals interesting patterns. Adopting
sentiment lexical resources
4
the whole polarity of
messages is computed summing positive and neg-
ative terms.
A normalization is finally performed,
i.e.
dividing the polarity value by the number of
terms in each group.
In particular, the four lexica
considered count more positive terms in positive
messages.
Similarly, negative terms are more fre-
quent in negative messages.
Ironic messages re-
veal a similar pattern,
even if smoothed.
Table 1
presents some of these results.
In addition,
the emotion lexicon indicates
a
larger frequency of terms related to anger, sadness,
fear and disgust in negative messages than in pos-
itive ones (See Fig.
3).
On the contrary,
positive
Figure 3: Distribution of emotions by polarity tags
messages contain more terms related to joy, antic-
ipation and surprise. Some suggestions can be de-
rived in the comparison of polarity categories and
the corresponding ironic ones. For instance, terms
related to joy are more frequent in ironic negative
messages than in negative ones.
It is an insight of
the polarity reversal phenomena,
where a shift is
produced by the adoption of a seemingly positive
statement,
to reflect
a negative one (Sulis et
al.,
2016).
The analysis of topic specification messages re-
veals a positive polarity for messages concerning
TOBEPA (to be parents),
while BECOMEPA (to
become parents) has a more negative polarity (See
Table 1).
Focusing on emotion lexicon, TOBEPA
has an higher incidence of Joy words (Fig. 4).
Messages
concerning educations
of
children
(JUDGOTHERPA)
contain a high frequency of
anger and disgust term. The category TOBESO (to
4
EmoLex (Mohammad and Turney,
2013)
as
well
as
an own-house Italian version of LIWC (Pennebaker et
al.,
2001), Hu&Liu (Hu and Liu, 2004), AFINN (Nielsen, 2011).
Lexicons
were translated from English in (Buscaldi
and
Hern
´
andez Far
´
ıas, 2015).
CLIC_2016_Proceedings.indd 277
02/12/16 15.05
278
tag
pLIWC
pHuLiu
pEmolex
Afinn
pAVG
POS
1.06
0.22
0.62
3.51
1.35
NEG
-1.61
0.04
0.12
0.39
-0.27
HUMPOS
0.19
0.12
0.23
2.29
-0.71
HUMNEG
-0.34
0.08
0.64
0.61
0.25
TOBESO
1.97
0.88
0.02
1.56
1.11
TOBECOMEPA
1.5
0.73
0.18
-1.64
0.19
TOBEPA
1.94
1.38
0.18
5.04
2.13
DAILYLIFE
1.13
1.56
0.32
6.04
2.26
Table 1: Polarity values according to different lexicons in tweets tagged with the following labels: POS,
NEG,
HUMPOS,
HUMNEG (polarity tags)
and TOBESO,
TOBECOMEPA,TOBEPA,
DAILYLIFE
(sub-topic tags).
Figure 4:
Distribution of emotions by sub-topic
tags
be sons) is more controversial,
having the higher
frequency of negative terms as fear, but also trust,
as well as having the lower frequency of Joy terms.
Coherently,
anticipation is more frequent
in the
BECOMEPA group of messages.
Summarizing,
it seems that children are more critics toward par-
ents.
On the contrary, parents seem express an at-
titude more positive towards children.
4
Conclusions and Future Work
The contribution of this paper is the exploration
of opinions and semantic orientation about fertil-
ity and parenthood by scrutinizing about 3 million
Italian tweets.
This analysis is useful to identify
features for the development of an automatic sys-
tem to address automatic classification tasks in this
domain. The corpus is available to the community.
Its development constitutes a first step and a pre-
condition to a further analysis that can be applied
on such contents in order to extract, from semanti-
cally enriched data, measures of SWB constructed
in an indirect
way.
This will
hopefully improve
our understanding of attitudes on fertility and par-
enthood.
We are currently extending the corpus by ex-
ploring the very interesting debate around the
“Fertility Day’s initiative” from the Italy’s Minis-
ter of Health Beatrice Lorenzin,
which had a re-
markable echo on social
media such as Twitter,
with a substantial number of (also sarcastic) mes-
sages with hashtag #fertilityday posted.
Acknowledgments
The authors gratefully acknowledge financial sup-
port
from the European Research Council
under
the European ERC Grant
Agreement
n.
StG-
313617 (SWELL-FER: Subjective Well-being and
Fertility, P.I. Letizia Mencarini).
References
Valerio Basile and Malvina Nissim.
2013.
Sentiment
analysis on italian tweets.
In Proceedings of the 4th
Workshop on Computational Approaches to Subjec-
tivity,
Sentiment and Social Media Analysis,
pages
100–107, Atlanta, Georgia. Association for Compu-
tational Linguistics.
Valerio Basile,
Andrea Bolioli,
Malvina Nissim,
Vi-
viana Patti,
and Paolo Rosso.
2014.
Overview of
the Evalita 2014 SENTIment
POLarity Classifica-
tion Task.
In Proc. of EVALITA 2014, pages 50–57,
Pisa, Italy. Pisa University Press.
Cristina Bosco,
Viviana Patti,
and Andrea Bolioli.
2013.
Developing corpora for sentiment
analysis:
The case of irony and senti-tut.
IEEE Intelligent Sys-
tems, 28(2):55–63, March.
Cristina Bosco,
Mirko Lai,
Viviana Patti, and Daniela
Virone.
2016.
Tweeting and being ironic in the de-
bate about a political reform:
the french annotated
corpus twitter-mariagepourtous.
In Proceedings of
CLIC_2016_Proceedings.indd 278
02/12/16 15.05
279
the Tenth International Conference on Language Re-
sources and Evaluation (LREC 2016), pages 1619–
1626, Portoroz, Slovenia. ELRA.
Davide Buscaldi
and Delia Iraz
´
u Hern
´
andez Far
´
ıas.
2015.
Sentiment analysis on microblogs for natural
disasters management:
A study on the 2014 genoa
floodings.
In Proceedings of the 24th International
Conference on World Wide Web,
WWW ’15 Com-
panion, pages 1185–1188. ACM.
A. Ceron, L. Curini, and S.M. Iacus.
2014.
Social Me-
dia e Sentiment Analysis: L’evoluzione dei fenomeni
sociali attraverso la Rete.
SxI - Springer for Inno-
vation / SxI - Springer per l’Innovazione.
Springer
Milan.
Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso,
Ekaterina Shutova,
Antonio Reyes,
and Jhon Barn-
den.
2015.
Semeval-2015 task 11:
Sentiment anal-
ysis of figurative language in Twitter.
In Proceed-
ings of the 9th International Workshop on Semantic
Evaluation (SemEval
2015),
pages 470–475,
Den-
ver, Colorado, USA. Association for Computational
Linguistics.
Delia Iraz
´
u Hern
´
andez Far
´
ıas, Viviana Patti, and Paolo
Rosso.
2016.
Irony detection in Twitter:
The role
of affective content.
ACM Transaction of
Internet
Technology, 16(3):19:1–19:24.
Minqing Hu and Bing Liu.
2004.
Mining and summa-
rizing customer reviews.
In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining,
KDD ’04,
pages
168–177, Seattle, WA, USA. ACM.
L.
Mitchell,
M.
R.
Frank,
K.
D.
Harris,
P.
S.
Dodds,
and C. M. Danforth.
2013.
The geography of happi-
ness:
Connecting Twitter sentiment and expression,
demographics, and objective characteristics of place.
PLoS ONE, 8(5), 05.
Saif
M.
Mohammad and Peter
D.
Turney.
2013.
Crowdsourcing a Word–Emotion Association Lex-
icon.
Computational Intelligence, 29(3):436–465.
Saif
M.
Mohammad,
Xiaodan Zhu,
Svetlana
Kir-
itchenko,
and Joel Martin.
2015.
Sentiment,
emo-
tion, purpose, and style in electoral tweets.
Informa-
tion Processing and Management, 51:480–499.
Preslav Nakov,
Alan Ritter,
Sara Rosenthal,
Fabrizio
Sebastiani,
and Veselin Stoyanov.
2016.
Semeval-
2016 task 4:
Sentiment
analysis
in twitter.
In
Proceedings of the 10th International Workshop on
Semantic Evaluation (SemEval-2016),
pages 1–18,
San Diego,
California,
June.
Association for Com-
putational Linguistics.
Finn
˚
Arup Nielsen.
2011.
A new ANEW: evaluation of
a word list for sentiment analysis in microblogs.
In
Proceedings of the ESWC2011 Workshop on ’Mak-
ing Sense of Microposts’: Big things come in small
packages,
volume 718 of
CEUR Workshop Pro-
ceedings,
pages 93–98,
Heraklion,
Crete,
Greece.
CEUR-WS.org.
Malvina Nissim and Viviana Patti.
2016.
Semantic
aspects in sentiment analysis.
In Fersini Elisabetta,
Bing Liu,
Enza Messina,
and Federico Pozzi,
edi-
tors,
Sentiment Analysis in Social Networks,
chap-
ter 3, pages 31–48. Elsevier.
James W. Pennebaker, Martha E. Francis, and Roger J.
Booth.
2001.
Linguistic Inquiry and Word Count:
LIWC 2001.
Mahway:
Lawrence Erlbaum Asso-
ciates, 71.
Christian Reimsbach-Kounatze.
2015.
The prolifera-
tion of big data and implications for official statistics
and statistical agencies.
Antonio Reyes,
Paolo Rosso,
and Tony Veale.
2013.
A multidimensional approach for detecting irony in
twitter.
Lang. Resour. Eval., 47(1):239–268, March.
Marco
Stranisci,
Cristina
Bosco,
Delia
Iraz
´
u Hern
´
andez Far
´
ıas,
and Viviana Patti.
2016.
Annotating sentiment and irony in the online italian
political debate on #labuonascuola.
In Proceedings
of
the
Tenth International
Conference
on Lan-
guage
Resources
and Evaluation (LREC 2016),
Paris,
France,
may.
European Language Resources
Association (ELRA).
Emilio Sulis, Mirko Lai, Manuela Vinai, and Manuela
Sanguinetti.
2015.
Exploring sentiment
in social
media and official
statistics:
a general
framework.
In Proceedings of
the 2nd International
Workshop
on Emotion and Sentiment
in Social
and Expres-
sive Media, co-located with AAMAS 2015, Istanbul,
Turkey, May 5, 2015., volume 1351 of CEUR Work-
shop Proceedings, pages 96–105. CEUR-WS.org.
Emilio Sulis, Iraz
´
u Hern
´
andez Far
´
ıas, Paolo Rosso, Vi-
viana Patti, and Giancarlo Ruffo.
2016.
Figurative
messages and affect in twitter: Differences between
#irony,
#sarcasm and #not.
Knowledge-Based Sys-
tems,
108:132 – 143.
New Avenues in Knowledge
Bases for Natural Language Processing.
Andranik Tumasjan, Timm Sprenger, Philipp Sandner,
and Isabell Welpe.
2010.
Predicting elections with
Twitter:
What
140 characters reveal
about
politi-
cal sentiment.
In International AAAI Conference on
Web and Social Media.
Sudha Verma,
Sarah Vieweg,
William Corvey,
Leysia
Palen, James Martin, Martha Palmer, Aaron Schram,
and Kenneth Anderson.
2011.
Natural
language
processing to the rescue?
extracting ”situational
awareness” tweets during mass emergency.
In Inter-
national AAAI Conference on Web and Social Me-
dia.
Deirdre Wilson.
2006.
The pragmatics of verbal irony:
Echo or pretence? Lingua, 116(10):1722 – 1743.
Emilio Zagheni
and Ingmar
Weber.
2005.
Demo-
graphic research with non-representative internet
data.
International Journal of Manpower, 36(1):13–
25.
CLIC_2016_Proceedings.indd 279
02/12/16 15.05
280
(Better than) State-of-the-Art PoS-tagging for Italian Texts
Fabio Tamburini
FICLIT - University of Bologna, Italy
fabio.tamburini@unibo.it
Abstract
English.
This paper
presents some ex-
periments for the construction of an high-
performance PoS-tagger for Italian using
deep neural
networks techniques (DNN)
integrated with an Italian powerful
mor-
phological
analyser.
The
results
ob-
tained by the proposed system on stan-
dard datasets taken from the EVALITA
campaigns show large accuracy improve-
ments when compared with previous sys-
tems from the literature.
Italiano.
Questo contributo presenta al-
cuni
esperimenti
per
la costruzione
di
un PoS-tagger
ad alte
prestazioni
per
l’italiano utilizzando reti
neurali
‘deep’
integrate con un potente analizzatore mor-
fologico.
I
risultati
ottenuti
sui
dataset
delle campagne EVALITA da parte del sis-
tema proposto mostrano incrementi di ac-
curatezza piuttosto rilevanti
in confronto
ai precedenti sistemi in letteratura.
1
Introduction
In recent years there were a large number of works
trying to push the accuracy of
the PoS-tagging
task forward using new techniques,
mainly from
the deep learning domain (Collobert et al.,
2011;
Søgaard,
2011;
dos Santos and Zadrozny,
2014;
Huang et al.,
2015;
Wang et al.,
2015;
Chiu and
Nichols, 2016).
All
these studies are mainly devoted to show
how to find the best
combination of
new neu-
ral network structures and character/word embed-
dings for reaching the highest
classification per-
formances, and typically present solutions that do
not
make any use of specific language resources
(e.g.
morphological analysers,
gazetteers,
guess-
ing procedures for unknown words, etc.).
This is,
in general,
a very desirable feature because it al-
lows for the production of tools not
tied to any
specific language,
but in various evaluation cam-
paigns,
at
least
for highly-inflected languages as
Italian,
the results showed quite clearly that
this
task would benefit from the use of specific and rich
language resources (Tamburini, 2007; Attardi and
Simi, 2009).
In this study,
still work-in-progress,
we set-up
a PoS-tagger for Italian able to gather the highest
classification performances by using any available
language resource and the most up-to-date DNN.
We used AnIta (Tamburini and Melandri,
2012),
one of the most powerful morphological analysers
for Italian, based on a wide lexicon (about 110.000
lemmas), for providing the PoS-tagger with a large
set of useful information.
2
Input features
The set of input features for each token is basically
formed by two different
components:
the word
embedding and some morphological information.
2.1
Word Embeddings
All the embeddings used in our experiments were
extracted from the CORIS corpus (Rossini Favretti
et al.,
2002),
a 130Mw synchronic reference cor-
pus for
Italian,
by using the tool
word2vec
1
(Mikolov et al., 2013).
We added two special to-
kens to mark the sentence beginning ‘
<
s
>
’ and
ending ‘
<
/s
>
’.
2.2
Morphological features
One of the most useful kind of information that in-
creases the performances of PoS-taggers concerns
the list of all possible tags for a single word-form.
Having a restricted list
of possibility enable the
tagger to reduce the search space and force it to
take reasonable decisions.
The results obtained
1
https://code.google.com/archive/p/word2vec/
CLIC_2016_Proceedings.indd 280
02/12/16 15.05
281
in past
PoS-taggers evaluations on Italian agree
in suggesting that powerful morphological analy-
sers based on large lexica are invaluable resources
to increase tagger
accuracy.
For
these reasons,
we extended the word embeddings computed in
a completely unsupervised way by concatenating
to them a vector containing the possible PoS-tags
provided by the AnIta analyser.
This tool is also
able to identify, through the use of simple regular
expressions,
numbers,
dates,
URLs,
emails,
etc.,
and assign them the proper tag(s).
2.3
Unknown words handling and Sentence
padding
The source of most tagging errors is certainly the
presence of the so called ‘unknown words’, word-
forms for which the tagger did not receive any in-
formation during the training phase.
A morpho-
logical analyser based on a large lexicon could cer-
tainly alleviate this problem providing information
also for word-forms not belonging to the training
set, but there are large classes of tokens that cannot
be successfully handled by the analyser, for exam-
ple proper names, foreign words, etc.
In a
previous
work (Tamburini,
2007b)
we
showed that using such a powerful morphological
analyser, the word-forms not covered by it in real
texts belongs at 95% to the class of proper names,
adjectives and common nouns and a simple heuris-
tic correctly assigns most
of
the cases.
In this
way AnIta always provides one or more PoS-tag
hypothesis for each word-form that can be trans-
formed into a binary vector with 1s in correspon-
dence of possible PoS-tags and 0s otherwise,
but
if the word-form did not have a computed embed-
ding, the first part of the input features would not
be defined.
For solving such problem,
instead of
using the common solution of assigning a random
vector to all unknown words, we averaged all the
embeddings of the other word presenting exactly
the same combination of possible PoS-tags.
It is also a common practice to pad sentences,
at
the beginning and at
the end,
using random
vectors,
but
we,
instead,
used the real
embed-
dings computed for the special tokens ‘
<
s
>
’ and
‘
<
/s
>
’,
added for this purpose,
with the respec-
tive tag ‘BoS’ and ‘EoS’. Due to the internal struc-
turing of the used tensor manipulating application
(see later),
we were forced to add also an out-of-
sentence vector to pad sentences to their maximal
length, and the correspondent tag OoS.
2.4
Data structuring
We experimented two different ways of structuring
the input features for processing:
•
Win:
this mode of organising input
data is
based on a sliding window that starts from the
beginning of each sentence and concatenates
word feature vectors into one single vector.
Padding is inserted at sentence borders.
•
Seq: each sentence is managed as one single
sequence padded at the borders.
Each network experimented in this study uses
one of these two data structuring type.
3
(Deep) Learning Blocks
All
the experiments presented in this paper has
been performed using Keras
2
a “a minimalist,
highly modular neural networks library, written in
Python and capable of running on top of either
TensorFlow or Theano”,
two widely used tensor
manipulation libraries. Keras provides some basic
neural network blocks as well as different learn-
ing procedures for the desired network configura-
tion and simple tools for writing new blocks.
In
our experiments we used some of them,
namely
multilayer-perceptrons
(MLP)
and Long Short-
Term Memory (LSTM), and we wrote a new block
to handle Conditional Random Fields (CRF).
MLP are simple feedforward neural
networks
with one or more fully-connected hidden layers.
We obtained maximum performances using only
one hidden layer.
LSTM networks (Hochreiter and Schmidhuber,
1997; Graves and Schmidhuber, 2005) are a kind
of recurrent neural network which received a lot
of attention in recent years due to their ability of
produce good classification results for sequence
problems. Their property of preventing the vanish-
ing (and exploding) gradient problem that affects
standard recurrent neural networks made them the
default choice for solving sequence classification
problems inside the DNN framework.
Usually
this kind of units are arranged to form a bidirec-
tional chain (BiLSTM) for gathering information
both from the past and from the future of the in-
put data sequence, a very desirable issue for such
kind of classification problems.
In all our experi-
ments using BiLSTM we obtained maximum per-
formances by stacking two layers of them,
with
2
https://github.com/fchollet/keras/tree/master/keras
CLIC_2016_Proceedings.indd 281
02/12/16 15.05
282
a dropout layer after each of them (Srivastava et
al.,
2014),
and a final
dense softmax layer,
or a
time-distributed-dense softmax layer,
feeded by
the BiLSTM output.
Linear
CRFs
are
the
simpler
Probabilistic
Graphical Model (PGM) and it has been success-
fully used in NLP for sequence classification prob-
lems (Lafferty et al., 2001).
We did some experi-
ments stacking them after the softmax layer.
Figure 1 shows the most complex DNN struc-
ture used in out experiments.
Figure 1: The most complex DNN used in our ex-
periments.
4
Experiments
All
the experiments
presented in this
paper
to
test
the effectiveness of the proposed system re-
fer to two evaluation campaigns organised inside
the EVALITA
3
framework.
In particular, in 2007
and 2009 were organised specific task to test Ital-
ian PoS-taggers performances.
4.1
The EVALITA 2007 evaluation
Two separate data sets were provided:
the Devel-
opment
Set
(DS),
composed of 133,756 tokens,
was used for system development and for the train-
ing phase,
while a Test
Set
(TS),
composed of
17,313 tokens,
was used as a reference for sys-
tems evaluation.
Both contain various documents
belonging mainly to journalistic and narrative gen-
res,
with small sections containing academic and
legal/administrative prose.
Each participant
was
allowed to use any available resource or
could
freely induce it from the training data.
3
http://www.evalita.it/
The original PoS-tagging task involved two dif-
ferent tagsets,
but our experiments used only the
tags and the annotation named ‘EAGLES-like’.
The evaluation metrics were based on a token-
by-token comparison and only one tag was al-
lowed for each token.
The EVALITA metric con-
sidered in this study is the Tagging Accuracy, de-
fined as the number
of
correct
PoS-tag assign-
ments divided by the total number of tokens in the
TS. See (Tamburini, 2007) for further details.
4.2
The EVALITA 2009 evaluation
The DS consisted in 113895 word forms (already
divided in a training set - 108,874 tokens - and a
validation set - 5021 tokens).
The TS consisted of
5066 word forms.
The training set is formed by
newspaper articles from ‘La Repubblica’,
while
the validation and test set contain documents ex-
tracted from the Italian Wikipedia.
This test the
degree of system adaptation to new domains.
The organisers
evaluated the results
using a
coarse grained (37 tags) and a morphed (336 tags)
tagsets inserted in a closed/open task framework,
but
in this study all
the results refer to the open
task (one can use external resources) on the coarse
grained tagset.
The evaluation metric is the same
described before in section 4.1.
See (Attardi and
Simi, 2009) for further details.
4.3
Hyper-Parameters
Considering the large number of hyper-parameters
involved in the whole procedure, we did not test all
the possible combinations;
we used,
instead,
the
most common set-up of parameters gathered from
the literature. Table 1 outlines the whole set-up for
the unmodified hyper-parameters.
word2vec Embed.
Feature extraction
Hyperpar.
Value
Hyperpar.
Value
type
SkipGr.
window
5
size
100
Learning Params.
(1/2) win.
5
batch (win)
1/4*NU
neg. sampl.
25
batch (seq)
1
sample
1e-4
Opt. Alg.
Adam
iter
15
Loss Func.
Categ.CE
Table 1:
Unmodified hyper-parameters and algo-
rithms used in our experiments.
NU means the
number of hidden or LSTM units per layer (the
same for all layers).
For Adam refer to (Kingma
and Ba, 2015).
CLIC_2016_Proceedings.indd 282
02/12/16 15.05
283
4.4
The Early Stopping Drama
There are some interesting studies (Bengio, 2012;
Prechelt, 2012) dealing with the problem of stop-
ping the learning process at
the right
point;
this
issue is known as the ‘early stopping’ problem.
Choosing the correct
epoch to stop the learning
process helps avoiding overfitting on the training
set
and usually produces systems exhibiting bet-
ter generalisations. But, how to choose the correct
epoch is not simple. The suggestion given in vari-
ous studies on this topic is to consider a validation
set and stop the learning process when the perfor-
mances on this set do not increase anymore or even
decrease, a clear hint of overfitting.
The usual
way to set
up an experiment
fol-
lowing this suggestions involves splitting the gold
standard into three different
instance sets:
the
training set, for training, the validation set, to de-
termine the stopping point, and the test set to eval-
uate the system.
However, we are testing our sys-
tems on real evaluation data that has been already
split by the organisers into development and test
set.
Thus, we can divide the development set into
training/validation set
for
optimising the hyper-
parameters and define the stopping epoch, but, for
the final evaluation, we would like to train the final
system on the complete development set to adhere
to the evaluation constraints and to benefit
from
using more training data.
Having two different training procedures for the
optimisation and evaluation phases leads to a more
complex procedure for determining the stopping
epoch.
Moreover, the typical accuracy profile for
DNN systems is not
smooth and oscillate heav-
ily during training.
To avoid any problem in de-
termining the stopping point we smoothed all the
profiles using a bezier spline.
The procedure we
adopted to determine the stopping epoch is (please
look at Fig.
2):
(1) find the first maximum in the
validation smoothed profile - A; (2) find the corre-
sponding value of accuracy on the smoothed train-
ing profile - B; (3) find the point in the smoothed
development set profile having the same accuracy
as in B - C; (4) select the epoch corresponding at
point C as the stopping epoch - D.
4.5
Results
Table 2 outlines the systems’ accuracies for dif-
ferent
configurations for both datasets.
We can
observe that by using AnIta morphological infor-
mation,
as well
as all
the techniques described
Figure 2: The early stopping procedure.
in section 2.3,
improves the systems’ results by
more than 1%.
Considering the data structuring
described in section 2.4,
the management
of an
entire sentence as a complete sequence allows re-
current configurations to work with larger contexts
producing better results. Adding a CRF layer after
the BiLSTM seems to slightly improve the perfor-
mances, but not in a significant way.
SYSTEM
TA
Notes
E07
E09
MLP-256
96.45
95.57
Win=5
MLP-256
97.75
96.84
M,Win=5
2-BiLSTM-256
98.12
97.30
M,Win=5
2-BiLSTM-256
98.14
97.45
M,Seq
2-BiLSTM-256-CRF
98.18
97.48
M,Seq
Table 2:
Tagging accuracies (TA)
for
different
configurations for both datasets.
(‘M’ marks the
use of AnIta morphological information).
In Table 3 we can see our best system perfor-
mances,
namely AnIta-BiLSTM-CRF,
compared
with the three best
systems
of
the considered
EVALITA campaigns.
As you can see,
in both
cases the proposed system ranked first improving
the scoring by large quantities.
5
Conclusions
The proposed system for
PoS-tagging,
integrat-
ing DNNs and a powerful morphological analyser,
exhibited very good accuracy results when ap-
plied to standard Italian evaluation datasets from
the EVALITA campaigns.
The information from
AnIta proved to be crucial to reach such accuracy
values as well as stacked BiLSTM networks pro-
cessing entire sentence sequences.
CLIC_2016_Proceedings.indd 283
02/12/16 15.05
284
EVALITA 2007
SYSTEM
TA
AnIta-BiLSTM-CRF
98.18
FBKirst Zanoli
98.04
UniTn Baroni
97.89
ILCcnrUniPi Lenci
97.65
EVALITA 2009
AnIta-BiLSTM-CRF
97.48
UniPi SemaWiki 2
97.03
UniPi SemaWiki 1
96.73
UniPi SemaWiki 4
96.67
Table 3:
Participants’ results with respect to Tag-
ging Accuracy (TA) at EVALITA 2007 and 2009.
We have to further test
different
DNN config-
urations and their integration with other kind of
PGMs as well as make more experiments with dif-
ferent hyperparameters.
References
Giuseppe Attardi
and Maria Simi.
2009.
Overview
of the EVALITA 2009 Part-of-Speech Tagging Task.
In Proc. of Workshop Evalita 2009.
Yoshua Bengio.
2012.
Practical Recommendations for
Gradient-Based Training of Deep Architectures.
In
Gr
´
egoire Montavon,
Genevi
`
eve B.
Orr,
and Klaus-
Robert M
¨
uller,
editors,
Neural Networks:
Tricks of
the Trade: Second Edition, pages 437–478. Springer
Berlin Heidelberg, Berlin, Heidelberg.
Jason Chiu and Eric Nichols.
2016.
Sequential Label-
ing with Bidirectional
LSTM-CNNs.
In Proc.
In-
ternational Conf. of Japanese Association for NLP,
pages 937–940.
Ronan Collobert, Jason Weston, L
´
eon Bottou, Michael
Karlen,
Koray Kavukcuoglu,
and Pavel
Kuksa.
2011.
Natural
language processing (almost) from
scratch.
J. Mach. Learn. Res., 12:2493–2537.
Cicero dos
Santos
and Bianca
Zadrozny.
2014.
Learning character-level
representations
for
part-
of-speech tagging.
In Proc.
of
the 31st
Interna-
tional Conference on Machine Learning, JMLR, vol-
ume 32. JMLR W&CP.
Alex Graves and J
¨
urgen Schmidhuber.
2005.
Frame-
wise phoneme classification with bidirectional lstm
and other neural network architectures.
Neural Net-
works, 18(5-6):602–610.
Sepp Hochreiter
and J
¨
urgen Schmidhuber.
1997.
Long short-term memory.
Neural
Computation,
9(8):1735–1780.
Zhiheng Huang, Wei Xu, and Kai Yu.
2015.
Bidirec-
tional
LSTM-CRF Models for Sequence Tagging.
ArXiv e-prints, 1508.01991.
D.P. Kingma and J.L. Ba.
2015.
Adam:
a method for
stochastic optimization.
In Proc. International Con-
ference on Learning Representations - ICLR., pages
1–13.
J. Lafferty, A. McCallum, and F. Pereira.
2001.
Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data.
In Proc. 18th
International
Conf.
on Machine Learning,
pages
282–289.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean.
2013.
Efficient Estimation of Word Repre-
sentations in Vector Space.
In Proc. of Workshop at
ICLR.
Lutz Prechelt.
2012.
Early Stopping — But When? In
Gr
´
egoire Montavon,
Genevi
`
eve B.
Orr,
and Klaus-
Robert M
¨
uller,
editors,
Neural Networks:
Tricks of
the Trade:
Second Edition,
pages 53–67.
Springer
Berlin Heidelberg, Berlin, Heidelberg.
Rema Rossini Favretti, Fabio Tamburini, and Cristiana
De Santis.
2002.
CORIS/CODIS:
A corpus of
written Italian based on a defined and a dynamic
model.
In Andrew Wilson,
Paul Rayson,
and Tony
McEnery,
editors,
A Rainbow of Corpora:
Corpus
Linguistics and the Languages of the World,
pages
27–38. Lincom-Europa, Munich.
Anders Søgaard.
2011.
Semi-supervised condensed
nearest
neighbor
for
part-of-speech tagging.
In
Proc. of the 49th Annual Meeting of the Association
for Computational
Linguistics:
Human Language
Technologies, pages 48–52, Portland, Oregon, USA.
Nitish Srivastava,
Geoffrey Hinton,
Alex Krizhevsky,
Ilya Sutskever,
and Ruslan Salakhutdinov.
2014.
Dropout:
A simple way to prevent neural networks
from overfitting.
Journal of Machine Learning Re-
search, 15:1929–1958.
Fabio Tamburini and Matias Melandri.
2012.
AnIta:
a powerful
morphological
analyser for Italian.
In
Proc. 8th International Conference on Language Re-
sources and Evaluation - LREC 2012,
pages 941–
947, Istanbul.
Fabio Tamburini.
2007.
EVALITA 2007:
the Part-
of-Speech Tagging Task.
Intelligenza Artificiale,
IV(2):4–7.
Fabio Tamburini.
2007b.
CORISTagger:
a high-
performance PoS tagger for Italian. Intelligenza Ar-
tificiale.
Intelligenza Artificiale, IV(2):14–15.
Peilu Wang,
Yao Qian,
Frank.
K Soong,
Lei He,
and
Hai
Zhao.
2015.
A Unified Tagging Solution:
Bidirectional LSTM Recurrent Neural Network with
Word Embedding.
ArXiv e-prints, 1511.00215.
CLIC_2016_Proceedings.indd 284
02/12/16 15.05
285
Language resources for Italian: towards the development of a corpus of
annotated Italian multiword expressions
Shiva Taslimipoor
University of Wolverhampton, UK
shiva.taslimi@wlv.ac.uk
Anna Desantis, Manuela Cherchi
University of Sassari, Italy
annadesantis_91@libero.it,
manuealacherchi82@gmail.com
Ruslan Mitkov
University of Wolverhampton, UK
r.mitkov@wlv.ac.uk
Johanna Monti
"L’Orientale" University of Naples, Italy
jmonti@unior.it
Abstract
English.
This paper
describes the first
resource annotated for multiword expres-
sions (MWEs) in Italian.
Two versions of
this dataset
have been prepared:
the first
with a fast
markup list
of out-of-context
MWEs, and the second with an in-context
annotation,
where the MWEs are entered
with their contexts.
The paper also dis-
cusses annotation issues and reports the
inter-annotator
agreement
for
both types
of
annotations.
Finally,
the results
of
the first exploitation of the new resource,
namely the automatic extraction of Italian
MWEs, are presented.
Italiano.
Questo
contributo
descrive
la prima risorsa italiana annotatata con
polirematiche.
Sono state preparate due
versioni
del
dataset:
la prima con una
lista di
polirematiche senza contesto,
e
la seconda con annotazione in contesto.
Il
contributo
discute
le
problematiche
emerse durante l’annotazione e riporta
il
grado di
accordo tra annotatori
per
entrambi
i
tipi
di
annotazione.
Infine
vengono presentati
i
risultati
del
primo
impiego
della
nuova
risorsa,
ovvero
l’estrazione automatica di
polirematiche
per l’italiano.
1
Rationale
Multiword expressions (MWEs) are a pervasive
phenomenon in language with their computational
treatment being crucial for users and NLP appli-
cations alike (Baldwin and Kim,
2010;
Granger
and Meunier, 2008; Monti et al., 2013; Monti and
Todirascu, 2015; Seretan and Wehrli, 2013). How-
ever,
despite being desiderata for linguistic anal-
ysis and language learning,
as well
as for train-
ing and evaluation of NLP tasks such as term ex-
traction (and Machine Translation in multilingual
scenarios), resources annotated with MWEs are a
scarce commodity (Schneider et al., 2014b).
The
need for such types of resources is even greater for
Italian which does not benefit from the variety and
volume of resources as does English.
This paper outlines the development
of a new
language resource for Italian, namely a corpus an-
notated with Italian MWEs of a particular class:
verb-noun expressions such as fare riferimento,
dare luogo and prendere atto.
Such colloca-
tions are reported to be the most frequent class of
MWEs and of high practical importance both for
automatic translation and language learning.
To
the best of our knowledge, this is the first resource
of this kind in Italian.
The development of this corpus is part of a mul-
tilingual project addressing the challenge of com-
putational treatment of MWEs.
It covers English,
Spanish,
Italian and French and its goal is to de-
velop a knowledge-poor
methodology for
auto-
matically identifying MWEs and retrieving their
translations (Taslimipoor et al., 2016) for any pair
of languages.
The developed methodology will
be used for
Machine Translation and multilin-
gual dictionary compilation, and also in computer-
aided tools to support the work of language learn-
ers and translators.
Two versions of the above resource have been
produced.
The
first
version consists
of
lists
of
MWEs annotated out-of-context
with a view
to performing fast
evaluation of
the developed
methodology (out-of-context mark-up).
The sec-
ond version consists of
annotated MWEs along
with their
concordances (in-context
annotation).
CLIC_2016_Proceedings.indd 285
02/12/16 15.05
286
The latter type of annotation is time-consuming,
but provides the contexts for the MWEs annotated.
2
Annotation of MWEs: out-of-context
mark-up and in-context annotation
After
more than two decades of
computational
studies on MWEs, the lack of a proper gold stan-
dard is still an issue.
Lexical resources like dic-
tionaries have limited coverage of these expres-
sions (Losnegaard et
al.,
2016) and there is also
no proper tagged corpus of MWEs in any language
(Schneider et al., 2014b).
Most
previous
studies
on the computational
treatment
of
MWEs have focused on extracting
types (rather than tokens)
1
of MWEs from corpora
(Ramisch et al.,
2010;
Villavicencio et al.,
2007;
Rondon et al., 2015; Salehi and Cook, 2013).
The
widely-used toolboxes of MWEToolkit (Ramisch
et al.,
2010) or Xtract (Smadja,
1993) extract ex-
pressions if their statistical occurrences represent
the likelihood of them being MWEs.
The evalu-
ation for the type-based extraction of MWEs has
been mostly performed against
a dictionary (de
Caseli
et
al.,
2010),
lexicon (Pichotta and DeN-
ero, 2013) or list of human-annotated expressions
(Villavicencio et
al.,
2007).
However,
there are
some examples like the expression have a baby,
which in exactly the same form and structure,
might be an MWE (meaning to give birth ) in some
contexts and a literal expression in others.
As for the automatic identification of the tokens
of MWEs,
Fazly et al.
(2009) make use of both
linguistic properties and the local context,
in de-
termining the class of an MWE token.
They re-
port
an unsupervised approach to identifying id-
iomatic and literal usages of an expression in con-
text.
Their method is evaluated on a very small
sample of expressions in a small
portion of the
British National Corpus (BNC), which were anno-
tated by humans.
Schneider et al.
(2014a) devel-
oped a supervised model whose purpose is to iden-
tify MWEs in context.
Their methodology results
in a corpus of automatically annotated MWEs.
It
is not clear,
however,
if the methodology is able
to tag one specific expression as an MWE in one
context and non-MWE in another. The PARSEME
shared task
2
is also devoted to annotating verbal
1
Type refers to the canonical form of an expression, while
token refers to each instance (usage) of the expression in any
morphological form in text.
2
http://typo.uni-konstanz.de/parseme/index.php/2-general/
142-parseme-shared-task-on-automatic-detection-of-verbal-mwes
MWEs in several
languages.
The shared task,
while having interesting discussions on the area,
has embarked upon the labour-intensive annota-
tion of verbal MWEs.
Since there is no list
of verb-noun MWEs in
Italian,
we first
automatically compile a list
of
such expressions,
to be annotated by human ex-
perts.
This is based on previous attempts at
ex-
tracting a lexicon of MWEs (as in (Villavicencio,
2005)). Annotators are not provided with any con-
text and hence the task is more feasible in terms
of time.
Human annotators are asked to label the
expressions as MWEs only if they have sufficient
degrees of idiomaticity.
In other words, a Verb +
Noun MWEs does not convey literal meaning in
that the verb is delexicalised.
However,
we believe that idiomaticity is not a
binary property; rather it is known to fall on a con-
tinuum from completely semantically transparent,
or
literal,
to entirely opaque,
or
idiomatic (Fa-
zly et al.,
2009).
This makes the task of out-of-
context marking-up of the expression more chal-
lenging for annotators,
since they have to pick a
value according to all
the possible contexts of a
target expression. This ambiguity and the fact that
there are many expressions that in some contexts
are MWEs and in some contexts not, prompted us
to initiate a subsequent annotation where MWEs
are tagged in their contexts.
The idea is to ex-
tract the concordances around all the occurrences
of a Verb + Noun expression and provide annota-
tors with these concordances in order to be able
to decide the degree of idiomaticity of the specific
verb-noun expression.
We compare the reliability
of the in-context and out-of-context annotations by
way of the agreement between annotators.
2.1
Experimental expressions
Highly polysemous verbs,
such as give and take
in English and fare and dare in Italian widely par-
ticipate in Verb+Noun MWEs, in which they con-
tribute a broad range of figurative meanings that
must
be recognised (Fazly et
al.,
2007).
We fo-
cus on four mostly frequent
Italian verbs:
fare,
dare, prendere and trovare.
We extract all the oc-
currences of these verbs when followed by any
noun, from the itWaC corpus (Baroni and Kilgar-
riff,
2006),
using SketchEngine (Kilgarriff et al.,
2004).
For the first experiment all the Verb+Noun
types are extracted when the verb is lemmatised;
and for
the second experiment
all
the concor-
CLIC_2016_Proceedings.indd 286
02/12/16 15.05
287
dances of these verbs when followed by a noun
are generated.
2.2
Out-of-context mark-up of Verb+Noun(s)
The extraction of
Verb+Noun candidates of
the
four verbs in focus and the removal of the expres-
sions with frequencies lower than
20
,
results in a
dataset of
3
,
375
expressions.
Two native speak-
ers annotated every candidate expression with 1
for an MWE if the expression was idiomatic and
with 0 for a non-MWE if the expression was lit-
eral.
We have also defined the tag 2 for the ex-
pressions that in some contexts behave as MWEs
and in others do not,
e.g.
dare frutti,
which has
a literal usage that means to produce fruits but in
some contexts means to produce results and is an
MWE in these contexts. While this out-of-context
‘fast
track’ annotation procedure saves time and
yields a long list
of marked-up expressions,
an-
notators often feel uncomfortable due to the lack
of context.
The information about the agreements
between annotators in terms of
Kappa
is shown
in Table 2 and is compared with the in-context an-
notation of MWEs as explained in Section 2.3.
2.3
Annotating Verb+Noun(s) in context
We design an annotation task, in which we provide
a sample of all usages of any type of Verb+Noun
expression to be annotated.
For this purpose,
we
employ the SketchEngine to list
all
the concor-
dances of each verb when it is followed by a noun.
Concordances include the verb in focus with al-
most
ten words before and ten words after that.
The SketchEngine reports only
100
,
000
concor-
dances for each query.
Among them, we filter out
the concordances that include Verb+Noun expres-
sions with frequencies lower than
50
and we ran-
domly select
10%
of the concordances for each
verb.
As a result,
there are
30
,
094
concordances
to be annotated.
The two annotators annotate all
usages of Verb+Noun expressions in these concor-
dances, considering the context that the expression
occurred in, marking up MWEs with
1
and expres-
sions which are not
MWEs,
with
0
.
Table 1 re-
ports on the details of annotation tasks and Table
2 shows the agreement details for them.
2.4
Discussion
As seen in Table 2, the inter-annotator agreement
is significantly higher when annotating the expres-
sions in context.
One of the main causes of dis-
agreements in out-of-context
annotation is con-
Table 1:
Annotation details (A: Annotator)
Annotation
tag 0
tag 1
tag 2
task
A
(MWE)
Out-of-context
1
st
2,491
792
92
2
nd
2,112
1,127
136
In-context
1
st
10,478
19,616
-
2
nd
9,058
21,036
-
Table 2:
Inter-annotator agreement
Annotation
Kappa
Observed
task
Agreement
Out-of-context
0.40
0.73
In-context
0.65
0.85
cerned with abstract nouns.
The annotation of ex-
pressions composed of a verb followed by a noun
with an abstract
meaning is a more complicated
process as the candidate expression may carry a
figurative meaning.
Each annotator uses their in-
tuition to annotate them and it
leads to random
tags for these expression (e.g.
fare notizia,
dare
identità, prendere possesso) when they are out-of-
context.
However, in the case of in-context anno-
tation,
concordances composed of abstract nouns
have been annotated in the majority of cases with
1 by both annotators.
In-context
annotation is also very helpful
for
annotating expressions with both idiomatic and
literal
meanings.
An interesting observation,
re-
ported in Table 3,
is related to the number of ex-
pressions that are detected with the two different
usages of idiomatic and non-idiomatic, in context.
Table 3:
Statistics on the in-context annotation
0 tagged
1 tagged
context
depending
1
st
annotator
924
195
530
2
nd
annotator
696
424
529
As can be seen in Table 3,
3
among the
1
,
649
types of expressions in concordances,
530
(
32%
)
of them could be MWEs in some context and non-
MWEs in others (context-depending),
according
to the first annotator. This annotator has annotated
only
3%
of the expressions with tag ‘2’ without
context.
3
Note that the numbers in Table 3 cannot be interpreted
to validate agreement between annotators, i.e.
no conclusion
about agreement can be derived from 3.
CLIC_2016_Proceedings.indd 287
02/12/16 15.05
288
3
First use of the MWE resource:
comparative evaluation of the
automatic extraction of Italian MWEs
In our multilingual project (see Section 1) we re-
gard the automatic translation of MWEs as a two-
stage process.
The first stage is the extraction of
MWEs in each of the languages; the second stage
is a matching procedure for the extracted MWEs in
each language which proposes translation equiv-
alents.
In this study the extraction of MWEs is
based on statistical association measures (AMs).
These measures have been proposed to deter-
mine the degree of compositionality, and fixedness
of expressions.
The more compositional or fixed
expressions are, the more likely it is that they are
MWEs (Evert, 2008; Bannard, 2007).
According
to Evert (2008), there is no ideal association mea-
sure for all
purposes.
We aim to evaluate AMs
as a baseline approach against the annotated data
which we prepared.
We focus on a selection of
five AMs which have been more widely discussed
to be the best measures to identify MWEs.
These
are:
MI3 (Oakes,
1998),
log-likelihood (Dun-
ning, 1993), T-score (Krenn and Evert, 2001), log-
Dice (Rychlý, 2008) and Salience (Kilgarriff et al.,
2004) all as defined in SketchEngine. We compare
the performance of these AMs and also frequency
of occurrence (Freq) as the sixth measure to rank
the candidate MWEs.
We evaluate the effect
of
these measures in ranking MWEs on both kinds of
datasets.
3.1
Experiments on type-based extraction of
MWEs
In the first experiment, the list of all extracted Verb
+ Noun combinations (as explained in Section 2.1)
are ranked according to the above measures that
are computed from itWaC as a reference corpus.
To perform the evaluation against
the list
of an-
notated expressions, we process all 2,415 expres-
sions for which the annotators agreed on tags 0
or 1.
After ranking the expressions by the mea-
sures,
we examine the retrieval
performance of
each measure by computing the 11-point Interpo-
lated Average Precision (11-p IAP).
This reflects
the goodness of a measure in ranking the relevant
items (here, MWEs) before the irrelevant ones. To
this end,
the interpolated precision at
the 11 re-
call values of 0, 10%, ..., 100% is calculated.
As
detailed in Manning et
al.
(2008),
the interpo-
lated precision at a certain recall level, r, is defined
Table 4:
11-p IAP
for
ranking MWEs
using different AMs
AMs
11-p IAP
Freq
0.49
MI3
0.51
log-likelihood
0.49
Salience
0.49
log-dice
0.48
T-Score
0.49
Table 5:
Accuracy of
AMs in classifying us-
ages of Verb+Noun(s).
AMs
Accuracy
Freq
0.72
MI3
0.68
log-likelihood
0.72
Salience
0.69
log-dice
0.67
T-Score
0.69
as the highest precision found for any recall level
r

≥
r
.
The average of these 11 points is reported
as 11-p IAP in Table 4.
As can be seen in Table 4,
the selected asso-
ciation measures generally perform with similar
performance in ranking this type of MWEs,
with
MI
3
performing slightly better than others.
3.2
Experiments on token-based
identification of MWEs
In the second experiment,
we seek to establish
the effect of these measures on identifying the us-
ages of
MWEs in our
dataset
of
in-context
an-
notations.
We set
a threshold for
each score
that
we have computed for
Verb+Noun expres-
sion types.
By setting thresholds we compute the
classification accuracy of
the measures to iden-
tify MWEs among the usages of Verb+Noun ex-
pressions in a corpus. Specifically, each candidate
of a Verb+Noun in the concordances is automat-
ically tagged as an MWE if its lemmatised form
has a score higher than the threshold, and as a non-
MWE, otherwise.
For each measure, we compute
the arithmetic mean (average) of all the values of
that
measure for all
expressions,
and set
the re-
sulted average value as a threshold.
The
accuracies
of
classifying the
candidate
Verb+Noun expressions are computed based on
the human annotations of the concordances and
are shown in Table 5.
The classification accura-
cies of AMs are also very close to each other (see
Table 5);
however,
this time
Log
-
likelihood
and
F req
fare slightly better than others in classifying
tokens of Verb+Noun expressions.
3.3
Usage-related features
Our new resource of concordances contains use-
ful linguistic information related to usages of ex-
pressions and as such important
features can be
CLIC_2016_Proceedings.indd 288
02/12/16 15.05
289
extracted from the resource to help identifying
MWEs.
One of these features can be obtained
from the statistics of different possible inflections
of the verb component of an expression. Based on
the premise of the fixedness of MWEs, we expect
that the verb component of a verb-noun MWE oc-
curs only in a limited number of inflections.
We
implement this feature by dividing the frequency
of occurrences of each expression by the number
of inflections that the verb component occurs in.
Note that to count the number of different inflec-
tions of the verb component,
we rely on the sub-
corpus of concordances that we gathered.
We evaluate this approach only on 1,077 ex-
pressions that
occur in concordances.
We rank
the expressions according to this newly computed
score and we call this score, which depends on the
inflection varieties,
INF-VAR.
For all
verbs,
the
INF-VAR performs comparably to Frequency in
ranking MWEs higher than non-MWEs,
but
for
the verb trovare, we obtain better 11-p IAP using
this score than by using Frequency (see Table 6).
Table 6:
Performance of new scores in ranking
MWEs in terms of 11-p IAP.
total
trovare
Frequency
0.57
0.44
INF-VAR
0.58
0.48
4
Conclusions and future work
In this paper, we outline our work towards a gold-
standard dataset which is tagged with Italian verb-
noun MWEs along with their contexts.
We show
the reliability of this dataset
by its considerable
inter-annotator agreement compared to the moder-
ate inter-annotator agreement on annotated verb-
noun expressions presented without context.
We
also report
the results of automatic extraction of
MWEs using this dataset as a gold-standard.
One
of the advantages of this dataset is that it includes
both 0-tagged and 1-tagged tokens of expressions
and it can be used for classification and other sta-
tistical NLP approaches.
In future work,
we are
interested in extracting context features from con-
cordances in this resource to automatically recog-
nise and classify the expressions that are MWEs in
some contexts but not MWEs in others.
References
Timothy Baldwin and Su Nam Kim.
2010.
Multi-
word expressions.
In Handbook of
Natural
Lan-
guage Processing,
second edition.,
pages 267–292.
CRC Press.
Colin Bannard.
2007.
A measure of syntactic flexibil-
ity for automatically identifying multiword expres-
sions in corpora.
In Proceedings of
the Workshop
on a Broader Perspective on Multiword Expressions,
pages 1–8. Association for Computational Linguis-
tics.
Marco Baroni
and Adam Kilgarriff.
2006.
Large
linguistically-processed web corpora for
multiple
languages.
In Proceedings of the Eleventh Confer-
ence of the European Chapter of the Association for
Computational Linguistics: Demonstrations, EACL
’06,
pages 87–90,
Stroudsburg,
PA, USA. Associa-
tion for Computational Linguistics.
Helena Medeiros de Caseli, Carlos Ramisch, Maria das
Graças Volpe Nunes, and Aline Villavicencio.
2010.
Alignment-based extraction of
multiword expres-
sions.
Language resources and evaluation,
44(1-
2):59–77.
Ted Dunning.
1993.
Accurate methods
for
the
statistics of surprise and coincidence.
COMPUTA-
TIONAL LINGUISTICS, 19(1):61–74.
Stefan Evert.
2008.
Corpora and collocations.
In Cor-
pus Linguistics.
An International
Handbook,
vol-
ume 2, pages 1212–1248.
Afsaneh Fazly,
Suzanne Stevenson,
and Ryan North.
2007.
Automatically learning semantic knowledge
about
multiword predicates.
Language Resources
and Evaluation, 41(1):61–89.
Afsaneh Fazly,
Paul
Cook,
and Suzanne Stevenson.
2009.
Unsupervised type and token identification of
idiomatic expressions.
Computational
Linguistics,
35(1):61–103.
Sylviane Granger and Fanny Meunier.
2008.
Phrase-
ology:
an interdisciplinary perspective.
John Ben-
jamins Publishing Company.
Adam Kilgarriff, Pavel Rychlý, Pavel Smrz, and David
Tugwell.
2004.
The sketch engine.
In EURALEX
2004, pages 105–116, Lorient, France.
Brigitte Krenn and Stefan Evert.
2001.
Can we do
better than frequency?
a case study on extracting
pp-verb collocations.
Proceedings of the ACL Work-
shop on Collocations, pages 39–46.
Gyri
Smørdal
Losnegaard,
Federico
Sangati,
Carla
Parra
Escartín,
Agata
Savary,
Sascha
Bargmann,
and Johanna Monti.
2016.
Parseme
survey on mwe
resources.
In Proceedings
of
the Tenth International
Conference on Language
Resources
and Evaluation (LREC 2016),
Paris,
France. European Language Resources Association
(ELRA).
CLIC_2016_Proceedings.indd 289
02/12/16 15.05
290
Christopher
D Manning,
Prabhakar
Raghavan,
and
Hinrich Schütze.
2008.
Introduction to information
retrieval.
Cambridge University Press.
Johanna Monti and Amalia Todirascu.
2015.
Multi-
word units translation evaluation in machine trans-
lation:
another pain in the neck?
In Proceedings
of MUMTTT workshop,
Corpas Pastor G, Monti J,
Mitkov R, Seretan V (eds) (2015), Multi-word Units
in Machine Translation and Translation Technology.
Johanna Monti,
Ruslan Mitkov,
Gloria Corpas Pastor,
and Violeta Seretan.
2013.
Multi-word units in ma-
chine translation and translation technologies.
Michael P. Oakes.
1998.
Statistics for Corpus Linguis-
tics.
Edinburgh: Edinburgh University Press.
Karl
Pichotta and John DeNero.
2013.
Identify-
ing phrasal verbs using many bilingual corpora.
In
Proceedings of
the 2013 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2013), Seattle, WA, October.
Carlos
Ramisch,
Aline Villavicencio,
and Christian
Boitet.
2010.
mwetoolkit:
a Framework for Mul-
tiword Expression Identification.
In Proceedings of
the Seventh International Conference on Language
Resources and Evaluation (LREC 2010),
Valetta,
Malta,
May.
European Language Resources Asso-
ciation.
Alexandre
Rondon,
Helena
Caseli,
and
Carlos
Ramisch.
2015.
Never-ending multiword expres-
sions learning.
In Proceedings of
the 11th Work-
shop on Multiword Expressions, pages 45–53, Den-
ver, Colorado, June. Association for Computational
Linguistics.
Pavel
Rychlý.
2008.
A lexicographer-friendly asso-
ciation score.
In RASLAN 2008,
pages 6–9,
Brno.
Masarykova Univerzita.
Bahar
Salehi
and Paul
Cook.
2013.
Predicting
the compositionality of multiword expressions us-
ing translations in multiple languages.
Second Joint
Conference on Lexical
and Computational
Seman-
tics (* SEM), 1:266–275.
Nathan Schneider,
Emily Danchik,
Chris Dyer,
and
Noah A.
Smith.
2014a.
Discriminative lexical se-
mantic segmentation with gaps:
Running the MWE
gamut.
TACL, 2:193–206.
Nathan Schneider,
Spencer
Onuffer,
Nora
Kazour,
Emily Danchik, Michael T. Mordowanec, Henrietta
Conrad,
and Noah A.
Smith.
2014b.
Comprehen-
sive annotation of multiword expressions in a so-
cial
web corpus.
In Proceedings of
the Ninth In-
ternational Conference on Language Resources and
Evaluation (LREC’14),
pages 455–461,
Reykjavik,
Iceland. European Language Resources Association
(ELRA).
Violeta Seretan and Eric Wehrli.
2013.
Syntactic
concordancing and multi-word expression detection.
International
Journal
of
Data Mining,
Modelling
and Management, 5(2):158–181.
Frank Smadja.
1993.
Retrieving collocations from
text:
Xtract.
Computational
Linguistics,
19:143–
177.
Shiva Taslimipoor, Ruslan Mitkov, Gloria Corpas Pas-
tor,
and Afsaneh Fazly.
2016.
Bilingual
contexts
from comparable corpora to mine for translations of
collocations.
In Proceedings of
the 17th Interna-
tional Conference on Intelligent Text Processing and
Computational Linguistics, CICLing’16. Springer.
Aline Villavicencio,
Valia Kordoni,
Yi Zhang,
Marco
Idiart,
and Carlos Ramisch.
2007.
Validation and
evaluation of automatically acquired multiword ex-
pressions for
grammar
engineering.
In EMNLP-
CoNLL, pages 1034–1043.
Aline Villavicencio.
2005.
The availability of verb–
particle constructions
in lexical
resources:
How
much is enough?
Computer Speech & Language,
19(4):415–432.
CLIC_2016_Proceedings.indd 290
02/12/16 15.05
291
SIMPITIKI: a Simplification corpus for Italian
Sara Tonelli
Fondazione Bruno Kessler
satonelli@fbk.eu
Alessio Palmero Aprosio
Fondazione Bruno Kessler
aprosio@fbk.eu
Francesca Saltori
Fondazione Bruno Kessler
fsaltori@fbk.eu
Abstract
English. In this work, we analyse whether
Wikipedia can be used to leverage simpli-
fication pairs instead of Simple Wikipedia,
which has proved unreliable for
assess-
ing automatic simplification systems,
and
is available only in English.
We focus
on sentence pairs in which the target sen-
tence is the outcome of a Wikipedia edit
marked as ‘simplified’,
and manually an-
notate simplification phenomena follow-
ing an existing scheme proposed for pre-
vious
simplification corpora
in Italian.
The outcome of this work is the SIMPI-
TIKI corpus, which we make freely avail-
able,
with pairs
of
sentences
extracted
from Wikipedia edits and annotated with
simplification types.
The resource con-
tains
also another
corpus
with roughly
the same number of simplifications, which
was manually created by simplifying doc-
uments in the administrative domain.
Italiano.
In
questo
lavoro
si
anal-
izza la possibilit
`
a di
utilizzare Wikipedia
per selezionare coppie di
frasi
semplifi-
cate.
Si
propone questa soluzione come
un’alternativa a Simple Wikipedia,
che si
`
e dimostrata inattendibile per studiare la
semplificazione automatica ed
`
e disponi-
bile solo in inglese.
Ci
concentriamo
soltanto su coppie di frasi in cui la frase
target
`
e indicata come il frutto di una mod-
ifica in Wikipedia,
indicata dagli
editor
come un caso di semplificazione. Tali cop-
pie sono annotate manualmente secondo
una classificazione delle tipologie di sem-
plificazione gi
`
a utilizzata in altri studi,
e
vengono rese liberamente disponibili
nel
corpus SIMPITIKI. La risorsa include an-
che un secondo corpus,
contenente circa
lo stesso numero di semplificazioni, realiz-
zato intervenendo manualmente su alcuni
documenti nel dominio amministrativo.
1
Introduction
In recent
years,
the shift
of
interest
from rule-
based to data-driven automated simplification has
led to new research related to the creation of sim-
plification corpora.
These are parallel
monolin-
gual
corpora,
possibly aligned at
sentence level,
in which source and target
are an original
and a
simplified version of the same sentence. This kind
of corpora is needed both for training automatic
simplification systems
and for
their
evaluation.
For English,
several
approaches have been eval-
uated based on the Parallel Wikipedia Simplifica-
tion corpus (Zhu et al.,
2010),
containing around
108,000 automatically aligned sentence pairs from
cross-linked articles between Simple and Normal
English Wikipedia.
Although this resource has
boosted research on data-driven simplification,
it
has some major drawbacks, for example its avail-
ability only in English,
the fact
that
automatic
alignment
between Simple and Normal
versions
shows poor quality,
and that only around 50% of
the sentence pairs correspond to real
simplifica-
tions (according to a sample analysis performed
on 200 pairs by Xu et al. (2015)). In this work, we
present a study aimed at assessing the possibility
to leverage a simplification corpus from Wikipedia
in a semi-automated way, starting from Wikipedia
edits.
The study is inspired by the work presented
in Woodsend and Lapata (2011),
in which a set
of parallel
sentences was extracted from Simple
Wikipedia revision history.
However,
the present
work is different
in that:
(i) we use the Italian
Wikipedia revision history, demonstrating that the
approach can be applied also to languages other
than English and on edits of Wikipedia that were
not created for educational purposes,
and (ii) we
CLIC_2016_Proceedings.indd 291
02/12/16 15.05
292
manually select the actual simplifications and la-
bel them following the annotation scheme already
applied to other Italian corpora.
This makes pos-
sible the comparison with other resources for text
simplification,
and allows a seamless integration
between different corpora.
Our
methodology can be summarised as fol-
lows:
we
first
select
the
edited
sentence
pairs which were commented as ‘simplified’
in
Wikipedia edits,
filtering out
some specific sim-
plification types (Section 3).
Then,
we manually
check the extracted pairs and, in case of simplifi-
cation,
we annotate the types in compliance with
the existing annotation scheme for Italian (Section
4).
Finally,
we analyse the annotated pairs and
compare their characteristics with the other cor-
pora available for Italian (Section 5).
2
Related work
Given the increasing relevance of
large corpora
with parallel
simplification pairs,
several
efforts
have been devoted to develop them.
The most
widely used corpus
of
this
kind is
the Paral-
lel
Wikipedia Simplification corpus (Zhu et
al.,
2010),
which was automatically leveraged by ex-
tracting normal
and simple Wikipedia sentence
pairs.
However,
Xu et
al.
(2015) have recently
presented a position paper, in which they describe
several shortcomings of this resource and recom-
mend the research community to drop it
as the
standard benchmark for simplification.
Other al-
ternative approaches,
suggesting to further refine
the selection of
normal
– Simple parallel
sen-
tences to target
specific phenomena like lexical
simplification,
have been also proposed (Yatskar
et
al.,
2010),
but
have had limited application.
The fact that Simple Wikipedia is not available for
languages other than English has proved benefi-
cial
to the development
of alternative resources.
Manually or automatically created corpora have
been proposed among others for
Brazilian Por-
tuguese (Pereira et al.,
2009),
German (Klaper et
al.,
2013) and Spanish (Bott and Saggion,
2011).
As for Italian,
the only available corpus contain-
ing parallel
pairs of simplified sentences is pre-
sented in Brunato et al. (2015).
We borrow from
this study the annotation scheme for our corpus, so
that we can make a comparison between the two
resources.
We include in the comparison also an-
other novel corpus,
made of manually simplified
sentences in the administrative domain, which we
release together with the Wikipedia-based one.
3
Corpus extraction
The extraction of
the pairs has been performed
using the dump for
the Italian Wikipedia avail-
able on a dedicated website.
1
This huge XML file
(more than 1 TB uncompressed) contains the his-
tory of every operation of editing in every page in
Wikipedia since it has been published for the first
time. In particular, the Italian edition of Wikipedia
contains 1.3M pages and is maintained by around
2.500 active editors, who made more than 60M ed-
its in 15 years of activity.
The Italian language is
spoken by 70M people, therefore there are on av-
erage 35 active editors per million speakers, giving
to the Italian Wikipedia the highest
ratio among
the 25 most spoken languages around the world.
We parse the 60M edits using a tool
in Java
developed internally and freely available on the
SIMPITIKI
website.
2
The
user
who edits
a
Wikipedia page can insert a text giving informa-
tion on why he or she has modified a particular
part of the article.
This action is not mandatory,
but it is included most of the times.
We first se-
lect the edits which description includes word such
as “semplificato” (simplified),
“semplice” (sim-
ple),
“semplificazione” (simplification),
and sim-
ilar.
Then,
the obtained set is further filtered by
removing edits marked with technical tags such as
“Template”, “Protected page”, “New page”.
This
eliminates,
for instance,
simplifications involving
the page template and not the textual content. The
text
in the Wikipedia pages is written using the
Wiki Markup Language,
therefore it needs to be
cleaned.
We use the Bliki
engine
3
for this task.
Finally,
the obtained list of cleaned text passages
is parsed using the Diff Match and Patch library,
4
identifies the parts of each article where the text
was modified.
With this process, we obtain a list
of 4,356 sentence pairs, where the differences be-
tween source and target sentence are marked with
deletion and insertion tags (see Figure 1).
4
Corpus annotation
We manually annotate pairs of sentences through
a web interface developed for
the purpose and
freely available for download.
2
Differently from
1
https://dumps.wikimedia.org/
2
https://github.com/dhfbk/simpitiki
3
http://bit.ly/bliki
4
http://bit.ly/diffmatchpatch
CLIC_2016_Proceedings.indd 292
02/12/16 15.05
293
Figure 1: Annotation interface used to mark simplification phenomena in the SIMPITIKI corpus.
corpora specifically created for text simplification,
in which modifications are almost
always sim-
plifications,
annotating Wikipedia edits is chal-
lenging because the source sentence may undergo
several modifications, being partly simplifications
and partly other types of changes.
Therefore, the
interface includes the possibility to select only the
text segments in the source and in the target sen-
tence that correspond to simplification pairs,
and
assign a label only to these specific segments.
It
also gives the possibility to skip the pair if it does
not contain any simplification.
A screenshot of the annotation tool is displayed
in Figure 1. On the left, the source sentence(s) are
reported, with the modified parts marked in red (as
given by the Diff Match and Patch library). On the
right,
the target sentence(s) were displayed,
with
segments marked in green to show which parts
were introduced during editing.
A tickbox next to
each red/green segment could be selected to align
the source and target segments that correspond to
a modification.
The annotation interface provides
the possibility to choose one of the simplification
types proposed in a dropdown menu (‘Conferma’),
or to skip the pair (‘Vai Avanti’).
The second op-
tion was given to mark the sentences where a mod-
ification did not correspond to a proper simplifica-
tion.
For example the last
edit
shown in Fig.
1
reports in the original version ‘Contando esclusi-
vamente sulla capacit
`
a del mare’, which was mod-
ified into ‘Contando soprattutto sulla capacit
`
a del
mare’.
Since this change affects the meaning of
the sentence,
turning exclusively into mainly,
but
not its readability, the pair was not annotated.
In order to develop a corpus which is compli-
ant
with the annotation scheme already used in
Class
Subclass
Split
Merge
Reordering
Insert
Verb
Subject
Other
Delete
Verb
Subject
Other
Transformation
Lexical substitution (word)
Lexical substitution (phrase)
Anaphoric replacement
Verb to Noun (nominalization)
Noun to Verb
Verbal voice
Verbal features
Table 1: Simplification classes and subclasses. For
details see Brunato et al. (2015).
previous works on simplification, we followed the
simplification types described in (Brunato et
al.,
2015).
The tagset is reported in Table 1 and com-
prises 6 main classes (Split,
Merge,
Reordering,
Insert, Delete and Transformation) and some sub-
classes to better
specify the Insert,
Delete and
Transformation operations.
The labels are avail-
able in the dropdown menu on the annotation in-
terface and can be used to tag selected pairs of sen-
tences.
5
Corpus analysis
So far,
annotators viewed 2,671 sentence pairs,
2,326 of which were skipped because the target
sentence was not a simplified version of the source
one.
345 sentence pairs with 575 annotations are
currently part
of the SIMPITIKI corpus,
and all
CLIC_2016_Proceedings.indd 293
02/12/16 15.05
294
Class
Subclass
# wiki
# PA
Total
Split
20
18
38
Merge
22
0
22
Reordering
14
20
34
Insert
Verb
11
5
16
Insert
Subject
5
1
6
Insert
Other
58
21
79
Delete
Verb
12
1
13
Delete
Subject
17
1
18
Delete
Other
146
31
177
Transformation
Lexical Substitution (word level)
96
253
349
Transformation
Lexical Substitution (phrase level)
143
184
327
Transformation
Anaphoric replacement
14
3
17
Transformation
Noun to Verb
3
32
35
Transformation
Verb to Noun (nominalization)
2
0
2
Transformation
Verbal Voice
2
1
3
Transformation
Verbal Features
10
20
30
Total
575
591
1166
Table 2:
Number of simplification phenomena annotated in the Wikipedia-based and the public admin-
istration (PA) corpus
phenomena presented in the annotation scheme
proposed by (Brunato et
al.,
2015) are currently
covered.
As a comparison,
we analyse also the content
of
the annotated corpora described in (Brunato
et
al.,
2015),
which represent
the only existing
corpora for Italian simplification.
These include
the Terence corpus of children stories, which was
specifically created to address the needs of poor
comprehenders,
and contains 1,036 parallel
sen-
tence pairs, and the Teacher corpus, a set of doc-
uments simplified by teachers for educational pur-
poses,
containing 357 sentence pairs.
Besides,
we include in the comparison also another
cor-
pus,
which we manually created by simplifying
documents issued by the Trento Municipality to
rule building permits and kindergarten admittance.
This corpus was simplified following the instruc-
tions in (Brunato et al., 2015) but pertains to a dif-
ferent domain, i.e. public administration (PA). The
wikipedia-based and the PA corpus have a compa-
rable size (575 vs.
591 pairs),
but
the simplifi-
cation phenomena have a different
frequency,
as
shown in Table 2.
In Fig. 2 we compare the distribution of the dif-
ferent simplification types across the four corpora.
The graph shows that the same phenomena such as
subject deletion,
nominalizations,
transfer of ver-
bal voice tend to be rare across the four datasets.
Similarly,
the
three
top-frequent
simplification
types,
i.e.
delete-other,
word transformation and
phrase transformation, are the same across the four
datasets. However, in the Wikipedia-based corpus,
word transformation is less frequent
than in the
other document
types,
while phrase transforma-
tion is much more present. This may show that the
‘controlled’ setting, in which the Terence and the
Teacher corpora were created, may lead educators
to put more emphasis on word-based transforma-
tions to teach synonyms, while in a more ‘ecologi-
cal’ setting like Wikipedia the performed simplifi-
cations are not guided or constrained, and phrase-
based transformations may sound more natural.
As for the PA documents, transformation phenom-
ena are probably very frequent because of the tech-
nical
language characterised by domain-specific
words,
which tend to be replaced by more com-
mon ones during manual
simplification.
In this
corpus,
noun-to-verb transformations are partic-
ularly frequent,
since nominalizations are typi-
cal phenomena of the administrative language af-
fecting its readability (Cortelazzo and Pellegrino,
2003).
While the Terence corpus
contains
on aver-
age 2.1 annotated phenomena per sentence pair,
Teacher 2.8 and the PA corpus 2.9 , the Wikipedia-
based corpus includes only 1.6 simplifications for
each parallel pair.
As expected, corpora that were
explicitly created for simplification tend to have a
higher concentration of simplification phenomena
than corpora developed in less controlled settings.
As for non simplifications discarded during the
CLIC_2016_Proceedings.indd 294
02/12/16 15.05
295
0 
5 
10 
15 
20 
25 
30 
35 
40 
45 
Split 
Merge 
Reordering 
Insert-Verb 
Insert-Subject 
Insert-Other 
Delete-Verb 
Delete-Subject 
Delete-Other 
Transf-Word 
Transf-Phrase 
Anaph-Replace 
Noun-To-Verb 
Verb-To-Noun 
Transf-VVoice 
Transf-VFeature 
Terence 
Teacher 
Wiki 
PA 
Figure 2: Distribution of the simplification phenomena covered in the Terence, Teacher and Wikipedia-
based and Public Administration corpora.
1.
Lo psicodramma
`
e stato il
precursore di
tutte le
forme di psicoterapia di gruppo
2.
Lo psicodramma
`
e in relazione con altre forme di
psicoterapia di gruppo
1.
Partigiani
non comunisti
e giornalisti
democratici
furono uccisi per il loro coraggio
2.
Partigiani non comunisti e giornalisti furono uccisi
per il loro coraggio
1.
Il dispositivo di memoria di massa utilizza memoria
allo stato solido, ovvero basata su un semiconduttore
2.
Il dispositivo di memoria di massa basata su semi-
conduttore utilizza memoria allo stato solido
Table 3: Examples of parallel pairs which were not
annotated as simplifications.
creation of the Wikipedia-based corpus,
they in-
clude generalizations,
specifications,
entailments,
deletions,
edits changing the meaning,
error cor-
rections, capitalizations, etc.
(see some examples
in Table 3).
These types of modifications are very
important because they may represent negative ex-
amples for training machine learning systems that
recognize simplification pairs.
6
Conclusions and Future work
We presented a study aimed at the extraction and
annotation of a corpus for Italian text simplifica-
tion based on Wikipedia.
The work has high-
lighted the challenges and the advantages related
to the use of Wikipedia edits.
Our goal is to pro-
pose this resource as a testbed for the evaluation
of Italian simplification systems, as an alternative
to other existing corpora created in a more ‘con-
trolled’ setting.
The corpus is made available to
the research community together
with the tools
used to create it.
The SIMPITIKI resource con-
tains also a second corpus,
of comparable size,
which was created by manually simplifying a set
of documents in the administrative domain.
This
allows cross-domain comparisons of
simplifica-
tion phenomena.
In the future, this work can be extended in sev-
eral directions.
We plan to use the simplification
pairs in this corpus to train a classifier with the
goal of distinguishing between simplified and not-
simplified pairs.
This could extend the gold stan-
dard with a larger set of “silver” data by labelling
all
the remaining candidate pairs extracted from
Wikipedia.
Besides, the SIMPITIKI methodology
is currently being used to create a similar corpus
for Spanish,
using the same annotation interface.
The outcome of this effort will allow multilingual
studies on simplification.
Finally, we plan to evaluate the Ernesta system
for Italian simplification (Barlacchi
and Tonelli,
2013) using this corpus.
Specifically,
since dif-
ferent simplification phenomena are annotated,
it
would be interesting to perform a separate eval-
uation on each class,
as suggested in (Xu et
al.,
CLIC_2016_Proceedings.indd 295
02/12/16 15.05
296
2015).
Acknowledgments
The research leading to this paper was partially
supported by the EU Horizon 2020 Programme via
the SIMPATICO Project
(H2020-EURO-6-2015,
n. 692819).
References
Gianni Barlacchi and Sara Tonelli.
2013.
ERNESTA:
A Sentence Simplification Tool for Children’s Sto-
ries in Italian.
In Alexander Gelbukh, editor, Com-
putational Linguistics and Intelligent Text Process-
ing: 14th International Conference, CICLing 2013,
Samos,
Greece,
March 24-30,
2013,
Proceedings,
Part II, pages 476–487, Berlin, Heidelberg. Springer
Berlin Heidelberg.
Stefan Bott
and Horacio Saggion.
2011.
An un-
supervised alignment algorithm for text simplifica-
tion corpus construction.
In Proceedings of
the
Workshop on Monolingual Text-To-Text Generation,
MTTG ’11,
pages 20–26,
Stroudsburg,
PA,
USA.
Association for Computational Linguistics.
Dominique Brunato,
Felice Dell’Orletta,
Giulia Ven-
turi, and Simonetta Montemagni.
2015.
Design and
Annotation of the First Italian Corpus for Text Sim-
plification.
In Proceedings of The 9th Linguistic An-
notation Workshop, pages 31–41, Denver, Colorado,
USA, June. Association for Computational Linguis-
tics.
M.
Cortelazzo and F.
Pellegrino.
2003.
Guida alla
scrittura istituzionale.
Laterza, New York, US.
David Klaper,
Sarah Ebling,
and Martin Volk.
2013.
Building a German/Simple German Parallel Corpus
for Automatic Text Simplification.
In In: Proceed-
ings of the 2nd Workshop on Predicting and Improv-
ing Text Readability for Target Reader Populations,
Sofia, Bulgaria, pages 11–19.
Tiago F.
Pereira,
Lucia Specia,
Thiago A.
S.
Pardo,
Caroline Gasperin, and Ra M. Aluisio.
2009.
Build-
ing a Brazilian Portuguese parallel corpus of origi-
nal and simplified texts.
In In: 10th Conference on
Intelligent Text Processing and Computational Lin-
guistics, Mexico City, pages 59–70.
Kristian Woodsend and Mirella Lapata.
2011.
Learn-
ing to simplify sentences with quasi-synchronous
grammar and integer programming.
In Proceedings
of
the 2011 Conference on Empirical
Methods in
Natural Language Processing,
pages 409–420,
Ed-
inburgh, Scotland, UK., July. Association for Com-
putational Linguistics.
Wei Xu, Chris Callison-Burch, and Courtney Napoles.
2015.
Problems in current
text
simplification re-
search:
New data can help.
Transactions of the As-
sociation for Computational Linguistics, 3:283–297.
Mark Yatskar,
Bo Pang,
Cristian Danescu-Niculescu-
Mizil,
and Lillian Lee.
2010.
For
the Sake
of Simplicity:
Unsupervised Extraction of Lexical
Simplifications from Wikipedia.
In Human Lan-
guage Technologies:
The 2010 Annual Conference
of
the North American Chapter of
the Association
for Computational Linguistics, HLT ’10, pages 365–
368,
Stroudsburg,
PA,
USA.
Association for Com-
putational Linguistics.
Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.
2010.
A monolingual tree-based translation model
for sentence simplification.
In Proceedings of
the
23rd International
Conference on Computational
Linguistics (Coling 2010),
pages 1353–1361,
Bei-
jing, China, August. Coling 2010 Organizing Com-
mittee.
CLIC_2016_Proceedings.indd 296
02/12/16 15.05
297
Dieci sfumature di marcatezza sintattica:
verso una nozione computazionale di complessit
`
a
Erica Tusa
Universit
`
a di Pisa
ericatusa@hotmail.it
Felice Dell’Orletta, Simonetta Montemagni, Giulia Venturi
Istituto di Linguistica Computazionale
“Antonio Zampolli” (ILC–CNR)
ItaliaNLP Lab - www.italianlp.it
{
nome.cognome
}
@ilc.cnr.it
Abstract
English.
In this work,
we will investiga-
te whether and to what extent algorithms
typically used to assess the reliability of
the output of syntactic parsers can be used
to study the correlation between proces-
sing complexity and the linguistic notion
of markedness.
Although still prelimina-
ry,
achieved results show the key role of
features such as dependency direction and
length in defining the markedness degrees
of a given syntactic construction.
Italiano.
In questo lavoro indagheremo
se e come algoritmi tipicamente utilizzati
per valutare l’affidabilit
`
a dell’analisi pro-
dotta da strumenti
di
annotazione sintat-
tica automatica possono essere utilizzati
per studiare la correlazione tra comples-
sit
`
a computazionale e la nozione lingui-
stica di marcatezza.
I risultati raggiunti,
sebbene ancora preliminari,
mostrano il
ruolo chiave di fattori quali l’orientamen-
to della relazione e la lunghezza della di-
pendenza nel definire le varie “sfumature”
di marcatezza di una stessa relazione.
1
Introduzione
Fin dagli anni ’80,
`
e andata affermandosi la con-
vinzione che metodi
e tecniche sviluppate nel-
l’ambito della linguistica computazionale potesse-
ro contribuire a far avanzare la ricerca fornendo
nuova evidenza per lo studio di nozioni chiave del-
la linguistica teorica.
“Computational linguistics
provides important
potential
tools for the testing
of theoretical linguistic constructs and of their po-
wer to predict actual language use”: cos
`
ı si apre il
contributo di Ku
ˇ
cera (1982), che fondandosi sulla
correlazione tra marcatezza e frequenza propone
i risultati di uno studio computazionale della no-
zione di marcatezza a livello lessicale e gramma-
ticale condotto sul Brown corpus.
Se da un lato
l’evidenza raccolta conferma la correlazione atte-
sa tra frequenza e marcatezza,
dall’altro vengono
registrati casi interessanti in cui “the statistical evi-
dence from the Brown Corpus offers both greater
problems and greater insight.
[...]
The frequen-
cy data is [...] the reverse of what one might have
assumed under the markedness analysis”.
Oggi, a pi
`
u di 40 anni dallo studio pioniestico di
Ku
ˇ
cera (1982) che si fondava su un corpus anno-
tato morfo–sintatticamente di circa un milione di
parole,
`
e possibile estrarre da corpora di ben mag-
giori dimensioni informazione linguistica accurata
e variegata. L’affidabilit
`
a crescente degli strumen-
ti di Trattamento Automatico del Linguaggio sta
rendendo infatti possibile l’acquisizione di eviden-
za quantitativa e computazionale che spazia attra-
verso diversi livelli di descrizione linguistica,
in-
cluso quello sintattico, che pu
`
o contribuire in mo-
do significativo allo studio di questioni aperte del-
la letteratura linguistica: Merlo (2016) rappresenta
un importante esempio di questo rinnovato filone
di studi.
All’interno del quadro delineato sopra, l’obiet-
tivo del presente contributo
`
e verificare se e in che
misura algoritmi per l’identificazione dell’affida-
bilit
`
a e plausibilit
`
a dell’annotazione sintattica pos-
sano contribuire allo studio di
un fenomeno lin-
guistico quale la marcatezza.
Con l’uso sempre
pi
`
u diffuso dell’annotazione sintattica a dipenden-
ze come punto di partenza per una vasta gamma
di
applicazioni
finalizzate all’estrazione di
infor-
mazione da vaste collezioni documentali,
tali al-
goritmi nascono dalla necessit
`
a di identificare al-
CLIC_2016_Proceedings.indd 297
02/12/16 15.05
298
l’interno delle annotazioni prodotte in modo auto-
matico quelle corrette o,
pi
`
u semplicemente,
ca-
ratterizzate da un maggior grado di affidabilit
`
a e
plausibilit
`
a.
Questo tipo di
valutazione pu
`
o av-
venire in relazione sia all’intero albero sintattico
assegnato alla singola frase (cfr.
ad esempio Del-
l’Orletta et
al.
(2011) e Reichart
and Rappoport
(2009b)), sia alla singola relazione di dipendenza
(si vedano,
tra gli altri,
Dell’Orletta et al.
(2013)
e Che et
al.
(2014)).
Se da un lato l’identifica-
zione di alberi sintattici corretti rappresenta un in-
grediente fondamentale all’interno di algoritmi di
Active Learning (Settles, 2012) o di apprendimen-
to automatico semi–supervisionato e non supervi-
sionato (Goldwasser et al., 2011), l’identificazione
dell’affidabilit
`
a di
singole relazioni
di
dipenden-
za e/o sotto–alberi sintattici diventa fondamentale,
ad esempio, per fornire evidenza utile a migliora-
re le prestazioni di un sistema di analisi sintattica
automatica (vanNoord,
2007;
Chen et al.,
2009),
oppure per l’estrazione di nuclei di informazione
affidabili.
Nel presente studio, ci focalizzeremo sul secon-
do tipo di algoritmi,
ovvero quelli che operano a
livello della singola relazione di dipendenza,
per
verificarne le potenzialit
`
a nello studio della nozio-
ne di marcatezza linguistica.
Per quanto questi al-
goritmi operino tipicamente su corpora annotati in
modo automatico (Dickinson, 2010), sono attesta-
ti
usi
anche su corpora con annotazione validata
manualmente (qualificata come “gold”): in questo
caso,
il fine consiste nell’identificazione di errori
e incoerenze di annotazione (Dickinson, 2015).
Il
risultato di questi algoritmi varia da una classifica-
zione binaria della dipendenza (corretta
vs.
errata)
come in Che et al. (2014), a un ordinamento del-
le relazioni secondo l’affidabilit
`
a e la plausibilit
`
a
dell’analisi,
come proposto da Dell’Orletta et al.
(2013). Al di l
`
a di differenze a livello dell’algorit-
mo utilizzato e del tipo di risultato,
in tutti i casi
viene fatto uso di un esteso inventario di caratte-
ristiche linguistiche selezionate come indicatori di
complessit
`
a.
2
L’ipotesi di ricerca
Combinando la prospettiva linguistica e quella
linguistico–computazionale,
l’ipotesi
che inten-
diamo esplorare
`
e se il
punteggio assegnato da
algoritmi per la misura della plausibilit
`
a dell’an-
notazione possa essere utilizzato per
ricostruire
il
passaggio graduale da costruzioni
non marca-
te a costruzioni
caratterizzate da gradi
crescenti
di marcatezza.
L’assunto di base sottostante a ta-
le ipotesi si fonda sulla correlazione,
ampiamen-
te adottata nella letteratura linguistica,
tra mar-
catezza e complessit
`
a:
se da un lato costruzio-
ni non marcate saranno caratterizzate da un mag-
gior
livello di
plausibilit
`
a di
annotazione (dun-
que da un minore livello di complessit
`
a),
dall’al-
tro costruzioni caratterizzate da gradi crescenti di
marcatezza saranno associate a punteggi
di
mi-
nore di
plausibilit
`
a (equivalente a una maggiore
complessit
`
a).
All’interno della letteratura linguistica, la “mar-
catezza” rappresenta una nozione ampiamente di-
battuta e altamente polisemica.
Secondo quan-
to affermato da Haspelmath (2006), a partire dal-
le prime accezioni
delineate negli
anni
’30 (Ja-
kobson,
1932) essa pu
`
o essere ricondotta a dodi-
ci significati diversi,
organizzati in quattro classi:
“markedness as complexity, as difficulty, as abnor-
mality,
or as a multidimensional operation”.
Tra
queste,
il presente contributo intende focalizzarsi
sulla definizione di “markedness as abnormality”
e, in particolare, sull’idea che quando consideria-
mo “marcato” un determinato evento linguistico lo
stiamo considerando “abnormal”,
ovvero devian-
te rispetto a strutture linguistiche riconosciute co-
me basiche all’interno della “norma linguistica”.
In questa ottica,
la marcatezza come devianza ri-
spetto alla norma
`
e strettamente connessa sia con
la frequenza d’uso (cfr.
“markedness as rarity in
texts”),
sia rispetto alla distribuzione di un even-
to linguistico all’interno di una variet
`
a pi
`
u o meno
ampia di contesti linguistici (cfr.
“markedness as
restricted distribution”).
In quanto segue,
analizzeremo i
risultati
di
un algoritmo per la valutazione della plausibilit
`
a
di
singole relazioni
alla luce delle accezioni
di
marcatezza selezionate.
3
Metodologia di analisi e corpora
L’algoritmo che abbiamo utilizzato per la misura
della plausibilit
`
a dell’annotazione sulla base del-
la quale produrre l’ordinamento delle relazioni di
dipendenza
`
e costituito da LISCA (Dell’Orletta et
al., 2013).
Tale algoritmo assegna a ogni relazio-
ne – definita come una tripla
(
d, h, t
)
dove
d
`
e il
dipendente,
h
`
e la testa, e
t
`
e il tipo di dipenden-
za che connette
d
a
h
– un valore di plausibilit
`
a.
LISCA opera in due fasi:
1) colleziona statistiche
relative a un insieme di caratteristiche linguistica-
CLIC_2016_Proceedings.indd 298
02/12/16 15.05
299
mente motivate estratte da un ampio corpus di al-
beri a dipendenze ottenuti attraverso un processo
di annotazione sintattica automatica;
2) combina
queste statistiche all’interno di
una funzione de-
scritta in Dell’Orletta et al. (2013) per ottenere il
punteggio da associare all’arco sintattico in cor-
so di valutazione.
La combinazione viene calco-
lata come il prodotto dei pesi associati a ciascuna
caratteristica identificata.
La Figura 1 descrive graficamente le caratteri-
stiche prese in esame da LISCA per la misura della
plausibilit
`
a dell’arco sintattico
(
d, h, t
)
. Ai fini del
presente studio, LISCA
`
e stato utilizzato nella sua
variante delessicalizzata per poter fare astrazione
da variazioni di natura lessicale. In particolare, so-
no stati presi in considerazione due diversi tipi di
caratteristiche, entrambe associate nella letteratura
linguistica alla nozione di complessit
`
a sintattica:
•
tratti
locali,
corrispondenti
alle peculiarit
`
a
dell’arco
sintattico
considerato,
come
ad
esempio la distanza in termini
di
tokens al-
l’interno della frase tra
d
e
h
, oppure la forza
associativa che unisce le categorie grammati-
cali coinvolte (POS
d
e POS
h
), o la POS della
testa di
h
e il tipo di relazione sintattica che li
lega;
•
tratti
globali,
volti
a localizzare l’arco con-
siderato all’interno della struttura sintattica
della frase,
ad esempio la distanza di
d
ri-
spetto alla radice dell’albero,
oppure rispet-
to alla foglia pi
`
u vicina o a quella pi
`
u lon-
tana,
oppure il
numero di
nodi
“fratelli” e
“figli” di
d
ricorrenti rispettivamente alla sua
destra–sinistra nell’ordine lineare della frase.
In questo studio,
per estrarre le statistiche ri-
spetto alle caratteristiche linguistiche prese in esa-
me,
LISCA
`
e
stato applicato a
un corpus
di
1.104.237 frasi
(22.830.739 tokens)
estratte da
articoli
del
quotidiano La Repubblica,
parte del
CLIC-ILC Corpus (Marinelli et al., 2003).
Il cor-
pus
`
e stato annotato a livello morfosintattico con
l’ILC–POS–Tagger (Dell’Orletta et al., 2009) e a
livello sintattico a dipendenze con DeSR (Attardi
et
al.,
2009).
Gli
strumenti
di
annotazione sono
stati
addestrati
sulla Italian Universal
Depende-
cies Treebank, in breve IUDT (Bosco et al., 2013).
Lo schema di annotazione utilizzato
`
e quello delle
“Universal
Dependencies”,
concepito per massi-
mizzare il parallelismo delle annotazioni in lingue
diverse e che per questo motivo privilegia relazioni
Figura 1:
Caratteristiche utilizzate LISCA per il
calcolo della plausibilit
`
a dell’arco
(
d, h, t
)
.
di dipendenza tra parole lessicali trattando le paro-
le grammaticali come dipendenti di parole seman-
ticamente piene (Nivre,
2015).
IUDT costituisce
anche il corpus di indagine di questo lavoro:
at-
traverso LISCA a ogni arco sintattico del corpus
`
e
stato assegnato un punteggio.
4
Analisi dei dati
I punteggi assegnati da LISCA alle relazioni di di-
pendenza della IUDT sono stati utilizzati per ordi-
nare le relazioni in ordine descrescente di plausibi-
lit
`
a.
La lista ordinata cos
`
ı ottenuta
`
e stata suddivi-
sa in 10 fasce di 24,644 relazioni ciascuna (corri-
spondente al 10% del totale). Partendo dall’analisi
della variazione della distribuzione dei tipi di re-
lazioni di dipendenza attraverso le fasce, ci siamo
poi focalizzati su singole relazioni, con l’intento di
ricostruire il passaggio da non marcato (o prototi-
pico) a marcato, e di identificare i fattori che con-
tribuiscono a determinare il
grado di
marcatezza
di una costruzione, definita in questo studio come
una relazione di dipendenza all’interno del conte-
sto sintattico di occorrenza.
Nella consapevolezza
che le relazioni
sono distribuite all’interno delle
fasce in virt
`
u della combinazione di tutte le carat-
teristiche locali e globali prese in considerazione,
ci siamo focalizzati su due parametri ampiamente
indagati nella letteratura linguistica con l’intento
di verificare se e in che misura l’ordinamento di
CLIC_2016_Proceedings.indd 299
02/12/16 15.05
300
Figura
2:
Distribuzione
di
una
selezione
di
dipendenze.
LISCA rifletta note gerarchie di
marcatezza.
In
particolare,
`
e stato analizzato il ruolo i) dell’orien-
tamento della dipendenza, definito dalla direzione
verso destra o sinistra dell’arco sintattico che lega
d
a
h
rispetto all’ordine lineare delle parole nella
frase,
e ii) della lunghezza della relazione di
di-
pendenza, calcolata come la distanza in parole tra
d
e
h
.
4.1
Distribuzione delle dipendenze
Partiamo dall’analisi della distribuzione delle di-
pendenze nelle 10 fasce.
Nelle prime fasce si os-
serva un insieme ristretto di
tipi
di
dipendenze,
la cui frequenza diminuisce proporzionalmente al
decrescere dei punteggi assegnati da LISCA. Man
mano che si prosegue verso le fasce intermedie, i
tipi di dipendenza all’interno di ciascuna fascia si
fanno pi
`
u numerosi e variabili. Gli archi con i pun-
teggi pi
`
u alti,
che si collocano nelle prime fasce,
mettono in relazione parole grammaticali e paro-
le lessicali,
come det(erminer),
case e mark(er),
che collegano,
rispettivamente,
articoli,
preposi-
zioni, congiunzioni subordinanti o avverbi alla re-
lativa testa.
Proseguendo oltre le prime due fasce,
troviamo relazioni
come advmod (adverbial
mo-
difier),
nummod (numerical modifier),
cop(ula) e
aux(iliary) che collegano,
rispettivamente,
avver-
bi, numerali, copule e ausiliari (verbi modali com-
presi) alla loro testa. A partire dalla quinta fascia si
osserva un’incidenza sempre maggiore di relazio-
ni
che collegano parole lessicali
come sostantivi
e verbi alla loro testa, ad esempio nsubj (nominal
subject), dobj (direct object), ccomp (clausal com-
plement),
xcomp (clausal
complement
with con-
trolled subject) e root.
Un caso a parte
`
e rappre-
sentato dalle relazioni amod e nmod che collegano
modificatori aggettivali o nominali con la relativa
testa: esse si distribuiscono in modo simile in tutte
le fasce.
Figura 3:
Orientamento generale delle dipenden-
ze.
La Figura 2 riporta l’andamento della distribu-
zione di
sei
relazioni
di
dipendenza selezionate
come segue:
due relazioni concentrate principal-
mente nelle prime fasce (det,
case),
due relazio-
ni
caratterizzate da una distribuzione pi
`
u diffusa
(amod, nmod) e due relazioni maggiormente ricor-
renti nelle ultime fasce (nsubj, dobj).
La distribu-
zione delle relazioni che vedono una parola gram-
maticale come dipendente all’interno delle prime
fasce pu
`
o essere ricondotta alle strutture general-
mente fisse o poco variabili, che le rendono facil-
mente trattabili computazionalmente. D’altro lato,
le parole lessicali tendono ad inserirsi in costruzio-
ni pi
`
u complesse,
caratterizzate da una maggiore
flessibilit
`
a a livello dell’ordine lineare all’interno
della frase, e potenzialmente soggette a condizio-
namenti
di
tipo pragmatico che portano alla for-
mazione di strutture sintattiche pi
`
u complesse.
La
presenza diffusa della relazione amod attraverso
le fasce rappresenta un caso diverso, non ricondu-
cibile alla libert
`
a di
movimento ma piuttosto al-
la direzione degli archi sintattici che li collegano
alla loro testa:
mentre la distanza media tra
d
e
h
in amod rimane tendenzialmente costante attra-
verso le fasce,
la direzione della relazione varia
significativamente.
In quanto segue, ci concentre-
remo su due dei parametri che sembrano svolgere
un ruolo chiave nella distribuzione delle relazioni
attraverso le fasce.
4.2
Orientamento delle dipendenze
La Figura 3 riporta la distribuzione attraverso le fa-
sce di tutte le relazioni di dipendenza, facendo di-
stinzione tra dipendenze con testa a destra (
d > h
)
e dipendenze con testa a sinistra (
h < d
).
Si
osserva che i due tipi di orientamento,
nonostan-
te ricorrano con frequenza molto simile (112.886
d > h
vs 104.301
h < d
), sono descritti da anda-
menti opposti: nelle prime fasce si concentrano le
CLIC_2016_Proceedings.indd 300
02/12/16 15.05
301
Figura
4:
Orientamento
di
una
selezione
di
dipendenze.
Figura 5:
Andamento generale della lunghezza
media delle dipendenze per fascia.
relazioni di tipo
d > h
, nelle ultime quelle
h < d
.
Nella Figura 4
`
e riportato l’andamento attra-
verso le fasce dell’orientamento di due relazioni,
amod e nsubj. Nel caso di amod le teste dei modi-
ficatori aggettivali si trovano in netta maggioran-
za a sinistra,
soprattutto nella seconda fascia:
gli
aggettivi
postnominali,
dunque in posizione non
marcata,
sono stati valutati come pi
`
u plausibili e
computazionalmente trattabili.
Invece, nsubj, che
collega il soggetto nominale alla testa verbale, nel-
la maggior parte dei casi presenta la testa a destra:
il soggetto preverbale corrisponde all’ordine non
marcato in italiano. La sequenza verbo–soggetto
`
e
attestata, con andamento crescente, a partire dalla
fascia 6.
Le relazioni che sono state valutate con
i punteggi pi
`
u alti, ovvero det e case, mostrano la
testa sempre a destra.
4.3
Lunghezza delle dipendenze
Nella Figura 5,
per ciascuna fascia
`
e riportata la
media delle lunghezze delle relazioni di dipenden-
za:
si
osserva che il
punteggio di
LISCA decre-
sce in maniera inversamente proporzionale al va-
lore della lunghezza media.
Nella Figura 6 sono
riportate le medie all’interno di ogni fascia delle
lunghezze di un gruppo selezionato di dipenden-
ze:
alcune delle relazioni che abbiamo visto con-
Figura 6:
Andamento della lunghezza media di
una selezione di dipendenze per fascia.
centrarsi nelle prime fasce,
come det
e case,
ma
anche relazioni
dalla distribuzione pi
`
u bilanciata
come amod e dobj risultano essere quelle pi
`
u bre-
vi (la loro lunghezza in media non supera una di-
stanza di 2 parole tra testa e dipendente);
dipen-
denze come nsubj
e nmod,
che collegano unit
`
a
dall’ordinamento pi
`
u flessibile,
cio
`
e caratterizza-
te da una maggiore libert
`
a di movimento rispetto
alla loro testa,
raggiungono in media,
soprattutto
verso le ultime fasce, le lunghezze maggiori. Con-
siderando il ruolo ampiamente ascritto in letteratu-
ra, non solo linguistico–computazionale ma anche
linguistica e psicolinguistica,
alla lunghezza del-
le dipendenze come fattore di complessit
`
a lingui-
stica, questi dati costituiscono una prova ulteriore
che l’ordinamento prodotto da LISCA riflette la
marcatezza della costruzione.
5
Conclusione
In questo studio abbiamo esplorato l’ipotesi
che
algoritmi sviluppati per valutare l’affidabilit
`
a e la
plausibilit
`
a di annotazioni sintattiche a dipenden-
ze possano fornire evidenza utile a una riflessione
attorno al
tema della complessit
`
a sintattica,
e in
particolare a ricostruire “sfumature” di marcatez-
za crescente in relazione alla stessa relazione di di-
pendenza. I primi risultati raggiunti sono incorag-
gianti: quanto osservato in relazione alla distribu-
zione delle dipendenze attraverso le fasce ci porta
a ipotizzare una forte correlazione tra la comples-
sit
`
a computazionale dell’analisi individuata da LI-
SCA e la nozione di marcatezza sintattica.
`
E sta-
to indagato in particolare il ruolo di fattori quali
l’orientamento della relazione e la lunghezza della
dipendenza, con risultati che mostrano chiaramen-
te che un algoritmo come LISCA pu
`
o essere un
valido strumento anche per analisi di tipo lingui-
stico.
Attraverso l’analisi della distribuzione delle
CLIC_2016_Proceedings.indd 301
02/12/16 15.05
302
relazioni
di
dipendenza nelle fasce definite sulla
base dell’ordinamento di
LISCA
`
e stato possibi-
le non solo discriminare tra costruzioni marcate e
non marcate (dato tipicamente recuperabile sulla
base della frequenza), ma anche identificare – re-
lazione per relazione – i fattori che hanno contri-
buito a renderla marcata.
Se l’orientamento della
relazione gioca un ruolo cruciale nel caso di amod,
nel caso di nsubj
`
e piuttosto la distanza tra la testa
e il dipendente a determinare la marcatezza della
costruzione.
Ovviamente,
questa metodologia di
analisi dovrebbe essere estesa alla vasta tipologia
di caratteristiche linguistiche considerate.
Gli sviluppi correnti di questo lavoro includo-
no: l’estensione, al di l
`
a della lunghezza e l’orien-
tamento della relazione,
della tipologia di
fattori
linguistici esplorati, per arrivare anche allo studio
dell’impatto di
fattori
lessicali;
l’estensione del-
la tipologia di costruzioni analizzate,
che potreb-
bero anche includere combinazioni di dipendenze
corrispondenti a sotto–alberi sintattici.
Riteniamo
che la metodologia dovrebbe anche essere applica-
ta a treebank di lingue diverse,
cos
`
ı come diversi
generi testuali all’interno della stessa lingua.
References
Attardi G.,
Dell’Orletta F.,
Simi M.,
Turian J.
2009.
Accurate dependency parsing with a stacked multi-
layer perceptron.
In Proceedings of EVALITA 2009
- Evaluation of
NLP and Speech Tools for Italian
2009,
Reggio Emilia, Italia, Dicembre 2009.
Bosco C.,
Montemagni,
S.,
Simi,
M.
2013.
Conver-
ting Italian Treebanks:
Towards an Italian Stanford
Dependency Treebank.
In Proceedings of the ACL
Linguistic Annotation Workshop & Interoperability
with Discourse,
Sofia, Bulgaria, August 2013.
Che W., Guo J., Liu T.
2014.
ReliAble dependency arc
recognition.
In Expert
Systems with Applications.
volume 41, number 4, pp. 17161722.
Chen W., Kazama J., Uchimoto K., Torisawa K.
2009.
Improving Dependency Parsing with Subtrees from
Auto-parsed Data.
In Proceedings
of
the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP ’09).
Association for
Computational Linguistics.
volume 2, pp. 570–579.
Dell’Orletta F.
2009.
Ensemble system for part-of-
speech tagging.
In Proceedings of EVALITA 2009 -
Evaluation of NLP and Speech Tools for Italian 2009
Reggio Emilia, Italia, Dicembre 2009.
Dell’Orletta F.
2011.
ULISSE:
an Unsupervised
Algorithm for Detecting Reliable Dependency Par-
ses.
In Proceedings of the Fifteenth Conference on
Computational Natural Language Learning, CoNLL
2011, Portland, Oregon, USA, June 23-24, 2011, pp.
115–124.
Dell’Orletta F.,
Venturi
G.,
Montemagni
S.
2013.
Linguistically-driven Selection of Correct Arcs for
Dependency Parsing.
In Computaci
`
on y Sistemas.
ISSN 1405-5546, vol. 17, No. 2, pp. 125-136.
Dickinson
M.
2010.
Detecting
Errors
in
Automatically-Parsed Dependency Relations.
In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational
Linguistics.
Uppsala,
Sweden, Association for Computational Linguistics,
pp. 729–738.
Dickinson M.
2015.
Detection of annotation errors
in corpora.
In Language and Linguistics Compass.
ISSN 1749-818X, vol. 9, No. 3, pp. 119-138.
Goldwasser D., Reichart R., Clarke J., Roth D.
2011.
Confidence Driven Unsupervised Semantic Parsing.
In Proceedings
of
the The 49th Annual
Meeting
of
the Association for Computational
Linguistics:
Human Language Technologies, Proceedings of the
Conference,
19-24 June,
2011,
Portland,
Oregon,
USA (ACL–2011).
pp. 1486–1495.
Haspelmath M.
2006.
Against markedness (and what
to replace it with).
In Journal of Linguistics.
ISSN
1469-7742, vol. 42, No. 01, pp. 25–70.
Jakobson R.
1932.
Zur
Struktur
des
russischen
Verbums.
In Charisteria Gvilelmo Mathesio.
Ku
ˇ
cera H.
1982.
Markedness and Frequency: a Com-
putational Analysis.
In Proceedings of COLING 82.
pp. 167-173.
Marinelli R., L. Biagini, R. Bindi, S. Goggi, M. Mona-
chini,
P. Orsolini,
E. Picchi,
S. Rossi,
N. Calzolari,
A.
Zampolli.
2003.
The Italian PAROLE corpus:
an overview.
In Zampolli A. et al. (eds.), Computa-
tional Linguistics in Pisa, Special Issue, XVI–XVII,
Pisa-Roma, IEPI. Tomo I, pp. 401-421.
Merlo P.
2016.
Quantitative computational
syn-
tax:
some initial
results.
In Italian Journal
of
Computational Linguistics.
vol. 2.
Nivre J.
2015.
Towards a Universal
Grammar
for
Natural
Language Processing.
In Proceedings of
the 16th International
Conference,
CICLing 2015,
Cairo, Egypt, April 14-20, 2015, Part I.
pp. 3–16.
Reichart Roi and Ari Rappoport.
2009b.
Sample Selec-
tion for Statistical Parsers:
Cognitively Driven Al-
gorithms and Evaluation Measures.
In Proceedings
of CoNLL 2009, pp. 3–11.
Settles B.
2012.
Active Learning.
Synthesis Lectu-
res on Artificial Intelligence and Machine Learning,
Morgan & Claypool Publishers.
van
Noord
G.
2007.
In
Proceedings
of
the
10th International Conference on Parsing Technolo-
gies (IWPT–2007).
Association for Computational
Linguistics, pp. 1–10.
CLIC_2016_Proceedings.indd 302
02/12/16 15.05
303
Tree Kernels-based Discriminative Reranker
for Italian Constituency Parsers
Antonio Uva
†
and Alessandro Moschitti
†
DISI, University of Trento, 38123 Povo (TN), Italy
Qatar Computing Research Institute, HBKU, 5825 Doha, Qatar
antonio.uva@unitn.it
amoschitti@gmail.com
Abstract
English.
This paper
aims at
filling the
gap between the accuracy of Italian and
English constituency parsing:
firstly,
we
adapt
the Bllip parser,
i.e.,
the most
ac-
curate
constituency parser
for
English,
also known as Charniak parser,
for Ital-
ian and trained it
on the Turin Univer-
sity Treebank (TUT). Secondly, we design
a parse reranker
based on Support
Vec-
tor Machines using tree kernels, where the
latter can effectively generalize syntactic
patterns,
requiring little training data for
training the model.
We show that
our
approach outperforms the state of the art
achieved by the Berkeley parser,
improv-
ing it from 84.54 to 86.81 in labeled F1.
Italiano.
Questo
paper
mira
a
col-
mare il
gap di
accuratezza tra il
con-
stituency parsing dell’Italiano e quello In-
glese:
come primo miglioramento,
abbi-
amo adattato il
parser a costituenti
per
l’Inglese,
Bllip,
anche noto come Char-
niak
parser,
per
l’Italiano e
lo abbi-
amo addestrato sul Turin University Tree-
bank.
In seguito,
abbiamo progettato un
reranker basato sulle Macchine a Vettori
di
Supporto che usano kernel
arborei,
i
quali possono efficacemente generalizzare
pattern sintattici,
richiedendo pochi
dati
di
training per addestrare il
modello.
Il
nostro approccio supera lo stato dell’arte
ottenuto con il
Berkeley parser,
miglio-
rando la labeled F1 da 84.54 a 86.81.
1
Introduction
Constituency Syntactic parsing is one of the most
important
research lines in Computational
Lin-
guistics.
Consequently,
a large body of work has
been also devoted to its design for Italian language
(Bosco et al., 2007; Bosco et al., 2009; Bosco and
Mazzei,
2011).
However,
the accuracy reported
for the best parser is still far behind the state of the
art of other languages, e.g., English.
One noticeable attempt
to fill
this technolog-
ical
gap was
carried out
in the
EvalIta
chal-
lenge,
which proposed a parsing track on both
dependency and constituency parsing for Italian.
Among the several participant systems, the Berke-
ley parser (Petrov and Klein,
2007) gave the best
result (Lavelli and Corazza, 2009; Lavelli, 2011).
At the beginning, the outcome for constituency
parsing computed on TUT (Bosco et
al.,
2009)
was much lower than the one obtained for English
on the Penn Treebank (Marcus et
al.,
1993).
In
the last EvalIta edition, such gap diminished as the
Italian parser labeled F1 increased from 78.73%
(EvalIta 2009) to 82.96% (EvalIta 2011).
Some
years
later
the parser
F1 improved to 83.27%
(Bosco et
al.,
2013).
However,
the performance
of the best English parser (McClosky et al., 2006),
i.e.,
92.1%,
is
still
far
away.
The main rea-
son for such gap is the difference in the amount
of training data available for Italian compared to
English.
In fact,
while Penn Treebank contains
49
,
191
sentences/trees, TUT only contains
3
,
542
sentences/trees.
In presence of scarcity of training data,
a gen-
eral solution for increasing the accuracy of a ma-
chine learning-based system is the use of
more
general
features.
This way,
the probability of
matching training and testing instance representa-
tions is larger, allowing the learning process to find
more accurate optima.
In case of syntactic pars-
ing, we need to generalize either lexical or syntac-
tic features, or possibly both.
However, modeling
such generalization in state-of-the-art parser algo-
rithms such as the Bllip
1
(Charniak,
2000;
Char-
niak and Johnson, 2005) is rather challenging.
In
particular,
the space of all possible syntactic pat-
terns is very large and cannot be explicitly coded
1
https://github.com/BLLIP/bllip-parser
CLIC_2016_Proceedings.indd 303
02/12/16 15.05
304
in the model.
An easier solution consists in us-
ing such features in a simpler model, which can be
trained to improve the outcome of the main parser,
e.g., selecting one of its best hypotheses. In partic-
ular, tree kernels (TKs) by Moschitti (2006) can be
used for encoding an exponential number of syn-
tactic patterns in parse rerankers.
In this work, we aim at filling the gap between
English and Italian constituency parsing:
firstly,
we adapted Bllip parser,
i.e.,
the most
accurate
constituency parser
for
English,
also known as
Charniak parser, for Italian and trained it on TUT.
We designed various configuration files for defin-
ing specific labels for TUT by also defining their
type,
although we did not
encode head-finding
rules for
Italian,
needed to complete the parser
adaptation.
Secondly, we apply rerankers based on Support
Vector Machines (SVMs) using TKs to the k-best
parses produced by Bllip,
with the aim of select-
ing its best hypotheses.
TKs allow us to represent
data using the entire space of subtrees, which cor-
respond to syntactic patterns of different level of
generality.
This representation enables the train-
ing of the reranker with little data.
Finally,
we
tested our models on TUT,
following the EvalIta
setting and compare with other parsers.
For ex-
ample, we observed an improvement of about 2%,
over the Berkeley parser, i.e., 86.81 vs. 84.54.
2
Bllip parser
The Bllip parser is a lexicalized probabilistic con-
stituency parser.
It can be considered a smoothed
PCFG,
whose non-terminals encode a wide vari-
ety of manually chosen conditioning information,
such as heads, governors, etc. Such information is
used to derive probability distributions, which, in
turn,
are utilized for computing the likelihood of
constituency trees being generated.
As described
by McClosky et al.
(2006),
Bllip uses five distri-
butions, i.e., the probabilities of the (i) constituent
heads, (ii) constituent part-of-speeches (PoS), (iii)
head-constituents,
(iv) left-of-head and (v) right-
of-head constituents.
Each probability distribu-
tion is conditioned by five or more features and
backed-off by the probability of lower-order mod-
els in case of
rare feature configurations.
The
variety of
information needed by Bllip to work
properly makes its configuration much harder than
for other parsers,
e.g.,
the Berkeley’ one.
How-
ever, Bllip is faster to train than other off-the-shelf
parsers.
2.1
Adapting Bllip to Italian Language
Bllip adaptation required to create various config-
uration files.
For example, PoS and bracket labels
observed in training and development sets must be
defined in a file named terms.txt. As labels present
in the TUT are different
from those of the Penn
Treebank
2
, we added them in such file.
Then, we
specified the type of labels present in the data, i.e.,
constituent type, open-class PoS, punctuation, etc.
Finally,
it
should be noted that,
since Bllip is
lexicalized,
head-finding rules for Italian should
be specified in the file, headInfo.txt.
For example,
the rule,
ADJP
r
−→
JJ
, specifies that the head of
an adjective phrase (ADJP) is the right-most ad-
jective (JJ).
Due to time restriction,
we used the
default Bllip rules and leave this task as our short-
term future work.
3
Tree Kernel-based Reranker
We describe three types of TKs and the Preference
Reranker approach using them.
3.1
Tree kernels
TKs can be used for
representing arbitrary tree
structures in kernel machines,
e.g.,
SVMs.
They
are a viable alternative to explicit
feature design
as they implement
the scalar
products between
feature vectors as a similarity between two trees.
Such scalar product is computed using efficient al-
gorithms and it is basically equal to the number of
the common subparts of the two trees.
Syntactic Tree Kernels (STK) count the num-
ber of common tree fragments, where the latter (i)
contain more than two nodes and (ii) each node is
connected to either all or none of its children.
We
also used a variant,
called STK
b
,
which adds the
number of common leaves of the comparing trees
in the final subpart count.
Partial
Tree Kernels (PTK)
counts a larger
class of tree fragments,
i.e.,
any subset of nodes,
where the latter are connected in the original trees:
clearly, PTK is a generalization of STK.
3.2
Preference Reranker
Preference reranking is cast as a binary classifica-
tion problem, where each instance is a pair

h
i
, h
j

of tree hypotheses and the classifier decides if
h
i
is better than
h
j
.
The positive training examples
are the pairs,

h
1
, h
i

,
where
h
1
has the highest
F1 with respect
to the gold standard among the
candidate hypotheses.
The negative examples are
2
For example,
the PoS-tag NN in Penn Treebank corre-
sponds to tag NOU∼CS in TUT
CLIC_2016_Proceedings.indd 304
02/12/16 15.05
305
Models
sentences ≤ 40 words
All sentences
LR
LP
LF
EMR
LR
LP
LF
EMR
Berkeley (Bosco et al., 2013)
83.45
84.48
83.96
24.91
82.78
83.76
83.27
23.67
Berkeley (our model)
85.31
85.76
85.53
27.76
84.35
84.72
84.54
26.33
Bllip base model
85.90
86.67
86.28
29.54
85.26
85.97
85.61
28.00
STK
86.16
87.02
86.59
30.96
85.73
86.38
86.05
29.33
STK
b
86.36
87.21
86.78
31.67
85.89
86.53
86.21
30.00
PTK
86.82
87.95
87.38
30.96
86.33
87.29
86.81
29.67
Table 1: Comparative results on the test set.
LR/LP/LF = labeled recall/precision/F 1.
EMR = percentage of sentences where
recall and precision are 100%. STK- and STK
b
-based rerankers use 20-best hypotheses, while PTK-based reranker use 30-best
hypotheses.
obtained inverting the hypotheses in the pairs, i.e.,

h
i
, h
1

.
If the hypotheses have the same score,
the pair is not included in the training set. At clas-
sification time all pairs

h
i
, h
j

generated from the
k-best hypotheses are classified. A positive classi-
fication is a vote for
h
i
, whereas a negative classi-
fication is a vote for
h
j
. The hypothesis associated
with the highest number of votes (or highest sum
of classifier scores) is selected as the best parse.
4
Experiments
In these experiments,
we first
report
on the per-
formance of Bllip for Italian and compare it with
the Berkeley parser. Then, we show that our parse
reranker can be very effective, even in case of use
of small training data.
4.1
Experimental Setup
Parsing data.
The data for
training and test-
ing the constituency parsers come from the TUT
project
3
,
developed at
the University of
Turin.
There have been several
releases of the dataset:
we used the latest version from EvalIta 2011.
The
training set is composed of
3
,
542
sentences, while
the test
set
contains
300
sentences.
The set
of
PoS-tags includes
97
tags:
68
encoding morpho-
logical
features (out
of which
19
basic tags) for
pre-terminal symbols (e.g., ADJ, ADVB, NOUN,
etc.) and
29
non-terminal symbols for phrase con-
stituents (e.g., ADJP, ADVP, NP, etc.).
Reranking Data.
To generate the data for train-
ing the reranker, we apply
10
-fold cross validation
to the official TUT training set: we train the based
parser on
9
folds and applied it to the remaining
fold to generate the
n
-best trees for each of its sen-
tences.
Then,
we merge all
the 10-labeled folds
to produce the training set
of the reranker.
This
way, we avoid the bias a parser would have if ap-
plied to the data used for training it.
For generat-
ing the test data of the reranker, we simply apply
3
http://www.di.unito.it/
˜
tutreeb/
the base parser (trained on all TUT training data)
to the TUT test set and generate
n
-hypotheses for
each sentence.
SVM Reranker.
We train the reranker
using
SVM-light-TK,
which takes both feature vectors
and trees as input to learn a classification model.
The features used for reranking constituency trees
are:
(i) the probability and the (inverse) rank of
the hypotheses provided by Bllip and (ii) the en-
tire syntactic trees used with two types of kernels,
STK and PTK, described in Sec. 3.
Measures.
For evaluating the parsers,
we used
the EVALB scoring program,
which reports the
Labeled Precision (LP), Labeled Recall (LR), La-
beled F1 (LF) and Exact Match Rate (EMR). Ac-
cording to the official EvalIta procedure for eval-
uating the participant
system output,
we did not
score the TOP label,
ignore all
functional
labels
attached to non-terminals and include punctuation
in the scoring procedure.
4.2
Bllip base parser results
We divided the training set in train and validation
sets,
where the latter is composed of the last
50
sentences of each of the six sections of the former
for a total of
300
sentences.
We train the models
on the training set and tune parameters on the val-
idation set.
Then,
we applied the learned model
to the
300
sentences of the test set.
Table 1 shows
the results obtained by the Bllip base parser on the
TUT test set. Our parser obtained an LF of
86
.
28%
for sentences with less than 40 words and a score
of
85
.
61%
for all sentences.
4.3
Comparison with the Berkeley parser
Table 1 also reports the results of the Berkeley
parser obtained by Bosco et al. (2013).
For com-
parison purposes,
we trained our own version of
the Berkeley parser.
In particular,
we trained the
parser for 5 split-merge cycles on the whole train-
ing set.
We selected such number of cycles ap-
plying 10-fold cross validation on the training set.
Similarly to Bosco et
al.
(2013),
we specialized
CLIC_2016_Proceedings.indd 305
02/12/16 15.05
306
Models
10-best
20-best
30-best
Tree
Tree + feat.
Tree
Tree + feat.
Tree
Tree + feat.
len≤40
All
≤40
All
len≤40
All
len≤40
All
len≤40
All
len≤40
All
Bllip base model
86.28
85.61
86.28
85.61
86.28
85.61
86.28
85.61
86.28
85.61
86.28
85.61
STK
84.95
84.49
86.31
85.69
84.70
84.16
86.59
86.05
84.99
84.45
86.55
86.00
STK
b
85.05
84.52
86.31
85.69
84.92
84.35
86.78
86.21
84.92
84.38
86.62
86.06
PTK
86.02
85.46
87.34
86.65
85.89
86.41
87.37
86.79
86.42
85.92
87.38
86.81
Table 2:
Reranker performance:
the first row reports the number n of the best hypotheses used during training.
The second
row shows the used group of features: Tree or Tree + feat, while the third row illustrates the parse results (LF) for two sentence
groups: sentences with ≤ 40 words and all sentences.
punctuation symbols to more specific tags.
How-
ever, we used full PoS-tags, as they gave the best
results in cross-fold validation.
Indeed,
the table
shows that our own version of the Berkeley parser
outperforms the version the one of Bosco et
al.
(2013) by
1
.
27
absolute percent points (84.54 vs.
83.27).
The table also reports the results of the
Bllip parser, which outperforms the best result ob-
tained by the Berkeley parser by 1.07% in LF, i.e.,
85
.
61
vs.
84
.
54
.
4.4
Reranking using different TKs
Table
2 reports
the
LF obtained by different
reranking models,
varying:
(i) the type of TKs,
(ii) the group of features (i.e., either trees or trees
+ feat.) and (iii) the number,
n
, of parse trees used
to generate the reranker training data. More in par-
ticular,
we experimented with three values for
n
,
i.e.,
10
-,
20
- and
30
-best parse trees.
As it can be
seen from the table,
PTK constantly outperforms
STK and STK
b
for any number of parse hypothe-
ses.
This indicates that the subtree features gener-
ated by PTK, which include nodes with any sub-
set of the children in the original tree,
are useful
for improving the parser accuracy.
Very interestingly, the performance of all mod-
els when trained on
30
-best trees give either worse
results (e.g.,
STK
b
and STK) or very little im-
provement
(e.g.,
PTK) than training on
20
-best
parse trees.
This may suggest
that
adding too
many negative examples,
largely populating the
lower part of the
n
-best list may be detrimental.
The bottom part
of
Table 1 shows
standard
parser evaluation metrics for different
reranking
models using different kernel types:
only the ker-
nel models with the highest LF from Table 2 are
reported. The method shows an 1.2% absolute im-
provement in LF (from 85.61% to 86.81%) on all
the sentences over the base-parser model (i.e., the
baseline) when using the most
powerful
kernel,
PTK,
and
30
-best
hypotheses.
STK and STK
b
show a lower improvement
over the baseline of
0
.
44%
and
0
.
6%
,
respectively.
One interesting
fact is the following:
while PTK gives better re-
sults in terms of LF, STK and STK
b
perform bet-
ter in terms of EMR,
i.e.,
the percentage of sen-
tence parse completely matching gold trees.
This
is rather
intuitive as the name suggests,
Partial
Tree Kernel generates partial subtrees, i.e., partial
production rules as patterns.
On one hand,
this
can improve the ability of matching syntactic pat-
terns,
thus capturing rules partially expressed by
more than one support vector.
On the other hand,
the precision in capturing complete patterns,
i.e.,
regarding a complete tree is intuitively decreased.
5
Related Work and Conclusions
This
work was
inspired by Collins
and Duffy
(2002) and Collins and Koo (2005), who explored
discriminative approaches for ranking problems.
Their studies were limited to WSJ,
though,
and
did not explore the use of max-margin classifiers,
i.e., SVMs.
The first experiments with SVMs and
TKs were conducted by Shen and Joshi
(2003),
who proposed a new SVM-based voting algorithm
making use of preference reranking.
In this paper,
we adapted the Charniak parser
for Italian gaining an improvement of 1.07% over
the Berkeley model
(indicated by EvalIta as the
state of the art for Italian).
Then,
our TK-based
reranker further improved it up to 2 absolute per-
cent points.
It should also be noted that our best
reranking result is 3.54 absolute points better than
the best outcome reported in (Bosco et al., 2013),
i.e., 83.27.
In the future, we would like to integrate (i) the
features developed in the reranking software avail-
able by Johnson and Ural (2010) in our model for
further improving it,
(ii) generalizing lexical fea-
tures (e.g.,
embeddings,
brown clusters) and in-
cluding similarity measures in PTK,
i.e.,
SPTK
(Croce et al., 2011).
Acknowledgments
A special
thank is
due to Alberto Lavelli
and
Alessandro Mazzei for enabling us to carry out an
exact comparison with their parser.
CLIC_2016_Proceedings.indd 306
02/12/16 15.05
307
References
[Bosco and Mazzei2011]
Cristina Bosco and Alessan-
dro Mazzei.
2011.
The evalita 2011 parsing task:
the constituency track.
Working Notes of EVALITA.
[Bosco et al.2007]
Cristina Bosco, Alessandro Mazzei,
and Vincenzo Lombardo.
2007.
Evalita parsing
task:
an analysis of the first parsing system contest
for italian.
Intelligenza artificiale, 12:30–33.
[Bosco et al.2009]
Cristina Bosco, Alessandro Mazzei,
and Vincenzo Lombardo.
2009.
Evalita09 parsing
task:
constituency parsers and the penn format for
italian.
Proceedings of EVALITA, 9:1794–1801.
[Bosco et al.2013]
Cristina Bosco, Alessandro Mazzei,
and Alberto Lavelli.
2013.
Looking back to the
evalita constituency parsing task:
2007-2011.
In
Evaluation of Natural Language and Speech Tools
for Italian, pages 46–57. Springer.
[Charniak and Johnson2005]
Eugene
Charniak
and
Mark Johnson.
2005.
Coarse-to-fine n-best parsing
and maxent
discriminative reranking.
In Proceed-
ings of
the 43rd Annual
Meeting on Association
for
Computational
Linguistics,
pages
173–180.
Association for Computational Linguistics.
[Charniak2000]
Eugene Charniak.
2000.
A maximum-
entropy-inspired parser.
In Proceedings of
the 1st
North American chapter of the Association for Com-
putational
Linguistics conference,
pages 132–139.
Association for Computational Linguistics.
[Collins and Duffy2002]
Michael
Collins
and
Nigel
Duffy.
2002.
New ranking algorithms for parsing
and tagging:
Kernels over discrete structures,
and
the voted perceptron.
In Proceedings of the 40th an-
nual meeting on association for computational lin-
guistics,
pages 263–270. Association for Computa-
tional Linguistics.
[Collins and Koo2005]
Michael Collins and Terry Koo.
2005.
Discriminative reranking for natural language
parsing.
Computational Linguistics, 31(1):25–70.
[Croce et al.2011]
Danilo Croce, Alessandro Moschitti,
and Roberto Basili.
2011.
Structured lexical
similarity via convolution kernels on dependency
trees.
In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1034–1046. Association for Computational Linguis-
tics.
[Johnson and Ural2010]
Mark Johnson and Ahmet En-
gin Ural.
2010.
Reranking the berkeley and brown
parsers.
In Human Language Technologies:
The
2010 Annual
Conference of
the North American
Chapter of the Association for Computational Lin-
guistics,
pages 665–668. Association for Computa-
tional Linguistics.
[Lavelli and Corazza2009]
Alberto Lavelli
and Anna
Corazza.
2009.
The berkeley parser at the evalita
2009 constituency parsing task.
In EVALITA 2009
Workshop on Evaluation of NLP Tools for Italian.
[Lavelli2011]
Alberto Lavelli.
2011.
The berkeley
parser at the evalita 2011 constituency parsing task.
In Working Notes of EVALITA.
[Marcus et al.1993]
Mitchell
P Marcus,
Mary
Ann
Marcinkiewicz,
and Beatrice
Santorini.
1993.
Building
a
large
annotated
corpus
of
english:
The
penn treebank.
Computational
linguistics,
19(2):313–330.
[McClosky et al.2006]
David McClosky, Eugene Char-
niak,
and Mark Johnson.
2006.
Effective self-
training for parsing.
In Proceedings of the main con-
ference on human language technology conference
of the North American Chapter of the Association of
Computational Linguistics, pages 152–159. Associ-
ation for Computational Linguistics.
[Moschitti2006]
Alessandro Moschitti.
2006.
Efficient
convolution kernels for dependency and constituent
syntactic trees.
In European Conference on Machine
Learning, pages 318–329. Springer.
[Petrov and Klein2007]
Slav Petrov and Dan Klein.
2007.
Improved inference for unlexicalized parsing.
In HLT-NAACL, volume 7, pages 404–411.
[Shen and Joshi2003]
Libin Shen and Aravind K Joshi.
2003.
An svm based voting algorithm with appli-
cation to parse reranking.
In Proceedings of
the
seventh conference on Natural language learning at
HLT-NAACL 2003-Volume 4,
pages 9–16. Associa-
tion for Computational Linguistics.
CLIC_2016_Proceedings.indd 307
02/12/16 15.05
308
Context-aware Spoken Language Understanding
for Human Robot Interaction
Andrea Vanzo
(†)
, Danilo Croce
(‡)
, Roberto Basili
(‡)
and Daniele Nardi
(†)
(†)
Sapienza University of Rome
Department of Computer, Control and Management Engineering “Antonio Ruberti”
Via Ariosto 25, 00185 Roma, Italy
(‡)
University of Roma, Tor Vergata
Department of Enterprise Engineering, Via del Politecnico 1, 00133 Roma, Italy
{vanzo,nardi}@dis.uniroma1.it, {croce,basili}@info.uniroma2.it
Abstract
English.
Robots operate in specific en-
vironments and the correct
interpretation
of linguistic interactions depends on phys-
ical, cognitive and language-dependent as-
pects triggered by the environment. In this
work,
we present
LU4R - adaptive spo-
ken Language Understanding 4 Robots,
a Spoken Language Understanding chain
for the semantic interpretation of robotic
commands,
that is sensitive to the opera-
tional environment.
The system has been
designed according to a Client/Server ar-
chitecture in order to be easily integrated
with the vast plethora of robotic platforms.
Italiano.
L’interpretazione di
comandi
espressi
nei
confronti
di
piattaforme
robotiche
`
e
un
processo
strettamente
legato al contesto operativo in cui avviene
l’interazione.
In questo lavoro,
presenti-
amo LU4R -
adaptive spoken Language
Understanding 4 Robots,
un sistema per
l’elaborazione automatica di comandi vo-
cali, dipendente dall’ambiente in cui il co-
mando viene espresso.
Il
sistema pro-
posto,
implementato come una cascata
di
passi
di
elaborazione
semantica,
`
e
stato progettato seguendo un’architettura
Client/Server, per ridurre i requisiti di in-
tegrazione con le piattaforme robotiche es-
istenti.
1
Introduction
End-to-end communication in natural
language
between humans and robots is challenging for the
different cognitive abilities involved during the in-
teraction.
As an example, for a robot to react to a
command like “take the book on the table”, a num-
ber of implicit assumptions should be met.
First,
at
least
two entities,
a book and a table,
must
exist in the environment and the speaker must be
aware of
such entities.
Accordingly,
the robot
must have access to an inner representation of the
objects,
e.g.,
an explicit map of the environment.
Second,
mappings from lexical references to real
world entities must
be developed or made avail-
able.
In this respect, the Grounding process (Har-
nad, 1990) links symbols (e.g., words) to the cor-
responding perceptual information.
Hence,
robot
interactions need to be grounded, as meaning de-
pends on the state of the physical world and the in-
terpretation crucially interacts with perception, as
pointed out by psycho-linguistic theories (Tanen-
haus et
al.,
1995).
To this end,
the integration
of perceptual information derived from the robot’s
sensors with an ontologically motivated descrip-
tion of
the world has been adopted as an aug-
mented representation of the environment,
in the
so-called semantic maps (N
¨
uchter and Hertzberg,
2008).
In this maps,
the existence of real
world
objects can be associated to lexical
information,
in the form of entity names given by a knowledge
engineer or spoken by a user for a pointed object,
as in Human-Augmented Mapping (Diosi
et
al.,
2005).
While SLU for Interactive Robotics have
been mostly carried out
over the only evidences
specific to the linguistic level
(see,
for example,
(Chen and Mooney, 2011; Matuszek et al., 2012)),
we argue that
such process should be context-
aware, in the sense that both the user and the robot
access and make references to a shared environ-
ment.
For example, in the above command, “tak-
ing” is the intended action whenever a book is ac-
tually on the table, so that “the book on the table”
refers to a single argument.
On the contrary,
the
command may refer to a “bringing” action, when
no book is on the table and the book and on the
table correspond to different semantic roles.
In this paper, we present LU4R an adaptive spo-
ken language understanding chain for
the auto-
CLIC_2016_Proceedings.indd 308
02/12/16 15.05
309
matic interpretation of robotic spoken commands
that is coherent with the above assumptions.
The
resulting chain is based on the approach proposed
in (Bastianelli
et
al.,
2016)
that
allows to pro-
duce interpretations that are consistent with (i) the
world (with all the entities composing it), (ii) the
Robotic Platform (with all its inner representations
and capabilities),
and (iii) the linguistic informa-
tion derived from the user’s utterance.
LU4R is
fully implemented in Java and is released accord-
ing to a Client/Server architecture, in order to de-
couple the chain from the specific robotic plat-
form that
will
use it.
It
receives as input
one
or more transcriptions of a spoken command and
produces one or more linguistic predicates reflect-
ing the actions intended by the user.
Predicates,
as well
as their arguments,
are consistent
with a
linguistically-motivated representation and coher-
ent with the environment perceived by the robot.
The rest
of the paper is structured as follows.
Section 2 provides an architectural description of
the entire system,
as well as an overall introduc-
tion about its integration with a generic robot.
In
Section 3 we demonstrate the applicability of the
chain in the interpretation of commands in English
and Italian.
2
The overall architecture
The architecture of the proposed system is decou-
pled into two main macro-components,
as shown
in Figure 1: the Robotic Platform and LU4R.
The Client-Server communication schema be-
tween the Robotic Platform (the Client) and LU4R
(the Server) allows to maintain the former inde-
pendent from the latter.
It is obvious that the in-
terpretation process must be achieved even when
no information about
the domain/environment
is
available,
i.e.,
a scenario involving a blind but
speaking robot.
This is the case when the com-
mand “take the book on the table” is paired with
any additional information and the ambiguity with
respect
to the evoked predicate,
i.e.,
Taking vs.
Bringing,
cannot be resolved.
At the same time,
the platform allows to specialize the semantic in-
terpretation process to individual situations when
contextual information is available.
In this case,
whenever the sentence “take the book on the ta-
ble” is provided along with information about the
presence and position of a book on a table,
the
above disambiguation can be solved.
In the following, each macro-component of the
architecture in Figure 1 is discussed and analyzed.
2.1
The Robotic Platform
The overall
architecture contemplates a generic
Robotic Platform, whose task, domain and physi-
cal setting are not necessarily specified. In order to
make LU4R independent from the above specific
aspects, we will assume that the platform requires
at least the following modules:
(i) an Automatic
Speech Recognition (ASR) system; (ii) a SLU Or-
chestrator;
(iii) a Grounding and Command Exe-
cution Engine;
(iv) a Physical
Robot.
Addition-
ally,
the optional component Support Knowledge
Base is expected to provide the contextual infor-
mation discussed above.
While the discussion
about
the Physical
Robot
is out
of the scope of
this work,
all the other components are hereafter
shortly summarized.
ASR system. An ASR engine allows to transcribe
a spoken utterance into one or more possible tran-
scriptions.
In the actual release,
the ASR is here
performed through an ad-hoc Android application
that can be deployed on both Android smartphones
and tablets.
It
relies on the official
Google ASR
API
1
that offers valuable performances for an off-
the-shelf
solution.
The acoustic model
is here
based on deep learning techniques,
i.e.
Recur-
rent Neural Networks (Hinton et al.,
2012).
The
Google ASR is publicly available and is rather
robust
toward some of the complexities of spo-
ken language, such as disfluencies and repetitions.
This allowed us to focus on other challenges of
spoken language, such as linguistic variations (e.g.
synonymy,
phonetically similar words,
interroga-
tive vs.
imperative sentences, . . . ).
Advantages of
our lexicalized grounding approach (Bastianelli et
al., 2015) is the robustness against variability and
sense ambiguity.
SLU Orchestrator. The SLU Orchestrator imple-
ments a TCP Server for the Android App,
here
coded as a ROS node (Quigley et al., 2009) wait-
ing for Client
requests.
Once a new request
ar-
rives (a list
of transcriptions for a given spoken
sentence),
this module is in charge of extracting
the perceived entities from a structured represen-
tation of the environment (here, a sub-component
of the Support Knowledge Base) and sending the
list of hypothesized transcriptions to LU4R along
with the list of the perceived entities. The commu-
nication protocol requires the serialization of such
1
https : //cloud.google.com/speech/
CLIC_2016_Proceedings.indd 309
02/12/16 15.05
310
Robotic Platform
(Client)
Response
LU4R
(Server)
Grounding
List of
hypotheses
Response
Support Knowledge Base
SLU Orchestrator
Hypotheses
Spoken
command
Morpho-Syntactic
Analysis
Re-ranking
Action Detection
Argument Labeling
Perceived entities
Domain
Model
Semantic
Map
User 
Model
Platform 
Model
Interpretation
Figure 1: Overall architecture of the system
information in two different JSON objects.
Even
though this module is actually a TCP Server for
the Android App, it represents also the Client in-
terface toward LU4R.
Grounding and Command Execution.
Even
though the grounding process is placed at the end
of the loop,
it
is discussed here as it
represents
part of the Robotic Platform.
In fact, this process
has been completely decoupled from the SLU, as
it
may involve perception capabilities and infor-
mation unavailable to LU4R or, in general, out of
the linguistic dimension.
Nevertheless,
this sit-
uation can be partially compensated by defining
mechanisms to exchange some of the grounding
information with the linguistic reasoning compo-
nent. However, grounding is always carried out on
board of the robot, as it represents the most general
situation.
The grounding carried out by the robot
is triggered by a logical
form expressing one or
more actions through (linguistic) predicates.
The
output of the SLU process embodies the produced
logical form: this latter exposes the recognized ac-
tions that are then linked to specific robotic oper-
ations (primitive actions or plans).
Correspond-
ingly,
the predicate arguments (e.g.,
objects and
location involved in the targeted action) are de-
tected and linked to the objects/entities of the cur-
rent environment.
A fully grounded command is
obtained through the complete instantiation of the
robot action (or plan) and its final execution.
2.2
The LU4R system
The language understanding process produces an
interpretation of the user’s utterance in terms of
linguistic predicates as defined in Frame Seman-
tics (Fillmore,
1985).
Specifically,
we consider
the formalization adopted in the FrameNet (Baker
et al.,
1998) database.
According to such theory,
actions expressed in user utterances can be mod-
eled as semantic frames. These are micro-theories
about real world situations, e.g., the action of tak-
ing.
Each frame specifies also the set
of partic-
ipating entities,
called frame elements,
e.g.,
the
T
HEME
representing the object that is taken dur-
ing the Taking action.
For example,
for the sen-
tence “take the book on the table”, a potential cor-
responding parsed version is:
[
take
]
Taking
[
the book on the table
]
T
HEME
(1)
In a robotic perspective, semantic frames provide
a cognitively sound bridge between the actions ex-
pressed in the language and the implementation of
such actions in the robot world.
As shown in Figure 1,
LU4R is composed of
four main steps.
Morpho-syntactic analysis is performed over
each available utterance transcription, by applying
Part-of-Speech tagging and syntactic parsing, pro-
viding morphological
and syntactic information,
essential for further processing.
Whenever
more than one hypothesized tran-
scription is available,
a Re-ranking module can
be activated to evaluate a new sorting of the hy-
potheses,
in order to get
the best
one out
of the
original ranking.
It allows to reuse existent ASR
solutions,
making the final
rank sensitive to the
specific robotic domain.
The selected transcription is the input
of
the
Action Detection (AD) component.
Here all the
CLIC_2016_Proceedings.indd 310
02/12/16 15.05
311
frames (i.e. intended actions) evoked in a sentence
are detected,
according to their triggering lexical
units.
For instance, given the above example, the
AD would produce the following interpretation:
[
take
]
Taking
the book on the table.
The final step is the Argument Labeling (AL).
Here a set of frame elements is retrieved for each
frame, detected during the AD step.
Such process
is,
in turn,
realized in two sub-steps.
First,
the
Argument
Identification (AI) aims at
finding the
spans of all the possible frame elements. Then, the
Argument Classification (AC) assigns the suitable
frame element label to each span identified during
the AI, producing the final tagging shown in (1).
An off-the-shelf tool
is used for the morpho-
syntactic analysis, namely the Stanford CoreNLP
suite (Manning et
al.,
2014).
Re-ranking is per-
formed using a learn-to-rank approach,
where a
Support Vector Machine exploiting a combination
of
linguistic kernels is applied,
as discussed in
(Basili
et
al.,
2013).
The AD,
AI and AC steps
are modeled as a sequential
labeling task,
as in
(Bastianelli et al.,
2016).
The Markovian formu-
lation of
a structured SVM proposed in (Altun
et al.,
2003) is applied to implement the sequen-
tial labeler,
known as SVM
hmm
.
In general,
this
learning algorithm combines a local
discrimina-
tive model,
which estimates the individual obser-
vation probabilities of a sequence,
with a global
generative approach to retrieve the most likely se-
quence, i.e.
tags that better explain the whole se-
quence.
In other words,
given an input sequence
x
= (
x
1
. . . x
l
)
∈ X
of feature vectors
x
1
. . . x
l
,
SVM
hmm
learns a model isomorphic to a
k
-order
Hidden Markov Model,
to associate x with a set
of labels y
= (
y
1
. . . y
l
)
∈ Y
.
A sentence
s
is here intended as a sequence
of
words
w
i
,
each modeled through a feature
vector
x
i
and associated to a dedicated label
y
i
,
specifically designed for each interpretation pro-
cess.
During training,
the SVM algorithm is
devoted to associating words to step-specific la-
bels:
linear kernel
functions are applied to dif-
ferent
types of features,
ranging from linguistic
to perception-based features, and linear combina-
tions of kernels are used to integrate independent
properties. At classification time, given a sentence
s
= (
w
1
. . . w
|s|
)
, the SVM
hmm
efficiently predicts
the tag sequence y
= (
y
1
. . . y
|s|
)
using a Viterbi-
like decoding algorithm.
Both the re-ranking and the language under-
standing phases can work in two different settings.
In the so-called basic scenario,
only linguistic
information is used during the interpretation task.
Perceptual
information from the environment
is
thus neglected and evidences from the user’s ut-
terances or linguistic resources are considered.
Conversely,
when perceptual
information is
made
available
to the
chain,
a
context-aware
interpretation is
triggered.
Such a perceptual
knowledge
is
mainly exploited through a
lin-
guistic grounding mechanism (Bastianelli
et
al.,
2015).
This lexically-driven grounding is esti-
mated through distances between filler (i.e.
ar-
gument
heads)
and entity names.
Such a se-
mantic distance integrates metrics over word vec-
tors descriptions and phonetic similarity.
Word
semantic vectors are here acquired through cor-
pus analysis, as in Distributional Lexical Semantic
paradigms (Turney and Pantel, 2010).
They allow
to map referential elements, such as lexical fillers,
e.g. desk, to entities, e.g. a table, by thus model-
ing synonymy or co-hyponymy.
Conversely, pho-
netic similarities ar smoothing factors against pos-
sible ASR transcription errors,
e.g.
pitcher and
picture.
Once links between fillers and entities
have been activated, the sequential labeler is made
sensitive to additional features, that inject percep-
tual information both in the learning and the tag-
ging process, e.g. the presence/absence of referred
objects in the environment.
As a side effect,
the
above mechanism provides the robot with the set
of linguistically-motivated groundings, that can be
potentially used for any further grounding process.
Overall,
the service provided by LU4R is per-
formed as a black-box component,
so that
the
complexity of each inner sub-task is hidden to the
user.
The service is realized through a server ac-
cepting connections on a predefined port.
LU4R
is entirely coded in Java and released as a sin-
gle Jar file
2
,
along with the required folders con-
taining linguistic models, configurations files and
other resources. Hence, it can be run through com-
mand line, so that it is easier to integrate it within
any architecture.
The LU4R system takes three input parameters:
type of the understanding process,
output format
and listening port.
The first parameter defines the
type of the interpretation process to be initialized:
the basic value activates the setting where only
linguistic information is adopted,
while simple
2
http://sag.art.uniroma2.it/sluchain.html
CLIC_2016_Proceedings.indd 311
02/12/16 15.05
312
refers to the interpretation where perceptual
in-
formation is considered.
The second parameter
specifies the desired output format, e.g., eXtended
Dependency Graph (Basili and Zanzotto, 2002) or
the Abstract Meaning Representation, proposed in
(Banarescu et al., 2013).
3
Evaluating LU4R
In order to provide evidences about the effective-
ness of the proposed solution, we report here a pre-
liminary evaluation of the interpretation process
w.r.t. robotic commands in two languages, i.e. En-
glish and Italian.
AD
AI
AC
English
95.91%
94.29%
95.31%
Italian
82.29%
79.46%
84.49%
Table 1:
Experimental evaluation of the semantic
interpretation process, in terms of F1
Table 1 shows results obtained over the Human
Robot Interaction Corpus (HuRIC) (Bastianelli et
al.,
2014),
a dataset
of
semantically annotated
commands typical
of Service Robotics.
HuRIC
contains 527 sentences in English.
Moreover, re-
sults w.r.t.
to a subset
of 188 commands from
HuRIC translated in Italian are reported.
The re-
sults, expressed in terms of F1 measure, focus on
the semantic interpretation process,
in particular
Action Detection (AD),
Argument
Identification
(AI) and Argument Classification (AC) steps.
In
fact,
F1 scores measures the quality of a specific
module.
While in the AD step the F1 refers to the
ability to extract the correct frame(s) evoked by a
sentence, in the AI step it evaluates to the correct-
ness of the predicted argument spans.
Finally,
in
the AC step the F1 measures the accuracy of the
classification of individual arguments.
We tested each sub-module in isolation,
feed-
ing each step with gold information provided by
the previous step in the chain. Moreover, the eval-
uation has been carried out
considering the cor-
rect transcriptions,
i.e.,
not contemplating the er-
ror introduced by the Automatic Speech Recogni-
tion system.
The results over the Italian dataset
refer to the basic setting of LU4R, i.e. leveraging
just linguistic information.
Conversely, the exper-
iments over the English dataset have been carried
out with the LU4R setting exploiting also percep-
tual
knowledge.
Results against
the commands
in English are encouraging for the application of
LU4R in realistic applications,
with a F1 higher
than 94% in the recognition of semantic predicates
used to express intended actions as well as the in-
volved entities.
We speculate that
the gap w.r.t.
results against the Italian dataset is mainly due to
the lack of perceptual
knowledge as well
as the
reduced size of the dataset.
A more detailed de-
scription of the above evaluation over the English
and Italian dataset is available in (Bastianelli et al.,
2016) and (Vanzo et al., 2016), respectively.
4
Conclusions
In this paper,
we presented LU4R,
an adaptive
SLU processing chain focused on the interpreta-
tion of commands in the Mobile Service Robotics
domain.
The proposed solution relies on Frame
Semantics and Distributional
Lexical
Semantics
to support
example-driven machine learning al-
gorithms that
map individual
sentence transcrip-
tions to meaningful commands.
Statistical learn-
ing,
i.e.
SVM
hmm
,
is applied by transforming
the interpretation process into a cascade of sen-
tence annotation tasks.
The use of Frame seman-
tics enables the reuse of large repositories of ex-
amples (i.e.
(Baker et al.,
1998)),
supporting the
recognition of up to more than 1,000 different se-
mantic frames, currently defined in the FrameNet
database.
The robustness of the sentence interpre-
tation,
as measured in this paper,
is rather good,
where language variability is tackled by relying
on distributional lexical models that generalize se-
mantics for large vocabularies,
well
beyond the
training set
dictionaries.
Moreover,
even though
LU4R is completely decoupled from the Robotic
Platform,
the final
interpretation is made depen-
dent on the robot’s environment, by designing per-
ceptual knowledge through feature modeling. Per-
ceptual knowledge is derived from the robot’s se-
mantic map and translated into feature values. The
corresponding space allow to synthesize informa-
tion about existence and position of named enti-
ties, useful to disambiguate predicates and role as-
signment.
The results gathered during repeated empiri-
cal investigation campaigns confirm the effective-
ness of the proposed tool
and,
in particular,
the
benefits provided by the injection of
perceptual
Knowledge into the understanding (i.e.
labeling)
process.
LU4R is thus an effective example of
grounded language learning framework,
whereas
CLIC_2016_Proceedings.indd 312
02/12/16 15.05
313
predicates and semantic roles are acquired through
an integration between linguistic (e.g.
lexical and
grammatical) properties and perceptual
informa-
tion (e.g.
distances between entities in a map):
this makes LU4R an interesting topic for future
research, such as the extension of command inter-
pretation process to complex interaction patterns,
such as in interactive question answering or dia-
logue.
References
Yasemin Altun,
I.
Tsochantaridis,
and T.
Hofmann.
2003.
Hidden Markov support vector machines.
In
Proc. of ICML.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998.
The berkeley framenet project.
In Proceed-
ings of ACL and COLING, pages 86–90.
Laura Banarescu,
Claire Bonial,
Shu Cai,
Madalina
Georgescu,
Kira Griffitt,
Ulf
Hermjakob,
Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider.
2013.
Abstract meaning representation
for sembanking.
In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse, pages 178–186, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Roberto Basili
and Fabio Massimo Zanzotto.
2002.
Parsing engineering and empirical robustness.
Nat.
Lang. Eng., 8(3):97–120, June.
Roberto
Basili,
Emanuele
Bastianelli,
Giuseppe
Castellucci,
Daniele
Nardi,
and Vittorio Perera.
2013.
Kernel-based discriminative re-ranking for
spoken command understanding in hri.
In AI*IA,
volume 8249, pages 169–180. Springer.
Emanuele Bastianelli,
Giuseppe Castellucci,
Danilo
Croce,
Roberto Basili,
and Daniele Nardi.
2014.
Huric:
a human robot
interaction corpus.
In Pro-
ceedings of LREC 2014, Reykjavik, Iceland, may.
Emanuele Bastianelli,
Danilo Croce,
Roberto Basili,
and Daniele Nardi.
2015.
Using semantic models
for robust natural language human robot interaction.
In AI* IA 2015,
Advances in Artificial Intelligence,
pages 343–356. Springer International Publishing.
Emanuele Bastianelli,
Danilo Croce,
Andrea Vanzo,
Roberto Basili,
and Daniele Nardi.
2016.
A dis-
criminative approach to grounded spoken language
understanding in interactive robotics.
In Proceed-
ings of
the Twenty-Fifth International
Joint
Con-
ference on Artificial Intelligence,
IJCAI 2016,
New
York.
David L. Chen and Raymond J. Mooney.
2011.
Learn-
ing to interpret natural language navigation instruc-
tions from observations.
In Proceedings of the 25th
AAAI Conference on AI, pages 859–865.
Albert
Diosi,
Geoffrey R.
Taylor,
and Lindsay Klee-
man.
2005.
Interactive SLAM using laser and ad-
vanced sonar.
In Proceedings of
the 2005 IEEE
International Conference on Robotics and Automa-
tion,
ICRA 2005,
April
18-22,
2005,
Barcelona,
Spain, pages 1103–1108.
Charles J. Fillmore.
1985.
Frames and the semantics of
understanding.
Quaderni
di
Semantica,
6(2):222–
254.
S.
Harnad.
1990.
The symbol
grounding problem.
Physica D:
Nonlinear
Phenomena,
42(1-3):335–
346.
Geoffrey Hinton,
Li
Deng,
Dong Yu,
Abdel
rahman
Mohamed, Navdeep Jaitly, Andrew Senior, Vincent
Vanhoucke,
Patrick Nguyen,
Tara Sainath George
Dahl,
and Brian Kingsbury.
2012.
Deep neural
networks for acoustic modeling in speech recogni-
tion.
IEEE Signal Processing Magazine, 29(6):82–
97, November.
Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel,
Steven J.
Bethard,
and David Mc-
Closky.
2014.
The Stanford CoreNLP natural lan-
guage processing toolkit.
In Association for Compu-
tational Linguistics (ACL) System Demonstrations,
pages 55–60.
Cynthia Matuszek, Evan Herbst, Luke S. Zettlemoyer,
and Dieter
Fox.
2012.
Learning to parse nat-
ural
language commands
to a robot
control
sys-
tem.
In Jaydev P.
Desai,
Gregory Dudek,
Ous-
sama Khatib,
and Vijay Kumar,
editors,
ISER,
vol-
ume 88 of Springer Tracts in Advanced Robotics,
pages 403–415. Springer.
Andreas N
¨
uchter and Joachim Hertzberg.
2008.
To-
wards semantic maps for mobile robots.
Robot. Au-
ton. Syst., 56(11):915–926.
Morgan Quigley,
Ken Conley,
Brian P.
Gerkey,
Josh
Faust,
Tully Foote,
Jeremy Leibs,
Rob Wheeler,
and Andrew Y.
Ng.
2009.
Ros:
an open-source
robot operating system.
In ICRA Workshop on Open
Source Software.
M. Tanenhaus, M. Spivey-Knowlton, K. Eberhard, and
J.
Sedivy.
1995.
Integration of visual and linguis-
tic information during spoken language comprehen-
sion.
Science, 268:1632–1634.
Peter D.
Turney and Patrick Pantel.
2010.
From fre-
quency to meaning: Vector space models of seman-
tics.
J. Artif. Int. Res., 37(1):141–188, January.
Andrea Vanzo,
Danilo Croce,
Giuseppe Castellucci,
Roberto Basili,
and Daniele Nardi.
2016.
Spoken
language understanding for service robotics in ital-
ian.
In 15th International Conference of the Italian
Association for Artificial
Intelligence,
page to ap-
pear.
CLIC_2016_Proceedings.indd 313
02/12/16 15.05
314
Abad Azad 46
Aivars Glaznieks 13
Alfieri Linda 19
Alfter David 24
Alicante Anita 29, 34
Andrea Abel 13
Arcara Giorgio 146
Baiamonte Daniela 40
Barlacchi Gianni 46
Basile Pierpaolo 51, 56, 168
Basile Valerio 51
Basili Roberto 111, 308
Bellandi Andrea 243
Benjamin Martin 211
Benotto Giulia 61, 243
Bernardi Raffaella 237
Bizzoni Yuri 24
Bogers Toine 66
Bompolas Stavros 72
Bondielli Alessandro 228
Bordea Georgeta 66
Bosco Cristina 274
Bottini Roberto 78
Bracchi Alice 83
Brunato Dominique 248
Budassi Marco 233
Buitelaar Paul 66
Cabrio Elena 51
Caputo Annalina 56
Cardillo Franco Alberto 72, 146
Caruso Valeria 89
Casasanto Daniel 78
Caselli Tommaso 40, 83
Chatterjee Rajen 94
Cherchi Manuela 285
Chiusaroli Francesca 211
Corazza Anna 29, 34, 100, 129
Corino Elisa 105
Crepaldi Davide 78
Croce Danilo 111, 308
Culy Chris 185
Curci Antonietta 168
Cutugno Francesco 129
De Martino Maria 190
De Meo Anna 89
Del Tredici Marco 117
Dell’Orletta Felice 222, 248, 297
Desantis Anna 285
Di Nunzio Giorgio Maria 123
Egon Stemle 13
Esposito Fabrizio 129
Fantini Anna 129
Feltracco Anna 141
Ferro Marcello 72, 146
Ferro Nicola 66
Filice Simone 111
Franzon Francesca 146
Frey Jennifer-Carmen 157
Gagné Christina L. 146
Gebremelak Gebremedhen 94
Giovannetti Emiliano 61, 243
Glaznieks Aivars 157
Gregori Lorenzo 162
Guglielmi Francesca 168
Herbelot Aurelie 237
Hernandez Farias Delia Irazu 274
Iovino Rossella 222
Isgrò Francesco 29
Jezek Elisabetta 141, 253
Lai Mirko 274
Laudanna Alessandro 190
Lavelli Alberto 173
Lebani Gianluca E. 268
Lenci Alessandro 228, 258, 268
Lieto Antonio 179
Lionel Nicolas 13
Litta Eleonora 185
Logozzo Felicia 190
Luisi Roberta 56
Maggio Valerio 100
Magnini Bernardo 141, 205, 253
Maistro Maria 123
Mancuso Azzurra 190
Mansour Sina 211
Marchi Simone 61
Marzi Claudia 72
Mazzei Alessandro 200
Mencarini Letizia 274
Mensa Enrico 179
Minard Anne-Lyse 205
Mitkov Ruslan 285
Montemagni Simonetta 297
Monti Johanna 211, 285
Moretti Giovanni 216
Moschitti Alessandro 46, 303
Mozzachiodi Michele 274
Nadalini Andrea 78
Nardi Daniele 308
Negri Matteo 94
Nissim Malvina 117
Orletti Franca 222
Palmero Aprosio Alessio 291
Panunzi Alessandro 162
Passaro Lucia C. 228
Passarotti Marco 185, 233
Patti Viviana 274
Pezzelle Sandro 237
Piccini Silvia 243
Pieri Giulia 248
Pironti Antonio 34
Pirrelli Vito 72. 146
Pisano Simone 263
Index of authors
CLIC_2016_Proceedings.indd 314
02/12/16 15.05
315
Ponti Edoardo Maria 253
Prodanof Irina 40, 83
Qwaider Mohammed R. H. 205
Radicioni Daniele P. 179
Ravelli Andrea Amelio 162
Rodda Martina A. 258
Rossinelli Emanuele 46
Russo Claudio 105
Russo Irene 263
Saltori Francesca 291
Sangati Federico 211
Scanniello Giuseppe 100
Semeraro Giovanni 56, 168
Senaldi Marco S. G. 258, 268
Silvello Gianmaria 66
Silvestri Stefano 29
Soria Claudia 263
Sorodoc Ionut 237
Spalding Thomas L. 146
Speranza Manuela 205
Sprugnoli Rachele 216
Stede Manfred 141
Stemle Egon W. 157
Sulis Emilio 274
Tamburini Fabio 19, 280
Taslimipoor Shiva 285
Tonelli Sara 216, 291
Turchi Marco 94
Tusa Erica 297
Uva Antonio 303
Vanzo Andrea 308
Venturi Giulia 297
Vignoli Daniele 274
Villata Serena 51
Vitale Vincenzo Norman 89
Zaninello Andrea 117
Zanini Chiara 146
Zilio Daniel 123
CLIC_2016_Proceedings.indd 315
02/12/16 15.05
