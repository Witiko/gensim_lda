Matthias Feys
nieuwscollecties
Extractie en disambiguatie van events in grote
Academiejaar 2012-2013
Faculteit Ingenieurswetenschappen en Architectuur
Voorzitter: prof. dr. ir. Daniël De Zutter
Vakgroep Informatietechnologie
Master in de ingenieurswetenschappen: elektrotechniek
Masterproef ingediend tot het behalen van de academische graad van
Begeleider: ir. Johannes Deleu
Promotoren: prof. dr. ir. Chris Develder, dr. ir. Thomas Demeester
Matthias Feys
nieuwscollecties
Extractie en disambiguatie van events in grote
Academiejaar 2012-2013
Faculteit Ingenieurswetenschappen en Architectuur
Voorzitter: prof. dr. ir. Daniël De Zutter
Vakgroep Informatietechnologie
Master in de ingenieurswetenschappen: elektrotechniek
Masterproef ingediend tot het behalen van de academische graad van
Begeleider: ir. Johannes Deleu
Promotoren: prof. dr. ir. Chris Develder, dr. ir. Thomas Demeester
Voorwoord
Bij
het zoeken van een thesis-onderwerp,
sprong deze thesis meteen in het oog.
Tijdens het
eerste gesprek over de thesis werd mijn interesse nog groter.
Dit enerzijds doordat ik een beter
beeld had over de thesis en anderzijds door de heel
vlotte communicatie.
Hierdoor was de
keuze voor deze thesis heel
snel
gemaakt.
Daarom wens ik eerst mijn promotors te bedanken
om mij de mogelijkheid te geven om gedurende mijn laatste masterjaar aan deze thesis te werken.
Natuurlijk is een onderwerp en interesse alleen niet genoeg om een thesis af te leveren.
Gedurende
mijn thesis kon ik steeds bij dr.
ir.
Thomas Demeester en ir.
Johannes Deleu terecht voor al
mijn vragen en problemen.
Ik kon altijd op hen rekenen voor ondersteuning,
waarvoor ik hen
heel
dankbaar ben.
Ook mijn promotor prof.
dr.
ir.
Chris Develder zou ik graag bedanken
voor zijn tips en tijd.
Bovendien wil ik naast mijn begeleider en promotors ook Koen Staelens
bedanken voor het zoeken naar spel- en grammaticale fouten in deze thesis en mijn zus Elien
om als tweede persoon artikels te annoteren.
Tenslotte wens ik mijn ouders,
familie en vrienden te bedanken voor de steun en ontspanning
tijdens het werken aan de thesis.
Matthias Feys, juni 2013
Toelating tot bruikleen
“De auteur geeft de toelating deze scriptie voor consultatie beschikbaar te stellen en delen van
de scriptie te kopi
¨
eren voor persoonlijk gebruik.
Elk ander gebruik valt onder de beperkingen van het auteursrecht,
in het bijzonder met be-
trekking tot de verplichting de bron uitdrukkelijk te vermelden bij het aanhalen van resultaten
uit deze scriptie.”
Matthias Feys, juni 2013
Extractie en disambiguatie van events
in grote nieuwscollecties
Matthias FEYS
Masterproef ingediend tot het behalen van de academische graad van
Master in de ingenieurswetenschappen:
elektrotechniek
Promotoren:
prof. dr. ir. Chris Develder, dr. ir. Thomas Demeester
Begeleider:
ir. Johannes Deleu
Vakgroep Informatietechnologie
Voorzitter:
prof. dr. ir. Dani
¨
el De Zutter
Faculteit Ingenieurswetenschappen en Architectuur
Universiteit Gent
Academiejaar 2012–2013
Samenvatting
Om de schat aan informatie vervat in kranten en magazines in de vorm van verschillende artikels
beter te kunnen benutten,
zal
er tijdens deze thesis een methode worden gezocht om nuttige
informatie te extraheren.
Meer concreet zullen we de meest belangrijke gebeurtenissen,
zoals
bv. de Aanslag in Noorwegen door Anders Behring Breivik, trachten te extraheren.
Op deze manier bekomen we dan een meer bruikbare voorstelling van de enorme set artikels.
Om deze lijst van events te bekomen, voeren we twee stappen uit.
Eerst zullen we een voorstelling
van documenten genereren die door de computer bruikbaar is,
concreet zal
dit een vector-
voorstelling zijn.
Daarna worden deze verschillende vectoren geclustered.
De bekomen clusters
stellen nu de verschillende events voor.
Bij de tekstvoorstellingstap, zullen we de nadruk leggen op het gebruik van temporele informatie
vervat in de artikelverzameling (de publicatiedatum van de artikels) om een betere tekstvoorstelling
te bekomen.
Hierbij
vertrekken we van de BurstVSM -tekstvoorstelling voorgesteld in [Zhao et al., 2012].
Deze zal uitvoerig worden onderzocht en op basis van deze resultaten stellen we dan een nieuwe
tekstvoorstelling voor, Boosted BurstVSM.
Voor het clusteren van de artikels stellen we een incrementele densiteitsgebaseerd clusteralgo-
ritme voor, waarvan de werking goed overeenkomt met het DBSCAN -algoritme.
Tenslotte zijn er ook nog visualisaties voorzien van de resultaten, door middel van een Timeline
en werd er een testset aangemaakt om de performantie van de verschillende algoritmes te ver-
gelijken.
Trefwoorden: event-detectie, burst-detectie, Temporal Information Retrieval, Information Ex-
traction
Extraction and disambiguation of events
from large news collections
Matthias Feys
Supervisors: prof. dr. ir. Chris Develder, dr. ir. Thomas Demeester,
ir. Johannes Deleu
Abstract— The current information age confronts people with a
new problem: information overload. This started the interest in in-
formation extraction techniques that autonomously gather struc-
tured information from massive datasets.
One such technique is
the extraction of events from news-collections. In our work we pro-
pose a complete event-detection methodology using a novel boosted
burst-based text representation and an incremental clustering al-
gorithm.
Considerable improvements over existing text represen-
tations were obtained.
Keywords—event detection, burst detection, Temporal Informa-
tion Retrieval, Information Extraction
I.
I
NTRODUCTION
T
HE problem of event-detection was first tackled by
the seminal
work on topic detection and tracking
(TDT, [1]) in which news stories are assigned to individ-
ual news topics. The detection consists of two steps: first
representing the documents as vectors and calculate sim-
ilarities between documents, afterwards grouping similar
documents to define the events.
In recent years, the research community has shown an in-
creasing interest into the “burstiness” of topics [2], where
the important topics are identified using bursts,
defined
as sudden surges of the presence of the topic in the text
stream.
These bursts are then used to improve the text
representation for various retrieval applications [2], [3].
Two contributions ([4],
[5]) showed particularly impor-
tant
for the current
work,
discussing two different
ap-
plications of these bursts.
Both utilize bursts to gen-
erate a temporal
text
representation.
This implies that
the representation of a document depends on the time-
stamp, in contrast to more traditional weighting methods
such as Term Frequency Vector Space Model(TF-VSM),
and Term Frequency-Inverse Document Frequency Vec-
tor Space Model(TFIDF-VSM).
The first contribution [4] introduces the boosting of bi-
nary term weights based on the corresponding bursts.
The second [5] proposes a burst-based text
representa-
tion, using bursts of terms as features for the text repre-
sentation instead of the terms themselves,
hence result-
ing in a more compact text representation,
significantly
reducing the number of non-zero entries in the document
representation.
In this work we propose improvements to both models
and combine them into a novel boosted burst-based text
representation model.
The remainder of this abstract contains 4 sections.
Sec-
tion 2 summarizes our methodology.
Sections 3 and 4
discuss the testset and obtained results.
The conclusions
to be derived from a document,
e.g.,
term feature
type, title term feature type.
• Feature selection/transformation:
select and trans-
form features,
e.g.,
both rarely used and overly
common term features may be discarded.
• Feature weighting:
assign weight to a feature type
based on a given formula,
e.g.,
binary,
TF,
and
TFIDF.
3.2
Motivation for Bursty Topic Representa-
tion Bursty topics can be emphasized by considering
only certain time windows and bursty features.
For ex-
ample,
the word feature “hurricane” from topic “Hur-
ricane Mitch” shown in Figure 3 overlaps significantly
with the topic document frequency.
In this example, a
feature traffic vs. topic traffic
0
20
40
1-Oct-98
17-Oct-98
2-Nov-98
18-Nov-98
4-Dec-98
20-Dec-98
time
feature: hurricane
topic: Hurricane Mitch
document
frequency
burst
Figure 3:
Traffic overlap between a bursty topic and its
feature “hurricane”.
total of 401 documents contain the feature “hurricane”,
among which 97 are outside of the “Hurricane Mitch”
topic.
If “hurricane” were the only feature discriminat-
ing this topic from the rest, the corresponding precision
would be (401 − 97)/401 = 75.81%.
From Figure 3,
if we only take into account the bursty period of word
feature “hurricane” lasting from 24-Oct to 16-Nov, only
10 out of
the 260 documents containing the word fea-
ture “hurricane” are off-topic,
thereby yielding a 20%
improvement in precision at (260 − 10)/260 = 96.15%!
The above simple example illustrates the benefit of
using a single bursty feature restricted to certain bursty
time periods over the whole life span of a topic.
If more
bursty periods and their associated bursty features are
identified,
they could collectively improve the overall
distinctiveness of each topic.
Such discriminative
features
with corresponding
bursty life spans are called “bursty features” in this
paper.
To find bursty features,
the burstiness of every
word feature in the corpus with respect to all topics will
have to be computed.
In this example,
we would need
to determine a set of features for the “Hurricane Mitch”
topic, and their corresponding bursty life spans.
This is
a challenging problem because the i-th document in a
text stream now has a dynamic vector representation
d
i
(t)
that
depends
on time
stamp t.
In the
next
section,
we shall
present our proposed bursty feature
representation to this challenging problem.
4
Bursty Feature Representation
We
now describe
our
bursty feature
representation
that combines burstiness with static feature weights.
Representing a document with bursty features involves
two major steps:
(1) identifying bursty features, and (2)
representing documents using bursty features/weights,
as shown in Figure 4.
Figure 4:
An overview of bursty feature representation.
In Figure 4, a document is assigned bursty weights
depending on its time stamp t.
The same raw document
may have different bursty feature representations at two
different time points t
i
6= t
j
.
In Section 4.1,
we will
first
describe how bursty
features can be identified.
This is followed by the bursty
feature representations in Section 4.2.
4.1
Bursty Feature Identification Bursty feature
identification from text
streams
have
recently been
investigated by a number of researchers [6, 7, 19].
Since
the goal of this paper is to utilize bursty features and not
to develop a new bursty feature identification algorithm,
we simply adopt Kleinberg’s [7] 2-state finite automaton
model to identify bursty features, as shown in Figure 5.
Figure 5:
A 2-state finite automaton model
for identi-
fying bursty features.
There are two states q
0
and q
1
in the finite automa-
ton model A of Figure 5.
For every feature f in a text
stream,
when A is in state q
0
at time point t,
it has a
low emission rate β
0
= |R
d
|/T ,
where |R
d
|
is the size
of
all
relevant documents containing f over the whole
Fig. 1.
Boosted BurstVSM architecture
can finally be found in section 5.
II.
M
ETHODOLOGY
The
proposed
methodology
consists
of
a
text-
representation part and a clustering part. These two parts
will now be discussed in detail.
A.
Boosted BurstVSM
Our
text-representation part
is schematically repre-
sented in figure 1,
this part
consists of two steps as in
[5] and [4].
The architecture is based on BurstVSM [5].
First
the
bursts of the different terms are identified using the two-
state automaton introduced by Kleinberg [2].
These
retrieved bursts
are subsequently used as
the bursty-
features in the document representation.
To obtain better results,
we performed weighted mov-
ing average on the document
frequencies of the terms
to make the burst-detection algorithm more robust to the
strong variance (visible in figure 2) of the document fre-
quencies.
The document representation of our Boosted BurstVSM-
representation consists of a vector containing the weights
of the bursty-features present in the document. A bursty-
feature is present if the corresponding term is present in
the document and if the timestamp of the document lies
within the period of the burst.
The weight
w
i
of bursty
feature
i
based on a term
j
, is defined as:
w
i
= T F IDF
j
· b
i
,
(1)
based on the TFIDF of term
j
in this document and the
boosting factor
b
i
of bursty feature
i
, proportional to the
weight of the burst.
Note that
this deviates from the bursty-feature weight
used in BurstVSM [5],
where the weight
w
i
is defined
as:
w
i
= T F IDF
i
,
(2)
thus only utilizing the TFIDF of the bursty-feature itself,
calculated using as document frequency only the number
of documents containing the bursty-feature itself.
Our boosting was inspired by He [4] in which the binary
term frequencies were boosted by adding a boosting fac-
tor.
But after a thorough study of this boosting we pro-
posed an optimized boosting factor (burst weight),
and
chose to multiply the feature weight with a boosting fac-
tor instead of adding a boosting factor, thereby omitting
an extra parameter. Furthermore this multiplied boosting
made it compatible with IDF-reweighting.
Some other extensions for the bursty-feature identifica-
tion were discussed, using a modified burst-detection al-
gorithm or other text stream input, but none consistently
outperformed the Boosted BurstVSM on all aspects.
B.
Incremental Density Based Clustering
To group the similar documents,
we constructed an
incremental
cluster algorithm,
determining the optimal
number
of
clusters during the clustering.
We opted
for a density-based algorithm since this kind of cluster-
ing doesn’t assign all documents to at least one cluster.
Density-based algorithms form clusters based on a min-
imum number of similar documents as proposed in the
DBSCAN-algorithm [6].
This way, documents not hav-
ing many similar documents will be neglected.
In addition,
we incorporated the temporal
character of
events by sequentially iterating over the set of documents
and only considering documents in the small
temporal
neighbourhood of each document (documents published
the previous or the same day).
This way we were able
to gain substantial
speed improvements over clustering
without
this temporal
character,
without
degrading the
quality of the resulting clustering,
this temporal restric-
tions even resulted in some quality improvements.
III.
E
VALUATION TESTSET
To quantitatively compare our different
implementa-
tions,
we tested the algorithms on a collection of news-
articles published in 2011.
We manually retrieved and
annotated documents belonging to 13 different
events.
These are used as the baseline for evaluating our event
detection approach.
IV.
R
ESULTS
A.
Bursty feature identification and text representation
For two example terms (“december” and “Pukkelpop”)
the detected bursts and their corresponding weights are
shown in figure 2.
It
can be observed that
the bursts
corresponding with strong peaks are more favoured us-
ing the new burst
weight
for Boosted BurstVSM.
This
results in an increase of the intersimilarity of the docu-
ments from the baseline events, see table I.
1
These are averaged over the different events.
We considered two
classes per event, the documents relevant for the event, and the docu-
ments published in this period but not relevant.
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
Date
0
50
100
150
200
250
Document Frequency
0
200
400
600
800
1000
1200
1400
1600
1800
burst weight
DF 'december' 
DF `Pukkelpop' 
bursts BurstVSM
bursts Boosted BurstVSM
Fig.
2.
Document
frequencies
(DF)
and the corresponding ob-
tained bursts using Boosted BurstVSM vs.
the original
detected
burst(weight)s used in [4][5].
TABLE I
C
OMPARISON OF THE MEAN INTER
-
AND INTRASIMILARITY
1
BurstVSM Boosted BurstVSM
intersimilarity
0.556
0.621
intrasimilarity
0.00680
0.00622
B.
Boosted BurstVSM for event-detection
The
results
of
the
clustering
using
the
Boosted
BurstVSM text
representation
vs.
the
standard
BurstVSM and the popular TFIDF-VSM are shown in
table II.
Confirming the improvements of the suggested
Boosting.
TABLE II
C
OMPARISON OF QUALITY OF THE RESULTING EVENTS
Boosted
TFIDF-VSM BurstVSM BurstVSM
F
1
-measure
0.582
0.562
0.682
# events
3099
2612
2630
V.
C
ONCLUSIONS
This thesis presents an implementation and analysis of
two bursty text representations.
Based on this analysis
we were able to suggest some improvements.
The com-
bination of these improved representations subsequently
lead to a new Boosted BurstVSM model.
This model
outperformed the original BurstVSM as well as the pop-
ular TFIDF-VSM.
These results prove that the burst-based text representa-
tion is an attractive approach.
The effective combination
of two different models clearly shows opportunities for
further research in the combination of even more mod-
els.
R
EFERENCES
[1]
James Allan,
Jaime G Carbonell,
George Doddington,
Jonathan
Yamron,
and Yiming Yang,
“Topic detection and tracking pilot
study final report,” 1998.
[2]
J Kleinberg,
“Bursty and hierarchical structure in streams,” Data
Mining and Knowledge Discovery, pp. 373–397, 2003.
[3]
Wei Chen and Parvathi Chundi,
“Extracting Hot spots of Topics
from Time Stamped Documents.,” Data & knowledge engineering,
vol. 70, no. 7, pp. 642–660, July 2011.
[4]
Q He, K Chang, EP Lim, and J Zhang,
“Bursty feature representa-
tion for clustering text streams,” Proc. SIAM Conference on Data
Mining, pp. 491–496, 2007.
[5]
WX Zhao,
Rishan Chen,
Kai
Fan,
Hongfei
Yan,
and Xiaoming
Li,
“A novel
burst-based text
representation model
for scalable
event detection,”
Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics:
Short Papers-Volume
2, , no. July, pp. 43–47, 2012.
[6]
Martin Ester,
Hans-Peter Kriegel,
J
¨
org Sander,
and Xiaowei Xu,
“A density-based algorithm for discovering clusters in large spatial
databases with noise,” Kdd, 1996.
INHOUDSOPGAVE
i
Inhoudsopgave
Lijst van figuren
iii
Afkortingen
v
1
Inleiding
1
1.1
Probleemstelling
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1
1.2
Doelstelling
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1
1.3
Overzicht hoofdstukken
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
2
Literatuurstudie/achtergrond
3
2.1
Basisconcepten
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
3
2.1.1
Tekstvoorstelling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
4
2.1.2
Gewichtsfuncties / VSM-uitbreidingen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
5
2.1.3
Verdere behandeling corpus
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
6
2.1.4
Evaluatiemetrieken .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7
2.2
State of the art
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2.2.1
Temporal Information Retrieval .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2.2.2
Clustering .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
2.2.3
Burstiness en event-detectie .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
13
Burst-detectie .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
13
Bursty-weighting .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16
Feature-pivot clustering
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
2.3
Conclusie
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
3
Het corpus
20
3.1
Analyse van het corpus
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
3.1.1
Preprocessing .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
3.1.2
Statistieken van het corpus
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
Corpusfrequenties
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
Termfrequenties
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
3.2
Structuur van het corpus
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
INHOUDSOPGAVE
ii
3.3
Framework voor corpusbehandeling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.3.1
Gensim .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27
3.3.2
Timesim .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
29
4
Modellering
32
4.1
Tekstvoorstellingen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
4.1.1
Analyse van BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
Ruis op de documentfrequenties
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
33
IDF-herweging
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
33
4.1.2
Toepassing van conclusies uit ander onderzoek
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
Feature-selectie .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
Feature-gewichten
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
37
4.1.3
Boosted BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
37
Boosting .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
38
Verfijning feature-selectie
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
40
4.1.4
Combineren van corpora .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
4.2
Clusteralgoritmen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
4.2.1
Afweging tussen de verschillende modellen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
4.2.2
Gebruik temporele informatie .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
5
Implementatie
45
5.1
Tekstvoorstellingen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45
5.1.1
BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45
5.1.2
Boosted BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48
5.1.3
Combinaties .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
49
5.2
Clusteralgoritmen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
49
5.2.1
Recursief
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
51
5.2.2
Sequentieel
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
53
5.2.3
Hi
¨
erarchisch clusteralgoritme
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
5.2.4
Serialiseren van de clusters
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
5.3
Visualisaties .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
56
5.3.1
Naamgeving events .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
56
5.3.2
Timeline .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
5.3.3
Artikelbrowser
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
58
5.4
Samenvatting .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
59
6
Evaluatiemethodologie
61
6.1
Testset .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
61
6.1.1
De gebeurtenissen/events
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
61
6.1.2
Afwegingen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
62
6.2
Evaluatiemethodes
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
62
INHOUDSOPGAVE
iii
6.2.1
Kwalitatieve analyse gevonden bursts
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
63
6.2.2
Inter- en intra-similarities
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
64
6.2.3
Doeltreffendheid gevonden events .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
65
7
Evaluatieresultaten
68
7.1
Tekstvoorstellingen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
69
7.1.1
Burst-detectie en parameters
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
69
Emissie-parameter s
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
69
Toestandstransitieprobabileit p
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
73
Verband tussen s en p .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
75
Uitmiddeling van documentfrequenties .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
75
7.1.2
IDF-herweging
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
77
7.1.3
Boosted BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
77
Accumulated Boosted BurstVSM-tekstvoorstellingen .
.
.
.
.
.
.
.
.
.
.
.
78
Multiplied Boosted BurstVSM-tekstvoorstellingen
.
.
.
.
.
.
.
.
.
.
.
.
.
79
Invloed DF-uitmiddeling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
80
7.1.4
Verfijning feature-selectie
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81
7.1.5
Gebruik eigennamen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82
7.1.6
Combinaties van woorden en eigennamen
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
84
7.2
Clusteralgoritmen .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
84
7.2.1
Gebruikte clusteralgoritme
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
85
Analyse parameters
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
85
Postprocessing
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
86
7.2.2
Andere clusteralgoritmen
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
86
7.3
Conclusie
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
87
8
Conclusies
89
9
Future work
91
A Appendices
92
A.1
Code Python-functie die clusters zoekt in minicorpus .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
92
A.2
Interpretatie TFIDF bij BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95
Bibliografie
97
LIJST VAN FIGUREN
iv
Lijst van figuren
2.1
Weergave van een voorbeeld inverted-index
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
6
2.2
Weergave van het probleem bij burst-detectie m.b.v.
een treshold .
.
.
.
.
.
.
.
.
14
2.3
Voorstelling van het HMM voor het burst-detectie algoritme .
.
.
.
.
.
.
.
.
.
.
.
16
3.1
Termdistributies van het corpus .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
3.2
Ruwe globale termfrequenties
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
3.3
Herwogen globale termfrequenties, logaritmische IDF .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
25
3.4
Herwogen globale termfrequenties bestaande, niet-logaritmische IDF .
.
.
.
.
.
.
25
4.1
Architectuur BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
33
4.2
Documentfrequenties van de term “mij”
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
4.3
Documentfrequenties en bursts van de termen “Pukkelpop” en “Marijke”
.
.
.
.
35
4.4
Documentfrequenties en bursts van de termen “Pukkelpop” en “december”
.
.
.
39
5.1
Grafische voorstelling van de clusteralgoritmen
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
5.2
Illustratie van de Timeline .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
58
5.3
Illustratie van de artikelbrowser .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
59
5.4
Schematische voorstelling van de pijplijn van transformaties
.
.
.
.
.
.
.
.
.
.
.
.
60
7.1
Simulatie van de impact van de emissieparameter s op de emissiekost-winst
.
.
.
71
7.2
Invloed van emissie-parameter s op burst-detectie .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
72
7.3
Invloed van toestandstransitieprobabiliteit p op burst-detectie .
.
.
.
.
.
.
.
.
.
.
74
7.4
Invloed DF-uitmiddeling op aantal gevonden bursty-features en events
.
.
.
.
.
.
75
7.5
Invloed DF-uitmiddeling op event-detectie met BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
76
7.6
Invloed DF-uitmiddeling op event-detectie met log MSB BurstVSM .
.
.
.
.
.
.
76
7.7
F
1
-measures bij gebruik AB BurstVSM tekstvoorstellingen .
.
.
.
.
.
.
.
.
.
.
.
.
78
7.8
F
1
-measures bij gebruik MB BurstVSM tekstvoorstellingen
.
.
.
.
.
.
.
.
.
.
.
.
80
7.9
Invloed van feature-verfijning op de gevonden bursts
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82
7.10 Invloed van p op de burst-detectie bij gebruik van eigennamen
.
.
.
.
.
.
.
.
.
.
83
7.11 Invloed van M inP ts op het aantal gevonden bursty-features en events bij gebruik
van log MSB-BurstVSM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
85
AFKORTINGEN
v
Afkortingen
ASB BurstVSM Accumulated Saturated Boosted BurstVSM
CF
Corpus Frequentie
DBSCAN
Density Based Spatial Clustering of Applications with Noise
DF
Document Frequentie
HDP
Hierarchical Dirichlet Process
HMM Hidden Markov Model
IE
Information Extraction
IR
Information Retrieval
LDA
Latent Dirichlet Allocation
LSI
Latent Semantic Indexing
ML
Machinaal Leren
MSB BurstVSM Multiplied Saturated Boosted BurstVSM
NLP
Natural Language Processing
PLSI
Probabilistic Latent Semantic Indexing
TDT
Topic Detection and Tracking
TF
Term Frequentie
TF-IDF / TFIDF
Term Frequency - Inverse Document Frequency
TTM Temporal Text Mining
VSM Vector Space Model
INLEIDING
1
Hoofdstuk 1
Inleiding
1.1
Probleemstelling
Kranten en magazines bevatten een schat aan informatie over personen, bedrijven, gebeurtenis-
sen,
etc.
Deze informatie is van groot belang om een beeld te kunnen vormen van de publieke
opinie of om bijvoorbeeld een samenvatting van de geschiedenis te kunnen vormen.
Het probleem is dat kranten en magazines zoveel
informatie bevatten dat er een “information
overload” is.
Hierdoor is het voor de mens quasi
onmogelijk om effici
¨
ent informatie terug te
vinden in deze ongestructureerde teksten.
1.2
Doelstelling
Het doel
van de thesis is om vertrekkende van de massale hoeveelheid artikels aanwezig in het
Mediargus-archief (verzameling van Nederlandstalige kranten en magazines) een interessantere
voorstelling/weergave te kunnen maken.
Hiervoor zal
vooral
gebruik worden gemaakt van het
temporele aspect.
We zullen technieken onderzoeken om belangrijke gebeurtenissen (waarover het archief informatie
bevat) te detecteren.
Dit zal gebeuren op basis van de datering van artikels (de zgn.
timestamp
in het media-archief) en extractie van informatie die ze bevatten.
We zullen hiertoe eigen tech-
nieken ontwikkelen en/of basistechnieken uit de literatuur verbeteren en met elkaar vergelijken.
Voorbeelden van zo’n belangrijke gebeurtenissen zijn de aanslagen in Noorwegen door Anders
Behring Breivik op 22 juli
2011,
of
de dood van Osama bin Laden op 2 mei
2011.
Vanuit
menselijk standpunt zou ons systeem dergelijke belangrijke gebeurtenissen automatisch moeten
terugvinden als we een overzicht willen maken van de gebeurtenissen tijdens een bepaald jaar.
Om dit te bereiken,
zullen we achtereenvolgens drie fases beschouwen.
In de eerste fase zal
er een voorstelling van de documenten worden gemaakt waarin de temporele informatie vervat
zit.
Deze beschrijving zal
in de tweede fase gebruikt worden om dan effectief
de belangrijke
1.3 Overzicht hoofdstukken
2
gebeurtenissen (events) terug te vinden die dan in een derde fase worden weergegeven aan de
gebruiker.
Een belangrijk onderdeel
zal
ook het testen van deze verschillende stappen zijn en dit aan de
hand van zelf-geannoteerde data.
1.3
Overzicht hoofdstukken
De thesis is onderverdeeld in 8 hoofdstukken die hieronder besproken worden.
In hoofdstuk 2 wordt er een basis gelegd door verschillende basisbegrippen te introduceren en
wordt het huidige gerelateerd onderzoek samengevat.
Verder volgt er ook een betere beschrijving
van “state of the art”-onderzoek naar gebeurtenis-detectie in teksten.
Hoofdstuk 3 geeft een beschrijving van het corpus,
het gebruikte kranten-archief,
door deze te
analyseren en de voornaamste bevindingen op te sommen.
Verder wordt er ook besproken welke
stappen noodzakelijk zijn om deze verzameling krantenartikels te gebruiken en hoe het frame-
work waarmee deze behandeld worden concreet in elkaar zit.
In hoofdstuk 4 zullen de bestaande technieken die beschreven werden in hoofdstuk 2 besproken
en vergeleken worden.
Op basis hiervan zullen dan concrete verbeteringen worden voorgesteld
en verantwoord.
Deze verbeteringen worden dan samen met hun oorspronkelijke technieken ge
¨
ımplementeerd en
meer uitleg hierover is terug te vinden in hoofdstuk 5.
Verder worden ook (de implementatie
van) de tools beschreven die gebruikt worden om de gevonden gebeurtenissen visueel
weer te
geven.
Hoofdstuk 6 bespreekt de gebruikte methoden om de ge
¨
ımplementeerde technieken kwantitatief
te evalueren.
Hierbij wordt ook stilgestaan bij het aanmaken van de referentieset van gebeurtenis-
sen en de verschillende afwegingen die hierbij gemaakt werden.
In hoofdstuk 7 zijn dan de effectieve resultaten van de verschillende technieken terug te vinden
die ook met elkaar vergeleken worden.
Tenslotte kan een conclusie van de thesis en een opsomming van de mogelijke verbeteringen
gevonden worden in de hoofdstukken 8 en 9.
LITERATUURSTUDIE/ACHTERGROND
3
Hoofdstuk 2
Literatuurstudie/achtergrond
In de eerste sectie van dit hoofdstuk volgt een beknopte beschrijving van het domein waarin de
thesis zich situeert,
gevolgd door een samenvatting van de meest relevante begrippen met be-
trekking tot deze thesis.
Zo wordt de terminologie rond tekstvoorstellingen doornomen, worden
verschillende gewichtsfuncties horende bij de tekstvoorstellingen vergeleken en volgt er een kort
overzicht van mogelijke verdere bewerkingen op de tekst.
Tenslotte zullen enkele evaluatieme-
trieken beschreven worden die later in de thesis gebruikt worden.
In de tweede sectie wordt er vervolgens dieper ingegaan op onderzoek dat reeds de temporele
informatie in de tekstuele data benut.
2.1
Basisconcepten
De thesis situeert zich in het domein van Information Retrieval
(IR) [Manning et al., 2008].
Dit domein houdt zich bezig met methodes om het zoeken van informatie in tekstuele data
mogelijk te maken, zoals bv. een krantenarchief.
Hierbij zal verder gebruik gemaakt worden van
technieken uit het domein van Machinaal
Leren (ML) [Bishop, 2007].
ML-technieken kunnen
leren, i.e. informatie extraheren uit een grote set data.
Meer specifiek zal er gewerkt worden met
Information Extraction (IE) algoritmes, die automatisch gestructureerde informatie extraheren
uit ongestructureerde documenten.
Deze gestructureerde informatie kan dan opgeslagen worden
in een database.
In het geval van deze thesis zou de database dan verschillende gebeurtenissen
bevatten,
die worden gekenmerkt door een set van documenten en waarbij informatie over de
gebeurtenissen opgeslagen wordt zoals hun tijdsduur en kenmerken zoals de corresponderende
locaties, personen, etc.
Verder maken we ook gebruik van technieken uit Natural
Language Processing (NLP)
[Jurafsky & James, 2000].
Er wordt namelijk gewerkt met teksten uit de krantenartikels.
Zo
zullen er enkele courante veronderstellingen gebruikt worden uit NLP en wordt er ook gebruik
gemaakt van technieken om automatisch de eigennamen [Sutton & McCallum, 2010] uit teksten
2.1 Basisconcepten
4
terug te vinden.
Dit zijn namen van personen, locaties, organisaties, etc.
2.1.1
Tekstvoorstelling
In IR terminologie worden verschillende onderdelen van een tekstverzameling met een specifieke
naam aangeduid:
Corpus:
een verzameling van documenten die op een bepaalde manier worden voorgesteld.
Tijdens deze thesis zal
het corpus een nieuwsarchief zijn,
bestaande uit een verzameling
van artikels.
Document:
een stuk tekst die wordt voorgesteld door een lijst van features.
Deze stukken
tekst zullen hier dus concreet de verschillende artikels zijn uit het nieuwsarchief.
Feature:
een eigenschap van een document.
Een veelgebruikte feature is het voorkomen van
een bepaalde term in de tekst van het document,
of
bij
temporele documenten bv.
de
timestamp van het document.
Term:
een term is een woord of een verzameling woorden die ´e´en geheel vormen.
Voorbeelden
zijn namen bestaande uit voornaam en familienaam, zoals de term “Yves Leterme”.
Ter-
men vormen dus een soort subset van de woordverzameling.
Woord:
een woord is een verzameling karakters (token) die een semantische betekenis heeft
en wordt meestal
als basis genomen voor documentvoorstelling.
Verder kan er ook pre-
processing gebeuren op deze woorden om een betere voorstelling van een document te
bekomen.
Zo kunnen stopwoorden (algemene woorden zoals “de”,
“een” die geen echte
betekenis hebben in een tekst) verwijderd worden enz.
De verzameling van woorden is dus
een subset van de verzameling tokens.
Token:
een opeenvolging van karakters in een tekst die gesplitst worden door witruimtes of
leestekens.
Timestamp:
dit is de datum die bij een bepaald document hoort.
Aangezien er in deze the-
sis uitsluitend krantenartikels gebruikt worden,
zal
hiervoor telkens de publicatiedatum
gekozen worden.
Het representeren van een document als een lijst van features, maakt het mogelijk om een docu-
ment voor te stellen als een vector, waarbij de verschillende features de verschillende dimensies
zijn van de vector en waarbij
iedere feature een gewicht krijgt.
Als deze features bv.
de aan-
wezigheid van verschillende termen voorstellen, dan kan men als gewicht voor deze feature het
aantal
voorkomens van de term in het document nemen:
dit is de termfrequentie (TF) VSM-
tekstvoorstelling.
Op deze manier kan de volledige corpus worden voorgesteld als een (zeer sparse) term/document-
matrix.
Deze documentvoorstelling wordt een Vector Space Model
(VSM) of
ook wel
“bag of
2.1 Basisconcepten
5
words”-documentvoorstelling [Salton & Buckley, 1988] genoemd, omdat de volgorde van de ter-
men in het document genegeerd wordt.
Tijdens deze thesis zal er altijd gebruik gemaakt worden
van termen als features.
Meer informatie over de constructie van deze termen is terug te vinden
in hoofdstuk 3.
Wel kan al meegegeven worden dat we twee soorten termen zullen gebruiken, namelijk ofwel alle
woorden die voorkomen in het corpus,
ofwel
de verzameling van eigennamen die ge
¨
extraheerd
werden, gebruik makende van statistical relational learning[Getoor, 2007].
Beide soort termen zullen gebruikt worden,
maar om verwarring te mijden zal
er in de tekst
indien mogelijk enkel de algemene benaming term gebruikt worden.
2.1.2
Gewichtsfuncties / VSM-uitbreidingen
De hierboven beschreven VSM-tekstvoorstelling volstaat voor de meeste taken niet.
Daarom
wordt deze verbeterd door de bestaande featurespace te transformeren.
De meest gebruikte
tekstvoorstellingen worden hieronder opgelijst,
waarbij
er onderscheid gemaakt wordt tussen
niet-probabilistische (eerste twee) en wel probabilistische.
Bij deze laatste wordt er gewerkt met
topics, dit zijn lijsten van “gewogen” termen.
TF-IDF:
Term Frequency - Inverse Document Frequency:
Tekstvoorstelling waarbij de feature-
gewichten de genormaliseerde versie zijn van het aantal
voorkomens van de term in het
document.
Deze normalisatie gebeurt door de termfrequenties te delen door het aantal doc-
umenten waarin de term voorkomt in de volledige corpus (op een logaritmische schaal):
de
term krijgt een groter gewicht als deze minder voorkomt in de volledige corpus.
De trans-
formatie van de TF-tekstvoorstelling naar de TFIDF-tekstvoorstelling zullen we voortaan
beschrijven als IDF-herweging, waarbij IDF dus staat voor Inverse Document Frequency.
LSI:
Latent Semantic Indexing [Deerwester et al., 1990]:
Hierbij wordt de dimensionaliteit van
de bestaande term/document-matrix verkleind door eigenwaarde decompositie.
Op deze
manier wordt het totaal aantal dimensies dus kleiner (minder features), waardoor sommige
termen worden samengenomen.
Dit kan deels problemen met synoniemen oplossen.
Zo zal
een tekst die bv. over “wagens” gaat in de TF VSM-tekstvoorstelling sterk verschillend zijn
dan een tekst die over “auto’s” gaat.
Doordat het aantal
features nu verminderd wordt
en er dus termen samengenomen worden,
zullen de documenten een grotere similarity
verkrijgen na LSI-transformatie.
Een probleem met deze voorstelling is dat die niet meer
op term-niveau te interpreteren is door de mens.
PLSI:
Probabilistic Latent Semantic Indexing (aspect model) [Hofmann, 1999]:
Een probabilis-
tisch model, waarbij de documenten voorgesteld worden als een mengsel van verschillende
topics.
Hierbij is het aantal topics vast.
Deze topics kunnen wel goed voorgesteld worden
door mensen, een voordeel tegenover LSI.
LDA:
Latent Dirichlet Allocation [Blei et al., 2003]:
Probabilistisch model waarbij de gewichten
2.1 Basisconcepten
6
van de topics worden gezien als een random verborgen variabele, waarbij het makkelijker
wordt om met nieuwe documenten te werken (online werken) en waarbij het model
niet
groeit met de grootte van de training corpus.
Ook is er minder overfitting dan bij PLSI.
Met behulp van deze voorstelling van documenten als vectoren is het nu ook eenvoudiger om
documenten met elkaar te vergelijken.
Zo kan de inhoudelijke overeenkomst tussen twee doc-
umenten (gelijkheid) uitgedrukt worden als de cosine-similarity van twee document-vectoren:
cosine similarity(
~
A,
~
B) =
~
A ·
~
B
||
~
A|| · ||
~
B||
(2.1)
Of kan er gebruikgemaakt worden van het vectorieel verschil tussen twee document-vectoren om
de afstand tussen twee documenten uit te drukken.
2.1.3
Verdere behandeling corpus
Het geconstrueerde corpus kan nu verder uitgebreid worden door de volgende taken uit te vo-
eren.
Indexing
Indexing of
index-constructie is het genereren van een inverted-index.
Een inverted-index is
een bestand die per term (of feature) bijhoudt in welke documenten deze voorkomt.
Zoals op
figuur
2.1 te zien, bekom je dan een dictionary van termen, die gelinkt zijn aan een postingslist
(inverted list) die voorstelt waar iedere term voorkomt.
Op deze manier is het mogelijk om te
zoeken in het corpus naar een bepaalde term,
zonder alle documenten te moeten raadplegen.
Figuur 2.1:
Illustratie van de opmaak van een inverted-index m.b.v.
een dictionary en een postingslist,
(bron [Manning et al., 2008])
2.1 Basisconcepten
7
Classificatie
Classificatie [Bishop, 2007, Hoofdstuk 13-14] is een ML-techniek en meer specifiek een vorm van
supervised learning.
Dit wil zeggen dat er een model gecre
¨
eerd wordt op basis van gelabelde data.
Concreet wordt er gezocht naar een model
om documenten te beschrijven op een distinctieve
manier,
door ze onder te verdelen in verschillende klassen.
Zodat na het analyseren van een
training set, voor nieuwe documenten voorspeld kan worden tot welke klasse ze met de hoogste
waarschijnlijkheid behoren.
Hierbij wordt gebruikelijk vertrokken van het VSM-model
van de
documenten.
Clustering
Clustering [Bishop, 2007, Hoofdstuk 15-16] is gelijkaardig aan classificatie, maar deze techniek is
nu een vorm van unsupervised learning aangezien er geen trainingsdata is om van te vertrekken.
Bij
clustering moet het algoritme dus zelf
de klassen defini
¨
eren.
Hierbij
zoekt het algoritme
naar een verdeling in klassen zodat de document-gelijkheid in de klassen (intersimilarity) ge-
maximaliseerd wordt, en de documentgelijkheid voor documenten van twee verschillende klassen
(intrasimilarity) geminimaliseerd wordt.
Aangezien clustering van groot belang is in deze thesis,
volgt in sectie 2.2.2 een meer uitgebreide bespreking hiervan.
2.1.4
Evaluatiemetrieken
Binnen IR is het doel van veel technieken om een selectie van documenten te bekomen.
Om op
een objectieve manier conclusies te kunnen trekken is het noodzakelijk om de correctheid van
de selectie gevonden documenten te achterhalen.
Hiervoor worden er standaard een aantal
metrieken gebruikt die hieronder worden opgesomd.
Dit gebeurt aan de hand van een categorisatie van de documenten zoals samengevat in tabel 2.1.
Zoals te zien in deze tabel hebben we twee onderverdelingen (de 2 assen).
Enerzijds hebben we
de opsplitsing in de relevante en de niet-relevante documenten op basis van eigen annotaties (de
referentie of gouden standaard).
Daarnaast splitsen we het aantal
documenten ook op volgens
gevonden en niet-gevonden documenten, dit is dus de opsplitsing gevonden door het algoritme.
Op deze manier kunnen we de documenten nu opdelen in 4 verschillende klassen:
tp true positive, de relevante documenten die teruggevonden zijn
fn false negative, de relevante documenten die niet zijn teruggevonden
tn true negative, de niet-relevante documenten die ook niet zijn teruggevonden
fp false positive, de niet-relevante documenten die wel zijn teruggevonden
2.1 Basisconcepten
8
relevant
niet-relevant
gevonden
tp
fp
niet-gevonden
fn
tn
Tabel
2.1:
Tabel
met de soorten documenten binnen IR
Precision
Precision is de verhouding van het aantal relevante documenten ten opzichte van alle teruggevon-
den documenten.
Wat dus een maat is voor de zuiverheid van de gevonden set documenten.
P recision =
|{relevante documenten} ∩ {gevonden documenten}|
|{gevonden documenten}|
=
#tp
#tp + #fp
(2.2)
Recall
Recall
is de verhouding van het aantal teruggevonden relevante documenten ten opzichte van alle
relevante documenten.
Deze metriek geeft dus een maat van de compleetheid van de gevonden
set documenten.
Recall =
|{relevante documenten} ∩ {gevonden documenten}|
|{relevante documenten}|
=
#tp
#tp + #fn
(2.3)
F-score
F-score (F
1
) of verder ook F
1
-measure genoemd, is een evaluatiemetriek die een afweging maakt
tussen precision en recall.
Deze wordt als volgt gedefinieerd:
F
1
= 2 ·
P recision · Recall
P recision + Recall
(2.4)
2.2 State of the art
9
2.2
State of the art
Aangezien de thesis vooral
gaat over het benutten van de temporele informatie in het corpus,
volgt nu een korte beschrijving van huidige technieken/onderzoek die deze temporele informatie
probeert te gebruiken om meer of betere informatie uit teksten te halen.
2.2.1
Temporal Information Retrieval
Temporal
Information Retrieval
is een specifiek probleem binnen het algemene IR-onderzoek
waarbij
ook het
temporele aspect
van de documenten van belang is.
Hieronder
vallen de
verschillende uitbreidingen van taken binnen IR zoals
clustering[Chi et al., 2009],
similarity
search[Radinsky et al., 2011] en het genereren van tekstsamenvattingen [Allan et al., 2001].
Maar verder kan er ook meer expliciet gebruik gemaakt worden van de temporele patronen in
het corpus.
Een van de eerste en ook meest uitgebreide onderzoeken is het werk rond Topic De-
tection and Tracking (TDT) [Allan et al., 1998][Yang et al., 1999][Wayne, 2000].
Hierbij wordt
er gewerkt op een document-niveau en wordt er gezocht naar events en de daarbijhorende doc-
umenten, waarbij een topic bestaat uit een zogenaamd seed-event en de daaropvolgende events.
Een event
1
is een bepaalde gebeurtenis waarover geschreven werd (bv. de aanslagen in Noorwegen
in 2011 door Anders Breivik) en een story is een verzameling teksten die samenhoren en gerela-
teerd zijn aan een bepaald event, dus bv.
een verzameling van krantenartikels over deze aanslag.
TDT kan opgesplitst worden in vijf taken:
topic tracking, link detectie[Allan et al., 1998], topic
detectie[Ozmutlu, 2006],
first story detectie [Allan et al., 2000]
en story segmentatie.
Voor de
verschillende stappen worden veelal
diverse clusteringsmethodes gebruikt aangezien het de be-
doeling is om een lijst van events te genereren die elk bestaan uit een verzameling documenten.
Meestal is het einddoel van deze TDT-sytemen dan ook om een weergave te genereren van deze
events onder de vorm van een timeline [Swan & Allan, 2000].
Meer recent werd er onderzoek gedaan naar algemenere technieken om deze temporele patronen
te gebruiken, wat leidt tot veel verschillende technieken die onder de noemer van Temporal Text
Mining (TTM) [Fivelstad, 2007] vallen.
Zo werd er een uitbreiding van topic tracking naar incident threading [Feng & Allan, 2009]
voorgesteld waarbij er meer aandacht is voor de relaties tussen de verschillende events.
Verder werd ook onderzoek verricht naar meer uitgebreide analyses van de thema’s in het corpus
en hun evolutie in de tijd.
Zo kunnen de verschillende thema’s aanwezig in het corpus geanaly-
seerd worden en kan hun evolutie worden opgevolgd door gebruik te maken van probabilistische
modellen [Mei & Zhai, 2005][Jo et al., 2011][Mei & Zhai, 2006].
1
In het vervolg van deze thesis zal de term gebeurtenis gebruikt worden om een effectieve gebeurtenis aan te
duiden en de term event om een corresponderende set van documenten aan te duiden.
2.2 State of the art
10
Anderzijds werd ook voorgesteld om gebruik te maken van een combinatie van verschillende
corpora om robuuster events te detecteren[Zhai et al., 2004][Wang et al., 2007].
In een ander onderzoek [De Smet & Moens, 2009] werden verschillende voorstellingen van dezelfde
corpus gecombineerd om een betere voorstelling te bekomen.
Deze voorstellingen worden as-
pecten van het corpus genoemd en kunnen bv. de lijst van aanwezige eigennamen, of de gevonden
topics (bekomen met behulp van LDA) zijn.
Door deze verschilllende aspecten nu afzonderlijk te
beschouwen en als verschillende onderdelen te gebruiken tijdens het vergelijken van documenten,
worden er betere resultaten bekomen.
Ook kan de gelijkheidsmaat,
die de inhoudelijke gelijkheid van documenten weergeeft en ge-
bruikt wordt bij TDT om gelijkaardige documenten met elkaar samen te voegen tot een event,
vervangen worden door invloeden [Shaparenko & Joachims, 2007], zodat de bidirectionele relatie
tussen documenten een unidirectionele wordt, wat bv.
interessant is om automatisch referenties
toe te voegen bij papers.
Concreet is het zo mogelijk om een verband tussen twee documenten
te leggen zonder dat deze echt inhoudelijk gelijk zijn.
Neem bv. twee wetenschappelijke papers
waarbij de eerste een bepaalde techniek omschrijft en de tweede een summary van technieken is
waarvan ´e´en hoofdstuk gaat over de techniek uit de eerste paper.
Aangezien er nog veel andere
technieken in deze laatste paper kunnen voorkomen,
zijn de twee papers inhoudelijk niet echt
gelijk.
Er is echter wel een invloed van de eerste paper op de tweede.
Dit is het soort invloeden
die gezocht worden door [Shaparenko & Joachims, 2007].
Tenslotte wordt er recent ook veel
aandacht besteed aan de burstiness van topics.
Dit is de
mate waarin het voorkomen van gerelateerde documenten plots varieert in de tijd.
Zo kunnen
de belangrijkste momenten (hot spots) van een bepaald topic gevonden worden door deze te
identificeren als de periode waarin de aanwezigheid van dit topic veel
groter is dan normaal
[Chen & Chundi, 2011].
Deze vaststelling wordt ook gebruikt om bv. de veelgebruikte TFIDF-
gewichten te vervangen door gewichten waarbij deze burstiness gebruikt wordt [Efron, 2010][He et al., 2007].
In sectie 2.2.3 wordt hier dieper op ingegaan.
2.2.2
Clustering
Zoals eerder vermeld,
is clusteren het automatisch onderverdelen van data,
in dit geval
docu-
menten,
in verschillende klassen waarbij documenten in dezelfde klasse zo gelijk mogelijk zijn
en documenten van twee verschillende klassen zo verschillend mogelijk.
Om dit doel te bereiken
zijn er veel
verschillende technieken in gebruik.
Wel
wordt er altijd gewerkt met data (docu-
menten) waarvan het mogelijk is om tussen de gelijkheid en/of afstand tussen twee documenten
kwantitatief voor te stellen.
Hiervoor is de voorstelling van documenten als vectoren dus zeer
goed geschikt.
We kunnen als afstands-
en gelijkheidsmaat tussen de documenten dan im-
mers respectievelijk de euclidische afstand en de cosine-similarity tussen de vectoren gebruiken.
Verder kunnen deze vectoren dan worden voorgesteld als punten in een n-dimensionale ruimte,
2.2 State of the art
11
waarbij
n het aantal
verschillende features is die voorkomen in het corpus.
Op deze manier
is het veel
eenvoudiger om een visuele voorstelling te maken van het clusteren,
al
is deze vi-
suele voorstelling natuurlijk enkel mogelijk bij laag-dimensionale vectoren.
Een overzicht van de
verschillende soorten clusteringsmodellen die gebruikt kunnen worden:
Centroid-modellen [Manning et al., 2008,
sectie 16.4]:
clustering waarbij
een cluster wordt
voorgesteld door ´e´en vector
Connectiviteitsmodellen [Manning et al., 2008,
hoofdstuk 17]:
clustering waarbij
clusters
gevormd worden op basis van de afstanden tussen de verschillende documenten.
Deze
modellen worden ook hi
¨
erarchische modellen genoemd.
Distributiemodellen [Blei et al., 2010]:
hierbij worden clusters gezien als distributies,
waar-
bij
voor ieder document dan kan berekend worden in welke mate deze behoren tot de
verschillende clusters (distributies).
Densiteitsmodellen [Ester et al., 1996]:
gebruik makende van de voorstelling van documenten
als punten in een n-dimensionale ruimte,
worden clusters gedefinieerd als dense ruimtes.
Dit zijn delen van de n-dimensionale ruimte waarin veel datapunten dicht bij elkaar liggen.
Graaf-gebaseerd modellen [Chi et al., 2009]:
clusters waarbij
eigenschappen uit de graaf-
theorie gebruikt worden, zoals het gebruik van cliques om een cluster te defini
¨
eren.
Subspace modellen [Agrawal et al., 2005]:
clustering waarbij er enkel bepaalde dimensies ge-
bruikt worden om clusters te defini
¨
eren, dit is dus vooral van belang bij hoog-dimensionale
datasets.
Verder kunnen clusteralgoritmen nog worden opgesplitst door de volgende eigenschappen
[Manning et al., 2008, hoofdstuk 16] te beschouwen:
• Hi
¨
erarchie:
clustermodellen zijn ofwel hi
¨
erarchisch ofwel vlak.
• Document-cluster relatie:
bij harde clustering behoort ieder document tot maximum ´e´en
cluster,
terwijl
een document bij zachte clustering tot meerdere clusters kan behoren en
dit in verschillende maten.
Zoals uit de lijst blijkt, zijn er veel verschillende soorten clusteringstechnieken.
Deze hebben elk
nog veel verschillende algoritmen.
Deze uitgebreide set van algoritmen toont dus het belang van
clustering aan.
Al wordt het hierdoor natuurlijk ook minder eenvoudig om snel en met zekerheid
het meest geschikte clusteringsalgoritme voor een specifieke taak te vinden.
De zoektocht naar het beste clusteringsalgoritme voor onze taak zal uitvoeriger aan bod komen
in sectie 4.2,
waar beknopt zal
worden besproken wat de voor- en nadelen zijn van bepaalde
clusteringsalgoritmen en waarom het gebruikte algoritme gekozen werd.
2.2 State of the art
12
Wegens het uitgebreide aanbod aan clusteralgoritmen zal nu enkel het meest relevante algoritme
in het licht van deze thesis,
en die ook beschreven is in de literatuur,
besproken worden.
Het
in deze thesis voorgestelde algoritme is een densiteitsmodel en meer specifiek een temporele uit-
breiding van het DBSCAN-algoritme [Ester et al., 1996]
2
, daarom zal nu dit DBSCAN-algoritme
besproken worden.
DBSCAN
DBSCAN (Density Based Spatial
Clustering of Applications with Noise) [Ester et al., 1996]
is
een algoritme dat ingevoerd werd speciaal om clusters te detecteren waarvan de verzameling doc-
umenten in de n-dimensionale dataruimte om het even welke vorm
3
kunnen hebben en waarmee
het mogelijk is om deze op een effici
¨
ente manier te vinden in een grote dataset.
De meestge-
bruikte algoritmen werken namelijk veelal enkel met sferische clusters.
Dit omdat er een centrum
van de cluster gekend moet zijn om de cluster te defini
¨
eren.
Hierbij kan “sferisch” het best wor-
den begrepen als we werken met laag-dimensionale documenten.
Als er bv. gewerkt wordt met
2-dimensionale documenten zoals in de paper die DBSCAN voorstelt,
dan kan “sferisch” sim-
pelweg worden ge
¨
ınterpreteerd als een cluster waarvan de puntenwolk (de verzameling punten
of documenten die bij de cluster horen) in een cirkelvorm liggen.
Hierbij is de afstand voor ieder
punt tot het centrum van deze cirkel
van belang.
Bij hoog-dimensionale documenten,
zoals de
documenten uit onze nieuwscorpus,
is deze visuele voorstelling niet meer mogelijk,
al
kan de
sferische puntenwolk dan ge
¨
ınterpreteerd worden als een hypersfeer.
Nu volgt een bespreking van de werking van het DBSCAN-algoritme na enkele definities die
noodzakelijk zijn om het algoritme te begrijpen.
Eps-omgeving van een punt:
is de verzameling punten die op een afstand kleiner dan Eps
van het gegeven punt liggen,
hierbij
is Eps dus de eerste parameter van het algoritme.
Verder kan voor de afstandsmaat de euclidische afstand tussen deze punten gebruikt wor-
den.
Direct dense bereikbaarheid:
een punt p is direct dens bereikbaar vanaf punt q als het punt
p in de Eps-omgeving van het punt q ligt en als het aantal
punten in de Eps-omgeving
van het punt q groter dan MinPts is.
Met MinPts de tweede parameter van het algoritme.
Deze direct dense bereikbaarheid relatie is dus niet symmetrisch aangezien ze ook afhangt
van het aantal
punten in de Eps-omgeving van ieder individueel
punt.
Punten waarvan
de Eps-omgeving meer dan MinPts punten bevatten, worden core-punten genoemd, zoniet
wordt het een grenspunt genoemd.
Dense bereikbaarheid:
een punt p is dens bereikbaarbaar van punt q als er een ketting van
2
Merk op dat het bestaan van dit DBSCAN-algoritme pas ter kennis kwam na het implementeren van ons
eigen algoritme.
Maar aangezien de werking van beide algoritmen duidelijk op elkaar lijken, leek het dus gepast
om deze op te nemen in de literatuurstudie.
3
Met vorm bedoelen we de vorm van de puntenwolk in de n-dimensionale dataruimte, waarbij ieder punt een
document voorstelt.
2.2 State of the art
13
punten tussen q en p bestaat, zodat ieder koppel punten, gezien vanaf punt q tot punt p,
direct dens bereikbaar zijn.
Deze relatie is dus net als de voorgaande niet symmetrisch.
Dense verbondenheid:
een punt p is dens verbonden met een punt q,
als er een punt o
bestaat, zodat zowel punt p als punt q dens bereikbaar zijn vanaf punt o.
Deze relatie is
dus wel symmetrisch.
Cluster:
een verzameling punten uit de dataset waarvoor voor ieder punt p en q aan de volgende
regels is voldaan:
1.
als een punt p tot de cluster behoort en als een punt q dens bereikbaar is vanaf punt
p, dan behoort punt q ook tot deze cluster.
2.
als punten p en q tot de cluster behoren, dan is punt p dens verbonden met punt q.
Ruis:
dit is de verzameling punten van de dataset die tot geen enkele cluster behoren.
Het algoritme gaat nu om de clusters te bepalen over alle punten uit de dataset itereren en telkens
alle punten zoeken die dens bereikbaar zijn met dit punt als dit punt nog niet tot een cluster
behoort.
Als het punt die onderzocht wordt een core-punt is,
dan wordt er een nieuwe cluster
gevormd met alle punten die dens bereikbaar zijn met dit eerste punt als deze punten nog niet
tot een andere cluster behoren.
Als het punt een grens-punt is, dan gebeurt er niets.
Aangezien
het zoeken van de Eps-omgeving per punt een gemiddelde tijdscomplexiteit van O(log n) heeft
als er gebruikgemaakt wordt van een R-tree [Beckmann et al., 1990], en dit gedaan moet worden
voor alle punten uit de dataset is de totale tijdscomplexiteit dus:
O(n log n).
2.2.3
Burstiness en event-detectie
Tijdens deze thesis ligt de nadruk op het ontdekken van events en dit door gebruik te maken
van bursty-features.
Een meer diepgaande bespreking van de literatuur hierover volgt in deze
sectie.
Burst-detectie
Een burst van activiteit over een bepaald onderwerp of
topic wordt gedefinieerd als de peri-
ode waarin deze veel
meer voorkomt dan normaal
in het corpus.
Om dit te detecteren,
wordt
gewerkt op term-niveau en worden de documentfrequenties (het aantal
documenten waarin de
term voorkomt) per term per dag uitgerekend
4
.
Op deze manier bekomen we dus per term een
lijst die per dag bijhoudt in hoeveel documenten de term voorkomt.
Een eerste simpele manier om bursts te detecteren kan gebruik maken van een treshold om deze
bursts te defini
¨
eren, door bursts te identificeren als de periode wanneer de termfrequentie deze
4
In het vervolg zal er met documentfrequentie telkens de documentfrequentie per dag bedoeld worden.
Enkel
in het geval
van IDF-herweging slaat de documentfrequentie (DF) op het aantal
documenten over de volledige
corpus.
2.2 State of the art
14
treshold overschrijdt,
zo een treshold-gebaseerde burst-detectie werd onder andere voorgesteld
door [Swan & Allan, 1999].
Het probleem hierbij
is dat de meeste perioden met hogere ac-
tiviteit op deze manier gesplitst worden in meerdere kortere bursts (zie figuur 2.2) wat meestal
niet gewenst is.
Dit komt door de sparsheid van de documentfrequenties,
waardoor de docu-
mentfrequentie over een korte tijd sterk varieert.
Uitmiddeling (zoals later in sectie 3.1.2 wordt
aangetoond) kan deze variatie beperken, maar het probleem blijft.
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
datum
0
10
20
30
40
50
60
documentfrequentie
opsplitsing burst
korte burst
DF ’Fukushima’
treshold 2
treshold 1
Figuur 2.2:
Illustratie van het probleem bij burst-detectie m.b.v.
een treshold.
Hier wordt de documentfre-
quentie (DF) van de term “fukushima” weergegeven en twee mogelijk tresholdwaarden.
Zoals aangeduid
bekomen we op deze manier enerzijds ongewenste opsplitsingen van bursts en anderzijds heel korte bursts.
De meest gebruikte methode voor burst-detectie,
voorgesteld in [Kleinberg, 2003],
die ook ge-
bruikt
zal
worden tijdens
deze thesis,
maakt
gebruik van een oneindige/eindige toestands-
automaat (A) om dit probleem op te lossen.
Verder is deze burst-detectie ook gedefinieerd per term.
Waardoor bursts dus enkel
slaan op
periodes waar een specifieke term meer voorkomt.
De input voor het algoritme is de artikelverdeling x
i
per dag i,
zijnde de combinatie van de
documentfrequentie r
i
van de term en het totaal
aantal
artikels d
i
per dag.
Deze laatste twee
kunnen voorgesteld als twee afzonderlijke vectoren:
r = (r
1
, r
2
, r
3
, ..., r
n
) en d = (d
1
, d
2
, d
3
, ..., d
n
)
(2.5)
Voor de leesbaarheid zal de combinatie van deze twee vectoren voorgesteld worden als ´e´en vector,
de artikelverdeling x,
die per dag dus zowel
de documentfrequentie van de term als het totaal
2.2 State of the art
15
aantal artikels bevat:
x = (x
1
, x
2
, x
3
, ..., x
n
), met x
i
= (r
i
, d
i
)
(2.6)
De automaat die beschreven zal
worden,
kan nu gezien worden als een generatief
model
die
zo’n vector x kan genereren.
Voor de eenvoud wordt nu enkel
de tweetoestandsautomaat(A
2
)
beschreven, hierbij zijn de twee toestanden:
bursty (q
1
) en niet-bursty (q
0
).
Maar de oneindige
toestandsautomaat(A
∞
) werkt analoog waarbij er dan verschillende maten van burstiness zijn.
Als de automaat zich in de toestand q
0
bevindt dan wordt er verondersteld dat de fractie p
∗
van
artikels die de term bevatten gemiddeld is,
deze verwachte gemiddelde fractie (over de gehele
corpus) voor toestand q
0
is dus:
p
0
=
P
n
t=1
r
t
P
n
t=1
d
t
(2.7)
Als de toestandsautomaat zich in toestand q
1
bevindt,
dan wordt verondersteld dat de fractie
p
∗
in deze toestand meer dan gemiddeld is, corresponderende met een grotere p
1
:
p
1
= s · p
0
, met emissie-parameter s > 1
(2.8)
Een gegeven toestand q
i
kan nu een x
i
(combinatie van r
i
en d
i
) genereren als een sample uit
de binomiale distributie met als probabiliteit p
i
en sample-grootte d
i
.
Op deze manier kan een
gegeven x dus gegenereerd worden als de output van de toestandsautomaat, gegegeven een reeks
toestanden q = (q
i
1
, q
i
2
, q
i
3
, ..., q
i
n
).
Het doel van het algoritme is echter om een reeks toestanden te verkrijgen, gegeven een reeks van
artikelverdelingen x.
Om dit te bereiken,
moet er dus een maat bepaald worden die aangeeft
met welke kost of
welke waarschijnlijkheid een gegeven toestandreeks q een gegeven artikel-
verdelingsreeks x kan genereren.
Dit gebeurt door het invoeren van kostfuncties.
Zo wordt er een emissiekost σ(i, x
t
) ingevoerd die de kost is om gegeven een bepaalde toestand
q
i
een gegeven artikelverdeling x
i
te genereren.
Deze wordt als volgt gedefinieerd:
σ(i, x
t
) = − ln
h

d
t
r
t

p
r
t
i
(1 − p
i
)
d
t
−r
t
i
(2.9)
Deze kost komt overeen met het negatief natuurlijk logaritme van de kans om x
t
te genereren,
gegeven toestand q
i
met bijhorende p
i
,
als x
t
gezien wordt als een sample van de binomiale
distributie.
Ook wordt er een kost ingevoerd horende bij de toestandstransities τ (i
t
, i
t+1
), waarbij i
t
en i
t+1
respectievelijk de toestanden zijn op dag t en dag t + 1.
Als we veronderstellen dat de toestand verandert met probabiliteit p, met 0 < p < 1,
en gelijk
blijft met probabiliteit 1 − p dan verkrijgen we, als we hier ook het negatief natuurlijk logaritme
2.2 State of the art
16
gebruiken om over te gaan van de kans naar de bijhorende kost, de volgende kostfunctie:
τ (i
t
, i
t+1
) =
(
− ln(p)
als i
t
= i
t+1
− ln(1 − p)
als i
t
6= i
t+1
(2.10)
Het zoeken van de optimale toestandsequentie q, gegeven x, komt nu neer op het minimaliseren
van de volgende kostfunctie:
c(q|x) =
n
X
t=1
τ (i
t−1
, i
t
) +
n
X
t=1
σ(i
t
, x
t
)
(2.11)
Om deze kostfunctie te minimaliseren, interpreteren we het gegeven model als een Hidden Markov
Model
(HMM)[Bishop, 2007,
hoofdstuk 13].
Dit wordt ge
¨
ıllustreerd in 2.3,
de optimale toes-
tandsequentie kan gevonden worden door gebruik te maken van het Viterbi-algoritme die wordt
beschreven in sectie 5.1.
Figuur 2.3:
Illustratie van het
HMM horende bij
de tweetoestandsautomaat
van het
burst-detectie al-
goritme.
Hierbij
start
de automaat
dus in toestand q
0
,
stellen de gevulde cirkels de geobserveerde ar-
tikelverdelingen x
t
voor en de lege cirkels de niet-geobserveerde toestanden q
i
t
.
De horizontale pijltjes
representeren de overgangen tussen de verschillende dagen en de daarbijhorende transitiekost τ (i
t
, i
t+1
),
de verticale pijltjes stellen het verband voor van de gegeven toestand op die dag, naar de artikelverdeling
die dag, met de erbijhorende kost σ(i
t
, x
t
)
Voor de tweetoestandsautomaat werd er ook een maat gedefinieerd die de grootte of het gewicht
van de burst uitdrukt.
Deze is gedefinieerd als de som over de volledige periode van de burst
van de vermindering in emissiekost doordat de automaat in toestand q
1
zit.
Dit kan als volgt
geschreven worden:
w
j
=
t
2
X
t=t
1
(σ(0, x
t
) − σ(1, x
t
))
(2.12)
Bursty-weighting
Een gebrek van de veelgebruikte TFIDF-tekstvoorstelling is dat deze niet geoptimaliseerd is
voor temporele teksten.
In het model
is er dus ook geen temporele informatie benut.
Zoals in
bovenstaande sectie 2.2.1 vermeld, zijn er temporele uitbreidingen voor bedacht.
2.2 State of the art
17
Het model
voorgesteld in [He et al., 2007]
maakt hiervoor gebruik van de bursts gevonden via
de bovenstaande burst-detectie algoritme van Kleinberg met twee toestanden.
Concreet
bestaat
de nieuwe documentvoorstelling uit
de binaire TF-tekstvoorstelling,
maar
waarbij
termen die in een bursty periode zitten een extra gewicht krijgen.
Deze verzameling
termen die minstens ´e´en bursty periode hebben, worden bursty-features genoemd.
Eerst worden deze bursty periodes ge
¨
ıdentificeerd m.b.v. het algoritme van Kleinberg.
Daarna
wordt iedere term van ieder document doorlopen en voor iedere term die op de timestamp van
het document in een burst zit,
wordt er bij het simpele statische binaire TF-gewicht een extra
gewicht toegevoegd evenredig met het gewicht van de burst w
j
.
Op deze manier is de docu-
mentvoorstelling afhankelijk van de timestamp.
Verder is er nog een parameter die bepaalt hoe
groot de extra bijdrage van de bursty-term moet zijn.
Op die manier kan een document op een
bepaald tijdstip d
i
(t), als volgt worden beschreven:
d
i
(t) = [d
i1
(t), d
i2
(t), ..., d
iM
(t)]
T
(2.13)
met als termgewichten:
d
ij
(t) =
(
T F
ij
+ δw
j
als bursty
T F
ij
als niet-bursty
(2.14)
Waarbij
T F
ij
het statische termgewicht is (hier de binaire termfrequentie,
0 als de term niet
voorkomt en 1 in de andere gevallen),
w
j
het gewicht van de burst en δ de wegingsfactor die
bepaalt hoe groot de bijdrage van de burstiness is.
Merk dus op dat de documentvoorstelling
dus alle termen bevat, en niet enkel de bursty-features.
Feature-pivot clustering
Events detecteren gebeurt meestal door het clusteren van documenten (document-pivot cluster-
ing), waarbij de gevormde clusters de events voorstellen.
In [Fung et al., 2005] wordt er echter
een alternatieve methode voorgesteld, waarbij events gevonden worden als een verzameling van
bursty-features (feature-pivot clustering ), met een bursty-feature zoals gedefinieerd hierboven.
Hierbij is het de bedoeling om telkens een minimale optimale set van bursty-features te vinden
die een event zo goed mogelijk beschrijven.
Er zijn twee voordelen aan deze aanpak.
Ten eerste is
het zo mogelijk om betere events te defini
¨
eren, want het probleem bij document-clustering is dat
deze enkel
gelijkaardige documenten samennemen,
maar meestal
zijn de documenten horende
bij een bepaald event vrij verschillend van elkaar en hebben ze slechts enkele gemeenschappelijke
termen.
Door dus enkel deze termen te beschouwen, worden de andere “ruis”-termen genegeerd.
Ten tweede is dit een parametervrije aanpak, terwijl er bij de meeste document-clusteringsmethoden
verschillende parameters noodzakelijk zijn.
Concreet bestaat het algoritme uit twee stappen:
Eerst worden de bursty-features gezocht zoals voorgesteld door [He et al., 2007].
In de tweede
2.2 State of the art
18
stap worden deze bursty-features dan gegroepeerd tot bursty events.
Het groeperen van deze bursty-features gebeurt door te vertrekken van de set van alle bursty-
features,
hiervan worden alle mogelijke combinaties van bursty-features getest.
De meest opti-
male combinatie van features (gegeven een optimaliteitscriterium) wordt dan uit de set gehaald.
Hierna worden dezelfde stappen herhaald op de resterende set en dit wordt herhaald tot de
resterende set nog maar ´e´en of geen bursty-feature bevat.
BurstVSM
De bestaande technieken die gebruik maken van de bursts, gebruiken nog steeds termen als fea-
tures, waarbij een bursty-feature gedefinieerd wordt als een term die minstens ´e´en burst vertoont.
Een tekortkoming hiervan is dat er geen temporele informatie in de feature vervat zit.
Zo kun-
nen de termen “verkiezingen”, “Obama” en “president” op verschillende events slaan afhankelijk
van het tijdstip.
Deze kunnen immers zowel
horen bij het event “de presidentsverkiezingen in
Amerika in 2008” als “de presidentsverkiezingen in Amerika in 2012”.
Een clustering die enkel
rekening houdt met deze termen zal
geen onderscheid kunnen maken tussen deze twee events.
In de paper [Zhao et al., 2012] wordt dit probleem opgelost door een nieuw soort bursty-feature
te gebruiken.
Nu is een bursty-feature niet meer een term die minstens ´e´en burst bevat,
maar
is een bursty-feature gedefinieerd per burst als een term en de bijhorende tijdspanne van deze
burst,
wat dus neerkomt op een tijdsgebonden term.
Op deze manier kan de term “verkiezin-
gen” dus meerdere bursty-features bevatten die overeenkomen met de verschillende bursts van
de term “verkiezingen”.
Een bursty-feature is dan enkel
aanwezig in een document als zowel
de timestamp van het document binnen de burst-periode van de bursty-feature valt,
als dat
de term corresponderend met de bursty-feature aanwezig is in het document.
Het feature-
gewicht van een bursty-feature voor een document wordt dan berekend als het TFIDF-gewicht
van deze bursty-feature voor dit document.
Hierbij
gebruiken we voor de berekening van het
TFIDF-gewicht TF als het aantal voorkomens van deze bursty-feature in het document en DF
als het aantal
documenten waarin de bursty-feature voorkomt.
Vanwege een aantal
onduideli-
jkheden in [Zhao et al., 2012] (waaronder het ontbreken van expliciete parameterwaarden), was
het niet mogelijk om de gebruikte methode experimenteel
te verifi
¨
eren.
In A.2 worden an-
dere frequenties voorgesteld waarmee de bursty-feature gewichten mogelijks worden berekend in
[Zhao et al., 2012].
Verder werd het burst-detectie algoritme voorgesteld in [Kleinberg, 2003] aangepast zodat p
0
nu
niet constant is over de volledige corpus,
maar gedefinieerd wordt per dag door een venster te
beschouwen rond deze dag en enkel de dagen in dit venster te gebruiken bij de berekening van
2.3 Conclusie
19
p
0
, concreet wordt dit met met venstergrootte L dagen:
p
0
(t) =
P
t+L/2
i=t−L/2
r
i
P
t+L/2
i=t−L/2
d
i
(2.15)
Hierbij zijn r
i
en d
i
opnieuw respectievelijk de documentfrequentie van de term en het totaal
aantal artikels op dag i en gebruikt men L = 180.
Deze nieuwe tekstvoorstelling wordt BurstVSM genoemd.
De twee grote voordelen van deze
nieuwe BurstVSM-tekstvoorstelling zijn dus dat ten eerste de temporele informatie vervat zit
in de features zelf en ten tweede dat door enkel met deze nieuwe bursty-features te werken, de
documentvoorstelling veel
compacter wordt,
aangezien er niet zoveel
bursty-features aanwezig
zijn per document.
Op deze manier kan er dus sneller/effici
¨
entier geclusterd worden.
2.3
Conclusie
Uit de literatuurstudie blijkt dus dat er al
verschillende pogingen ondernomen zijn naar au-
tomatische event-detectie.
Typisch wordt het probleem opgesplitst in twee onderdelen.
Eerst
wordt de tekstvoorstelling van de corpus aangepast om een zo goed mogelijke voorstelling van
de documenten te bekomen.
De tweede stap is het clusteren van de documenten,
waarbij
de
clusters dan verschillende events voorstellen.
Meer recent is de nadruk bij het onderzoek naar tekstvoorstellingen verschoven naar de “bursti-
ness” van de termen en de bijhorende bursts.
Tijdens het vergelijken van de verschillende
papers viel er op dat er niet consistent gebruik wordt gemaakt van dezelfde evaluatiemethodes
en datasets.
Dit maakt het moeilijker om de performantie van de verschillende algoritmen met
elkaar te vergelijken.
Ten eerste omdat sommige kwalitatieve resultaten onmogelijk te verge-
lijken zijn en anderzijds omdat de kwantitatieve resultaten sterk afhankelijk zijn van de dataset
en de gebruikte testmethodes.
Aangezien de paper [Zhao et al., 2012]
de meest recente publicatie is rond event-detectie,
deze
een vernieuwende aanpak hanteert en de verbeteringen ook kwantitatief aantoont, zal er verder
gewerkt worden met hun beschreven algoritme.
In sectie 2.1.1 zal deze verder onderzocht worden
en zullen er enkele mogelijke verbeteringen voorgesteld worden.
Deze zullen in hoofdstuk 5 en
7 dan respectievelijk worden ge
¨
ımplementeerd en geverifieerd.
HET CORPUS
20
Hoofdstuk 3
Het corpus
Nu volgt een korte analyse en bespreking van het corpus en van het framework om deze te
behandelen.
3.1
Analyse van het corpus
Tijdens deze thesis werd er gebruik gemaakt van alle Nederlandstalige artikels die verzameld wer-
den door Mediargus
1
en dit tijdens het jaar 2011.
Hiervan ontbreken er wel 59 dagen (waaronder
alle zondagen), in totaal komt dit dan neer op een verzameling van 748521 artikels gespreid over
306 dagen.
Om de rekentijd van de verschillende algoritmen te beperken,
werd deze verzamel-
ing artikels gefilterd.
Zo werden alle artikels die als sport werden geklasseerd,
alle artikels die
een lege titel
hadden en alle artikels die bestonden uit minder dan 100 tekens verwijderd.
De
resterenhet corpus bevat nu 427003 artikels.
3.1.1
Preprocessing
Om met deze artikels te werken, moet er van de ongestructureerde tekstvoorstelling overgegaan
worden naar een gestructureerde vector-voorstelling.
De stappen noodzakelijk om deze overgang
te verwezenlijken worden hieronder beschreven en kunnen worden samengevat als preprocessing.
De eerste stap is het voorstellen van een document als een lijst van tokens, dit wordt ook token-
ization genoemd.
Waarbij ieder token een opeenvolging van tekens is die van elkaar gescheiden
worden door witruimtes of leestekens.
Deze tokens interpreteren we nu rechtstreeks als woorden.
We controleren dus niet of de tokens
een semantische betekenis hebben, op die manier kunnen we dus woorden bekomen die uit een
1
http://mediargus.be/
3.1 Analyse van het corpus
21
willekeurige combinatie van tekens bestaan,
wat echter niet zoveel
voorkomt.
Veel
van deze
woorden hebben echter wel
weinig betekenis in het licht van IR.
Algemene woorden zoals de
lidwoorden en veel
werkwoorden zijn niet onderscheidend genoeg om een tekst te kenmerken.
Bijvoorbeeld omdat ze bijna in alle documenten voorkomen.
Deze verzameling van stopwoorden
worden dan ook uit het corpus gefilterd.
Hiervoor werd gebruik gemaakt van de document fre-
quenties over de volledige corpus.
Dus het aantal documenten waarin de term voorkomt over de
volledige corpus.
Na uitvoerig deze woorden te analyseren, bleek dat woorden die in meer dan
15 % van de artikels voorkomen, geklasseerd kunnen worden als stopwoorden.
Het feit dat deze
woorden in veel
documenten voorkomen,
zorgt natuurlijk voor een grote verkleining van het
corpus als deze verwijderd worden.
Verder werden ook alle woorden verwijderd die in minder
dan 20 documenten voorkomen.
Een volgende stap die uitgevoerd wordt om een betere voorstelling te bekomen is normalisatie.
Dit is het samennemen van woorden die dezelfde betekenis hebben,
zoals bv.
“fukushima” en
“Fukushima”.
De enige vorm van normalisatie die gebruikt wordt,
is het omzetten van alle
hoofdletters naar kleine letters.
Meer uitgebreide normalisatiestappen kunnen bv. ook verschil-
lende (foutieve) schrijfwijzen van hetzelfde woord of
zelfs synoniemen samennemen,
maar dit
werd niet gebruikt.
Een derde mogelijke preprocessing stap ,die niet werd uitgevoerd, is stemming en/of lemmatisa-
tion.
Beide proberen om ieder woord terug te brengen tot zijn absolute basis/stam.
Zo worden
bv.
alle werkwoordsvervoegingen van werkwoorden tot de werkwoordsstam herleid,
of worden
meervouden vervangen door hun enkelvoudige basis.
Hierbij
maakt stemming gebruikt van simpele heuristieken,
terwijl
er bij
lemmatisation ver-
schillende woordlijsten en morfologische analyses gebeuren.
Deze stap werd niet uitgevoerd
aangezien ze een negatieve impact kan hebben op de verdere taken als deze te aggressief wordt
toegepast [Manning et al., 2008, sectie 15.3.2], verder zijn de implementaties voor Nederlandse
teksten ook minder uitgebreid dan de Engelstalige versies,
wat de kwaliteit hiervan dus ook
negatief kan be
¨
ınvloeden.
We werken nu rechtstreeks met deze overgebleven woorden en noemen ze in het vervolg ook
meestal termen.
Hierbij zijn deze termen dus enkelvoudige woorden en worden er geen woorden
samengenomen om ´e´en term te vormen zoals beschreven staat in sectie 2.1.1.
Wel werd er naast het corpus met als termen de verschillende woorden, ook een andere voorstelling
van het corpus gemaakt, die gebruikmaakt van de verschillende eigennamen die teruggevonden
werden in de artikels en die eigennamen gebruikt als termen.
Deze werden verkregen met de
Named Entity Recognition software ontwikkeld aan deze onderzoeksgroep [Deleu et al., 2012].
3.1 Analyse van het corpus
22
3.1.2
Statistieken van het corpus
Om een idee te kunnen vormen van de omvang en de verdeling van de verschillende termen,
woorden en eigennamen,
in het corpus volgt een korte analyse.
Zo bevat de gefilterde corpus
in totaal
98390 verschillende woorden en 26552 verschillende eigennamen.
Hierbij
werden de
eigennamen ook bekomen na een gelijkaardige preprocessing als bij de woorden, met als verschil
dat de eigennamen nu worden overgehouden als ze in minder dan 50% van de documenten
voorkomen in plaats van 15%.
Corpusfrequenties
De corpusfrequentie (CF) van een term is het totaal
aantal
voorkomens van die term in de
volledige corpus.
In figuur 3.1 worden deze corpusfrequenties voor de verschillende termen,
woorden (bovenste grafiek) en eigennamen (onderste grafiek) uiteengezet.
Dit is dus een weer-
gave van de termendistributie, waarbij de termen aflopend geordend worden volgens deze corpus-
frequentie.
De term met id 1 is dus de term met de grootste corpusfrequentie.
Tevens werd een lijn meegegeven die overeenkomt met Zipf’s law [Manning et al., 2008, sectie 5.1.2].
10
0
10
1
10
2
10
3
10
4
10
5
id
10
0
10
1
10
2
10
3
10
4
10
5
10
6
corpusfrequentie
woorden
Zipf’s law
10
0
10
1
10
2
10
3
10
4
10
5
id
10
0
10
1
10
2
10
3
10
4
10
5
10
6
corpusfrequentie
eigennamen
Zipf’s law
Figuur 3.1:
Weergave van de woorden(boven)/eigennamen(onder)-distributie op een dubbel-logaritmische
schaal.
De termen worden gekenmerkt door hun id op de x-as, deze id wordt toegekend op basis van hun
positie in het corpusfrequentietabel.
Deze stelt dat de corpusfrequentie (CF
i
) van een bepaalde term omgekeerd evenredig is met zijn
plaats in de corpusfrequentietabel, waarbij de termen in de corpusfrequentietabel geordend zijn
volgens aflopende corpusfrequentie.
Dus voor term met positie i in de corpusfrequentietabel
geldt:
CF
i
∝
1
i
(3.1)
3.1 Analyse van het corpus
23
Deze eenvoudige benadering maakt het mogelijk om intu
¨
ıtief
de snelle daling van de corpus-
frequentie te karakteriseren.
Wel vormt ze nog maar een ruwe benadering voor de exacte corpus-
frequenties.
Zo is duidelijk dat dit model voor veelvoorkomende termen niet overeenstemt met
de effectieve corpusfrequenties, dit zowel voor de woorden als voor de eigennamen.
De effectieve
corpusfrequenties van de woorden/eigennamen daalt namelijk sneller naarmate hun id-groter
wordt.
Dit is af
te lijden uit de duidelijk concave kromming van de woorden/eigennamen-
distributie.
Termfrequenties
Aangezien het de bedoeling is om op basis van deze documentvoorstelling met termen events
te detecteren,
worden de termfrequenties van enkele termen onderzocht.
Hierbij
staat term-
frequentie nu voor het aantal voorkomens van een term gedurende een bepaalde dag
2
.
We verwachten dat er op basis van deze termfrequenties al informatie te achterhalen is over het
voorkomen van events.
Om dit te onderzoeken bekijken we nu de termfrequenties van enkele ter-
men over de volledige corpus, zie figuur 3.2 (merk op dat de dagen waarop er geen documenten
beschikbaar zijn, niet worden weergegeven).
Uit deze figuur kunnen we besluiten dat we op deze manier effectief informatie over events kun-
nen terugvinden.
Als we kijken naar een individuele term, dan zien we namelijk een piek op het
moment dat er een speciale gebeurtenis was die te maken heeft met deze term (hier meestal de
locatie van een bepaalde ramp).
Wat ons echter ook opvalt is dat het minder eenvoudig is om per dag te bekijken wat de meest
belangrijke termen zijn, in het licht van gebeurtenissen.
Zo zien we dat veelvoorkomende termen
zoals bv. CD&V, bijna altijd meer voorkomen dan een term die betrekking heeft tot een event
(ramp) (probleem1).
Verder zien we ook dat de termfrequenties onderhevig zijn aan veel variatie
(probleem2).
Deze variatie biedt geen extra informatie (alleszins niet om events te detecteren),
maar is meer te interpreteren als “ruis” op de termfrequenties.
Deze variatie duidt immers geen
effectief verschil in belang van de termen aan.
Een van de verklaringen voor deze variatie is dat
het totaal aantal artikels per dag ook varieert.
Verder worden er ook consequent minder artikels
gepubliceerd iedere maandag.
Deze invloed van het aantal
artikels kan vermeden worden door
de termfrequenties te delen door het aantal artikels die die dag werden gepubliceerd.
Hierdoor
is de ruis echter nog niet verdwenen.
Verder
kunnen we om deze twee problemen op te lossen,
de volgende twee stappen uitvo-
eren:
1.
De termfrequenties vervangen door de som van de TFIDF-gewichten over een bepaalde dag
2
Deze betekenis van de termfrequentie wordt enkel in deze sectie gehanteerd.
In de andere hoofdstukken staat
termfrequentie consequent voor het aantal voorkomens van een term in ´e´en document.
3.1 Analyse van het corpus
24
van een bepaalde term.
Op deze manier krijgen termen die in veel documenten voorkomen
dus een kleiner gewicht,
zoals beschreven in sectie 2.1.2.
Deze sommen worden nu de
gewogen termfrequenties genoemd.
2.
Het onderdrukken van de ruis door de termfrequenties te onderwerpen aan een glijdend en
gewogen gemiddelde.
Hierbij wordt de termfrequentie van een dag dus vervangen door het
gemiddelde van de termfrequenties van die dag en de omgevende dagen, waarbij de dagen
verder van de huidige dag telkens een kleiner gewicht krijgen.
0
50
100
150
200
250
300
datum - dagen sinds 3 jan 2011
0
100
200
300
400
500
600
termfrequentie
Fukushima
Pukkelpop
Noorwegen
Luik
CD&V
Figuur 3.2:
Termfrequenties van verschillende termen, zonder enige vorm van voorbewerking.
Het resultaat na het uitvoeren van deze stappen is terug te vinden in figuur 3.3.
Hierop zien
we dat de ruis sterk verminderd is en dat het ruis-probleem dus is opgelost,
wel
zorgt de uit-
middeling er natuurlijk voor dat de pieken in de gewogen termfrequenties worden afgevlakt.
Het vervangen van de termfrequenties door de som van de TFIDF-gewichten blijkt echter on-
voldoende om de gewogen termfrequenties van de minder voorkomende termen te boosten.
Een
betere voorstelling kan gevonden worden door gebruik te maken van TFIDF-gewichten waar-
bij de documentfrequentie op een lineaire schaal
bekeken wordt in plaats van de logaritmische
schaal.
Het resultaat hiervan is terug te vinden in figuur 3.4.
Deze voorstelling maakt het inder-
daad mogelijk om per dag de belangrijkste termen terug te vinden.
Het probleem bij het gebruik
maken van documentfrequenties die niet logaritmisch herschaald worden, is echter dat deze als
herweging bij
de VSM-voorstelling van de documenten minder bruikbaar is,
de herschaling is
namelijk te drastisch.
3.1 Analyse van het corpus
25
0
50
100
150
200
250
300
datum - dagen sinds 3 jan 2011
0.000
0.002
0.004
0.006
0.008
0.010
0.012
0.014
0.016
termfrequentie
Fukushima
Pukkelpop
Noorwegen
Luik
CD&V
Figuur 3.3:
Gewogen termfrequenties van verschillende termen,
waarbij
de termfrequenties nu bestaan
uit de som van de verschillende TFIDF-gewichten per term per dag gedeeld door het aantal
documenten
gepubliceerd die dag.
Deze gewogen termfrequenties werden vervolgens onderworpen aan een gewogen
glijdende uitmiddeling met enkelzijdige vensterbreedte van 3 dagen.
0
50
100
150
200
250
300
datum - dagen sinds 3 jan 2011
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
termfrequentie
Fukushima
Pukkelpop
Noorwegen
Luik
CD&V
Figuur 3.4:
Gewogen termfrequenties van verschillende termen,
waarbij
de gewogen termfrequenties nu
bestaan uit de som van de verschillende TFIDF-gewichten per term (met de documentfrequentie nu niet
logaritmisch herwogen) gedeeld door het aantal
documenten gepubliceerd die dag.
Deze gewogen termfre-
quenties werden vervolgens onderworpen aan een gewogen glijdende uitmiddeling met
enkelzijdige ven-
sterbreedte van 3 dagen.
3.2 Structuur van het corpus
26
3.2
Structuur van het corpus
De gegeven verzameling krantenartikels bestaat uit een verzameling zip-files, waarbij iedere zip-
file alle krantenartikels van een bepaalde dag bevat.
Ieder krantenartikel wordt nu voorgesteld
door een xml-file die de volgende informatie over het artikel bevat:
• de titel
• de tekst
• de publicatiedatum
• de auteur
• de uitgever
• het paginanummer
Daarnaast zijn er nog twee preprocessing stappen uitgevoerd m.b.v.
de software ontwikkeld aan
de onderzoeksgroep,
waardoor er nog twee andere voorstellingen van de artikels beschikbaar
is:
• .ner-files:
die per dag een .ner file bevat en die een lijst van alle aanwezige eigennamen per
artikel weergeeft.
• .sequence-files:
die per dag een .sequence-file bevat, die een lijst van alle tokens per artikel
weergeeft.
Het probleem met deze voorstellingen is dat ze niet de meest compacte of meest rekenvriendelijke
voorstellingen zijn.
Het zou namelijk voordeliger zijn om met term-ids te werken i.p.v.
deze
termen telkens expliciet te moeten gebruiken.
Daarom zal er op basis van de gegeven voorstelling
een nieuwe compactere voorstelling gemaakt worden met behulp van het framework dat hierna
besproken wordt.
3.3
Framework voor corpusbehandeling
Gezien de omvang van het corpus werd de noodzaak gezien voor een algemene aanpak om met
het corpus te werken en hiermee te kunnen experimenteren.
Hierbij
moest de aanpak of
het
framework waarmee gewerkt zal worden, voldoen aan de volgende eisen:
1.
Bewerkingen op het corpus moeten gedaan kunnen worden op een geheugeneffici
¨
ente maar
snelle manier.
2.
Het geheel
moet schaalbaar zijn,
zodat het ook kan omgaan met grotere corpora,
dus
corpora die niet in het werkgeheugen passen.
3.
De temporele informatie vervat in het corpus moet benut kunnen worden.
3.3 Framework voor corpusbehandeling
27
4.
Een pluspunt zou zijn dat ze op deze manier is opgebouwd dat bestaande ge
¨
ımplementeerde
technieken rechtstreeks gebruikt kunnen worden.
Tijdens het zoeken naar reeds bestaande implementaties van frameworks die hiermee compat-
ibel
zouden moeten zijn,
werd een module in Python gevonden die bijna aan al
deze eisen
voldeed, Gensim [Radim & Sojka, 2010] genaamd.
Deze module heeft een gestructureerde aan-
pak voor het werken met grote corpora,
maar de nadruk ligt hier meer op het gebruik van
deze corpora voor topic modellering.
Een nadeel
is dat hierbij
geen mogelijkheden waren om
de temporele informatie uit het corpus te benutten.
Aangezien er wel
al
reeds andere tech-
nieken ge
¨
ımplementeerd werden die op het corpus konden gebruikt worden, is dan besloten om
te vertrekken van deze module en deze uit te breiden zodat ze gebruik kan maken van de tem-
porele informatie.
Deze uitbreiding werd Timesim genaamd.
Beide modules worden nu in de
volgende secties besproken.
3.3.1
Gensim
Nu volgt een korte bespreking van het Gensim-framework.
Dit is een Python-module, waarin er
vier verschillende concepten van belang zijn om met het corpus te werken.
Deze vier concepten zijn corpus, dictionary, model en similarities.
Waarbij corpus de mogelijk-
heid voorziet om de verzameling documenten als vectors van term-id’s en gewichten te overlopen.
Dictionary bevat de relatie tussen de termen en hun id’s,
een model
maakt het mogelijk om
gegeven een bepaalde corpus, een nieuwe corpus te genereren die een andere voorstelling van de
documenten bevat.
Similarities maken het mogelijk om op een effici
¨
ente manier verschillende
documenten met elkaar te vergelijken.
Alle concepten, uitgezonderd de dictionary, zijn gedefinieerd als een soort interface (ge
¨
ımplementeerd
als abstracte klasse) in Python, deze kunnen dan in verschillende klassen worden ge
¨
ımplementeerd.
Er zijn reeds verschillende klassen aanwezig in de Gensim module.
Maar algemeen kunnen de
klassen die deze interfaces implementeren als volgt beschreven worden:
Een corpus-klasse is een klasse die een bijhorende dictionary bevat en een verzameling van
artikels.
Deze verzameling van artikels blijft “on disk”.
De belangrijkste functie van
een corpus is het teruggeven van een iterator,
die deze artikels een voor een doorloopt.
Ieder artikel
wordt voorgesteld door een vector met id’s en hun bijhorende gewichten.
De betekenis van deze id’s is in de bijhorende dictionary terug te vinden.
De meeste
corpus-klassen zijn ook ge
¨
ımplementeerd als indexed corpus,
waardoor de documenten
ook via hun document-id kunnen worden opgevraagd.
Het verschil tussen de verschillende
klassen is dat ze elk een eigen serializatie-formaat hebben.
Ook is het mogelijk om van
de ene corpus-klasse over te gaan naar de andere, aangezien enkel het serializatie-formaat
verschilt.
Concreet kan een corpus dus worden voorgesteld als een genummerde lijst van
sparse vectoren, dezelfde corpusklasse kan dus gebruikt worden voor de verschillende VSM-
3.3 Framework voor corpusbehandeling
28
tekstvoorstellingen.
corpus =











docid
1
:
[f eature
1
1
: weight
1
1
,
f eature
1
2
: weight
1
2
, ...
]
docid
2
:
[f eature
2
1
: weight
2
1
,
f eature
2
2
: weight
2
2
, ...
]
...
docid
n
:
[f eature
n
1
: weight
n
1
,
f eature
n
2
: weight
n
2
, ...
]
(3.2)
Dictionary is een klasse die de relatie tussen alle termen en hun bijhorende id’s bevat in het
corpus.
Ze bevat ook de volgende belangrijke functies:
• Functie om een document (als lijst van woorden) om te vormen naar een vector van
id’s en gewichten.
Deze functie bevat ook de mogelijkheid om de dictionary zo “on-
the-fly” aan te vullen.
• Functie om de dictionary te filteren,
zodat id’s die te veel
of
te weinig voorkomen,
worden verwijderd.
Verder houdt een dictionary het aantal voorkomens van iedere term bij, de corpusfrequentie
(CF).
Van deze dictionary is er ook maar ´e´en implementatie in Gensim.
Dit kan dus als
volgt worden samengevat:
dictionary =











termid
1
:
CF
1
woordstring
1
termid
2
:
CF
2
woordstring
2
...
termid
m
:
CF
m
woordstring
m
(3.3)
Een model-klasse is een klasse die een corpus kan transformeren en dit doet het in twee
stappen die ge
¨
ımplementeerd worden als twee functies.
De eerste is het initialiseren van
het model.
Dit gebeurt door een corpus mee te geven en de nodige parameters.
De tweede
stap is dan de eigenlijke transformatie.
Deze methode vraagt als input een voorstelling van
een document, en geeft dan de nieuwe voorstelling (volgens het model) van dit document
terug.
Merk op dat dit dus een heel brede definitie is van een model, maar dit biedt veel
vrijheid voor de verschillende implementaties van de modellen, die sterk kunnen verschillen.
Modellen of transformaties die in Gensim ge
¨
ımplementeerd zijn:
• TFIDF
• LSI (Latent Semantic Indexing)
• LDA (Latent Dirichlet Allocation)
• HDP (Hierarchical Dirichlet Process)
• Random Projections
• LogEntropy
3.3 Framework voor corpusbehandeling
29
Een Similarity-klasse maakt het mogelijk om gegeven documenten in vectorvoorstelling (VSM),
zoals ze gedefinieerd zijn in een corpus, te vergelijken met elkaar.
Om dit zo effici
¨
ent mo-
gelijk te doen, wordt hiervoor de volgende methode gehanteerd:
Eerst wordt een Similarity-instantie ge
¨
ınitialiseerd door een corpus mee te geven.
Hiervoor
genereert deze dan een index, dit is een effici
¨
ente Scipy voorstelling van het corpus die het
mogelijk maakt om sneller berekeningen uit te voeren.
Eenmaal
deze index bestaat,
kunnen nu verschillende documenten met elkaar vergeleken
worden.
Deze documenten kunnen tot het corpus behoren, maar kunnen evengoed nieuwe
documenten zijn.
Ook is het mogelijk om met corpussen te werken waarvan de index niet in het werkge-
heugen past.
Hiervoor wordt de index dan opgesplitst in kleinere shards,
die opgeslagen
worden “on disk”.
3.3.2
Timesim
De bovenstaande Gensim-module werd nu uitgebreid zodat er ook gebruik gemaakt kon wor-
den van de tijdsinformatie in het corpus.
Hierbij
werd ook aandacht besteed aan backward-
compatibiliteit,
zodat er nog steeds gebruik gemaakt kan worden van de verschillende functies
van Gensim.
Om deze backward-compatibiliteit te verzekeren,
werd er vertrokken van de interfaces van de
corpus-klassen en de dictionary-klasse om een meer uitgebreide versie te maken.
Er werden ook
nieuwe modellen ge
¨
ımplementeerd, maar deze worden pas in het volgende hoofdstuk besproken.
Ook kan er nog steeds gebruik gemaakt worden van de bestaande Similarity-klassen.
Uitbreidingen corpus
Op basis van de bestaande Corpus-klassen werden er nu verschillende nieuwe klassen toegevoegd
om enerzijds met temporele informatie te kunnen werken en anderzijds om flexibeler met deze
corpora om te gaan.
Om compatibiliteit met de bestaande corpus-klassen te bewaren,
werd geopteerd voor een uit-
gebreide corpus,
waarbij
de uitbreidingen (metadata zoals timestamp,
titel
enz.)
gescheiden
worden geserialiseerd naast de bestaande vectori
¨
ele corpusrepresentatie.
Dit biedt twee voorde-
len:
1.
De bestaande files die het corpus “on-disk” voorstellen kunnen zo blijven gebruikt worden
en nieuwe corpussen die gecre
¨
eerd worden, kunnen dus ook rechtstreeks gebruikmaken van
de bestaande gensim-modellen.
2.
De extra informatie die vervat zit in het uitgebreide corpus (de metadata) zijn statische
gegevens die dus door een model
nooit veranderd moeten worden.
Daarom is het ook
3.3 Framework voor corpusbehandeling
30
logisch om deze apart te houden van de vectori
¨
ele voorstelling,
zodat deze niet onnodig
gekopieerd moet worden na iedere corpustransformatie.
Een korte samenvatting van de verschillende corpusklassen:
RichIndexedCorpus:
Uitbreiding van de basis IndexedCorpus uit gensim, waarbij er nu ook
extra informatie (zoals de timestamp) per document kan worden bijgehouden.
RichTextCorpus:
Corpus-klasse om vertrekkende van de .segment- of de .ner-files een corpus
te genereren.
Deze corpus-klasse biedt echter geen mogelijkheid tot het serialiseren van
het corpus.
AnnotatedCorpus:
Implementatie van RichIndexedcorpus,
waarbij
het corpus nu kan gese-
rialiseerd worden en waarbij
dus zowel
de vectori
¨
ele voorstelling als de extra informatie
geserialiseerd kunnen worden.
DocInfo:
Corpus waarbij enkel de extra informatie per document wordt beschouwd.
Deze kan
dus gebruikt worden om de meta-data van een document op te vragen,
zonder dat de
vectori
¨
ele voorstelling gekend moet zijn.
CombinedCorpus:
Corpus die ge
¨
ınitiliseerd wordt door twee andere corpora mee te geven.
Op deze manier kan een nieuwe corpus gecre
¨
eerd worden als combinatie van twee andere,
bv. een nieuwe corpus die zowel de eigennamen als woorden van de documenten bevat.
SubIndexedCorpus:
Corpus ge
¨
ınitiliseerd door het meegeven van een bestaande corpus en
een lijst van document-id’s, deze nieuwe corpus zal dan enkel de selectie van artikels van
de eerste corpus bevatten.
Deze uitgebreide corpusvoorstelling met extra meta-data (timestamp, titel, paginanummer enz.)
kan dus als volgt worden samengevat:
corpus =











docid
1
:
[f eature
1
1
: weight
1
1
,
f eature
1
2
: weight
1
2
, ...
]
metadata
1
docid
2
:
[f eature
2
1
: weight
2
1
,
f eature
2
2
: weight
2
2
, ...
]
metadata
2
...
docid
n
:
[f eature
n
1
: weight
n
1
,
f eature
n
2
: weight
n
2
, ...
]
metadata
n
(3.4)
Waarbij zowel de metadata als de vectori
¨
ele voorstelling afzonderlijk bruikbaar zijn.
Uitbreiding Dictionary
Om ook temporele informatie beschikbaar te maken op term-niveau, werd de dictionary uitge-
breid.
Hierbij werd wel aandacht besteed om zo weinig mogelijk informatie dubbel op te slaan.
Daardoor wordt er enkel
een lijst van de documenten waarin de term voorkomt (postingslist)
bijgehouden,
maar niet expliciet het aantal voorkomens van de term per dag.
Deze informatie
3.3 Framework voor corpusbehandeling
31
kan namelijk bekomen worden via het corpus.
Hierdoor wordt er in de dictionary nu de volgende
informatie per term bijgehouden:
• De vertaling van de term-id naar de term, de woordstring.
• Documentfrequentie die bijhoudt in hoeveel documenten de term voorkomt.
• Een postingslist die bijhoudt in welke documenten de term voorkomt.
Wat dus meer symbolisch als volgt wordt voorgesteld:
dictionary =











termid
1
:
cf
1
woordstring
1
[docid
1
1
,
docid
1
2
, ...]
termid
2
:
cf
2
woordstring
2
[docid
2
1
,
docid
2
2
, ...]
...
termid
m
:
cf
m
woordstring
m
[docid
m
1
,
docid
m
2
, ...]
(3.5)
MODELLERING
32
Hoofdstuk 4
Modellering
In dit hoofdstuk zullen we enkele algoritmen uit de literatuurstudie beter analyseren en op basis
van onze analyse enkele verbeteringen voorstellen.
Concreet starten we met het analyseren van
de BurstVSM-tekstvoorstelling en daarna zullen we onze keuze voor het gebruikte clusteralgo-
ritme verantwoorden.
4.1
Tekstvoorstellingen
In de literatuurstudie zijn er al
verschillende tekstvoorstellingen besproken,
waarbij
er enkele
gebruik maken van temporele informatie.
De meest vernieuwende hiervan is de voorstelling door
middel van bursty-features gedefinieerd over bursty periodes (bursts), of BurstVSM [Zhao et al., 2012].
Deze vernieuwende aanpak waarbij features gedefinieerd worden per burst, lijkt heel wat poten-
tieel
te hebben.
Daarom zullen we deze voorstelling analyseren en mogelijke verbeteringen
voorstellen.
4.1.1
Analyse van BurstVSM
Een aantal aspecten rond de implementatie van het BurstVSM-algoritme zijn terug te vinden in
sectie 5.1.1, gerelateerde testresultaten worden in sectie 7 gegeven.
Schematisch is het algoritme
weergegeven in de onderstaande figuur 4.1.
De werking van het algoritme zullen we nu echter al methodologisch analyseren om zo een beter
inzicht te verwerven in de werking en om potenti
¨
ele verbeteringen te kunnen voorstellen.
Zo kunnen we het algoritme zien als een vectortransformatie waarbij
overgegaan wordt van
de statische TF VSM-voorstelling,
naar de BurstVSM-voorstelling die dus werkt met nieuw
gedefinieerde bursty-features (als de verschillende dimensies van de vectoren).
Om het algoritme beter te kunnen begrijpen, is het ook eenvoudiger om dit nu op te splitsen in
4.1 Tekstvoorstellingen
33
to be derived from a document,
e.g.,
term feature
type, title term feature type.
• Feature selection/transformation:
select and trans-
form features,
e.g.,
both rarely used and overly
common term features may be discarded.
• Feature weighting:
assign weight to a feature type
based on a given formula,
e.g.,
binary,
TF,
and
TFIDF.
3.2
Motivation for Bursty Topic Representa-
tion Bursty topics can be emphasized by considering
only certain time windows and bursty features.
For ex-
ample,
the word feature “hurricane” from topic “Hur-
ricane Mitch” shown in Figure 3 overlaps significantly
with the topic document frequency.
In this example, a
feature traffic vs. topic traffic
0
20
40
1-Oct-98
17-Oct-98
2-Nov-98
18-Nov-98
4-Dec-98
20-Dec-98
time
feature: hurricane
topic: Hurricane Mitch
document
frequency
burst
Figure 3:
Traffic overlap between a bursty topic and its
feature “hurricane”.
total of 401 documents contain the feature “hurricane”,
among which 97 are outside of the “Hurricane Mitch”
topic.
If “hurricane” were the only feature discriminat-
ing this topic from the rest, the corresponding precision
would be (401 − 97)/401 = 75.81%.
From Figure 3,
if we only take into account the bursty period of word
feature “hurricane” lasting from 24-Oct to 16-Nov, only
10 out of
the 260 documents containing the word fea-
ture “hurricane” are off-topic,
thereby yielding a 20%
improvement in precision at (260 − 10)/260 = 96.15%!
The above simple example illustrates the benefit of
using a single bursty feature restricted to certain bursty
time periods over the whole life span of a topic.
If more
bursty periods and their associated bursty features are
identified,
they could collectively improve the overall
distinctiveness of each topic.
Such discriminative
features
with corresponding
bursty life spans are called “bursty features” in this
paper.
To find bursty features,
the burstiness of every
word feature in the corpus with respect to all topics will
have to be computed.
In this example,
we would need
to determine a set of features for the “Hurricane Mitch”
topic, and their corresponding bursty life spans.
This is
a challenging problem because the i-th document in a
text stream now has a dynamic vector representation
d
i
(t)
that
depends
on time
stamp t.
In the
next
section,
we shall
present our proposed bursty feature
representation to this challenging problem.
4
Bursty Feature Representation
We
now describe
our
bursty feature
representation
that combines burstiness with static feature weights.
Representing a document with bursty features involves
two major steps:
(1) identifying bursty features, and (2)
representing documents using bursty features/weights,
as shown in Figure 4.
Figure 4:
An overview of bursty feature representation.
In Figure 4, a document is assigned bursty weights
depending on its time stamp t.
The same raw document
may have different bursty feature representations at two
different time points t
i
6= t
j
.
In Section 4.1,
we will
first
describe how bursty
features can be identified.
This is followed by the bursty
feature representations in Section 4.2.
4.1
Bursty Feature Identification Bursty feature
identification from text
streams
have
recently been
investigated by a number of researchers [6, 7, 19].
Since
the goal of this paper is to utilize bursty features and not
to develop a new bursty feature identification algorithm,
we simply adopt Kleinberg’s [7] 2-state finite automaton
model to identify bursty features, as shown in Figure 5.
Figure 5:
A 2-state finite automaton model
for identi-
fying bursty features.
There are two states q
0
and q
1
in the finite automa-
ton model A of Figure 5.
For every feature f in a text
stream,
when A is in state q
0
at time point t,
it has a
low emission rate β
0
= |R
d
|/T ,
where |R
d
|
is the size
of
all
relevant documents containing f over the whole
Figuur 4.1:
Schematische weergave van het
BurstVSM-algoritme,
waarbij
er in de eerste stap de ver-
schillende bursty-features ge
¨
ıdentificeerd worden, in de tweede stap worden de documenten dan voorgesteld
gebruik makende van de gevonden bursty-features,
waarbij
ook de bijhorende gewichten bepaald moeten
worden.
(bron:
[He et al., 2007])
twee onderdelen.
Zo worden eerst de nieuwe bursty-features (dimensies) bepaald.
Deze features
worden gevonden met behulp van het burst-detectie algoritme van Kleinberg [Kleinberg, 2003].
Het is dus al
belangrijk om deze goed te analyseren om mogelijk betere features te bekomen.
Daarna worden de document-vectoren getransformeerd.
Hierbij wordt IDF-herweging toegepast
op de gevonden bursty-features.
Het is dus ook mogelijk om betere herwegingen dan de IDF-
herweging te zoeken.
In deze sectie zullen we eerst enkele bestaande implementatiekeuzes in vraag stellen,
waarna
we in de volgende sectie concrete voorstellen doen en andere verbeteringen voorstellen gebruik
makende van conclusies uit ander gerelateerd onderzoek.
Ruis op de documentfrequenties
Zoals in sectie 3.1.2 aangetoond, bevatten de document(/term)-frequenties heel wat variatie/ruis.
Aangezien deze variatie geen bruikbare informatie bevat, lijkt het ook nogal zinloos om deze te
gebruiken.
De ruis kan er immers enkel
voor zorgen dat bursts voortijdig opgesplitst worden,
al
wordt dit natuurlijk grotendeels vermeden door gebruik van de toestandsautomaat met een
transitiekost.
We zullen in onze uitbreiding van het BurstVSM-model
kijken om deze ruis dus weg te fil-
teren door
gebruik te maken van een gewogen glijdende uitmiddeling,
zoals
beschreven in
sectie 3.1.2.
IDF-herweging
In het
bestaande BurstVSM-model
wordt
er
op de gewichten van de bursty-features
IDF-
herweging toegepast.
Deze klassieke herweging gaat uit van de veronderstelling dat termen/fea-
tures die in veel documenten voorkomen, algemene termen zijn, die dus weinig onderscheidend
vermogen hebben.
Deze termen zijn dus minder beschrijvend of discriminatief voor een docu-
ment en zijn dus ook niet van belang om documenten van elkaar te scheiden.
4.1 Tekstvoorstellingen
34
Bij een algemene corpus die gebruik maakt van conventionele niet-temporele features (met ´e´en
niet-nul
feature per term) zoals TF VSM-tekstvoorstelling,
klopt deze veronderstelling inder-
daad.
Zo is het logisch dat termen die bijna in alle documenten voorkomen (bv.
stopwoorden
zoals “de”, “is” etc.) een kleiner gewicht krijgen in de vectori
¨
ele voorstelling van documenten.
Nu er echter gewerkt wordt met bursty-features,
die enkel
voorkomen over een beperkte peri-
ode (burst) gaat deze veronderstelling niet meer op.
Zoals in sectie 2.2.3 beschreven,
worden
bursty-features enkel
gedefinieerd als de bijhorende term over een bepaalde periode veel
meer
dan gemiddeld voorkomt.
Op deze manier worden algemene termen,
die geen onderscheidend
vermogen hebben al automatisch uit de selectie gefilterd.
Deze termen hebben namelijk een heel
constante documentfrequentie (op de ruis na) zoals te zien is op figuur 4.2.
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
datum
0
50
100
150
200
documentfrequentie
DF “mij”
Figuur 4.2:
Weergave van de documentfrequenties (DF) van de inhoudelijk onbelangrijke term “mij”.
Hier zijn er dus duidelijk geen bursts in terug te vinden.
Verder komen alle bursty-features slechts over een beperkt aantal
documenten voor.
Als een
burst van een bursty-feature bv. drie weken duurt, dan kan deze bursty-feature slechts voorkomen
in documenten tijdens
deze drie weken.
Dit
toont
ook aan dat
de IDF-herweging minder
toepasselijk is voor bursty-features.
Als we namelijk uitgaan van deze herweging,
dan zullen
bursty-features,
die bv. een burst hebben van 5 dagen (en dus ook in veel minder documenten
voorkomen) een veel
groter gewicht krijgen dan bursty-features van de burst die drie weken
duurt.
Dit komt echter niet overeen met de menselijke perceptie van het belang van deze features.
Om
dit te illustreren volgt nu een voorbeeld.
In figuur 4.3 zijn de documentfrequenties van twee termen en hun bijhorende bursty-features
die horen bij
het pukkelpop-drama weergegeven.
Deze termen zijn “Pukkelpop” en “Mari-
jke”,
met “Marijke” de naam van ´e´en van de slachtoffers.
Zoals in figuur 4.3 merkbaar,
duurt
4.1 Tekstvoorstellingen
35
de gevonden burst van “Pukkelpop” veel
langer dan de burst van “Marijke”.
Verder zijn de
documentfrequenties van “Pukkelpop” veel
hoger dan die van “Marijke”,
op de figuur zijn de
documentfrequenties van “Marijke” zelfs nog met 5 vermenigvuldigd om de duidelijkheid van de
figuur te verbeteren.
Aangezien de documentfrequenties van de bursty-features enkel geteld worden tijdens de burst,
zal de bursty-feature horende bij “Pukkelpop” na IDF-herweging dus een kleiner gewicht toegek-
end krijgen dan deze horende bij “Marijke”.
Dit is echter niet gewenst,
want op deze manier
zullen documenten over het Pukkelpop-drama minder op elkaar gaan lijken volgens deze tekst-
voorstelling aangezien documenten een groter gewicht toekennen op basis van de aanwezigheid
van meer uitzonderlijke termen als “Marijke”.
Hierdoor zullen er dus meer kleine clusters
gevormd worden,
maar minder clusters die gaan over een volledig event.
Dit toont dus aan
dat het de verkeerde features zijn die een groot gewicht krijgen.
Daarom zullen we deze IDF-
herweging weglaten en/of vervangen door andere herwegingsfuncties.
Jul
Aug
Sep
Oct
Nov
datum
0
50
100
150
200
250
documentfrequentie
0
50
100
150
200
250
DF “Pukkelpop”
DF “Marijke”
bursts “Pukkelpop”
bursts “Marijke”
Figuur 4.3:
Documentfrequenties en de erbijhorende bursts van de termen “Pukkelpop” en “Marijke”.
Waarbij
de documentfrequenties van “Marijke” met
5 zijn vermenigvuldigd om de leesbaarheid te ver-
beteren.
We zullen IDF-herweging echter wel testen op de termen (die dus lopen over de volledige corpus)
in plaats van op de bursty-features.
Hierbij gelden de veronderstellingen rond IDF-herweging
immers wel nog.
Let wel dat deze herweging enkel impact heeft op de gewichten van de bursty-
features,
niet de bursty-feature selectie.
Bij deze selectie wordt immers enkel
gebruikgemaakt
van de documentfrequenties.
4.1 Tekstvoorstellingen
36
4.1.2
Toepassing van conclusies uit ander onderzoek
Om een betere voorstelling te bekomen, zullen we verder gebruik maken van conclusies uit de pa-
pers over feature pivot clustering [Fung et al., 2005] en bursty-weighting [He et al., 2007].
Feature-selectie
In de eerste paper [Fung et al., 2005]
wordt overgegaan van document-pivot clustering naar
feature-pivot clustering.
Dit wil zeggen dat events gedefinieerd worden als een verzameling van
features i.p.v.
een verzameling documenten.
Deze nieuwe aanpak werd voorgesteld omdat er
ook uit eerdere studies [Chang, 2004] bleek dat gelijkaardige documenten, vaak tot verschillende
categorie
¨
en behoren,
in dit onderzoek waren de documenten webpagina’s en de verschillende
categorie
¨
en verschillende soorten webpagina’s.
Wat voor hen de indicatie gaf dat gelijkaardige
documenten ook tot verschillende events kunnen behoren en documenten horende bij hetzelfde
event dus sterk verschillend kunnen zijn.
Deze problemen worden veroorzaakt door ruis-termen
of
ruis-features die in de documenten voorkomen,
maar niet van belang zijn voor de event-
detectie.
Door nu events te defini
¨
eren op basis van een kleine set bursty-features,
worden de
aanwezige ruis-termen dus al grotendeels verwaarloosd.
Deze impact is echter nog niet volledig
verdwenen.
Deze mogelijk negatieve invloed van ruis-termen kwam ook naar voren tijdens het aanmaken
van de referentieset van events en het zoeken naar de bijhorende documenten.
Zo werd duidelijk
dat events meestal
bestaan uit een groep documenten die inhoudelijk sterk van elkaar kunnen
verschillen.
Zo zijn er voor het event “Pukkelpop drama” verschillende soorten artikels,
die
hieronder worden opgesomd:
• artikels met rapportering over de ramp
• artikels over de slachtoffers
• artikels over financi
¨
ele gevolgen en de verzekeringen
• artikels over de toekomst van Pukkelpop of de impact op andere festivals
• ...
Veel
artikels zijn inhoudelijk en dus ook in hun vectori
¨
ele voorstelling sterk verschillend.
De
artikels horen echter bij elkaar omdat ze allemaal over hetzelfde onderwerp gaan:
“Pukkelpop”.
Het lijkt dus ook logisch om events te defini
¨
eren op basis van een heel
beperkte set features.
Dit kan dus door deze features te clusteren tot events [Fung et al., 2005].
Maar dit zou ook
toepasbaar zijn door de set van features te verkleinen en dus enkel
deze niet-ruis-features te
behouden in de voorstelling van de documenten en deze voorstelling te gebruiken om documenten
te clusteren tot events,
zoals bij
BurstVSM [Zhao et al., 2012].
Hierbij
worden de niet-ruis-
features dus gedefinieerd als de bursty-features.
Bij het zoeken van deze bursty-features moet
er dus veel aandacht besteed worden aan het vermijden van deze ruis-features.
4.1 Tekstvoorstellingen
37
Feature-gewichten
Bij
de huidige gewichtsfuncties,
zowel
bij
gebruik van de zuivere termfrequenties als na IDF-
herweging, is er geen mogelijkheid om het belang of de grootte van de bursty-features te incor-
poreren.
Het zou echter nuttig zijn om belangrijke features een groter gewicht te kunnen geven.
Idealiter zou bv.
tijdens de periode rond het Pukkelpop-drama,
de bursty-feature horende bij
“Pukkelpop” een veel groter gewicht krijgen dan deze horende bij “Marijke”, zodat documenten
eerder geclusterd worden op basis van de aanwezigheid van de term ”Pukkelpop”,
dan op de
aanwezigheid van de term “Marijke”.
Deze soort van gewichtsuitbreiding (boosting) werd voorgesteld in [He et al., 2007].
In deze pa-
per werden de statische feature-gewichten (de binaire termfrequenties per document) vergroot
met een bijdrage die evenredig is met het gewicht van de bijhorende burst, waarbij het gewicht
en de burst bepaald werden met het burstdetectie-algoritme voorgesteld in [Kleinberg, 2003].
Op deze manier krijgen de termen die in een bursty periode zitten dus een boost waardoor het
belang van deze term in het document groter wordt.
Hierdoor zal
bij het clusteren van docu-
menten de aanwezigheid van deze term van groter belang zijn,
dan als deze niet in een burst
zit.
Een analoge boosting zal
in de volgende sectie ook worden voorgesteld voor de bursty-
features.
Het verschil
van de boosting van de bursty-features in vergelijking met de boosting
van de termen zoals in [He et al., 2007]
is dat de boosting bij
de bursty-features constant is
over de periode van de bursty-feature en dus een eigenschap is van de bursty-feature,
terwijl
het burst-gewicht bij
de boosting van termen afhankelijk is van de tijd (welke burst) en dit
gewicht gebruikt wordt om de temporele informatie te benutten.
Concreet zal
er bij het algo-
ritme beschreven in [He et al., 2007] dus een ander gewicht gegeven worden aan de term “Luik”
gedurende de periode april-mei 2011 dan gedurende de periode december 2011 aangezien de term
in de eerste periode gerelateerd wordt met het event “Luik-Bastenaken-Luik”,
terwijl
de term
in de tweede periode gerelateerd is met het event “aanslag in Luik”.
Het BurstVSM-algoritme
werkt echter met bursty-features.
Hierdoor zullen de burst-gewichten nu horen bij de twee ver-
schillende bursty-features en zijn deze gewichten dus constant voor de bursty-features en enkel
een indicatie van het belang van deze bursty-feature.
4.1.3
Boosted BurstVSM
De verschillende aanpassingen aan het bestaande BurstVSM-algoritme incorporeren we nu in
een nieuwe voorstelling, Boosted BurstVSM genaamd.
Deze bevat de volgende aanpassingen:
• IDF-herweging op de termfrequenties,
• gewogen glijdende uitmiddeling van de documentfrequenties,
• geen IDF-herweging van de bursty-features,
4.1 Tekstvoorstellingen
38
• boosting van de bursty-feature gewichten met behulp van de burstgewichten.
Nu zullen we concreet de boosting formaliseren en verschillende implementaties voorstellen.
Boosting
We vertrekken net als [He et al., 2007] van de burst-gewichten gedefinieerd door [Kleinberg, 2003],
gedefinieerd als:
w
j
=
t
2
X
t=t
1
(σ(0, r
t
, d
t
) − σ(1, r
t
, d
t
))
(4.1)
Waarbij
t
dus
loopt
over
de verschillende dagen van de burst
en σ(i, r
t
, d
t
)
staat
voor
de
emissiekost per dag,
gegeven toestand i
(1 of
0),
als r
t
documenten de term bevatten over
een totaal van d
t
documenten.
In de paper wordt dit gewicht (w
j
) nu opgeteld bij
het statische featuregewicht (T F
kj
).
Het
probleem is dat dit burst-gewicht heel
groot kan zijn (zie figuur 4.4) en sterk kan vari
¨
eren in
grootte.
Het minimum-gewicht is tweemaal
de transitiekost (zie [Kleinberg, 2003]),
wat in ons
geval neerkomt op ±7.5, terwijl de burst van bv. december een gewicht heeft van ±3500.
Daarom
moet deze nog worden genormaliseerd met behulp van een extra parameter, de burst-coeffici
¨
ent
δ,
die bepaald moet worden aan de hand van trainingsdata.
Dit soort boosting noemen we
voortaan Accumulated Boosting (AB).
We poneren nu een andere soort boosting,
die werkt zonder extra parameter.
Deze tweede
manier is het vermenigvuldigen van het statische featuregewicht met het burstgewicht,
die we
Multiplied Boosting (MB) zullen noemen.
Hierdoor is het uiteindelijke featuregewicht dus recht-evenredig met zowel het burstgewicht als
het statisch gewicht van de feature in het document.
De invloed van de grote variatie in de burst-gewichten zullen we ook proberen te minimaliseren
door het logaritme van het burst-gewicht te gebruiken,
Logarithmic Boosting (LB).
Verder in-
troduceren we hieronder een nieuwe gewichtsfunctie voor bursts, die gemotiveerd wordt aan de
hand van figuur 4.4.
4.1 Tekstvoorstellingen
39
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
datum
0
50
100
150
200
250
documentfrequentie
0
500
1000
1500
2000
2500
3000
3500
4000
burstsgewicht
DF Pukkelpop
DF december
bursts Pukkelpop
bursts december
Figuur 4.4:
Documentfrequenties en aanduiding van bijhorende bursts voor de term “Pukkelpop” met een
grote smalle piek en de term “december” die een meer constante hoge waarde heeft.
Hierop zien we dat de termen die typisch te maken hebben met een event en meer bepaald
een ramp of ongeval, meestal worden gekenmerkt door een heel scherpe piek in hun document-
frequenties,
zoals bv.
te zien op bovenstaande figuur 4.4 voor de term “Pukkelpop”.
Andere
termen die ook veel
meer gedurende een bepaalde periode voorkomen in vergelijking met het
gemiddelde voorkomen, zoals bv. “december” worden dan weer gekenmerkt door een meer con-
stante hoge documentfrequentie in de burst.
Het probleem met de huidige gewichtsfunctie voor bursts is dat de burst horende bij de term
“december” echter bevoordeeld wordt aangezien het gewicht afhangt van de afzonderlijke bij-
dragen van de verschillende dagen en de heel fijne pieken op deze manier niet veel bijdragen tot
het totale gewicht van de burst.
Het gewicht van de burst van “december” is zelfs groter dan
dit van “Pukkelpop”, terwijl intu
¨
ıtief duidelijk is dat de laatste een groter gewicht zou moeten
krijgen.
Om dit probleem te verhelpen en om termen waarvan de documentfrequenties een echte piek
vertonen sterker te doen doorwegen,
voeren we nu de volgende nieuwe gewichtsfunctie voor de
bursts in:
w
i
= (t
2
− t
1
) · max
t
(σ(0, r
t
, d
t
) − σ(1, r
t
, d
t
))
(4.2)
Hierbij werd de som over de gewichten per dag nu vervangen door het product van het maximale
gewicht over de dagen in de burst met het aantal dagen in de burst.
Op deze manier is het gewicht
van de burst dus rechstreeks afhankelijk van de maximale documentfrequentie in de burst.
Dit
burstgewicht noemen we nu het gesatureerde burstgewicht
en boosting die gebruik maakt van
dit burstgewicht zullen we Saturated Boosting (SB) noemen.
4.1 Tekstvoorstellingen
40
Verfijning feature-selectie
Uit het voorgaande voorbeeld blijkt dus dat er ook voor termen zoals “december” bursts gevon-
den worden.
Dit soort termen kan algemeen gezien worden als termen die enkel een temporele
betekenis hebben.
Andere voorbeelden zijn bv. seizoenen en moesten we een grotere corpus ter
beschikking hebben ook jaartallen etc.
De bursts horende bij deze termen,
hier specifiek voor
“december” hebben zelfs een groot gewicht,
wegens de lange duur van de burst.
Als we de
documentfrequenties bekijken dan is ook duidelijk dat deze term een duidelijke burst vertoont.
Het probleem is echter dat zo’n algemene term niet echt correspondeert met een event, waardoor
de bursty-features horende bij dergelijke termen gezien kunnen worden als de ruis-features uit
sectie 4.1.2.
Door de aanwezigheid van deze bursty-feature kunnen allerlei documenten namelijk
foutief geclusterd worden tot ´e´en event.
We proberen nu de feature-selectie of de burst-detectie
zo aan te passen of te tunen zodat er in dergelijke termen geen bursts gevonden worden.
Om dit doel te bereiken, analyseren we nu verschillende documentfrequentie-grafieken van ver-
schillende soorten termen of
meer specifiek met verschillende soorten bursts en zullen we op
basis hiervan de burst-detectie verfijnen.
Zo kunnen we verschillende soorten bursts identificeren:
• bursts horende bij rampen, bv. het Pukkelpop-drama
• bursts horende bij gekende gebeurtenissen over een korte tijdspanne, bv. nieuwjaar
• bursts horende bij gekende gebeurtenissen over een langere tijdspanne, bv. Tour de France
• bursts horende bij “temporele” termen (zoals hierboven gedefinieerd), die dus niet gelinkt
zijn met specifieke gebeurtenissen, bv. de verschillende maanden en seizoenen
Hierbij
verwachten we dat de laatste twee soorten bursts moeilijk te onderscheiden zijn,
wat
het dus ook moeilijk zou maken om enkel
deze laatste soort uit te filteren.
Als we echter de
documentfrequenties bekijken, dan merken we dat er enkel bij de laatste soort bursts een steeds
continue stijging en daling is van de documentfrequenties.
In alle andere gevallen is er gedurende
de burst een zekere gepiekte stijging van de documentfrequentie.
Om deze laatste soort bursts te negeren,
moeten we dus een model
gebruiken die deze niet-
continue stijgingen in de documentfrequenties gebruikt.
Dit zullen we proberen te bereiken
door de documentfrequentie op een bepaalde dag proberen te voorspellen op basis van een lin-
eair model,
en de afwijking hiervan gebruiken als gewicht.
Deze aanpak werd ook door Efron
[Efron, 2010] gebruikt om de gewichtsfunctie van de termen te bepalen.
Wij zullen nu concreet
als lineair model,
een glijdende gemiddelde nemen van de documentfrequenties in een venster
van 60 dagen rond de betreffende dag.
Hierbij werd de keuze van 60 dagen empirisch bepaald.
Bij een kleiner venster zijn er namelijk problemen door de aanwezige variatie in de document-
4.1 Tekstvoorstellingen
41
frequenties en zal er verder een grote overschatting van de documentfrequentie zijn de dagen net
na de piek, wat een nadelig effect heeft op de detectie van bursts.
Het verschil van deze uitmiddeling in vergelijking met de uitmiddeling gebruikt in [Zhao et al., 2012]
is praktisch dat deze uitmiddeling over een kortere periode gebeurt (60 dagen in plaats van 180
dagen), conceptueel is er echter een veel groter verschil aangezien de uitmiddeling in [Zhao et al., 2012]
gebruikt wordt om een meer correct gemiddeld voorkomen van de term te bepalen.
In deze paper
werd namelijk een corpus van 10 jaar gebruikt,
die artikels bevat van 2000 tot 2009.
Hierdoor
zijn er sommige termen die in deze periode een evolutie in hun gemiddeld voorkomen hebben.
Zo
zal de term “iPhone” slechts voorkomen vanaf het jaar 2007.
Door nu het gemiddeld voorkomen
van deze term over de volledige corpus te nemen, zal dit een serieuze onderschatting leveren van
het effectief gemiddeld voorkomen vanaf de introductie van deze term.
De uitmiddeling die we hier hanteren heeft echter een heel andere bedoeling.
Deze uitmiddeling
dient nu om effectief de documentfrequentie van de term te schatten per dag.
Hierdoor verge-
lijken we de effectieve documentfrequentie van een bepaalde dag dus niet met de gemiddelde
documentfrequentie, maar met de geschatte documentfrequentie.
Een andere manier om de bursts van deze temporele termen weg te filteren, zou kunnen gebeuren
door gebruik te maken van een frequentie-analyse om periodieke bursts uit te filteren.
Hiervoor
werd echter niet gekozen omdat er enerzijds maar 1 jaar ter beschikking is, waardoor dit onmo-
gelijk zou zijn en ten tweede omdat op deze manier alle periodieke events (zoals bv.
de jaarlijkse
“Tour de France”) natuurlijk ook uit het corpus gefilterd zouden worden.
4.1.4
Combineren van corpora
Zoals in vorig hoofdstuk 3 besproken,
kunnen we gebruik maken van zowel
eigennamen als
woorden om termen te defini
¨
eren.
Het lijkt daarom ook interessant om de bursty-features van
deze beide soorten termen te kunnen combineren.
Op deze manier zouden we de voordelen van
beide soorten termen kunnen combineren en dus een nog betere tekstvoorstelling bekomen.
4.2 Clusteralgoritmen
42
4.2
Clusteralgoritmen
4.2.1
Afweging tussen de verschillende modellen
Zoals in sectie 2.2.2 beschreven,
zijn er verschillende soorten clusteralgoritmen.
Om nu het
meest toepasselijke algoritme te zoeken, worden de volgende eigenschappen van de data of eisen
van de clustering vooropgesteld:
• sparse heel grote dataset met hoog-dimensionale documenten
• algoritme moet zelf optimaal aantal clusters bepalen
Een van de meest gebruikte clusteringsmodellen zijn de centroid-modellen,
met als meest gek-
ende algoritme K-Means clustering [Bishop, 2007,
Hoofdstuk 9].
Het grote nadeel
aan deze
aanpak is dat hierbij zelf het aantal
clusters moet opgegeven worden.
Een ander nadeel is dat
bij K-Means clustering alle documenten tot een van de K clusters moeten behoren.
Aangezien
niet ieder document/artikel
uit onze corpus tot een event moet behoren is dit model
dus ook
niet geschikt hiervoor.
Verder werkt deze clustering met sferische clusters,
wat natuurlijk een
nadeel is als een cluster bestaat uit verschillende soorten documenten, die dus niet allemaal op
elkaar lijken (zie sectie 4.1.2).
Maar waarvan er dus verschillende groepen documenten zijn die
meer op elkaar lijken.
Een tweede mogelijkheid die werd onderzocht,
was gebruik maken van distributiemodellen en
dan meer specifiek niet-parametrische bayesiaanse modellen.
Dit zijn probabilistische modellen
die zelf
een cluster-structuur opstellen en hierbij
zelf
het aantal
niveau’s en het aantal
clus-
ters bepalen.
Voorbeelden hiervan zijn nested Chinese Restaurant Process [Blei et al., 2010] en
recursive Chinese Restaurant Process [Kim et al., 2012].
Deze modellen bieden echter minder
transparantie naar de invloed van de tekstvoorstellingen op de gevonden clusters.
Waardoor
deze dus minder konden gebruikt worden om tegelijkertijd ook de tekstvoorstellingen verder te
verbeteren en te analyseren.
Daarom werden vervolgens enkele connectiviteitsmodellen, of hi
¨
erarchische modellen onderzocht.
Deze bepalen ook zelf het aantal clusters en kunnen ook een hi
¨
erarchische clusterverdelig gener-
eren.
Deze clustering gebeurt verder op basis van de onderlinge afstand tussen de verschil-
lende documenten.
Door te werken op basis van deze afstanden tussen de documenten is het
dus intu
¨
ıtiever om de invloed van verschillende tekstvoorstellingen te vergelijken.
Tussen deze
hi
¨
erarchisch modellen wordt er verder nog een onderscheid gemaakt tussen divisive en agglom-
eratieve modellen,
waarbij
de eerste “Top down”-aanpak hanteert,
waarbij
er dus vertrokken
wordt van ´e´en cluster en deze telkens wordt opgesplitst.
De tweede is een “bottom up”-aanpak.
Waarbij er dus telkens grotere clusters worden gevormd.
Verder werden er ook al
combinaties
van beide voorgesteld [Cheng et al., 2005].
Het probleem met al deze hi
¨
erarchische modellen is echter de complexiteit, deze is in het beste
geval namelijk O(n
3
) voor agglomeratieve en O(2
n
) voor divisieve algoritmes, met n het aantal
documenten.
4.2 Clusteralgoritmen
43
Daarom werd overgegaan op een densiteitsmodel die ge
¨
ınspireerd is op connectiviteitsmodellen.
Zoals eerder besproken in sectie 2.2.2, werd er dus een variant van DBSCAN ge
¨
ımplementeerd, al
was er toen nog geen kennis van dit DBSCAN-algoritme.
Hierbij worden clusters dus voorgesteld
als een verzameling documenten waarvan de erbijhorende punten in de featurespace een dense
verzameling punten is.
Deze clusters hebben om het even welke vorm,
het aantal
clusters
wordt door het algoritme zelf bepaald en het algoritme werkt ook behoorlijk effici
¨
ent voor grote
datasets.
Aangezien er bij deze soort clustering ook een filtering van de datapunten gebeurt, niet
alle punten zullen aan een cluster toegekend worden, werd dit densiteitsmodel ook als het meest
optimale clustermodel
bevonden.
Wel
wordt er geen speciale aandacht besteedt aan het feit
dat de documenten heel hoog-dimensionaal zijn, maar aangezien we tijdens het clusteren enkel
gebruik maken van de afstanden tussen verschillende documenten is dit geen zo’n probleem.
De
effectieve implementatie wordt beschreven in sectie 5.2 en wordt hier dus niet besproken.
Wel
worden enkele temporele uitbreidingen van het DBSCAN-algoritme besproken om de clustering
sneller uit te voeren.
4.2.2
Gebruik temporele informatie
Er moet worden opgemerkt dat de documenten in het corpus niet opgeslagen worden in een
R-tree zoals verondersteld wordt in [Ester et al., 1996].
Hierdoor is de tijdscomplexiteit van dit
algoritme van de orde O(n
2
) i.p.v. O(n log n).
Om dit probleem op te lossen zullen we gebruik
maken van de temporele informatie van de documenten.
We weten namelijk dat documenten
die dichter bij
elkaar gelegen zijn,
meer kans maken om bij
elkaar te horen dan documenten
die verder van elkaar gelegen zijn.
Zo komen de artikels die over een bepaald event gaan ook
(enkel) samen in een bepaalde tijdspanne voor en duurt deze tijdspanne maximaal
slechts een
paar weken.
Verder maken we ook gebruik van bursty-features die slechts over een beperkte tijd
voorkomen, meestal ook minder dan een maand.
Hierdoor wordt het dus zinloos om documenten
met elkaar te vergelijken die nooit dezelfde features kunnen bevatten.
Concreet kunnen we het clusteren nu versnellen door de dataset van artikels over het jaar 2011
eerst opsplitsen in kleinere stukken van 2 weken,
waarop dan geclusterd zal
worden.
Een-
maal
op al
deze stukken clusters gevonden zijn,
zal
op een niveau hoger,
stukken van 4 weken
beschouwd worden.
Hierbij worden dan de verschillende clusters die gevonden werden tijdens
de twee kortere periodes van 2 weken vergeleken en worden clusters samengevoegd als deze goed
overeenkomen.
Dit proces wordt telkens op een hoger niveau herhaald,
dus de volgende stap
is om twee stukken van elk 4 weken samen te nemen etc.
tot we twee stukken van 6 maanden
met elkaar vergelijken.
Op deze manier is het dus mogelijk om events die een veel
langere ti-
jdspanne hebben toch tot 1 cluster te kunnen samennemen.
Hierdoor moet er voor het meest
rekenintensieve deel dus enkel documenten met elkaar vergeleken worden die in dezelfde periode
van 2 weken voorkomen, waardoor het clusteren nu lineair schaalt met het aantal dagen, als het
aantal documenten per dag constant blijft.
In het vervolg zal deze clustermethode de recursieve
clustermethode genoemd worden.
Deze clusteringsmethode heeft echter nog steeds een aanzien-
4.2 Clusteralgoritmen
44
lijke rekentijd (±7h),
daarom werd gezocht naar een nog snellere methode.
Dit kan dus enkel
bereikt worden door minder documenten met elkaar te vergelijken.
Hiervoor werd een online incrementeel algoritme ge
¨
ımplementeerd, waarbij de documenten enkel
vergeleken worden met documenten uit het korte verleden (de dag voordien) en documenten die
dezelfde dag werden gepubliceerd.
Hierbij wordt het corpus dus niet opgesplitst in kleinere de-
len die achteraf
gemerged moeten worden,
maar worden de clusters ge
¨
ınitialiseerd tijdens het
doorlopen van het corpus en groeien deze ook tijdens het doorlopen van de documenten.
Meer
informatie over de effectieve implementatie van deze clusteralgoritmen is terug te vinden in
sectie 5.2.
IMPLEMENTATIE
45
Hoofdstuk 5
Implementatie
In dit hoofdstuk worden de implementaties van de verschillende technieken besproken.
Dit
zijn dus de modellen om nieuwe corpora te genereren en de clusteralgoritmen die documenten
groeperen om zo events te detecteren.
Daarnaast worden ook de implementaties van de visual-
isaties besproken.
De verschillende rekentijden die vermeld worden, werden bekomen bij het uitvoeren van de code
op een 64-bit linux server met een Intel Core
TM
i5-2400 CPU @3.10GHz en 4GB RAM
5.1
Tekstvoorstellingen
Zoals in sectie 3.3 besproken, werkt Gensim en bij uitbreiding dus ook Timesim met voorstellin-
gen van tekstcorpora als een geordende lijst van vectoren.
Om nu een specifieke tekstvoorstelling
te bekomen,
moet het corpus verschillende transformaties ondergaan en deze transformaties
gebeuren door middel van modellen.
De initi
¨
ele corpusvoorstelling is de statische TF VSM-representatie,
waarbij de features en de
bijhorende gewichten van de documenten respectievelijk de termen en hun termfrequentie zijn.
Om nu een nieuwe corpusvoorstelling te genereren waarbij andere gewichtsfuncties en/of features
gebruikt worden, moet de bestaande corpusvoorstelling getransformeerd worden door middel van
een model.
Op deze manier wordt dus een nieuwe corpus gegenereerd die dezelfde documenten
bevat, maar hiervan een andere voorstelling weergeeft.
De implementatie van de eerder beschreven BurstVSM-tekstvoorstelling volgt nu in de onder-
staande sectie.
5.1.1
BurstVSM
Het BurstVSM-model die de tekstvoorstelling van een corpus omvormt van een statische VSM-
tekstvoorstelling naar de BurstVSM voorstelling,
vertrekt van een uitgebreide corpus (onder
5.1 Tekstvoorstellingen
46
de vorm van een Annotated Corpus-klasse uit sectie 3.3.2) die naast de vectori
¨
ele voorstelling
ook extra meta-data (zoals de timestamp) bevat per document.
De gegenereerde corpus zal
echter enkel bestaan uit een nieuwe vectori
¨
ele voorstelling van de corpus, onder de vorm van een
instantie van de standaard corpus-klasse van de Gensim-module.
De temporele informatie zit
immers al vervat in de features.
Deze nieuwe corpus kan dus opnieuw gebruikt worden om een
ander model op toe te passen.
Verder kan de meta-data uit de oorspronkelijke uitgebreide corpus nog steeds gebruikt worden,
aangezien deze ook apart geserialiseerd werd.
Het model
Het eigenlijke model
bestaat nu ook uit twee delen,
zoals ieder model
uit de Gensim-module.
Het eerste deel is de initialisatie.
In deze stap wordt de nieuwe verzameling van bursty-features
aangemaakt.
Dit gebeurt door voor iedere term, de postingslist te doorlopen en op basis hiervan
de bijhorende set van bursty-features te bepalen.
Het tweede deel is dan de effectieve transformatie, waarbij gestart wordt van de volledige verza-
meling van bursty-features en de uitgebreide corpus.
Nu wordt ieder document doorlopen en
wordt voor iedere term in het document gecontroleerd of er bij de timestamp van dit document
een bursty-feature bij die term hoort.
Indien dit zo is, dan wordt deze toegevoegd aan de bursty-
features van het document.
Als gewicht van de bursty-feature wordt dan de termfrequentie (van de bijhorende term) in het
document gebruikt.
We gebruiken dus niet meteen het TFIDF-gewicht omdat er in Gensim reeds
een TFIDF-model gedefinieerd is, die we dan achteraf toepassen op het corpus bekomen met het
BurstVSM-model.
Dit resulteert dan in het BurstVSM-model beschreven in [Zhao et al., 2012].
Het enige verschil is dat we in dit model wel de statische p
0
-waarde gebruiken zoals voorgesteld
in [Kleinberg, 2003].
Bij [Zhao et al., 2012]
wordt hiervoor enkel
een venster bekeken van 180
dagen rond de desbetreffende dag.
Maar aangezien onze corpus veel kleiner is, 1 jaar in plaats
van 10 jaar bij
[Zhao et al., 2012],
werd hiervan geen gebruikgemaakt.
In ons geval
zou dit
namelijk leiden tot te veel
randeffecten (als we geen cyclische uitbreiding van het corpus ge-
bruiken),
aangezien er dan enkel
voor documenten in het midden van het jaar het volledige
venster van 180 dagen gebruikt zou kunnen worden.
Verder is de impact van deze aanpassing
ook veel kleiner aangezien de effectieve corpus in ons geval maar uit 306 dagen bestaat.
Implementatie van de burstdetectie
De burst-detectie gebeurt dus per term door middel van de methode voorgesteld in [Kleinberg, 2003].
Deze methode heeft twee parameters s en p die constant blijven over de volledige corpus en over
alle termen.
Door dit model
kan het zoeken naar bursts nu vervangen worden door het mini-
5.1 Tekstvoorstellingen
47
maliseren van de volgende kostfunctie:
c(q|x) =
n
X
t=1
τ (i
t−1
, i
t
) +
n
X
t=1
σ(i
t
, x
t
)
(5.1)
met q de gezochte toestandsequentie, x de documentverdeling en τ (i
t−1
, i
t
) en σ(i
t
, x
t
) respec-
tievelijk de transitie- en emissiekosten zoals beschreven in sectie 2.2.3.
Om de optimale toestandsequentie te vinden die de gegeven kostfunctie minimaliseert,
maken
we nu gebruik van het Viterbi-algoritme [Forney, 1973].
Dit is een dynamisch programmeeral-
goritme om de meest waarschijnlijke sequentie van ongekende toestanden te berekenen, gegeven
een opsomming van gekende toestanden,
een typisch vraagstuk bij
HMM’s.
De werking van
het algoritme wordt nu schematisch als opeenvolging van verschillende stappen met bijhorende
vergelijkingen uiteengedaan hieronder.
Merk op dat deze formules al concreet zijn voor het op
te lossen probleem en dat we dus ook gebruik maken van de reeds gedefinieerde kostfuncties.
In het algemeen is het Viterbi-algoritme gedefinieerd als een maximalisatie-probleem,
waarbij
vertrokken wordt van probabiliteiten in plaats van kosten, maar wegens het verband tussen deze
probabiliteiten en de gedefinieerde kostfuncties zoals besproken in sectie 2.2.3 kunnen we het
probleem nu herdefini
¨
eren als een minimalisatie-vraagstuk met kosten.
1.
Initialisatie
δ
1
(j) = [τ (0, j)] + σ(j, x
1
), j ∈ (0, 1)
(5.2)
2.
Recursie
δ
n+1
(j) = min
i∈(0,1)
[δ
n
(i) + τ (i, j)] + σ(j, x
n+1
), j ∈ (0, 1) en n = 1, 2, . . . , N − 1
(5.3)
φ
n+1
(j) = argmin
i∈(0,1)
[δ
n
(i) + τ (i, j)], j ∈ (0, 1) en n = 1, 2, . . . , N − 1
(5.4)
3.
Terminatie
q
N
= argmin
i∈(0,1)
[δ
N
(i)]
(5.5)
4.
Backtracking
q
n
= φ
n+1
(q
n+1
), n = N − 1, N − 2, . . . , 1
(5.6)
Hierbij is δ
i
(n) de totale kost om op dag n in toestand i te zitten.
φ
n+1
(j) bevat de toestand
op dag n die het meest waarschijnlijk is, als de toestand op dag n + 1,
j is.
Na het uitvoeren van de recursiestappen,
is de toestand met de laagste kost voor de laatste
dag N gekend.
Vervolgens kan door het uitvoeren van de backtrackingstappen de optimale
toestandsequentie voor de andere dagen gevonden worden, gebruik makende van φ.
Per term worden de bursty-features dan ge
¨
ıdentificeerd als de aaneensluitende periodes waarin
5.1 Tekstvoorstellingen
48
de gevonden toestand 1 is.
Rekentijd
Dit model kan nu gebruikt worden op zowel het corpus die als termen eigennamen gebruikt, of
op het corpus met als termen de verschillende woorden.
Het grootste deel
van de rekentijd zit in het bepalen van de bursty-features.
De rekentijd
hiervan schaalt lineair met het aantal
dagen en het aantal
termen.
Verder is het mogelijk om
de berekening van de bursts per term volledig in parallel uit te voeren.
Als we alle berekeningen sequentieel
uitvoeren,
dan bekomen we bij
benadering,
de volgende
gemiddelde rekentijden:
• gemiddelde rekentijd op het corpus met 98390 woorden is ±12040s,
• gemiddelde rekentijd op het corpus met 26552 eigennamen is ±2860s.
5.1.2
Boosted BurstVSM
De verschillende aanpassingen aan BurstVSM die voorgesteld worden in sectie 4.1 zijn con-
ceptueel op te splitsen in twee soorten:
1.
Aanpassingen aan de detectie van de bursts, of bursty-features
2.
Aanpassingen aan de gewichten horende bij de bursty-features
Op implementatie-niveau kan er echter nog een bijkomend onderscheid gemaakt worden.
De
verschillende aanpassingen worden namelijk enerzijds
verwezenlijkt
als
aanpassingen in het
BurstVSM-model
en anderzijds als transformaties uitgevoerd door andere modellen voor of
na de transformatie met het BurstVSM-model.
Nu volgt een opsomming van de mogelijke
aanpassingen die ook gecombineerd werden.
• uitmiddeling van de documentfrequenties over de verschillende dagen, detectieaanpassing
• documentfrequenties voorspellen op basis van een lineair model, detectieaanpassing
• boosting van bursty-featuregewicht, gewichtsaanpassing
• geen IDF-herweging op de bursty-features, gewichtsaanpassing
• IDF-herweging op de termen, gewichtsaanpassing
Enkel
de eerste drie aanpassingen zijn nu effectief
aanpassingen in het BurstVSM-model,
het
model met deze aanpassingen wordt BoostedBurstVSM-model genoemd.
5.2 Clusteralgoritmen
49
5.1.3
Combinaties
Verder werd ook de mogelijkheid ge
¨
ımplementeerd om verschillende corpora te combineren tot
´e´en nieuwe corpus.
Dit om zoals in sectie 4.1.4 voorgesteld een corpus te genereren die bursty-
features bevat afkomstig van zowel woord-termen als eigennaam-termen.
Dit werd niet ge
¨
ımplementeerd als een model, maar als een nieuw soort corpus die ge
¨
ınitialiseerd
wordt door de twee corpora mee te geven die gecombineerd moeten worden.
Daarna zal
deze
corpus-klasse dan de nieuwe corpus samenstellen door chronologisch door ieder document te
gaan en telkens de twee vectorvoorstellingen uit de twee andere corpora te combineren.
5.2
Clusteralgoritmen
De clusteralgoritmen die ge
¨
ımplementeerd werden,
zijn allen densiteits-gebaseerde clusteralgo-
ritmen zoals het DBSCAN-algoritme beschreven in sectie 2.2.2.
Alle implementaties hebben
echter de volgende drie grote verschilpunten met het DBSCAN-algoritme:
• Om documenten te vergelijken,
gebruiken we de cosine-similarity tussen de documenten
in plaats van de euclidische afstand zoals bij het DBSCAN-algoritme.
• De documenten worden in onze algoritmen per dag sequentieel doorlopen, wat het mogelijk
maakt om het algoritme online te gebruiken.
• De eis op het minimum aantal
documenten in de Eps-omgeving van een punt/document
valt weg,
er wordt enkel
een ondergrens op de totale grootte van een kandidaatcluster
gebruikt om deze effectief als cluster te initialiseren.
Er werden 3 verschillende clusteralgoritmen ge
¨
ımplementeerd die grafisch weergegeven worden in
figuur 5.1.
Hierop stelt ieder punt in het vlak een similarity-check (het uitrekenen van de cosine-
similarity) tussen 2 documenten voor.
Waarbij verder voor de eenvoud een blok symbolisch een
verzameling is van similarity-checks tussen alle documenten van een bepaalde dag met alle
documenten van een andere dag.
Voor de duidelijkheid zijn de similarity-checks die effectief
worden uitgerekend geel gekleurd.
De similarity-checks worden uitgerekend met behulp van de Similarity-klasse van Gensim, die als
similarity-maat de cosine-similarity gebruikt.
Deze Similarity-klasse initialiseert eerst een index,
dit is een voorstelling van het corpus in een scipy.sparse.csr matrix, die het mogelijk maakt om
veel sneller/effici
¨
enter bewerkingen (similarity-checks) uit te voeren.
Daarna wordt deze nieuwe
voorstelling gebruikt om de effectieve similarity-checks uit te rekenen.
De 3 verschillende algoritmen worden nu besproken, waarbij de opeenvolgende algoritmen telkens
een kortere rekentijd hebben.
5.2 Clusteralgoritmen
50
(a) Recursieve clustering
(b) 1
e
Sequenti
¨
ele clustering
(c) 2
e
Sequenti
¨
ele clustering
Figuur 5.1:
Grafische voorstelling van de uit
te voeren similarity-checks bij
de verschillende cluster-
methodes.
Hierbij
stellen de punten op de horizontale as de documenten voor die worden onderzocht,
chronologisch geordend van links naar rechts.
De punten op de verticale as stellen dezelfde documenten
voor waarmee vergeleken wordt,
chronologisch geordend van boven naar onder.
Ieder punt
in het
vlak
stelt dan een vergelijking tussen twee documenten voor en ieder punt op de diagonaal stelt dus een vergeli-
jking voor tussen twee dezelfde documenten.
Hierbij
is ieder vierkant blokje nu de vergelijking van alle
documenten van een bepaalde dag met alle documenten van een andere dag.
De documenten waarvan de
similarity-check effectief wordt uitgerekend worden geel
gekleurd.
5.2 Clusteralgoritmen
51
5.2.1
Recursief
Het eerste clusteralgoritme is het recursieve clusteralgoritme die bestaat uit twee delen:
• Het zoeken van clusters in korte periodes van twee weken(de grote gele blokken van figuur
5.1a).
• Het recursief
combineren/mergen van de clusters gevonden in de verschillende kortere
periodes.
Clusterdetectie
Zoals weergegeven in figuur 5.1a worden voor iedere periode van twee weken alle documenten
met elkaar vergeleken.
Hierbij stellen de grote gele blokken dus symbolisch perioden van twee
weken voor.
Door gebruik te maken van de Gensim Similarity-klasse kan deze operatie geparal-
lelliseerd worden.
Vervolgens wordt een verzameling van kandidaatclusters opgesteld door alle documenten in deze
periode chronologisch te overlopen en de Eps-omgeving per document op te stellen
1
.
Als de
Eps-omgeving van het document niet leeg is,
dan wordt gecontroleerd of
de documenten in
deze Eps-omgeving reeds voorkomen in ´e´en of meerdere van de kandidaatclusters.
Als dit zo is,
dan worden deze clusters uit de set van kandidaatclusters gehaald.
Deze kandi-
daatclusters worden vervolgens gecombineerd met de Eps-omgeving van dit document tot een
nieuwe kandidaatcluster die wordt toegevoegd aan de kandidaatclusterset.
Als het document niet voorkomt in ´e´en van de kandidaatclusters,
dan wordt de Eps-omgeving
(samen met het document) als nieuwe cluster toegevoegd aan de kandidaatclusterset.
Na het uitvoeren van deze stappen voor alle documenten,
worden nu enkel
de clusters overge-
houden die minstens MinPts documenten bevatten.
Van deze clusters worden nu samenvattingen gegenereerd die gebruikt zullen worden om in de
tweede stap de verschillende clusters te mergen.
Deze samenvattingen bevatten enerzijds al-
gemene informatie zoals het aantal
documenten,
het aantal
dagen en het document met het
grootste aantal documenten in de Eps-omgeving.
Anderzijds bevat het ook de essenti
¨
ele informatie om de verschillende clusters te kunnen verge-
lijken.
Dit is de gemiddelde documentvoorstelling die bekomen wordt door de featuregewichten
over de verschillende documenten uit te middelen en enkel
deze features over te houden die in
minstens de helft van de documenten voorkomen.
1
In tegenstelling tot de Eps-omgeving van het DBSCAN algoritme,
gedefinieerd op pagina 12,
bevat deze
Eps-omgeving enkel documenten die voorkomen in dezelfde blok van 2 weken.
5.2 Clusteralgoritmen
52
Clustermerging
Het resultaat van de clusterdetectie is een lijst die per periode van 2 weken een verzameling van
clusters bevat (een clusterset).
Deze clusters worden gekarakteriseerd door de verzameling van
documenten die het bevat en de gegenereerde samenvatting van de cluster.
De clustermerging-stap vertrekt nu van deze grote lijst, en wordt ge
¨
ımplementeerd door recursief
een merging-functie op te roepen die als input een lijst van clustersets bevat.
Als deze lijst twee
clustersets bevat, dan worden deze twee clustersets gemerged zoals hieronder beschreven staat.
Als deze lijst meer dan twee clustersets bevat,
dan zal
deze eerst tweemaal
de merging-functie
oproepen op de lijsten gegenereerd door de lijst van clustersets op te splitsen in twee delen van
gelijke grootte.
Op deze manier worden enkel
clustersets gemerged die in de meeste gevallen hetzelfde aantal
dagen omvatten.
Het mergen van twee clustersets gebeurt nu door sequentieel
alle clusters uit deze twee sets te
doorlopen en deze op gepaste wijze toe te voegen aan de gemergede lijst van clusters.
Het toevoegen van een cluster aan de nieuwe lijst, gebeurt door de cosine-similarity tussen deze
cluster met iedere cluster in de lijst van gemergede clusters te berekenen.
Hierbij
wordt de
cosine-similarity berekend door de gemiddelde documentvoorstellingen van beide clusters te ver-
gelijken.
Als er geen cluster in de nieuwe set is waarvoor de cosine-similarity een zekere constante
treshold MinClusterSim overschrijdt, dan wordt deze cluster als nieuwe cluster toegevoegd aan
de lijst van gemergede clusters.
Als er wel minstens ´e´en cluster is waarvoor deze treshold overschreden wordt, dan worden deze
clusters uit de nieuwe lijst verwijderd en wordt de nieuwe cluster gemerged met deze verwijderde
clusters.
Deze gemergede cluster wordt dan toegevoegd aan de nieuwe lijst.
Tijdens het mer-
gen van de clusters worden de verschillende elementen van de samenvatting ook gemerged of
ge
¨
update.
Op deze manier worden er dus zowel kleine clusters behouden als clusters bestaande uit meerdere
kleine clusters die gemerged werden.
Er werd geopteerd om de merging recursief
aan te pakken zodat er telkens clusters worden
vergeleken die ongeveer dezelfde tijdspanne omvatten (2 weken,
4 weken,
8 weken etc.
).
Op
deze manier wordt verhinderd dat clusters niet gemerged worden omdat ze een verschillende
tijdspanne omvatten en waardoor de ene cluster bijgevolg veel algemener is dan de andere.
De rekentijd van dit algoritme over een corpus van 427003 artikels is ±29380s.
Deze rekentijd
werd bekomen bij het gebruik van een corpus met 7975 bursty-features.
5.2 Clusteralgoritmen
53
5.2.2
Sequentieel
De tweede soort clusteralgoritmen,
de sequenti
¨
ele clusteralgoritmen,
bestaan nu enkel
uit een
clusterdetectiedeel.
Er is geen merging meer nodig doordat de clusterdetectie niet gebeurt op
afzonderlijke sets van documenten, maar op een steeds overlappende set van documenten zoals
weergegeven op figuur 5.1.
Hierdoor kunnen de clusters sequentieel groeien en stijgt of daalt het
aantal
clusters tijdens het doorlopen van de verschillende documenten.
Het grootste voordeel
van deze methodes is echter dat er veel minder documenten vergeleken moeten worden.
Sequentieel1
De eerste sequenti
¨
ele methode die grafisch wordt weergegeven in figuur 5.1b start met het op-
splitsen van het corpus in verschillende kleinere overlappende minicorpora die alle documenten
van twee opeenvolgende dagen bevatten.
Op deze manier komt ieder document dus voor in exact
twee minicorpora,
waardoor ieder document dus vergeleken kan worden met alle documenten
die ofwel de dag voordien, de dag zelf of de dag nadien werden gepubliceerd.
Nu worden al
deze minicorpora ´e´en voor ´e´en doorlopen en worden de volgende taken uitge-
voerd:
• De gelijkheid tussen alle documenten in de minicorpus worden berekend met behulp van
de Gensim Similarity-klasse.
• Daarna worden de documenten ´e´en voor ´e´en doorlopen en wordt voor ieder document
de verzameling documenten gezocht die eerder in deze minicorpus voorkomen (dit komt
dus overeen met de similarity-checks die boven de diagonaal liggen op figuur 5.1b) en een
cosine-similarity met het document hebben die groter is dan MinClusterSim.
Dit is dus
een aangepaste (kleinere) Eps-omgeving van dit document.
Er wordt nu gecontroleerd of de documenten uit de Eps-omgeving van dit document reeds
tot een cluster behoren.
Hiervoor zijn er per document B uit de Eps-omgeving drie mo-
gelijkheden:
– B behoort tot een cluster die reeds ge
¨
ınitialiseerd werd met documenten die chronol-
ogisch voor de documenten uit deze minicorpus voorkomen.
De clusterset waartoe
deze cluster behoort, wordt de FinalClusterset genoemd.
Het onderzochte document
A wordt dan aan deze cluster van de FinalClusterset toegevoegd.
– B behoort tot een cluster die ge
¨
ınitialiseerd werd met documenten uit deze mini-
corpus.
De clusterset waartoe deze cluster behoort,
wordt de KandidaatClusterset
genoemd.
Het document A wordt ook in dit geval
toegevoegd aan de cluster van
document B.
– Als het document B tot geen enkele cluster behoort,
dan wordt een nieuwe clus-
ter ge
¨
ınitialiseerd bestaande uit documenten A en B,
deze cluster wordt uiteraard
5.2 Clusteralgoritmen
54
toegevoegd aan de KandidaatClusterset.
Vervolgens worden alle clusters die het document A bevatten,
gemerged tot ´e´en nieuwe
cluster.
Als er minstens ´e´en cluster tot de FinalClusterset
behoort, dan wordt de nieuwe
gemergede cluster aan deze FinalClusterset toegevoegd.
Anders wordt ze toegevoegd aan
de KandidaatClusterset.
De clusters die gemerged werden, worden uiteraard verwijderd.
• Nadat het uitvoeren van bovenstaande stap voor alle documenten uit de minicorpus, wor-
den de clusters in de KandidaatClusterset doorlopen.
Als de cluster minstens MinCluster-
Size documenten bevat, dan wordt deze toegevoegd aan de FinalClusterset, anders wordt
ze verwijderd.
Deze stappen worden dus sequentieel uitgevoerd voor alle overlappende minicorpora bestaande
uit alle documenten van twee opeenvolgende dagen.
Om deze clustering te kunnen laten werken
zonder een bijkomende clustermerging stap,
wordt dezelfde FinalClusterset
nu gebruikt voor
de verschillende minicorpora terwijl
de KandidaatClusterset
vernieuwd wordt per minicorpus.
Om de implementatie van dit algoritme te optimaliseren,
maken we gebruik van verschillende
datastructuren in Python zoals dictionaries en sets,
naast de lijsten om een zo snel
mogelijke
implementatie te bekomen.
Het nadeel
hiervan is dat de code minder elegant is.
De effectieve
implementatie van de taken die uitgevoerd worden per minicorpus is terug te vinden in bijlage
A.1.
Merk op dat er bij dit clusteralgoritme dus verondersteld wordt dat de clusters bestaan uit een
verzameling documenten die voorkomen in een aaneensluitende reeks van dagen.
Maar intu
¨
ıtief
lijkt deze eis geen probleem te zijn.
Over events die belangrijk zijn zal er immers gedurende een
zekere periode een minimum aantal artikels in de pers verschijnen.
De gemiddelde rekentijd van dit algoritme over een corpus van 7975 bursty-features is ±12050s.
Sequentieel2
De tweede sequenti
¨
ele methode,
weergegeven in figuur 5.1c,
werkt analoog als de eerste se-
quenti
¨
ele methode.
Om het aantal
te vergelijken documenten echter nog verder naar beneden
te halen, bevatten de minicorpora nu enkel de documenten van 1 dag.
Toch zullen alle documenten van een bepaalde dag ook vergeleken worden met de documenten
van de dag voordien.
Dit zal bereikt worden door ieder document niet enkel te vergelijken met
de andere documenten uit de bijhorende minicorpus, maar ook met de documenten uit de mini-
corpus die de documenten van de dag voordien bevat.
Het verschil
van deze methode met de voorgaande is dat de documenten van dezelfde dag nu
nog maar 1 keer met elkaar vergeleken worden.
In de eerste sequenti
¨
ele methode gebeurde
dit namelijk twee keer.
De gemiddelde rekentijd van dit algoritme over een corpus van 7975
bursty-features is ±11140s.
5.2 Clusteralgoritmen
55
5.2.3
Hi
¨
erarchisch clusteralgoritme
De laatste soort ge
¨
ımplementeerde clustering wordt gebruikt om een hi
¨
erarchie te construeren.
Hierbij wordt ook vertrokken van een verzameling van clusters en deze worden net zoals in het
clustermerging-algoritme van de recursieve clustermethode gemerged tot grotere clusters.
Het
enige verschil
is nu dat enkel
de clusters worden overgehouden die bestaan uit een combinatie
van meerdere kleinere clusters.
Deze gevonden verzameling van grotere clusters kan nu telkens
onderworpen worden aan dezelfde hi
¨
erarchische clustermethode,
waarbij
telkens een kleinere
clustersimilarity gebruikt moet worden.
Op deze manier is het mogelijk om een hi
¨
erarchische
voorstelling van de documenten te maken.
5.2.4
Serialiseren van de clusters
De clusters gevonden met de verschillende algoritmen zijn de set van verzamelingen documenten
die telkens een event voorstellen.
Om deze events te kunnen analyseren en te kunnen weergeven
aan de gebruiker worden deze clusters nu onder verschillende formaten geserialiseerd die telkens
gebruikt kunnen worden door ´e´en van de volgende test- of visualisatiemethodes.
Concreet worden deze onder de volgende drie formaten opgeslagen:
Identifier-lists
Deze methode zal per gevonden cluster twee files aanmaken:
.info-file:
bevat alle algemene info gevonden met het clusteralgoritme:
• het aantal documenten,
• de verzameling van dagen,
• de naam van het event, gevonden met het naamgevingsalgoritme beschreven in sectie
5.3.1,
• de verzameling van termen horende bij de gemiddelde documentvoorstelling
2
van de
cluster,
• de identifier (uniek nummer) van het document die de grootste Eps-omgeving heeft
en dus wellicht het meest representatief is om het event te beschrijven.
.identifiers-file:
deze bevat de verzameling van identifiers van alle documenten in de cluster.
De .identifiers-files worden gebruikt bij de evaluatiemethodes beschreven in hoofdstuk 6.
2
Deze gemiddelde documentvoorstelling wordt gegenereerd zoals beschreven op pagina 51
5.3 Visualisaties
56
Tag-files
De tag-files zijn de input voor de artikelbrowser beschreven in sectie 5.3.3, en bevat per document
een lijst van tags.
Deze tag is in ons geval
de naam van het event waar het document toe
behoort.
XML-file
Dit is de input voor het genereren van de Timeline beschreven in sectie 5.3.2.
Deze bevat per
cluster:
• de naam van de cluster
• de tijdspanne van de cluster
• het aantal documenten in de cluster
5.3
Visualisaties
Eenmaal de events gedetecteerd zijn, is het natuurlijk nog belangrijk om deze aan een gebruiker
te kunnen weergeven.
Hiervoor zijn er nog twee stappen noodzakelijk.
De eerste is het zoeken
van een geschikte naam om een event herkenbaar/onderscheidend te beschrijven en de tweede
is het effectief visueel
weergeven van de events.
Hiervoor zijn er twee mogelijkheden voorzien,
enerzijds is er een timeline die het mogelijk maakt om visueel de opeenvolging van de events te
zien als een soort samenvatting van een tijdsperiode en de tweede is het gebruik van deze events
als tag bij een artikelbrowser, zodat snel gerelateerde artikels gevonden kunnen worden.
De verschillende stappen worden hieronder beschreven.
5.3.1
Naamgeving events
Bij het zoeken van een naam voor een bepaald event stellen we de volgende eisen:
1.
De naam van het event is liefst een stuk natuurlijke tekst,
dus geen cryptische rij
van
woorden.
2.
De naam is zo kort als mogelijk, maar bevat wel alle woorden noodzakelijk om het event
uniek te defini
¨
eren.
Om aan deze eisen te voldoen, moeten we dus een stuk natuurlijke tekst genereren of zoeken die
aan de tweede eis voldoet.
Als we verschillende artikels bekijken, dan blijkt snel dat de meeste titels van artikels een goede
beschrijving van de inhoud van het artikel kunnen geven.
Aangezien een event nu gedefinieerd
is als een verzameling artikels, kunnen we dus zoeken in de verzameling van artikeltitels van het
5.3 Visualisaties
57
event naar de titel die het event het beste omschrijft.
Dit doen we als volgt:
• Zoek de lijst van meest belangrijke (beschrijvende) bursty-features van het event.
• Zoek voor iedere bursty-feature uit de lijst de corresponderende term met behulp van
de modellen gebruikt voor de transformaties en gebruik nu deze termen als voorstelling
tekstuele representatie van de bursty-features.
• Interpreteer de lijst met meest belangrijke bursty-features samen met hun gewichten als
een vector.
• Zoek de titel
waarvan als deze beschreven wordt in het binaire VSM-formaat,
de cosine-
similarity met de bovenstaande vector maximaal
is.
Op deze manier wordt de kortst
mogelijke titel gevonden die het maximaal aantal beschrijvende termen bevat.
Om de lijst van meest beschrijvende bursty-features van een event te zoeken,
kunnen we bij
de recursieve clustering gebruik maken van de gemiddelde documentvoorstelling van de cluster.
Hiervan gebruiken we nu enkel de 10 bursty-features met het grootste gemiddelde gewicht.
Deze
worden dan samen met hun respectievelijk gewicht gebruikt voor de vectorvoorstelling.
Bij de
sequenti
¨
ele clustering is er geen gemiddelde documentvoorstelling aanwezig,
maar deze wordt
nu op een analoge manier gegenereerd,
waarbij dan ook enkel
de 10 features met het grootste
gewicht gebruikt worden.
5.3.2
Timeline
Om nu de verschillende events weer te geven,
kan dit uiteraard gebeuren door deze als een
(geordende) lijst weer te geven.
Het nadeel
van deze aanpak is dat er op die manier geen
tijdsinformatie te zien is.
Het zou beter zijn om een soort timeline te genereren,
waarbij
de
verschillende events geordend staan in de tijd en waarbij ook hun tijdsduur zichtbaar zou zijn.
Om
dit
te
construeren,
hebben
we
gebruik
gemaakt
van
de
Simile
Timeline
Visualisation [MIT Libraries, 2013].
Een printscreen van een deel van een gecre
¨
eerde timeline is
terug te vinden op figuur 5.2.
Zoals duidelijk op de figuur zichtbaar is, bestaat deze timeline uit
3 banden.
De eerste is de band met alle event-namen erin, samen met een aanduiding van hun
tijdsduur (de blauwe lijn boven de event-titel).
Als er op een event wordt geklikt,
dan wordt
dit event weergegeven in de artikelbrowser die beschreven wordt in onderstaande sectie 5.3.3.
Verder is er ook nog een band die het begin van iedere week weergeeft en een band die de maand
van het jaar weergeeft.
Op iedere band kan er gescrold worden om door de timeline te navigeren
en alle banden zijn met elkaar gesynchroniseerd.
Om de timeline te kunnen teruggeven werd nu een webpagina gemaakt die een xml-file met
de lijst van events en hun tijdsduur doorstuurt naar de Simile Timeline’s Javascript API,
die
hiermee dan de timeline genereert.
Verder is het ook mogelijk om te filteren op de grootte of de tijdsduur van de events.
Als de
5.3 Visualisaties
58
filterselectie wordt aangepast,
dan wordt de xml-file geupdate,
en wordt de timeline opnieuw
gegenereerd.
Figuur 5.2:
Illustratie van de Timeline met de events.
5.3.3
Artikelbrowser
Om de Mediargus-artikels te bekijken en te doorzoeken,
was er reeds een artikelbrowser (zie
figuur 5.3) beschikbaar gemaakt door de onderzoeksgroep.
Hiermee was er ook de mogelijkheid
om verschillende soorten tags toe te kennen aan artikels.
Hiervan werd gebruikgemaakt om nieuwe soorten tags toe te voegen.
De eerste is de “event”-tag
die wordt toegekend per event, aan alle documenten die in het event voorkomen.
De tweede is de
“big-event”-tag die nu toegekend wordt aan alle documenten die behoren tot een groter event,
verkregen met de hi
¨
erarichsche clustering.
Op deze manier kan er dus gemakkelijker tijdens
het lezen van een artikel,
andere artikels over hetzelfde event teruggevonden worden.
Door op
de tags te klikken,
bekomt men namelijk de verzameling van artikels die deze tag bevatten.
Verder is het ook mogelijk om documenten te zoeken door een query in te voeren in het query-
venster bovenaan.
De tags zichtbaar links, zijn dan alle tags die in de verzameling documenten
voorkomen.
5.4 Samenvatting
59
Figuur 5.3:
Screenshot van de artikelbrowser.
Op de rechterzijde is nu een aantal tags zichtbaar, waaron-
der de ”event”-tag.
Deze toont de verschillende events die aanwezig zijn in de selectie van artikels.
5.4
Samenvatting
De volledige implementatie van het eventdetectie systeem kan dus worden gezien als een pijplijn
van verschillende corpus-transformaties zoals schematisch weergegeven wordt in figuur 5.4.
Er
wordt vertrokken van de data uit het Mediargus-archief onder de vorm van XML-files, waaruit
ook eigennaam-data en woord-data ge
¨
extraheerd werd die respectievelijk terug te vinden is in
de .ner- en .sequence-files.
Van deze voorstellingen kunnen er dan verschillende corpora en bijhorende dictionaries ge
¨
ınitialiseerd
worden.
Deze kunnen dan gebruik makende van de verschillende modellen getransformeerd of
gecombineerd worden zoals weergegeven op figuur 5.4.
Op basis van de uiteindelijke corpora
kunnen de clusteralgoritmen dan events detecteren die dan opgeslagen worden onder drie ver-
schillende serialisatie-formaten.
5.4 Samenvatting
60
Figuur 5.4:
Schematische voorstelling van de verschillende corpus-transformaties noodzakelijk voor de
eventdetectie, waarbij in dit voorbeeld een corpus gegenereerd wordt die bestaat uit de combinatie van de
bursty-features van zowel
woorden als eigennamen.
Verder wordt er in dit voorbeeld ook gewerkt met de
BurstVSM-voorstelling van [Zhao et al., 2012], waarbij de IDF-herweging gebeurt op de bursty-features
EVALUATIEMETHODOLOGIE
61
Hoofdstuk 6
Evaluatiemethodologie
Om de performantie van de verschillende onderdelen te evalueren, moeten deze aan testen onder-
worpen worden.
Aangezien het doel van de verschillende onderdelen is om events te detecteren,
is er natuurlijk een noodzaak aan een testset die als referentie gebruikt kan worden.
Op basis
hiervan kunnen we dan de kwaliteit van de gevonden events vergelijken.
Het probleem is echter
dat het onmogelijk is om alle correcte events met de hand terug te vinden en om alle hierbij-
horende documenten uit het corpus te vinden.
Daarom kunnen we dus slechts met een subset
werken.
De constructie van deze subset wordt nu in de volgende sectie besproken en daarna
worden de verschillende evaluatiemethoden toegelicht.
6.1
Testset
6.1.1
De gebeurtenissen/events
Aangezien het corpus enkel
artikels bevat uit het jaar 2011 is er vertrokken van de lijst van
gebeurtenissen van dit jaar gevonden via wikipedia
1
.
Voor al
deze 60-tal
gebeurtenissen zijn
dan de corresponderende documenten uit het corpus opgezocht met behulp van queries,
die
ook tijdsrestricties bevatten.
Op deze manier is er dan een beschrijving van events door een
verzameling documenten.
Er bleek echter al snel dat sommige events veel groter en/of belangrijker waren dan andere events.
Ook waren er events waarvan er te weinig (< 10) of zelfs geen documenten terug te vinden waren
in het corpus.
Daarom zijn dan enkel
de meest belangrijke events (30-tal) beschouwd.
13 van
deze events zijn dan handmatig verfijnd zo om enkel nog de niet-dubbelzinnige documenten over
te houden en soms enkele nieuwe documenten toe te voegen.
1
http://nl.wikipedia.org/wiki/2011
6.2 Evaluatiemethodes
62
6.1.2
Afwegingen
Het probleem met event-detectie is dat er geen concrete mathematische definitie is van wat een
event is [Pan & Mitra, 2011].
Hierdoor is het ook moeilijk om objectieve conclusies te trekken.
Iedere persoon zal een eigen notie hebben van wat een event precies is, en op welke granulariteit
een event gedefinieerd moet worden (interrater-betrouwbaarheid).
Een verdere discussie is terug
te vinden in sectie 6.2.3.
Verder is het zo dat er ook voor de documenten een ambigu
¨
ıteit is om de relatie tot een bepaald
event uit te drukken.
Zo kan een document bijvoorbeeld referenties naar meerdere events bevat-
ten,
of kan een document slechts gedeeltelijk gaan over ´e´en bepaald event,
waardoor het voor
de manuele annotator niet eenduidig is om een binaire beslissing te nemen.
Om toch zo correct mogelijk te werken,
is dus gewerkt met een verzameling van 13 events die
manueel verfijnd werden.
Dit wil zeggen dat de documenten horende bij een event dus allemaal
met de hand werden geannoteerd.
Hierbij werd de verzameling van documenten voor ´e´en event
zo gekozen dat ze slechts in ´e´en bepaalde tijdspanne voorkomen en dat enkel de documenten die
een rechtstreekse relatie hebben met het event werden overgehouden.
Documenten waarvan de
relatie niet eenduidig was (zoals bv.
een column of een lezersrubriek waar onder andere gespro-
ken wordt over het event,
worden dan geannoteerd als ’ambigu’
en deze documenten worden
dan ook genegeerd bij de evaluatie.
De annotatie gebeurde door van ieder document de titel te
bekijken, op basis van deze titel werd dan een beslissing genomen.
Als er op basis van de titel
geen beslissing kon genomen worden, dan werd ook het artikel gelezen.
6.2
Evaluatiemethodes
De kwaliteit van de verschillende methodes kan op verschillende manieren getest worden.
Verder
moeten we enerzijds tekstvoorstellingen testen en anderzijds de clustermethodes.
In deze sectie worden de verschillende gebruikte evaluatiemethodes voorgesteld en besproken.
Alle voorgestelde methodes kunnen gebruikt worden om de verschillende tekstvoorstellingen
te vergelijken.
De kwaliteit van de clustermethodes kan echter enkel
met de laatste methode
gecontroleerd worden.
Deze laatste is ook de belangrijkste maat om de effectieve kwaliteit van de
tekstvoorstelling te analyseren.
Al moet hier wel worden opgemerkt dat de resultaten natuurlijk
ook sterk afhankelijk zijn van het gebruikte clusteralgoritme en de bijhorende parameters.
Zo
kunnen de parameters van het clusteralgoritme telkens opnieuw geoptimaliseerd worden per
tekstvoorstelling,
wat het dus moeilijker maakt om de tekstvoorstellingen volledig objectief te
vergelijken.
6.2 Evaluatiemethodes
63
6.2.1
Kwalitatieve analyse gevonden bursts
Al
de gebruikte tekstvoorstellingen gebruiken bursty-features die gedefinieerd worden op basis
van de verschillende bursts die gevonden werden door het burstdetectie-algoritme.
Door deze
gevonden bursts te analyseren kunnen we al heel wat conclusies trekken.
Deze analyse bestaat
uit het visueel
vergelijken van de automatisch gevonden bursts bij
enkele termen met wat we
intu
¨
ıtief als burst zouden defini
¨
eren op basis van de documentfrequenties.
Voorbeelden hiervan
zijn terug te vinden op figuren 4.3 en 4.4.
Hierbij kunnen we ook de exacte gewichten van de
gevonden bursts weergeven zoals op figuur 4.4 om op deze manier de verschillende gewichtsfunc-
ties te vergelijken.
Men zou kunnen voorstellen om dit ook op een kwantitatieve manier aan te pakken door hand-
matig de verschillende correcte bursts van een set termen te bepalen.
Het probleem hiermee
is echter dat de concrete aflijning van een burst nogal
subjectief is,
ook is het exacte gewicht
horende bij een burst niet zo eenduidig te bepalen.
Deze methode is dus niet zo geschikt om op een nauwkeurig niveau de optimale parameters
te bepalen,
maar ze is wel
uiterst geschikt om inzichten te verwerven in de invloeden van de
verschillende parameters.
Verder kunnen we ook de volgende eigenschappen gebruiken die een
goed burstdetectie-algoritme karakteriseert:
• De burst-detectie werkt goed als er duidelijk gezien wordt dat het algoritme kan omgaan
met de grote variaties van de documentfrequenties,
d.w.z.
dat korte pieken (van ´e´en dag
bv. )
niet als burst ge
¨
ınitialiseerd worden en bursts met een korte dip nog steeds als ´e´en
burst gezien worden.
• De duur van de gevonden bursten is beter te lang dan te kort.
Deze laatste eigenschap kan nu worden aangetoond door de effectieve functie van de bursts bin-
nen de BurstVSM en de Boosted BurstVSM voorstelling te analyseren.
De bursts
worden namelijk gebruikt
om de temporele betekenis van termen in de features
te incorporeren,
door de termen te splitsen in verschillende bursty-features.
Zo kan de term
“verkiezingen” namelijk slaan op de gemeenteraadsverkiezingen,
de regionale verkiezingen enz.
waarbij
de concrete betekenis van de term afhankelijk is van het moment waarop de term
voorkomt.
Door gebruik te maken van bursty-features zullen de verschillende betekenissen van
de term “verkiezingen” nu gesplitst worden over de verschillende bursty-features.
Op momenten waarbij
de term niet in een burst zit,
hoort er bij
deze term dus geen enkele
bursty-feature, waardoor deze term in de voorstelling van het document genegeerd zal worden.
Als de bursts van een bepaalde term nu iets langer zijn dan er op basis van visuele inspectie van
de documentfrequenties verwacht wordt,
dan zullen er meer documenten zijn waarvoor er met
deze term ook effectief een bursty-feature correspondeert.
Aangezien deze documenten echter
deze term bevatten, is het toevoegen van de bursty-feature aan de documentvoorstelling niet zo
nadelig.
Het document bevat immers een term die onlangs veel meer in de verschillende artikels
voorkwam.
Hierdoor is de kans groot dat deze term en dit document ook effectief van belang
6.2 Evaluatiemethodes
64
zijn en de corresponderende feature dus geen ruis-feature is.
Verder worden documenten ook
pas geclusterd als er verschillende features gemeenschappelijk voorkomen.
Als de bursts van een bepaalde term nu in tegenstelling korter zijn dan wat er op basis van
de visuele inspectie verwacht wordt,
dan zullen er documenten zijn waarvoor de aanwezigheid
van deze term foutief genegeerd wordt.
Gedurende een periode waarin deze term veel meer dan
gemiddeld voorkomt en dus hoogstwaarschijnlijk relevant is, zal de term immers niet als bursty
beschouwd worden,
waardoor documenten die geclusterd zouden moeten worden op basis van
de aanwezigheid van deze bursty-feature nu niet geclusterd zullen worden.
Verder is het ook zeer ongewenst als een visuele burst van de documentfrequenties,
gesplitst
wordt in twee bursts.
Dit zorgt er namelijk voor dat er dus twee verschillende bursty-features
gedefinieerd worden.
Documenten die voorkomen gedurende de periode van de eerste burst
zullen dan een andere bursty-feature voor deze term hebben, dan documenten die gedurende de
periode van de tweede burst voorkomen,
waardoor deze op basis van deze bursty-features dus
niet geclusterd zullen worden.
6.2.2
Inter- en intra-similarities
Aangezien de clusteringsmethodes gebruik maken van de similarities tussen de verschillende
documenten.
Is het van groot belang om deze similarities beter te analyseren.
Hoe groter de
similarity tussen twee documenten die bij hetzelfde event horen en hoe kleiner de similarity met
andere documenten, hoe beter het clusteralgoritme documenten zal clusteren.
Wat dus leidt tot
een betere eventdetectie.
Om deze waarden nu expliciet te analyseren,
worden de similarities tussen documenten uit de
referentieset berekend, en dit voor de verschillende tekstvoorstellingen.
Concreet worden de volgende stappen uitgevoerd per event uit de referentieset:
1.
Bekijk voor alle documenten die tot het event behoren alle similarities tussen alle paren van
documenten,
dus als er N documenten horen bij dit event,
worden er
N(N−1)
2
similarities
berekend.
Hiervan wordt dan de gemiddelde similarity en de standaardafwijking berekend.
2.
Vervolgens wordt er voor ieder document die tot het event behoort, de similarity berekend
met alle documenten die in de tijdspanne van het event behoren maar niet tot het event zelf.
Dus als er N documenten tot het event behoren en M documenten in dezelfde tijdspanne
voorkomen, maar niet tot het event zelf behoren, dan komt dit neer op N · M similarities.
Hiervan wordt nu weer het gemiddelde en de standaardafwijking berekend.
3.
Tenslotte wordt de verhouding van de inter-
op de intra-similarity per event berekend.
Deze verhouding geeft dus weer hoe onderscheidend de documenten van het event zijn
t.o.v.
de andere documenten in dezelfde tijdspanne.
Nu worden deze waarden uitgemiddeld over de verschillende events om een algemeen beeld te
kunnen vormen.
Ook de standaardafwijking op deze waarden over de events wordt uitgerekend
6.2 Evaluatiemethodes
65
zodat we kunnen analyseren hoe robuust de voorstelling is over de verschillende (soorten) events.
Merk op dat we bij deze evaluatiemethode dus gebruik maken van de gemiddelde similarity over
alle documenten in de cluster, terwijl de clusters gegenereerd worden op basis van de maximale
similarity tussen een document en zijn dichtste buur.
Het zou dan intu
¨
ıtief logischer lijken om
deze maximum similarity te gebruiken als maat aangezien deze ook rechtstreeks gebruikt wordt.
Het probleem hiermee is dat de documenten op deze manier niet tot ´e´en cluster moeten behoren.
Zo zal een verzameling van documenten die bestaat uit telkens twee gelijkaardige documenten,
maar waarvan de totale verzameling documenten geen cluster vormen, ook een heel hoge simi-
larity hebben volgens deze gelijkheidsmaat.
Anderzijds toont de gebruikte gemiddelde similarity
van een cluster wel aan hoe goed dat de documenten volgens deze representatie op elkaar lijken,
wat dus wel interessant is.
Anderzijds wordt tijdens deze evaluatie de intrasimilarity beschouwd en meer specifiek de ver-
houding van de inter- op de intra-similarity,
terwijl
deze in de clustermethodes niet expliciet
gebruikt worden.
Er zou dus ook kunnen voorgesteld worden om deze verhouding effectief te
gebruiken tijdens het clusteren aangezien ze duidelijk een maat is die het onderscheid tussen een
cluster en de andere (ruis-)documenten samenvat.
Moesten we deze maat echter gebruiken om
clusters te vormen of te evalueren, dan zou deze te veel voordeel bieden aan kleine clusters die
heel goed op elkaar lijken.
Grote clusters bevatten namelijk een veel uitgebreidere set features en
verschillende soorten documenten, waardoor het onderscheidend vermogen kleiner zou worden.
Hierdoor is de maat minder geschikt is om grote events te detecteren, wel is ze natuurlijk ideaal
om de corpusvoorstellingen te vergelijken.
6.2.3
Doeltreffendheid gevonden events
Om dan de effectieve event-detectie te testen,
die dus gebruik maakt van zowel
de cluster-
methode als de tekstvoorstelling,
werden de automatisch gevonden events vergeleken met de
zelf-geannoteerde events.
Hierbij zijn de volgende maatstaven van belang:
• Hoe meer events er gevonden zijn die goed overeenkomen met de zelf-geannoteerde events,
hoe beter.
• Hoe minder valse (insignificante) events, hoe beter.
Het probleem is nu echter dat het onmogelijk is om de significantie van alle gevonden events te
controleren.
Maar aangezien de meest significante (en de meest gewenste) events deze zijn die
zelf geannoteerd zijn.
Kunnen we dus stellen dat hoe minder andere events er gevonden worden,
hoe beter de gemiddelde significantie van de gevonden events zal zijn.
Hierdoor kunnen we de
tweede maatstaf vervangen door:
”Hoe minder gevonden events, hoe beter”.
Om de eerste maatstaaf uit te drukken, zoeken we per zelf-geannoteerd event, het automatisch
gevonden event met de grootste cosine similarity, waarbij de document-ids van de events dienst
doen als features van het event.
Hierbij beschouwen we in het automatisch gevonden event verder
enkel de documenten waarvan de timestamp binnen de tijdsduur van het zelf-geannoteerde event
6.2 Evaluatiemethodes
66
valt.
Dit omdat tijdens het testen bleek dat niet alle relevante documenten horende bij
een
bepaalde gebeurtenis correct met de hand werden geannoteerd (teruggevonden), wat dus zorgt
voor een onderschatting van de precision.
´
E´en van de verklaringen hiervoor is dat we tijdens
de manuele annotatering enkel documenten binnen een te korte periode onderzochten, waardoor
relevante documenten buiten deze periode dus verkeerdelijk als niet-relevant werden beschouwd.
Het negeren van de documenten die buiten deze periode vallen,
zorgt dus voor een correctere
precision.
Zonder een impact te hebben op de berekende recall.
Daarna berekenen we voor ieder zelf-geannoteerde event de volgende metrieken (met betrekking
tot het automatisch gevonden event):
• cosine similarity
• precision
• recall
• F
1
-measure
• grootte van het automatisch gegenereerd event (aantal documenten)
• duur van het automatisch gegenereerd event (aantal dagen)
De globale resultaten van een bepaald algoritme worden dan bekomen door bovenstaande me-
trieken uit te middelen over alle events.
Dit wordt voor de precision, recall en F
1
-measure ook de
macro-uitmiddeling genoemd.
Op deze manier is de invloed van ieder event op het uiteindelijke
globale resultaat gelijk.
De andere mogelijke uitmiddeling (micro-uitmiddeling),
berekent de
globale resultaten door de totale set van documenten te beschouwen en op basis hiervan de pre-
cision, recall en F
1
-measure te bepalen.
Deze methode wordt echter niet gebruikt omdat events
met veel documenten hierdoor een groter gewicht krijgen.
Wel gebruiken we een globale hybride F
1
-measure.
Deze wordt uitgerekend door de F
1
-measure
te berekenen op basis van de macro-gemiddelden van de precision en recall.
In het vervolg zullen
we enkel deze hybride F
1
-measure gebruiken in plaats van de macro F
1
-measure.
Kadering van de bekomen precision en recall
Het is van belang om de cijfers voor de precision en recall
in context te plaatsen.
De zelf-
geannoteerde artikels zijn immers het resultaat van subjectieve beslissingen van de annotator
en verder werden ook niet alle documenten in het corpus onderzocht om de annotaties uit te
voeren.
Dit heeft als gevolg dat er een bovengrens is (lager dan 1) op de maximaal
zinvolle
precision en recall.
Om een waarde voor deze bovengrens te zoeken,
werden de documenten horende bij ´e´en event
door een tweede persoon gezocht en geannoteerd.
Als we de gevonden documenten vergelijken
met de eigen annotaties,
dan bekomen we een precision van 0.613 en een recall van 0.409.
Dit
terwijl zoals uit hoofdstuk 7 zal blijken, de precision- en recall-waarden voor het beste algoritme
6.2 Evaluatiemethodes
67
veel hoger zijn, respectievelijk 0.897 en 0.547 bij dit event.
Hieruit zou besloten kunnen worden dat deze hoge precision- en recall-waarden horende bij de
automatisch gevonden documenten geen zinvolle betekenis meer hebben, want deze zijn immers
hoger dan de precision/recall-waarden bij
de documenten gevonden door een andere persoon.
Deze conclusie kan echter niet zomaar gemaakt worden omdat de lage precision en recall tussen
de twee manueel
geannoteerde sets documenten niet enkel
te wijten is aan de onenigheid over
de relevantie van de documenten.
Deze lage waarden worden namelijk vooral bekomen doordat
niet alle documenten onderzocht werden door beide annotators.
Om dit aan te tonen, worden nu enkel de set van documenten beschouwd die door beide annota-
tors onderzocht zijn.
Als we op basis van deze verkleinde set opnieuw de annotaties vergelijken,
dan bekomen we een precision van 1 en een recall
van 0.867,
met als referentieset nog steeds
onze eigen annotaties.
Deze resultaten tonen dus aan dat onze referentieset inderdaad niet perfect is.
Vooral het ont-
breken van annotaties bij sommige relevante documenten (doordat niet alle documenten in het
corpus onderzocht werden) zorgt voor een onderschatting van de precision.
De recall zal echter
minder be
¨
ınvloed worden, als we veronderstellen dat de set geannoteerde relevante documenten
een random selectie is uit de effectieve set relevante documenten.
De oplossing om deze niet-perfecte referentie-set correcter te maken,
is om effectief
alle doc-
umenten te onderzoeken.
Of
toch minstens een random selectie van documenten tijdens de
periode van een event.
Het probleem is dat het annoteren van deze grote sets documenten te
veel
tijd in beslag zou nemen.
Ook als er gewerkt zou worden met een selectie.
Doordat het
aandeel relevante documenten zo laag is (maximum ±1/100 tijdens de periode van het event) en
er een minimum aantal (en aandeel van de totale set) relevante documenten moet geannoteerd
worden om conclusies te trekken,
zouden er per event toch duizenden documenten onderzocht
moeten worden.
Op deze manier zou er geen onderschatting van de precision (en recall) meer
zijn, maar enkel een bovengrens op de maximaal zinvolle precision/recall-waarde.
Aangezien er echter niet genoeg tijd was om effectief alle documenten te onderzoeken,
bestaat
onze referentieset dus wellicht uit een subset van de effectief relevante documenten.
EVALUATIERESULTATEN
68
Hoofdstuk 7
Evaluatieresultaten
In dit hoofdstuk worden de verschillende tekstvoorstellingen vergeleken,
wordt het gebruikte
clusteralgoritme geanalyseerd en kaderen we de bekomen resultaten van de event-detectie met
resultaten gebruik makende van niet-temporele tekstvoorstellingen.
Hierbij ligt de nadruk vooral op de verschillende tekstvoorstellingen en de impact van de verschil-
lende parameters.
Verder vertrekken we ook met het corpus dat bestaat uit de artikels met hun
woorden (in tegenstelling tot het corpus enkel gebaseerd op de eigennamen).
We kiezen om te
werken met de woorden aangezien deze potentieel meer informatie bevatten.
Deze zijn ook meer
gevoelig aan de gekozen parameters van de algoritmen aangezien een deel
van deze woorden
ook irrelevant zijn en dus met behulp van het algoritme uit de voorstelling gefilterd zouden
moeten worden.
Voorbeelden van zo’n woorden zijn:“mij”, “lopen” en andere stopwoorden die
niet verwijderd werden tijdens de preprocessing.
Aangezien het testen van de verschillende methoden met alle mogelijke parameter-combinaties
door middel van een grid-search onmogelijk is gezien de rekentijd van de algoritmen, hebben we
op een iteratieve manier de verschillende parameters afzonderlijk verfijnd, waarbij we vertrokken
van een heel sparse grid-search.
In de bespreking zullen we de impact van de verschillende parameters echter afzonderlijk beschouwen,
aangezien uit vroegere experimenten bleek dat de parameters nagenoeg onafhankelijk de resul-
taten be
¨
ınvloeden.
We starten met het analyseren van de tekstvoorstellingen,
waarbij we voor de clustermethode
telkens de tweede sequenti
¨
ele methode gebruiken.
Hierbij houden we de minimale grootte van de
clusters constant (M inP ts = 6) en laten we de treshold op de minimale documentovereenkomst
(M inClusterSim) vari
¨
eren.
Een korte bespreking van de effecten van deze parameters bij de clustermethode en een vergeli-
jking met de twee andere clustermethoden volgt daarna in sectie 7.2.
7.1 Tekstvoorstellingen
69
7.1
Tekstvoorstellingen
In deze sectie zullen we de verschillende tekstvoorstellingen testen door de invloed van verschil-
lende parameters en verbeteringen afzonderlijk te analyseren.
We starten in sectie 7.1.1 met het analyseren van de parameters en onderdelen bij het bepalen
van de bursts.
We starten met de analyse van de burst-detectie aangezien de gevonden bursts
de bursty-features bepalen die door alle besproken tekstvoorstellingen gebruikt worden.
Hierbij
vertrekken we met het analyseren van de twee parameters die gebruikt werden in [Zhao et al., 2012],
namelijk de emissie-parameteter (s) en toestandstransitieprobabiliteit (p),
daarna bepalen we
ook de invloed van het uitmiddelen van de documentfrequenties.
In sectie 7.1.2 onderzoeken we dan of onze conclusie over de IDF-herweging uit sectie 4.1 klopt.
Daar stelden we dat de IDF-herweging op de bursty-features een negatieve impact op de tekst-
voorstelling zou hebben.
Onze concrete voorstellen waren om deze IDF-herweging ofwel te laten
wegvallen, ofwel de IDF-herweging toe te passen op de termen die lopen over de volledige corpus
in plaats van de bursty-features die slechts voorkomen tijdens de bursts.
In sectie 7.1.3 zullen we vervolgens de verschillende boosting-functies vergelijken.
We besluiten dan het onderzoek naar de tekstvoorstellingen met drie afzonderlijke testen.
Deze
testen zijn het verfijnen van de feature-selectie, het gebruik van eigennamen als termen, en het
gebruik van zowel woorden als eigennamen.
Bij deze drie testen gebruiken we telkens de optimale
boosting-functie van sectie 7.1.3.
7.1.1
Burst-detectie en parameters
Emissie-parameter s
Deze emissie-parameter s, zoals in sectie 2.2.3 gedefinieerd, duidt de verhouding aan tussen de
emissieprobabiliteit van de bursty toestand en deze van de niet-bursty toestand van de toestands-
automaat.
Dit komt concreet neer op de verwachte verhoging van de fractie van artikels die een
bepaalde term bevatten tijdens een burst-periode ten opzichte van deze fractie tijdens een niet-
bursty periode.
Aangezien ze de verhouding van de bursty fractie p
1
op de gemiddelde fractie p
0
weergeeft, moet
deze parameter groter dan ´e´en zijn.
In [Zhao et al., 2012] werd s = 1.5 gebruikt.
Tijdens de testen hebben we de invloed van s op de burst-detectie en de BurstVSM-tekstvoorstelling
bepaald,
door
s waarden tussen 1.1 en 2.1 te laten aannemen.
We gebruikten hierbij
als
toestandstransitieprobabiliteit p = 0.0007, op deze keuze wordt verder in detail ingegaan.
De belangrijkste resultaten van deze testen zijn terug te vinden op figuur 7.2.
Hierbij wordt voor
de resultaten van de clustering gebruik gemaakt van de parameter settings die de maximale F
1
-
measure opleveren.
Enkel bij figuur 7.2d worden resultaten met verschillende M inClusterSim
gebruikt
om robuustheid van de voorstelling voor
deze M inClusterSim-parameter weer te
7.1 Tekstvoorstellingen
70
geven.
Deze M inClusterSim neemt alle waarden aan in [0.76, 0.78, 0.80, 0.82, 0.84].
De maxi-
male F
1
-measure werd bijna altijd bereikt met M inClusterSim = 0.78.
Op basis van de resultaten uit figuur 7.2 kunnen we concluderen dat s = 1.5 inderdaad de
beste resultaten oplevert voor het BurstVSM-model.
Bij deze waarde bekomen we immers de
maximale F
1
-measure (zie figuur 7.2d).
Dit geeft dus een goede afweging tussen de precision en
recall zoals ook te zien op figuur 7.2c.
Op basis van figuur 7.2b zou echter verwacht kunnen worden dat de event-detectie beter zou
werken,
en dus ook de tekstvoorstelling beter wordt,
naarmate s stijgt.
Bij hogere s bekomen
we namelijk een grotere ratio tussen de inter- en intra-similarity van de documenten die zelf
geannoteerd werden.
Deze conclusie kan echter niet gemaakt worden omdat de verhoging van
de gemiddelde ratio (vooral bekomen door het verkleinen van de intrasimilarity) niet bekomen
werd door het gelijkmatig groter worden van deze ratio over alle gevonden events,
maar door
het heel sterk stijgen van de ratio bij enkele events.
Op deze manier wordt er dus een vertekend
beeld verkregen.
Tenslotte kunnen we uit figuur 7.2a concluderen dat het verhogen van s consistent zorgt voor
het het stijgen van het aantal
gevonden bursty-features en het aantal
gevonden events.
De
stijging van het aantal gevonden events, bij een stijging van het aantal bursty-features, kunnen
we verklaren doordat er op deze manier ook meer documenten zijn die bursty-features bevatten
en die er op deze manier dus ook meer documenten zijn met gemeenschappelijke features.
De stijging in het aantal bursty-features bij het vergroten van s lijkt echter contra-intu
¨
ıtief.
Aangezien s de verhouding tussen p
0
en p
1
is, kunnen we namelijk verwachten dat als we deze
verhouding groter maken, de toestandsautomaat minder snel van een niet-bursty toestand naar
een bursty toestand zal overgaan.
De effectieve fractie van documenten die een bepaalde term
bevatten (p
∗
-waarde) zal namelijk hoger moeten zijn vooraleer de emissiekost σ(i, x
t
) (verg.
7.1)
van beide toestanden gelijk is,
zoals weergegeven op figuur 7.1.
Hierbij komt de noodzakelijke
fractie-verhoging (p
∗
/p
0
) overeen met het de abscis-waarde waarbij de emissiekostwinst (σ(0, x
t
)-
σ(1, x
t
)) nihil wordt.
σ(i, x
t
) = − ln
h

d
t
r
t

p
r
t
i
(1 − p
i
)
d
t
−r
t
i
(7.1)
Op basis van figuur 7.1 kan de stijging van het aantal bursty-features met de parameter s nu ook
verklaard worden.
We zien namelijk dat de emissiekost-winst steeds sneller stijgt,
naarmate s
groter gekozen wordt.
Verder kunnen we na het analyseren van enkele document/term-frequentie
grafieken (zoals figuren 4.3,4.4 enz.) besluiten dat de documentfrequentie en dus ook de fractie
van documenten die een bepaalde term bevat, bij de potentieel “bursty”-periodes veel hoger is
dan anderhalve keer het gemiddelde (p
∗
/p
0
 1.5).
Hierdoor bekomen we bij het gebruik van
een grotere s dus een grotere emissiekostwinst tijdens potentieel bursty periodes.
Op deze manier zullen er dus sneller bursts ge
¨
ınitialiseerd worden.
Bursts zullen namelijk
7.1 Tekstvoorstellingen
71
gedefinieerd worden van zodra de emissiekostwinst gedurende een bepaalde periode groter wordt
dan de bijhorende transitiekosten die onafhankelijk zijn van s,
zie sectie 2.2.3.
Aangezien het
burst-gewicht gedefinieerd wordt als de som van de emissiekostwinsten gedurende de burst-
periode, volgt hier ook uit dat de burst-gewichten stijgen met het vergroten van s.
1
2
3
4
5
6
p
∗
/p
0
−100
−50
0
50
100
150
200
250
emmissiekost-winst:
σ(0, x
t
)
-
σ(1, x
t
)
0
s=1.3
s=1.5
s=3
Figuur 7.1:
Simulatie van de emissiekost-winst (gewicht van de burst) per dag in functie van de verhoging
van de fractie documenten die een bepaalde term bevatten (p
∗
/p
0
) bij verschillende s-waarden.
7.1 Tekstvoorstellingen
72
1.0
1.2
1.4
1.6
1.8
2.0
2.2
s
0
2000
4000
6000
8000
10000
12000
14000
# bursty-features
1000
1500
2000
2500
3000
3500
# gevonden events
# bursty-features
# gevonden events
(a) aantal
bursty-features en gevonden events
1.0
1.2
1.4
1.6
1.8
2.0
2.2
s
0.47
0.48
0.49
0.50
0.51
0.52
0.53
0.54
intrasimilarity
0.0050
0.0055
0.0060
0.0065
0.0070
0.0075
intrasimilarity
intersimilarity
intrasimilarity
(b) inter- en intrasimilarities van de zelf-geannoteerde events
1.0
1.2
1.4
1.6
1.8
2.0
2.2
s
0.30
0.35
0.40
0.45
0.50
0.55
0.60
0.65
0.70
0.75
precision/recall
precision
recall
(c) precision en recall
van de event-detectie
1.0
1.2
1.4
1.6
1.8
2.0
2.2
s
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
F
1
-measure
0.74
0.75
0.76
0.77
0.78
0.79
0.80
0.81
0.82
0.83
0.84
(d) F
1
-measure van de event-detectie
Figuur 7.2:
Impact van emissie-parameter s op de burstVSM-voorstelling.
In (d) worden de F
1
-measures weergegeven voor verschillende waarden van de
M inClusterSim-parameter.
In de andere figuren wordt enkel
de M inClusterSim met hoogste F
1
gebruikt.
7.1 Tekstvoorstellingen
73
Toestandstransitieprobabileit p
De tweede parameter bij de burst-detectie is de toestandstransitieprobabiliteit p en deze duidt
de kans aan om over te gaan van een bursty toestand naar niet-bursty toestand of andersom.
Een relatief kleine p-waarde duidt dus aan dat de kans om van toestand te veranderen klein is.
Dit is gewenst aangezien we bursts wensen met een zekere minimum-lengte en dat ze niet zo
gevoelig zijn aan de documentfrequentie-ruis.
De concrete waarde die gebruikt werd in [Zhao et al., 2012],
werd niet meegegeven.
Daarom
moest er dus zelf een correcte range gezocht worden.
Tijdens het testen bleek dat de effectieve
waarde bij gebruik van eigennamen als termen redelijk hoog gekozen mocht worden (p > 0.1).
Bij
gebruik van woorden werden er echter geen goede resultaten bekomen in deze parameter-
range.
Dit probleem werd eerst aangepakt door de documentfrequenties uit te middelen, wat tot betere
resultaten leidde,
maar toch nog niet voldoende was.
Pas later werd gevonden dat deze p-
waarde veel
lager gekozen moest worden.
De invloed van de p-parameter op de BurstVSM-
voorstelling die vertrekt van TFIDF-termgewichten (optimaal
zoals in de volgende sectie be-
sproken) is weergegeven op onderstaande figuur 7.3.
Op basis van grafiek 7.3a zien we zoals verwacht dat het vergroten van p meer bursty-features en
events oplevert.
Als er een lagere kost is om te veranderen van toestand zullen er immers meer
nieuwe (kortere) bursty-features ontstaan.
Doordat deze bursty-features echter korter worden,
zal de tekstvoorstelling met deze features slechter worden aangezien het dan kan voorkomen dat
sommige bursty-features niet de volledige periode van een bepaalde gebeurtenis omvatten.
Deze
conclusie kan ook getrokken worden op basis van de resultaten van figuren 7.3b en 7.3c.
Daarop
is bij de laatste figuur duidelijk te zien dat de recall, dus de compleetheid van de gevonden set
documenten gebruik makende van de BurstVSM-representatie met deze p-waarde,
sterk daalt
bij het verhogen van p.
De optimale waarde van p ligt zoals op basis van de grafieken in figuur 7.3 af te leiden tussen
0.001 en 0.0001.
Bij deze waarden moeten we weer een afweging maken tussen het aantal gevon-
den events en de maximale F
1
-measure.
In het vervolg zal gewerkt worden met p = 0.0007.
7.1 Tekstvoorstellingen
74
10
−4
10
−3
10
−2
p
4000
6000
8000
10000
12000
14000
16000
18000
20000
22000
# bursty-features
2400
2600
2800
3000
3200
3400
3600
# gevonden events
# bursty-features
# gevonden events
(a) aantal
bursty-features en gevonden events
10
−4
10
−3
10
−2
10
−1
p
0.40
0.45
0.50
0.55
0.60
intrasimilarity
0.0030
0.0035
0.0040
0.0045
0.0050
0.0055
0.0060
intrasimilarity
intersimilarity
intrasimilarity
(b) inter- en intrasimilarities van de zelf-geannoteerde events
10
−4
10
−3
10
−2
p
0.40
0.45
0.50
0.55
0.60
0.65
0.70
0.75
precision/recall
precision
recall
(c) precision en recall
van de event-detectie
10
−4
10
−3
10
−2
p
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
F
1
-me5sure
0.760
0.765
0.770
0.775
0.780
0.785
0.790
0.795
0.800
(d) F
1
-measure van de event-detectie
Figuur 7.3:
Impact van p op de burstVSM-voorstelling.
In (d) worden de F
1
-measures weergegeven voor verschillende waarden van de M inClusterSim-
parameter.
In de andere figuren wordt enkel
de M inClusterSim met hoogste F
1
gebruikt.
7.1 Tekstvoorstellingen
75
Verder werd er ook ge
¨
experimenteerd met het ontdubbelen van p.
Met de bestaande imple-
mentatie wordt er namelijk dezelfde transitiekans gebruikt bij
de overgang van bursty naar
niet-bursty toestand als omgekeerd.
Deze overgangen elk een eigen transitiekans geven,
gaf
echter geen merkbare verbetering, al kwam er op deze manier natuurlijk wel een extra parame-
ter bij.
Verband tussen s en p
Aangezien zowel
s als p het gewicht van hun corresponderende kostfunctie be
¨
ınvloeden,
is het
dus in een zekere zin mogelijk om de effecten van beide parameters elkaar te doen tegenwerken.
Doordat enkel
de emissiekost afhankelijk is van de p
∗
/p
0
-verhouding is het echter nooit zo dat
de effecten van beide parameters elkaar volledig kunnen opheffen.
Uitmiddeling van documentfrequenties
Zoals in sectie 4.1 voorgesteld,
zullen we nu de invloed van het uitmiddelen van de document-
frequenties analyseren op de BurstVSM-voorstelling.
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
breedte uitmiddelvenster (dagen)
5500
6000
6500
7000
7500
8000
# bursty-features
2200
2250
2300
2350
2400
2450
2500
2550
2600
2650
# gevonden events
# bursty-features
# gevonden events
Figuur 7.4:
Invloed van DF-uitmiddeling op het aantal
bursty-features en events.
Een eerste conclusie (zie figuur 7.4) is dat er minder events en minder bursts gevonden worden
naarmate we meer uitmiddelen.
Dit is ook wat we wensten te bekomen.
Verder kunnen we
op basis van figuur 7.5 besluiten dat de event-detectie verbeterd kan worden met behulp van
DF-uitmiddeling.
Zo zien we dat de maximale F
1
-measure verhoogd kan worden door uit te
middelen, waarbij er een positief effect is bij alle gebruikte vensterbreedtes.
7.1 Tekstvoorstellingen
76
−1
0
1
2
3
4
5
breedte uitmiddelvenster (dagen)
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
F
1
-measure
0.760
0.768
0.776
0.784
0.792
0.800
0.808
0.816
Figuur 7.5:
Invloed van DF-uitmiddeling op de event-detectie performantie bij BurstVSM. Hierbij werden
telkens 4 verschillende M inClusterSim-waarden gebruikt, weergegeven met de kleur van de punten
De mogelijke verbetering is echter wel gelimiteerd omdat het uitmiddelen de piekwaarden doet
verkleinen en in het uiterste geval doet verdwijnen.
Aangezien er bij Boosted BurstVSM verder
gebruik gemaakt wordt van het gewicht van deze bursts,
is de negatieve invloed hiervan nog
groter, zoals in figuur 7.6 weergegeven.
Bij de log MSB BurstVSM van figuur 7.6 is er enkel bij
gebruik van een uitmiddelvenster met breedte 1 dag een verhoging van de F
1
-measure bereikt.
−1
0
1
2
3
4
5
breedte uitmiddelvenster (dagen)
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
F
1
-measure
0.760
0.768
0.776
0.784
0.792
0.800
0.808
0.816
Figuur 7.6:
Invloed van DF-uitmiddeling op de event-detectie performantie bij log MSB BurstVSM (zie
sectie 7.1.3).
Hierbij werden telkens 4 verschillende M inClusterSim-waarden gebruikt, weergegeven met
de kleur van de punten
7.1 Tekstvoorstellingen
77
7.1.2
IDF-herweging
Een andere wijziging aan het BurstVSM-algoritme,
is om de gebruikte IDF-herweging aan te
passen.
Zo zullen we in een eerste test de IDF-herweging volledig laten wegvallen, daarna voeren
we IDF-herweging uit op de frequenties van de termen in plaats van de bursty-features, met als
DF dus het aantal documenten over de volledige corpus die de term bevatten.
De resultaten van deze testen zijn terug te vinden in tabel
7.1.
Hierop is te zien dat de inter-
similarity inderdaad stijgt door het laten vallen van de IDF-herweging.
Het probleem is dat
de intrasimilarity echter ook aanzienlijk stijgt.
Hierdoor verkrijgen we zelfs een slechtere tekst-
voorstelling, wat duidelijk wordt bij het vergelijken van de F
1
-measure na clustering.
Als we de IDF-herweging echter toepassen op de termen, dan bekomen we resultaten die beide
vorige op alle gebied overtreffen, zoals terug te vinden in tabel 7.1.
Het ontbreken van de negatieve impact van de IDF-herweging van de TF van de bursty-features
kunnen we verklaren doordat er toch bursty-features voorkomen die eigenlijk meer algemene
features zijn, die documenten dus ongewenst kunnen clusteren.
Hierbij denken we aan de tem-
porele “ruis”-termen uit sectie 4.1.3,
zoals bv. de maanden.
Het toepassen van IDF-herweging
op de TF van deze bursty-features heeft dus wel een positief effect dat groter is dan het nadelig
effect op de andere bursty-features.
BurstVSM
Standaard
zonder
IDF-
herweging
IDF-herweging
op termen
intersimilarity
0.543
0.561
0.571
intrasimilarity
0.00604
0.00687
0.00522
precision
0.676
0.542
0.689
recall
0.476
0.414
0.553
F
1
-measure
0.559
0.469
0.614
Tabel 7.1:
Invloed van de IDF-herweging op de kwaliteit van de BurstVSM-tekstvoorstelling.
(p = 0.0005)
Uit de bovenstaande tabel 7.1 kunnen we wel besluiten dat de IDF-herweging op de termen in
plaats van de bursty-features een significant betere tekstvoorstelling oplevert.
In het vervolg
zullen we bij het vergelijken van de verschillende gewichtsfuncties dus deze IDF-herweging ge-
bruiken.
Ook kunnen we uit tabel 7.1 afleiden dat de stijging van de F
1
-measure van 55.9% tot
61.4% vooral te danken is aan de sterke stijging van de recall.
7.1.3
Boosted BurstVSM
We vergelijken nu de verschillende Boosted BurstVSM-tekstvoorstellingen die voorgesteld wer-
den in sectie 4.1.3.
We vertrekken hierbij telkens van de TFIDF-gewichten van de termen,
die
een veel
betere tekstvoorstelling mogelijk maken zoals uit de vorige sectie 7.1.2 bleek.
Gezien
7.1 Tekstvoorstellingen
78
de mogelijk negatieve impact van de DF-uitmiddeling op de gewichten van de bursts, zullen we
eerst de resultaten bespreken zonder uitmiddeling.
Achteraf volgt dan een samenvatting van de
impact van de DF-uitmiddeling.
Om de Boosted BurstVSM-tekstvoorstellingen te vergelijken,
analyseren we de resulterende F
1
-measures door telkens deze uit te rekenen bij
gebruik van
verschillende M inClusterSim-waarden in de omgeving van het optimum.
Concreet komt dit
meestal neer op M inClusterSim ∈ [0.76, 0.78, 0.80, 0.82, 0.84] tenzij anders vermeld.
Accumulated Boosted BurstVSM-tekstvoorstellingen
Accumulated boosting gebeurt door een boosting-term op te tellen bij de het bursty-featuregewicht.
De resultaten hiervan zijn weergegeven in figuur 7.7, waarbij de bestaande BurstVSM-voorstelling
als referentie is weergegeven
1
.
Voor de burst-coeffici
¨
ent δ horende bij
dit soort boosting,
ge-
bruiken we telkens de best gevonden waarde die bekomen werd met behulp van een grid-search.
BurstVSM
AB-BurstVSM
ASB-BurstVSM
log AB-BurstVSM
log ASB-BurstVSM
0.30
0.35
0.40
0.45
0.50
0.55
0.60
0.65
0.70
F
1
-measure
0.760
0.768
0.776
0.784
0.792
0.800
0.808
0.816
0.824
0.832
0.840
Figuur 7.7:
Performantie van de AB BurstVSM-tekstvoorstellingen,
waarbij
we de performantie uit-
drukken als de F
1
-measure van de gevonden clusters.
We zien dus dat we met dit soort boosting geen merkbare verbetering verkrijgen.
Meestal zijn
de bekomen F
1
-measures zelfs lager.
Bij
gebruik van de gesatureerde gewichten,
(log) SB-BurstVSM,
zien we dat de invloed van
M inP ts kleiner wordt in de buurt van het optimum.
De punten liggen bij het het optimum dus
dichter bij elkaar.
Verder zien we op deze figuur geen merkbare impact van het logaritmisch herschalen van de
gewichten.
Er is echter wel een verschil zichtbaar bij grotere M inClusterSim-waarden, die dus
1
Merk op dat dit wel
de aangepaste BurstVSM-voorstelling is waarbij
er vertrokken wordt van de TFIDF-
gewichten van de termen en er geen IDF-herweging wordt toegepast op de bursty-features.
7.1 Tekstvoorstellingen
79
niet meer optimaal zijn (en niet weergegeven).
Dan zien we dat de F
1
-measure veel sneller daalt
bij
gebruik van de logaritmisch herschaalde gewichten.
Dit kunnen we verklaren doordat er
bij gebruik van niet-logaritmisch herschaalde gewichten,
de gelijkheid van documenten slechts
van een klein aandeel
bursty-features afhangt.
Hierdoor zullen de documenten dus ofwel
heel
goed op elkaar lijken,
ofwel
totaal
niet.
Daardoor is vanaf
een bepaalde M inClusterSim de
effectieve grootte minder van belang.
Dit is ook af te leiden uit de standaardafwijking van de
intersimilarities die bij de logaritmisch herschaalde gewichten iets kleiner is.
De resultaten van deze soort boosting vallen nogal tegen, nochtans werden er in [He et al., 2007]
wel
goede resultaten geboekt met deze boosting.
Dit kunnen we verklaren doordat we werken
met TFIDF-gewichten,
terwijl
er in [He et al., 2007]
enkel
gebruik werd gemaakt van binaire
termfrequentie-gewichten.
Bij
gebruik van binaire termfrequentie-gewichten is de bijdrage van de boosting immers con-
stant voor alle termen.
Het binaire termfrequentie-gewicht van termen in een document is
immers ofwel
0,
ofwel
1.
De TFIDF-gewichten horende bij
de bursty-features kunnen echter
wel sterk vari
¨
eren in grootte, afhankelijk van het aantal features in de documentvoorstelling en
de documentfrequenties van deze features.
Hierdoor kan de impact van boosting soms te groot
zijn,
als het TFIDF-gewicht van de feature klein is,
en soms te klein,
als het feature-gewicht
groot is.
Dit toont dus aan dat dit soort boosting niet compatibel
is met IDF-herweging,
en
verklaart waarom dit soort boosting met alle soorten burstgewichten een negatieve impact heeft.
Gezien de TFIDF-gewichten echter een veel
betere tekstvoorstelling zijn dan de binaire TF-
gewichten, zoeken we nu een boosting die wel compatibel is met de IDF-herweging.
Multiplied Boosted BurstVSM-tekstvoorstellingen
We verwachten dat deze nieuwe Boosting betere resultaten zal geven aangezien de bijdrage van de
boosting op het bursty-featuregewicht hier constant is.
Beide worden namelijk vermenigvuldigd
met elkaar,
waardoor de bijdragen van zowel
de IDF-herweging als de boosting los van elkaar
staan.
De resultaten zijn terug te vinden in figuur 7.8.
Hierop zien is te zien dat we inderdaad een
verbetering kunnen bekomen, maar dit enkel bij het gebruik maken van de gesatureerde burst-
gewichten, (log) MSB-BurstVSM. Het is opmerkelijk dat het verschil met (log) MB-BurstVSM
zo groot is.
Dit toont dus aan dat het nieuwe gesatureerde burstgewicht inderdaad een beter
burstgewicht is dan het gebruikelijke burstgewicht.
Ook zien we dat door gebruik te maken van de logaritmische burstgewichten er vooral bij de niet-
gesatureerde versies een sterk verbeterde tekst-voorstelling bekomen wordt.
Dit kan verklaard
worden doordat het
verschil
tussen de verschillende gewichten bij
logaritmische herschaling
7.1 Tekstvoorstellingen
80
BurstVSM
MB-BurstVSM
MSB-BurstVSM
log MB-BurstVSM
log MSB-BurstVSM
0.30
0.35
0.40
0.45
0.50
0.55
0.60
0.65
0.70
F
1
-measure
0.76
0.78
0.80
0.82
0.84
0.86
0.88
0.90
0.92
Figuur 7.8:
Performantie van de MB BurstVSM-tekstvoorstellingen,
waarbij
we de performantie uit-
drukken als de F
1
-measure van de gevonden clusters.
kleiner wordt.
Als de niet-gesatureerde gewichten soms incorrect zijn,
dan zal
dit probleem
dus kleiner worden als het logaritme van dit gewicht gebruikt wordt.
Bij zowel de MB- als de MSB-BurstVSM zien we echter dat de impact van de M inClusterSim
sterk daalt bij
gebruik van logaritmische boosting.
Ook zien we dat we zonder logaritmische
herschaling M inClusterSim veel
groter moeten nemen dan de gebruikelijke optimale waarde
M inClusterSim = 0.78.
Dit kan verklaard worden doordat er net zoals bij
de Accumulated
versie, er zonder logaritmische herschaling veel minder bursty-features zijn waarvan het bursty-
featuregewicht van dezelfde grootteorde is.
Hierdoor is er dus een veel kleinere set van bursty-
features die bijna de volledige vector-voorstelling van een document domineren.
De clustering
zal daardoor bijna enkel bepaald worden op basis van de aan- of afwezigheid van deze beperkte
set bursty-features.
De M inClusterSim zal
hierdoor dus veel
hoger gekozen moet worden.
Anderzijds zullen er bij de log M(S)B-BurstVSM meer bursty-features zijn die van belang zijn
bij de vector-voorstelling.
De bursty-features die van belang zijn om gelijkaardige documenten
te clusteren zullen nu enkel een groter gewicht krijgen dan in de niet-Boosted versie, waardoor de
Boosted versie dus minder afhankelijk wordt van de concrete M inClusterSim-parameter zoals
gewenst.
Invloed DF-uitmiddeling
Als we nu de verschillende boosting-methodes toepassen na het uitmiddelen van de document-
frequenties,
dan bekomen we voor de AB BurstVSM-tekstvoorstellingen geen merkbare veran-
deringen.
Bij de MB BurstVSM-tekstvoorstellingen bekomen we echter een daling van de F
1
-
measure bij
de niet-logaritmische boosting en een stijging bij
de logaritmische boosting.
Dit
7.1 Tekstvoorstellingen
81
maakt de DF-uitgemiddelde (met uitmiddelvenster van 1 dag) log MSB BurstVSM de beste
tekstvoorstelling die bestudeerd werd.
Met een F
1
-measure= 0.682 is de F
1
-measure dus 12.3% gestegen ten opzichte van de F
1
-measure
van de oorspronkelijke BurstVSM-voorstelling, met F
1
-measure= 0.559.
7.1.4
Verfijning feature-selectie
Als we nu de aanpassingen voorgesteld in sectie 4.1.3 (de aangepaste burst-detectie) testen, dan
bekomen we de resultaten uit tabel 7.2.
Hierbij gebruiken we dezelfde boosting als bij log MSB-BurstVSM,
maar op basis van andere
bursts en gebruiken we ook de DF-uitmiddeling met enkelzijdige vensterbreedte van 1 dag.
Verder hebben we als vensterbreedte voor de DF-schatting 60 dagen gekozen.
De s en p param-
eters hebben we bepaald door het analyseren van de documentfrequentie-grafieken van verschil-
lende termen, zoals bv. deze van figuur 7.9.
Hieruit hebben we s = 2.3 en p = 0.0001 als optimale waarden gevonden.
Deze s-waarde is dus
groter dan bij de andere BurstVSM-voorstellingen, aangezien de detectie nu effectief gebeurt aan
de hand van de detectie van de grote discontinu
¨
ıteiten in de documentfrequenties.
De p-waarde
is kleiner om de invloed van de hogere s-waarde bij minder grote discontinu
¨
ıteiten te beperken.
Verder is de optimale M inClustersim = 0.86, dus hoger dan de gebruikelijke M inClustersim =
0.78.
Dit kan weerom verklaard worden door de veel
kleinere set bursty-features,
waardoor de
documenten dus ofwel goed op elkaar lijken, ofwel totaal niet.
Deze conclusie kan ook getrokken
worden op basis van de hogere standaardafwijking op de intersimilarity,
deze is nu namelijk
0.195 in plaats van 0.152.
log MSB-BurstVSM verfijnde log MSB-BurstVSM
intersimilarity
0.621
0.560
intrasimilarity
0.00622
0.00461
# features
6618
2194
precision
0.693
0.630
recall
0.671
0.628
F
1
-measure
0.682
0.629
# events
2630
1029
Tabel
7.2:
Resultaten bij de verfijnde feature-selectie
Uit tabel 7.2 zien we dat we geen hogere F
1
-measure bekomen als we de verfijning van de feature-
selectie uitvoeren.
Het uitfilteren van de “ruis”-termen is met deze methode dus te agressief.
Als we bv.
de bursts horende bij
de term “DSK” bekijken (zie figuur 7.9),
dan zien we dat
de burst-periodes met behulp van deze burst-detectie veel kleiner worden, of dat de burst zelfs
gesplitst wordt, waardoor we dus een slechtere voorstelling verkrijgen.
7.1 Tekstvoorstellingen
82
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
datum
0
5
10
15
20
25
30
35
40
documentfrequentie
0
200
400
600
800
1000
burstgewicht
DF ’DSK’
log MSB BurstVSM
verfijnde log MSB BurstVSM
Figuur 7.9:
Negatieve impact van de feature-verfijning op de vorm van de gevonden bursts.
De bursts zijn
namelijk korter, in dit voorbeeld werd de burst zelfs gesplitst.
In deze figuur zijn de documentfrequenties
(DF) horende bij de term “DSK” weergegeven en de bursts (met bijhorende gesatureerde gewicht) gevonden
met de zowel log MSB BurstVSM als de verfijnde versie, waarbij het gewicht van de bursts van de verfijnde
versie met 5 werd vermenigvuldigd om de leesbaarheid te verhogen.
Wel
bekomen we verder een zeer goede compressie van het corpus.
Bij
deze verfijnde burst-
detectie werken we met 2194 bursty-features,
die horen bij 1041 verschillende termen.
Terwijl
er bij de vorige niet-verfijnde burst-detectie gewerkt wordt met 6618 bursty-features,
horende
bij
5965 verschillende termen.
Verder zijn er ook veel
minder events gevonden,
wat ook een
voordeel van deze aanpak is.
7.1.5
Gebruik eigennamen
De log MSB-BurstVSM die de best mogelijke resultaten gaf, werd nu ook toegepast op de termen
bestaande uit eigennamen.
Hierbij werd opnieuw gewerkt met een uitmiddelvenster van 1 dag
en werd s = 1.5 gebruikt.
Wel
werd de invloed van de p-parameter opnieuw onderzocht.
De
impact van deze p-parameter is terug te vinden op onderstaande figuur 7.10.
Hierbij beschouwen
we nu enkel de M inClusterSim beschouwen die correspondeert met de hoogste F
1
-measure.
We kunnen dus besluiten dat de p-parameter nog steeds dezelfde invloed heeft op het aantal
gevonden bursty-features en events, maar dat de invloed op de kwaliteit van de tekstvoorstelling
F
1
-measure,
minder groot is.
De kwaliteit van de gevonden events stijgt zelfs bij
p-waarden
groter dan 0.05.
Een mogelijke verklaring hiervoor is de volgende:
als de p-parameter stijgt, dan zullen er meer
7.1 Tekstvoorstellingen
83
10
−4
10
−3
10
−2
10
−1
10
0
p
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
F
1
-measure
0
5000
10000
15000
20000
25000
30000
# events / bursty-features
F
1
− measure
# bursty-features
# events
Figuur 7.10:
Invloed van p op het aantal
bursty-features, aantal
events en de F
1
-measure bij gebruik van
het corpus met eigennamen.
termen zijn die een bursty-feature bevatten.
Bij gebruik van woorden kan het hierbij voorkomen
dat deze nieuwe bursty-features optreden als “ruis”-features,
waardoor er een nadelige impact
is op de tekstvoorstelling.
Bij eigennamen is de kans echter veel kleiner dat een bursty-feature
als “ruis”-feature optreedt.
Zo zal een document dat over een bepaalde persoon of een bepaalde
plaats gaat, met veel meer kans gerelateerd zijn aan een ander artikel dat over dezelfde persoon
of plaats gaat.
Dit is minder het geval bij bv. woorden als “operatie”,“zaterdag” enz.
Wel
zien we dat de maximaal
gevonden F
1
-measure iets lager is (0.657 met p = 0.01 in plaats
van 0.681 bij de woorden) dan bij gebruik van de woorden als eigennamen.
Dit is ook logisch
gezien we vertrekken van een veel
kleinere set termen (26552 in plaats van 98390).
Zo komen
woorden zoals:
“ramp”, “aanslag”, “misbruik”, “schandaal” enz. niet voor in de set van eigen-
namen, terwijl ze wel belangrijke informatie kunnen bevatten.
Verder zien we ook dat de daling
van de F
1
-measure enkel
komt door het verkleinen van de precision.
De recall
is zelfs hoger
bij het gebruik van de eigennamen als termen.
Deze cijfers kunnen dus ge
¨
ınterpreteerd worden
als het verhogen van de fractie teruggevonden relevante documenten,
maar dit ten koste van
de zuiverheid van de gevonden documenten.
Hierbij
dient wel
te worden opgemerkt dat onze
gebruikte referentieset mogelijk niet compleet is,
waardoor de berekende precision dus foutief
kleiner wordt, terwijl de recall beter de effectieve recall benadert.
De exacte cijfers zijn terug te vinden in tabel
7.3.
Hierbij
werd als p-waarde 0.01 gebruikt,
aangezien deze de hoogste F
1
-measure bereikt zonder heel
veel
bursty-features te moeten ge-
bruiken.
7.2 Clusteralgoritmen
84
woorden
eigennamen
combinatie
intersimilarity
0.621
0.618
0.603
intrasimilarity
0.00622
0.00442
0.00588
# features
6618
4602
11220
precision
0.693
0.608
0.625
recall
0.671
0.715
0.766
F
1
-measure
0.682
0.657
0.688
# events
2630
2146
3333
Tabel
7.3:
Resultaten bij het combineren van de log MSB-BurstVSM corpora
7.1.6
Combinaties van woorden en eigennamen
Nu controleren we of het mogelijk is om nog betere resultaten te verkrijgen als we de log MSB-
BurstVSM voorstelling op basis van de woorden en eigennamen combineren.
Hierbij combineren we de twee tekstvoorstellingen door een nieuwe corpus te genereren dat per
document bestaat uit de combinatie van de verkregen bursty-features uit de twee bestaande log
MSB-BurstVSM corpussen.
Voor de woord log MSB-BurstVSM corpus gebruiken we als parameters s = 1.5,
p = 0.0007
en als DF-uitmiddelvenster van breedte 1 dag.
Voor de eigennaam log MSB-BurstVSM corpus
gebruiken we dezelfde waarden voor het uitmiddelvenster en s,
maar nemen we p = 0.01.
Een
samenvatting van de resultaten is terug te vinden in tabel 7.3.
Met
het
gecombineerde corpus
kan dus
inderdaad een hogere F
1
-measure behaald worden,
dankzij een verdere stijging van de recall.
Maar de verbetering op andere gebieden is niet echt
groot,
als rekening gehouden wordt dat er bij deze tekstvoorstelling veel
meer bursty-features
nodig zijn.
Dit is niet zo vreemd aangezien er ook veel overlap is tussen de twee voorstellingen.
Zo zullen
eigennamen,
die bestaan uit ´e´en woord zowel
voorkomen bij
de eigennaam-termen als bij
de
woord-termen.
Het enige gevolg van het combineren van beide is dan dat deze features een
groter gewicht krijgen doordat ze dubbel geteld worden.
7.2
Clusteralgoritmen
Nu volgt een bespreking van de gebruikte clustermethode,
waarbij we als tekstvoorstelling de
optimale Boosted BurstVSM-voorstelling met woorden als termen gebruiken.
Hierbij starten we
met het bespreken van de parameters van de gebruikte tweede sequenti
¨
ele methode.
We stellen
ook enkele postprocessing-stappen voor om de gevonden events verder te filteren en dus betere
resultaten te bekomen.
Daarna vergelijken we de resultaten van deze clustermethode met de
resultaten verkregen met de tragere methodes.
7.2 Clusteralgoritmen
85
7.2.1
Gebruikte clusteralgoritme
Analyse parameters
De eerste parameter bij
de sequenti
¨
ele clustermethodes is het minimaal
aantal
documenten
M inP ts dat een kandidaat-cluster moet bevatten vooraleer deze als cluster ge
¨
ınitialiseerd wordt.
Tijdens het testen van de tekstvoorstellingen werd deze constant op 6 gehouden.
De invloed op het aantal
gevonden events en de bekomen F
1
-measure is terug te vinden op
figuur 7.11.
Hierop is te zien dat we inderdaad een maximum voor de F
1
-measure bekomen bij
MinP ts = 6.
Aangezien we echter ook het aantal
gevonden events proberen te minimaliseren
is deze oplossing slechts pareto-optimaal
2
.
Zo zou M inP ts = 11 ook een goede of zelfs betere
keuze zijn aangezien er hierbij veel
minder events/clusters gevonden worden.
Maar aangezien
deze parameter bijna enkel
zorgt voor een filtering van de gevonden events,
is deze niet zo
kritisch om de kwaliteit van de documentvoorstellingen te vergelijken.
Verder werd er ook
gekozen om een kleine M inP ts te gebruiken,
om een meer consistente vergelijking tussen de
verschillende tekstvoorstellingen te bekomen.
Mochten we een hogere waarde gebruiken,
dan
zou de kwaliteit veel
sterker afhangen van de effectieve M inP ts-waarde.
De filtering van de
clusters kan per tekstvoorstelling immers een ander lokaal
maximum vertonen zoals het lokale
F
1
-measure maximum die in figuur 7.11 op 11 ligt.
4
6
8
10
12
14
16
MinP ts
0.60
0.62
0.64
0.66
0.68
F
1
-measure
500
1000
1500
2000
2500
3000
3500
# gevonden events
F
1
− measure
# gevonden events
Figuur 7.11:
Invloed van de M inP ts-parameter op het aantal
bursty-features en events, bij gebruik van
log MSB-BurstVSM.
De tweede parameter, die wel gevarieerd werd tijdens alle testen, is M inClusterSim.
Deze kan
2
Dit pareto-optimum wil dus zeggen dat ze op ´e´en criterium optimaal is (maximale F
1
-measure), verbeteringen
van het andere criterium (minimum aantal events) gaan dan steeds gepaard met het verkleinen van de F
1
-measure.
7.2 Clusteralgoritmen
86
immers per tekstvoorstelling een andere globale optimale waarde hebben.
Bij de bursty-feature
tekstvoorstellingen bleef deze echter meestal optimaal bij 0.78.
Het is voor deze parameter wel
van belang om deze te verfijnen aangezien ze afhangt van de
similarities tussen de documenten binnen een bepaalde voorstelling.
Het is hier zinloos om een
constante hoge of
lage waarde te gebruiken.
Om de effectieve waarde te zoeken kunnen we
gebruik maken van de analyse van de tekstvoorstelling bij de zelf-geannoteerde events, waarbij
de gemiddelde en de variantie van de intersimilarity over de documenten per zelf-geannoteerd
event uitgerekend werd.
We kunnen dan als schatting voor de M inClusterSim de som van de
gevonden gemiddelde intersimilarity en de variantie op de intersimilarity gebruiken.
De concrete invloed van deze parameter op het aantal gevonden events en de F
1
-measure hangt
echter af
van de gebruikte documentvoorstelling,
waardoor we deze nu niet weergeven in een
figuur.
In de figuren van de voorgaande secties werden echter wel al resultaten voor verschillende
M inClusterSim-waarden weergegeven.
Postprocessing
Zoals in de vorige subsectie vermeld, zijn de gebruikte parameters slechts pareto-optimaal.
Wel
is het mogelijk om iedere gevonden clustering verder te optimaliseren door deze achteraf te fil-
teren.
Zo kan de verzameling events verkleind worden door bv.
een restrictie te leggen op de
minimale tijdspanne die de cluster in beslag neemt, of het minimaal aantal documenten die een
cluster moet bevatten.
Verder kunnen we door gebruik te maken van de hi
¨
erarchische clustering ook betere samenvat-
tingen van events bekomen.
Beide postprocessing stappen zullen hier echter niet geanalyseerd worden.
7.2.2
Andere clusteralgoritmen
Als we het gebruikte clusteralgoritme vergelijken met de twee ander voorgestelde (tragere) clus-
teralgoritmen, dan verkrijgen we als eerste conclusie dat het gebruikte algoritme inderdaad een
veel kortere rekentijd heeft.
Namelijk resp.
62% en 8% kortere rekentijd dan het recursieve en
het eerste sequenti
¨
ele algoritme.
Als we verder de resultaten bekomen met de sequenti
¨
ele algoritmen vergelijken met deze bekomen
met het recursieve algoritme, dan merken we dat de veel snellere sequenti
¨
ele algoritmen betere re-
sultaten opleveren.
Bij het recursieve algoritme krijgen we namelijk F
1
-measure= 0.57 in plaats
van 0.68 en 2876 clusters in plaats van 2630.
Deze resultaten kunnen respectievelijk verklaard
worden doordat we de clusterdetectie doen op afzonderlijke verzamelingen documenten,
waar-
door we clusters moeten mergen.
De stijging in het aantal
clusters kan dan weer verklaard
worden doordat de M inP ts nu geldt over een verzameling documenten die voorkomen over 14
dagen in plaats van 2 dagen.
Hierdoor kunnen er dus veel meer kandidaatclusters voldoen aan
deze eis.
7.3 Conclusie
87
Wel
dient te worden opgemerkt dat de resultaten van de recursieve methode nog veel
verbe-
terd kunnen worden doordat de postprocessing stappen reeds in de recursieve methode kunnen
gebeuren (minimum aantal documenten en de minimum tijdspanne).
Om de clustermethodes op
een objectieve manier te kunnen vergelijken, werden deze stappen echter niet uitgevoerd.
7.3
Conclusie
Op basis van de voorgaande resultaten kunnen we besluiten dat de beste Boosted BurstVSM-
voorstelling de log MSB-BurstVSM op basis van woorden met een DF-uitmiddelvenster van
1 dag is.
De resultaten van de verfijnde versie zijn ook zeer belovend, met een verdere reductie in het aan-
tal bursty-features en het aantal gevonden events.
Maar aangezien de resulterende F
1
-measure
daalt, maakt dit het moeilijk om deze versie te verkiezen.
Door gebruik te maken van eigennamen kunnen we verder de recall verhogen met minder bursty-
features ten koste van de precision.
Maar door beide soorten termen te combineren, is het enkel
mogelijk om de recall (sterk) te doen stijgen.
Gezien de sterke stijging in het resulterende aantal
bursty-features loont dit echter niet de moeite.
In onderstaande tabel zijn nu de resultaten van de beste Boosted BurstVSM-tekstvoorstellingen
weergegeven, samen met de resultaten van de oorspronkelijke BurstVSM en twee niet-temporele
tekstvoorstellingen.
TF-gewichten
TFIDF-
gewichten
BurstVSM Boosted
BurstVSM
intersimilarity
0.243
0.263
0.537
0.621
intrasimilarity
0.00387
0.00854
0.00597
0.00622
precision
0.728
0.695
0.730
0.693
recall
0.430
0.500
0.457
0.671
F
1
-measure
0.541
0.582
0.562
0.682
# events
3013
3099
2612
2630
Tabel
7.4:
Vergelijking van Boosted BurstVSM met andere tekstvoorstellingen
Hieruit kunnen we dus besluiten dat de Boosted BurstVSM-tekstvoorstelling inderdaad de beste
tekstvoorstelling is.
Vooral
de recall
is met deze voorstelling veel
hoger dan bij de andere.
De
verhouding van de inter- op de intrasimilarity is ook veel
hoger,
wat dus aantoont dat dit een
veel betere tekstvoorstelling is.
Het voordeel van deze BurstVSM-voorstellingen ten opzichte van de statische tekstvoorstellingen
is ook merkbaar.
Maar de eigenlijke verbetering van de voorstelling is niet volledig zichtbaar,
7.3 Conclusie
88
aangezien de gebruikte clustering reeds temporeel clustert.
Moesten we een algemeen clusteral-
goritme gebruiken die effectief alle documenten met elkaar vergelijkt, dan zou het voordeel van
de BurstVSM-voorstellingen nog veel duidelijker worden aangezien er enkel bij deze voorstellin-
gen temporele informatie vervat zit in de features.
Ten laatste kan opgemerkt worden dat het aantal
bekomen events nog steeds groot is.
Maar
dit is grotendeels te wijten aan de gebruikte clustermethode en vooral de laag gekozen M inP ts.
Zoals in sectie 7.2 vermeld,
kan het aantal
gevonden events drastisch verminderd worden door
enerzijds een grotere M inP ts te gebruiken en anderzijds door postprocessing stappen uit te
voeren.
CONCLUSIES
89
Hoofdstuk 8
Conclusies
In deze thesis werd een aanzet gedaan tot het bekomen van een volledig automatisch event-
detectie systeem.
Alle verschillende stappen werden hiervoor ge
¨
ımplementeerd.
De gevonden
events zijn ook bruikbaar om een volledig overzicht van gebeurtenissen te cre
¨
eren.
De huidige
implementatie is echter nog niet in staat om zonder verdere postprocessing-stappen een extrac-
tie te maken van een heel beknopte lijst enkel bestaande uit de meest belangrijke gebeurtenissen.
Tijdens de thesis werd de focus echter meer gelegd op het verbeteren en analyseren van de
bestaande tekstvoorstellingen in plaats van het concreet bekomen van deze beknopte lijst van
meest belangrijke gebeurtenissen.
We vertrokken voor de tekstvoorstelling van de BurstVSM-
tekstvoorstelling.
Na het analyseren van deze tekstvoorstelling werden de volgende concrete
verbeteringen gevonden:
• Verbetering van de bestaande BurstVSM-voorstelling door:
– het uitmiddelen van de documentfrequenties,
– het vervangen van de IDF-herweging van de bursty-features door de IDF-herweging
van de termen.
• Het
introduceren van een Boosted BurstVSM-model
die de gewichten van de bursty-
features boost op basis van de grootte van de corresponderende burst.
• Het verbeteren van de boosting voorgesteld in [Chi et al., 2009] door:
– het combineerbaar maken van de boosting met het gebruik van TFIDF-gewichten,
– het herdefini
¨
eren van het gebruikte burst-gewicht.
• Een aangepaste burst-detectie die leidt tot een nog compactere tekstvoorstelling (minder
bursty-features).
CONCLUSIES
90
Daarnaast werd een schaalbaar incrementeel clusteralgoritme ge
¨
ımplementeerd die lineair schaalt
met het aantal dagen in de corpus.
De kortere rekentijd van dit algoritme maakt het ideaal om
de kwaliteit van verschillende tekstvoorstellingen te vergelijken.
Verder hebben we ook de problematiek van de evaluatiemethodes aangetoond.
Deze kunnen we
samenvatten tot twee problemen bij het aanmaken van de referentieset:
• Er is geen concrete mathematische definitie van wat een event is en welke documenten hier
concreet moeten toebehoren.
De menselijke perceptie van de kwaliteit van de events en de
corresponderende documenten is dus heel subjectief.
• Iedere manuele selectie van documenten die bekomen werd zonder effectief alle documenten
in de corpus te onderzoeken zal met grote waarschijnlijkheid incompleet zijn.
Hieruit volgt dus dat de gebruikte referentieset niet als perfect beschouwd mag worden.
Dit is
van belang bij het interpreteren van de bekomen resultaten.
FUTURE WORK
91
Hoofdstuk 9
Future work
We bespreken nu enkele concrete mogelijke verbeteringen aan de gebruikte tekstvoorstellingen
en de evaluatiemethode.
Verdere verbeteringen aan de burst-gebaseerde tekstvoorstelling:
• Het gebruik van topic-modellen in combinatie met bursty-features.
Deze uitbreiding kan op
twee verschillende manier uitgevoerd worden, die beide afzonderlijk getest kunnen worden:
– Het defini
¨
eren van bursty-features als bursts van de topics.
– Het defini
¨
eren van topics als een lijst van bursty-features.
• Het combineren van verschillende aspecten van de corpora met behulp van een “max”-
functie zoals voorgesteld in [De Smet & Moens, 2009].
Concreet kan dan bijvoorbeeld
een topic-tekstvoorstelling gecombineerd worden met een bursty-tekstvoorstelling om een
betere tekstvoorstelling te bekomen.
• Het verbeteren van de burst-detectie door te werken met een 3-toestandsautomaat in
plaats van een 2-toestandsautomaat.
Concreet zou een burst dan ge
¨
ınitialiseerd kunnen
worden als de toestandsautomaat zich minstens ´e´en dag in toestand 2 bevindt (meest
bursty toestand,
corresponderend met een sterke piek).
De corresponderende burst kan
dan worden gedefinieerd als de aaneensluitende periode die deze dag omvat en waarin de
toestand van de toestandsautomaat minstens 1 (gewoon bursty toestand) is.
Op deze manier kunnen we dan bursts bekomen die enkel
ge
¨
ınitialiseerd worden als er
een sterke piek in de documentfrequenties is (uitfilteren van temporele termen), terwijl de
lengte van de burst gelijk blijft aan deze bij de normale burst-detectie.
Verdere verbeteringen aan de evaluatiemethode/referentieset:
• De documenten door meerdere personen laten annoteren om zo een meer objectieve refer-
entieset te bekomen.
• Effectief alle documenten annoteren in plaats van te vertrekken van een lijst documenten
verkregen met een query, om met zekerheid alle relevante documenten terug te vinden.
APPENDICES
92
Bijlage A
Appendices
A.1
Code Python-functie die clusters zoekt in minicorpus
Op de volgende twee pagina’s is de Python-functie weergegeven die per minicorpus-index wordt
uitgevoerd om de documenten te clusteren.
Hierbij
wordt dus gewerkt met zowel
sets,
lists als dictionaries om de performantie van de
implementatie te doen stijgen.
Een beschrijving van enkele entiteiten volgt hieronder:
newDocs:
dit is de dictionary die per minicorpus bijhoudt welke documenten van de mini-
corpus tot een cluster behoren.
Voor ieder document horende bij een cluster wordt dan
bijgehouden tot welke cluster ze behoort.
Dit gebeurt door zowel
het clusterid als een
boolean mee te geven die aanduidt of de cluster tot de KandidaatClusterset behoort of de
FinalClusterset.
oldDocs:
dit is de oude newDocs-dictionary die dus voor de documenten uit de vorige mini-
corpus bijhoudt tot welke clusters ze behoren.
DocClusterset:
dit is de set die bijhoudt in welke clusters een gegeven document voorkomt.
A.1 Code Python-functie die clusters zoekt in minicorpus
93
1
def
clustersimilarity ( self ,
selection ):
2
self . oldDocs = self . newDocs
3
self . newDocs ={}
4
KandidaatClusterset =[]
5
for
docid1 , simarray
in
enumerate ( self . index ):
6
DocClusterset = set ()
7
for
docid2 , docsim
in
enumerate ( simarray ):
8
if
docsim > self . eta :
9
if
docid1 != docid2 :
10
try :
11
# doc2
is
onderdeel
van
oldDocs
12
clusterid = self . oldDocs [ selection [ docid2 ]][0]
13
self . newDocs [ selection [ docid1 ]]=( clusterid , False )
14
self . FinalClusterset [ clusterid ]. add ( selection [ docid1 ])
15
DocClusterset . add (( clusterid , False ))
16
except
KeyError :
17
try :
18
# doc2
hoort
bij
newDocs
19
( clusterid , newCluster )= self . newDocs [ selection [ docid2 ]]
20
self . newDocs [ selection [ docid1 ]]=( clusterid , newCluster )
21
DocClusterset . add (( clusterid , newCluster ))
22
if
newCluster :
23
KandidaatClusterset [ clusterid ]. add ( selection [ docid1 ])
24
else :
25
self . FinalClusterset [ clusterid ]. add ( selection [ docid1 ])
26
except
KeyError :
27
# doc2
hoort
bij
geen
enkele
cluster
28
KandidaatClusterset . append ( set ([ selection [ docid1 ] , selection [ docid2 ]]))
29
self . newDocs [ selection [ docid1 ]]=( len ( KandidaatClusterset ) -1 , True )
30
self . newDocs [ selection [ docid2 ]]=( len ( KandidaatClusterset ) -1 , True )
31
DocClusterset . add (( len ( KandidaatClusterset ) -1 , True ))
32
else :
33
break
34
# # merge
alle
clusters
die
doc1
bevatten
35
#
start
met
FinalClusterset
36
finalCluster = None
37
oldClusterIds =[ clusterid
for
clusterid , newCluster
in
DocClusterset
if
not
newCluster ]
38
if
len ( oldClusterIds ) >0:
A.1 Code Python-functie die clusters zoekt in minicorpus
94
39
finalCluster = oldClusterIds [0]
40
if
len ( oldClusterIds ) >1:
41
for
tel
in
range (1 , len ( oldClusterIds )):
42
while
len ( self . FinalClusterset [ oldClusterIds [ tel ]]) >0:
43
docid = self . FinalClusterset [ oldClusterIds [ tel ]]. pop ()
44
self . FinalClusterset [ finalCluster ]. add ( docid )
45
if
docid
in
self . newDocs :
46
self . newDocs [ docid ]=( finalCluster , False )
47
else :
48
if
docid
in
self . oldDocs :
49
self . oldDocs [ docid ]=( finalCluster , False )
50
#
merge
nu
de
clusters
uit
KandidaatClusterset
51
newClusterIds =[ clusterid
for
clusterid , newCluster
in
DocClusterset
if
newCluster ]
52
if
len ( newClusterIds ) >0:
53
if
finalCluster != None :
54
for
tel
in
newClusterIds :
55
while
len ( KandidaatClusterset [ tel ]) >0:
56
docid = KandidaatClusterset [ tel ]. pop ()
57
self . FinalClusterset [ finalCluster ]. add ( docid )
58
self . newDocs [ docid ]=( finalCluster , False )
59
else :
60
if
len ( newClusterIds ) >1:
61
for
tel
in
range (1 , len ( newClusterIds )):
62
while
len ( KandidaatClusterset [ newClusterIds [ tel ]]) >0:
63
docid = KandidaatClusterset [ newClusterIds [ tel ]]. pop ()
64
KandidaatClusterset [ newClusterIds [0]]. add ( docid )
65
self . newDocs [ docid ]=( newClusterIds [0] , True )
66
##
filter
de
KandidaatClusterset
67
for
clusterid , cluster
in
enumerate ( KandidaatClusterset ):
68
if
len ( cluster ) < self . minclustersize :
69
for
docid
in
cluster :
70
self . newDocs . pop ( docid )
71
else :
72
for
docid
in
cluster :
73
self . newDocs [ docid ]=( len ( self . FinalClusterset ) , False )
74
self . FinalClusterset . append ( cluster )
A.2 Interpretatie TFIDF bij BurstVSM
95
A.2
Interpretatie TFIDF bij BurstVSM
In [Zhao et al., 2012]
wordt uitgelegd dat het gewicht van een bursty-feature in een document
berekend wordt door gebruik te maken van de TF-IDF methode.
Hierbij
wordt evenwel
niet
expliciet uitgelegd welke frequenties nu precies worden gebruikt om deze parameters te berekenen
(bv. het aantal documenten binnen een burst, het aantal documenten in de corpus etc.).
De bursty-feature wordt
in deze paper
ook voorgesteld als
een feature van een document,
net als een term een feature van een document is bij
een standaard VSM-tekstvoorstelling.
Aangezien we zoals in sectie 2.1.1 vermeld een gewicht nodig hebben horende bij een feature en
er in [Zhao et al., 2012] vermeld wordt dat er gebruik gemaakt wordt van de TF-IDF methode,
veronderstellen we dat de gekende TF-IDF methode toegepast wordt op de aanwezigheid van
de bursty-features.
Dit zou dus berekend moeten worden door het aantal
voorkomens van de
bursty-feature in het document (TF) te vermenigvuldingen met de IDF van de bursty-feature
(log N/(1 + DF )).
DF stelt hierbij dan het aantal
aantal
documenten voor waarin de bursty-
feature voorkomt en N het totaal aantal documenten in het corpus.
In de paper wordt concreet de volgende definitie van het bursty-feature gewicht gebruikt:
d
i,j
=
(
tf-idf
i,w
β
j
, if t ∈ [t
β
j
s
, t
β
j
e
]
0
, otherwise
(A.1)
Waarbij d
i,j
het gewicht van bursty-feature β
j
in document i voorstelt.
De periode van de burst
van de bursty-feature wordt voorgesteld door [t
β
j
s
, t
β
j
e
]
en w
β
j
stelt de bursty-term horende bij
de bursty-feature voor.
Tijdens het onderzoek in aanloop naar deze thesis, werd verondersteld dat deze bursty-term, net
zoals de bursty-feature,
enkel
tijdens de periode van de burst voorkomt.
De bursty-term werd
ge
¨
ınterpreteerd als de tekstuele voorstelling van de bursty-feature.
Het bovenstaande gewicht
tf-idf
i,w
β
j
kan dan ge
¨
ınterpreteerd worden als de TFIDF van de bursty-feature, maar ook als de
TFIDF van de bursty-term.
Beide hebben zijn namelijk even groot, maar aangezien de TF-IDF
methode oorspronkelijk gedefinieerd werd voor termen,
is de laatste voorstelling intu
¨
ıtiever te
interpreteren.
Er is echter een andere interpretatie mogelijk van het gegeven bursty-feature gewicht.
Als de
bursty-term namelijk gewoon een term zonder tijdsrestricties voorstelt, dan zou de TFIDF van
de bursty-term dus niet meer overeenkomen met de TFIDF van de bursty-feature.
Op deze
manier zou het gewicht van de bursty-feature bestaan uit de TFIDF van de corresponderende
niet-tijdsgebonden term.
De DF stelt dan namelijk het aantal
documenten over de volledige
corpus voor,
waar de term in voorkomt en TF het aantal
voorkomens van de de term in het
document.
Bij
nader inzien is dit wellicht ook de enige correcte interpretatie van het bursty-
feature gewicht in [Zhao et al., 2012]
aangezien de bursty-term voorgesteld wordt als de term
A.2 Interpretatie TFIDF bij BurstVSM
96
van de bursty-feature zonder dat de tijdsgebondenheid van deze term besproken wordt.
Aangezien deze alternatieve interpretatie pas in de laatste fase van de thesis naar boven kwam,
werd er
besloten om de opbouw niet
te wijzigen.
Aan het
werk dat
in deze thesis wordt
voorgesteld, met ook de bespreking van de experimenten en het inzicht in de invloed van param-
eters, verandert er namelijk niets.
Enkel de resultaten voor de referentiemethode zijn afhankelijk
van de precieze details van de methode van [Zhao et al., 2012].
BIBLIOGRAFIE
97
Bibliografie
[Agrawal et al., 2005]
Agrawal, R., Gehrke, J., Gunopulos, D. & Raghavan, P. 2005.
Automatic
subspace clustering of high dimensional data.
Data Mining and Knowledge Discovery, 11 (1),
5–33.
[Allan et al., 1998]
Allan,
J.,
Carbonell,
J.
G.,
Doddington,
G.,
Yamron,
J.
& Yang,
Y.
1998.
Topic detection and tracking pilot study final report.
[Allan et al., 2001]
Allan,
J.,
Gupta,
R.
& Khandelwal,
V.
2001.
Temporal
summaries of new
topics.
In Proceedings of the 24th annual
international
ACM SIGIR conference on Research
and development in information retrieval - SIGIR ’01 pp. 10–18, ACM Press, New York, New
York, USA.
[Allan et al., 2000]
Allan,
J.,
Lavrenko,
V.
& Jin,
H.
2000.
First story detection in TDT is
hard.
In Proceedings of
the ninth international
conference on Information and knowledge
management - CIKM ’00 pp. 374–381, ACM Press, New York, New York, USA.
[Allan et al., 1998]
Allan, J., Papka, R. & Lavrenko, V. 1998.
On-line new event detection and
tracking.
In Proceedings of the 21st annual international ACM SIGIR conference on Research
and development in information retrieval - SIGIR ’98 pp. 37–45, ACM Press, New York, New
York, USA.
[Beckmann et al., 1990]
Beckmann,
N.,
Kriegel,
H.-P.,
Schneider,
R.
& Seeger,
B.
1990.
The
R*-tree:
an efficient and robust access method for points and rectangles.
ACM SIGMOD
Record, 19 (2), 322–331.
[Bishop, 2007]
Bishop,
C.
2007.
Pattern Recognition and Machine Learning (Information Sci-
ence and Statistics).
1st ed. 20 edition, Springer.
[Blei et al., 2010]
Blei, D. M., Griffiths, T. L. & Jordan, M. I. 2010.
The nested chinese restau-
rant process and bayesian nonparametric inference of topic hierarchies.
Journal of the ACM,
57 (2), 1–30.
[Blei et al., 2003]
Blei, D. M., Ng, A. Y. & Jordan, M. I. 2003.
Latent dirichlet allocation.
The
Journal of Machine Learning Research, 3, 993–1022.
BIBLIOGRAFIE
98
[Chang, 2004]
Chang,
K. 2004.
Pebl:web page classification without negative examples.
IEEE
Transactions on Knowledge and Data Engineering, 16 (1), 70–81.
[Chen & Chundi, 2011]
Chen, W. & Chundi, P. 2011. Extracting Hot spots of Topics from Time
Stamped Documents.
Data & knowledge engineering, 70 (7), 642–660.
[Cheng et al., 2005]
Cheng,
D.,
Vempala,
S.,
Kannan,
R.
& Wang,
G.
2005.
A divide-and-
merge methodology for clustering. Proceedings of the twenty-fourth ACM SIGMOD-SIGACT-
SIGART symposium on Principles of database systems - PODS ’05, p. 196.
[Chi et al., 2009]
Chi, Y., Song, X., Zhou, D., Hino, K. & Tseng, B. L. 2009.
On evolutionary
spectral clustering.
ACM Transactions on Knowledge Discovery from Data, 3 (4), 1–30.
[De Smet & Moens, 2009]
De Smet,
W.
& Moens,
M.-F.
2009.
An aspect based document
representation for event clustering.
In Proceedings of
the 19th Meeting of
Computational
Linguistics in the Netherlands.
[Deerwester et al., 1990]
Deerwester,
S.,
Dumais,
S.
T.,
Furnas,
G.
W.,
Landauer,
T.
K.
&
Harshman,
R.
1990.
Indexing by latent semantic analysis.
Journal
of the American society
for information science, 41 (6), 391–407.
[Deleu et al., 2012]
Deleu,
J.,
De Moor,
A.,
Demeester,
T.,
Vermeulen,
B.
& Demeester,
P.
2012.
Named entity recognition on flemish audio-visual
and news-paper archives.
In 12th
Dutch-Belgian Information Retrieval
Workshop,
Proceedings pp.
38–41,
Ghent University,
Department of Information technology.
[Efron, 2010]
Efron,
M.
2010.
Linear Time Series Models for Term Weighting in Information
Retrieval Context of this Research.
Journal of the American Society for Information Science
and Technology, 61, 1299–1312.
[Ester et al., 1996]
Ester,
M.,
Kriegel,
H.-P.,
Sander,
J.
& Xu,
X.
1996.
A density-based algo-
rithm for discovering clusters in large spatial databases with noise.
Kdd.
[Feng & Allan, 2009]
Feng,
A.
& Allan,
J.
2009.
Incident threading for news passages.
In
Proceedings of
the 18th ACM conference on Information and knowledge management
pp.
1307–1316, ACM.
[Fivelstad, 2007]
Fivelstad,
O.
K.
2007.
Temporal
text mining:
the ttm testbench.
Master’s
thesis Norwegian University of Science and Technology.
[Forney, 1973]
Forney, G. 1973. The viterbi algorithm. Proceedings of the IEEE, 61 (3), 268–278.
[Fung et al., 2005]
Fung,
G.
P.
C.,
Yu,
J.
X.,
Yu,
P.
S.
& Lu,
H.
2005.
Parameter free bursty
events detection in text streams.
ReCALL, 22, 181–192.
[Getoor, 2007]
Getoor, L. 2007.
Introduction to statistical
relational
learning.
BIBLIOGRAFIE
99
[He et al., 2007]
He,
Q.,
Chang,
K.,
Lim,
E.
& Zhang,
J.
2007.
Bursty feature representation
for clustering text streams.
Proc. SIAM Conference on Data Mining, pp. 491–496.
[Hofmann, 1999]
Hofmann,
T.
1999.
Probabilistic latent semantic indexing.
In Proceedings
of
the 22nd annual
international
ACM SIGIR conference on Research and development
in
information retrieval
- SIGIR ’99 pp. 50–57, ACM Press, New York, New York, USA.
[Huang et al., 2008]
Huang, L., Wang, L. & Li, X. 2008. Achieving both high precision and high
recall in near-duplicate detection.
In Proceeding of the 17th ACM conference on Information
and knowledge mining - CIKM ’08 p. 63, ACM Press, New York, New York, USA.
[Jo et al., 2011]
Jo, Y., Hopcroft, J. E. & Lagoze, C. 2011.
The web of topics.
In Proceedings of
the 20th international
conference on World wide web - WWW ’11 p.
257,
ACM Press,
New
York, New York, USA.
[Jurafsky & James, 2000]
Jurafsky,
D.
& James,
H.
2000.
Speech and language processing an
introduction to natural language processing, computational linguistics, and speech.
[Kim et al., 2012]
Kim,
J.
H.,
Kim,
D.,
Kim,
S.
& Oh,
A.
2012.
Modeling topic hierarchies
with the recursive chinese restaurant process.
In Proceedings of the 21st ACM international
conference on Information and knowledge management - CIKM ’12 p. 783, ACM Press, New
York, New York, USA.
[Kleinberg, 2003]
Kleinberg, J. 2003. Bursty and hierarchical structure in streams. Data Mining
and Knowledge Discovery, pp. 373–397.
[Manning et al., 2008]
Manning,
C.
D.,
Raghavan,
P.
& Sch
¨
utze,
H.
2008.
Introduction to in-
formation retrieval.
Cambridge University Press Cambridge.
[Mei & Zhai, 2005]
Mei,
Q.
& Zhai,
C.
2005.
Discovering evolutionary theme patterns from
text.
In Proceeding of
the eleventh ACM SIGKDD international
conference on Knowledge
discovery in data mining - KDD ’05 p. 198, ACM Press, New York, New York, USA.
[Mei & Zhai, 2006]
Mei,
Q.
& Zhai,
C.
2006.
A mixture model
for contextual
text mining.
In
Proceedings of the 12th ACM SIGKDD international
conference on Knowledge discovery and
data mining - KDD ’06 p. 649, ACM Press, New York, New York, USA.
[MIT Libraries, 2013]
MIT Libraries,
C.
2013.
SIMILE Project.
http://simile.mit.edu/.
Bezocht 8 maart, 2013.
[Ozmutlu, 2006]
Ozmutlu,
S.
2006.
Automatic new topic identification using multiple linear
regression.
Information Processing & Management, 42 (4), 934–950.
[Pan & Mitra, 2011]
Pan, C.-C. & Mitra, P. 2011.
Event detection with spatial latent Dirichlet
allocation.
In Proceeding of
the 11th annual
international
ACM/IEEE joint
conference on
Digital
libraries - JCDL ’11 p. 349, ACM Press, New York, New York, USA.
BIBLIOGRAFIE
100
[Radim & Sojka, 2010]
Radim, R. & Sojka, P. 2010.
Petr. Software Framework for Topic Mod-
elling with Large Corpora.
Proceedings of LREC 2010 Workshop on New Challenges for NLP
Frameworks, pp. 45–50.
[Radinsky et al., 2011]
Radinsky,
K.,
Agichtein,
E.,
Gabrilovich,
E.
& Markovitch,
S.
2011.
A
Word at a Time :
Computing Word Relatedness using Temporal
Semantic Analysis.
ACM,
pp. 337–346.
[Salton & Buckley, 1988]
Salton,
G.
& Buckley,
C.
1988.
Term-weighting approaches in auto-
matic text retrieval.
Information Processing & Management, 24 (5), 513–523.
[Setchi et al., 2010]
Setchi, R., Jordanov, I., Howlett, R. J. & Jain, L. C., eds 2010.
Knowledge-
Based and Intelligent Information and Engineering Systems,
vol.
6277,
of
Lecture Notes in
Computer Science.
Springer Berlin Heidelberg, Berlin, Heidelberg.
[Shaparenko & Joachims, 2007]
Shaparenko,
B.
& Joachims,
T.
2007.
Information genealogy.
In Proceedings of
the 13th ACM SIGKDD international
conference on Knowledge discovery
and data mining - KDD ’07 p. 619, ACM Press, New York, New York, USA.
[Sutton & McCallum, 2010]
Sutton,
C.
& McCallum,
A.
2010.
An introduction to conditional
random fields.
arXiv preprint arXiv:1011.4088, 50.
[Swan & Allan, 1999]
Swan,
R.
& Allan,
J.
1999.
Extracting significant time varying features
from text. In Proceedings of the eighth international conference on Information and knowledge
management - CIKM ’99 pp. 38–45, ACM Press, New York, New York, USA.
[Swan & Allan, 2000]
Swan,
R. & Allan,
J. 2000.
Automatic generation of overview timelines.
In Proceedings of
the 23rd annual
international
ACM SIGIR conference on Research and
development
in information retrieval
- SIGIR ’00 pp.
49–56,
ACM Press,
New York,
New
York, USA.
[Wang et al., 2007]
Wang,
X.,
Zhai,
C.,
Hu,
X.
& Sproat,
R.
2007.
Mining correlated bursty
topic patterns from coordinated text streams.
In Proceedings of
the 13th ACM SIGKDD
international
conference on Knowledge discovery and data mining - KDD ’07 p.
784,
ACM
Press, New York, New York, USA.
[Wayne, 2000]
Wayne,
C.
2000.
Multilingual
topic detection and tracking:
Successful
research
enabled by corpora and evaluation.
Language resources and evaluation conference, pp. 1487–
1494.
[Yang et al., 1999]
Yang,
Y.,
Jaime,
Q.,
Brown,
R.
D.,
Pierce,
T.
& Liu,
X.
1999.
The TDT
program.
IEEE Intelligent Systems, .
[Yang et al., 1998]
Yang,
Y.,
Pierce,
T.
& Carbonell,
J.
1998.
A study of
retrospective and
on-line event detection.
Proceedings of the 21st annual international ACM SIGIR conference
on Research and development in information retrieval - SIGIR ’98, pp. 28–36.
BIBLIOGRAFIE
101
[Zhai et al., 2004]
Zhai,
C.,
Velivelli,
A.
& Yu,
B.
2004.
A cross-collection mixture model
for
comparative text mining.
In Proceedings of the 2004 ACM SIGKDD international conference
on Knowledge discovery and data mining - KDD ’04 p.
743,
ACM Press,
New York,
New
York, USA.
[Zhao et al., 2012]
Zhao, W., Chen, R., Fan, K., Yan, H. & Li, X. 2012. A novel burst-based text
representation model
for scalable event detection.
Proceedings of the 50th Annual
Meeting
of the Association for Computational Linguistics:
Short Papers-Volume 2, (July), 43–47.
