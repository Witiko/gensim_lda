Procedia - Social and Behavioral Sciences 236 ( 2016 ) 71 – 75 
Available online at www.sciencedirect.com
ScienceDirect
1877-0428 © 2016 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license 
(http://creativecommons.org/licenses/by-nc-nd/4.0/).
Peer-review under responsibility of the National Research Nuclear University MEPhI (Moscow Engineering Physics Institute).
doi: 10.1016/j.sbspro.2016.12.022 
International Conference on Communication in Multicultural Society, CMSC 2015, 6-8 December 
2015, Moscow, Russian Federation 
Automatic detection of verbal aggression for Russian and American 
imageboards 
Denis Gordeev
a,b,
* 
a
National Research Nuclear University MEPhI (Moscow Engineering Physics Institute), Kashirskoe shosse 31, Moscow 115409, Russian 
Federation 
b
Moscow State Linguistic University, Ostozhenka, 38, Moscow 119034, Russian Federation 
Abstract 
The problem of aggression for Internet communities is rampant. Anonymous forums usually called imageboards are notorious for 
their aggressive and deviant behaviour even in comparison with other Internet communities. This study is aimed at learning ways 
of automatic detection of verbal aggression for the most popular American (4chan.org) and Russian (2ch.hk) imageboards. The 
study material consists of 1,802,789 messages. The machine learning algorithm word2vec was applied to detect the state of 
aggression. A decent result is obtained for English (88%), the results for Russian are yet to be improved. 
© 2016 The Authors. Published by Elsevier Ltd. 
Peer-review under responsibility of the National Research Nuclear University MEPhI (Moscow Engineering Physics Institute). 
Keywords:
Aggression; word2vec; imageboard; 4chan; 2ch; cyberbullying; random forest 
1.
Introduction 
The Internet is sometimes considered a quite violent and rude place. Many people, especially active users, face 
with cyberbullying and other expressions of aggression on a daily basis. For example, the U.S. Department of Health 
& Human Services has launched an initiative to stop bullying, including Internet bullying [A]. According to the 
article 282 from the Russian criminal code, hate speech on the Internet is punishable by a fine of up to 300 thousand 
rubles or a sentence of up to 4 years [B]. However, this law does not give any criteria for distinguishing messages 
* Corresponding author. Tel.: +7-495-788-5699; fax: +7-499-324-2111. 
E-mail address:
DIGordeyev@mephi.ru 
© 2016 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license 
(http://creativecommons.org/licenses/by-nc-nd/4.0/).
Peer-review under responsibility of the National Research Nuclear University MEPhI (Moscow Engineering Physics Institute).
72 
Denis Gordeev / Procedia - Social and Behavioral Sciences 236 ( 2016 ) 71 – 75 
arousing hate and it is a task for linguists. Imageboards that have been a buzzword for a while are considered a truly 
epicentre of all kind of unruly behaviours that we can find on the Net. For example, they are called ‘the Internet hate 
machine’ (Bernstein, Monroy-Hernández, Harry, André, Panovich, and Vargas, 2011). 
Imageboards are usual Internet forums with no registration. Messages contain no personal details, only the text, 
date and email. However, registration mechanisms are not implemented and emails are not checked. Personal 
tripcodes are the only means to state your identity but they are used only in about 4% of cases (Bernstein, Monroy-
Hernández, Harry, André, Panovich, and Vargas, 2011). It is only natural that aggression will flourish in such an 
environment where nobody can track you and where there are no social limits. Nevertheless, Potapova and Gordeev 
(2015) have shown that it may be not true for Russian Internet communities, although the results are still disputed. 
In this research, we study aggression in the environment where it is vividly presented and is not constrained by 
social boundaries. This research is also important because it is one of the first works on automatic detection of verbal 
aggression. We also publish our trained neural model online that can be used by other scientists to find word 
similarities for imageboards and compare them with other sites. Moreover, our methods may be used for training 
other word similarities models, but the procedure may change for languages that have no explicit word boundaries 
and in other difficult cases. 
2.
Related works 
Many researchers deal with aggression and its representation on the Internet. Potapova has been investigating 
aggression (Potapova and Komalova, 2014) and compiled a Russian dictionary containing words describing this 
emotional state (Potapova and Komalova, 2015). Bernstein has conducted a research on 4chan and imageboard 
culture (Bernstein, Monroy-Hernández, Harry, André, Panovich, and Vargas, 2011). The task of sentiment analysis 
is rather close to aggression analysis because both deal with detection of different human emotions. Twitter and 
social networks sentiment analysis is especially close to our research field, because the majority of anonymous 
forums messages are short, e.g. a 4chan message contains 15 words on average (Potapova and Gordeev, 2015) and 
there are no more than 140 symbols for a Twitter post. Numerous papers has been published on this and adjacent 
topics in recent years. Cerrea et al. studied the influence of complete anonymity on the users' behavior (Correa, 
Silva, Mondal, Benevenuto, and Gummadi, 2015) in comparison with partial anonymity of Twitter. They have 
found that users tend to be more open and are more ready to express negative emotions (not only aggression) in 
anonymous environment. However, they have studied a site Whisper designed to share secrets and confessions, and 
it may influence their results. Martínez-Cámara has conducted an overview of different methods for Twitter 
sentiment analysis (Martínez-Cámara, Martín-Valdivia, Ureña-López, and Montejo-Ráez, 2014). Another research 
was done by Dos Santos. He successfully (from 76% to 88% for various measurement sets) detected the sentiment 
for Twitter messages (Dos Santos, 2014) without using any handcrafted features. Tang and Wei analyzed Twitter 
sentiments using emoticons, smileys and neural networks (Tang, Wei, Yang, Zhou, Liu, and Qin, 2014). As we see, 
many modern studies use machine learning and neural networks methods for sentiment detection. However, 
Paltoglou (2012) asserts that 'unsupervised' dictionary-based methods outperform 'state-of-the-art' machine learning. 
Nevertheless, he does not mention any deep learning or neural network-based algorithms, and his results are difficult 
to apply to other languages, besides English. 
3.
Methods and materials 
Our study is focused on automatic identification of aggression for Russian and American imageboards. We have 
chosen 2ch.hk and 4chan.org as the most prominent and popular imageboards for their respective countries [С]. 
Aggression was detected by our algorithm based on the neural network library word2vec (Mikolov, Chen, 
Corrado, and Dean, 2013) and its Gensim (Řehůřek & Sojka, 2010) implementation for the Python programming 
language. Word2vec is an unsupervised algorithm that allows finding semantic relations and distances between 
words without any annotation or other data preprocessing. Nowadays this method is considered to be the best for 
determining semantic relations between words (Arefyev, Lesota, and Lukanin, n.d.). Although, some researchers 
argued that their systems performed better. For example, J. Pennington and R. Socher offered an algorithm called 
GloVe (Global Vectors for Word Representations) and proved that it outperforms word2vec (Pennington, Socher, 
73
Denis Gordeev / Procedia - Social and Behavioral Sciences 236 ( 2016 ) 71 – 75 
Manning, JeffreyPennington, Manning, Pennington et al., 2014). However, other researchers found that word2vec is 
better in majority of cases and not so computationally expensive (a quadratic difference) (Konopík and Praz
̆
ák, 
2015). 
First of all, we prepared the data for a more efficient training of a word2vec neural network. For training we used 
654,047 4chan.org messages and 1,148,692 2ch.hk messages. We removed stopwords (some pronouns, articles, 
prepositions and other not meaningful words and phrases) based on nltk-toolkit stopword list (Bird, 2006). Then we 
turned tokens to their types for the Russian and English language using Snowball stemmer from nltk library that 
uses simplified rules of word inflection. The stemmer doesn’t consider context while prescribing type to a token but 
we needed to boost individual word occurrences to train our model more efficiently. Moreover, word2vec analyses 
the context of every word. After that we found set phrases for pairs of words that occur in some contexts 
significantly more often than in other and included these phrases in our model (for example, New and York make a 
phrase New_York because they occur together more often than in many other contexts). We did it with the help of 
Gensim package. We used word2vec neural net algorithm to train two models, one for each analyzed imageboard. 
Then we built an automatic scikit-learn (Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel et al., 2011) 
implemented random forest classifier which we trained on manually annotated corpus of about 1000 messages (1308 
messages for Russian, 1027 for English). 90% of messages were used for training and 10% for later evaluation. 
Annotation included only information whether this message is aggressive or not. Random forest classifier builds a 
tree of decisions based on some criteria (in our case, if the message is similar to manually chosen words typical for 
aggressive messages, the highest and the lowest similarity between words in the analyzed message to words typical 
for aggressive messages, average semantic distance of words in the message to some manually chosen words and 
phrases that are typical for aggressive messages, as well as average, maximum and minimum length of words and 
messages). Two professionally trained linguists participated in the annotation. We have manually chosen 5 words 
for English and 5 for Russian as words most typical for aggressive messages (obscene as well as not obscene, for 
example ‘вали’ or ‘be off’). We tried using k-means clusterizing (MacQueen, 1967) to choose aggressive words 
automatically but we failed to get any advance with this method. After that we tested our trained classifier on 10% 
of the data and tried to detect whether these messages contain aggression or not. Finally, we have found the most 
important criteria for the classification (see Table 1). The most important features for the English language are the 
average semantic difference between words in a message and difference between maximum and minimum distance 
to the chosen wordset. It corresponds to our expectations and shows us that the message as a whole is more 
important for the detection of aggression than some obscene or other keywords. However, the closest distance to our 
wordset is important, too. However, we expect that the importance of this criterion will decrease as we will add new 
features that take grammatical and syntactic features into consideration. We successfully detected aggression in 88% 
of cases for the English language. However, for the Russian language our detection ratio is only 59% and the closest 
distance to the chosen wordset is the most important feature. It means that the classifier pays too much attention to 
individual rude or obscene words while the message as a whole may not be aggressive. Thus, it is vital to include 
some grammar and syntactic criteria to improve the results. 
Table 1. Random forest feature importance. 
Language 
(Imageboard) 
Percentage of 
correct 
classification 
(
%
) 
Weights of different parameters (Total – 1) 
Difference 
between 
maximum 
and minimum 
distance to 
the chosen 
wordset 
Max closest 
distance to 
the chosen 
wordset 
Average 
length of a 
word in 
message 
Average 
distance of 
words in a 
message to 
the chosen 
wordset 
Average 
semantic 
distance 
between 
words in a 
message 
Other 
parameters 
Russian 
(2ch.hk) 
59.13 
0.158 
0.156 
0.037 
0.158 
0.150 
0.341 
English 
(4chan.org) 
88.40 
0.157 
0.157 
0.139 
0.122 
0.109 
0.316 
74 
Denis Gordeev / Procedia - Social and Behavioral Sciences 236 ( 2016 ) 71 – 75 
4. Discussion of results 
The results for the English language are quite decent (88%) and after some additional testing and evaluation, the 
method may be used in practice. 
Unfortunately, the results of automatic classification are very low for the Russian language. It may be connected 
with grammar and syntactic complexity of Russian. There are more tokens for one type form in Russian that is why 
the amount of annotated and not annotated data should be increased. We may also include some other information 
like parts of speech and other grammar characteristics (for example, information about imperative verb forms may 
be useful for detecting aggression) as well as paradigmatic features, e.g. punctuation, emoticons, capitalization. 
Switching machine learning Random Forest algorithm to support-vector machines or some neural networks-based 
method may also help. 
5. Conclusion 
All in all we have gained a decent result for automatic aggression detection for the English language (88%). We 
used word2vec models to find similarities between words and applied random forest classifier to judge whether a 
message is aggressive or not based on similarity of the message to a manually selected set of words. Yet our method 
may be still improved with the help of other features and parameters. However, the results of automatic aggression 
detection for the Russian language leave much to be desired (59%). It is possible that lexical criteria are insufficient 
for aggression detection in Russian messages. 
We 
are going 
to 
focus on 
considering and 
applying tagging 
of parts 
of 
speech 
and other 
grammatical 
characteristics of the text (for example, taking in consideration imperative verb forms seems to us very promising) in 
future research. We also would like to implement a doc2vec approach suggested by Le and Mikolov (Le and 
Mikolov, 2014) or other similar method. 
Acknowledgements 
The survey was partially funded by the Russian Science Foundation (RSF) in the framework of the project № 14-
18-01059 at Institute of Applied and Mathematical Linguistics of the Moscow State Linguistic University (scientific 
head of the project – R. K. Potapova). 
References 
Arefyev, 
N., 
Lesota, 
O., 
and 
Lukanin, 
А. 
(n.d.). 
Evaluating 
three 
corpus-based 
semantic 
similarity 
systems 
for 
Russian. 
URL: 
/citations?view_op=view_citation&continue=/scholar%3Fhl%3Den%26as_sdt%3D0,5%26scilib%3D1&citilm=1&citation_for_view=GGyy
B6QAAAAJ:9yKSN-GCB0IC&hl=en&oi=p (accessed on 23.10.2015). 
Bernstein, M., Monroy-Hernández, A., Harry, D., André, P., Panovich, K., and Vargas, G. (2011). 4chan and /b/: An analysis of anonymity and 
ephemerality in a large online community. 
Proc. Fifth Int. AAAI Conf. Weblogs Soc. Media,
pp. 50–57. DOI: 10.1.1.207.9761. 
Bird, S. (2006). NLTK: the natural language toolkit. 
Proc. COLING/ACL Interact. Present. Sess., Association for Computational Linguistics,
pp. 
69–72. 
Correa, D., Silva, L.A., Mondal, M., Benevenuto, F., and Gummadi, K.P. (2015). The many shades of anonymity: characterizing anonymous 
social 
media 
content. 
Proc. 
9th 
Int. 
AAAI 
Conf. 
Weblogs 
Soc. 
Media
, 
Oxford, 
UK. 
URL: 
http://pubman.mpdl.mpg.de/pubman/faces/viewItemOverviewPage.jsp?itemId=escidoc:2144344 (accessed on 26.10.2015). 
Dos Santos, C.N. (2014). Think positive: towards Twitter sentiment analysis from scratch. 
Semeval-2014,
647–651. 
Konopík, M., and Praz
̆
ák, O. (2015). Information sources of word semantics methods. 
Speech Comput., Springer,
pp. 243–250. 
Le, Q., and Mikolov, T. (2014). Distributed representations of sentences and documents. 
Proceedings of the 31st International Conference on 
Machine Learning
, Beijing, China, 2014. JMLR: W&CP volume 32. URL: https://cs.stanford.edu/~quocle/paragraph_vector.pdf (accessed 
on 25.10.2015). 
MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations. 
Proc. Fifth Berkeley Symp. Math. Stat. Probab.
, 
Oakland, CA, USA, pp. 281–297. 
Martínez-Cámara, E., Martín-Valdivia, M.T., Ureña-López, L.A., and Montejo-Ráez, a R. (2014). Sentiment analysis in Twitter. 
Nat. Lang. Eng., 
20,
1–28. DOI: 10.1017/S1351324912000332. 
Mikolov, T., Chen, K., Corrado, 
G., and Dean, J. (2013). 
Efficient estimation of word representations in vector space, arXiv Prepr. 
arXiv1301.3781. URL: http://arxiv.org/abs/1301.3781 (accessed on 26.10.2015). 
75
Denis Gordeev / Procedia - Social and Behavioral Sciences 236 ( 2016 ) 71 – 75 
Paltoglou, G., and Thelwall, M. (2012). Twitter, MySpace, Digg: unsupervised sentiment analysis in social media. 
ACM Trans. Intell. Syst. 
Technol., 3
, 1–19. DOI: 10.1145/2337542.2337551. 
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O. et al. (2011). Scikit-learn: machine learning in Python. 
J. Mach. 
Learn. Res., 12,
2825–2830. 
Pennington, J., Socher, R., Manning, C.C., JeffreyPennington, R., Manning, C.C., Pennington, J. et al. (2014). Glove: global vectors for word 
representation. 
Proc. Empiricial Methods
, Association for Computational Linguistics, Stroudsburg, PA, USA, pp. 1532–1543. DOI: 
10.3115/v1/D14-1162. 
Potapova, R., and Gordeev, D. (2015). Determination of the Internet anonymity influence on the level of aggression and usage of obscene lexis 
BT. 
Proceedings of the 17th International conference Speech and Computer (SPECOM 2015)
. Athens, Greece, September 20-24, 2015. 
Patras: University of Patras Press, pp. 29–36. 
Potapova, R., and Komalova, L. (2014). On principles of annotated databases of the semantic field “Aggression”. 
Speech and Computer.
Springer 
International Publishing. DOI: 10.1007/978-3-319-11581-8_40. 
Potapova, R., and Komalova, L. (2015). 
Verbalnaya struktura kommunikativnogo akta agressii: Tematicheskiy tolkovuy slovar.
Issue. 1. Moscow: 
Institut nauchnoi informatsii po obschestvennym naukam RAN. 
Řehůřek, R., and Sojka, P. (2010). Software framework for topic modelling with large corpora. 
Proc. Lr. 2010 Work. New Challenges NLP Fram
., 
ELRA, Valletta, Malta, 2010, pp. 45–50. 
Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., and Qin, B. (2014). Learning sentiment-specific word embedding for twitter sentiment 
classification. 
Proc. 52nd Annu. Meet. Assoc. Comput. Linguist
, pp. 1555–1565. 
Sources 
[A] ASPA, What is Cyberbullying, (2012). http://www.stopbullying.gov/cyberbullying/what-is-it/ (accessed October 24, 2015). 
[B] Russian Criminal Code, art. 282 
[С] Alexa Top 500 Global Sites, (n.d.). http://www.alexa.com/topsites (accessed October 26, 2015). 
