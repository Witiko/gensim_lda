Domain Ontology Induction using Word
Embeddings
Niharika Gupta
IIIT Delhi
niharika1416@iiitd.ac.in
Sanjay Podder,
Annervaz K M,
Shubhashis Sengupta
Accenture Technology Labs
{
sanjay.podder,
annervaz.k.m,
shubhashis.sengupta
}
@accenture.com
Abstract—Ontology, the shared formal conceptualization of do-
main information,
has been shown to have multiple applications
in modeling, processing and understanding natural language text.
In this
work,
we use distributed word vectors
out
of
various
recent language models from Deep Learning for semi-automated
domain ontology creation for closed domains. We cover all major
aspects
of
Domain Ontology
Induction or
Learning like
con-
cept identiﬁcation,
attribute identiﬁcation,
taxonomical and non-
taxonomical relationship identiﬁcation using the distributed word
vectors.
Preliminary results show that
simple clustering based
methods
using distributed word vectors
from these
language
models outperforms methods using models like LSI in ontology
learning for closed domains.
Index Terms—Language Modeling,
Deep Learning,
Natural
Language Processing,
Ontology Learning,
Word Vectors,
Clus-
tering,
Latent Semantic Indexing
I.
I
NTRODUCTION AND
M
OTIVATION
The word Ontology has different
contextual
meanings in
literature.
One
of
its
main usage
is
to denote
a
formal
conceptualization of
the information pertaining to a domain
[Fensel,
2001].
In this context,
it
is referred to as a Domain
Ontology;
to distinguish from an Upper Ontology [Biemann,
2005] which considers more generic or commonsensical con-
ceptualization of knowledge.
In domain ontologies,
important
entities from the domain are represented in terms of concepts
and attributes of the concepts.
The taxonomical(hierarchical)
and non-taxonomical
relationships between concepts are also
included in speciﬁcation. For example, in Pharmacovigilance,
a domain where the adverse events
of
clinical
drug usage
from users
are collected and analyzed,
some of
the main
concepts
are Drug,
Disease,
Procedure,
Person,
Physician,
Organization,
Age,
Date etc.
The concept
Physician comes
taxonomically under Person,
similarly Hospital
under Orga-
nization.
Person can have Age as an attribute.
An example
of non-taxonomical relationship in this case is between Drug
and Disease,
which represents that
drug is associated with
disease through relationships
such as
drug treats
or
cures
disease.
Thus,
the
domain ontology speciﬁcation contains
mainly concepts, attribute relationships, taxonomical and non-
taxonomical
relationships related to a particular
domain.
In
addition,
ontology speciﬁcation contains
axioms
capturing
the constraints in the relationships.
In this work,
we do not
consider these axioms. For our purpose ontology is deﬁned as
O
=
{C
,
A
,
T
,
N }
, representing the set of concepts, attributes,
taxonomical,
and non-taxonomical relationships respectively.
The applications of ontology are many - ranging from cap-
ture of information to natural language text understanding by
computer systems [Poli et al., 2010]. In the Pharmacovigilance
example,
a natural
language sentence,
Ameera was
started
on Ciproxin for
infection from 23rd December,
has
to be
deconstructed and the tokens have to be mapped to concepts
like Person, Drug, Disease and Date and relationships between
them to facilitate the automated processing of the information.
Here, we have to identify Ameera as a Person, of type Patient.
Ciproxin as
a Drug.
infection as
a type of
Disease.
23rd
December is a Date. Also, the drug start date and drug disease
relationships holds between
{
23rd December,Ciproxin
}
and
{
infection,Ciproxin
}
respectively.
Multiple approaches using
machine learning and various heuristics have been proposed
for doing this.
Typical
Machine Learning approach used for
such tasks is to use Named Entity Recognition [Sharnagat,
2014] for identiﬁcation of the concepts and various classiﬁer
schemes for identifying the relationships.
However the main
concepts and relationships have to be pre-instantiated before
posing the task as a machine learning problem.
Hence,
for
the purpose of automated processing of information in natural
language
text,
a
domain ontology is
required in the
ﬁrst
place.
But
the creation of
such domain ontology requires
intensive manual
effort,
and therefore time consuming and
costly.
The
completeness
of
a
manually curated ontology
cannot be guaranteed. It is in this context the ontology learning
from unstructured domain text
gained prominence in the last
decade [Wong et
al.,
2012]
[Maedche and Staab,
2004].
In
this
work,
we have used the recent
advances
in language
modeling [Mikolov et al.,
2013a; Pennington et al.,
2014] for
effective ontology learning from unstructured text in a domain.
The rest
of the paper is structured as follows - in the next
section,
we describe the major related work in this space.
In
section III,
we brieﬂy describe the various word embeddings
and distributed word vectors
from deep learning literature.
We describe our
approach and algorithms in section IV.
In
section V,
we provide experimental
results and evaluations.
We conclude with section VI
pointing out
some interesting
future work directions.
II.
R
ELATED
W
ORK
Ontology induction has multiple focus areas; namely learn-
ing ontology from scratch,
ontology extension and ontology
population [Biemann, 2005]. Here, we focus more on learning
2016 15th IEEE International Conference on Machine Learning and Applications
978-1-5090-6167-9/16 $31.00 © 2016 IEEE
DOI 10.1109/ICMLA.2016.81
115
from scratch.
Hierarchical
Clustering [Grira et
al.,
2004] on
the extracted terms or nouns has been the main approach for
learning ontology from scratch.
Different
kinds of similarity
measures have been deﬁned between the noun terms to carry
out
the clustering.
The approaches for deﬁning the similarity
measures can be roughly divided into three main categories:
1)
The ﬁrst is based on syntactic relationships like predicate
argument relations.
2)
The second is based on co-occurrences in a given context
window,
which does not rely on parsing.
3)
The
third approach is
based on speciﬁc
patterns
of
occurrence of words, known as Hearst Patterns [Hearst,
1992].
For
a comprehensive and detailed coverage of
the area,
please
refer
[Buitelaar
et
al.,
2005]
[Maedche
and Staab,
2004].
Another
similar
and connected stream of
work is that
of
Knowledge Graph [Singhal,
2012]
creation and completion.
But
in this stream of
work,
the base ontology induction is
rarely targeted,
but
rather
instance population for
concepts
and relationships is addressed. This recent work [Nimishakavi
et
al.,
2016] uses Tensor Factorization for concept
and rela-
tionship induction for a domain.
The Word Embeddings derived from Neural
Probabilistic
Language Modeling(NPLM)
[Bengio et
al.,
2003]
roughly
falls into second category in the list
above,
as they are also
based on the co-occurrences in a given context
window.
But
other recent forms of embeddings have been shown to capture
more semantic relationships between words [Mikolov et
al.,
2013b].
III.
W
ORD
E
MBEDDINGS
You shall
know a word by the company it
keeps (Firth,
J.
R.
1957:11),
is one of
the most
inﬂuential
idea in NLP.
Multiple
models
for
representing a
word as
a
numerical
vector,
based on the context
it
appears,
stems from this idea.
Such vector representations for words has been proposed in
multiple models,
including the well
known Latent
Semantic
Indexing(LSI) [Dumais, 2004]. Here, each word is represented
as
a
vector
depicting the
contexts
in which they appear
and the technique of
Singular
Value Decomposition(SVD)
is applied on the constructed term-document
matrix(or term-
term matrix),
to come up with low dimensional vector repre-
sentation for
words.
The non interpretability of
the vectors
along with high computational
cost
for
carrying out
SVD
prevented the large scale adoption of
this technique.
Vector
representations for
words in the context
of
neural
networks
was
proposed in [Bengio et
al.,
2003].
In this work,
each
word in the vocabulary is assigned a Distributed Word Feature
Vector
∈ R
m
.
The
probability distribution of
word se-
quences,
P
(
w
t
|
w
t−(n−1)
, .., w
t−1
)
, is then expressed in terms
of these word feature vectors,
and word feature vectors and
parameters of the probability function(a neural
network) are
learned together
by training a suitable feed-forward neural
network [Haykin, 1998] to maximize the log-likelihood of the
text corpora. Each occurrence of a text snippet of ﬁxed window
size(deﬁned hyper parameter) is considered here as a training
sample. Inspired from this model
[Mikolov et al., 2013a] pro-
posed two new models - Continuous Bag Of Words(CBOW)
and Skip-gram Model.
CBOW architecture tries
to predict
the current
word given the previous
and next
surrounding
words,
discarding the word order,
in a ﬁxed context window.
Skip-gram model
predicts the surrounding words given the
current word. These are popularly known as Word2Vec models.
These models have better
training complexity,
and thus can
be used for
training on large corpus.
The vectors generated
by
these
models
after
having trained
on a
large
corpus
have
been shown to capture
subtle
semantic
relationships
between words
[Mikolov et
al.,
2013b],
by simple vector
operations of
the corresponding word vectors.
For
example,
Vector(’King’)-Vector(’Man’)+Vector(’Woman’)
is
closest
to
Vector(’Queen’) than to the vectors of any other term in the
corpus.
Similarly Vector(’Germany’)-Vector(’Berlin’)
is very
close to Vector(’France’)-Vector(’Paris’).
If
we compare the LSI
and neural
network models,
LSI
was doing a global computation(SVD) on the full corpus(term-
document matrix), whereas neural network models were using
only local
information(words
in a contextual
window).
To
effectively utilize the positive side of using global information,
without
succumbing to the high computational
cost,
[Pen-
nington et al.,
2014] have proposed GloVe word vectors.
The
model
tries to create word vectors,
such that
the dot
product
of two word vectors,
will closely resemble the co-occurrence
count
of the corresponding words in the corpus.
The model
is shown to be more effective compared to Word2Vec models
for capturing semantic regularities on smaller corpus. We have
used CBOW,Skip-gram and GloVe models in our experiments,
along with the LSI word embeddings for comparisons.
IV.
O
UR
A
PPROACH
& A
LGORITHM
As discussed earlier,
domain ontology has four parts to be
learned
O
=
{C
,
A
,
T
,
N }
,
representing the set
of concepts,
attribute,
taxonomical
and non-taxonomical
relationships re-
spectively.
Let us see each of them in the subsequent subsec-
tions.
A.
Concept & Taxonomy Identiﬁcation
For identifying the set of concepts from a text corpus,
ﬁrst
the noun phrases and other
relevant
tokens were extracted
from the text
corpus using text
chunking [Tjong Kim Sang
and Buchholz, 2000] [Bird, 2006]. From the corpus, the word
vectors for each term was generated using CBOW, Skip Gram
and GloVe models separately.
A vector for multi-word noun
phrases was learned again from the corpus by replacing it
as a single term through appropriate concatenation.
Vectors
were also generated by simple addition of terms involved in
multi-word phrases.
The experiments
were conducted with
both kinds of vectors.
There has been many work reported in
composing the word vectors to form representations of multi-
word phrases
[Socher
et
al.,
2013].
However
we have not
included those approaches in our current work,
and restricted
116
Concept Identiﬁcation
DataSet
Noun Phrase
Count
LSI
CBOW
Skip-gram
GloVe(100)
GloVe(300)
Lonely
Planet
24660
0.56,0.80
0.54,0.87
0.73,0.87
0.69,0.84
0.58,0.84
Yahoo
Finance
33939
0.67,0.72
0.73,0.81
0.73,0.81
0.67,0.85
Not Done
Biology
20582
0.50,0.89
0.50,0.95
0.58,0.94
0.62,0.83
0.54,0.94
TABLE I
Q
UALITY OF
G
ENERATED
C
ONCEPTS AGAINST GOLD STANDARD
- P
RECISION
, R
ECALL
ourselves to term concatenation.
We plan to explore this in
future.
After
generating the vectors
for
noun phrases
and other
tokens,
recursive divisive clustering was carried out
on the
word vectors.
Taking the Euclidean distance as the measure
between the vectors,
K Means [Bishop,
2006]
[Jain,
2010]
clustering was
done.
The
search for
optimal
k was
done
using elbow analysis,
gap statistics[Tibshirani
et
al.,
2001]
and silhouette
coefﬁcient
[Rousseeuw,
1987].
At
the
ﬁrst
level
after
identifying k,
for
each of
the clusters identiﬁed,
recursively clustering was performed,
separately ﬁnding the
optimal
k for
each individual
clusters.
Note that
k will
be
different for different clusters from this level.
To identify the
granular
concepts
at
subsequent
levels,
the clustering were
done recursively till
the depth where variance of
the gap
statistic or silhouette coefﬁcients was very low.
The cluster identiﬁed at each level of hierarchy is a concept
in the ontology.
The clusters at
higher level
represent
coarse
concepts and the ones below represent more granular concepts.
For
example,
concepts
like geographical
regions
including
countries,
cities and continents came up together in the ﬁrst
level cluster (places). Subsequent smaller clusters grouped the
countries,
cities and continents separately.
The different gran-
ular concepts were also identiﬁed, when gap statistics showed
non-monotone behavior.
The values of k,
where gap statistics
curve changed direction was giving different
points at
which
different
granular
concepts(which were shown to the user
and validated interactively) were identiﬁed.
The hierarchical
clustering not only served the purpose of concept identiﬁcation
but that also of the taxonomical relationship between them, as
seen in the ”region-country” and ”region-continent” examples.
Please note that here, ”continent-country” is not a taxonomical
relationship, and will not be identiﬁed here. It will be identiﬁed
as a non-taxonomical relationship later. Also it is important to
note here that, all connected concepts were not appearing in a
single cluster at the ﬁrst level.
There were many cases where
related concepts,
were part
of
different
clusters of
the ﬁrst
level.
Naming of
Concepts:
We devised this solution as a tool
for human assisted ontology creation from unstructured text
for closed domain.
So for naming,
we ﬁrst
checked whether
some
elements
of
the
concept
clusters
are
present
in the
WordNet
[Miller,
1995] and proposed the name to the user.
This was more applicable to higher level concepts like places.
Then we checked whether some of the elements are appearing
in the corpus with some Hearst Patterns. For example, if there
is an occurrence of ’countries such as X’ and X is a member
of a cluster, ’countries’ would be an appropriate name for the
concept.
If more than one candidates were found,
frequency
analysis was done to resolve the conﬂict.
The last resort was
to present the identiﬁed cluster centroid and closest elements
to the centroid and asking the humans to name the cluster.
Naming was just for human consumption of the Ontology, not
for any algorithmic purpose.
B.
Attribute & Non-Taxonomical Relationship Identiﬁcation
The identiﬁcation of attribute and non-taxonomical relation-
ships was done in two separate ways.
The ﬁrst
was using
Hearst Patterns and frequency analysis. For attribute detection
after identifying the concepts,
a frequency analysis was done
for two concepts occurring together in an appropriate Hearst
Pattern or as an adjectival from. For example, the frequent oc-
currence of ’Nationality Person’ helps to identify nationality is
an attribute of a person.
Similarly SVO(Subject-Verb-Object)
based frequency analysis was done for two concepts occurring
together with in the context
of verbs or semantically related
verbs.
Such frequently occurring combinations were hypothe-
sized to have a non-taxonomical relationship. For example, the
occurrence of doctor treated fever, neurologist healed amnesia
all
contributes
to identify the non-taxonomical
relationship
Physician-Cures-Disease. Note that for both attribute and non-
taxonomical relationships, the frequency analysis of SVO tuple
or Hearst
Patterns were carried out
after mapping the terms
to the concepts(clusters),
starting from the lowest level of the
hierarchy they fall into.
The
second approach of
identifying attribute
and non-
taxonomical
relationships was based on word vectors.
Con-
sider
two concepts(clusters),
a bi-partite matching between
the elements of ﬁrst
cluster and second cluster is ﬁgured out
by brute force search.
In a particular
combination the two
elements are matched,
only if the

1
norm of the difference
of the corresponding two vectors are very close across other
matches
in that
combination.
The
brute
force
search has
exponential time complexity of
O
(
n
!)
, where n is the number
of
elements in the cluster.
This poses a problem to do this
effectively.
Currently we
have
explored only relationships
cued by the frequency analysis or entered by humans for the
non-taxonomical
relationships and attributes.
Efﬁcient
search
algorithms
for
attributes
and non-taxonomical
relationships
identiﬁcation using the word vectors is yet to be explored.
117
Taxonomy Relation Identiﬁcation
DataSet
LSI
CBOW
Skip-gram
GloVe(100)
GloVe(300)
Lonely
Planet
0.52,0.94
0.58,0.94
0.52,0.94
0.66,0.77
0.61,0.97
Biology
0.42,0.71
0.53,0.73
0.49,0.62
0.46,0.80
0.53,0.70
TABLE II
Q
UALITY OF
T
AXONOMY
R
ELATIONSHIPS AGAINST GOLD STANDARD
- P
RECISION AND
R
ECALL
V.
E
XPERIMENTAL
R
ESULTS
& E
VALUATION
We have done two kinds of
evaluation for
assessing the
quality of the ontologies generated.
The ﬁrst
one is a direct
evaluation of
generated ontologies [Zavitsanos et
al.,
2011]
on three data sets on which state-of-the-art
techniques have
reported their numbers.
The second is indirect
evaluation of
using the ontology concepts to improve clustering and classi-
ﬁcation metrics on a different
data set.
We have reported in
detail the results of the ﬁrst kind of evaluation. We developed
our code in Python using Theano
1
,
NLTK [Bird,
2006],
Gen-
sim [
ˇ
Reh
˚
u
ˇ
rek and Sojka,
2010],
and scikit-learn [Pedregosa
et al.,
2011].
For evaluation purpose we used Lonely Planet, Biology and
Yahoo news data set. Lonely planet data set [Zavitsanos et al.,
2011] is a collection of text articles written about places and a
gold ontology manually created for tourism domain.
Biology
is a set of articles collected from Biology News Website
2
and
a gold ontology manually created for
biology domain.
For
both these datasets,
evaluated precision and recall
measures,
computed against
the gold standard are given for
concept
identiﬁcation in Table
I.
We have also reported the results
for concept identiﬁcation on Yahoo Finance dataset, which is a
collection of Yahoo Finance news articles and an associated set
of concepts manually created. For taxonomy relationship iden-
tiﬁcation, the evaluated scores against gold standard is given in
Table
II for the ﬁrst two datasets. Yahoo Finance dataset gold
ontology does not contain the taxonomy relationships.
Hence
this evaluation is omitted.
The experiments for precision and
recall numbers for GloVe based methods was conducted using
both 100 dimensional
and 300 dimensional
vectors,
whereas
for
other
methods results are reported for
100 dimensional
vectors only.
Context window of 5 were used in all methods.
Experiments for Yahoo Finance dataset
using GloVe vectors
were conducted only for
100 dimensional
vectors,
not
for
300 dimensional
vectors,
because of
the hardware memory
constraints stemming from the quadratic(on number of terms)
memory requirement of the method.
It
has to be noted that,
gold standard ontologies contained
much more information of the domain, which was not present
in the text at all. The concepts and relationships not present in
the text at all, cannot be captured by standard learning methods
from text.
Also the corpus we have experimented are small,
word vectors are known to capture semantic regularities when
trained on large corpus.
The precision and recall measures in
all
the cases,
for concept
identiﬁcation as well
as taxonomy
1
http://deeplearning.net/software/theano/
2
http://www.biologynews.net
relationship identiﬁcation,
have improved considerably using
the word embeddings from deep learning based language mod-
els compared to LSI. Among these models and corresponding
hyper-parameters, there is no single winner across all datasets
for all the methods. Skip-gram based methods performs better
for concept identiﬁcation in general and GloVe based method
performs better
for
taxonomy relationship identiﬁcation,
but
the margins are very close.
VI.
C
ONCLUSION
& F
UTURE
W
ORK
We presented a simple hierarchical
clustering based ap-
proach for Ontology Induction from unstructured text,
using
state of the art
deep learning based language modeling.
Al-
though Ontology Learning is a well researched area [Buitelaar
et
al.,
2005] [Maedche and Staab,
2004],
to the best
of our
knowledge no work has been previously done to assess the
performance of
the distributed word vectors
generated by
these language models for Ontology Learning.
We presented
evaluation results to articulate the effectiveness of distributed
word vectors for Ontology Learning on 3 different
datasets.
Our
results shows that
distributed word vectors from these
language models outperforms other models like LSI in creating
practically useful ontologies for closed domains.
This
work is
an early start
to the problem of
Ontology
Learning using word vectors from language modeling and deep
learning in general.
Ontology learning is very broad problem,
with various
sub-problems
demanding special
focus.
Apart
from the required detailed experimentation(for e.g.: with term-
term matrix LSI instead of term-document matrix LSI), hyper-
parameter tuning and evaluations(attribute and non taxonomy
relationships),
there are plethora of improvements and future
work directions that can be embarked on. We are enumerating
ﬁve of the important ones here,
1)
In this work,
we considered only word vectors learned
independently of
Ontology Learning task.
Ontology
Learning can be potentially formulated as consistently
capturing the information content
of
a domain in an
optimal way,
at the minimal considering the number of
concepts and consistency. This notion can be formulated
as a learning objective.
Ontology Learning neural
net-
work can be formulated so,
this is a major
stream of
work.
2)
Extending the language models and jointly learning the
cluster assignments [Xie et
al.,
2015] for the ontology
incorporating the known information or
constraints of
a domain,
along with the word embeddings is another
direction to be explored.
118
3)
For
generating
the
vectors
for
multi
term phrases,
we have not
leveraged the composition of
word vec-
tors [Socher et al.,
2013].
4)
We
have
not
yet
addressed the
axiom learning for
ontologies,
which is another line of work.
5)
As mentioned before in section
IV-B, developing com-
putationally feasible algorithms(compared to exponen-
tial
time algorithm)
to excavate non-taxonomical
rela-
tionships using word vectors directly is another stream
of work.
The encouraging results from the preliminary experiments
with just
simple clustering techniques advocate the advanced
work in these directions.
R
EFERENCES
Yoshua Bengio, R
´
ejean Ducharme, Pascal Vincent, and Chris-
tian Janvin.
A neural
probabilistic language model.
The
Journal of Machine Learning Research, 3:1137–1155, 2003.
Chris Biemann.
Ontology learning from text:
A survey of
methods.
In LDV forum,
volume 20,
pages 75–93,
2005.
Steven Bird. Nltk: the natural language toolkit. In Proceedings
of
the COLING/ACL on Interactive presentation sessions,
pages
69–72.
Association for
Computational
Linguistics,
2006.
Christopher
M.
Bishop.
Pattern Recognition and Machine
Learning (Information Science and Statistics).
Springer-
Verlag New York,
Inc.,
Secaucus,
NJ,
USA,
2006.
ISBN
0387310738.
Paul Buitelaar,
Philipp Cimiano,
and Bernardo Magnini.
On-
tology learning from text: methods, evaluation and applica-
tions,
volume 123.
IOS press,
2005.
Susan T Dumais.
Latent semantic analysis.
Annual review of
information science and technology,
38(1):188–230,
2004.
Dieter Fensel.
Ontologies.
Springer,
2001.
Nizar
Grira,
Michel
Crucianu,
and Nozha Boujemaa.
Un-
supervised and semi-supervised clustering:
a brief
survey.
A review of
machine learning techniques
for
processing
multimedia content,
1:9–16,
2004.
Simon Haykin.
Neural
Networks: A Comprehensive Founda-
tion.
Prentice Hall PTR, Upper Saddle River, NJ, USA, 2nd
edition,
1998.
ISBN 0132733501.
Marti
A Hearst.
Automatic acquisition of
hyponyms from
large text
corpora.
In Proceedings of
the 14th conference
on Computational
linguistics-Volume
2,
pages
539–545.
Association for Computational Linguistics,
1992.
Anil
K Jain.
Data clustering:
50 years
beyond k-means.
Pattern recognition letters,
31(8):651–666,
2010.
Alexander Maedche and Steffen Staab.
Ontology learning.
In
Handbook on ontologies,
pages 173–190.
Springer,
2004.
Tomas Mikolov,
Kai
Chen,
Greg Corrado,
and Jeffrey Dean.
Efﬁcient estimation of word representations in vector space.
arXiv preprint arXiv:1301.3781,
2013a.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
Linguistic
regularities in continuous space word representations.
In
HLT-NAACL,
pages 746–751,
2013b.
George A Miller.
Wordnet:
a lexical
database for
english.
Communications of the ACM,
38(11):39–41,
1995.
Madhav Nimishakavi, Uday Singh Saini, and Partha Talukdar.
Relation schema induction using tensor
factorization with
side information.
arXiv preprint arXiv:1605.04227,
2016.
F.
Pedregosa,
G.
Varoquaux,
A.
Gramfort,
V.
Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,
V.
Dubourg,
J.
Vanderplas,
A.
Passos,
D.
Cournapeau,
M.
Brucher,
M.
Perrot,
and E.
Duchesnay.
Scikit-learn:
Machine learning in Python.
Journal of Machine Learning
Research,
12:2825–2830,
2011.
Jeffrey Pennington,
Richard Socher,
and Christopher D Man-
ning.
Glove:
Global
vectors for
word representation.
In
EMNLP,
volume 14,
pages 1532–1543,
2014.
Roberto Poli,
Michael
Healy,
and Achilles
Kameas.
The-
ory and Applications of
Ontology: Computer Applications.
Springer,
2010.
Radim
ˇ
Reh
˚
u
ˇ
rek and Petr Sojka. Software Framework for Topic
Modelling with Large Corpora. In Proceedings of the LREC
2010 Workshop on New Challenges for NLP Frameworks,
pages 45–50,
Valletta,
Malta,
May 2010.
ELRA.
http://is.
muni.cz/publication/884893/en.
Peter
J Rousseeuw.
Silhouettes:
a graphical
aid to the in-
terpretation and validation of
cluster
analysis.
Journal
of
computational and applied mathematics,
20:53–65,
1987.
Rahul
Sharnagat.
Named entity recognition:
A literature
survey,
2014.
Amit
Singhal.
Introducing the knowledge graph:
things,
not
strings.
Ofﬁcial google blog,
2012.
Richard Socher,
Alex Perelygin,
Jean Y Wu,
Jason Chuang,
Christopher
D Manning,
Andrew Y Ng,
and Christopher
Potts.
Recursive deep models for semantic compositionality
over
a sentiment
treebank.
In Proceedings of
the confer-
ence on empirical methods in natural language processing
(EMNLP),
volume 1631,
page 1642.
Citeseer,
2013.
Robert
Tibshirani,
Guenther Walther,
and Trevor Hastie.
Es-
timating the number
of
clusters in a data set
via the gap
statistic.
Journal
of
the Royal
Statistical
Society: Series B
(Statistical Methodology),
63(2):411–423,
2001.
Erik F Tjong Kim Sang and Sabine Buchholz.
Introduction to
the conll-2000 shared task: Chunking. In Proceedings of the
2nd workshop on Learning language in logic and the 4th
conference on Computational
natural
language learning-
Volume 7,
pages 127–132.
Association for
Computational
Linguistics,
2000.
Wilson Wong,
Wei Liu,
and Mohammed Bennamoun.
Ontol-
ogy learning from text:
A look back and into the future.
ACM Computing Surveys (CSUR),
44(4):20,
2012.
Junyuan Xie,
Ross Girshick,
and Ali
Farhadi.
Unsupervised
deep embedding for
clustering analysis.
arXiv preprint
arXiv:1511.06335,
2015.
E. Zavitsanos, G. Paliouras, and G. A. Vouros.
Gold standard
evaluation of
ontology learning methods
through ontol-
ogy transformation and alignment.
IEEE Transactions on
Knowledge and Data Engineering, 23(11):1635–1648, Nov
2011.
ISSN 1041-4347.
doi: 10.1109/TKDE.2010.195.
119
