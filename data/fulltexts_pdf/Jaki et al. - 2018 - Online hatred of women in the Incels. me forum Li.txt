Online Hatred of Women in the Incels.me Forum: 
Linguistic Analysis and Automatic Detection 
Sylvia Jaki,
1
Tom De Smedt,
2
Maja Gwóźdź,
3
Rudresh Panchal,
4
Alexander Rossa,
5
Guy De Pauw
6
1
University of Hildesheim, 
2
University of Antwerp, 
3
University of Munich, 
4
Columbia University, 
5
University of Hull, 
6
Textgain 
Abstract
This paper presents a study of the online discussion forum Incels.me and its users, 
involuntary
celibates
or 
incels
, a virtual community of isolated men without a sexual life, who see women as 
the cause of their problems and often use the forum for misogynistic hate speech and other forms 
of incitement. Involuntary celibates have recently attracted media attention and concern, after a 
killing spree in April 2018 in Toronto, Canada. The aim of this study is to shed light on the incel 
community, by applying a combination of quantitative and qualitative approaches to analyze the 
communication between the users of the forum. We investigate the vernacular used by incels, 
apply automatic profiling techniques to determine who they are, discuss the hate speech posted in 
the forum, and propose a Deep Learning system that is able to automatically detect instances of 
misogyny, homophobia, and racism, with approximately 95% accuracy. 
Keywords
: misogyny, hate speech, social media, forensic linguistics, text analytics, text profiling 
1 
Introduction 
On April 23, 2018, 25-year old Alek Minassian killed 10 and injured 16 in Toronto, Canada, by 
driving a rented van into pedestrians “like he was playing a video game” (The Telegraph, 2018). 
This incident has become known as the Toronto van attack. Shortly before the attack, he posted a 
cryptic message on Facebook stating: “The Incel Rebellion has begun!” (Reuters, 2018). The 
term is shorthand for 
involuntary
celibates
and refers to an online community of men that blame 
women for their celibacy (Ging, 2017). Evidence shows that Minassian was inspired by the 2014 
Isla Vista killings, where 22-year old Elliot Rodger stabbed and shot 6 people to death near the 
UCLA campus, after posting a video on YouTube in which he complained about being rejected 
by women, while envying sexually active men (Blommaert, 2017; Larkin, 2018). 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
2 
Several studies suggest that “echo chambers”, online forums where like-minded people share 
disparaging views, may be a catalyst for radicalization (e.g., Colleoni et al., 2014). To illustrate 
this, on November 7, 2017, the 
r/Incels
community was banned from Reddit for spreading 
misogyny.
1
However, a new incel forum, 
Incels.me
, appeared online shortly after. 
In this paper, we analyze the discourse in the new forum to shed more light on the nature of the 
incel movement. In section 2, we outline the dataset collected for quantitative analysis and the 
sample that we used for qualitative analysis. Section 3 examines the language used in the forum 
discussion threads, and section 4 discusses the forum’s users. Section 5 analyzes the disparaging 
nature of (most of) the content (misogyny, homophobia, racism), the user’s motives for posting 
it, and techniques for automatic detection. Section 6 discusses the group dynamics in the forum. 
In section 7, we formulate our conclusions of the case study. 
2 
Methods & Materials
We have combined quantitative techniques from Natural Language Processing (NLP) with an 
in-depth qualitative analysis, which allows for a systematic description of the data and the 
development of an automatic detection system using Machine Learning (ML) techniques. This 
kind of technology can be useful for the monitoring or prevention of online misogyny. 
QUANTITATIVE ANALYSIS
We used the Pattern toolkit for the Python programming language (De Smedt & Daelemans, 
2012) to crawl and collect approximately 65,000 messages (about 1.5M words) from Incels.me. 
The resulting dataset covers 3,500 threads
(i.e., discussion topics) with messages by 1,250 users, 
posted in the 6-month period between November 2017 and May 2018. Approximately, each 
thread contains about 20 messages, by 10 users. Each user posted about 50 messages on average. 
About 350 new messages were posted each day. The number of posts increases significantly in 
April, after the news of the Toronto van attack, as shown in Figure 1 below.
1
As of July 2018, 
r/braincels
was still active on Reddit, featuring a mix of less inflammatory incel rhetoric and role-playing. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
3 
QUALITATIVE ANALYSIS 
We manually reviewed a subset of a 100 threads (~3%) selected to reflect the variety of topics 
discussed in the forum, including definitions of 
inceldom
, the prospect of being an incel, 
feminism, female promiscuity, male attractiveness, ethnicity, suicide and violence as coping 
mechanisms, and so on. Providing insight into the debate in the forum does not go without 
showing concrete examples, hence the reproduction of discriminatory or offensive language is 
unavoidable (see Marx, 2018: 1 for a similar observation). All of the examples are indicated as 
published, i.e., without changing spelling or grammar mistakes. 
Figure 1
. Timeline of messages posted on Incels.me (November 2017 – April 2018). 
Figure 2
. References to violence on Incels.me (November 2017 – April 2018).
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
4 
AIM OF THE STUDY
The aim of this study is to assess whether or not the Incels.me forum fosters 
radicalization
. In 
general, the earliest reference to an 
Incel Rebellion
is only made on April 24, the day after the 
Toronto van attack, in a thread titled “Well I’ll be damned”. However, references to a 
Beta 
Uprising
, which is the term that the forum’s users seem to prefer, occur as early as February, in a 
number of threads where some users attempt to incite others to commit acts of violence, such as: 
“Even if it’s shooting up a school, don’t sit back and do nothing”. This is illegal according to the 
International Covenant on Civil and Political Rights,
2
but most likely protected by the First 
Amendment of the United States Constitution and 
Brandenburg v. Ohio
, 395 U.S. 444 (1969). 
As a first tentative cue, Figure 2 shows the relative frequency of messages that contain common 
references to violence (~2%), i.e., the words 
kill
, 
rape
and/or 
shoot
. Notably, these references 
tone down around Christmas, but the frequency of messages that contain 
kill
then increases in the 
weeks before the attack. In particular, violence against women is often judged as acceptable or 
even desirable, which is a cause for concern. Thus, it is important to discuss how likely it is that 
the users would resort to actual violence, for example under peer pressure. 
3 
Text Analysis
Text Analysis refers to the study of words and combinations of words that constitute the rhetoric. 
Quantitative approaches from NLP include analysis of word frequency, word combinations, 
word context, and dictionary tagging (e.g., identifying aggressive verbs or negative adjectives). 
3.1 
Quantitative Analysis 
We 
compared 
50,000 
Incels.me 
messages 
to 
50,000 
“neutral” 
texts, 
composed 
of 
40,000 
paragraphs from random English Wikipedia articles (which are moderated for neutrality) and 
10,000 random English tweets (to account for internet slang). In theory, all words should be 
evenly distributed between both sets. For example, most sentences require function words such 
as 
a
and 
the
to be comprehensible. However, there are also content words that occur more 
2
https://www.ohchr.org/EN/ProfessionalInterest/Pages/CCPR.aspx 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
5 
frequently in a specific context, e.g., sports tweets will often mention 
winner
while messages on 
Incels.me may often mention 
loser
.
3
Below is an overview of words that 9 out of 10 times occur 
in incel messages, and which are statistically significantly biased (chi-square 
p
-value < 0.05). 
TOP 10 KEYWORDS 
The top 10 of most frequent significantly biased keywords consists of 
I
(30,000x), 
you
(20,000x), 
n’t 
(10,000x), 
do
(7,500x), 
if
(6,500x), 
just
(6,000x), 
like
(6,000x), 
me
(6,000x), 
get
(4,500x), 
even
(4,000x). The occurrence of personal pronouns (
I
, 
me
, 
you
) is explained by the difference in 
genre: Wikipedia articles tend to represent facts while Incels.me posts reflect personal opinions. 
Wikipedia articles also avoid informal contractions, using 
do not
instead of 
don’t
. The presence 
of adverbs such as 
just
and 
even
indicates expressions of uncertainty (i.e., hedge cues; Farkas et 
al., 2010). Conjunctions such as 
if
are generally used to introduce unlikely events. 
TOP 100 KEYWORDS
The top 100 of biased keywords has references to gender (
female
/
male
, 
girl
/
guy
, 
woman
/
man
), 
physical traits (
attractive
, 
fat
, 
pretty
, 
ugly
, 
white
), and sex. Swear words (
fuck
, 
fucking
, 
shit
) and 
internet slang (
kek
, 
lmao
, 
lol
) occur frequently, indicating adolescent age (Barbieri, 2008). Also 
common are more negations (
nothing
, 
never
), negative adjectives (
bad
, 
hard
), modal adverbs of 
uncertainty (
maybe
, 
probably
, 
why
), and emotion verbs (
hate
, 
hope
, 
want
, 
wish
). Some words 
constitute coded language. For example, 
Chad
or 
Tyrone
are derogatory denominations for an 
attractive and successful young man (cf., 
alpha male
, 
bad boy
, 
bro
, 
jock
) while 
Stacy
denotes an 
attractive 
roastie
, a promiscuous young woman. A central metaphor in the incel jargon refers to 
The Matrix
, a popular science fiction film in which the protagonist is offered either a red pill 
(knowledge 
and 
misery) 
or 
a 
blue 
pill 
(ignorance 
and 
bliss). 
In 
the 
online 
men’s 
rights 
community (i.e., the 
Manosphere
),
4
the red pill refers to the belief that men are oppressed. 
Particularly in incel subculture, this means that a minority of attractive men have access to the 
majority of all women, while the other men are left to compete over a minority of women. The 
black pill (Figure 3, rank 89) then is the nihilistic belief that unattractive men will never “score”. 
3
https://docs.google.com/spreadsheets/d/1j6GNs075HQjF-D3GWbSBk3QEAgi1ms-AfYOO8kGPvxQ 
4
https://rationalwiki.org/wiki/Manosphere_glossary 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
6 
Figure 3
. Top 100 keywords.
WORD 
COUNT 
RANK 
women 
3473 
11 
fuck 
2547 
15 
fucking 
2322 
17 
want 
2266 
19 
shit 
2258 
20 
why 
2165 
22 
Chad 
2098 
24 
ugly 
1539 
36 
sex 
1480 
37 
girl 
1195 
45 
bad 
905 
62 
pretty 
774 
75 
maybe 
703 
80 
hope 
693 
83 
blackpill 
630 
89 
Figure 4
. Top 1,000 keywords.
WORD 
COUNT 
RANK 
myself 
556 
101 
dick 
542 
105 
virgin 
510 
114 
rape 
276 
185 
dumb 
230 
215 
pathetic 
214 
226 
faggot 
214 
227 
girlfriend 
210 
234 
slut 
169 
267 
cum 
120 
350 
scum 
81 
499 
nigger 
76 
527 
landwhale 
57 
617 
horny 
48 
690 
pillow 
38 
799 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
7 
Figure 5
. Top 2,000 keywords.
WORD 
COUNT 
RANK 
legitimately 
27 
1001 
eyebrows 
26 
1027 
wageslave 
25 
1053 
boner 
24 
1072 
infuriating 
21 
1137 
urges 
19 
1241 
submissive 
17 
1316 
micropenis 
15 
1399 
stalk 
15 
1436 
sexbot 
14 
1443 
impregnate 
13 
1555 
hag 
12 
1622 
terrifying 
12 
1723 
weeman 
11 
1797 
tampon 
10 
1899 
TOP 1,000 KEYWORDS
The top 1,000 of biased keywords (Figure 4) has references to romance (
girlfriend
/
boyfriend
, 
date
), sexuality (
horny
, 
masturbating
, 
virgin
), and pornography (
ass
, 
cum
, 
cunt
, 
dick
). Misogyny 
(
bitch
, 
slut
, 
whore
) and other hate speech (
faggot
, 
nigger
, 
retard
) start to surface. There are many 
more negative adjectives (e.g., 
brutal
, 
disgusting
, 
dumb
, 
lazy
, 
insane
, 
lonely
, 
pathetic
, 
stupid
, 
terrible
, 
useless
) and verbs expressing aggression (
crush
, 
die
, 
hate
, 
kill
, 
rape
, 
shoot
, 
slay
).
TOP 2,000 KEYWORDS
Beyond the top 1,000 biased keywords (Figure 5), we find more (and more specific) references 
to male sexuality (
boner
, 
micropenis
, 
urges
), more negative adjectives (
infuriating
, 
submissive
), 
and more aggressive verbs (
beat
, 
stalk
, 
torture
). There are noticeably many more compounds of 
a disparaging nature (e.g., 
noodlewhore
, 
soyboy
, 
wageslave
). 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
8 
WORD COMBINATIONS
Commonly co-occurring adjective-noun pairs are 
high
school
(~200x), 
white
man
(200x), 
black
woman
(80x), 
good
looking
(125x), 
ugly
man
(125x), 
ugly
woman
(30x), 
social
anxiety
(30x), 
social
skills
(65x), 
low
IQ
(50x), 
big
dick
(40x), 
big
deal
(30x), 
little
bitch
(15x), and 
little
girl
(15x). There are many more, usually referring to physical attributes and the size of body parts. 
Figure 6 shows the context of the word 
women
in the dataset, with size representing frequency. 
WORD EMBEDDINGS
We can use the co-occurrence counts of words to discover prevalent topics in the data. This is 
often done using topic modeling techniques such as Latent Dirichlet Allocation (Blei et al., 
2003), but these require vast amounts of data. Therefore, we opted to use word embeddings, an 
NLP technique that represents words as vectors of real numbers, derived from co-occurrence 
statistics. Word embeddings encode semantic as well as syntactic information, and have been 
shown to work well with limited data. We used Gensim (Rehurek & Sojka, 2010) to refit the 
standard word2vec word embeddings (Mikolov et al., 2013) onto the Incels.me data, and t-SNE 
(Maaten & Hinton, 2008) for dimensionality reduction, to map the vector space to a 2-D visual 
representation where semantically related words are projected in close proximity to one another. 
Figure 6
. Words preceding or succeeding the word 
women.
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
9 
Figure 7 shows an example t-SNE visualization of words that occur more than 400 times in the 
Incels.me dataset. Notably, topical clusters emerge with swear words (7.1) in the center, words 
that represent physical traits (7.2), and words referring to gender (7.3) – although in general the 
rhetoric appears to be highly heterogeneous. 
We also experimented with non-negative matrix factorization (Xu et al., 2003) to compute topic 
clusters. In this case, some of the most distinct topics are formed by verbs that express thinking 
processes (
know
, 
think
, 
want
), verbs that express sensory perception (
feel
, 
like
, 
look
), and swear 
words (
fuck
, 
fucking
, 
shit
, …). 
Figure 7
. t-SNE visualization of words occurring > 400x.
(7.1) 
(7.2) 
(7.3) 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
10 
3.2 
Qualitative Analysis 
We can identify three broad trends in the messages that users post and the language that they use: 
1) negative discourse that pertains to being a incel, 2) offensive discourse that targets (attractive) 
women (and men), and 3) infighting and bullying while competing for in-group status, discussed 
in section 4 (profiling), section 5 (hate speech) and section 6 (group dynamics) respectively. 
SEXUALITY
The most prominent topics in all discussions are 
sexuality
(from physical, psychological as well 
as sociocultural perspectives), 
sexual
selection
, and 
sex
(from a pornographic perspective). In 
particular, incels are concerned with what constitutes attractiveness (“just a bit of muscle is best 
for general-purpose attractiveness”), how to approach women (“I don’t approach women, ever”), 
and how and why they are unsuccessful in this regard (“Attempts: 3”). The forum’s users reflect 
on the physical aspects of sexuality and invent ranking systems (e.g., by chin size or penis size), 
discuss detrimental psychological aspects (e.g., anxiety, anger, loneliness), and construct unusual 
theories about the sociocultural aspects of sexual relationships (“Throughout history women 
frequently killed their own offspring to sleep with the conquerors”). 
SEX & PORNOGRAPHY
It is likely that online pornography distorts the incel’s perception of women’s sexual preferences. 
As a test, we searched the dataset for 
porn
and manually reviewed 250 matching messages. The 
prevalent pattern in this sample is that users either praise mainstream heterosexual pornography, 
or otherwise blame the pornography industry for their low self-esteem (most notably, insecurity 
about penis size). Some messages (~15%) include hyperlinks to freely available pornographic 
content (e.g., pornhub.com), which offers a cue to the misogynistic nature of the forum, i.e., what 
kind of pornography users prefer to watch and how they advertise it on the forum: “convincing 
rape porn”, “best uncensored rape porn”, “humiliation”, etc. 
Research on pornography consumption and sexual aggression is too broad to include here (for an 
overview, see Pollard, 1995) but we can highlight two studies that relate to the unusual views on 
sexuality in incel subculture. Firstly, it has been shown that antisocial individuals may be drawn 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
11 
to pornography due to its impersonal opportunity to exert control over a member of the opposite 
sex (Vega & Malmuth, 2007: 106). However, Malamuth & Ceniti (1986) report that exposure to 
(violent) pornographic material does not raise the level of aggression towards women, and does 
not turn consumers into rapists, except when individuals already exhibit personality traits linked 
to aggression. Dominance-centered views on sex are common in the dataset. The overwhelming 
majority of users also openly despise LGBT+ practices. One user states: “Nothing hardens your 
heart and strengthens your resolve like hatred, sexualized hatred is what I prescribe for looming 
thoughts of faggotry”. Other users also claim that forced female-on-male oral sex is not arousing 
since it resembles male homosexual practices. A small amount of messages are more moderate 
and view pornography as stress-relief to the incel predicament. 
4 
Text Profiling 
Text Profiling pertains to gaining insight into the demographic and psychosocial aspects of the 
(anonymous) author of a text, based on the words that they use, the topics that they discuss, their 
personal writing style, and metadata such as what usernames they choose. Relevant techniques 
from NLP include sentiment analysis, and age, gender and personality prediction (Argamon et 
al., 2009), which have for example been used to identify school shooters (Neuman et al., 2015) 
or jihadists on social media (De Smedt et al., 2018). 
Incels.me discussion threads related to the Toronto attack show that incels feel misrepresented in 
the media, being framed as white conservatives: “I’m sick of these Ameritards trying to label us 
all as white and right wingers. They don’t want to learn about inceldom all they want to do is 
push their narrative and political agenda”. According to another user, the forum is a “community 
made up of disparate groups ranging from edgy shitposting teens to Salafi Jihadist apologists and 
Christian Identity white supremacists”. We will attempt to shed further light on who the incels 
are, in terms of age, gender, ethnicity, and state-of-mind, using a combination of quantitative and 
qualitative analysis to reveal a negative mindset of mostly male adolescents who suffer from 
anger issues, uncertainty, and social inhibition. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
12 
4.1 
Quantitative Analysis 
SENTIMENT ANALYSIS
Sentiment Analysis is the NLP task of 
automatically predicting whether a text is 
positive, negative or neutral (Liu, 2012). 
Using the Pattern toolkit (75% accuracy), 
we find that over 60% of Incel messages 
are 
negative
. By comparison, less than 
5% of articles on Wikipedia are negative. 
DEMOGRAPHIC PROFILING
We used the Textgain API
5
to detect age, 
gender, education level and personality of 
the forum’s users (~80% accuracy). Most 
of them are flagged as 
adolescent
, 
male
, 
and slightly less educated (Figure 8). 
Figure 8
. Sentiment analysis & demographic profiling.
In prior work, Pennebaker (2011) demonstrated how personal writing style contains subtle cues 
for age, gender, state-of-mind, and personality. For example, statistically, women tend to use 
more pronouns (
I
, 
my
, 
we
) to talk about relationships, while men tend to use more determiners 
and quantifiers to talk about objects and concepts (
the
, 
one
, 
more
, …). Adolescents use more 
informal language and profanity, while introverted persons tend to use more negative adjectives. 
Such findings support the results of the Textgain API. For example, the results indicate that 35% 
of the users might be women, even though we know with certainty that all of them are men. But 
then most of the discourse is about interpersonal relationships and physical functions, topics that 
are statistically more prevalent with women (Newman et al., 2008: 219). Likewise, younger age 
correlates with lower education, suggesting that the users are not necessarily less educated than 
other people, although there are multiple references to 
low IQ
(~50x), which may indicate low 
5
https://www.textgain.com 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
13 
self-esteem (or contempt). Finally, in popular belief, about one third of the world’s population is 
introverted, which would mean that relatively more Incels.me users are introverted (which 
corroborates the prevalence of negative adjectives), but there is little evidence to support this. 
PSYCHOLOGICAL PROFILING
The Linguistic Inquiry and Word Count analysis (LIWC; Pennebaker et al., 2001) automatically 
identifies psychological categories for common words, e.g., 
cried
= Affective, Negative, Past, 
Sadness, Verb. In general, the results support our earlier observations that the forum users tend to 
use more swear words, more personal pronouns, more modal adverbs, more negative adjectives, 
and fewer positive adjectives. They tend to express more negative emotions like anger and 
uncertainty, and display 
social
inhibition
(i.e., avoidance, anxiety). They talk less about their 
family, work, hobbies, goals, beliefs, and more about relationships and sexuality.
4.2 
Qualitative Analysis 
Due to the heterogeneity of the community, as well as the subjective nature of attractiveness, 
there is no standard in-group definition of inceldom, i.e., being an incel. The question of who can 
be considered to be an incel repeatedly comes up in the forum, mainly because not all users of 
the forum are welcome, especially 
normies
or 
volcels
(voluntary celibates). All sorts of threads 
contain discussions about who is a real incel (
truecel
), i.e., a legitimate and particularly a badly-
off user, which is important since it often entails receiving emotional support. 
DEMOGRAPHIC PROFILING 
Gender
. The forum contains a short section with terminology, rules, and FAQs.
6
It defines an 
incel as a “[p]erson who is not in a relationship nor has had sex in a significant amount of time, 
despite numerous attempts”. A 
person
here has to be understood as a 
man
, since women are 
considered not to have problems finding sexual partners, which is noted both in the rules section 
and in the threads. The minimal criteria of inceldom are: being male, and not having had a sexual 
partner for a long time. The majority of users understand that this entails being a virgin, without 
any hope of changing status (“Im going to be a kissless virgin for life. its truly over”). 
6
https://incels.me/threads/rules-terminology-and-faq.799 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
14 
Age
. The age of the average user is harder to determine, since most users do not make explicit 
references to their age, nor their place of residence. However, many of the users appear to be 
adolescent men. This is implied by references to school (
my school
, 
my college
), parents (
my 
mom
, 
my dad
), and video games that are popular with teens (
League of Legends
, 
World of 
Warcraft
). But other users seem to be considerably older. The age that they self-report in our 100 
sample threads varies between 21 and 33. That a non-negligible part of the forum consists of 
older members can also be inferred from indirect references to age (“Most of us take fewer risks 
because our rejections are in the 30s and higher”), from references to a former university, and by 
talking about school in the past tense (“things were different when I was in high school”). 
Race
. There is no definite evidence that Incels.me users are predominantly white, contrary to 
what is often reported about incels. We will discuss race and ethnicity in section 5. 
PHYSICAL PROFILING
The users generally attribute their lack of sexual experience and social contacts to 
ugliness
.
7
Many of them refer to the absence of physical attraction by their username,
8
such as 
Hunchback
, 
MicroDong
, 
YunGandUgly
, 
Uglyinkel
, 
blackletcel
, 
Asianmanletcel
, 
patheticmanletcel
(where 
-let
refers to a shorter height). Some users describe their physical shortcomings openly (“manlet 
stature with abnormally long arms and a huge skull”), in part because this attracts attention, pity, 
and confirmation of their perceived hopeless predicament. The incels’ views on beauty are quite 
elaborate: They discuss it in a detailed and controversial way, using coded designations such as 
lookism
or 
LMS
, which involves a categorization system based on specific facial features such as 
a broad chin or a normal nose, build, height, personality, and/or normally-sized genitals. Such 
aspects are discussed in minute detail in threads titled “Being a self aware ugly male is pure 
torture”, “Are we incels because”, or “Are you fucked if your cock is sub 5?”. 
7
See DiMauro (2008) and Donnelly et al. (2001: 165) on the connection between self-image and an involuntary lack of sexual experience. 
8
In general, usernames can be divided into three groups: 1) names based on 
incel 
or 
-cel
(e.g., 
theonlytruecel
, 
Poverty Cel
, 
Weirdcel
, 
Suicel
), or 
2) names referring to the mental disposition of the user (
fukmylyf
, 
lonelyistheworld
, 
Subhuman Trash
, 
itsOVER
), or 3) names based on incel 
terminology (
Blackpill101
, 
ropenotcope
, 
Heightframeface
, 
Cuck
). These categories are not mutually exclusive. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
15 
PSYCHOLOGICAL PROFILING
Isolation
. There is another defining criterion with general consent: being alone. Some incels 
have never had a date (see also Donnelly et al., 2001: 163) or any contact with women (“I’ve 
never touched a non-related female even for a handshake or something”; “I wish I could be 
friend zoned but girls are to repulsed by me to even consider me a friend”). Even establishing 
any social contact whatsoever seems to be difficult for some incels (“no one ask me to hang out 
in my entire 22 years of existence. Not even men or my neighbors”). 
Inhibition
. Some users argue that mental disorders like autism can also render a person an incel. 
This opinion is in line with the forum’s rules section, where 
mentalcels
are implicitly included as 
a “[t]ype of incel whose reason for failure in relationships/sex is related to mental illness or 
major insecurities”. Some users report taking psychotropic drugs and having been diagnosed 
with schizophrenia, autism, and/or personality disorders, as in “I’m diagnosed autistic aspergers, 
social anxiety and anti social personality disorder aka sociopath” or “diagnosed aspiecel and 
borderlinecel here but i 
LITERALLY
fit the description of 
EVERY SINGLE
Personality disorder 
except antisocial personality disorder and narcissistic personality disorder”. These members have 
usernames such as 
Schizoidcel
, 
Psychocel
, or 
HopelessMentalcel
. Anxiety and depression are 
common as well, but these afflictions are believed to be a consequence of the lack of physical 
attractiveness, since “those are just usual symptoms of being a subhuman outcast”. Some users 
feel left out because of their low IQ, which is discussed as an inherent feature of inceldom in one 
thread: “We are not only uglier than beautiful people but also dumber on average”. Examples of 
usernames that hint at a low IQ and/or depression are 
retarded_dumbshit
, 
lowIQretard
, 
Sadness
, 
Eternaldarkness
, and 
Melancholy_Worm
. 
Negativity
. The comments by the users show that incels suffer because of their condition (e.g., 
feeling lonely, deprived of sexual contacts, stared at in public, lacking a career).
9
There is a large 
number of discussion threads (~25%) containing “it’s over”, which stands for the lack of hope to 
escape their situation. There are a few positive users in the forum who address their situation, for 
example by going to the gym (
gymcel
), but this is often experienced as a strain because of the 
9
https://www.huffingtonpost.ca/2018/06/05/incel_a_23451320 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
16 
high number of 
Chads
in the gym (“gymcelling is literally torture”). When discussing what to do 
on a free night, self-reported activities point to an isolated life, with solitary exercising, drinking, 
playing video games, cleaning, masturbating, or doing nothing at all as the most common 
answers. Cautiously positive messages like “I’m probably coping but maybe there is a glimmer 
of hope” are rare. This prevalence of negativity is substantiated by our sentiment analysis. 
Neglect
. Self-pity and hopelessness drive part of the users to neglect their daily grooming, as in: 
“I haven’t brushed my teeth in over six months. I did shower yesterday, but it was for the first 
time in like 2 to 3 weeks”, or “I dress like a bum, have unkempt hair, ripped shoes”. This might 
contribute to a vicious circle of depression. Once their impression of hopelessness is reinforced 
by other users, they call it 
suicidefuel 
(in contrast to 
lifefuel
). Direct messages expressing the 
desire for suicide are quite common: “This is so fucking brutal and I also want to end it as soon 
as possible. I don’t even get emotional when thinking about suicide anymore. I’m just waiting 
for the right time”. Several users claim a right to euthanasia (“Painless suicide pills should be 
freely distributed to people like us”). Another effect of feeling let down is the development of 
hatred towards society, especially towards women and attractive men (see section 5). 
Figure 9
. Summary of core and peripheral aspects of inceldom.
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
17 
SUMMARY
Within the community, there is considerable disagreement on which defining factors are the most 
prevalent, and also on the relation between ethnicity and attractiveness. Other potential criteria 
are a lack of stable personality (as a long-term result of physical and mental flaws) and success 
in one’s professional life (many incels seem to be unemployed). Figure 9 sums up the factors that 
are often discussed in the forum as defining inceldom. While some factors are apparently more 
defining than others, a prototypical incel would be somebody like: “22 yr old kissless, dateless, 
virgin. Chubby cheeks, crooked nose, 5"10,
10
balding at age 22, weak frame, and awkward voice. 
Shitty career prospects. Mild autism and social anxiety. My life is fucking fucked […]”. 
5 
Hate Speech 
Hate speech is defined in the Encyclopedia of the American Constitution as “any communication 
that disparages a person or a group on the basis of some characteristic such as race, color, 
ethnicity, gender, sexual orientation, nationality, religion, or other characteristic” (Nockleby, 
2000). However, in the US, freedom of speech is protected by the First Amendment and there is 
no exception that prohibits hate speech, unless it constitutes incitement to imminent crime.
11
The 
EU’s Code of Conduct on countering illegal hate speech online
12
defines hate speech as “the 
public incitement to violence or hatred directed to groups or individuals on the basis of certain 
characteristics, including race, colour, religion, descent and national or ethnic origin”. 
In this section, we examine to what extent incel vernacular constitutes hate speech, to understand 
how disparaging and/or offensive the incel discourse is, in particular towards women. Together 
with the explicit references to violence, this may serve as an indicator of how dangerous the 
community is, with respect to potential future attacks. Finally, a growing number of attempts 
have been made to automatically detect hate speech (for an overview, see Schmidt & Wiegand, 
2017). This section also discusses our attempt to automatically detect misogynistic vernacular. 
10
Incels partly assess their attractivity by penis size, which is a common focus in a penis-centered view of sex (Plummer 2005: 179). 
11
https://washingtonpost.com/news/volokh-conspiracy/no-theres-no-hate-speech-exception-to-the-first-amendment 
12
http://europa.eu/rapid/press-release_MEMO-18-262_en.htm 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
18 
5.1 
Quantitative Analysis 
To get a first impression, we looked for the occurrence of 10 offensive words in each discussion 
thread, in particular words that constitute misogyny (
bitch
, 
landwhale
, 
roastie
, 
slut
, 
whore
), 
homophobia (
fag
, 
faggot
, 
soyboy
), and racism (
coon
, 
nigger
). Using this approach, about 30% of 
the threads are 
misogynistic
. About 15% are 
homophobic
, and 3% are 
racist
. For example, 
three of the most hateful discussion threads are titled “Caught this fat bitch swiping left on 
Tinder”, “Faggots are just as bad as women!”, and “Black man chases femoid through streets”. 
About 5% of all messages in our dataset contain one or more of these 10 offensive words. By 
comparison, the likelihood that a random Twitter message contains one of these words is 0.4% 
(about 40 out of 10,000 tweets), or over 10x less than incel messages. 
About half of the users in our dataset posted hateful messages at one time or another. Nearly 500 
use misogynistic slurs, 250 (also) use homophobic slurs, and 75 (also) use racial slurs. But most 
users post no more than two or three hateful messages. About 10% of the users are responsible 
for the majority of the hate speech. The most aggressive user posted nearly 500 hateful messages 
in as many threads in a 6-month period. 
The reported numbers are an approximation based on a small selection of 10 offensive words, 
while hate speech is a heterogeneous phenomenon that does not even necessarily always involve 
attitudes of hatred (Brown, 2017: 432). Most likely, our estimates err on the conservative side. 
If we do a search for 50 offensive words, 
word combinations (
dumb
girl
, 
fat chick
), 
and verb constructions (
beat
/
teach her
), 
the percentage of misogynistic discussion 
threads steadily rises over 50%, most of it 
again posted by 10% of the users. Figure 
10 presents an overview. 
Figure 10
. Threads with hate speech.
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
19 
5.2 
Qualitative Analysis 
HOMOPHOBIA
Wikipedia states that incels are mostly heterosexual and white.
13
The former is true for the users 
of the Incels.me forum (the latter is not).
14
For example, one user states: “gays cant be incel 
theyre too busy having sex and shopping at bed bath and beyond”. Homosexuals are often 
despised and called 
faggots 
(“being a faggot is a mental disorder same with being trans”), and 
only once in the subsample of a 100 threads does a user refer to himself as homosexual. The 
pervasiveness of heterosexuality can be attributed to 1) the fact that homosexuals are not wanted 
in the forum, and 2) that the world views (particularly misogyny) of heterosexual incels may not 
be something that homosexuals can relate to. 
RACISM
It has been shown that the anti-feminist movement is connected to white supremacism and to 
antisemitism (Kämper, 2011), and the same has been suggested for the incel community in 
various news media.
15
It is impossible to say whether the majority of Incels.me users are white 
men, but our data implies that this may be less true than expected. There are some mentions of 
Hitler or gas chambers and some anti-semitic remarks (“The damage that Jews have done to our 
species is almost unfathomable. Fucking kikes”). There are some racist comments in general, 
targeted either at other users (“go back to freaking syria, find some camel or goat and fuck”) or 
at a group as a whole (“Muslims need to be exterminated”). But in the 100 threads we analyzed 
such cases are sporadic rather than systematic. 
However. race is an extensively treated topic in the forum, but primarily in relation to which race 
has more incels and which race has more (dis)loyal women. There is a general consent that 
unattractive non-white men have a harder time than unattractive white men (“Ethnic subhumans 
like me […] are either instantly rejected or friendzoned”), which is referred to as the “just be 
white theory”. There is also consent that “[r]ace is a big part of looks” and that Indian incels 
13
https://en.wikipedia.org/wiki/Incel 
14
We also found sporadic evidence of sexual deviation, including pedophilia (“A lot of pedos in this community actually”), necrophilia (“No 
pics of its dead body Disappointed tbh”), and zoophilia (“I have sex with willing mares in heat”). 
15
https://www.nytimes.com/2018/05/09/world/americas/incels-toronto-attack.html 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
20 
(
currycels
) are most badly off. Other ethnic groups mentioned in this context are Asians, and less 
often African Americans and Arabs. This may reflect, to some extent, the 
ethnic
variety
of the 
forum. One user believes that only half of the people on Incels.me are white. Other users claim 
that most incels are not white, and one user substantiates this by referring to a poll in the forum. 
MISOGYNY
Misogyny can be defined as “an unreasonable fear or hatred of women that takes on some 
palpable form in any given society” and “sexual prejudice that is symbolically exchanged 
(shared) among men” (Gilmore, 2001: 9). Misogyny is one of the most pervasive features of the 
Incels.me forum. One user says: “I think acceptance of ‘misogyny’ and disregard for outsiders is 
what separates us from other communities”. Hating women is seen as an inherent characteristic 
of incels (“hating women is a requirement”), who attribute their situation to undesirable female 
behavior. Indian and Asian women are hated the most (“Ethnik Indian and noodlewhores are the 
worse of the worst”) because they are said to prefer only white men, while at the same time 
Asian women are recommended as prostitutes. Unsurprisingly, the forum is thus replete with 
derogatory designations for women (
cum
dumpster
, 
cum
rag
, 
it
, 
roastie
, 
slut
, 
whore
, etc.). 
Nevertheless, not all users hate all women. A discussion thread designed as a poll asks whether 
the forum users hate all women and shows that opinions are mixed: about 55% (33x) answer 
positively, while about 45% (28x) answer negatively (“No, I like my mom and grandma”).
16
One 
user states the following: “I don’t hate all woman. And I believe that most brothers here in the 
Forum also don’t hate them. We hate the situation we are in”. 
Dehumanization
. Many users criticize feminism, which is seen as a threat to masculinity, or as 
brainwashing (Ging, 2017: 3), or the reason for “loneliness and suicides”, “the decay of society”, 
“terror”, and so on. Multiple messages call for the abolishment of women’s rights, to the extent 
that women should not be allowed to vote and should be regarded as the property of their 
husbands: “Female 
HAVE TO
become property again. They should not have the right to even 
SPEAK
without male permission”. Concrete advice includes treating women like wild animals 
(“You have to get used to seeing them as animals”) and keeping them on a leash and caging them 
16
As self-reported comments in the poll suggest, 45% hate only 
some
women, or no women at all. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
21 
when their owner leaves the house. In turn, men should have a legal claim on virgin brides, and 
the government should mediate their desire for sexual contact by “redistribut[ing] pussy”, i.e., 
legalizing and subsidizing prostitution. This extreme dehumanization of women
17
entails several 
other more or less systematic opinions about women’s rights, such as capital punishment (e.g., 
stoning, acid throwing) of adultery or wearing “revealing clothing”. 
Incitement
. As these opinions already suggest, the attitude towards violence against women is 
often favorable (“Disobedient wives should be beaten”). One particular topic that comes up 
frequently is rape, which is encouraged, with the main concern that women falsely accuse men of 
rape. Some users believe that women enjoy being raped, and that it should be legally impossible 
to accuse men of rape. Some users would like to see all women dead (“I want them all to die”), 
writing minutely detailed instructions of how they should be raped or killed. Other users praise 
reports on rape (“Roastie slut got what she deserved”) and attacks on women (“Better a few dead 
than all of them living their carefree lives. Enjoy the little things“). 
The reason why incels have such a negative attitude towards women is the perceived female 
“degeneracy”, i.e., an exclusive interest in (sex with) attractive men, who are also a target of 
incel hatred. Women are portrayed as being shallow, immoral, promiscuous, and responsible for 
the incels’ isolation. Users post pictures of women taken from the news and social media, upon 
which the women’s physical traits are derided, especially obesity (“I loathe fat women. Bunch of 
useless fucking hogs”). The users believe that men generally “date down”, while women are not 
willing to do so (“They think that they deserve only rich handsome princes and muscular greek 
gods with perfect bodies”). However, it is important to emphasize that a lot of features of incel 
misogyny extends to online misogyny in general, such as detailed depictions of sexual violence, 
extreme insults, or the shaming of women for bodily flaws (Jane, 2014). 
17
Dehumanization in discriminatory talk has often been subject to Critical Discourse Analysis (Musolff, 2012). 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
22 
5.3 
Threat Assessment 
The discussion threads show considerable 
glorification
of incel-related crime: “Alek Minassian. 
Spread that name, speak of his sacrifice for our cause, worship him for he gave his life for our 
future”. Several users have Rodger’s or Minassian’s face as their profile picture. Some want to 
exact 
revenge
on society (“I’m driven by hate, any action that can lead to the slightest bit of 
revenge upon society is worth the effort”) and choose usernames that refer to hate, rage, rape, 
murder, and so on. Some user profiles contain explicit depictions of violence, for example GIFs 
(animated images) that show women being hit in the face, shot in the head, or stabbed with a 
knife. Users do not necessarily agree on what revenge should be like. While some would derive 
satisfaction from systematically
blackpilling
the world, i.e., spreading their negative world view 
(“I want people to feel a sort of visceral dread that has then questioning the very value of 
existance”), others actively incite violence towards women, or even call for human extinction in 
general. One user states: “They don’t give a shit about us. Nobody does. That’s why I have no 
problem if any of us starts killing as many people as possible. The more young women, Chads, 
Chadlites, normies, cucks, and Boomers who get slaughtered, the better”. 
We identified three general verbal acts in this regard: 
Incitement
including appeals to kill people in the course of the Beta Uprising using lengthy 
descriptions, for example titled “How a crazy school shooter is made, and how women play a 
part in this whole”, that explain how the perceived discrimination and injustice that incels 
experience leads to becoming a mass shooter. 
Fantasizing
about how people could be injured or killed, for example by beheading, poisoning, 
stabbing, “spray[ing] that class with bullets”, renting a van to run over people, or driving a fire 
truck into the Coachella music and arts festival. 
Threatening
, in varying stages of concreteness, with users considering to follow in the footsteps 
of previous attackers such as Elliot Rodger and Alex Minassian. More precisely, we found five 
such messages (~0.25%) in the subsample of a 100 discussion threads. By extrapolation, this 
means that there might be a 150+ more in our entire dataset that should be examined. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
23 
To offer three examples: 
●
“I hope one day I get the confidence or the opportunity to seriously injure a chad at my HS”
●
“Can’t wait until the next physical blackpill movement. I will join in”
●
“I’m not even exaggerating, I’m probably gonna snap one day”
MEDIA RESPONSIBILITY
The forum’s users generally agree that incel attacks will become more common in the future. 
However, we must add that there is also a clearly visible faction among the users that objects to 
violence and in particular mass killings (“I don’t condone violence. Especially mindless violence 
against innocent people”). They see a dangerous trend in the incel movement: “The spreading of 
the blackpill would no doubt increase shooting (and suicides) because some young men lose 
control”. The media response to the Toronto attack also raises concerns, firstly, how the “media 
makes these killers into overnight celebrities” could increase the motivation for such killings, 
and secondly, how incels will be perceived in the future (“this event has been a disaster for this 
forum”, “Now we are gonna be thought of as psychos even more cause of this crazy asshole”). 
Given that news reports on the incel community in the wake of the Toronto attack indeed seem 
to portray the members as a homogeneous rather than a 
heterogeneous
group, such worries may 
be legitimate. However, the pro-violence incels seem to outnumber the anti-violence faction, 
which might be in part explicable by the group dynamics of the forum (see section 6).
5.4 
Automatic Detection
One way to mitigate the surge of online hate speech is to deploy systems that assist with the early 
identification of worrisome content. Machine Learning (ML) is a field of AI that uses statistical 
techniques to train systems that “learn by example” to make automatic predictions. For example, 
given a 1,000 junk emails and a 1,000 real emails, a machine learning algorithm will infer that 
words such as 
viagra
and 
lottery
occur more often in junk emails. Such cues can then be used to 
classify unknown emails as junk or real. We used state-of-the-art Deep Learning techniques to 
train a Multichannel Convolutional Neural Network (CNN; Kim, 2014) in Keras (Chollet, 2015) 
with 50,000 Incels.me messages and 50,000 neutral texts composed of 40,000 paragraphs from 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
24 
random English Wikipedia articles and 10,000 random English tweets. The statistical accuracy of 
the model is 
95.1%
, which makes applications for detecting online hatred of women viable. 
We also experimented with the Perceptron algorithm (see Collins, 2002), which does not require 
expensive GPU hardware during the training sequence. We used character unigrams (
u
, 
g
, 
l
, 
y
), 
bigrams (
ug
, 
gl
, 
ly
), trigrams (
ugl
, 
gly
), and word unigrams (
ugly
) and bigrams (
ugly
guy
) to 
encode both lexical (e.g., word endings) and contextual features (e.g., word combinations). 
Using 10-fold cross-validation (i.e., 10 tests on 10 different samples), the statistical accuracy 
(F
1
-score) is 92.5%, which is a competitive tradeoff between cost and effectiveness. 
6 
Discussion 
PERSPECTIVES ON GROUP DYNAMICS
Donnelly et al. (2001: 167) have shown in their study on involuntary celibacy that test persons 
“appeared to be using the Internet more to find moral support than for sexual stimulation. For 
most, the Internet was used to create a sense of community and to fill emotional needs”. This is 
what Dholakia & Bagozzi (2004: 258) refer to as the “companionship motive” for participating 
in virtual communities. This motive is also true for Incels.me, where users turn to because they 
feel isolated. One user remarks: “if it wasnt for incel forums id have 0 social interaction 
whatsoever”. The users feel part of an in-group, which creates a sense of community between 
like-minded people. To illustrate this, there is even merchandise such as T-shirts that can be 
purchased on the website.
18 
The downside of this sense of community is that it also creates a 
toxic platform for anti-feminist radicalization (Ging, 2017). For example, Blommaert (2017: 20) 
highlights the importance of the online communities themselves in the radicalization of Elliot 
Rodger, which has resulted in the incel expression 
to go ER
(to commit a mass killing spree): 
Rodger derived from his engagement in those communities an absolute certainty about his identity as 
a victim of a world that conspired to steal away his (sexually focused) happiness, and enough of a 
commitment to take this logic of action to its very end, where the victim becomes the perpetrator. 
18
https://teespring.com/stores/fast-banana 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
25 
The internet enables small hate groups to reach a large number of people, whereas in pre-internet 
times extremists had to work in more isolation (Douglas, 2009: 155). The gratification that users 
derive from a forum like Incels.me is 
approval
, as they spread ideas or initiate threads that are 
considered as “high IQ”. Such ideas often involve complex (but also absurd) reasoning, leading 
to “the emerging of individual and collective identity categories (‘victims’, ‘beta males’) and 
commonly ratified (‘normal’) lines of action” according to Blommaert (2017: 16). Messages that 
proliferate misogyny or incite crime help a user to cement his reputation as an alpha user. 
As as result, the Incels.me forum brims with subcultural language, partly composed of in-group 
terminology for much-discussed agents, and partly composed of youth language in general. The 
terms most often recurred to can broadly be grouped in 1) designations for themselves (see above 
for different word formations including the creatively coined morpheme 
-cel
), 2) their targets, 
i.e., women (
Staceys
, 
roasties
, 
femoids
) and attractive men (
Chads
, 
Tyrones
), and 3) the incel 
ideology (e.g., 
blue pill
, 
red pill
, 
blackpill
, 
lookism
, 
go ER
). This aspect is particularly important, 
since online communities emerge through language, and the use of a group-specific language 
determines the boundaries of the community (cf. Haythornthwaite, 2009: 123f). 
PERSPECTIVES ON ECHO CHAMBER EFFECTS
These identity-forming mechanisms have the downside that discussions motivate users to post 
messages with content that attracts attention, i.e., producing comments that are more extreme 
than previous comments in a thread. For example, one thread on how to rape a woman shows 
that users will try to come up with more “creative” methods of accomplishing this. It is unclear 
whether such extreme views about killing women are fantasies or an early warning sign. In non-
anonymous face-to-face interactions, users might speak less drastically than in these echo 
chambers (Colleoni et al., 2014).
19
It can be argued that the image of an aggressive group does 
not correspond to reality, but rather that the existence of the forum in general contributes to 
cementing a negative worldview. As Waltman & Haas (2011: 63) state, “[t]he Internet has 
become the lifeblood of the organized hate movement”. One user answers the question if he 
hates all women with: “[b]efore incels.me: no. After incels.me: 
YES
YES
YES
”. 
19
See Haines et al. (2014) on the connection between anonymity in computer-mediated communication and the expression of unethical opinions. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
26 
Figure 10
. Incels.me screenshot of an example discussion thread.
One reason why people are able to engage in this toxic communication is that there is little or no 
content moderation. There are some rules restricting what can be said and how, and infringement 
is penalized by users being banned. These rules include: 1) no persecution or bullying of other 
users, 2) no race-baiting, 3) no stories of sexual experiences, 4) no discussion of illegal activities, 
and 5) violent content and pornography need a spoiler tag. The rules also state that positivity is 
appreciated “as long it is not bluepill ideology or white-knighting”. But these rules are enforced 
only half-heartedly, and banned users can ask the moderator to lift their ban again.
20
Hence, the 
forum is rife with hate speech, filled with discussions about illegal hate crimes, and extremely 
offensive infighting. It is not uncommon for users to react to comments with insults such as “Just 
kill yourself and do us all a favour” or “you little worthless sub-human scum”. Although 
positivity is officially appreciated, it is often those users who bring optimism into the forum that 
are viciously attacked by their peers. It is not surprising that some users recognize the dangers of 
the forum: “This site isn’t good for anyone’s mental health, let’s be real”.
20
https://incels.me/forums/ban-appeals.18 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
27 
PERSPECTIVES ON HATE COMMUNITIES 
Is the Incels.me forum part of a growing number of online hate communities? Our analysis has 
shown that it may be so, in part because its users share in-group mechanisms such as subcultural 
language, extremist beliefs, and a tendency for radicalization. They also engage in intergroup 
rudeness (Kleinke & Bös, 2015: 50) such as the construction of a majority outgroup outside the 
forum (
normies 
vs 
incels
) and persecuted outgroups within the ingroup (i.e., users who are not 
truecels
). However, there is one major and important difference to other hate communities: the 
community is more heterogeneous than other hate communities, because users are not united by 
a common goal, but by a feature that its individuals share, i.e., not being able to engage in social 
and/or sexual contacts. Due to the resulting negative self-image, incels do not, in contrast to 
other hate communities, create in-group identity through self-portrayal in positive terms, but only 
create out-group identity by depicting 
normies
as flawed and deplorable, which is again a feature 
that it shares with other ideological groupings (Waltman & Haas, 2011: 34). 
7 
Conclusion
In this paper we have demonstrated how the key to identifying features of an online subculture is 
examining their language use, both quantitatively and qualitatively. Using various methods, we 
have outlined an alliance of necessity of isolated young men with a highly negative mindset and 
a pronounced inclination towards misogynistic spite. Our findings correspond in part to how 
incels have been depicted by the media, but the analysis also reveals that the group is more 
heterogeneous than assumed. Our dataset displays a mixed picture of how dangerous or violent 
the members of the community may be, which is important to assess in regard to potential future 
attacks like the one committed by Alek Minassian. On the one hand, the forum is replete with 
incitement and explicitly violent fantasies. On the other hand, part of these may be no more than 
verbal tactics of self-enhancement in an online echo chamber. How to deal with a community 
such as Incels.me? The prior removal from Reddit has demonstrated that a community does not 
simply disappear, but finds new ways to spread and share hatred. Close monitoring of platforms 
such as Incels.me in terms of radicalization should be considered, with the possibility to act upon 
explicit threats. Automatic techniques to detect hateful speech can facilitate this process, in our 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
28 
case with up to 95% accuracy. We encourage the use of such tools to 
assist
, but not to 
replace
, a 
continued monitoring of the activities and development of online hate communities. 
Acknowledgments 
The research was conducted during Google Summer of Code 2018 (GSoC). The source code for 
the linguistic analysis and the machine learning models was developed by GSoC students Maja 
Gwóźdź, Rudresh Panchal and Alexander Rossa, and is available on request. A Textgain API 
license key was donated by Textgain to conduct the automatic profiling experiments. 
Bibliography 
Argamon, S., Koppel, M., Pennebaker, J. W., & Schler, J. (2009): Automatically profiling the author of 
an anonymous text. 
Communications of the ACM
52(2): 119-123. 
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003): Latent dirichlet allocation. 
Journal of Machine Learning 
Research
3, 993-1022. 
Blommaert, J. (2017): Online-offline modes of identity and community: Elliot Rodger’s twisted world of 
masculine victimhood. 
Tilburg Papers in Culture Studies 
200. 
Brown, A. (2017): What is hate speech? Part 1: The myth of hate. 
Law and Philosophy 
36: 419-468. 
Chollet, F. (2015): Keras: Deep learning library for Theano and Tensorflow. 
https://keras.io 
Colleoni, E., Rozza, A., & Arvidsson, A. (2014): Echo chamber or public sphere? Predicting political 
orientation and measuring political homophily in Twitter using big data. 
Journal of Communication
64(2): 317-332. 
Collins, M. (2002): Discriminative training methods for hidden markov models: Theory and experiments 
with perceptron algorithms. In 
Proceedings of the ACL-02 Conference on Empirical Methods in 
Natural Language Processing
10: 1-8. 
De Smedt, T. & Daelemans, W. (2012): Pattern for Python. 
Journal of Machine Learning Research
13: 
2063-2067. 
De Smedt, T., De Pauw, G., & Van Ostaeyen, P. (2018): Automatic detection of online Jihadist hate 
speech. 
CLiPS Technical Report Series
7: 1-30. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
29 
Dholakia, U. M. & Bagozzi, R. P. (2004): Motivational antecedents, constituents and consequents of 
virtual community identity. In: S. H. Godar & S. P. Ferris (eds.), 
Virtual and Collaborative Teams: 
Process, Technologies, and Practice
. Hershey/London: Idea Group Publishing, 252-267. 
DiMauro, D. (2008): Reluctant virginity: the relationship between sexual status and self-esteem. 
Theses 
and Dissertations
717. 
Donnelly, D., Burgess, E., Anderson, S., Davis, R., & Dillard, J. (2001): Involuntary Celibacy: A life 
course analysis. 
The Journal of Sex Research
38(2): 159-169. 
Douglas, K. M. (2009): Psychology, discrimination and hate groups online. In: A. N. Joinson, K. Y. A. 
McKenna, 
T. 
Postmes, 
& 
U.-D. 
Reips 
(eds.), 
The 
Oxford 
Handbook 
of 
Internet 
Psychology
. 
Oxford/New York: Oxford University Press, 155-163. 
Farkas, R., Vincze, V., Móra, G., Csirik, J., & Szarvas, G. (2010): The CoNLL-2010 shared task: learning 
to 
detect 
hedges 
and 
their 
scope 
in 
natural 
language 
text. 
In 
Proceedings 
of 
the 
Fourteenth 
Conference on Computational Natural Language Learning---Shared Task
, 1-12. 
Gilmore, D. D. (2001): 
Misogyny: The Male Malady
. Philadelphia: University of Pennsylvania Press. 
Ging, D. (2017): Alphas, Betas, and Incels: theorizing the masculinities of the Manosphere. 
Men and 
Masculinities
. 
Haines, R., Hough, J., Cao, L., & Haines, D. (2014): Anonymity in computer-mediated communication: 
More contrarian ideas with less influence. 
Group Decision and Negotiation
23(4): 265-786. 
Haythornthwaite, C. (2009): Social networks and online community. In: A. N. Joinson, K. Y. A. 
McKenna, 
T. 
Postmes, 
& 
U.-D. 
Reips 
(eds.), 
The 
Oxford 
Handbook 
of 
Internet 
Psychology
. 
Oxford/New York: Oxford University Press, 121-137. 
Jane, E. A. (2014): “Back to the kitchen, cunt”: speaking the unspeakable about online misogyny. 
Continuum: Journal of Media and Cultural Studies
28(4): 558-570. 
Kämper, A. (2011): 
[r]echte Kerle. Zur Kumpanei der MännerRECHTSbewegung
. Münster: UNRAST. 
Kim, Y. (2014): Convolutional neural networks for sentence classification. arXiv:1408.5882. 
Kleinke, S. & Bös, B. (2015): Intergroup rudeness and the metapragmatics of its negotiation in online 
discussion fora. 
Pragmatics
25(1): 47-71. 
Larkin, R. W. (2018): Learning to be a rampage shooter. The case of Elliot Rodger. In: H. Shapiro (ed.), 
The Wiley Handbook on Violence in Education: Forms, Factors, and Preventions
. Wiley, 69-84. 
Liu, B. (2012): 
Sentiment Analysis and Opinion Mining
. Morgan & Claypool. 
Maaten, L. V. D., & Hinton, G. (2008): Visualizing data using t-SNE. 
Journal of Machine Learning 
Research 
9, 2579-2605. 
Malamuth, N. M. & Ceniti, J. (1986): Repeated exposure to violent and nonviolent pornography: 
Likelihood of raping and laboratory aggression against women. 
Aggressive Behavior
12: 129-137. 
ONLINE HATRED OF WOMEN – JAKI, DE SMEDT, GWÓŹDŹ, PANCHAL, ROSSA & DE PAUW
30 
Marx, K. (2018): Cybermobbing aus sprachwissenschaftlicher Perspektive. 
Sprachreport 
1/18: 1-9. 
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013): Efficient estimation of word representations in 
vector space. arXiv:1301.3781. 
Musolff, A. (2012): The study of metaphor as part of critical discourse analysis. 
Critical Discourse 
Studies
9(3): 301-310. 
Newman, M. L., Groom, C. J. Handelman, L. D., & Pennebaker, J. W. (2008): Gender differences in 
language use: An analysis of 14,000 text samples. 
Discourse Processes
45: 211-236. 
Neuman, Y., Assaf, D., Cohen, Y., & Knoll, J. L. (2015): Profiling school shooters: Automatic text-based 
analysis. 
Frontiers in Psychiatry
6, 86. 
Nockleby, J. T. (2000): Hate speech. In: L. W. Levy & K. L. Karst (eds.), 
Encyclopedia of the American 
Constitution
, Vol. 3, 2nd ed. Detroit: Macmillan Reference US, 1277-79.
Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001): 
Linguistic Inquiry and Word Count: LIWC 
2001
. Mahwah: Lawrence Erlbaum Associates. 
Pennebaker, J. W. (2011): 
The Secret Life of Pronouns. What Our Words Say About Us
. New York: 
Bloomsbury. 
Plummer, K. (2005): Male sexualities. In: M. S. Kimmel, J. Hearn, & R. W. Connell (eds.), 
Handbook of 
Studies on Men & Masculinities
. Thousand Oaks/London/New Delhi: Sage, 178-195. 
Pollard, P. (1995): Pornography and sexual aggression. 
Current Psychology
14(3): 200-221. 
Rehurek, R. & Sojka, P. (2010): Software framework for topic modelling with large corpora. In 
Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks
, 46-50. 
Reuters (2018): Toronto police eye deadly van attack suspect’s “cryptic message”. April 24, 2018. 
https://www.reuters.com/article/us-canada-van/toronto-police-eye-deadly-
van-attack-suspects-cryptic-message-idUSKBN1HV1AY
Schmidt, A. & Wiegand, M. (2017): A survey on hate speech detection using natural language processing. 
In 
Proceedings of the Fifth Workshop on Natural Language Processing for Social Media
, 1-10. 
The Telegraph (2018): What do we know about Alek Minassian, arrested after Toronto van attack?
April 
23, 2018. 
https://www.telegraph.co.uk/news/2018/04/24/do-know-alek-minassian-
arrested-toronto-van-attack
Vega, V. & Malamuth, M. (2007): Predicting sexual aggression: The role of pornography in the context 
of general and specific risk factors. 
Aggressive Behavior
33: 104-117. 
Waltman, M. & Haas, J (2011): 
The Communication of Hate
. New York: Peter Lang. 
Xu, W., Liu, X., & Gong, Y. (2003): Document clustering based on non-negative matrix factorization. 
Proceedings of the 26th annual international ACM SIGIR conference on Research and development 
in information retrieval
, 267-273. 
