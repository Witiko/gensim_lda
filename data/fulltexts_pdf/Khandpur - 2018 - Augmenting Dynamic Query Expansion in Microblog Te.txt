Augmenting Dynamic Query Expansion in Microblog Texts
Rupinder Paul Khandpur
Dissertation submitted to the Faculty of the
Virginia Polytechnic Institute and State University
in partial fulfillment of the requirements for the degree of
Doctor of Philosophy
in
Computer Science and Applications
Narendran Ramakrishnan, Chair
Chang-Tien Lu, Co-chair
Christopher North
Chandan Reddy
Eui-Hong Han
June 15, 2018
Arlington, Virginia
Keywords:
Dynamic Query Expansion, Microblog Event Retrieval, Social Media Analytics,
Visual Knowledge Discovery
Copyright 2018, Rupinder Paul Khandpur
Augmenting Dynamic Query Expansion in Microblog Texts
Rupinder Paul Khandpur
(ABSTRACT)
Dynamic query expansion is a method of automatically identifying terms relevant to a target
domain based on an incomplete query input.
With the explosive growth of online media, such
tools are essential for efficient search result refining to track emerging themes in noisy,
un-
structured text streams.
It’s crucial for large-scale predictive analytics and decision-making,
systems which use open source indicators to find meaningful information rapidly and accu-
rately.
The problems of information overload and semantic mismatch are systemic during
the Information Retrieval
(IR) tasks undertaken by such systems.
In this dissertation,
we
develop approaches to dynamic query expansion algorithms that can help improve the effi-
cacy of such systems using only a small set of seed queries and requires no training or labeled
samples.
We primarily investigate four significant problems related to the retrieval & assess-
ment of event-related information,
viz.
(1) How can we adapt the query expansion process
to support rank-based analysis when tracking a fixed set of entities? A scalable framework is
essential to allow relative assessment of emerging themes such as airport threats.
(2) What
visual
knowledge discovery framework to adopt that can incorporate users’
feedback back
into the search result refinement process?
A crucial
step to efficiently integrate real-time
‘situational
awareness’
when monitoring specific themes using open source indicators.
(3)
How can we contextualize query expansions? We focus on capturing semantic relatedness be-
tween a query and reference text so that it can quickly adapt to different target domains.
(4)
How can we synchronously perform knowledge discovery and characterization (unstructured
to structured) during the retrieval process? We mainly aim to model high-order, relational
aspects of event-related information from microblog texts.
Augmenting Dynamic Query Expansion in Microblog Texts
Rupinder Paul Khandpur
(GENERAL AUDIENCE ABSTRACT)
Analysis of real-time, social media can provide critical insights into ongoing societal events.
Where consequences and implications of
specific events include monetary losses,
threats
to critical
infrastructure and national
security,
disruptions to daily life,
and a potential
to cause loss of
life and physical
property.
It is imperative for developing good ‘ground
truth’ to develop adequate data-driven information systems, i.e., an authoritative record of
events reported in the media cataloged alongside important dimensions.
Availability of high-
quality ground truth events can support various analytic efforts, e.g., identifying precursors
of attacks,
developing predictive indicators using surrogate data sources,
and tracking the
progression of
events over space and time.
A dynamic search result refinement is useful
for expanding a general
set of user queries into a more relevant collection.
The challenges
of information overload and misalignment of context between the user query and retrieved
results can overwhelm both human and machine.
In this dissertation,
we focus our efforts
on these specific challenges.
With the ever-increasing volume of user-generated data large-scale analysis is a tedious task.
Our first focus is to develop a scalable model
that dynamically tracks and ranks evolving
topics as they appear in social media.
Then to simplify the cognitive tasks involving sense-
making of evolving themes,
we take a visual
approach to retrieve situationally critical
and
emergent information effectively.
This visual
analytics approach learns from user’s inter-
actions during the exploratory process and then generates a better representation of
the
data.
Thus, improving the situational understanding and usability of underlying data mod-
els.
Such features are crucial for big-data based decision & support systems.
To make the event-focused retrieval process more robust, we developed a context-rich proce-
dure that adds new relevant key terms to the user’s original query by utilizing the linguistic
structures in text.
This context-awareness allows the algorithm to retrieve those relevant
characteristics that can help users to gain adequate information from social
media about
real-world events.
Online social
commentary about events is very informal
and can be
incomplete.
However,
to get the complete picture and adequately describe these events we
develop an approach that models the underlying relatedness of information and iteratively
extract meaning and denotations from event-related texts.
We learn how to express the high-
order relationships between events and entities and group them to identify those attributes
that best explain the events the user is trying to uncover.
In all
the augmentations we develop,
our strategy is to allow only very minimal
human
supervision using just a small set of seed event triggers and requires no training or labeled
samples.
We show a comprehensive evaluation of these augmentations on real-world domains
- threats on airports, cyber attacks, and protests.
We also demonstrate their applicability as
for real-time analysis that provides vital
event characteristics,
and contextually consistent
information can be a beneficial aid for emergency responders.
Dedication
To my mother, Kamlesh Khandpur and my father, Geeta Paul
Khandpur
v
Acknowledgments
Whoever said it takes a village to raise a Ph.D. was very right!
So I would like to thank my
village and acknowledge its essential members.
Firstly, I would like to express my sincere gratitude to my advisor Dr.
Naren Ramakrishnan
for the unwavering support of my Ph.D. study and guidance that helped shape my research.
Over the course of my Ph.D., there were many occasions where I faltered, but he was there
to help me get back up.
I am most thankful for his patience and trust in my abilities that
I could achieve all
that I have and more.
As an advisor,
he propelled me forward with
ideas when I got stuck;
and as a friend,
he was always there to share his experiences and
encouraged me throughout this journey.
My co-advisor, Dr.
Chang-Tien Lu for his crucial insights and expertise that were instrumen-
tal in helping me improve my understanding of the research challenges that I had undertaken.
He was always there to encourage me to refine every aspect of my research work and helped
me notice the minute details which makes a good researcher even better.
My committee members, Dr.
Chandan Reddy, Dr.
Chris North, and Dr.
Eui-Hong Han for
guiding me through the process, without their valuable feedback and knowledge it would not
have been possible for me to complete my Ph.D.
I have learned a lot from their combined
experiences and wisdom.
My father, Mr.
Geeta Paul Khandpur who has been the rock of my life and a pivotal person
without whom this journey would have lacked meaning.
His strength and faith in me took
away any doubt I had in my abilities.
Dr.
Sumit Kumar Jha,
for being an excellent mentor and a great friend to me when I
was contemplating pursuing my doctoral studies.
I am thankful to him for many things, for
showing me ropes early on when I was starting out as a researcher, nurturing my aspirations,
giving me the confidence that I could do a Ph.D.,
and was the one to introduce me to Dr.
Ramakrishnan.
My best friends - Mubariz Shariff,
Nakul
Jinsi,
Arpit Jain,
Ana Karen Ramé Montiel,
Dr.
Sana Ahmad,
Dr.
Sangamitra Singh,
Mit Shah,
Dr.
Samvid Dwivedi,
Shubham Yadav,
Amrinder Singh, and Varun Kapoor.
Each of them, unequivocally, have played an essential
role in my life.
They have been there for me every step of the way, giving me their support
and pushing me when I needed it the most.
vi
I am grateful to be a part of the Discovery Analytics Center (DAC) and would like to thank
all the members and alumni who have contributed to my research work and academic life at
Virginia Tech immensely.
I would like to thank my esteemed colleagues:
Dr.
Yue Ning, Dr.
Hao Wu, Dr.
Brian Goode, Dr.
Wei Wang, Dr.
Saurav Ghosh, Dr.
Prithwish Chakraborty,
Nikhil
Muralidhar,
Dr.
Fang Jin,
Rongrong Tao,
Malay Chakrabarti,
Dr.
M.
Shahriar
Hossain,
Dr.
Patrick Butler,
Dr.
Samah Gad,
Dr.
Huijuan Shao,
Dr.
K.S.M.
Tozammel
Hossain, Mohammad Raihanul Islam, Yaser Keneshloo, Debanjan Datta, Subhodip Biswas,
Sneha Mehta, Dr.
Parang Saraf, and Dr.
Siddharth Krishnan.
Especially,
Aravindan Mahendiran,
Sathappan Muthiah,
Michael
Shuffett,
and Taoran Ji,
who helped me a lot during my graduate studies at Virginia Tech.
I am very thankful
for
their friendship and camaraderie.
I also want to take this opportunity to thank Juanita Victoria,
Wanawsha Hawrami,
and
Joyce Newberry for their incredible support on countless occasions when I needed help.
vii
Contents
List of Figures
xi
List of Tables
xv
1
Introduction
1
1.1
Research Problems
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
1.1.1
Emergent Theme Assessment
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
1.1.2
Visual Theme Refinement
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
3
1.1.3
Query Contextualization .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
4
1.1.4
Query-driven Event Characterization .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
4
1.2
Organization of the Dissertation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
5
2
Background
7
2.1
Microblog Event Retrieval Task .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7
2.2
Dynamic Query Expansion (DQE)
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
8
2.2.1
DQE for Microblogs
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
2.3
Visualizing Rankings
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11
2.4
Threat Analytics
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
12
2.4.1
Airport Threats .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
14
2.4.2
Cyber Threats
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
3
Adapting DQE for Relative Ranking Analysis of Emerging Themes
17
3.1
A Scalable Framework for DQE .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
viii
3.1.1
Data Ingest & Enrichment
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
3.1.2
Modeling Target Theme
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
3.2
DQE for Tracking Emerging Themes
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
21
3.3
Ranking Emerging Themes
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
3.4
Evaluation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
3.4.1
Evaluation Metrics
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
3.4.2
Performance Analysis
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.4.3
Case Studies
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27
3.5
Summary
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
4
Incorporating User Feedback in DQE for Theme Refinement
30
4.1
Visual Analytic Framework
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
4.2
ThreatFlows .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
4.2.1
Interface .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
4.2.2
User Interactions
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
4.3
Modeling User Preferences .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
4.3.1
Theme Refinement
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
4.3.2
Rank Refinement .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
40
4.3.3
Rank Flow Layout Algorithm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
4.3.4
Narrative Reporting
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
4.4
Preliminary User Study
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
44
4.4.1
Design .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45
4.4.2
Results
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
4.5
Case Studies .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
4.6
Summary
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
ix
5
Improving DQE with Semantic Context-aware Retrieval
54
5.1
Preliminaries
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
5.2
Structured Retrieval
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
5.3
Dynamic (Typed) Query Expansion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
59
5.4
Cybersecurity Event Detection
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
61
5.5
Evaluation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
63
5.5.1
Datasets .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
63
5.5.2
Baseline Methods .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
64
5.5.3
Measuring Performance
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
66
5.5.4
Case Studies
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68
5.6
Summary
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
71
6
Augmenting DQE with Hypergraph Learning
72
6.1
Preliminaries
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
73
6.2
Semantic Hypergraphs
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
74
6.2.1
Hypergraph Construction
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
76
6.2.2
Hypergraph Learning .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
76
6.3
Dynamic Query Expansion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
77
6.4
Evaluation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81
6.5
Summary
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82
7
Conclusion
83
7.1
Future Work
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
85
Bibliography
87
x
List of Figures
3.1
An overview of the relative threat ranking system. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
3.2
Illustration of
news-Twitter reciprocity (left) and dynamic query expansion
(right) around the shooting incident at Houston Airport (IAH) on 5 May
2013.
We show how the news reporting (vertical dotted line) closely overlaps
with bursts in Twitter activity (blue color bars) which are then dynamically
tracked (see word clouds) by our model over time.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
3.3
Distribution of 198 GSR events from January 2013 to August 2015.
.
.
.
.
.
25
3.4
This rank flow diagram indicates the relative rankings generated using our
OSI (P2) model.
The row order of
the (threat) denotes how these airports
compared among each other in their threat ranking (in the grey box), and the
number (rank) next to each airport code indicates their global ranking across
all 45 airports (selected for the study).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.5
These plots show timelines of
several
reported GSR events and our threat
evaluation at those airports.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
29
4.1
The interface of
ThreatFlow:
A visual
analytics tool
for analyzing relative
airport threats determined from open source indicators.
The rank flow (A)
displays the rank order (decreasing threat) and represents quarterly changes
in rankings (since 2013) for those U.S airports which have appeared at least
once in the top 15 list of our threat index.
The user can select a specific threat
flow (B) that displays (below the chart) - an automatically generated narrative
detailing the trend of a selected airport (C); the tweets (E) and matched news
articles (F) from which that airport’s threat score is shown in center panel
(D); a gold standard report (GSR) of known threat-related airport incidents
(G).
Users can vertically adjust airport rankings in the rank flow or remove
noisy tweets and unrelated GSR incidents to trigger a re-scoring of
threats
and layout of the rank flow.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
xi
4.2
System Overview:
(a) data preprocessing (b) airport threats tracking and
scoring models (c) user interactions (d) rank flow based visualization and
data views.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
4.3
Primary system components and visualization panels.
The six thought clouds
illustrate the essential
questions for situational
awareness.
The dashed lines
from each thought cloud map the thought to the corresponding panel.
Solid
lines from system components map the information flow to their correspond-
ing visualization panels.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
35
4.4
For each tweet that was used to calculate the threat score of
the current
airport the tweet review panel, displays that tweet’s content and the number
of news articles identified as related to this tweet.
Users can indicate tweets
as “non-relevant” via checkboxes.
In this example,
a user entered a search
term to more easily remove the tweets related to an incident that the user
feels should not be involved in this airports threat ranking.
Not only do these
tweets refer to an event that seems to have had no malicious intent, but also
the incident occurred at nearby LGA but incorrectly assigned to nearby JFK.
37
4.5
The gold standard report
panel
displays a list of
threat-related events that
have occurred at the given airport.
News reports contribute to the threat
score for each airport.
In this example, the user has used a regular expression
search to find events that are potentially not relevant to the current line of
inquiry.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
38
4.6
Our visual analytics loop is designed to support the refinement of airport rank-
ings and the development of the threat tracking model through user feedback
workflows.
The primary tasks are adjusting rankings and performing abla-
tion on the inputs to the scoring algorithm.
The system’s visual environment
allows the analyst to generate insights for situation assessment which then
can be communicated to stakeholders.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
38
4.7
The questionnaire results for the 11 ease-of-use questions answered by study
participants on a 7-point scale.
The chart shows the average, minimum, and
maximum responses.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
47
xii
4.8
An annotated timeline of relative airport threats rankings (from weekly aggre-
gates) of George Bush Intercontinental Airport (IAH), Detroit Metropolitan
Airport (DTW),
Logan International
Airport (BOS),
and EWR.
For each
airport, we highlight the GSR incident which led to the high threat rankings
between February 18, 2013, to July 21, 2013. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
4.9
An annotated timeline of relative airport threats rankings (from weekly ag-
gregates) of Los Angeles International
Airport (LAX),
Denver International
Airport (DEN),
and DTW.
We observe that in cases when a flight gets di-
verted from (DTW) to another unscheduled destination (DEN), the relative
rankings for both involved airports get elevated.
These rank flows show rela-
tive threats determined March 31 to May 11, 2014.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
51
4.10 Between January 19,
2015 through February 1,
2015 several
ISIS-inspired
threats were issued via Twitter against over 20 airlines in continental US. We
show using this annotated timeline of relative airport threats rankings (from
weekly aggregates) for some 13 US airports.
We observed the largest uptick
in threat rankings for BOS, Orlando International Airport (MCO), and San
Diego International Airport (SAN).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
5.1
Dependency parses of an input query and reference text.
.
.
.
.
.
.
.
.
.
.
.
54
5.2
A dependency tree diagram of a cyber-attack related tweet illustrating short-
range (local) and long-range word-word dependencies. .
.
.
.
.
.
.
.
.
.
.
.
.
59
5.3
A schematic overview of the cybersecurity event detection system.
.
.
.
.
.
.
62
5.4
Streamgraph showing normalized volume of tweets (August 2014 through Au-
gust 2015) tagged with data breach (red), DDoS activity (grey) and account
hijacking (blue) types of cyber-security events.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68
5.5
Streamgraph showing normalized volume of tweets (September 2015 through
October 2016) tagged with data breach (red),
DDoS activity (grey) and ac-
count hijacking (blue) types of cyber-security events.
.
.
.
.
.
.
.
.
.
.
.
.
.
69
5.6
Query expansions (size is proportional to the query’s feature score) produced
on October 22 2016 for the DDoS attack on DNS provider Dyn.
.
.
.
.
.
.
.
69
xiii
5.7
Ashley Madison website data breach.
The streamgraph shows the bursty
normalized volume of tweets related to the data breaches.
Along with all the
query expansions (size is proportional to the query’s feature score) produced
at each iteration of TypedDQE.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
70
5.8
Query expansions (size is proportional to the query’s feature score) produced
from the U.S CentCom Twitter account hijacking event.
.
.
.
.
.
.
.
.
.
.
.
70
6.1
An example of lexical hypergraph constructed from four tweets.
.
.
.
.
.
.
.
76
6.2
This plot shows distribution of embeddings of subset of top words from tweets
in our dataset from August 4, 2014.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
79
7.1
Wordclouds showing expansions from three different DQE approaches.
.
.
.
84
7.2
Wordclouds showing expansions from DQE for specific seed queries.
.
.
.
.
.
85
xiv
List of Tables
3.1
Seed keywords for target theme identification.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
3.2
Comparison of ranking performance and relevance.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.3
Comparing of matching performance.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27
4.1
Top 10 Ranked Airports for April 2013. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
5.1
Seed queries for cyber-attack events.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
60
5.2
A sample of negative instances for cyber-attack events used in the evaluation
of target domain generation methods.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
64
5.3
Seed intances for data breach, DDoS and account hijacking.
.
.
.
.
.
.
.
.
.
66
5.4
Contingency table used to assess cyber-attack related tweet detection results.
67
5.5
Overall evaluation of cyber-attack detection.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
67
5.6
Matching the detected events with the GSR.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68
6.1
Event Detection Performance
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82
xv
Chapter 1
Introduction
On social networks at any given time, a wide-variety of evolving topics are being discussed
referring to domain-specific news or events.
Social media is a sensor of various societal events
such as disease outbreaks [99], civil unrest, and natural disasters [93].
Therefore, to improve
the quality of downstream analysis in decision-support systems, it has become necessary to
develop tools to increase the contextual relevance of information retrieved.
With the exponential growth of user-generated data, significant challenges persist in informa-
tion retrieval
from unstructured,
microblog text.
Informal
language use,
out-of-vocabulary
terms, and overlapping, fragmented discourse are common characteristics of social media use.
Furthermore,
typical
user search queries have limited context and may contain terms with
multiple meanings, thus, creating a fine-grained lexicon is impractical.
Then, to filter down
to only most relevant and usable information from microblog text, we also need to address
the problem of
contextual
mismatch and information overload.
Specifically,
we require a
systematic framework of dynamic methods which can adapt to evolving discussions through
query expansion, target the intended domain through contextual cues and succinctly charac-
terize domain-relevant themes for the end-user.
In traditional IR systems (such as web search
engines), query reformulation is possible through search log mining, but in microblog-based
systems, this is infeasible due to the sheer volume and dynamic context of social media data.
These are some of the critical
considerations for state-of-the-art information retrieval
(IR)
system that uses a microblog corpus.
Social
media as a crowdsourced sensor serves as a proxy for public opinion for emerging
societal
events and provides critical
insights into these events.
The query expansion-based
retrieval using social media should be able to comprehensively focus on the targeted domain
generation in a minimally supervised manner,
using only a small
set of seed event triggers
and require no training or labeled samples.
1
2
Chapter 1. Introduction
1.1
Research Problems
In this dissertation, we explore the immense potential of the dynamic query expansion (DQE)
methods that apply to microblogs, by proposing the following research questions:
1.1.1
Emergent Theme Assessment
An analysis of emerging themes that originate from open source indicators (such as Twitter-
like microblogs) can be a very challenging cognitive task.
In real-world scenarios,
the re-
quirements for any large-scale predictive analytic system go beyond the implementation of
robust dynamic theme tracking methods.
They are also used for sense-making and gathering
situational
awareness which undermines the validity of
their analytical
insights.
How can
we systematically evaluate targeted themes captured by the DQE methodology to provide a
situational assessment? We being by posing the following questions:
What should be the objective of a theme assessment? Providing information about
the degrees to which an evolving theme is associated with ongoing events such as those
about security can be a useful
goal
independent of
predicting the occurrence of
an actual
threat.
For instance,
based on historical
government data (such as crime,
terrorism,
acci-
dents, natural disasters) and other security-specific criteria (passenger or cargo flow volumes
at ports of entry), individual entities are logically and data-supported as primary concerns.
However, once we get beyond the major public hubs, determining the threat level faced by
mid-level entities becomes less intuitive and therefore benefits from data-supported analytic
approaches.
This information can help government agencies plan resources accordingly.
Should we cast this as a regression or prediction problem? Focusing on evolving
themes in isolation,
rather than collectively,
may result in misdirection of resources to less
severe problems.
The Department of Homeland Security risk management doctrine recom-
mends that agencies develop processes that “should facilitate the ability to compare risks,
as required,
across the organization.” Experiences from the state of California found rank-
ing methodologies useful
for comparing environmental
risks and these methods can apply
to comparisons of
other varieties of
threats.
Thus the objective is to (1) assess and rank
threats (2) critique underlying modeling and (3) explore alternatives for mitigation and
priority-setting [86].
1.1. Research Problems
3
The solution may lie in dynamically tracking and ranking target themes.
However, how do
we characterize the target theme, since event domains may contain sub-categories described
by one or more query terms?
Furthermore,
how can we adapt DQE to allow the relative
comparison of
one entity with another?
How do we determine the validity of
emerging
themes? When tracking themes for fixed entities (such as airports) whose social
chatter is
evolving, how do we aggregate and assess their longitudinal trends?
1.1.2
Visual Theme Refinement
To provide an integrated situational assessment, users need insights into how the themes are
evolving,
what the historical
trends are,
and how to isolate irrelevant information.
These
can be made possible with a framework that provides easy identification, visualization, and
interpretation of emerging themes from a decision-support point of view.
When presented
with the relative ranking of emerging themes rather than discrete events, a visual analytics
system must address the challenges to support resource planning, aid decision making, and
improve communication between enforcement agencies.
Specifically, in our case, a ranking-
based visual analytic approach should allow users to:
• reveal changes in rankings over time
• compare multiple rankings simultaneously
• infer the direction and magnitude of change of evolving flow
• identify normal and unusual flows
• prioritize entities based on which are improving and which need attention
Furthermore, given a model that dynamically quantifies and relatively ranks target themes
for specific entities,
how can we incorporate the users’
feedback to improve the underlying
data model? The model should iteratively learn a better representation of underlying data
and generate more accurate rankings.
In other words, what visual analytic approach allows
improvement in our model
by using user interactions to steer the underlying algorithms,
without users having to do so explicitly? Also, users may have subjective preferences on how
the entities should be ranked.
In such a case,
how do we model
those preferences so that
human cognitive bias does not invalidate data-supported evidence?
4
Chapter 1. Introduction
1.1.3
Query Contextualization
The mostly quasi-static and unadaptable nature of existing predictive analytic systems makes
them vulnerable to rapidly-evolving mechanisms of social media, and thus engender not just
a ‘warning deficit’ but also a ‘detection deficit’, i.e., an increase in the mean time between the
time of an event and its discovery.
One of the reasons why underlying methods fail to identify
domain-relevant events consistently is their inability to produce semantically coherent query
expansions.
For this, the critical question we address is how can we contextualize the query
expansion process so that it can consistently identify and include semantically coherent
expansion terms that allow easy encoding and characterization in an event-focused retrieval
process.
Further,
how do we maintain contextual
integrity in the (seed) query-based retrieval
that
reduces noisy inputs? How can we bring structure to our unstructured data form which can
then allow retrieval methods to target different domains with high specificity and coverage?
Another challenging task is to make the query expansion more robust, which can be done by
accounting for semantic term dependencies in the text.
Therefore, without having to rely on
a bag-of-words model or (window-based) term co-occurrences, how can the query expansion
process go about capturing long and short-range term dependencies?
1.1.4
Query-driven Event Characterization
Apart from the highly informal event reporting style of online social media users, the dissem-
inated information though interrelated is often incomplete or fragmented as the information
usually arrives in short bursts [23].
Identifying the complete picture of emerging events re-
quires extracting their key attributes and retrieving only the most relevant and up-to-date
information.
Microblog data is heterogeneous and contains relational attributes that arrive
in fragmented forms.
What learning mechanism can we adopt that can iteratively capture
event-focused characteristics from a stream of
short-texts containing incomplete informa-
tion?
Furthermore,
what event-semantic framework can we assume in query expansion to
identify semantic arguments (actions and agents) of an ongoing event at the same time,
in
the retrieval process?
Past work has focused on modeling the heterogeneity and (semantic) relational
aspects in
isolation.
How can we improve on those modeling approaches?
To capture event-related
1.2. Organization of the Dissertation
5
characteristics as new expansion terms, what categories of relational information are suited
for structured encoding of event reports in microblog? Next, given these high-order relations,
how do we represent them and induce a learning framework that can allow us to group
complex relationships among features and entities that best describe those events?
1.2
Organization of the Dissertation
The organization and goals of this dissertation are as follows:
In Chapter 2,
we present a detailed background on several
key topics and concepts that
we discuss in this dissertation.
We begin by explaining the microblog event retrieval
task
and several
emerging applications that use social
media for data-driven analytics.
We also
describe the role dynamic query expansion plays in the retrieval
task and related work in
this field.
We discuss in detail the applications of DQE-based retrieval for Threat Analytics.
Finally, we discuss two specific types of threats - aviation security (threats on airports) and
cyber attacks - which can be related to user activity on social media.
In Chapter 3,
we present an automated system for the relative ranking of
airport threats
that integrates real-time ‘situational
awareness’
using open source indicators (Twitter and
news).
With the help of an evaluation of over 45 US airports we illustrate the capabilities
of our ranking system in effectively identifying deliberate and emergent trends.
In Chapter 4,
we present a novel
visual
analytics system that allows exploration and in-
vestigation of
relative airport threats rankings.
We discuss in detail
different interactions
and underlying algorithms this interactive system offers to the users to steer the back-end
retrieval model.
In Chapter 5, we demonstrate the feasibility of using social media as a crowdsourced sensor
for detecting and providing insights to cyber-security events.
We describe a dynamic query
expansion method that makes use of dependency parsing of text which allows extraction of
rich event attributes (e.g., attack type and targets) to assist analysis or even forecasting.
In Chapter 6, we propose a dynamic query expansion algorithm using hypergraph learning,
to model
high-order dependencies that represent event attributes.
We show that a query-
driven event characterization strategy is adept in modeling incomplete information.
We
evaluate our approach on an event detection task for two themes -
civil
unrest and data
6
Chapter 1. Introduction
breach events.
In Chapter 7, we list our contributions towards augmenting dynamic query expansion meth-
ods for microblog event retrieval
task and present the scope of future work for each of the
proposed augmentations.
Chapter 2
Background
2.1
Microblog Event Retrieval Task
Societal
events can be detected by modeling population-level
dynamics where online users
and their content act as real-time and ubiquitous social
sensors.
Large body of
related
work focuses on Twitter to extract various events such as trending news [5,
89],
natural
disasters [93],
criminal
incidents [112]
and population migrations [79].
Common event ex-
traction methods include simple keyword matching and clustering, and topic modeling with
temporal
and geolocation constrains [9,
105,
121].
A variety of
methods have been pro-
posed for such event detection by formalizing notions of spatial
burstiness [119],
temporal
burstiness [116],
or spatiotemporal
burstiness [49],
in applications such as detecting earth-
quakes [93]
and tracking disease outbreaks [3,
48].
Event forecasting,
on the other hand,
aims to predict future events based on early signals extracted from tweets.
Example appli-
cations include detecting activity planning [8], predicting stock market movements [11, 83],
traffic conditions [37],
and forecasting socio-political
events such as civil
unrest [85]
and
elections [76, 110].
The data modeling approaches in most of these studies focus on identi-
fying and mapping predictive features from content such as sentiment scores,
latent topics
or volume of keywords to event characteristics.
A majority of research for detecting the emergence and continuously tracking the evolution-
ary dynamics of
a specified theme adopts a classification framework to extract themes or
topics from texts as contextual features [93]; online social interactions such as friendships [57]
or user mentions [87].
In another approach, joint frameworks to model textual content and
social networks [119] using a query expansion method that expands keywords in Twitter het-
erogeneous information network through multiple relationships including term occurrence,
user friendship, tweet replying, and user authorship.
We can group theme tracking in social
media into two categories:
general and targeted theme tracking.
7
8
Chapter 2. Background
General
Theme Tracking:
focuses on discovering and delineating hidden patterns in
the data.
A majority of
research in this specific area is centered around analyzing latent
topics [67] and inter-relationships between multiple data sources [38].
Targeted Theme Tracking In contrast, the targeted approach entails detecting the emer-
gence and continuously tracking the evolutionary dynamics of
a specified theme such as
airport threats,
crime,
or earthquakes.
The majority of research in this area adopts a clas-
sification framework to extract themes or topics from texts as contextual
features [58,
93];
online social interactions such as friendships [57] and user mentions [87],
and;
joint models
of textual content and social networks [119].
Social
Media - News Reciprocity Another important line of
work leverages on online
social network’s dual role in event reporting [56, 96] and as a news source [1, 14] researchers
have explored the reciprocal
relationship of
social
media and conventional
news by com-
bining these two diverse sources of
information.
This reciprocity helps in validating the
trustworthiness of tracked themes or topic-focused social media content, improved retrieval
and relevance ranking of
both tweets [46]
and news articles [98],
and event-related news
summarization [74].
To uncover any symbiotic relationship between social networks and on-
line news media, studies (such as
[74]) show a principled framework for understanding the
symbiotic relationship between Twitter and news media.
Usually, multiple news articles are
reporting an event and its development, thus forming a story chain of news.
They define four
interaction states based on the type of
information flow between these two heterogeneous
datasets over time.
By clustering story chains using the sequential interaction states, where
each cluster contains the main topics of interests.
2.2
Dynamic Query Expansion (DQE)
The query term mismatch is one of
the significant issues in Information Retrieval
(IR)
systems.
To resolve this problem query expansion is used which can automatically expand
(or reformulate) the original
user query by including more related terms and aiming to
retrieve more relevant results.
Query expansion approaches must handle:(1) short query
length - the inherent sparseness of information in the users’ query terms and (2) redundant
or irrelevant terms from retrieved documents that may cause “query-drift” [69] in the query
expansion procedure.
One strategy to generate expansions is by determining a global context
2.2. Dynamic Query Expansion (DQE)
9
of terms or concepts which then can be leveraged to determine semantically similar terms.
This involves making use of concept network graphs extracted from an external
thesaurus
such as Wikipedia [2, 35] or ontologies (such as WordNet [59, 73, 78]) to introduce a broad
set of relevant terms or extract corpus-wide statistics such as term co-occurrences [18],
to
expand the results using terms pair with the highest similarity in the corpus.
In contrast to global analysis where the retrieval model uses an external thesaurus to identify
candidate expansions,
pseudo-relevance feedback (PRF) approach helps match the (seed)
user query to the input corpus assuming that the top-k results are most relevant and then
select new terms from the identified documents or re-weight the original query.
Majority of
the query expansion techniques are based on extracting candidate expansions
from the top-k relevant documents in response to the original
query.
To compute the top-
k ranked documents in the seed-query retrieval
run,
it is necessary to transform the data
collection into a representation that can be more effectively indexed and allows computation
of relevance score over the documents for a given query.
Depending upon the data source,
the choice of indexing and document ranking in the retrieval model may vary.
Traditionally,
indexed documents are represented as a collection of weighted terms and then ranked using
vector space model
[95].
Several
other ad-hoc strategies to document ranking have been
explored such as probabilistic relevance
[51, 91], statistical language models [118], weighted
document vectors using collection-wide statistics [84].
Expansion term extraction relates to generation and ranking of
expansion terms from the
top-k retrieved documents.
A majority of
approaches for this task involve heuristically
mining term-to-term associations from the relevant documents.
Poor queries tend to retrieve
a few relevant documents,
degrading precision and recall
after local
feedback loop.
Hybrid
approaches such as local context analysis [117] and those that combine large knowledge bases
(Wikipedia [4, 28, 39],
ConceptNet) and top-ranked documents provide a better metric for
selecting expansion terms by first identifying concepts from the input query to locate relevant
concepts in the linked knowledge base.
A key task that is common to both global and local techniques for automatic query expansion
is - the selection of
top relevant terms from a weighted set of
newly suggested,
candidate
expansion terms.
The choice of
term weighting & selection methods is a crucial
factor in
the effectiveness of expanded queries to provide more contextual information than the initial
query for improving the retrieval results.
It helps determine which subset of terms and how
10
Chapter 2. Background
to consider them for query reformulation.
Traditional
term selection methods either use corpus-wide statistics (such as Chi-Square
Statistic,
K-L Divergence) or term-association measures (such as Mutual
Information and
Co-occurrence Information [101]).
In the past, several studies [100] have also employed the
approach of combining multiple query terms selection methods to improve performance.
Even though the use of
domain-independent ontologies (such as WordNet) in IR tasks is
frequent,
they lack coverage and suffer from term ambiguity [65].
To overcome this,
use
of hybrid approaches [34]
consisting of a global
thesaurus and a dynamically created local
thesaurus.
Furthermore to improve recall,
use of
domain-specific knowledge models have
also been explored in IR applications for clinical
[18]
geography [31],
and multimedia [71],
medical [25, 27] and newswire [16] corpuses to name but a few.
2.2.1
DQE for Microblogs
To improve the performance of retrieval tailored for short text mediums or microblogs such
as Twitter, based on earlier work on query expansion to expand keyword sets [7, 64], retrieve
user-generated content [66],
and discover events [119].
The expanded keywords are typi-
cally extracted iteratively by exploring their co-occurrence with the specified initial
query
in textual
content and are then used to grow the vocabulary automatically.
Massoudi
et
al. [66] consider not only the co-occurrence but also the time information to score the related
terms to expand the query.
Similarly, in [64], vocabulary is built over time but rather than
pre-committing to a specific strategy,
they use a more sophisticated probabilistic formal-
ism to incorporate multiple indicators (social network, demographics, time) to help grow the
vocabulary.
A variety of query expansion methods exist that - are based on term/concept co-
occurrences using heuristics and language models;
incorporate social
network relationships
using graph theory based Zhao et al. [119] proposed a new iterative query expansion method
to expand both keywords and relevant tweets from seed query by considering both semantic
and social
network relationships,
and then do spatial
clustering on the extracted related
tweets to identify civil
unrest events.
Whereas,
proposed a new query expansion method
that expands keywords in Twitter heterogeneous information network through multiple re-
lationships including term occurrence, user friendship, tweet replying, and user authorship.
2.3. Visualizing Rankings
11
2.3
Visualizing Rankings
Ranking visualizations are used to reveal
relative comparisons between entities or abstract
groupings in data.
Typically, in multi-attribute ranking systems, the set of attributes which
describe the ranked entities are a limited set of fixed attributes (for example LineUp [33],
Podium [111]).
However, when ranked data points are from open source indicators such as
social
media,
where underlying attributes are dynamic (changing over time) and a much
broader set causes a “information overload” to both the computational
& cognitive tasks.
We can generalize these dynamic attributes with a notion of
a meta-attribute – a single
quantifiable target theme which can then be used to rank order entities Since,
retrieval
models often suffer from contextual mismatch (attributes are not equally trustworthy), which
then leads to a problem of incorrectly bloating relative ranks of entities.
Traditional
ranking visualization techniques use ranked lists,
tables,
scatterplots,
stacked
bar charts,
and pie charts can be used to compare data based on specific criteria or at-
tribute.
These techniques can also be adapted to compare multi-attribute rankings as shown
in LineUp [33] where authors developed an interactive framework to refine weights and map-
pings of multiple rankings using stacked bar charts segmented over different time periods.
Another example of
a visual
analytic system that ranks data is Podium [111]
that infers
a weighting model for attributes that satisfies user’s data preferences as closely as possible
(while remaining true to the underlying data).
It is motivated by the idea of mixed-initiative
visual analytics [19] which enables balanced collaboration between the human operator and
the algorithm to solve a common problem (of generating most accurate rankings).
In ranking based visual analysis it is becoming commonplace show how rankings change over
time,
for example,
how can we show evolving threats for the top 15 busiest airports in the
United States have progressed over time, relative to one another.
The RankExplorer system
proposed by Shi et al [97] uses stacked graphs to segment rankings and use a ThemeRiver [36]
to compare rankings over time.
Slopegraphs and their specialized form,
rank flows,
are an
excellent alternative to previous ranking visualization techniques.
In particular,
rank flows
allow intuitive visualization of the progression and encoding of relative rankings.
These are
essentially line charts between two time periods on an ordinal or interval scale.
Slopegraphs
were first introduced as Table Graphics [109] by Edward Tufte who described use cases for
showing the hierarchy of data elements, changes in the data over time, and, most significantly,
the rate of change.
Slopegraphs are an ideal way to contrast two sets of data, either showing
12
Chapter 2. Background
how the data changes over time, or how two groups are different [15].
Rank flows, or bump
charts (because of
the visual
effect provided by the crossings between flows or lines) help
visualize how one entity has surpassed the other entity in absolute terms, visually mapped by
their relative ranked order.
In a recent study, a similar ranking based visual analysis solution
was adopted in TrajRank [63] to analyze taxi travel behavior exploration by ranking relative
travel time on each road segment.
2.4
Threat Analytics
In homeland security applications,
real-time information gathering and recognition of pub-
licly available indicators that allow for early warning capabilities in decision-support systems
are increasingly important.
Nearly any real-world threat to the general public or critical in-
frastructures, such as airports, can be related to activities online, especially on social media
platforms.
However, while some homeland security areas benefit from significant amounts of data and
information to feed data analytics, others do not.
This scenario is especially acute for home-
land security assets where reliable intelligence reporting on threats are infrequent or do not
exist.
In the absence of threat reporting,
DHS assets rely on broader regional
risk assess-
ments that may not accurately convey the relative significance of threats they individually
face.
For example,
consistent and credible intelligence does not exist for each airport,
port
of entry, or critical infrastructure asset.
Due to the lack of robust indicators of the potential
threats, it is difficult to determine which data points best predict whether particular assets
are more attractive to threat actors than others.
This ambiguity frustrates analyst efforts
to develop accurate estimates about when, where, and how a threat will manifest [20].
With the advent of Web 2.0,
in the last decade,
homeland security operators have realized
the need for another class of automated systems that help gain “situational awareness”, viz.
using open source indicators such as social media.
Such systems entail real-time information
gathering and recognition of
publicly available,
indicators that allow for an early warning
signal capability in the system.
Under this paradigm, tracking threats are increasingly crucial
because any real-world threat to the general public or critical infrastructures such as airports
can be related to activities online.
To make a case for applying DQE-based approaches we
first address the following questions:
2.4. Threat Analytics
13
Are automated tools necessary? Traditional forms of security assessment are not real-
time and often do not exist for each airport and port of
entry.
Thus,
homeland security
professionals must rely on measures of the attractiveness of an airport as a target for attacks.
The volume and diversity of
social
media indicators make manual
collection and analysis
daunting.
Automated tools are necessary to handle these challenges.
Why is real-time analysis important? Analyzing real-time news and social media feeds
provide DHS with necessary tools that can enhance their existing investigative process.
Specific existing threat assessment processes are not set up to be real-time systems that
track emerging events.
Instead,
they are intended to look at which airports might draw a
threat actor to attack or exploit an airport’s conveyances,
facilities,
employees,
passengers,
cargo,
or surrounding area.
Real-time news and social
media feeds can provide greater
granularity at the airport level.
How relevant are open source indicators (news and social
media) for this un-
dertaking?
Is the objective to reproduce DHS rankings of threats using other
sources? Many agencies, including the TSA Office of Intelligence, already gather informa-
tion from several social media sites to mitigate threats and to promote situational awareness.
The goal
of tapping online social
media is to cast a wider net and to help develop a proxy
indicator of public opinion across the region.
Therefore, open source social media indicators
can offer the necessary context for policymakers in assessing the comparative threat across
the various critical infrastructure.
Threat Recognition using Open Source Indicator Early detection of threats based on
open source indicators could help prevent incidents.
However, the amount of user-generated
data in social media, blogs, and forums is rapidly increasing, and manual monitoring of each
source is time-consuming.
Therefore,
it is essential
to develop systems that rank messages
based on their threat potential
and thereby allow users to sift through data streams more
efficiently.
For instance, in [72] made an interesting observation the tendency that bad news
seems to travel fast on Twitter.
Therefore, research studies have targeted automated detec-
tion of
sinister motives in users’
tweets by using natural
language processing (NLP) tech-
niques.
Related keywords can be extracted using syntactic,
n-grams rules centered around
verbs [77] or trigger keywords [103] generated semi-automatically from a labeled training set
of threatening and non-threatening tweets.
There is a strong relationship between negative
sentiment in Twitter posts in the days leading up to disruptive social unrest events [41] and
border security-related issues [6, 80].
14
Chapter 2. Background
As people tend to join the discussion and post their opinions on social media, which makes
channels like Twitter a valuable information source, dynamic query expansion methods are
applied for tracking emerging threat-related chatter and can also be used to measure its
performance and effectiveness for retrieval & detection tasks for these threat-related domains.
Furthermore, we highlight below the need of DQE-based approaches for two such domains.
2.4.1
Airport Threats
Traditional
decision-support systems for airport security [81,
82]
have focused on resource
allocation and optimization problems.
These are built using a defender-adversary,
multi-
agent modeling approach to either simulate the interaction between the passengers and
the security system [114] or to aid the development of randomized schedules for patrolling,
checking, and monitoring by airport security.
In more recent research work, authors in [22]
developed a new system for multiple threat scenarios and handling uncertain interruptions
in the execution of
patrol
schedules,
which uses Markov decision processes (MDPs) in its
scheduling.
Still, aviation continues to face a complex and evolving threat environment.
From terrorists
who continually demonstrate a desire to conduct attacks,
to the smuggling of illicit goods,
animals,
weapons,
and bulk cash,
to criminal
networks smuggling and trafficking people –
aviation security must work to detect, deter, and disrupt various threats that pose a danger
to the traveling public or seek to exploit the system.
In 2015,
708 million passengers,
432
million checked bags,
1.6 billion carry-on bags,
and roughly 13 million airport employees
were screened.
In addition to seizing more than 100,000 dangerous prohibited items such as
explosives, drugs, and knives, more than 2,600 firearms were discovered across 236 domestic
airports (12 more than in 2014) at checkpoints in carry-on baggage.
Roughly 83 percent of
these firearms were loaded [107].
Consistently evolving nature of
threats also present unique challenges to aviation security
due to their complexity and potential impacts.
A terrorist threat increasingly characterized
by lone offenders and small
groups that are difficult to identify and counter;
transnational
criminal organizations that continue to expand in size, scope, and influence; and increasingly
sophisticated cyber intrusions capable of disrupting essential services are just a few examples
of this changing environment [24].
Faced with these challenges, the Department of Homeland
Security (DHS) recognizes the need to advance homeland security data capabilities to “fill
2.4. Threat Analytics
15
some of the gaps and mitigate some of the homeland security risks” through better informed
risk-based security strategies [106].
In this dissertation,
we address this void by building an automated system for the relative
threat ranking of airports that integrates real-time ‘situational awareness’ using open source
indicators (Twitter and news).
2.4.2
Cyber Threats
National
security policy makers and practitioners continue to face a demanding security
environment.
Terrorism, security breaches, smuggling, and increasingly sophisticated cyber
intrusions capable of disrupting essential services.
In recent years, online media such as blogs and social networks have become another promis-
ing data source of security intelligence [70, 115].
Most existing work focuses on technology
blogs and tweets from security professionals to extract useful information [108].
For example,
Liao et al.
build text mining tools to extract key attack identifiers (IP, MD5 hashes) from
security tech blogs [55].
Sabottke et al. leverage Twitter data to estimate the level of interest
in existing CVE vulnerabilities, and predict their chance of being exploited in practice [92].
Detecting and characterizing cyber-attacks is highly challenging due to the constant-evolving
nature of cyber criminals.
Earlier work primarily focuses on mining network traffic data for
intrusion detection.
Specific techniques range from classifying malicious network flows [52] to
anomaly detection in graphs to detecting malicious servers and connections [21, 26, 47, 75].
More recently, researchers seek to move ahead to predict cyber-attacks before they happen,
for early notifications [54].
For example, Liu et al. leverage various network data associated
with an organization to look for indicators of attacks [60,
61].
By extracting signals from
misconfigured DNS and BGP networks as well
as spam and phishing activities,
they build
classifiers to predict if an organization is (or will
be) under attack.
Similarly,
Soska et al.
apply supervised classifiers to network traffic data to detect vulnerable websites and predict
their chances of turning malicious in the future [102].
While the use of social
media cannot entirely supplant the need for internal
telemetry for
certain types of attacks (e.g.,
use of network flow data to detect malicious network behav-
ior [21,
47,
75]),
analysis of such online media can provide insight into a broader range of
cyber-attacks such as data breaches, account hijacking and newer ones as they emerge.
Our
16
Chapter 2. Background
work differs from existing literature since we focus on crowdsourced data from the much
broader user population who are likely the victims of
security attacks.
The most related
work to ours is [90] which uses weakly supervised learning to detect security-related tweets.
However,
this technique is unable to capture the dynamically evolving nature of
attacks
and is unable to encode characteristics of detected events.
In our work, we follow a similar
intuition to detect signals for major security attacks.
The key novelty in our approach, dif-
ferent from these works, is the need for a typed query expansion strategy that provides both
focused results and aids in extracting key indicators underlying the cyber-attack.
Chapter 3
Adapting DQE for Relative Ranking
Analysis of Emerging Themes
A more comprehensive understanding of emerging themes in social
media can help inform
decisions that guide resource allocations and security measures.
We posit that including a
broad range of
open source indicators (OSI) can account for some deficiencies in domain-
specific “sense-making” and incorporate public opinions for real-time “situation awareness”.
An automated approach to theme tracking in social media involves detecting the emergence
and continuous tracking of
the evolving dynamics of
specified themes.
A wide variety of
applications have been developed for tracking emerging themes in social
media related to
crime [112],
disease outbreaks [99],
socio-political
events such as civil
unrest [85],
and in
terrorism informatics [17].
In this chapter,
we detail
the problem of
adapting dynamic query expansion (DQE) that
enables automated tracking of emerging themes using a relative ranking analysis.
We specif-
ically address the problem of “information overload” in microblog event retrieval
tasks by
integrating rank-based analysis when tracking a fixed set of entities.
The relative ranking
analysis is commonly used in risk-ranking,
to derive relative assessments or an estimate of
how much risk is faced by a specific asset versus another similar one [86].
We then draw
insights about the relative ranking of each entity for a target theme.
This ranking approach
allows us to aggregate and assess longitudinal trends easily when tracking “dynamic themes”
(perceived threats at airports or reported crimes across cities) for fixed entities whose social
chatter is evolving.
The majority of existing research in targeted theme tracking adopts a classification frame-
work to extract themes or latent topics from the text as contextual
features [93]
or online
social interactions [57].
In contrast,
our approach leverages an unsupervised method [119]
that expands vocabularies and leverages on the reciprocal relationship between social media
and conventional
news.
By combining these two mediums,
we can evaluate the trustwor-
17
18
Chapter 3. Adapting DQE for Relative Ranking Analysis of Emerging Themes
thiness of content in discovered themes on social
media.
News-Twitter reciprocity has also
been shown to provide improved retrieval and relevance ranking of both tweets [46] and news
articles [98].
Using an aviation security theme as a case study, we present a scalable framework for DQE
that is comprised of three main components:
1.)
a dynamic query expansion algorithm for
tracking emerging themes, 2.) news-Twitter reciprocity modeling for capturing interactions
between social
and traditional
media,
and 3.)
a ranking scheme to provide an ordered
assessment of
airport threats.
This approach is not intended to determine an absolute
percentage of likelihood that an attack on an airport occurs,
or even to forecast an attack.
Instead, it can be used to gain additional situational awareness, prioritize resource planning,
plan security mobilization, and improve communication between enforcement agencies.
The
contributions of our work are:
1.
We articulate the problem of relative theme assessment and present the first automated
system, to the best of our knowledge, that provides an integrated situational assessment
of
the relative airport threats from open source indicators such as news and social
media.
2.
We employ a dynamic query expansion methodology with news-Twitter reciprocity
modeling to track evolving discussions on mutually reinforced multi-source data.
3.
We develop a ranking strategy to provide an ordered assessment of themes and cali-
brated to support situational awareness and resource planning while at the same time
being responsive to developing situations.
4.
Through various case studies on the US domestic airport system,
we highlight the
ability of our system to produce rankings that reflect developing security situations,
such as bomb threats, shootings, and airport diversions.
3.1
A Scalable Framework for DQE
Our proposed framework is illustrated in Figure 3.1.
It can be factorized into the stages of
enrichment,
query expansion,
news-Twitter reciprocity modeling,
and developing rankings
of relative airport threats.
These steps are detailed next.
3.1. A Scalable Framework for DQE
19
Data Ingest
News, 
Blogs
Seed 
Query-based 
Retrieval
Geocoding
Airport 
Annotation
Date 
Normalization
A
Data Sources
Airport 
Threat Index
Text Enrichment
B
Dynamic 
Query 
Expansion
Expanded Query-
based Retrieval
C
Spatial 
Clustering
News-Twitter 
Reciprocity 
Ranking 
Airports
Twitter
Threat 
Ranking Model
D
Figure 3.1:
An overview of the relative threat ranking system.
3.1.1
Data Ingest & Enrichment
Data ingest is done using a broad class of threat-related filters to query tweets (from Topsy
API) and news articles (from online web URLs mentioned in collected tweets) from January
2013 through August 2015.
Using Basis Technology’s Rosette Linguistics Platform
1
(RLP), the documents were subject
to tokenization,
lemmatization,
and named entity extraction.
Further enrichment includes
geocoding, airport annotation, and date expression normalization.
For geocoding, we exploit
both text features and metadata of a document such as (GPS) geotag, and descriptive meta
tags (e.g., in the HTML source of news articles) to extract multiple indicators which we then
use to perform spatial
queries in gazetteers (constructed using GeoNames
2
) to ultimately
yield the best (latitude and longitude) geolocation.
We also built a large regular expression
library that identifies IATA codes, canonical names, and aliases for airports mentioned in the
text.
For instance, the Seattle–Tacoma International Airport (SEA) is frequently mentioned
as ‘SeaTac’.
We use this library along with the geolocation information to map documents
(tweets and news articles) to the 45 busiest U.S.
airports (by total
passenger boardings
3
).
Finally, the TIMEN [62] package is used to normalize date expressions.
1
www.basistech.com/text-analytics/rosette
2
www.geonames.org
3
Wikipedia
20
Chapter 3. Adapting DQE for Relative Ranking Analysis of Emerging Themes
Table 3.1:
Seed keywords for target theme identification.
Category
Seed Keywords
Threat
bomb, gun,
scream,
smuggle, knife,
shot,
threat,
weapon, attack, crash, suspicious, terror, screen-
ing, scare, police, hoax, prank
Terrorism
dawla,
baqiyah,
shami,
caliphate,
muhajir,
ghuraba,
islamic state,
isis,
isil,
da’ish,
daash,
dabiq, kuffar, kafir, takfir, sharia
Airport
flight, tsa, air(port
|
line
|
plane
|
craft), terminal
Final Query:
(Threat OR Terrorism) AND Airport
3.1.2
Modeling Target Theme
For the first-pass retrieval of the target theme, we apply seed query filters which are presented
in Table 5.1.
These were identified with the help of
domain experts
4
.
Since the model
is
intended to capture more than just terrorism, these seed words serve as a starting point for
a broader collection of possible social media information related to airport threats.
We represent our microblog corpus as a collection of time-ordered tweets
D
=
{
D
1
,
D
2
, . . . ,
D
T
}
organized alongside T time slots.
Each subcollection
D
i
can be modeled as a heterogeneous
graph G =
{
V, E, W
}
,
where nodes V =
D ∪ F
consist of
two kinds of
nodes:
tweets
D
and features
F
(tokens,
hashtags,
user mentions).
Furthermore,
D
+
is used to denote the
target Twitter subspace comprising threat-related tweets,
and
D
−
=
D − D
+
denotes the
unrelated set.
E is the set of edges formed by a tweet node and the feature nodes it contains.
W is the set of
weights for nodes where higher weights denote a higher degree of
relation
between the node (either a tweet or a feature) and threat-related theme.
We posit that, in
targeted theme tracking,
D
and
F
are influenced by each other,
which translates to tweet
nodes with higher weight being more likely to have an edge with features nodes (such as
bomb,
gun) with higher weight.
In an ideal situation,
threat-related tweets could easily be
collected, using higher-weighted feature nodes as the query.
However, in practice, especially
in our noisy and dynamic medium, a static or fixed keyword set (even if provided by domain
experts) does not guarantee optimal performance for tracking evolving themes.
4
Analytic Services Inc., VA
3.2. DQE for Tracking Emerging Themes
21
3.2
DQE for Tracking Emerging Themes
Algorithm 1: Dynamic Query Expansion Algorithm
Input:
Seed query S, Twitter subcollection
D
Output:
Expanded Query
Q
Set
Q
(0)
= S, W (
Q
(0)
) =
⃗
1;
Set D
+
= match(
Q
(0)
,
D
), k = 0;
repeat
k = k + 1;
W (
F
(k)
) = B
·
C
·
W (
D
(k−1)
);
Q
(k)
= topn
(
W (
F
(k)
)
)
;
repeat
swap
(
min
(
W(D
+
)
)
, max
(
W (
D
−
)
)
)
;
σ = min
(
W(D
+
)
)
−
max
(
W (
D
−
)
)
;
until σ
≥
0// adjust subspace;
until W (F
(k−1)
t
) = W (F
(k)
t
)// DQE iteration;
Q
=
Q
(k)
;
Leveraging this heterogeneous network G, we developed a tracking method based on dynamic
query expansion (DQE) [119] techniques, to search for threat-related feature nodes
F
+
⊆ F
,
given only a small set of seed keywords.
Let
Q
(k)
,
D
(k)
and
F
(k)
denote a set of query terms,
tweet nodes,
and feature nodes at the kth iteration,
respectively.
During the initialization
procedure (lines 1
−
2 in Algorithm 7),
the theme-related query
Q
(0)
is initialized with S,
its weight W (
Q
(0)
) as a ones vector, and
D
+
as a set of tweets that match
Q
(0)
.
For the kth
iteration,
where k
≥
1,
as shown in lines 4
−
6 in Algorithm 7,
the new expanded query is
set as
Q
(k)
by selecting the top N weighted entities in
F
(k)
:
W (
F
) = B
·
C
·
W (
D
),
(3.1)
where B denotes the inverse document frequency (IDF) matrix of
F
, and C is the adjacency
matrix between
F
and
D
.
Note that this is a variant of the popular TFIDF term weighting
strategy.
Then,
as shown in lines 7
−
10 in Algorithm 7,
based on the weights of
feature
nodes,
DQE selects a target subspace
D
+
such that every tweet node in
D
+
has a higher
score than the tweet node in
D
−
, based on the following weighting strategy:
W (
D
) = Φ
·
C
′
·
W (
Q
),
(3.2)
22
Chapter 3. Adapting DQE for Relative Ranking Analysis of Emerging Themes
Here,
C
′
is the transpose matrix of C,
and Φ is the normalized coefficient that makes sure
the weights are normalized.
In this way, DQE will iteratively expand the query
Q
=
F
+
, as
shown in Algorithm 7.
The number of iterations required on average is minimal.
3.3
Ranking Emerging Themes
Our threat ranking approach is based on the joint modeling of
news-Twitter reciprocity
and the tweets collected from DQE.
Before threat scoring,
we first aggregate target tweet
subspaces spatiotemporally,
denoted by
D
+
t,a
where a
∈
A refers to a specific airport which
is used for spatial clustering [29].
We adopt the following clustering criterion:
D
i,a
=
∪
⌊
t
ς
⌋=i
D
t,a
,
(3.3)
where the parameter ς controls window size of temporally aggregation of
D
i,a
.
In our method-
ology, we begin with daily, spatially clustered tweets and ς is set to 7 which leads to weekly
aggregates.
SEED KEYWORDS
ITERATION 1
ITERATION 2
Expanded Query 
After Convergence
KHOU-TV: Man, armed with AR-15 
and a handgun, shot himself in the 
head near Bush Airport security 
#Houston - MT @KHOU: 
HPD says airport shooter walked in, fired 
2 shots in air w/AR-15; then shot self in head 
http://bit.ly/163ddgh
man just shot himself in head at 
security checkpoint in Houston airport. 
Armed with AR-15 & handgun. Fired 2 
shots in air, then shot himself
12:03 PM
12:07 PM
12:09 PM
Police taping off Terminal B at Bush Intl. 
Airport following shooting that left shooter 
dead. - @KHOU
1:04 PM
1 dead at Houston airport. 
Man fires off several shots 
with assault type weapon , Federal agents fire 
at him he then uses handgun on himself
12:46 PM
12:28 PM
One male armed with a gun suffers life 
threatening injuries after shots fired at 
Houston Intercontinental Airport - police 
#breaking
Figure 3.2:
Illustration of
news-Twitter reciprocity (left) and dynamic query expansion
(right) around the shooting incident at Houston Airport (IAH) on 5 May 2013.
We show
how the news reporting (vertical dotted line) closely overlaps with bursts in Twitter activity
(blue color bars) which are then dynamically tracked (see word clouds) by our model
over
time.
News-Twitter Reciprocity Modeling:
One straightforward approach to rank airport
threat levels is by their cluster size,
but this strategy may lead to bias due to several
fac-
tors.
For instance,
tweets (within each cluster) may have a higher degree of relatedness to
threats;
passenger traffic at airports is typically varied and can influence the size inferred
3.4. Evaluation
23
target subspace; and, finally, the noisy nature of Twitter can lead to inaccurate threat scor-
ing.
We overcome this by applying reciprocity modeling that consolidates the information
shared across the mainstream newswire and social media, which in turn helps us standardize
reporting levels.
To model this interaction, we first generate a keyword list for a given news article by combin-
ing the top 10 keywords from the tokenized content of tweets that mention a URL (of news)
and the named entities mentioned in the article.
Then, a TFIDF based filtering method [74]
is used to extract a set of tweets associated with this news, posted within a period.
We apply
this procedure for every news article, to build a set of (reciprocal) tweets H.
The alert value
of a tweet can then be determined by this interaction model:
v(d) =
{
α
·
W (d),
if d
∈ D
i,·
∩
H,
(1
−
α)
·
W (d),
else.
(3.4)
where v(d) denotes the alert value of tweet d, α is the coefficient used to trade off between
influence of unmapped tweets and the mapped news-related tweets.
Higher α will
lead to
news-related tweets making a larger contribution to the airport threat ranking.
By considering both the alert value of tweets for the current time window and the historical
assessments,
our approach to track the airport threat level
on ith time window can be
formulated as:
K(τ, a) = γK(τ
−
1, a) + (1
−
γ)
∑
d∈D
i,a
v(d),
(3.5)
where K(τ, a) is the threat level
of
airport a at time τ ,
γ determines the weight for the
current normalized threat value at this airport.
Then a ranking for each time window is
generated according to this threat value.
3.4
Evaluation
Our evaluation focuses on the following key questions:
1.
Do the airport rankings inferred by our approach correspond with known ground truth?
How does our system’s performance fare against a baseline approach?
2.
Is the automated system consistent in continuously monitoring the threat-related inci-
24
Chapter 3. Adapting DQE for Relative Ranking Analysis of Emerging Themes
dents for each airport, using multiple data streams? That is, does it produce relevant
measurements of the threat at each airport, over time?
3.
How easily can we uncover new threats from the airport rankings?
We use the data from January 2013 through December 2013 as the training set for tuning
parameters in our proposed open source indicators (OSI) based airport threats model:
α and
γ (described in Equation 3.4 and 4.1).
We learn two sets of parameter settings; in the first
setting (P1) where α = 0.1 and γ = 0, the influence of news reciprocity and historical priors
on the threat scoring of airports is minimal.
In the second setting (P2), we set α = 0.5 and
γ = 0.2, which allows higher influence of both attributes.
Groundtruth Dataset:
In the absence of any official ground truth or rankings to airports
threat levels,
we developed our gold standard report (GSR).
It contains detailed records
of
the known airport (threat-related) incidents that took place in the United States,
be-
tween 2013 and 2015.
This GSR was prepared using an independent (online) source
5
and
manual
web search.
Each GSR event contains the date of
the incident,
airport (IATA
code), description, URL of the news article referring to the incident, and a (manually anno-
tated) threat category.
The tuple gives an example of a labeled GSR event (DATE=“2013-
11-01”,
AIRPORT=“LAX”,
DESCRIPTION=“TSA Agent Killed - Gunman In Custody”,
URL=“tinyurl.com/laa6edq”,
TYPE=“Shooting” ).
We filtered this GSR for those 45 air-
ports that were considered in our study,
yielding a total
198 GSR events,
as shown in
Figure 3.3.
Those events which described ongoing investigations or follow up reports to
known incidents were excluded.
Also,
12 airports had no associated GSR events and were
excluded from our evaluation.
3.4.1
Evaluation Metrics
We make use of
three metrics to measure the performance of
the ranking approach that
assesses relevancy and coverage of airport rankings generated from our system.
Average Rank (M1): If an airport appears in a daily ranked list, we assume an incident has
been detected for that airport.
We then construct a maximum weighted bipartite matching
between the set of
detected incidents (I) and GSR events (E),
where allowable edges are
5
www.globalincidentmap.com
3.4. Evaluation
25
0 
6 
12 
18 
24 
30 
36 
LAX
MIA
ATL
JFK
EWR
CLT
PHX
SLC
BOS
SEA
DEN
ORD
SFO
DTW
DFW
MCI
IAH
AUS
DCA
PHL
MSY
MSP
SAN
IAD
LGA
BNA
HNL
PDX
SAT
SNA
SMF
RDU
1 
2 
2 
1 
5 
4 
7 
11 
12 
17 
136 
Fire Incident
Other
Sabotage
General Security Alert
Terrorism Threat
Shooting
Biochemical Threat
Security Breach
Threatening Behavior
Weapon/Ordinance 
Bomb Threat
Airports with no events in GSR: 
BWI, DAL, FLL, HOU, LAS, MCO, 
MDW, OAK, PIT, RSW, SJC, TPA 
Figure 3.3:
Distribution of 198 GSR events from January 2013 to August 2015.
those that satisfy an inclusion criterion, and weights on these edges denoted by their quality
scores.
The quality score (QS) of a match is the sum of a location score and a date score.
Location score (LS) is defined using in a straightforward manner:
if the airport names of an
(I, E) pair match, then LS has a value of 1, else it is 0.
Date score (DS) is defined as:
DS = 1
−
(min(date offset, window)/ window).
where the allowed time window is set to a 1 day offset.
Finally, for all determined matched
(I
−
E) pairs denoted as M , we calculate the average daily ranking score as:
AverageRank =
∑
(I−E)∈M
rank(I)
|
M
|
,
26
Chapter 3. Adapting DQE for Relative Ranking Analysis of Emerging Themes
where the rank(
·
) function returns the rank (by threat score) for the airport related with
incident I.
Rank Biased Overlap (M2):
We measure the similarity of determined rankings using the
rank-biased overlap measure (RBO;
[113]).
The RBO measure is based on comparing the
overlap of the two rankings at incrementally increasing depths.
RBO is commonly used in
comparing the results produced by online search engines and text retrieval systems.
Ranking Loss (M3):
This measure follows from the observation that at any specific time,
the ranking system may not provide the threat estimation for a specified airport.
We use
this metric to measure the coverage of our model.
Ranking Baselines:
We make use of
three baseline models to compare with our OSI
approach - (1) Raw Twitter Volume (RTV) based threat rankings are generated from the
total
volume of
tweets for each airport (larger volume translates to a higher rank for an
airport);
(2) DQE Volume (DQEV) refers to using only theme-relevant tweets and;
(3)
Tweet Score Value (TSV) using aggregated threat score (as shown in Equation 4.1).
3.4.2
Performance Analysis
We use M 1 and M 3 to evaluate overall ranking performance.
In comparison to baselines, as
shown in Table 3.2,
PI provides improvements in the criterion for average ranking,
but P2
produces a better score for (lower) ranking loss.
Table 3.2:
Comparison of ranking performance and relevance.
Model
Average
Ranking
Ranking
Loss
Weekly
Monthly
Quarterly
RTV
8.09
5
0.46
0.54
0.68
DQEV
4.73
66
0.41
0.55
0.70
TSV
4.73
66
0.37
0.49
0.68
OSI (P1)
3.50
66
0.38
0.40
0.69
OSI (P2)
7.80
1
0.49
0.54
0.69
We also evaluate the DQE approach for theme targeting compared to a fixed keyword set
filtering (RTV).
For each set of matched I
−
E pairs generated from DQEV and RTV,
we
manually inspected tweets, to validate if the detected incident(s) correspond to the matched
GSR event (E) or not.
Table.
3.3 summarizes the results of
this analysis,
which shows
3.4. Evaluation
27
Table 3.3:
Comparing of matching performance.
Model
Detected
Incidents
Matched
I-E Pairs
True
Positive
Matches
False
Positive
Matches
DQEV
8209
142
91
51
RTV
19757
184
89
95
that DQE is not only useful
in reducing noise (false positive matches) but also achieves
comparable recall (0.72) of ground truth events.
To measure the relevance, we compare the
similarity of rankings between our method and the GSR using the RBO score.
As shown in
Table 3.2, our quarterly performance across all airports are around 69% overall.
3.4.3
Case Studies
We visualize the ranked airports using rank flows which are an intuitive way to interpret
progression (of
threat
flows) and encoding of
relative rankings.
We present our results in
Figure 3.4, aggregated for every two months.
Due to space constraints, we show only those
airports that have appeared at least once in the top 15 positions of our rankings.
We observed
some very interesting patterns; for example, we can see characteristic (upward) bumps in rank
flows for airports signaling threat incidents.
For example in the case of Hartsfield-Jackson
Atlanta International Airport (ATL), the rapid increase in threat rankings towards the end
of
August 2014 can be attributed to the fact that during this period two very disruptive
events took place.
First, Ebola screenings at airports were started in October 2014 and ATL
was one of the 5 participating U.S. airports.
Second, a gun smuggling racket was uncovered
between ATL and JFK airports in late December 2014 (see Figure 3.5b),
where an ATL
baggage handler was arrested on December 10 in possession of 18 firearms
6
.
As shown in Figure 3.5a,
our system reported a series of
upticks in threat assessment for
Detroit Metropolitan Airport (DTW), Los Angeles International Airport (LAX), and Denver
International
Airport (DEN) that coincides with evacuation incidents due to false bomb
threats.
In the last few years,
we have also seen cases where users on social
media have
issued threats to airlines or specific flights.
One of
the most bizarre cases of
such social
media abuse was when a series of online threats were made using Twitter to over 20 different
6
tinyurl.com/hlksja2
28
Chapter 3. Adapting DQE for Relative Ranking Analysis of Emerging Themes
Jan'14-Feb'14
Mar'14-Apr'14
May'14-Jun'14
Jul'14-Aug'14
Sept'14-Oct'14
Nov'14-Dec'14
Jan'15-Feb'15
Mar'15-Apr'15
May'15-Jun'15
Jul'15-Aug'15
1
1
2
2
3
3
4
4
5
5
6
6
7
7
8
8
9
9
10
10
11
11
12
12
13
13
14
14
15
15
16
16
17
17
18
18
ATL
ATL
ATL
ATL
ATL
ATL
ATL
ATL
ATL
ATL
MIA
MIA
MIA
MIA
MIA
MIA
MIA
MIA
MIA
MIA
AUS
AUS
AUS
AUS
AUS
AUS
AUS
AUS
AUS
AUS
LAX
LAX
LAX
LAX
LAX
LAX
LAX
LAX
LAX
LAX
PHL
PHL
PHL
PHL
PHL
PHL
PHL
PHL
PHL
PHL
DEN
DEN
DEN
DEN
DEN
DEN
DEN
DEN
DEN
DEN
SEA
SEA
SEA
SEA
SEA
SEA
SEA
SEA
SEA
SEA
HNL
HNL
HNL
HNL
HNL
HNL
HNL
HNL
HNL
HNL
SAN
SAN
SAN
SAN
SAN
SAN
SAN
SAN
SAN
SAN
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
SFO
SFO
SFO
SFO
SFO
SFO
SFO
SFO
SFO
SFO
CLT
CLT
CLT
CLT
CLT
CLT
CLT
CLT
CLT
CLT
PHX
PHX
PHX
PHX
PHX
PHX
PHX
PHX
PHX
PHX
JFK
JFK
JFK
JFK
JFK
JFK
JFK
JFK
JFK
JFK
BNA
BNA
BNA
BNA
BNA
BNA
BNA
BNA
BNA
BNA
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
ORD
ORD
ORD
ORD
ORD
ORD
ORD
ORD
ORD
ORD
1
2
3
4
5
6
7
8
10
11
12
13
14
15
17
18
9
21
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
22
9
26
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
20
9
28
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
17
9
24
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
18
9
19
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
18
9
19
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
17
9
21
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
17
9
23
1
2
3
4
5
6
7
8
10
11
12
13
14
15
16
17
9
25
1
2
3
4
5
6
7
8
10
11
12
13
14
15
17
18
9
27
Figure 3.4:
This rank flow diagram indicates the relative rankings generated using our OSI
(P2) model.
The row order of the (threat) denotes how these airports compared among each
other in their threat ranking (in the grey box), and the number (rank) next to each airport
code indicates their global ranking across all 45 airports (selected for the study).
U.S. passenger planes in the last two weeks of January 2015.
We noticed high threat scores
(shown in Figure 3.5c) and corresponding bumps in relative ranks for several airports (such
as the SEA, JFK, and ATL), where flights were grounded and later evacuated in response to
the online threats made by terrorist organizations (e.g., ISIS) through fake Twitter accounts.
3.5
Summary
In this chapter,
we have presented a scalable framework of dynamic query expansion that
incorporates relative ranking analysis of
emerging themes.
With an additional
goal
of
in-
tegrating real-time situational
awareness using open source indicators (Twitter and news).
Our evaluation over 45 U.S. airports illustrates the capabilities of our system in effectively
identifying relative threats (dynamic themes) and their emergent patterns.
We show a high
degree of overlap and relevance between our generated, ranking index and the ground truth of
known list of airport incidents.
Our results should be interpreted as the order of magnitude
indications of potential threats, rather than actual predictions of attack incidence.
3.5. Summary
29
(a) False Bomb Threats
(b) Gun Smuggling
(c) Online Threats
Figure 3.5:
These plots show timelines of several reported GSR events and our threat eval-
uation at those airports.
Future work is targeted at factoring semantic context and user’s attitudes towards the secu-
rity assessment of airports so that comparative threat assessment and airport rankings are
not solely model-driven but incorporate expert judgments and values.
Chapter 4
Incorporating User Feedback in DQE
for Theme Refinement
Figure 4.1:
The interface of ThreatFlow:
A visual analytics tool for analyzing relative airport
threats determined from open source indicators.
The rank flow (A) displays the rank order
(decreasing threat) and represents quarterly changes in rankings (since 2013) for those U.S
airports which have appeared at least once in the top 15 list of
our threat index.
The
user can select a specific threat flow (B) that displays (below the chart) - an automatically
generated narrative detailing the trend of a selected airport (C); the tweets (E) and matched
news articles (F) from which that airport’s threat score is shown in center panel (D); a gold
standard report (GSR) of known threat-related airport incidents (G).
Users can vertically
adjust airport rankings in the rank flow or remove noisy tweets and unrelated GSR incidents
to trigger a re-scoring of threats and layout of the rank flow.
In this chapter, we present a visual analytics system that guides users toward a more com-
30
31
prehensive understanding of emerging themes.
The freedom offered by social media outlets
for people to join discussions and post opinions is a double-edged sword.
While this freedom
allows channels like Twitter to be a valuable source of information, it is nevertheless a chal-
lenging task for social
media based event detection systems to accurately determine which
data points best predict whether particular assets are more attractive to threat actors than
others.
There is a lack of robust models to extract and refine information about emerging
themes.
Consider a dynamic theme tracking scenario which relies on real-time information gathering
from publicly available data such as Twitter.
A dynamic theme represents a general
topic
(perceived threats at airports or reported crimes across cities) where its intermediate at-
tributes are not fixed (theme evolves).
Our goal with this system is to allow a visual analysis
that can quantify and aggregate the target theme for a known set of entities (such as airports
or cities).
The rank-based visual analysis can be used to compare the relative importance of
one entity to another and assess longitudinal trends.
A visualization of this ranking allows
for analysis of
the results of
the ranking algorithm and inspection of
its inputs.
Ranking
systems are useful in decision-making tasks which rely on sense-making or situational aware-
ness based on relative importance of ranked items.
We allow user interactions that allow the
algorithms to learn to better ranking models by excluding inputs or by explicitly re-ordering
ranks.
Users can examine how the ranking model would be different if certain parts of the
input data are left out.
Moreover, provides a set of user interactions that allow for (with the
underlying algorithms and inputs) that help establish a user feedback loop which ultimately
helps generate valuable insight.
Through several
case studies,
we present how our analytics solution can help situational
awareness of security operators for the identification of relative threats that correspond to
ongoing security mishaps and incidents at airports.
The system discussed in this paper
deals with the 45 busiest US airports to illustrate the capabilities of
our visual
analytics
framework in effectively identifying deliberate and emergent threat on airports.
The major
contributions of this work are as follows:
• We propose a design for visual analysis of relative airport threats and their data sources.
• We couple state-of-art algorithms in the targeted tracking of emerging threat-related
social media chatter with a human-centered, visual analytics loop.
• We incorporate user feedback indicating what indicators are relevant to the target
32
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
theme and how the model
can learn to generate better rankings of emerging themes.
This approach allows for in-depth exploration and investigation of determined threats.
• We provide threat reporting as natural
language generated narratives to help gain
quick insights for threat assessments.
• To the best of our knowledge, this is the first system for situational awareness of relative
airport threats from news and social media that allows for exploratory analysis via user
feedback.
Figure 4.2:
System Overview:
(a) data preprocessing (b) airport threats tracking and scoring
models (c) user interactions (d) rank flow based visualization and data views.
4.1
Visual Analytic Framework
We now describe a framework (shown in Figure 4.2) that fulfills specific requirements that
may not be addressed sufficiently for visual analysis tasks in decision-support systems.
We
believe in providing a more comprehensive understanding of themes.
Our goal for situational
awareness is to provide enough information for users to be grounded in their understanding
of
the rankings.
With the help of
multiple domain experts,
we identify features that are
necessary to enable situational awareness.
We present the following requirement analysis for
a visual analytic framework.
(Q1):
Which trends have the most
significant
impact?:
The visualization tool
should allow an analyst to make sense of the situation at a glance and to identify trends in
rank change over time.
(Q2):
Which airports are critical?:
The design should allow users to identify which
airports need the most attention.
The threat level
of each airport in the context of all
US
airports should be apparent.
4.1. Visual Analytic Framework
33
(Q3):
How did the situation evolve?:
The design should allow comparison of multiple
rankings and easy comprehension of changes in airport rankings over time.
Further, it should
also allow for visual inspection of an audit trail of threat flows for each airport so that they
can be used to support the cause of those rankings.
(Q4):
Which supporting data are irrelevant?:
The design should allow the user
to inspect the data used to generate threat scores for each airport.
To better understand
the threat score calculations,
users should be able to inspect the supporting data that was
used in those calculations and come to a determination about whether those data points are
valuable.
(Q5):
What if we ignore unrelated source data?:
Users should be able to select data
points that are either they believe to be poor indicators of
threat or which are irrelevant
to their current line of
inquiry and ablate these inputs from the threat scoring process.
Visualizations should update to reflect threat scores based on only data deemed relevant by
users.
(Q6):
How can the sharing of results be promoted?:
The design should provide
some automatic identification and narration of
new trends for each airport that will
help
communicate the relative significance of threats for a specific airport.
Airport Threats Ranking In Chapter 3, we developed a dynamic query expansion (DQE)
that enabled automated tracking of emerging themes.
We use the same approach to targeted
theme tracking to filter tweets related to the airport threats.
After aggregating Twitter data
by time and location,
we track airport threat levels by considering tweet alert values and
historical
assessments to assimilate new trends smoothly.
Given a certain time slot τ the
threat level for a certain airport a is:
K(τ, a) = (1
−
γ)(α
·
K(τ
−
1, a) + β
·
K(τ
−
2, a)) + γ
∑
d∈D
τ,a
v(d),
(4.1)
where K(τ, a) is the threat level
of airport a at time τ ,
α and β,
respectively,
control
the
influence of
an airport’s threat level
of
across different time slots,
and γ determines the
weight for the alert value of aggregated tweets at time τ .
After this calculation, airports are
sorted by K for each time interval τ to produce a ranking.
Visualizing Rankings:
Ranking visualizations are used to reveal
relative comparisons
between entities or groups in data.
Traditional
visualization techniques based on ranked
34
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
lists,
tables,
scatterplots,
stacked bar charts,
and pie charts can be used to compare data
based on specific criteria or attribute.
In the last chapter, we discussed several case studies
and compared the threat estimates for the top 15 busiest airports in the United States
have progressed over time,
relative to one another.
These techniques can also be adapted
to compare multi-attribute rankings as shown in LineUp [33]
where authors developed an
interactive framework to refine weights and mappings of multiple rankings using stacked bar
charts segmented over different time periods.
In Podium [111],
a multi-attribute ranking
system that learns to rank based on mixed-initiative visual
analytics.
It infers a weighting
model
for attributes that satisfies user’s data preferences as closely as possible.
Users can
users can indicate preferences and based on those interactions, the system attempts to model
using Ranking SVM.
In our case,
we generalize the dynamic attributes with a notion of a
meta-attribute – a single quantifiable target theme which can then be used to rank order
entities Microblog event retrieval model often suffers from contextual mismatch (attributes
are not equally trustworthy), which then leads to the problem of incorrectly bloating relative
ranks of entities.
4.2
ThreatFlows
In this section, we introduce ThreatFlows - visual analytics tool for analyzing relative airport
threats determined from open source indicators.
Our goal
for situational
awareness is to
provide enough information for users to be grounded in their understanding of
the threat
rankings in time.
In Figure 4.3 we illustrate the types of questions users need to answer to
orient themselves.
The rank flow should situate users in historical
trends and allow them
to form some mental
model
of
each airport’s relative threat level
in the near future.
For
each airport,
the visualization panels convey information that was considered relevant by
the ranking algorithm for that airport.
These views should provide some insight into the
models,
and the raw data used to produce the airport rankings and allow users to situate
themselves in the current lay of the land.
4.2.1
Interface
ThreatFlows is designed as a series of panels that encapsulate certain parts of the analysis
spatially.
It takes a flow-based visual
design that represents the dynamic development of
4.2. ThreatFlows
35
Figure 4.3:
Primary system components and visualization panels.
The six thought clouds il-
lustrate the essential questions for situational awareness.
The dashed lines from each thought
cloud map the thought to the corresponding panel.
Solid lines from system components map
the information flow to their corresponding visualization panels.
airport threat levels in a straightforward way.
The primary view,
the rank flow panel,
is used to show the entire threat level
of
airports
(for Q1-Q3).
This panel visualizes the emerging themes over time of airport threat levels as
a graph of airport rankings connected by edges.
Each rank node is represented as a fixed-
size colored rectangle which denotes a targeted airport.
Secondary panels for tweets and
GSR allow exploration of the data sources involved in the assessment system.
They provide
detailed metadata used for the theme assessment.
The Tweets Review panel
((shown in
Figure 4.4) tabulates the full
set of
tweets considered for assessing the selected airport’s
threat level (for Q4).
The GSR (Gold Standard Report) Review panel tabulates documented
threat-related events per airport.
The panel
design,
seen in Figure 4.5,
consists primarily
of
essential
items for describing the event including date,
event type,
and description for
that event (for Q4).
The definition of “threat” varies in different application scenarios.
For
instance, users may want to focus on bomb threats and ignore other less serious threats like
36
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
“laser pointed into cockpits”.
Furthermore,
a search box provides a way to filter the table
by regular expression.
Additionally,
a Narrative Reporting panel
displays an automatically
generated narrative report in natural language that describes the trends found in the current
airport’s change in threat level over time.
This display can aid users in analyzing the threat
rankings of
this airport and understanding resulting rank flows in a user-friendly manner
(for Q6).
We automatically identify both positive and negative trends of the airport threats
level development as shown in Figure 4.1.
This narrative report is updated every time user
interactions adjust the ranking for the current airport by either rank refinement or data
ablation operations.
A detailed description of the narrative reporting algorithm is outlined
in Section 4.3.4.
An automatically generated natural language description provides a quick
summary of rank change trends.
4.2.2
User Interactions
:
To overcome the limitations of a static system and to enable exploratory analysis, Threat-
Flows allows users to re-order the relative rankings of
airports.
These interactions allow
users to pose hypotheses about what they believe the ranking should be (rank refinement)
or about which data points are irrelevant (theme refinement).
As shown in Figure 4.6, after
each of these interactions, models recompute their results to provide an updated visualization
to the user who can then resume investigations and analysis.
Theme Refinement:
As per this interaction,
the user can indicate tweets that are non-
relevant based on keyword-searches in Tweets Review panel.
The typical use case is when the
user either notices false positive tweets or based on expert judgment have identified tweets
that are not as relevant to the domain.
In both cases, such “non-relevant“” tweets can bias
the features weights and lead to learning a poor retrieval
model,
which in turn generates
bloated or erroneously elevated rankings for airports.
Rank Refinement:
To allow users to express a ranking they would prefer,
ThreatFlows
allows for object-level interaction [53] in which users can adjust the row number of a specific
node by dragging it up or down.
The typical
use case is When the user wants to rank
one entity higher or lower than another entity.
This value judgment could be based on the
domain knowledge or their subjective preferernce.
Consider a case of
two airports - X (a
larger airport which translates higher twitter volume) and Y (a smaller airport with relatively
much lower twitter volume) such that X is preferred over Y, i.e., rank(X) < rank(Y). If the
4.2. ThreatFlows
37
Figure 4.4:
For each tweet that was used to calculate the threat score of the current airport
the tweet review panel, displays that tweet’s content and the number of news articles identified
as related to this tweet.
Users can indicate tweets as “non-relevant” via checkboxes.
In this
example, a user entered a search term to more easily remove the tweets related to an incident
that the user feels should not be involved in this airports threat ranking.
Not only do these
tweets refer to an event that seems to have had no malicious intent,
but also the incident
occurred at nearby LGA but incorrectly assigned to nearby JFK.
user notices for the same time that – airport Y has tweets on shooting incident whereas
airport X contains tweets reporting a passenger escorted off an airplane,
in such scenarios
users’
value judgment can help learn new weight vectors for attributes and generate more
accurate rankings.
38
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
Figure 4.5:
The gold standard report panel
displays a list of threat-related events that have
occurred at the given airport.
News reports contribute to the threat score for each airport.
In
this example, the user has used a regular expression search to find events that are potentially
not relevant to the current line of inquiry.
Figure 4.6:
Our visual analytics loop is designed to support the refinement of airport rankings
and the development of
the threat tracking model
through user feedback workflows.
The
primary tasks are adjusting rankings and performing ablation on the inputs to the scoring
algorithm.
The system’s visual
environment allows the analyst to generate insights for
situation assessment which then can be communicated to stakeholders.
4.3. Modeling User Preferences
39
4.3
Modeling User Preferences
This section first provides greater detail
on the two algorithms that correspond to taking
user feedback as input for dynamic query expansion to learn a new weighting model for tweet
user input.
We also describe the rank flow layout algorithm and narrative report generation.
Algorithm 2: DQE-Based Algorithm for Theme Refinement
Input:
Input Query Q
k
=
{(
v
i
, w(v
i
)
k
)}
; Heterogeneous network G = (V, E, W
k
, R)
Output:
Expanded query Q
p
; Updated weight vector W
p
; Filtered data T
p
r
Initialize:
Set T
k
r
←
Match (Q
k
, T )
if k is 0 then
Set w(T
k
r
) =
⃗
1 and w(T
−
T
k
r
) =
⃗
0
else
Update w(T )
k
= w(T )
k
·
R
repeat
repeat
Swap (min (w(T
k
r
)
k
) , max (w(T
−
T
k
r
)
k
))
σ = min (w(T
k
r
)
k
)
−
max (w(T
−
T
k
r
)
k
)
until σ
≥
0;
k = k + 1
w(F )
k
= D
F
·
A
F,T
·
w(T )
k−1
w(T )
k
= Φ
·
A
′
F,T
·
w(F )
k
σ = max (w(T
−
T
k
r
)
k
)
−
min (w(T
k
r
)
k
)
until σ
≤
0;
Set W
p
←
W
k
w(F
r
) =
{
w(v
i
)
k
∈
w(F )
k
|
v
i
∈
F
r
⊆
F
}
Q
p
=
{
(v
i
, w(v
i
))
|
v
i
∈
F
r
, w(v
i
)
∈
w(F
r
)
}
T
p
r
←
Match (Q
p
, T )
4.3.1
Theme Refinement
This algorithm incorporates feedback where the user has indicated which tweets that non-
relevant based on keyword-searches in Tweets Review panel.
As shown in Algorithm 2, based
on this interaction,
we model
user preferences to assign higher/lower weights to individual
tweets.
For this we create a relevance vector r(T )
= [1, . . . , 1, 0, 0, 1, 1, . . . , 1]
∈
R
that
40
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
denotes a indicator vector with 1 in all
positions except for a 0 in the indexes of
tweet
nodes that are marked irrelevant.
During the first-run of DQE when k = 0,
the algorithm
implicitly assumes that all tweets which contain any of the terms of input query as relevant.
It then proceeds to learn a global weight vector W for all (features & tweets type) attributes.
When the system registers an external
input where the user has explicitly marked specific
tweet type attributes as non-relevant, this information is recorded as relevance vector R, we
apply the relevance vector on the previously learned weight vector W
k
from the previous
kth iteration (last-run),
and re-run DQE with input Q
k
and W
k
.
This treatment allows
for learning of new lower weights for corresponding word features that have edges to “non-
relevant” tweets in the weighted heterogeneous Twitter network.
Now, when DQE iteratively
updates the weight vectors for tweet (T ) and features (F ) nodes.
Since the tweet and feature
nodes exhibit a mutually reinforcing relationship, the heterogeneous network may learn the
model that assigns more discriminative weights that can result in filtering out of all/partial
of the non-relevant tweets as per user’s preferences,
and/or inclusion of new tweets in the
filtered set.
4.3.2
Rank Refinement
Using the user’s value judgment as feedback on how to rank is the essential
purpose of
this refinement step.
As shown in Algorithm 2,
based on the user’s re-ordering to relative
rankings,
we transform user preferences into a set of
constraints.
For a given time point
in which the user has interacted with the system,
let’s say there is a set of n entities that
have been marked as updated (rank order changed),
For each marked entity a
i
we add 1
entity ranked above a
i
and one below,
to derive a set C = (a
u
, a
s
), (a
s
, a
q
), . . .
such that
rank(a
u
) < rank(a
s
), rank(a
s
) < rank(a
q
) in other words a
u
is preferred over a
s
and so on,
of ordered tuples that formalize the update constraints for rank refinement algorithm.
The
notion of deriving constraints (based on user preference of rank order) is similar to the one
described in Podium [111], in our case given the latest retrieval model = (Q
k
, G
k
) from the
kth run of DQE, and set of ordered pairs of airports as constraints C from the user feedback.
Then for each tuple (a
u
, a
s
)
∈
C, We learn new attribute (tweet & feature) vectors for a
s
with
respect to the fixed tweet weight vector of a
u
, until
∀
v
i
∈
T
u
, and
∀
v
j
∈
T
s
: w(v
i
)
≥
w(v
j
);
then after convergence we update the weight vectors in the original
retrieval
model
Once
all weight vectors based on derived constraints from the user feedback are derived, we do a
global update of the weight vector W
k
by running a single iteration with the entire dataset
4.3. Modeling User Preferences
41
Algorithm 3: DQE-Based Algorithm for Rank Refinement
Input:
Input Query Q
k
=
{(
v
i
, w(v
i
)
k
)}
; Heterogeneous network G = (V, E, W
k
);
Constraint Tuples C =
{
(
a
u
, a
v
)
}
Output:
Updated weight vector W
p
; Filtered data T
p
r
Set m = 0
for (a
u
, a
s
)
∈
C do
Set T
0
u
←
Match (Q
k
, T
∩
T
a
u
)
Set T
0
s
←
Match (Q
k
, T
∩
T
a
s
)
Set T
0
a
= T
0
u
∪
T
0
s
Set F
a
=
{
v
f
| ∀
v
e
∈
T
a
,
∃
v
f
∈
F : v
e
↔
v
f
}
Set x(T
u
∪
T
s
)
0
←
w(T
u
∪
T
s
)
k
Set x(F
a
)
0
←
w(F
a
)
k
Set j = 0
repeat
j = j + 1
x(F
a
)
j
= D
F
·
A
F
a
,T
a
·
x(T
a
)
j−1
x(T
a
)
j
= Φ
·
A
′
F
a
,T
a
·
x(F
a
)
j
if m
≥
0 or a
u
notUpdated then
Set x(T
j
u
) = x(T
u
)
j−1
σ = max (x(T
s
)
j
)
−
min (x(T
u
)
j
)
until σ
≤
0;
Update m = m + 1
Update w(T
u
∪
T
s
)
k
= x(T
u
∪
T
s
)
k
Update k = k + 1
w(F )
k
= D
F
·
A
F,T
·
w(T )
k−1
w(T )
k
= Φ
·
A
′
F,T
·
w(F )
k
Set W
p
←
W
k
w(F
r
) =
{
w(v
i
)
k
∈
w(F )
k
|
v
i
∈
F
r
⊆
F
}
Q
p
=
{
(v
i
, w(v
i
))
|
v
i
∈
F
r
, w(v
i
)
∈
w(F
r
)
}
T
p
r
←
Match (Q
p
, T )
that results in a new weight vector.
After which we recalculate the threat score for each
airport.
Usage Scenario:
To illustrate how the new rankings might reflect this,
consider the air-
port rankings from the month of
Apr’13 (shown in Table 4.1) before the user interaction.
From inspecting the weight vectors of the model we observed that the top contributing key-
42
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
Table 4.1:
Top 10 Ranked Airports for April 2013.
Rank
Airport
Known Incident(s)
#1
DCA
man arrested with loaded gun
#2
DTW
bomb squad evacuates airport; man arrested with pressure cooker
#3
BOS
emergency landing of airplane; unruly passenger escorted out of the plane
#4
JFK
bomb squad evacuates airport
#5
MIA
bomb squad evacuates airport; man arrested for false threat
–#6-9#– (ranked airports with no events but higher baseline volume of threat-related tweets)
#10
ORD
bomb squad evacuates airport
words were:
“gun” (0.87), “bomb” (0.71), “security” (0.68), “airport” (0.62), “threat” (0.54),
“squad” (0.52), “evacuate” (0.51), “arrest” (0.49), “airplane” (0.44).
Notice that the Logan Airport (BOS) is ranked #3 due to the large volume of tweets reporting
heightened security at the Logan airport in the aftermath of Boston Marathon bombing (15th
Apr’13).
Also, that the Chicago O’Hare International Airport (ORD) is ranked #10 due to
lower filtered, the volume of tweets as compared to preceding airports.
If
the user,
in retrospect believes that ranking of
BOS is bloated because of
the Boston
Marathon bombing and/or bomb-threats, in general, should have a higher weight than emer-
gency landing type of events.
So,
when we downgrade the ranking of BOS to below MIA,
with interaction (rank refinement) the new set of weight vectors include updated weights for
top contributing keywords:
“gun” (0.83), “squad” (0.68), “bomb” (0.66), “evacuate” (0.65),
“threat” (0.61),
“airport” (0.61),
“arrest” (0.58),
“security” (0.55),
“airplane” (0.35).
And
the in the updated rankings - overall
relative order of
airports DCA (ranked #1),
DTW
(#2),
JFK (#3),
MIA (#4),
BOS(#5) is maintained,
with weights of keywords like ”gun”
remain relatively unchanged.
Except, for BOS which is gets demoted to rank #5, due to the
new lower weights for words - “security” and “bomb”.
Moreover,
rank for ORD goes up to
#6 because of higher weights for expansions like “squad” and “evacuate”.
4.3. Modeling User Preferences
43
4.3.3
Rank Flow Layout Algorithm
The layout for each airport is essentially a stylized time series of
that airport’s relative
threat over time.
Because of
this,
computing the layout is relatively straightforward,
but
we did impose a few restrictions to make the resulting visualization more clear.
Because of
the relatively large number of airports represented in the chart, we are wary of introducing
too much visual
clutter.
We made the architectural
decision to show each airport over the
entire time range rather than allowing airport lines to fall off the bottom of the chart.
This
way users do not have to handle the complexity of learning a visual encoding that signifies
airports are dropping off before re-entering the main chart.
Some user interactions cause airport rank order to change.
Our interface animates the threat
flows from one layout to the next to avoid user disorientation.
Each such interaction involves
user input concerning the ranking of a single airport a.
At the beginning of each animation,
the flow for a will be highlighted, and the flows for all other airports will be ghosted.
First,
ThreatFlows system animates the flow for a at time t from its original rank to the new one
determined by the interaction.
We continue animating for each column, with a short delay
between each column,
until
the entire flow for a is updated.
After a is finished,
a similar
animation occurs for each other airport.
In cases where an airport needs to be added to or
removed from the visualization,
these new nodes will
be added or removed after all
other
airports have been updated.
4.3.4
Narrative Reporting
To integrate threat reporting into our visual
analytics system,
we implemented a trend
detection algorithm [13] based on wavelet analysis of the time-series representation for each
airport’s rank flow.
Automatic analysis of wavelet transforms of these time-series signals at
many scales detects not only different trends present in the signals but also their start and
end time points.
For example, as shown in Figure 4.1, ThreatFlows was able to automatically
identify two trends in the rank flows for Miami International Airport:
an upward trend from
June to October 2013,
and a downward trend from September 2014,
through June 2015.
We further augment this trend detection with rule-based heuristics such as “what was the
highest rank attained by this airport and for how long?”, Moreover, “how consistently does
this airport appear in the top K of airports ranked by threat?”.
We then map the statistics
44
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
Algorithm 4: Rank flow layout algorithm
Input:
a
:
airport to be re-ranked.
t
:
re-ranking happens at this column.
Set
cur
_
col
=
t
;
while
cur
_
col
is not visited do
increase transparency of
cur
_
col
;
cur
_
col
=
next column;
Set
airport
_
to
_
rank
=
a
;
Set
cur
_
col
=
t
;
while
airport
_
to
_
rank
is not visited do
while
cur
_
col
is not visited do
remove transparency of
airport
_
to
_
rank
in the column
cur
_
col
;
animate
airport
_
to
_
rank
from old rank to new rank;
cur
_
col
=
next column;
airport
_
to
_
rank
=
next airport;
from these identified trends to templated slot-and-filler natural
language structures.
For
example,
using the numerical
values from the example described earlier,
the upward trend
for Miami
International
Airport can be described using “steady increase” which is slotted
into a complex predicate construct as <“first
trend”,
“steady increase”,
“Jun-13 through
Oct-13”>.
At the end of this document planning step, we use SimpleNLG [32], a realization
engine for English,
for natural
language generation.
This engine allows for the integration
of
lexical
features and syntactic realization to provide a robust interface for constructing
syntactically correct English sentences for our narrative reports.
4.4
Preliminary User Study
We conducted a pilot user study to evaluate ThreatFlow’s effectiveness for ease of
use,
interpretable of visual information and how its overall utility as a situational awareness tool
for exploratory analyses of
the type that a domain expert might undertake.
This section
presents the study design and reports its results.
4.4. Preliminary User Study
45
4.4.1
Design
We asked 4 users to participate in the pilot study.
All participants had a strong foundation
in social media analytics and knowledge discovery.
One limitation of this study design is that
users were not domain experts on threat analytics,
with prior experience using situational
awareness tools.
We,
therefore,
plan to conduct other involving users that are practicing
professionals in the airport security industry.
Each user participated in one 45 minute study.
Each session began with a brief orientation
in which a moderator reviewed the concepts - role of social
media in threat identification,
types of airport threats and relative threat-ranking strategy used by the system.
Followed by
a functional overview which includes descriptions of information panels and user interactions
offered by the visualization system.
Once familiar with the basic operation of the system,
users were asked to perform a series of tasks which allowed them further acclimatize to the
system and gain experience with the specific types of questions that would be asked later in
the study session.
Tasks and Questionnaire
Each user was asked to perform 6 tasks designed to allow exploration of all
the functional
aspects of our design.
The first three tasks (T1-T3) focuses on the interpretation of relative
threat rankings and the identification of emerging trends from the rank flow visualization.
The next set of
tasks (T4-T6) focuses on users interacting with the tool
to identify noisy
data and what strategy is adopted to promote/demote specific airport rankings.
The specific
goals of the 6 tasks were as follows:
T1.
Identify 3 airports, which are most critical.
T1a.
Identify related tweets and corresponding GSR events for some of those airports
T2.
Identify 2 airports, which are the least critical.
T2a.
Identify related tweets and corresponding GSR events for some of those airports
T3.
Identify any trends from the threat flows
T4.
Identify and remove noisy tweets for a specific airport from one of those trends
46
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
T6.
Find an airport that seems too highly ranked; demote it down the rankings
T7.
Find an airport that seems ranked too low; promote it up the rankings
On completion, users were asked to complete a questionnaire which was to be answered on
a 7-point Likert scale (1=very easy, 7=very hard).
Questions on if it was easy or hard to:
Q1.
Learn how to use ThreatFlows
Q2.
Use once you’ve been trained
Q3.
Quickly assess the key trends for airports
Q4.
Interpret the narratives
Q5.
Compare the threat flows for a single airport over time
Q6.
Compare and follow threat flows for multiple airports over time
Q7.
Explore the cause of the determined threat flow
Q8.
Investigate the cause of the determined threat flow
Q9.
Adjust ranking of an airport
Q10.
Understand the changes that take place in the flow after doing data ablation
Q11.
Gain overall situational awareness from the system from the system
4.4.2
Results
We summarize the evaluation results from users’ responses to our questionnaire, descriptions
of their strategy and post-study feedback.
4.4. Preliminary User Study
47
Figure 4.7:
The questionnaire results for the 11 ease-of-use questions answered by study
participants on a 7-point scale.
The chart shows the average,
minimum,
and maximum
responses.
Questionnaires Response Summary
The results of
the questionnaire are shown in Figure 4.7.
As the responses show,
users
generally found the system relatively easy to use with marked improvement once additional
training tasks were provided.
Our central
visual
analysis technique - rank flows proved to
be very useful for users to deduce emerging trends of relative airport threats.
The question
Q4 which focused on providing an automated summary of the critical trends of single threat
flow for an airport.
The responses indicate satisfactory effectiveness for necessary narrative
capability offered by the system.
Questions Q5-Q8 focused on the ability of users to com-
pare and verify the cause of estimated threat flow.
The responses for this subset of questions
showed still
low,
but somewhat higher scores.
Since sifting through large numbers (some-
times thousands) of
tweets is a very challenging cognitive task.
We consider these scores
a sign of success given the inability of previous methods to handle such high-volume data
and information.
Questions Q9-Q10 covered the two re-ranking related user-interactions.
Users found the drag/move interaction to be the easiest to perform the task in the entire
questionnaire.
Meanwhile, pertaining the data ablation task which required multiple re-runs
of filter/select/re-rank steps to achieve the desired re-ranking effect, response question Q10
showed moderate user-friendliness.
The final
question Q11 gauges the overall
effectiveness
of our system as an aid to situation awareness.
To this, we recorded a positive response on
average.
48
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
Task Strategies
For the study tasks T1-T3, we identified two strategies that were adopted by the participants.
Two out of the 4 users first focused on the different types of ground truth events and their
descriptions to understand what are the relevant threat-related keywords.
Then they selected
one airport each from the top, middle and low ranked airports and analyzed their flow and
identify the associated tweets and their corresponding threat scores.
The other two users
focused on selecting airports based on their flow pattern that showed a sharp bump up/down
before proceeding to filter and explore their tweets for the specific time periods.
The study tasks T4-T6 allowed users to refine the rankings of
relative airport threats by
removing noisy tweets (data ablation).
The users reported more varied strategies in these
tasks.
Two out of four participants identified noisy signals by sorting tweets by decreasing
order of their estimated threat scores, but they selected their target airports in different ways.
One of
them focussed solely on the top-ranked airports (such as JFK,
BOS) whereas the
second participant identified airports which had the most number of associated tweets.
The
third participant reported the strategy of analyzing event descriptions to shortlist irrelevant
GSR events and then extract keywords from their descriptions to filter and remove tweets.
For example events describing on-going TSA investigations and interruptions caused laser
strikes were used as proxy to identify noisy tweets.
The fourth participant isolated airports
which showed a sharp bump up in their rankings and then drilled down for that specific
period,
in a brute-force manner to identify noisy tweets.
The user was able to find several
different keywords and hashtags (such as “guns”, “buccaneers”, “#precheck”, “#travel”) to
identify noisy tweets that applied to other airports.
General Feedback
Overall
the participants found the rank flows based,
visual
analysis approach using to be
quite intuitive.
The most frequent positive comments focused on the ease to identify emerging
trends of airport threats, events, and the associated tweets - “It is easy to check what tweets
were responsible for a given airport’s high rank“.
Moreover, recommended, to do an in-depth
investigation into the causes of threat flows - more automated drill-down tools are needed to
sift through tweets and remove noise.
A common issue that was raised by all users was the
transition speed of rank flows changing caused some disorientation when analyzing the effect
of re-ranking especially concerning changes to other airports.
With one user suggesting the
4.5. Case Studies
49
use of additional visual aid such as a bar chart showing the number of rank steps gained/lost
by either data ablation or manual
rearrangement of rank flows - “that would be useful
to
get a user action caused a quick picture how much change”.
Two of
the users reported
finding automated narratives useful
to interpret the (sub)trends of
threats at an airport.
One of them suggested adding a more detailed summary of evidence (such as the trends are
changing because users on Twitter are reporting a bomb threat in X airport during Y period)
extracted from tweets’
texts.
Another user suggested allowing the end-users to manually
add annotations to specific points in the rank flows that describe reasons for adjusting the
ranking.
Lessons Learnt
We identified several
potential
strategies which can be implemented to remove noisy data
during query expansion automatically:
A.
Sort tweets by decreasing order of their estimated threat scores
• Instead of topK selection of relevant documents use bottom-k removal for relevance
modeling
B.
Select airport with unusually high filtered volume
• Assume that domain-relevant documents are low in number
• Expansions with very high volume might not be of good quality
C.
Find irrelevant GSR events and then find key terms from event descriptions to search
noisy tweets
• Learn term quality indicators from negative instances
• Use both local and global methods for relevance
D.
Followed key trends (bumps in rank flows) and drilled down for those specific periods
• Add additional criteria for clustering terms by their “burstiness”
50
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
2013-W8
2013-W9
2013-W10
2013-W11
2013-W12
2013-W13
2013-W14
2013-W15
2013-W16
2013-W17
2013-W18
2013-W19
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
IAH
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
EWR
BOS
BOS
BOS
BOS
BOS
BOS
BOS
BOS
BOS
BOS
BOS
BOS
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
DTW
17-Mar
False bomb threats
http://tinyurl.com/d2sgjk5
01-Apr
Evacuation due
to suspicious item
http://tinyurl.com/j3vb86v
15-Apr
Flights banned over Boston
after marathon bombing 
http://tinyurl.com/zosbjoh
02-May
Shooter on airport 
http://tinyurl.com/zzvxcac
Figure 4.8:
An annotated timeline of relative airport threats rankings (from weekly aggre-
gates) of George Bush Intercontinental Airport (IAH), Detroit Metropolitan Airport (DTW),
Logan International Airport (BOS), and EWR. For each airport, we highlight the GSR in-
cident which led to the high threat rankings between February 18, 2013, to July 21, 2013.
4.5
Case Studies
News articles in the GSR indicate that the majority of threat-related incidents at airports
are due to false bomb threats.
Bomb threats can result from suspicious objects found in
either an airport or on board an airplane.
Finding such objects in airports can lead to an
evacuation of specific terminals.
For instance,
as shown in Figure 4.8,
our system reported
a series of upticks in threat assessment that coincided with evacuation incidents due to false
bomb threats for three airports:
Newark Liberty International Airport (EWR) in week 11,
Detroit Metropolitan Airport (DTW) in week 14,
2013,
and Los Angeles Airport in week
16, 2014,.
Also illustrated in our case studies are two separate incidents of shootings.
First,
as shown in Figure 4.8,
in 2013 at Bush Intercontinental
Airport (IAH) a shooter walked
into the airport and later killed himself.
A second major incident occurred at LAX,
which
frequently appears in our top 5 list of most threatened airports, wherein a gunman opened
fire in November 2013 and shot dead a TSA agent.
Only a month earlier, in October, several
dry ice explosions that were carried out by an airport employee took place.
These events
received extensive coverage in social media as illustrated in Figure 4.9,
where we can see a
sharp peak in detected threats for LAX corresponding to both these incidents.
In contrast,
when a threat is reported from onboard an airplane,
such as the discovery
of suspicious items mid-flight,
the safety protocol
is to divert them to the nearest possible
airport for evacuation and inspection.
In this case, we observed that our system appropriately
detects and reports the elevated threat levels for both airports:
the one from which the flight
4.5. Case Studies
51
2014-W14
2014-W15
2014-W16
2014-W17
2014-W18
2014-W19
1
2
3
LAX
LAX
LAX
LAX
LAX
LAX
DEN
DEN
DEN
DEN
DEN
DEN
DTW
DTW
DTW
DTW
DTW
DTW
17-Apr
Delta flight from DTW diverted
to DEN due to a bomb threat
http://tinyurl.com/znxnabw
17-Apr
False bomb threat
http://tinyurl.com/j3g3wpj
Figure 4.9:
An annotated timeline of relative airport threats rankings (from weekly aggre-
gates) of
Los Angeles International
Airport (LAX),
Denver International
Airport (DEN),
and DTW.
We observe that in cases when a flight gets diverted from (DTW) to another
unscheduled destination (DEN), the relative rankings for both involved airports get elevated.
These rank flows show relative threats determined March 31 to May 11, 2014.
originated and the one to which it has been diverted.
One such example is an evacuation
incident that occurred in late April 2014.
In Figure 4.9 we can observe high relative threat
scores for both DTW (origin) and DEN (redirected destination).
In one case of
online threats,
a United Airlines flight was evacuated before its scheduled
takeoff from John F. Kennedy (JFK) Airport on April 16, 2014, after the airlines spotted a
bomb threat on Twitter
1
).
In some cases, bomb threats from social media can lead to travel
disruptions across many airports.
One of the most bizarre cases of social
media abuse was
when a series of online threats were made using Twitter to over 20 different US passenger
planes in the last two weeks of January 2015.
In Figure 4.10 we show the evolution of the
threat for a few of the involved airports.
Several flights were grounded and later evacuated
in response to the online threats made by terrorist organizations (ISIS and Islamic State)
and through fake Twitter accounts.
1
http://tinyurl.com/httf9rn
52
Chapter 4. Incorporating User Feedback in DQE for Theme Refinement
2015-W2
2015-W3
2015-W4
2015-W5
2015-W6
2015-W7
ATL
ATL
ATL
ATL
ATL
ATL
JFK
JFK
JFK
JFK
JFK
JFK
IAH
IAH
IAH
IAH
IAH
IAH
MIA
MIA
MIA
MIA
MIA
MIA
MCI
MCI
MCI
MCI
MCI
MCI
SEA
SEA
SEA
SEA
SEA
SEA
LAX
LAX
LAX
LAX
LAX
LAX
ORD
ORD
ORD
ORD
ORD
ORD
BOS
BOS
BOS
BOS
BOS
BOS
LGA
LGA
LGA
LGA
LGA
LGA
DFW
DFW
DFW
DFW
DFW
DFW
MCO
MCO
MCO
MCO
MCO
MCO
SAN
SAN
SAN
SAN
SAN
SAN
Figure 4.10:
Between January 19,
2015 through February 1,
2015 several
ISIS-inspired
threats were issued via Twitter against over 20 airlines in continental
US.
We show us-
ing this annotated timeline of relative airport threats rankings (from weekly aggregates) for
some 13 US airports.
We observed the largest uptick in threat rankings for BOS,
Orlando
International Airport (MCO), and San Diego International Airport (SAN).
4.6
Summary
In this chapter, we present ThreatFlows, a novel ranking-based visual analytics system that
allows exploration and refinement of dynamic themes (perceived threats at airports or re-
ported crimes across cities) extracted from social media streams.
ThreatFlows incorporates a
dynamic query expansion ranking algorithm that can incorporate user feedback to learn and
update the weights for words & tweets that modeled as a heterogeneous graph.
We show-
case this system by applying it towards a real-world application of relative airport threats
rankings.
We also conduct a preliminary user study to evaluate our system and how it
aids sense-making and other knowledge discovery tasks to improve situational awareness of
airport threats.
Our rank flow based interface allows users to perform visual
analysis by
manipulating rank flows and by controlling the algorithm’s data inputs.
However, there are
4.6. Summary
53
still challenges that need future research:
C1:
Semantic clustering in tweets/news review panel.
In ThreatFlows, Tweets are a
critical
data source for the assessment of airport threat levels.
As users select rank nodes,
the tweets considered for that airport are shown in the tweets/news review panel
ordered
by their score.
However,
this may lead to a readability problem when the Twitter volume
is substantial.
Semantic clustering,
commonly used in text classification,
could be used to
group texts related to similar topics.
Thus,
a curated view of semantically grouped tweets
may help users to understand better the data considered in the system and perform data
ablation operations more efficiently.
C2:
Multi-source evaluation and presentation.
Currently, only Twitter and news are
involved in the assessment.
We plan to incorporate other social
media such as Facebook
and Tumblr into the threat assessment evaluation and thereby generate more comprehensive
output.
Furthermore,
we plan to design another view panel
to present the connections
between these multi-source social media signals.
In conjunction with the narrative panel, this
provides users a better understanding of the connection between information from different
sources and provide a clear picture of each airport’s security situation.
Chapter 5
Improving DQE with Semantic
Context-aware Retrieval
It is non-trivial
to harness social
media to identify all
aspects of
a general
event domain
accurately.
It can be particularly daunting for an event retrieval system to detect a range of
different events and determine their characteristics (e.g., the key players, the type of event),
in a noisy medium like Twitter,
and do so in a weakly supervised manner without any
requirement for training phase or labeled samples.
Prior work (e.g., [90]) relies on training
with annotated samples with fixed feature sets that are unable to capture the dynamically
evolving nature of cyber-attacks over time and are also unable to encode characteristics of
detected events, as we aim to do here.
In this chapter,
we augment the dynamic query expansion algorithm with query contextu-
alization.
The key challenge we address is:
how do we maintain contextual integrity in the
query-based retrieval that reduces noisy inputs?.
To illustrate, consider a query “user data
hacked”.
A simple bag-of-words approach match the reference text - “Try this growth hack
to analyze user data of your website”.
These approaches would fail to identify the semantic
Figure 5.1:
Dependency parses of an input query and reference text.
54
5.1. Preliminaries
55
context of the user’s query and contributes non-relevant documents in the first-pass of the
retrieval process.
An ideal approach should match only “user data” as shown in Figure 5.1.
To make the retrieval
more context-aware in our approach we allow structured retrieval
where we transform the text to their tree (constituency or syntactic parse) or dependency
parsed form.
Moreover,
then to measure the similarity between a query and documents in
the corpus, we recursively calculate all common paths over the “sub-structures”.
Our main contributions are:
• A novel
query expansion strategy based on dependency tree patterns.
To
model event reporting structure, we propose a dynamic event trigger expansion method
based on convolution kernels and dependency parses.
The proposed approach also
employs a word embedding strategy to capture semantic context between event triggers
and candidate event reports.
• A framework for cybersecurity event detection from online social media.
We
propose a dynamically typed query expansion approach that requires only a small set of
general seed event triggers and learns to map them to specific event-related expansions
and thus provide situational awareness into cyber-events in an unsupervised manner.
• Extensive empirical evaluation for three kinds of cyber-attacks.
We manually
catalog ground truth for three event classes:
distributed denial
of
service (DDoS)
attacks,
data breaches,
and account hijacking.
We demonstrate that our approach
consistently identifies and encodes events.
5.1
Preliminaries
The input to our methodology is a collection of time-ordered tweets
D
=
{
D
1
,
D
2
, . . . ,
D
p
}
organized along p time slots.
Let
D
denote the tweet space corresponding to a subcollection
D
i
,
let
D
+
denote the target tweet subspace (in our case,
comprising cyber-attack events),
and let
D
−
=
D − D
+
denote the rest of the tweets in the considered tweet space.
Definition 5.1. Typed Dependency Query:
A typed dependency query is a linguistic
structure that characterizes a semantically coherent event related topic.
Different from n-
grams, terms contained in a typed dependency query share both syntactic and semantic
56
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
relationships.
Mathematically, a typed dependency query is formulated as a tree structure
G =
{
V, E
}
, where node v
∈
V can be either a word, user mention, or a hashtag and ε
∈
E
represents a syntactic relation between two nodes.
Definition 5.2.
Seed Query:
A seed query is a manually selected typed dependency
query targeted for a certain type of event.
For instance, “hacked account” can be defined as
a potential seed query for an account hijacking event.
Definition 5.3.
Expanded Query:
An expanded query is a typed dependency query
which is automatically generated by the dynamic query expansion algorithm based on a set
of seed queries and a given tweet collection
D
.
The expanded query and its seed query
can be two different descriptions of the same subject.
More commonly, an expanded query
can be more specific than its seed query.
For instance,
“prime minister dmitry medvedev
twitter account hack”,
an expanded query from “hacked account”,
denotes the message of
an account hijacking event related with Russian Prime Minister Dmitry Medvedev.
Definition 5.4.
Event Representation:
An event e is defined as (
Q
e
, date, type), where
Q
e
is the set of event-related expanded queries, date denotes when the event happens, and
type refers to the category of the cyber-attack event (i.e., DDoS, account hijacking, or data
breach).
Here
Q
e
is a defined as a set because, in general, a cyber-attack event can be presented and
retrieved by multiple query templates.
For instance,
among online discussion and report
about event “Fashola’s account, website hacked”, the query template most used are “fashola
twitter account hack”,
“fashola n78m website twitter account hack” and “hack account”.
Given the above definitions,
the major tasks underlying the cyber-attack event detection
problem are defined as follows:
Task 1:
Target Domain Generation.
Given a tweet subcollection
D
,
target domain
generation is the the task of identifying the set of target-related tweets
D
+
.
D
+
contains
critical domain relevant information based on which the expanded queries can be mined.
Task 2:
Expanded Query Extraction.
Given target domain
D
+
, the task of expanded
query extraction is to generate a set of expanded queries
Q
=
{
q
1
, . . . , q
n
}
which represents
the relevant concepts delivered by
D
+
.
Thus set
Q
can be used to retrieve event related
information from other collection sets.
Task 3:
Dynamic Typed Query Expansion.
Given a small set of seed queries
Q
0
and a
5.2. Structured Retrieval
57
twitter collection
D
, the task of dynamic typed query expansion is to iteratively expand
D
k
+
and
Q
k
until all the target related messages are included.
5.2
Structured Retrieval
In traditional
information extraction (IE),
a large corpus of
text must first be annotated
to train extractors for event triggers,
defined as main keywords indicating an event occur-
rence [40].
However,
in our scenario using online social
media,
a manually annotated label
set is impractical due to the massive volume of online media and the generally noisy charac-
teristics of social
media text.
In this subsection,
we describe our target domain generation
wherein crowdsourced social indicators (tweets) of cyber-attack events are retrieved.
Target Domain Generation:
Given a query and a collection of tweets
D
, the the typical
way to retrieve query-related documentation is based on a bag of words model
[94]
which
comes with its attendant disadvantages.
Consider the following two tweets:
“have Riseup
servers been compromised or data leaked?” and “@O2 You completely screwed me over!
My phones back on, still leaking data and YOU are so UNHELPFUL #CancellingContract
#Bye”.
Though the important indicator “data leak” for a data breach attack is mentioned in
both tweets, the second tweet is complaining about a phone carrier and would be considered
noise for the cybersecurity domain.
To address this problem, syntactically bound information
and semantic similarity constraints are jointly considered in our proposed method.
More specifically, each tweet in
D
is first converted into its dependency tree form.
Thus for
a given seed query q,
the target domain
D
+
⊆ D
can be generated by collecting all
tweets
which are both syntactically and semantically similar to the seed query q.
Mathematically,
given the two dependency trees q and d
∈
D, a convolution tree kernel [42] is used to measure
the similarity by computing all the common paths between two trees:
K(q, d) =
∑
u∈q
v∈d
(
1 +
H
(u, v)
)
1
R
>0
(
H(u,v)
)
(5.1)
where v and u are nodes from two trees q and d respectively,
R
>0
represents the set of
positive real
numbers,
1
(
·
) is the indicator function,
and
H
(v, u) counts the number of
common paths between the two trees which peak at v and u, which can be calculated by an
efficient algorithm proposed by Kate et al. [42], as described in Algorithm 5.
58
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
Algorithm 5: Compute all common paths.
Input:
u
∈
q, v
∈
d
Output:
H
(
u, v
)
1
Set
r
=
κ
(
u, v
)
;
2
Set
C
u
=
children
(
u
)
;
3
Set
C
v
=
children
(
v
)
;
// consider every pair of common child nodes
4
for
c
i
, c
j
∈ C
u
, i
̸
=
j
do
5
for
c
m
, c
n
∈ C
v
, m
̸
=
n
do
6
if
c
i
.
=
c
m
and
c
j
.
=
c
n
then
// compute all common paths from children
7
x
=
κ
(
c
i
, c
m
)
;
8
y
=
κ
(
c
j
, c
n
)
;
9
r
=
r
+
√
λ
+
λx
+
λy
+
λxy
// increment
10
H
(
u, v
) =
r
;
In Algorithm 5, λ
∈
(0, 1] (set to 0.5) is a parameter used to down-weight the contribution
of long paths, κ(u, v) is the number of common paths between the two trees which originate
from u and v, and can be recursively defined as:
κ(u, v) =
∑
µ∈C(u)
η∈C(v)
(1 + κ(µ, η))
1
µ
.
=η
(u,v)
,
(5.2)
where C(
·
) denotes the set of children node.
It reinforces the common paths which are lin-
guistically meaningful thereby reducing the noise introduced by coincidentally matched word
chains.
Also the occurrence of long-range dependencies between words, for example “Ashley
Madison”
→
“breached” as shown in Fig.
5.2,
which may decrease the kernel
performance
when considering a fixed-window, are avoided because functionally related words are always
directly linked in a dependency tree.
A key novelty of our convolution tree kernel is the use of a word embedding approach (instead
of
exact string matching) to compare the similarity between two words.
In both (line 6)
Algorithm 5 and Equation 5.2, we use the similarity operator
.
= to denote the comparison of
word representations in vector space.
This allows words that occur in similar contexts (that
have similar embeddings) to be semantically compared (as measured by cosine similarity).
This helps improve recall
& precision of
target domain generation,
by allowing the kernel
to explore longer paths for example when comparing “data”
←
“leak” with “data”
←
“breach”
5.3. Dynamic (Typed) Query Expansion
59
Figure 5.2:
A dependency tree diagram of
a cyber-attack related tweet illustrating short-
range (local) and long-range word-word dependencies.
but reject paths such as when comparing “website”
←
“hack” with “life”
←
“hack”.
5.3
Dynamic (Typed) Query Expansion
In this subsection, we propose a way to dynamically mine an expanded query given a small
collection of seed queries,
as shown in Table 5.1.
By providing a small
set of seed queries
(unigrams),
Zhao et al.
[119]
proposed a dynamic query expansion (DQE) method which
is able to expand the seed query iteratively set from a currently selected target tweet sub-
space until
convergence.
Looking beyond the simple unigram-based expansion,
we propose
a dynamic typed query expansion method that uses dependency-based tree structures for
expansion.
Our choice of cyber-attack categories is based on two assumptions:
first,
these
capture over 80% of the yearly, cyber-attack occurrences
1
and second, that these categories
have a direct impact on users, and thus crowdsourcing and social media have the potential
to capture them.
The detection of other attacks such as insider attacks or network intrusion
still
relies on traditional
network-based approach.
Nevertheless,
even though the types of
attacks focused by our paper can be viewed as “user-centric attacks” our approach (described
below) can be extended to other categories.
Let us denote
Q
k
,
D
k
+
as the expanded query set and target domain at the kth iteration.
At
the start of the iteration,
Q
0
is initialized with a small set of domain-relevant seed queries, as
shown in Table 5.1.
With
D
and
Q
0
, then
D
0
+
, the target domain (at iteration 0) tweets are
retrieved using the kernel similarity function described in Equation 5.1.
At the kth iteration,
given the last expanded query set
Q
k−1
and last generated target domain
D
k−1
+
, our approach
1
http://www.hackmageddon.com/category/security/cyber-attacks-statistics/
60
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
Table 5.1:
Seed queries for cyber-attack events.
Category
Seed Query
Data breach
data
leak,
security
breach,
information
stolen, password stolen, hacker stole
DDoS
DDoS attack,
slow internet,
network infil-
trated,
malicious activity,
vulnerability ex-
ploit, phishing attack
Account Hijacking
unauthorized access,
stolen identity,
hacked
account
Algorithm 6: Dynamic Typed Query Expansion Algorithm.
Input:
Seed Query Set
Q
0
, Twitter sub-collection
D
Output:
Expanded Query Set
Q
1
Set
D
0
+
=
match
(
Q
0
,
D
)
, k
= 0
2
repeat
3
k
=
k
+ 1
4
for
q
i
∈ Q
k−1
, d
∈ D
k−1
+
do
5
b
q
k
i
=
subtree
(
argmax
v∈d
∑
u∈q
i
CP P
(
v, u
))
// new candidate
6
for
f
∈
b
q
k
i
do
7
Pr
(
f
|D
k−1
+
) =
tf (f )
|D
k−1
+
|
8
Pr
(
f
|D
) =
tf (f )
|D|
9
w
(
f
) =
KL
(
f,
D
k−1
+
|D
)
// feature score
10
w
(
b
q
k
i
) =
∑
f∈b
q
k
i
w
(
f
)
// query score
11
Q
k
=
topN
(
w
(
b
Q
k
))
,
b
Q
k
=
{
b
q
k
1
, . . . ,
b
q
k
|
b
Q
k
|
}
12
D
k
+
=
match
(
Q
k
,
D
)
// filter new target subspace
13
until
k
∪
i=0
Q
i
−
k−1
∪
i=0
Q
i
̸
=
∅
// DQE iteration;
14
Q
=
Q
k
5.4. Cybersecurity Event Detection
61
first prepares candidate expanded queries for each matched q
i
∈ Q
k−1
and d
∈ D
k−1
+
:
ˆ
q
k
i
= subtree
(
argmax
v∈d
(
∑
u∈q
i
H
(v, u))
)
,
(5.3)
where v and u are term nodes in tweet d and q
i
respectively, and subgraph(
·
) is an operator
to extract the subtree structure from entire tree with v as root.
Thus the candidate query
expansions are collected based on the relevant document and query space, that is
D
k−1
+
and
Q
k−1
.
To identify the best (candidates) expanded queries, query terms are then ranked based
on the Kullback-Leibler divergence [68] between the target domain
D
k−1
+
and the whole tweet
collection
D
:
KL(f,
D
k−1
+
|D
) = log
Pr(f
|D
k−1
+
)
Pr(f
|D
)
Pr(f
|D
k−1
+
),
(5.4)
where KL(f,
D
k−1
+
|D
) denotes the Kullback-Leibler divergence, f is a term in ˆ
q
k
i
, Pr(f
|D
k−1
+
)
and Pr(f
|D
) is the probability of term f appearing in
D
k−1
+
and
D
, respectively.
Using the
KL divergence to rank query terms we are able to assign scores to terms that best discrim-
inate relevant and non-relevant expansions.
For example query terms such “account” and
“twitter” both appear frequently in the candidate expansions but they have little informative
value as they will have a similar (random) distribution in any subset of the twitter collection,
whereas terms such as “hacked” will have comparatively higher probability of occurrence in
the relevant subspace.
These high ranked candidates will then act as the expanded queries
set to run the next iteration until
the algorithm converges.detailed dynamic typed query
expansion algorithm is shown in Algorithm 7.
5.4
Cybersecurity Event Detection
Our proposed system is shown in Figure 5.3.
It can be factorized into the stages of enrich-
ment, dynamic query expansion, event extraction.
For the enrichment step, the text of each
tweet was tokenized and parsed to include their lemmas and dependency relations.
Next,
we describe our strategy to extract cybersecurity-related events automatically.
Event Extraction Given an expanded query set
Q
,
we extract
Q
s
|
q
i
⊈
q
j
|
q
i
, q
j
∈ Q
s
.
For example,
if the surface string representations of a set of expanded queries Q is (“data
breach”,
“data leak”,
“ashley madison”,
“ashley madison data breach”) then
Q
s
will
be
(“ashley madison data breach”).
We then cluster the query expansions in
Q
s
using affinity
62
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
Figure 5.3:
A schematic overview of the cybersecurity event detection system.
propagation [30] and also extract exemplars q
e
of each query set
Q
e
that are representative
of clusters, where each member query is represented by a vector ˜
q calculated from the word
embedding ˜
u of the lemma of each query term u
∈
q as:
˜
q =
∑
u∈q
˜
u.
(5.5)
Each exemplar query q
e
is then annotated to a cyber-attack type.
For this purpose,
we
first compute the cosine similarity between an exemplar query expansion q
e
and seed query
q
j
∈ Q
(0)
as:
sim(q
e
, q
j
) =
˜
q
e
·
˜
q
j
||
˜
q
e
|| · ||
˜
q
j
||
.
(5.6)
The q
j
∈ Q
(0)
which has the highest similarity value with q
e
determines the event type to
which
Q
e
belongs to.
For the complete event representation (
Q
e
, date, type) date information
is extracted based on the time interval chosen for DQE; for example in our experiments we
run DQE on a daily aggregated collection of tweets.
In this way we extract the final set of
event tuples.
5.5. Evaluation
63
5.5
Evaluation
5.5.1
Datasets
We evaluate the proposed method on a large stream of tweets from GNIP’s decahose (10%
sample) collected from August 2014 through October 2016.
The total
raw volume of
our
Twitter dataset across these 27 months is 5,146,666,178 (after removing all
re-tweets and
non-English tweets).
Then, from this raw volume we create two subset collections:
• Fixed Keyword Filtered Tweets:
We filtered 79,501,789 tweets that contain at
least one matching term from a list of cyber-attack related keywords.
These are top
1000 keywords (ranked by TFIDF) extracted from description texts of events in our
gold standard report (see below).
• Normalized Tweet Texts:
We extract and normalize tweet texts (after removing
accents, user mentions and URLs) to produce a collection of 3,267,567,087 unique texts
to train a 200-dimensional word embedding via Gensim’s word2vec software [88].
Note that the experimental results for the performance of our event detection approach are
done using the entire raw volume of over 5 billion tweets.
The total
volume of
tweets filtered from query expansion algorithm is 1,093,716 over the
entire period.
To evaluate our methods,
we organize a Gold Standard Report (GSR) on cybersecurity-
related incidents to serve as a ground truth database.
In particular, we focus on high impact
events about data breach,
DDoS and account hijacking incidents based on two different
sources:
Hackmageddon
2
and PrivacyRights
3
.
In both sources,
each event is characterized
by an event type, date (when the event was publicly reported), victim organization(s), and
a short description.
• Hackmageddon is an independently maintained website that collects public reports
of cybersecurity incidents.
Between January 2014 and December 2016, we extract 295
account hijacking events and 268 DDoS events.
For account hijacking,
since we are
2
http://hackmageddon.com
3
https://www.privacyrights.org/data-breaches
64
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
using social media data, we mainly focus on hijacking attacks on social media accounts
(Twitter,
Instagram,
Facebook) by cyber crimes.
After filtering US-based events and
matching the time range of our Twitter data,
we obtain 55 account hijacking events
and 80 DDoS events to include in the GSR.
• PrivacyRights is a highly reputable repository for data breach incident reports.
Be-
tween January 2014 and December 2016, we extract 1064 reported data breach events.
To enhance the accuracy of GSR, we choose events reported by four large, well-known
sources — “Media”, “KrebsOnSecurity”, “California Attorney General”, and “Security
Breach Letter”.
Then,
we filter out data breaches involving non-cyber reasons (e.g.,
physical
theft) and focus on the HACK category.
After removing events with an un-
known size of data loss, and matching the time range with our data, we have 85 data
breach events for inclusion in the GSR.
5.5.2
Baseline Methods
Table 5.2:
A sample of negative instances for cyber-attack events used in the evaluation of
target domain generation methods.
Event Entity
Date
Sample Tweet
white house
2014-08-08
Toddler causes perimeter breach at White House
julia pierson
2014-10-01
The collapse of
the Julia Pierson’s Secret Service and the
White House Breach
green zone
2016-04-30
Anti-Government Protesters Breach Baghdad’s Green Zone
microsoft
2016-03-01
#EXPconsulting Microsoft Cures Breach Blindness for En-
terprises
avijit roy
2015-02-27
American-Bangladeshi
blogger Avijit Roy hacked to death
by Islamist extremists
jessica jones
2016-01-13
NBC thinks it’s hacked Netflix’s ratings, says ’Jessica Jones’
bests ’Master of None’
arbor networks
2015-03-25
Arbor Networks, Cisco partner on DDoS protection
zenedge
2016-07-30
ZENEDGE Debuts Always-On DDoS Protection #Bitcoin
We use two Twitter-based baselines to independently evaluate the performance of our target
domain and cyber-attack detection methods:
5.5. Evaluation
65
1.
Target
Domain Generation using Expectation Regularization (baseline 1) [90]:
This
baseline is trained based on a small
set of
seed events for each type of
attack.
For
training,
we randomly selected 10 ground-truth events for each of
the three attack
types (from our GSR). Additionally, keeping the similar proportions of per attack-type
events, in the test phase we also included several negative sample events (as shown in
Table 5.2) from manual search.
An expectation regularization model is trained based on a small set of seed events for
each type of cyber-attack.
In our setup, as per the data preparation process described
in [90],
separately for both training & testing we randomly selected 10 ground-truth
events for each of
the three attack types from our GSR.
Additionally,
in test phase
we also included several
negative sample events (as shown in Table 5.2).
The seed
events selected for each type is shown in Table 5.3.
Following the dataset preparation
process described in [90],
we retained only those event-related tweets that contained
keywords - “hacked” (for account hijacking events), “breach” (data breach events), and
“ddos” (DDoS events).
Following this step, the feature set was generated by collecting
a window of
contextual
words and POS tags surrounding the seed event keyword,
where this window size was set to 4 in our evaluation,
and the target expectation
was set to 0.55, l
2
regularization term to 100, and expectation regularization term λ
U
set to 10 times the number of labeled samples.
In total,
we collected 8943 and 8585
tweet samples for training and testing,
respectively.
Further,
we were able to extract
8969,
6178 and 10760 features from the data breach,
DDoS,
and account hijacking
event-related tweets, respectively.
2.
Cyber-attack Event Detection using Bursty Keywords (baseline 2) [45]:
This baseline
method identifies time periods in which a target event is uncharacteristically frequent
or bursty on a set of
static keywords.
An event is extracted if
the size of
this set
of
bursty keywords is larger than a threshold of
T
b
.
In this experiment,
we use the
79.5 million Fixed Keyword Filtered Tweets and the 1000 static keywords to apply
the baseline method.
We set the threshold T
b
based on small-scale empirical tests on
a few months of
data,
and manually examine the detected events.
We set T
b
=36
which returns a better event/noise ratio.
We apply this threshold on all the data and
detects 81 events from August 2014 through October 2016.
Each detected event is
characterized by a date and a set of bursty keywords.
66
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
Data Breach
DDoS
Account Hijacking
Event Entity
Date
Event Entity
Date
Event Entity
Date
yahoo
2016-09-22
dyn
2016-10-21
sarah silverman
2016-07-29
apple
2014-09-02
github
2015-03-30
al-arabiya
2016-01-05
white house
2014-10-29
bbc
2015-12-31
cia
2015-10-19
staples
2014-10-21
sony
2014-08-24
centcom
2015-01-12
dnc
2016-06-14
hsbc
2016-01-29
central command
2015-01-12
premera
2015-03-17
uk police
2015-09-01
nsa
2016-08-17
carphone warehous
2015-08-08
telgram
2015-07-13
taylor swift
2015-01-27
slack
2015-03-27
kremlin
2015-09-18
leslie jones
2016-08-24
red cross
2016-10-28
blizzard
2014-11-14
lastpass
2015-06-15
Table 5.3:
Seed intances for data breach, DDoS and account hijacking.
5.5.3
Measuring Performance
To match the detected events with the GSR,
we developed a matching scheme.
Given a
detected event presented by e = (
Q
e
, date, type) is matched with any event in the GSR if:
1.
For named entity in e, we check if it matches any event description in GSR and obtain
a matched collection from GSR, say M E;
2.
Further filter M E by matching the event date between date in e and M E, with a time
window as 3 (one day before date, and one day after date), and obtain a new filtered
event set, say F M E;
3.
Compare the event type between e and event in F M E; if the event type also matches,
then event e is consider as a matched event.
However, considering that the detected events are mined from the Twitter environment which
may not use formal keywords to describe the event.
We also manually double check the event
e if it fails step 1.
Detected events by the baseline method use the same approach to match
against GSR. The only adjustment is to match the bursty keywords of the detected events
instead of named entities.
Target Domain Generation.
Concerning precision and recall
(see Table 6.1),
our ap-
proach achieves a 70% accuracy in extracting target domain tweets, outperforming the com-
parison to baseline 1 [90] in two categories, viz.
data breach and DDoS. In case of account
5.5. Evaluation
67
Table 5.4:
Contingency table used to assess cyber-attack related tweet detection results.
Method
Data Breach
DDoS
Account Hijacking
TP
FP
FN
TN
TP
FP
FN
TN
TP
FP
FN
TN
Typed DQE
1110
389
528
1085
516
129
93
30
2028
1
2976
200
Baseline 1 [90]
1526
1391
112
83
295
113
314
46
2182
29
2322
172
Table 5.5:
Overall evaluation of cyber-attack detection.
Method
Data Breach
DDoS
Account Hijacking
Precision
Recall
F1
Precision
Recall
F1
Precision
Recall
F1
Typed DQE
0.74
0.68
0.71
0.80
0.85
0.82
0.99
0.45
0.61
Baseline 1 [90]
0.52
0.93
0.67
0.72
0.48
0.58
0.99
0.48
0.65
Baseline 2 [45]
0.21
0.20
0.20
0.01
0.02
0.01
0.01
0.01
0.01
hijacking our accuracy is only slightly less due to our lower recall, because TypedDQE will
reject tweets by way of down-ranking expansion candidates that are not specific enough (for
example if they contain only one keyword such as “hacked”) and are below a certain support
threshold.
The use of kernel similarity (as opposed to fixed context window) provides higher
precision, seen clearly from Table 5.4 where our approach detected only 1 tweet incorrectly
as account hijacking-related in comparison to 29 false positives by the baseline.
Also worth
noting is the high specificity (true negative rate) of 71% as compared to baseline’s 16%.
Cyber-attack Event Detection.
Precision and recall over different types of cyber-attack
events are summarized in Table 6.1 using a second baseline [45].
These results show that
with only a small
set of
seed queries (as shown in Table 5.1),
our approach can obtain
around 80% of precision for data breach and DDoS events.
This means our approach can
handle the noisy Twitter environment and perform cyber-attack event detection accurately.
The precision for account hijacking is not as high (66%).
On manual analysis (using online
search) we identified several
events detected by our system even though the GSR did not
cover them.
We show this disparity in Table 5.6 where we can notice that it is highest
for account hijacking type of
events (as social
media tends to provide greater coverage to
celebrity and other individual cases of hacked accounts).
Data breach events have a higher
recall (75%).
The relatively low recall for account hijacking and DDoS is explainable.
Both
DDoS and account hijacking events have a rather short life cycle from occurrence to being
addressed.
Thus their signal in social media is relatively weaker.
For instance, DDoS events
68
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
Table 5.6:
Matching the detected events with the GSR.
Matched with GSR
Data Breach
DDoS
Account Hijacking
TP
FP
TP
FP
TP
FP
Yes
22
0
20
0
8
0
No
156
49
29
12
51
31
often result in several
minutes to a few hours of
slow Internet access and thus may end
even before people realize it.
This intuition is validated in the baseline performance.
The
extremely low precision and recall show that relying on burstiness is challenging to capture
such events, possibly due to their weak signals over noise.
5.5.4
Case Studies
Figure 5.4:
Streamgraph showing normalized volume of tweets (August 2014 through August
2015) tagged with data breach (red), DDoS activity (grey) and account hijacking (blue) types
of cyber-security events.
We comprehensively show in Figure 5.4 and Figure 5.5,
the wide range of events that our
system is able to detect.
Notice the clear bursts in the Twitter activity that our query
expansion algorithm can detect.
Through the following case studies,
we highlight some of
the interesting cases for each of three cyber-attack types, that our system detected.
Targeted DDoS Attacks on Dyn.
We capture 12 separate events of
DDoS attacks
including four in the last week of
August 2014,
beginning with the first on August 24th.
Further, in 2015, more ensuing attacks are captured, one highlighted by the data breach of
their movie production house (on December 12th) and then a massively crippling targeted
5.5. Evaluation
69
Figure 5.5:
Streamgraph showing normalized volume of
tweets (September 2015 through
October 2016) tagged with data breach (red),
DDoS activity (grey) and account hijacking
(blue) types of cyber-security events.
Figure 5.6:
Query expansions (size is proportional to the query’s feature score) produced on
October 22 2016 for the DDoS attack on DNS provider Dyn.
DDoS attack on their PlayStation network in late December 2015.
Another noteworthy
case of
DDoS attacks in 2016 is the multiple distributed denial-of-service attack on DNS
provider “Dyn” from October 21st through 31st in 2016 that almost caused a worldwide
Internet outage.
Our system generates several query expansions, shown in Figure 5.6 which
characterizes the nature of these attacks where the hackers turned a large number of Internet-
connected devices around the world into botnets executing a distributed attack.
Ashley Madison Website Data Breach.
In July 2015 a group calling itself “The Impact
Team” stole the user data of Ashley Madison,
an adult dating website.
The hackers stole
all the customer data and threatened to release personally identifying information if the site
was not immediately shut down.
Between 18th and 20th August,
the group leaked more
than 25 gigabytes of
company data.
The word clouds in Figure 5.7 clearly show how our
method iteratively expands from the seed queries to the expanded queries in the last iteration
(iteration 3) capturing rich characteristics of the breach.
After the initial
burst as seen in
the figure,
we also see a second corresponding burst a month later (on August 19th) when
70
Chapter 5. Improving DQE with Semantic Context-aware Retrieval
Figure 5.7:
Ashley Madison website data breach.
The streamgraph shows the bursty nor-
malized volume of tweets related to the data breaches.
Along with all the query expansions
(size is proportional to the query’s feature score) produced at each iteration of TypedDQE.
Figure 5.8:
Query expansions (size is proportional
to the query’s feature score) produced
from the U.S CentCom Twitter account hijacking event.
the user data was released online.
Twitter Account Hijackings.
We were also able to detect with very high date accuracy,
several high profile cases of account hijackings of social media accounts of known personalities
and government institutions including the Twitter account for U.S. Central Command which
was hacked by ISIS sympathizers on January 12th,
2015.
We show in Figure 5.8 that our
method identifies not only the victim (“central
command twitter account hack”) but also
the actor who perpetrated the hacking (“isis hack twitter account”).
5.6. Summary
71
5.6
Summary
In this chapter, we have demonstrated a weakly supervised approach with no training phase
requirement to dynamically extract and encode cyber-attacks reported and discussed in social
media.
We have motivated the need for a careful,
structured query expansion strategy,
and how the use of
dependency parse trees and word embeddings supports context-rich
retrieval.
Our retrieval
algorithm can be easily extended to other languages (by training
additional embedding models) and different data sources of real-time, text streams such as
users’ status updates and blog posts commonly found in several online social networks other
than Twitter.
We have performed a comprehensive evaluation of
our approach achieving
over 70% accuracy in retrieving cyber-attacks related content from social
media streams,
and 80% precision in successfully detecting cybersecurity-related events, outperforming the
two considered baselines.
Given the widespread prevalence of cyber-attacks,
tools such as
presented here are crucial to providing situational awareness on an ongoing basis.
Future work is aimed at broadening the class of attacks that the system is geared to as well
as at modeling sequential dependencies (from occurrence to reporting) of cyber-attacks.
This
will
aid in capturing characteristics such as the increased prevalence of attacks on specific
institutions or countries during particular time periods.
Chapter 6
Augmenting DQE with Hypergraph
Learning
Micro-blogging platforms present themselves as a hybrid news information source where
users can share links to events reported in conventional
news sources and also report in
real-time,
their in-person accounts of events as they unfold.
The sheer variety and volume
of
this information pose a severe challenge to deploying large-scale applications based on
social
media analytics.
In contrast to the curated and structured form of news releases in
conventional media, microblog texts such as tweets are inherently unstructured that contain
out-of-vocabulary keywords in the form of hashtags,
social
slang,
and acronyms.
Further-
more,
due to the text length limitation in microblogs,
the widely adopted event reporting
style though concise,
is highly informal
and although interrelated,
is often incomplete or
fragmented since the information often arrives in short bursts [23] as emerging trends [50].
Prior work has primarily focused on modeling emerging trends using topic models and recency
ranking of information.
However, they fail to capture and model the “relational structures”
of
event-related information in microblog texts.
In chapter 3,
we approach this challenge
using a heterogeneous information network built from tweet texts,
but we observed poor
characterization of
semantic knowledge leading to semantic mismatch problems.
Then,
in
chapter 5 we improved on this by developing the notion of
contextualization of
texts (for
both input user queries and reference texts) to make the retrieval process more context-aware
using dependency relations between words in texts.
In this chapter, we aim to include both heterogeneity and (semantic) relational aspects not
in isolation,
but as a merged data representation model.
Typically,
dyadic graphs are a
straightforward choice to bring structure to information, using co-occurrence relations that
capture pairwise term dependencies.
However,
they inevitably lead to loss of information,
since it’s unclear how well
simple graphs can capture high-order dependencies resulting
from complex interactions of
concepts,
entities in event-related information.
This loss of
72
6.1. Preliminaries
73
information in general, also explains one of the underlying causes of the semantic mismatch
problem in microblog event retrieval
tasks.
Therefore,
we propose an augmented dynamic
query expansion with hypergraph learning to capture event-related characteristics better.
Hypergraphs are generalizations of graphs with (hyper)edges that can connect to (more than
two) subset of vertices.
Hyperedges can better represent relational data (events and entities
involved) that contains complex,
non-pairwise relationships.
Compared to dyadic graphs,
hypergraphs are also more computational
efficient as they require less Storage (incidence
matrix smaller) and fewer vector multiplication operations.
They have been particularly
useful in image segmentation tasks and community detection in social networks, and recently
in natural languages processing tasks such as information retrieval and key-phrase extraction.
Our main contributions are:
• A structured approach to represent the complex, relational microblog texts
using Hypergraphs.
We propose to use semantic hypergraphs to model
the in-
terrelated information in short texts.
We encode lexical
dependencies and linguistic
knowledge structures (semantic frames) as hyperedges.
• A novel
dynamic query expansion algorithm using hypergraph learning.
Given a short query, dynamically expand original query with relevant key-terms (lexical
units) that iteratively captures event-focused characteristics from a stream of
short-
texts containing incomplete information.
• An evaluation of our strategy to event detection on Twitter.
We demonstrate
that our approach can deliver high detection accuracy for civil unrest and cyber-attack
events.
6.1
Preliminaries
This section briefly describes the notations and fundamental concepts in hypergraph learning
that we refer to later in this paper.
A hypergraph [10]
is formally defined as a pair H = (V, E),
where V is a set of
objects,
called hypernodes,
and E is a set of
non-empty subsets of
V called hyperedges such that
∪
e∈E
= V .
In case of a weighted hypergraph it has a positive number w(e) associated with
74
Chapter 6. Augmenting DQE with Hypergraph Learning
each hyperedge e,
called the weight of
the hyperedge e:
denoted as H = (V, E, w).
For
a vertex v
∈
V ,
its degree is defined as d(v) =
∑
v∈V,e∈E
w(e) and degree of
a hyperedge
e denoted as δ(e),
is defined to be δ(e) =
|
e
|
.
The incidence matrix for a hypergraph H,
represented by M
∈
R
|V |×|E|
with elements h(v, e) = 1 if v
∈
e and 0 otherwise.
Then we
have:
d(v) =
∑
e∈E
w(e)h(v, e) and δ(e) =
∑
v∈V
h(v, e)
Let D
v
and D
e
denote the diagonal matrices containing the vertices and hyperedge degrees
respectively, and let W denote the diagonal matrix containing the weights of the hyperedges.
To represent complex relationships among objects (hypernodes) we need to be able to parti-
tion the hypergraph.
One popular approach in simple (dyadic) graphs is the use of spectral
clustering that uses the normalized graph Laplacian.
To partition the hypernodes using
spectral
techniques generalized for hypergraphs we adopt the algorithm for normalized hy-
pergraph cut proposed in [120].
Given a vertex subset S
⊂
V , denote its compliment as S
c
,
then a cut of
the hypergraph H = (V, E, w) is a 2-way partition of
V and can be as the
weighted sum of all edges which are cut:
hCut(H, (S, S
c
)) :=
∑
e∈∂S
w(e)
|
e
∩
S
||
e
∩
S
c
|
δ(e)
(6.1)
where hyperedge boundary ∂S := e
∈
E
|
e
∩
S
̸
=
∅
, e
∩
S
c
̸
=
∅
denotes the set of hyperedges
that are cut.
For a balanced partition we want to minimize cutting edges among the vertices
in the cluster that can be dense connectivity instead focus on border edges which have sparse
connectivity.
Formally, a normalized hypergraph cut is defined as:
nhCut(H, (S, S
c
)) := hCut(H, (S, S
c
))
(
1
vol(S)
+
1
vol(S
c
)
)
(6.2)
where the vol(S) is the volume of S, that is, volS :=
∑
v∈S
d(v).
6.2
Semantic Hypergraphs
The input to our dynamic query expansion algorithm is a collection
D
of
timestamped
microblog texts defined as
D
= [d
1
, d
2
, . . . , d
n
]
where d
i
is a single microblog document.
6.2. Semantic Hypergraphs
75
Let
D
+
denote the targeted domain subspace (relevant texts pertaining to users’ domain of
interest), and
D
−
=
D − D
+
denote the remaining texts in the sub-collections.
Definition 6.1.
Lexical
unit:
A lexical
unit u,
is defined as a single word token,
which
has been lemmatized and annotated by its part-of-speech tag.
For example, the lexical unit
for the word “breached” would be “breach.V”.
Definition 6.2. Seed Query:
The seed queries are defined as an initial set of domain rel-
evant search keywords.
Let Q
0
= (q
0
i
, s(q
i
)
0
)
n
i=1
denote the initial seed query set, where query
q
i
= [u
1
, . . . , u
m
] is a subset of distinct lexical units and weight s(q
i
)
∈
R
+
indicating query
relevance to the target event domain.
A collection of
expanded queries is an extended
set of weighted queries.
An expanded query Q
k
= (q
k
i
, s(q
i
)
k
)
n
i=1
is automatically generated
by dynamic query expansion algorithm based on the input set of queries from the previous
iteration k
−
1.
For example ([“data”, “breach”], 1), ([“protest”], 1) can be defined as the seed
queries and their resulting query expansions as ([“data”, “leak”], 1), ([“protest”, “march”], 1)
Definition 6.3.
Event Representation:
An event z is defined as (
Q
z
, date, type), where
Q
z
is the set of event-related expanded queries, date denotes when the event happens, and
type refers to most similar seed query q
0
i
.
The input to our dynamic query expansion algorithm is a collection
D
of
timestamped
microblog texts defined as
D
= [d
1
, d
2
, . . . , d
n
]
where d
i
is a single microblog document.
Let
D
+
denote the targeted domain subspace (relevant texts pertaining to users’
domain
of
interest),
and
D
−
=
D − D
+
denote the remaining texts in the sub-collections.
Given
the above definitions, the major tasks underlying the dynamic query expansion problem are
defined as follows:
Task 1:
Semantic Hypergraph Construction.
Given a subset of
microblog texts
⊂
D
,
its hypergraph construction is the task of creating a homogenous hypergraph H =
(V, E, w, l) where the vertices or hypernodes V are lexical
units,
hyperedge e
∈
E models
the lexical and semantic relationships of a subset of lexical units.
Further, each hyperedge e
is associated with a weight w(e) and label l(e) denoting the type of relationship hyperedge
encodes.
Task 2:
Expanded Query Extraction.
Given target domain
D
+
, the task of expanded
query extraction is to generate a set of expanded queries Q =
{
q
1
, . . . , q
n
}
which represents
the relevant concepts delivered by
D
+
.
Thus set Q can be used to retrieve event related
information from other collection sets.
76
Chapter 6. Augmenting DQE with Hypergraph Learning
6.2.1
Hypergraph Construction
For hypergraph construction,
each hyperedge e contains subset of
vertices v
∈
e
|
e
∈
E
that are lexical
units u
∈
C,
where C denotes the vocabulary of
distinct words extracted
from our corpus.
Given a subset of
microblog texts d
i
∈
,
each defined as a tuple d
i
=
(u
i,1
, u
i,2
, . . . , u
i,k
) of distinct lexical units, then using a bag-of-words model we embed each
d
i
as vertices of
a hyperedge e.
In essence,
we initially begin with a lexical
hypergraph,
as shown in Figure 6.1.
Then,
we further induce several
high-order dependencies between
lexical units.
We consider two broad categories of these dependencies:
(1) Lexico-Semantic:
containing dependency relations between words, Subject-Verb-Object triplets, noun phrases
and named entities;
(2) Frame-Semantic parses which yield predicate-argument structures
of event descriptions.
We extract these high-order dependencies from each microblog text
and individually add them as new hyperedges to construct our semantic hypergraph.
Figure 6.1:
An example of lexical hypergraph constructed from four tweets.
6.2.2
Hypergraph Learning
The primary motivation of using hypergraph in our query expansion approach, is to allow a
mechanism for high-order semantic groupings of lexical units.
To this end, we focus on the
application of hypergraphs to the spectral clustering of relational data.
One of the popular
approaches to spectral hypergraph clustering is the computation of a normalized hypergraph
6.3. Dynamic Query Expansion
77
“Laplacian”.
In [120]
authors proposed a real-valued relaxation of Equation 6.2 that leads
to the eigen-decomposition of a positive semidefinite matrix, which then yields a normalized
hypergraph Laplacian defined as
∆ = I
−
D
−
1
2
v
MWD
−1
e
M
T
D
−
1
2
v
(6.3)
where I denotes the identity matrix.
The inclusion of
D
e
guarantees the positive semi-
definiteness of
the hypergraph Laplacian,
which can then be extended to obtain k-way
partitioning of
the hypergraph.
Denote a k-way partition of
hypergraph H = (V, E),
by
Π = (V
1
,
· · ·
, V
k
), where V
1
∩
V
2
∩ · · · ∩
V
k
= V , and V
i
∪
V
j
=
∅
∀
1
≤
i, j
≤
k.
Then we can
obtain a k-way partion by minimizing:
hCut(H, Π) =
k
∑
i=1
vol∂V
i
volV
i
over all k-way partitions
(6.4)
Similarly,
as showin in [120]
by applying a real-valued relaxation of
above optimization
problem.
The resulting theoretical solution can then be seen as a embeddings matrix X
V xk
:
X = [ψ
1
,
· · ·
, ψ
k
]
(6.5)
,
where ψ
i
’s are the eigenvectors ∆ associated with the k smallest eigenvalues.
The row
vectors of X can be regarded as the embeddings of the vertices in the hypergraph and are
expected to be well separated, and this can be use to perform a multiclass clustering of the
hypernodes.
The basic intuition behind extracting spectral
embedding of
vertices is that
when cluster vertices,
each cluster will
contain connections of vertices that describe dense
semantic relationships as shown in Figure 6.2.
6.3
Dynamic Query Expansion
In this subsection, we describe our algorithm for dynamic query expansion.
We propose an
iterative scheme to dynamically mine query expansions using hypergraph learning, as shown
in Algorithm 7.
Let us denote Q
k
and
D
k
+
as the expanded query set and target domain
respectively, at the kth iteration.
Then, at the start of the iteration, Q
0
is initialized with a
limited set of domain-relevant seed queries Q
0
.
We make use of several
utility functions in
78
Chapter 6. Augmenting DQE with Hypergraph Learning
Algorithm 7: Dynamic Query Expansion.
Input:
Seed Query Set Q
0
, Microblog sub-collection
D
Output:
Expanded Query Set Q
1
Initialize:
2
Set k = 0
3
Set Q = []
4
D
0
+
←
DoFiltering (Q
0
,
D
)
5
Append (Q, Q
0
)
6
repeat
7
k = k + 1
8
H
←
ConstructHypergraph(D
k−1
+
)
9
L
←
ConstructLaplacian(H) // per Equation 6.3
10
X
←
ExtractEmbeddings(L) // per Equation 6.5
11
C
←
DoClustering(X)
12
ˆ
C
←
DoFiltering (Q
k−1
, C)
13
U
←
GetDistinctLexicalUnits(
ˆ
C)
14
Set Q
k
=
{}
// empty query expansion set at kth iteration
15
for q
i
∈
Q
k−1
do
// extract candidate query expansions
E
←
GetTop
m
MostSimilarHyperedges (q
i
, H, X, U )
16
for e
∈
E
do
17
r[e]
←
∑
u∈e
KL(u,D
k−1
+
,D))
|e|
// candidate query expansion score
18
Update (Q
k
, GetTop
n
Hyperedges (
E
, r)
19
D
k
+
←
DoFiltering (Q
k
,
D
)
20
Append (Q, Q
k
)
21
until
k
∪
i=0
Q
i
−
k−1
∪
i=0
Q
i
̸
=
∅
// DQE iteration;
6.3. Dynamic Query Expansion
79
Figure 6.2:
This plot shows distribution of embeddings of subset of top words from tweets
in our dataset from August 4, 2014.
the algorithm which are described as following:
1.
Filtering.
This function takes as input a set of queries Q
k
and a list of documents
= [d
1
, d
2
. . . , d
p
] where each document is a tuple of lexical units similar to Q
k
.
It returns
a subset of matched documents such that for any query q
i
∈
Q
|
q
i
⊂
d
i
.
2.
Clustering.
This function takes as input the embeddings generated from the eigen-
decomposition of the hypergraph Laplacian.
We then follow the spectral
embedding
discretizing approach in [104] to cluster each row vector in matrix X to coherent groups
by rotating normalized eigenvectors to obtain an optimal segmentation.
3.
Similar Hyperedges.
Given a hypergraph H = (V, E),
this function extracts most
similar hyperedges e
∈
E for given query q
i
;
using the embeddings X of vertices we
compute the centroids-based cosine similarity for q
i
and
∀
e
∈
E and return the top m
most similar hyperedges.
To identify the best (candidates) expanded queries, hyperedges are then ranked based on the
relative entropy of each vertex v
∈
e or lexical units, which is calculated using the Kullback-
80
Chapter 6. Augmenting DQE with Hypergraph Learning
Leibler divergence [68] between the target domain D
k−1
+
and the whole tweet collection
D
:
KL(u, D
k−1
+
|D
) = log
Pr(u
|
D
k−1
+
)
Pr(u
|D
)
Pr(u
|
D
k−1
+
),
(6.6)
where KL(u, D
k−1
+
|D
) denotes the Kullback-Leibler divergence,
u is a vertex (lexical
unit)
in e,
Pr(u
|
D
k−1
+
) and Pr(u
|D
) is the probability of
lexical
unit u appearing in D
k−1
+
and
D
, respectively.
Using the KL divergence to rank query terms we are able to assign scores
to terms that best discriminate relevant vs those containing noisy expansions.
These high
ranked candidates will
then act as the expanded queries set to run the next iteration until
the algorithm converges.
Event Extraction
Given an expanded query set Q
k
from the kth iteration after DQE terminates;
we extract
Q
s
|
q
i
⊈
q
j
|
q
i
, q
j
∈
Q
k
.
We then compute the embedding matrix X
k
from D
k
+
(as shown
in Algorithm 7 from line 8 - line 10).
We then cluster the query expansions in Q
s
using
the discretized approach in [104]
and using the centroid-based distance metric to extract
exemplars q
e
of each query set Q
e
,
where each member query is represented by a vector ˜
q
calculated from the sum of spectral embedding vector of the lexical units of each query term
u
∈
q as:
˜
q =
∑
u∈q
˜
u.
(6.7)
Each exemplar query q
e
is then annotated to a event type.
For this purpose, we first compute
the cosine similarity between an exemplar query expansion q
e
and seed query q
j
∈ Q
(0)
as:
sim(q
e
, q
j
) =
˜
q
e
·
˜
q
j
||
˜
q
e
|| · ||
˜
q
j
||
.
(6.8)
The q
j
∈
Q
0
which has the highest similarity value with q
e
determines the event type to
which Q
e
belongs to.
For the complete event representation (Q
e
, date, type) date information
is extracted based on the time interval chosen for DQE. In this way we extract the final set
of event tuples.
6.4. Evaluation
81
6.4
Evaluation
Datasets:
Our microblog text corpus is created from GNIP’s decahose (10% sample) col-
lected from January 2017 through March 2017.
The total raw volume of our Twitter dataset
across these 3 months is 212,216,838 (after removing all
retweets and non-English tweets).
We organize a ground truth dataset for two domains -
• Data Breaches:
The ground truth events for the cyber security were extracted from two
different sources:
Hackmageddon
1
and PrivacyRights
2
.
In both sources, each event is
characterized by an event type,
date (when the event was publicly reported),
victim
organization(s), and a short description.
• Protests:
These civil unrest events were extracted from the ICEWS dataset [12] which
stands for Integrated Crisis Early Warning System.
It contains news articles published
all over the world with the goal of evaluating national and international crisis events.
The events in this dataset are automatically identified and extracted by the BBN
ACCENT event encoder
Baseline:
We created a baseline approach using a co-occurrence graph which can be used
to compute the spectral embeddings of terms in tweets using the (dyadic) graph Laplacian.
We create the affinity matrix in this co-occurrence graph using the frequency count of two
terms appearing together in tweet text.
We then apply the DQE algorithm and similarly
extract events as discussed in the previous section.
Matching Detected Events with GSR: Given a detected event presented by e = (Q
e
, date, type),
we developed a semi-automatic method to detect if
e is matched with any event in the
ground-truth dataset:
1.
For each named entity in e, we check if it matches any in the event description in the
ground-truth and obtain a matched collection from GSR, say M
e
;
2.
Further filter M
e
by matching the event date between date in e and M
E
, with a time
window as 3 (one day before date, and one day after date), and obtain a new filtered
event set, say
ˆ
(M)
e
;
1
http://hackmageddon.com
2
https://www.privacyrights.org/data-breaches
82
Chapter 6. Augmenting DQE with Hypergraph Learning
Table 6.1:
Event Detection Performance
Method
Data Breach
Protest
Precision
Recall
F1
Precision
Recall
F1
Hypergraph DQE
0.77
0.65
0.70
0.71
0.76
0.73
Graph DQE
0.65
0.39
0.48
0.57
0.62
0.59
3.
Compare the event type between e and event in
ˆ
(M)
e
; if the event type also matches,
then event e is consider as a matched event.
Measuring Performance:
Precision and recall
over the data breach and protest events
are summarized in Table 6.1.
Results show that encoding high-order relational
structures
significantly improves the event detection performance in comparison to the baseline which
only encapsulates term co-occurrences.
Our approach yields an average F1 score of
71%
whereas the baselines manage an average of 55%.
6.5
Summary
In this chapter, we have presented a dynamic query expansion algorithm using hypergraph
learning.
We show that using hypergraph we can model the high-order semantic relationships
which then helps improve the event-characterization and in turn results in event retrieval
model.
We have performed a comprehensive evaluation of our approach achieving over 70%
accuracy in retrieving events related to civil unrest and cyber-attacks related from Twitter.
Future work targets inclusion of
other relational
attributes including social
network char-
acteristics and temporal
aspects of
information in social
media using hypergraphs.
Thus,
creating a contextual and recency-aware retrieval model for dynamic query expansion.
Chapter 7
Conclusion
Social media and microblogging services such as Twitter have become hybrid news informa-
tion sources where users can share links to events reported in conventional news media and
report their in-person accounts of
events as they unfold in real-time.
This form of
usage
makes such social platforms an attractive data source for several real-world applications.
In this dissertation, we have presented several augmentations to dynamic query expansion,
for microblog event retrieval
systems to provide more meaningful
domain-relevant search
results using a robust context-aware query expansion method.
We have identified four major
augmentations:
(1) A scalable query expansion framework that dynamically tracks and ranks evolving
themes.
We have presented an open source indicators approach for tracking emerging
threat-related chatter,
with news-Twitter reciprocity modeling for capturing interac-
tions between social and traditional media, and a ranking scheme to provide an ordered
assessment of airport threats, i.e., estimating if one airport is under greater threat than
another.
(2) An interactive visual theme refinement tool which models user preferences and incorpo-
rates their feedback to allows the DQE algorithm to learn an improved model for query
expansion and produce a more accurate ranking of emergent themes.
Since data-driven
decision-making is a multi-dimensional process, we argued that the detected threats or
reported incidents alone should not predominate the decision-making process.
We have shown how relative rankings are valuable to this process and adept for priority-
setting in conjunction with other factors, including expert opinions and data-supported
evidence.
(3) A context-aware query expansion procedure that can willfully target a domain with
high specificity.
We developed a novel
query expansion algorithm that uses semantic
83
84
Chapter 7. Conclusion
similarities computed from structural dependencies between textual features.
Making
the query expansion more context-aware allows a richer characterization of events.
For
example, as shown in Figure 7.1b, in comparison to the baseline DQE, the Typed DQE
approach generates expansion terms which provide meaningful insights into the event’s
attributes.
(4) An approach to encode high-order semantic relationships in the dynamic query expan-
sion with the help of hypergraphs.
In this DQE augmentation,
we identified concep-
tually relevant arguments (actions and agents) of
an ongoing event with the help of
a query-driven strategy.
Our strategy based on dynamically expanding the original
query with relevant key-terms iteratively captures event-focused characteristics from a
stream of short-texts containing incomplete information.
We constructed a semantic
hypergraph that provides a more accurate grouping of
complex relationships among
features and entities that describe events.
(a) Baseline DQE
(b) Typed DQE
(c) Hypergraph DQE
Figure 7.1:
Wordclouds showing expansions from three different DQE approaches.
7.1. Future Work
85
(a) IoT
(b) Machine Learning
(c) Datascience
Figure 7.2:
Wordclouds showing expansions from DQE for specific seed queries.
To evaluate our DQE augmentations, we have also tried them on other domains.
Two specific
domains we consider are - (1) 2017 US Primary Elections
1
and (2) Science & Technology
Forecasting
2
.
We have built web-based applications to showcase the quality of
query ex-
pansions and retrieved tweets.
These applications demonstrate the ability of our approach
to different domains.
For example,
in Figure 7.2 we display the word clouds of
query ex-
pansions using three specific keywords (“IoT”, “Machine Learning” and “Datascience”.
The
expansions selected provide key insights for the (Science & Technology) domain.
7.1
Future Work
Future research directions are discussed below:
1
http://people.cs.vt.edu/rupen/us-elections-2017-primaries/
2
http://people.cs.vt.edu/rupen/dqe-twitter-trends/
86
Chapter 7. Conclusion
• Problem 1:
We have adapted the dynamic query expansion as a targeted theme tracking
application.
This application focuses on identifying relative threats.
We posit that if
we consider a broad range of
data sources (e.g.,
news,
Twitter),
we can account for
deficiencies in specific intelligence as well as incorporate public perceptions.
We have
communicated our findings at IAAI 2017 [43].
In future work, exploring the temporal
evolution of
expanded queries with DQE can be particularly useful
to determine a
sequence of events, and, for specific scenarios, forecast their emergence within a given
lead time horizon.
• Problem 2:
We have built an interface for visual
knowledge discovery and analysis
for real-time,
situational
awareness using open source indicators.
It allows users to
manipulate relative rankings of a fixed set of entities for specific emergent themes and
provide feedback to control the algorithm’s inputs.
We are in the process of submitting
our findings to an appropriate journal.
Future work includes conducting more user-
studies with security professionals.
• Problem 3:
We have developed a structured query expansion strategy which empha-
sizes context-rich retrieval
of
information during each iteration of
query expansion.
This approach provides a well-characterized input for societal
event detection meth-
ods.
We have communicated a comprehensive evaluation of
this approach at CIKM
2017 [44].
Future work focuses on developing a Multimodal DQE, by adapting query
conceptualization to model other data modalities such as images and videos jointly.
• Problem 4:
We have presented a framework to adopt dynamic query expansion to per-
form event discovery and characterization in unison iteratively.
We are in the process
of submitting our findings to an appropriate machine learning conference.
Future work
focuses on building a custom lexicon of event frames for microblogs, to allow more nat-
ural
coupling of DQE and event extraction.
Such query expansions are formal
event
surrogates rather than simpler keyword constructs.
Bibliography
[1]
Puneet
Agarwal,
Rajgopal
Vaithiyanathan,
Saurabh Sharma,
and Gautam Shroff.
Catching the long-tail:
Extracting local news events from twitter.
In ICWSM, 2012.
[2]
Hadi Amiri, Abolfazl Ale Ahmad, Masoud Rahgozar, and Farhad Oroumchian.
Query
expansion using wikipedia concept graph.
2008.
[3]
Eiji Aramaki, Sachiko Maskawa, and Mizuki Morita. Twitter catches the flu:
detecting
influenza epidemics using twitter.
In EMNLP ’14, pages 1568–1576, 2011.
[4]
Jaime Arguello, Jonathan L Elsas, Jamie Callan, and Jaime G Carbonell.
Document
representation and query expansion models for blog recommendation.
ICWSM,
2008
(0):1, 2008.
[5]
Farzindar Atefeh and Wael
Khreich.
A survey of
techniques for event detection in
twitter.
Comput. Intell., 31(1):132–164, 2015.
[6]
Martin Atkinson, Jakub Piskorski, Erik Van der Goot, and Roman Yangarber.
Multi-
lingual
real-time event extraction for border security intelligence gathering.
Springer,
2011.
[7]
Ayan Bandyopadhyay, Kripabandhu Ghosh, Prasenjit Majumder, and Mandar Mitra.
Query expansion for microblog retrieval.
International
Journal
of Web Science,
1(4):
368–380, 2012.
[8]
Hila Becker, Dan Iter, Mor Naaman, and Luis Gravano. Identifying content for planned
events across social media sites.
In Proc. WSDM’12, 2012.
[9]
Hila Becker,
Mor Naaman,
and Luis Gravano.
Beyond trending topics:
Real-world
event identification on twitter.
In Proc. ICWSM’14, 2012.
[10]
C Berge.
Hypergraphs. 1989.
Bordas, Paris.
[11]
Johan Bollen, Huina Mao, and Xiaojun Zeng. Twitter mood predicts the stock market.
Journal
of Computational
Science, 2(1):1–8, 2011.
87
88
BIBLIOGRAPHY
[12]
Elizabeth Boschee,
Jennifer Lautenschlager,
Sean O’Brien,
Steve Shellman,
James
Starz, and Michael Ward.
Icews coded event data.
Harvard Dataverse, 12, 2015.
[13]
Sarah Boyd. Trend:
a system for generating intelligent descriptions of time series data.
In IEEE International
Conference on Intelligent
Processing Systems (ICIPS1998).
Citeseer, 1998.
[14]
Igor Brigadir, Derek Greene, and Pádraig Cunningham.
Adaptive Representations for
Tracking Breaking News on Twitter.
http://arxiv.org/abs/1403.2923, 2014.
[15]
Claudio Carpineto,
Giovanni
Romano,
and Vittorio Giannini.
Improving retrieval
feedback with multiple term-ranking function combination.
ACM Transactions on
Information Systems (TOIS), 20(3):259–290, 2002.
[16]
Liang-Chu Chen,
Wen-Tsan Chao,
and Chia-Jung Hsieh.
A novel
query expansion
method for military news retrieval
service.
In Asian Language Processing (IALP),
2014 International
Conference on, pages 183–186. IEEE, 2014.
[17]
Marc Cheong and Vincent CS Lee.
A microblogging-based approach to terrorism
informatics:
Exploration and chronicling civilian sentiment and response to terrorism
events via twitter.
Information Systems Frontiers, 13(1):45–59, 2011.
[18]
Wesley W Chu, Zhenyu Liu, and Wenlei Mao. Textual document indexing and retrieval
via knowledge sources and data mining. Communication of the Institute of Information
and Computing Machinery (CIICM), Taiwan, 5(2), 2002.
[19]
Kristin Cook, Nick Cramer, David Israel, Michael Wolverton, Joe Bruce, Russ Burtner,
and Alex Endert. Mixed-initiative visual analytics using task-driven recommendations.
In Visual Analytics Science and Technology (VAST), 2015 IEEE Conference on, pages
9–16. IEEE, 2015.
[20]
Adam Cox.
Building a relative risk methodology to inform decisionmaking.
http:
//tinyurl.com/johvutl, 2015.
[21]
Michael Davis,
Weiru Liu,
Paul Miller,
and George Redpath.
Detecting anomalies in
graphs with numeric labels.
In Proc. CIKM’11, 2011.
[22]
Francesco M Delle Fave, Matthew Brown, Chao Zhang, Eric Shieh, Albert Xin Jiang,
Heather Rosoff,
Milind Tambe,
and John P Sullivan.
Security games in the field:
BIBLIOGRAPHY
89
Deployments on a transit system.
In Engineering Multi-Agent
Systems,
pages 103–
126. Springer, 2014.
[23]
Kristina M DeVoe.
Bursts of information:
Microblogging.
The Reference Librarian,
50(2):212–214, 2009.
[24]
DHS.
The
2014 Quadrennial
homeland security review.
http://tinyurl.com/
ofsxhhh, 2014.
[25]
Manuel
Carlos Díaz-Galiano,
Maite Teresa Martín-Valdivia,
and LA Ureña-López.
Query expansion with a medical
ontology to improve a multimodal
information re-
trieval system.
Computers in biology and medicine, 39(4):396–403, 2009.
[26]
Qi Ding, Natallia Katenka, Paul Barford, Eric Kolaczyk, and Mark Crovella. Intrusion
as (anti)social
communication:
Characterization and detection.
In Proc.
KDD’12,
2012.
[27]
Liang Dong,
Pradip K Srimani,
and James Z Wang.
Ontology graph based query
expansion for biomedical
information retrieval.
In Bioinformatics and Biomedicine
(BIBM), 2011 IEEE International
Conference on, pages 488–493. IEEE, 2011.
[28]
Ofer Egozi,
Shaul
Markovitch,
and Evgeniy Gabrilovich.
Concept-based information
retrieval using explicit semantic analysis.
ACM Transactions on Information Systems
(TOIS), 29(2):8, 2011.
[29]
Martin Ester,
Hans-Peter Kriegel,
Jörg Sander,
and Xiaowei
Xu.
A density-based
algorithm for discovering clusters in large spatial
databases with noise.
In KDD ’96,
pages 226–231, 1996.
[30]
Brendan J Frey and Delbert Dueck.
Clustering by passing messages between data
points.
Science, 315(5814):972–976, 2007.
[31]
Gaihua Fu, Christopher B Jones, and Alia I Abdelmoty.
Ontology-based spatial query
expansion in information retrieval.
In OTM Confederated International
Conferences”
On the Move to Meaningful
Internet Systems”, pages 1466–1482. Springer, 2005.
[32]
Albert Gatt and Ehud Reiter.
Simplenlg:
A realisation engine for practical
applica-
tions. In Proceedings of the 12th European Workshop on Natural Language Generation,
pages 90–93. Association for Computational Linguistics, 2009.
90
BIBLIOGRAPHY
[33]
Samuel
Gratzl,
Alexander Lex,
Nils Gehlenborg,
Hanspeter Pfister,
and Marc Streit.
Lineup:
Visual
analysis
of
multi-attribute rankings.
Visualization and Computer
Graphics, IEEE Transactions on, 19(12):2277–2286, 2013.
[34]
Franciscus Alexander Grootjen and Th P Van Der Weide. Conceptual query expansion.
Data & Knowledge Engineering, 56(2):174–193, 2006.
[35]
Joan Guisado-Gámez,
David Dominguez-Sal,
and Josep-LLuis Larriba-Pey.
Massive
query expansion by exploiting graph knowledge bases. arXiv preprint arXiv:1310.5698,
2013.
[36]
Susan Havre, Beth Hetzler, and Lucy Nowell.
Themeriver:
Visualizing theme changes
over time.
In Information Visualization,
2000.
InfoVis 2000.
IEEE Symposium on,
pages 115–123. IEEE, 2000.
[37]
Jingrui He, Wei Shen, Phani Divakaruni, Laura Wynter, and Rick Lawrence. Improving
traffic prediction with tweet semantics.
In AAAI ’13, pages 1387–1393, 2013.
[38]
Liangjie Hong,
Byron Dom,
Siva Gurumurthy,
and Kostas Tsioutsiouliklis.
A time-
dependent topic model for multiple text streams.
In KDD ’11, pages 832–840, 2011.
[39]
Jian Hu, Gang Wang, Fred Lochovsky, Jian-tao Sun, and Zheng Chen.
Understanding
user’s query intent with wikipedia.
In Proceedings of the 18th international conference
on World wide web, pages 471–480. ACM, 2009.
[40]
Heng Ji,
Ralph Grishman,
et al.
Refining event extraction through cross-document
inference.
In Proc. ACL’08, 2008.
[41]
Anna Jurek, Yaxin Bi, and Maurice Mulvenna. Twitter sentiment analysis for security-
related information gathering.
In JISIC ’14, pages 48–55, 2014.
[42]
Rohit J Kate.
A dependency-based word subsequence kernel.
In Proc.
EMNLP’08,
2008.
[43]
Rupinder P Khandpur,
Taoran Ji,
Yue Ning,
Liang Zhao,
Chang-Tien Lu,
Erik R
Smith,
Christopher Adams,
and Naren Ramakrishnan.
Determining relative airport
threats from news and social media.
AAAI, 2017.
BIBLIOGRAPHY
91
[44]
Rupinder Paul
Khandpur,
Taoran Ji,
Steve Jan,
Gang Wang,
Chang-Tien Lu,
and
Naren Ramakrishnan.
Crowdsourcing cybersecurity:
Cyber attack detection using
social
media.
In Proceedings of
the 2017 ACM on Conference on Information and
Knowledge Management, pages 1049–1057. ACM, 2017.
[45]
Jon Kleinberg.
Bursty and hierarchical structure in streams.
In Proc. KDD’02, 2002.
[46]
Ralf Krestel, Thomas Werkmeister, Timur Pratama Wiradarma, and Gjergji Kasneci.
Tweet-recommender:
Finding relevant tweets for news articles.
In WWW ’15,
pages
53–54, 2015.
[47]
Bum Jun Kwon, Jayanta Mondal, Jiyong Jang, Leyla Bilge, and Tudor Dumitras.
The
dropper effect:
Insights into malware distribution with downloader graph analytics.
In
Proc. CCS’15, 2015.
[48]
Alex Lamb, Michael J Paul, and Mark Dredze.
Separating fact from fear:
Tracking flu
infections on twitter.
In HLT-NAACL, pages 789–795, 2013.
[49]
Theodoros Lappas, Marcos R Vieira, Dimitrios Gunopulos, and Vassilis J Tsotras.
On
the spatiotemporal burstiness of terms.
VLDB ’12, 5(9):836–847, 2012.
[50]
Jey Han Lau, Nigel Collier, and Timothy Baldwin.
On-line trend analysis with topic
models:
\
# twitter trends detection topic model online.
Proceedings of COLING 2012,
pages 1519–1534, 2012.
[51]
Victor Lavrenko and W Bruce Croft.
Relevance-based language models.
In ACM
SIGIR Forum, volume 51, pages 260–267. ACM, 2017.
[52]
Wenke Lee and Salvatore J.
Stolfo.
Data mining approaches for intrusion detection.
In Proc. USENIX Sec’98, 1998.
[53]
Scotland C Leman,
Leanna House,
Dipayan Maiti,
Alex Endert,
and Chris North.
Visual to parametric interaction (v2pi).
PLOS ONE, 8(3):e50474, 2013.
[54]
Frank Li, Zakir Durumeric, Jakub Czyz, Mohammad Karami, Michael Bailey, Damon
McCoy, Stefan Savage, and Vern Paxson.
You’ve got vulnerability:
Exploring effective
vulnerability notifications.
In Proc. USENIX Sec’16, 2016.
92
BIBLIOGRAPHY
[55]
Xiaojing Liao,
Kan Yuan,
XiaoFeng Wang,
Zhou Li,
Luyi
Xing,
and Raheem Beyah.
Acing the ioc game:
Toward automatic discovery and analysis of
open-source cyber
threat intelligence.
In Proc. CCS’16, 2016.
[56]
Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang, Yang Chen, and Tao Li. Generating
event storylines from microblogs.
In CIKM ’12, pages 175–184, 2012.
[57]
Cindy Xide Lin,
Qiaozhu Mei,
Jiawei
Han,
Yunliang Jiang,
and Marina Danilevsky.
The joint inference of topic diffusion and evolution in social
communities.
In ICDM
’11, pages 378–387, 2011.
[58]
Jimmy Lin,
Rion Snow,
and William Morgan.
Smoothing techniques for adaptive
online language models:
topic tracking in tweet streams.
In KDD ’11, pages 422–429,
2011.
[59]
Shuang Liu,
Fang Liu,
Clement Yu,
and Weiyi
Meng.
An effective approach to doc-
ument retrieval
via utilizing wordnet and recognizing phrases.
In Proceedings of
the
27th annual
international
ACM SIGIR conference on Research and development
in
information retrieval, pages 266–272. ACM, 2004.
[60]
Yang Liu,
Armin Sarabi,
Jing Zhang,
Parinaz Naghizadeh,
Manish Karir,
Michael
Bailey, and Mingyan Liu.
Cloudy with a chance of breach:
Forecasting cyber security
incidents.
In Proc. USENIX Sec’15, 2015.
[61]
Yang Liu, Jing Zhang, Armin Sarabi, Mingyan Liu, Manish Karir, and Michael Bailey.
Predicting cyber security incidents using feature-based characterization of
network-
level malicious activities.
In Proc. IWSPA’15, 2015.
[62]
Hector Llorens, Leon Derczynski, Robert J. Gaizauskas, and Estela Saquete.
TIMEN:
an open temporal expression normalisation resource.
In LREC ’12, pages 3044–3051,
2012.
[63]
Min Lu,
Zuchao Wang,
and Xiaoru Yuan.
Trajrank:
Exploring travel
behaviour on
a route by trajectory ranking.
In Visualization Symposium (PacificVis),
2015 IEEE
Pacific, pages 311–318. IEEE, 2015.
[64]
Aravindan Mahendiran, Wei Wang, Jaime Arredondo Sanchez Lira, Bert Huang, Lise
Getoor, David Mares, and Naren Ramakrishnan.
Discovering evolving political vocab-
BIBLIOGRAPHY
93
ulary in social
media.
In Behavior,
Economic and Social
Computing (BESC),
2014
International
Conference on, pages 1–7. IEEE, 2014.
[65]
Rila Mandala,
Tokunaga Takenobu,
and Tanaka Hozumi.
The use of
wordnet in
information retrieval.
Usage of
WordNet
in Natural
Language Processing Systems,
1998.
[66]
Kamran Massoudi,
Manos Tsagkias,
Maarten De Rijke,
and Wouter Weerkamp.
In-
corporating query expansion and quality indicators in searching microblog posts.
In
European Conference on Information Retrieval, pages 362–367. Springer, 2011.
[67]
Qiaozhu Mei
and ChengXiang Zhai.
Discovering evolutionary theme patterns from
text:
An exploration of temporal text mining.
In KDD ’05, pages 198–207, 2005.
[68]
Qiaozhu Mei
and ChengXiang Zhai.
Discovering evolutionary theme patterns from
text:
an exploration of temporal text mining.
In Proc. KDD’05, 2005.
[69]
Mandar Mitra,
Amit Singhal,
and Chris Buckley.
Improving automatic query ex-
pansion.
In Proceedings of
the 21st annual
international
ACM SIGIR conference on
Research and development in information retrieval, pages 206–214. ACM, 1998.
[70]
A. Modi, Z. Sun, A. Panwar, T. Khairnar, Z. Zhao, A. Doupé, G. J. Ahn, and P. Black.
Towards automated threat intelligence fusion.
In Proc. IEEE CIC’16, 2016.
[71]
Apostol
Paul
Natsev,
Alexander Haubold,
Jelena Tešić,
Lexing Xie,
and Rong Yan.
Semantic concept-based query expansion and re-ranking for multimedia retrieval.
In
Proceedings of the 15th ACM international conference on Multimedia, pages 991–1000.
ACM, 2007.
[72]
Nasir Naveed,
Thomas Gottron,
Jérôme Kunegis,
and Arifah Che Alhadi.
Bad news
travel
fast:
A content-based analysis of interestingness on twitter.
In Proceedings of
the 3rd international
web science conference, page 8. ACM, 2011.
[73]
Roberto Navigli
and Paola Velardi.
An analysis of
ontology-based query expansion
strategies.
In Proceedings of
the 14th European Conference on Machine Learning,
Workshop on Adaptive Text Extraction and Mining, Cavtat-Dubrovnik, Croatia, pages
42–49. Citeseer, 2003.
94
BIBLIOGRAPHY
[74]
Yue Ning, Sathappan Muthiah, Ravi Tandon, and Naren Ramakrishnan.
Uncovering
news-twitter reciprocity via interaction patterns.
In ASONAM ’15, pages 1–8, 2015.
[75]
Caleb C. Noble and Diane J. Cook. Graph-based anomaly detection. In Proc. KDD’03,
2003.
[76]
Brendan O’Connor,
Ramnath Balasubramanyan,
Bryan R Routledge,
and Noah A
Smith.
From tweets to polls:
Linking text sentiment to public opinion time series.
ICWSM, 11(122-129):1–2, 2010.
[77]
Nelleke Oostdijk and Hans van Halteren.
N-gram-based recognition of
threatening
tweets.
In CICLing ’13, pages 183–196. Springer, 2013.
[78]
Min Peng,
Quanchen Lin,
Ye Tian,
Ming Yang,
Yuling Xiao,
and Bin Ni.
Query
expansion based on conceptual word cluster space graph.
In Information Science and
Service Science (NISS), 2011 5th International Conference on New Trends in, volume 1,
pages 128–133. IEEE, 2011.
[79]
J. Piskorski, H. Tanev, and A. Balahur.
Exploiting twitter for border security-related
intelligence gathering.
In Proc. EISIC’13, 2013.
[80]
Jaroslaw Piskorski, Hristo Tanev, and Alexandra Balahur. Exploiting twitter for border
security-related intelligence gathering.
In EISIC ’13, pages 239–246, 2013.
[81]
James Pita, Manish Jain, C Western, P Paruchuri, J Marecki, M Tambe, F Ordonez,
and Sarit Kraus.
Armor software:
A game theoretic approach to airport security.
Protecting Airline Passengers in the Age of Terrorism, page 163, 2009.
[82]
James Pita,
Milind Tambe,
Chris Kiekintveld,
Shane Cullen,
and Erin Steigerwald.
Guards:
game theoretic security allocation on a national scale.
In AAMAS ’11, pages
37–44, 2011.
[83]
Tobias Preis,
Helen Susannah Moat,
and H Eugene Stanley.
Quantifying trading
behavior in financial markets using google trends.
Scientific reports, 3, 2013.
[84]
Yonggang Qiu and Hans-Peter Frei.
Concept based query expansion.
In Proceedings
of the 16th annual international ACM SIGIR conference on Research and development
in information retrieval, pages 160–169. ACM, 1993.
BIBLIOGRAPHY
95
[85]
Naren Ramakrishnan,
Patrick Butler,
Sathappan Muthiah,
Nathan Self,
Rupinder
Khandpur,
Parang Saraf,
Wei
Wang,
Jose Cadena,
Anil
Vullikanti,
Gizem Korkmaz,
et al.
’beating the news’
with embers:
forecasting civil
unrest using open source
indicators.
In KDD ’14, pages 1799–1808, 2014.
[86]
Alan Ramo.
California comparative risk project (1994).
toward the 21st century:
Planning for the protection of california’s environment. Golden Gate University School
of Law Digital
Commons, 1994.
[87]
Jacob Ratkiewicz, Michael Conover, Mark Meiss, Bruno Gonçalves, Alessandro Flam-
mini, and Filippo Menczer.
Detecting and tracking political abuse in social media.
In
ICWSM, 2011.
[88]
Radim Rehurek and Petr Sojka.
Software framework for topic modelling with large
corpora.
In Proc. LREC Workshop of NLP Frameworks, 2010.
[89]
Alan Ritter,
Mausam,
Oren Etzioni,
and Sam Clark.
Open domain event extraction
from twitter.
In Proc. KDD’12, 2012.
[90]
Alan Ritter,
Evan Wright,
William Casey,
and Tom Mitchell.
Weakly supervised
extraction of computer security events from twitter.
In Proc. WWW’15, 2015.
[91]
Stephen E Robertson, Steve Walker, Micheline Beaulieu, and Peter Willett.
Okapi at
trec-7:
automatic ad hoc, filtering, vlc and interactive track.
Nist Special
Publication
SP, (500):253–264, 1999.
[92]
Carl
Sabottke,
Octavian Suciu,
and Tudor Dumitras.
Vulnerability disclosure in the
age of
social
media:
Exploiting twitter for predicting real-world exploits.
In Proc.
USENIX Sec’15, 2015.
[93]
Takeshi
Sakaki,
Makoto Okazaki,
and Yutaka Matsuo.
Earthquake shakes twitter
users:
real-time event detection by social sensors.
In WWW ’10, pages 851–860, 2010.
[94]
Gerard Salton and Michael
J McGill.
Introduction to modern information retrieval.
1986.
[95]
Gerard Salton and J Michael.
Mcgill.
1983.
Introduction to modern information
retrieval, 1983.
96
BIBLIOGRAPHY
[96]
Jagan Sankaranarayanan,
Hanan Samet,
Benjamin E Teitler,
Michael
D Lieberman,
and Jon Sperling.
Twitterstand:
news in tweets.
In SIGSPATIAL ’09,
pages 42–51,
2009.
[97]
Conglei Shi, Weiwei Cui, Shixia Liu, Panpan Xu, Wei Chen, and Huamin Qu. Rankex-
plorer:
Visualization of ranking changes in large time series data.
Visualization and
Computer Graphics, IEEE Transactions on, 18(12):2669–2678, 2012.
[98]
Xin Shuai, Xiaozhong Liu, and Johan Bollen.
Improving news ranking by community
tweets.
In WWW ’12, pages 1227–1232, 2012.
[99]
Alessio Signorini, Alberto Maria Segre, and Philip M Polgreen.
The use of twitter to
track levels of disease activity and public concern in the us during the influenza a h1n1
pandemic.
PLoS one, 6(5):e19467, 2011.
[100]
Jagendra Singh and A Sharan. Ranks aggregation and semantic genetic approach based
hybrid model for query expansion. International Journal of Computational Intelligence
Systems, Taylor & Francis, 10(1):34–55, 2016.
[101]
Jagendra Singh and Aditi Sharan.
Context window based co-occurrence approach for
improving feedback based query expansion in information retrieval.
In Information
Retrieval
and Management:
Concepts,
Methodologies,
Tools,
and Applications,
pages
1597–1613. IGI Global, 2018.
[102]
Kyle Soska and Nicolas Christin.
Automatically detecting vulnerable websites before
they turn malicious.
In Proc. USENIX Sec’14, 2014.
[103]
Martijn Spitters,
Pieter T Eendebak,
Daniël
TH Worm,
and Henri
Bouma.
Threat
detection in tweets with trigger patterns and contextual
cues.
In JISIC ’14,
pages
216–219, 2014.
[104]
X Yu Stella and Jianbo Shi.
Multiclass spectral
clustering.
In null,
page 313.
IEEE,
2003.
[105]
Hristo Tanev, Maud Ehrmann, Jakub Piskorski, and Vanni Zavarella. Enhancing event
descriptions through twitter mining.
In Proc. ICWSM’14, 2012.
[106]
The
White
House.
Big Data:
Seizing opportunities,
preserving values.
http:
//tinyurl.com/ondfdop, 2014.
BIBLIOGRAPHY
97
[107]
TSA Blog.
TSA 2015 year in review.
http://tinyurl.com/j8h593o, 2015.
[108]
Flora S.
Tsai
and Kap Luk Chan.
Detecting cyber security threats in weblogs using
probabilistic models.
In Proc. PAISI’07, 2007.
[109]
Edward R Tufte and PR Graves-Morris. The visual display of quantitative information,
volume 2.
Graphics press Cheshire, CT, 1983.
[110]
Andranik Tumasjan, Timm Oliver Sprenger, Philipp G Sandner, and Isabell M Welpe.
Predicting elections with twitter:
What 140 characters reveal about political sentiment.
ICWSM, 10:178–185, 2010.
[111]
Emily Wall, Subhajit Das, Ravish Chawla, Bharath Kalidindi, Eli T Brown, and Alex
Endert.
Podium:
Ranking data using mixed-initiative visual analytics.
IEEE transac-
tions on visualization and computer graphics, 24(1):288–297, 2018.
[112]
Xiaofeng Wang, Matthew S Gerber, and Donald E Brown. Automatic crime prediction
using events extracted from twitter posts.
In SBP ’12, pages 231–238. Springer, 2012.
[113]
William Webber, Alistair Moffat, and Justin Zobel. A similarity measure for indefinite
rankings.
ACM Transactions on Information Systems (TOIS), 28(4):20, 2010.
[114]
William E Weiss.
Dynamic security:
An agent-based model
for airport defense.
In
WSC ’08, pages 1320–1325, 2008.
[115]
David J. Weller-Fahy.
Towards finding malicious cyber discussions in social media.
In
Proc. AICS’17, 2017.
[116]
Jianshu Weng and Bu-Sung Lee.
Event detection in twitter.
ICWSM ’11, 11:401–408,
2011.
[117]
Jinxi
Xu and W Bruce Croft.
Query expansion using local
and global
document
analysis.
In Proceedings of
the 19th annual
international
ACM SIGIR conference on
Research and development in information retrieval, pages 4–11. ACM, 1996.
[118]
Chengxiang Zhai
and John Lafferty.
A study of
smoothing methods for language
models applied to information retrieval.
ACM Transactions on Information Systems
(TOIS), 22(2):179–214, 2004.
98
BIBLIOGRAPHY
[119]
Liang Zhao, Feng Chen, Jing Dai, Ting Hua, Chang-Tien Lu, and Naren Ramakrish-
nan.
Unsupervised spatial
event detection in targeted domains with applications to
civil unrest modeling.
PLoS ONE, 9(10):e110206, 2014.
[120]
Denny Zhou,
Jiayuan Huang,
and Bernhard Schölkopf.
Learning with hypergraphs:
Clustering, classification, and embedding. In Advances in neural information processing
systems, pages 1601–1608, 2007.
[121]
Xiangmin Zhou and Lei Chen.
Event detection over twitter social media streams.
The
VLDB Journal, 23(3):381–400, 2014.
