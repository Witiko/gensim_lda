Graduate School Form 
30 Updated 
12/26/2015
PURDUE UNIVERSITY 
GRADUATE SCHOOL 
Thesis/Dissertation Acceptance 
This is to certify that the thesis/dissertation prepared 
By 
Entitled 
For the degree of 
Is approved by the final examining committee: 
To the best of my knowledge and as understood by the student in the Thesis/Dissertation 
Agreement, Publication Delay, and Certification Disclaimer (Graduate School Form 32), 
this thesis/dissertation adheres to the provisions of Purdue University’s “Policy of 
Integrity in Research” and the use of copyright material. 
Approved by Major Professor(s): 
Approved by: 
Head of the Departmental Graduate Program 
Date 
BHUIYAN, MD MANSURUL, ALAM
GENERIC FRAMEWORKS FOR INTERACTIVE PERSONALIZED INTERESTING PATTERN DISCOVERY
Doctor of Philosophy
MOHAMMAD AL HASAN
ELISA BERTINO
Chair
SNEHASIS MUKHOPADHYAY
JEAN HONORIO
CHRIS CLIFTON 
MOHAMMAD AL HASAN
SUNIL PRABHAKAR/WILLIAM J. GORMAN
9/30/2016
PREVIEW
PREVIEW
GENERIC FRAMEWORKS FOR INTERACTIVE PERSONALIZED
INTERESTING PATTERN DISCOVERY
A Dissertation
Submitted to the Faculty
of
Purdue University
by
Md Mansurul Bhuiyan
In Partial Fulfillment of the
Requirements for the Degree
of
Doctor of Philosophy
December 2016
Purdue University
West Lafayette, Indiana
PREVIEW




ProQuest
Number:




All rights 
reserved

INFORMATION 
TO ALL 
USERS
The
quality
of this 
reproduction
is 
dependent upon 
the
quality
of the 
copy submitted.

In the unlikely 
event
that the 
author
did not send a 
complete 
manuscript
and there are missing 
pages,
these will be 
noted.
Also, if 
material
had to be 
removed,
a
note
will
indicate 
the 
deletion.





ProQuest

Published by ProQuest LLC ( 
). 
Copyright
of the Dissertation 
is 
held by the 
Author.


All rights 
reserved.
This
work
is 
protected against unauthorized copying 
under Title 17, United States 
Code
Microform
Edition © ProQuest 
LLC.


ProQuest
LLC.
789 East Eisenhower 
Parkway
P.O. Box 
1346
Ann Arbor, MI 48106 
-
1346
10195545
10195545
2017
PREVIEW
ii
To my parents and wife; without whom none of these would be possible.
PREVIEW
iii
ACKNOWLEDGMENTS
I can not acknowledge enough to my PhD advisor Dr.
Mohammad Hasan.
Six
years back when I was fresh from the boat,
Dr.
Hasan took my responsibility.
He
understood my shortcomings and recognized my eagerness to learn.
He taught me so
many things that became part of my everyday work.
I thank him from the bottom of
my heart.
I would also like to thank Dr.
Chris Clifton, Dr.
Snehasis Mukhopadhyay,
Dr.
Elisa Burtino, Dr.
Jean Honorio and Dr.
David Gleich for their guidance, encour-
agement and suggestions.
I appreciate the friendship and research contributions from
all the members of our lab and would like to take this opportunity to thank Mahmud,
Tanay,
Baichuan and Vachik.
Lastly,
I am thankful
to my all
family members for
their support and encouragement.
PREVIEW
iv
TABLE OF CONTENTS
Page
LIST OF TABLES .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ix
LIST OF FIGURES
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
x
ABSTRACT .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
xii
1
INTRODUCTION .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1
1.1
Problem Definition of Interactive Personalized Interesting Pattern Dis-
covery
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
1.2
Interactive Learning Model .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
3
1.2.1
User Interaction Design
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
3
1.2.2
Interactive Pattern Discovery though Sampling
.
.
.
.
.
.
.
4
1.2.3
Interactive Pattern Discovery through Supervised Learning .
4
1.3
Selecting Patterns for Feedback
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
5
1.4
Feature Representation of Patterns and Genericness
.
.
.
.
.
.
.
.
.
6
1.5
Real-life Application of
Interactive Personalized Interesting Pattern
Discovery
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7
1.6
Organization of the Dissertation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
8
2
BACKGROUND AND RELATED WORKS .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2.1
Background .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2.1.1
Frequent Pattern Mining .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
2.1.2
Frequent Pattern Space .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11
2.2
Related Works .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
12
2.2.1
Frequent Pattern Summarization
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
12
2.2.2
Interactive Knowledge Discovery
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
2.2.3
Interactive Pattern Mining .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16
2.2.4
Interestingness Measures of Patterns
.
.
.
.
.
.
.
.
.
.
.
.
.
18
PREVIEW
v
Page
3
INTERACTIVE PATTERN MINING ON HIDDEN DATA: A SAMPLING-
BASED SOLUTION .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
3.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
3.2
Related Works .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
3.2.1
Data Analytics over Hidden Databases
.
.
.
.
.
.
.
.
.
.
.
.
24
3.2.2
Privacy Preserving Pattern Mining
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
3.2.3
Frequent Pattern Sampling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
25
3.3
Problem Statement
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.4
Background .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27
3.4.1
Frequent Partial Order Graph .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.4.2
Markov Chains, Random Walk and Metropolis-Hastings (MH)
Algorithm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.5
Interactive Sampling Algorithm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
3.5.1
User’s Scoring Function
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
3.5.2
Updated Scoring Function(γ) for Graph Patterns
.
.
.
.
.
.
32
3.5.3
User Interaction Design
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
3.5.4
Feedback Mechanism .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
3.5.5
State-transition Graph and Convergence of MH-based Random
Walk .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
3.5.6
Algorithm .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
3.5.7
Mining Patterns from Hidden Datasets
.
.
.
.
.
.
.
.
.
.
.
.
46
3.6
Experiments & Results
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
47
3.6.1
Experiment Setup .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
47
3.6.2
Dataset
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48
3.6.3
Analysis of Sampler’s Performance
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
3.6.4
Interactive vs Uniform Sampling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
3.6.5
Analysis of Sampler’s Performance for Conditional Periodic Feed-
back Mechanism .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
3.6.6
Analysis of Sampler’s Performance with Updated Scoring Func-
tion for Graph Data
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
57
PREVIEW
vi
Page
3.6.7
Timing Analysis .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
58
3.6.8
Empirical
Evaluation of Disclosure of Hidden Itemset Dataset
through IPM .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
59
3.6.9
Real-life Utility of Interactive Mining .
.
.
.
.
.
.
.
.
.
.
.
.
64
3.6.10 Illustration of Interactiveness over HIV-1 Dataset
.
.
.
.
.
.
66
3.7
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68
3.7.1
Safeguarding the System from Manipulative User
.
.
.
.
.
.
68
3.7.2
Advanced Feedback Mechanism .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
68
3.7.3
Making Learning and Sampling Phase Independent
.
.
.
.
.
68
3.7.4
Robust Data Privacy Model
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
69
3.8
Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
69
4
PATTERN2VEC: NEURAL-NET BASED FEATURE REPRESENTATION
LEARNING OF COMPLEX FREQUENT PATTERNS .
.
.
.
.
.
.
.
.
.
71
4.1
Related Works .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
72
4.1.1
Representation Learning of Text .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
72
4.1.2
Representation Learning of Graph .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
72
4.2
Background .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
73
4.2.1
Feature Representation of Words
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
74
4.2.2
Feature Representation of Paragraphs .
.
.
.
.
.
.
.
.
.
.
.
.
76
4.3
Feature Representation of Sequence Pattern
.
.
.
.
.
.
.
.
.
.
.
.
.
77
4.4
Feature Representation of Graph Pattern .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
78
4.5
Experiments .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
79
4.5.1
Data .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
79
4.5.2
Experiment Setup .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81
4.5.3
Transaction Classification
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82
4.5.4
Pattern Classification .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
82
4.6
Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
83
5
PRIIME: A ROBUST FRAMEWORK FOR INTERACTIVE PERSONAL-
IZED INTERESTING PATTERN DISCOVERY .
.
.
.
.
.
.
.
.
.
.
.
.
.
85
PREVIEW
vii
Page
5.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
85
5.2
Problem Definition and System Architecture
.
.
.
.
.
.
.
.
.
.
.
.
87
5.3
Learning Method
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
89
5.3.1
Pattern Representation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
90
5.4
Feature Representation of Set Patterns
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
90
5.4.1
Classification Model
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
91
5.4.2
Regression Model
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
92
5.4.3
Selection of Representative Data-points for Feedback
.
.
.
.
93
5.4.4
Stopping Criteria .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
94
5.5
Experiments and Results .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95
5.5.1
Data .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
95
5.5.2
Experimental Setup .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
96
5.5.3
Interestingness Criteria .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
97
5.5.4
Experiment on the Learner’s Performance
.
.
.
.
.
.
.
.
.
.
98
5.5.5
Comparison with the Existing Algorithms
.
.
.
.
.
.
.
.
.
.
101
5.5.6
Representative Patterns Selection .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
102
5.5.7
Experimental Results of Gradient Boosted Regression Tree Model
104
5.5.8
Comparison with Different Regression Algorithms
.
.
.
.
.
.
107
5.6
Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
108
6
RAVEN : WEB-BASED SMART HOME EXPLORATION THROUGH IN-
TERACTIVE PATTERN DISCOVERY .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
109
6.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
109
6.2
Problem Formulation and System Architecture
.
.
.
.
.
.
.
.
.
.
.
112
6.3
Method
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
115
6.3.1
Data and Pattern Representation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
115
6.3.2
Classification Model
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
116
6.3.3
Selection of Representative Data-points for Feedback
.
.
.
.
117
6.4
RAVEN: The System .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
118
PREVIEW
viii
Page
6.4.1
First Level Feedback Module .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
118
6.4.2
Second Level Feedback Module
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
120
6.4.3
House Recommendation Module .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
121
6.4.4
Implementation Detail
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
121
6.5
Data .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
122
6.5.1
Data Collection .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
122
6.5.2
Data Cleanup .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
122
6.5.3
Data Statistics
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
123
6.6
Empirical Evaluation on Housing Data
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
123
6.6.1
Demographic Group 1
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
124
6.6.2
Demographic Group 2
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
124
6.6.3
Demographic Group 3
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
126
6.6.4
Experimental Setup .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
126
6.6.5
Observations
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
128
6.6.6
Analysis of Recommendation Quality .
.
.
.
.
.
.
.
.
.
.
.
.
129
6.7
Related Works .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
130
6.7.1
Real Estate Price Modeling
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
131
6.7.2
Commercial Real Estate Search Products .
.
.
.
.
.
.
.
.
.
.
131
6.7.3
Real Estate Recommendation
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
132
6.8
Future Directions and Conclusion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
132
7
FUTURE WORKS AND CONCLUSION .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
134
7.1
Sampling Based Solution .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
134
7.2
Pattern Representation:
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
135
7.3
RAVEN : The Home Discovery System .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
135
LIST OF REFERENCES
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
137
VITA .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
146
PREVIEW
ix
LIST OF TABLES
Table
Page
3.1
Effect of random edges in POG on spectral gap
.
.
.
.
.
.
.
.
.
.
.
.
.
39
3.2
Dataset statistics
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48
3.3
Effects of parameter b on Mushroom data-set
.
.
.
.
.
.
.
.
.
.
.
.
.
.
53
3.4
Effects of parameter miniter on Mushroom data-set
.
.
.
.
.
.
.
.
.
.
.
53
3.5
Effects of parameter percentage of divergence (η) on Mushroom data-set
54
3.6
Average sampler’s precision measure of uniform and interactive sampling.
56
3.7
Comparisons of average sampler’s precision measure while considering con-
ditional periodic feedback VS periodic feedback
.
.
.
.
.
.
.
.
.
.
.
.
.
56
3.8
Comparisons
of
average sampler’s
precision measure while considering
topological information in scoring function and not.
.
.
.
.
.
.
.
.
.
.
.
57
3.9
Chebyshev-Cantelli’s probability bound on Attacker 2’s data-set exact re-
construction performance measured by l2-norm.
*DP=Data Points
.
.
62
3.10 Some frequent patterns from eBay query dataset .
.
.
.
.
.
.
.
.
.
.
.
.
64
4.1
Dataset statistics
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
80
4.2
Sequence transaction classification .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
80
4.3
Graph transaction classification .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
81
5.1
Dataset statistics
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
96
5.2
Comparison on percentage accuracy of
our algorithm with the existing
ones
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
101
5.3
R-squared (R
2
) and Mean absolute error of our algorithm on Class score
, Jaccard index and Odds ratio based interestingness.
.
.
.
.
.
.
.
.
.
.
105
6.1
Number of house in each city
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
123
6.2
Recommend city for demographic group 1, demographic group 2, and de-
mographic group 3 (Indy is the short form in Indianapolis)
.
.
.
.
.
.
.
130
PREVIEW
x
LIST OF FIGURES
Figure
Page
2.1
(a) Graph database with 3 transaction graphs (b) Frequent subgraph of
(a) with minsup = 2
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2.2
(a) Itemset database with 5 transaction sets (b) Frequent,
maximal
and
closed itemsets of (a) with minsup = 3 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
2.3
Candidate space lattice of the toy itemset dataset
.
.
.
.
.
.
.
.
.
.
.
.
12
2.4
Frequent subgraph patterns lattice for minimum support 2 .
.
.
.
.
.
.
13
3.1
Sampling-based interactive pattern mining on a hidden dataset .
.
.
.
.
22
3.2
(a) Partial Order Graph (POG) (b) State-transition graph .
.
.
.
.
.
.
29
3.3
Set of undirected graphical structures with 3 and 4 vertices.
.
.
.
.
.
.
31
3.4
Scatter-plot with a fitted straight line showing the relationship between
the sampler’s precision and the number of feedback in (a) Mushroom (b)
Chess (c) eBay (d) Connect (e) HIV (f) Biodegradability (g) Mutagenicity-
II with Periodic Feedback.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
49
3.5
Scatter-plot with a fitted straight line showing the relationship between the
sampler’s precision and the number of feedback in (a) Mushroom (b) Chess
(c) eBay (d) Connect (e) HIV (f) Biodegradability and (g) Mutagenicity-II
with “Conditional Periodic” Feedback scheme.
.
.
.
.
.
.
.
.
.
.
.
.
.
51
3.6
Timing performance of
IPM w.r.t different database size and minimum
support for Mutagenicity-II(Graph) and Mushroom(Itemset) data-set
.
59
3.7
L2-norm between parameters of Dist and Dist
′
with the increasing number
of released patterns over (a) Mushroom (b) Chess data-set
.
.
.
.
.
.
.
63
3.8
Changing of sampling distribution with feedback for HIV-1 dataset
.
.
66
4.1
Neural network of feature representation of words
.
.
.
.
.
.
.
.
.
.
.
.
74
4.2
Neural network of feature representation of paragraphs
.
.
.
.
.
.
.
.
.
76
4.3
Unsupervised feature construction of graph patterns .
.
.
.
.
.
.
.
.
.
.
77
4.4
Performance of unsupervised feature construction.
.
.
.
.
.
.
.
.
.
.
.
83
5.1
Generic interactive personalized interesting pattern discovery framework
87
PREVIEW
xi
Figure
Page
5.2
Unsupervised feature construction of sequence Patterns .
.
.
.
.
.
.
.
.
91
5.3
Weighted F-Score of the learner across iterations of feedback in set dataset
98
5.4
Weighted F-Score of the learner across iterations of feedback in sequence
dataset .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
99
5.5
Weighted F-Score of
the learner across iterations of
feedback in graph
dataset .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
99
5.6
Box-plot of weighted F-score across five folds.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
100
5.7
Performance of
the learner with different feedback collection scheme in
Mushroom set dataset
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
102
5.8
Performance of
the learner with different feedback collection scheme in
Reuters1 sequence dataset
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
102
5.9
Performance of
the learner with different feedback collection scheme in
Mutagenicity-II graph dataset
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
103
5.10 R
2
of the learner across increasing number of feedback in Chess dataset
106
5.11 R
2
of the learner across increasing number of feedback in (a) Pumsb (b)
EHR and (c) Drug dataset .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
107
5.12 Comparison of GBRT based learner with SVM and Linear regression using
odds ratio on (a) Chess (b) Pumsb (c) EHR (d) Drug dataset
.
.
.
.
.
108
6.1
Architecture of RAVEN
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
114
6.2
User interface of first level feedback module of RAVEN.
.
.
.
.
.
.
.
.
119
6.3
Partial user interface of second level feedback module of RAVEN .
.
.
120
6.4
Partial user interface of final house recommendation module of RAVEN
121
6.5
Performance of
the learner with across iterations of
feedback for demo-
graphic group 1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
125
6.6
Performance of
the learner with across iterations of
feedback for demo-
graphic group 2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
125
6.7
Performance of
the learner with across iterations of
feedback for demo-
graphic group 3 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
126
6.8
Quality of training on the demographic group 1
.
.
.
.
.
.
.
.
.
.
.
.
.
127
6.9
Quality of training on the demographic group 2
.
.
.
.
.
.
.
.
.
.
.
.
.
127
6.10 Quality of training on the demographic group 3
.
.
.
.
.
.
.
.
.
.
.
.
.
128
PREVIEW
xii
ABSTRACT
Bhuiyan,
Md Mansurul
Ph.D.,
Purdue University,
December 2016.
Generic Frame-
works for Interactive Personalized Interesting Pattern Discovery.
Major Professor:
Mohammad Al Hasan.
The traditional
frequent
pattern mining algorithms generate an exponentially
large number of
patterns of
which a substantial
portion are not much significant
for many data analysis endeavors.
Due to this, the discovery of a small number of in-
teresting patterns from the exponentially large number of frequent patterns according
to a particular user’s interest is an important task.
Existing works on pattern summa-
rization compute a summary that globally represents the entire frequent pattern-set.
Such a representative set solves the interesting pattern discovery problem from a
global
perspective which,
more often,
far from the personalization that is required
to fulfill
the pattern discovery criteria of a particular user.
In this dissertation,
we
propose two interactive pattern discovery frameworks to identify a set of interesting
patterns for a particular user without requiring any prior input on the measure of
interest of patterns from the user.
The proposed frameworks are generic to support
discovery of the interesting set, sequence and graph type patterns.
In the first framework, we solve the problem by proposing a novel solution which
is based on Markov Chain Monte Carlo (MCMC) sampling of patterns.
Our solution
allows interactive sampling so that the sampled patterns can fulfill the user’s require-
ment effectively.
Instead of
returning all
the patterns for feedback,
the proposed
paradigm sends back a small set of randomly selected patterns so that an adversary
will not be able to reconstruct the entire dataset with higher accuracy using the re-
leased set of patterns, hence protecting the confidentiality of the data-set as a whole.
PREVIEW
xiii
This feature enables the proposed framework to mine interesting patterns from hidden
datasets.
In the second framework,
we develop an interactive pattern discovery framework
called PRIIME that is based on iterative learning of
a user’s interestingness func-
tion.
The learning process is supervised where the supervision is provided by a user
through feedback on a small
set of
pattern.
Depending on the nature of
feedback
i.e.
non-negative real
valued or discrete,
in PRIIME we develop gradient boosted
tree-based regression and softmax classification algorithms that use a limited number
of interactive feedbacks from the user to learn the interestingness profile of the user,
and use this profile for pattern recommendation.
Both the proposed frameworks are generic in nature.
First proposed framework
discover patterns by commencing a random walk over a pattern space so the frame-
work is inherently generic.
However,
in PRIIME,
the interactive pattern discovery
is performed by modeling a traditional
regression/classification function,
for which
we need a vector representation of pattern instances.
For vector representation of set
patterns we use bag-of-words based model.
However, for graph and sequential pattern
we propose a neural net (NN) based unsupervised feature construction approach.
In an interactive pattern discovery system,
effective nomination of
patterns for
feedback to train a learning model is an important task.
In both the proposed frame-
works, we develop efficient strategy that combine exploration and exploitation to se-
lect patterns for feedback.
We show experimental results on several real-life datasets
to validate the performance of the proposed frameworks.
We also compare with the
existing methods of interactive pattern discovery to show that our methods are sub-
stantially superior in performance.
Finally, to portray the applicability of the interactive pattern discovery, we build a
new home discovery tool for home buyers called RAVEN. It uses interactive feedback
over a collection of home feature-sets to learn a buyer’s interestingness profile.
Then
it recommends a small list of homes that match with the buyer’s interest, eventually
decreasing the time interval between home search initiation and purchase.
PREVIEW
1
1.
INTRODUCTION
Frequent pattern (itemsets, sequences, or graphs) mining [1] has been a core research
task in the data mining domain for over two decades,
yet its deployment in real life
data analysis has been moderate due to the following two challenges:
(1) the pat-
tern space is combinatorial,
so the number of patterns that a mining task produces
is generally too large to process by an end user,
(2) for various data analysis tasks,
frequency threshold is not a sufficient filtering criterion for selecting patterns.
To
overcome (1), many works have been proposed for pattern summarization and com-
pression [2–6], and to overcome (2), several
alternative interestingness metrics,
such
as Jaccard index,
odds ratio,
and lift [1, 7, 8] have been proposed.
Nevertheless,
the
discovery of interesting patterns remains an unsolved problem due to the subjectivity
in the definition of interestingness.
In many cases, off-the-shelf interestingness metrics
does not represent true interestingness for a specific user over the patterns.
Pattern
summarization does not help either,
as such an approach solves interesting pattern
discovery from a global perspective which is far from personalization that is needed
to meet the pattern discovery demand of a specific user.
There exist few works which target personalized pattern discovery by using users
feedback [9, 10].
The overall
methodologies of
these works are to build an interac-
tive pattern discovery system,
that works as the following—a user provides ratings
on a small
collection of patterns,
then the system uses these ratings to train a per-
sonalization model,
which is later used to isolate user’s preferred patterns from the
remaining ones.
The major design choices of
an interactive pattern discovery sys-
tem are:
(1) learning model
that the system uses;
(2) pattern selection process for
feedback—whether it is active [11]
or non-active;
(3) feature representation of
pat-
terns for facilitating learning; and (4) genericness, i.e.
the kinds of patterns that the
system supports.
Existing solutions [9, 10]
for interactive pattern discovery are not
PREVIEW
2
effective for a number of the above design choices.
In this dissertation,
we address
the challenges associated with each of the above design choices to build an efficient,
personalized pattern discovery system.
1.1
Problem Definition of
Interactive Personalized Interesting Pattern
Discovery
Consider a transactional dataset
D
, where each transaction in
D
is a combinatorial
object, such as an itemset, a sequence,
or a graph.
Depending on the objects that it
contains, the dataset
D
can be an itemset, a sequence or a graph dataset.
A user u is
interested in mining interesting patterns from
D
, where the patterns (denoted by set
O
) are sub-objects,
say subsets,
subsequences,
or subgraphs,
over the objects in
D
.
Traditional
approaches [12, 13]
consider frequency as the interestingness metric and
design frequent pattern mining algorithms which return patterns that exceed mini-
mum support thresholds over the transactions in
D
.
However,
due to the fact that
the frequent pattern space is combinatorial [1], existing frequent pattern mining algo-
rithms generally return a large number of patterns, causing an information overload.
Interactive pattern discovery is a framework for negotiating information overload so
that a succinct set of interesting patterns (a small subset of frequent patterns,
O
) can
be delivered to u, which are personalized by utilizing u’s feedback on a small number
of patterns.
We call this framework IPIPD, which stands for Interactive Personalized
Interesting Pattern Discovery.
We assume u possesses an interestingness function (say, f ) over the patterns (
O
).
f maps each pattern in
O
to a score indicating u’s interest level for the pattern, i.e.,
f :
O →
Y .
Here, Y can be modeled as discrete or non-negative real number.
IPIPD
framework learns f through an iterative user’s feedback session.
During an iteration
(say i),
the system returns a set of l
patterns
{
p
t
}
1≤t≤l
to u,
which is selected from
O
; u sends feedback
{
y
t
= f (p
t
)
}
1≤t≤l
using an interactive console; y
t
’s are discrete or
non-negative real number reflecting the user’s empathy towards the selected patterns;
PREVIEW
3
using the feedback the system updates its current model of the user’s interestingness
function, f .
In the following sections,
we will
explain our contributions addressing the four
design choices:
i) interactive learning model, ii) pattern selection process for feedback,
iii) effective feature representation of pattern, and iv) genericness associated with an
efficient personalized interactive interesting pattern discovery system.
Contribution
of this dissertation is also demonstrate through a real-life application of interactive
pattern discovery framework.
1.2
Interactive Learning Model
Learning the user’s interestingness
criteria (function f ) is at the core of
per-
sonalized pattern discovery problem.
The task of
identifying a learning model
and
training the model
for effective pattern recommendation is the most prioritized job
of an IPIPD system.
In this dissertation,
we model the learning of a user’s interest-
ingness function, f in two ways.
In one, we design it as a sampling mechanism that
interactively modifies the sampling distribution (proportional
to the interestingness
function) according to the user’s feedback (y
t
).
In second,
we design the problem
as supervised learning where we adopt both regression and classification for learning
the model
iteratively while leveraging the user’s feedback.
In the following,
we first
discuss the user interaction design that we use in this work and then we explain both
of the learning models in details.
1.2.1
User Interaction Design
The applicability of the IPIPD framework in a real
life setting depends strongly
on the way a user interacts with the system.
Ideally, level of interaction between the
system and the user should be simple and the system should put manageable burden
to the user while collecting feedback.
Existing systems fail to provide above feature
in their interactive mechanism.
In [9],
the user has to provide a complete ordering
PREVIEW
4
of a set of patterns for feedback.
Since the user has to cross check among patterns
in the set to formulate the feedback,
the chance of
making mistakes is high.
This
misinformation directly affects the learning model.
In [10], apart from providing the
ordering,
the user has to decide whether the system chooses between exploitation
or exploration.
Such interaction protocol
puts more burden on a user in the sense
that the quality of
the learned model
is directly influenced by the user’s ability to
provide precise feedback.
From the very beginning,
we were motivated to design an
interaction mechanism that is simple as well
as effective.
With that in mind,
in our
proposed IPIPD frameworks,
a user only considers one pattern at a time when she
formulates a feedback.
The user considers a notion of an interestingness score, either
discrete or positive real-valued, to construct a feedback on the patterns quality.
1.2.2
Interactive Pattern Discovery though Sampling
In [14], we propose a novel
sampling-based interactive pattern discovery method
where the user interacts with a Metropolis-Hastings (MH) based Markov Chain Monte
Carlo (MCMC) sampling entity.
It samples patterns from the data; the target distri-
bution of the sampler is iteratively refined based on binary feedback (discrete y
t
) from
the user.
We model
the user’s interestingness function (f ) over the patterns using
the target sampling distribution.
As an additional
feature,
this sampling based ap-
proach protects the integrity of a hidden dataset by releasing patterns in a restrictive
manner such that the probability of entire dataset reconstruction using the released
set of patterns with high accuracy is very low [15].
In Chapter 3, we discuss in detail
of the proposed algorithm and show experimental
results from several
real-life data
sets to validate the capability and usefulness of our solution.
1.2.3
Interactive Pattern Discovery through Supervised Learning
Even though the overall
idea is novel,
the sampling-based solution has a crucial
drawback.
The learning and the sampling are unified,
which causes the sampler to
PREVIEW
5
converge to a sharp distribution prematurely.
As a consequence,
this sampler may
sample patterns only from a local region of the frequent pattern space while keeping
a significant amount of space unexplored.
We solve the drawback by modeling the
interestingness function as a linear predictor function.
Depending on the nature of
feedback,
we either use a regression (positive real-valued feedback) or a classifica-
tion (discrete values) algorithm.
Classification
In the classification approach,
interestingness function f can be defined as f :
O →
C
; i.e.
f maps each pattern in
O
to a discrete number (class label).
We build
a softmax classification based iterative learning algorithm that leverages a limited
number of
interactive feedback from the user to learn the interestingness profile of
the user and uses this profile for pattern recommendation.
In Chapter 5 we discuss
the model in detail.
Regression
In the regression approach, interestingness function f can be defined as f :
O →
R
+
;
i.e.
f maps each pattern in
O
to a non-negative real
number.
We develop a
gradient boosted regression tree (an ensemble of
high bias regression trees) based
iterative learning algorithm that uses a limited number of interactive feedback from
the user to learn her interestingness profile of the patterns and uses this profile for
pattern recommendation.
In Chapter 5 we elaborately discuss the model.
1.3
Selecting Patterns for Feedback
For any interactive learning platform, designing a method for selecting a small set
of patterns for which a user’s feedback is sought is critical.
Given that the number
of
frequent patterns is typically enormous,
the performance of
interactive learning
PREVIEW
6
depends critically on the module that selects the patterns for collecting user’s feed-
back.
In the sampling-based approach, we combine model learning with the feedback
set selection.
First, we [14] adopt a step function to nominate patterns for feedback.
Later in [15], we upgrade the pattern selection process by providing the system a ca-
pability to measure whether the information obtained through feedback is significant
for learning or not.
One major flaw with the heavy coupling between the learning
and selection is that the initial
sets of
feedbacks play a vital
role to the model’s
configuration.
Hence,
the model
may risk suffering from the positive reinforcement
phenomenon.
It sometimes makes the predictive model
representing some areas of
the pattern space, making it sub-optimal over the entire space.
To resolve this issue
in the supervised learning setup, we reduce the coupling between the existing state of
the learning model and the feedback pattern selection which yields a much improved
learning model.
We effectively combine exploration and exploitation which reduces
the bias that the existing learning model imposes on pattern selection.
1.4
Feature Representation of Patterns and Genericness
The majority of the existing platforms for interactive pattern discovery only sup-
port itemset patterns because they do not have an effective metric embedding for more
complex patterns, say, sequences, or graphs.
Metric embedding of patterns is needed
for facilitating the training of a model
which discriminates between interesting and
not-so-interesting patterns.
For itemset patterns, existing works leverage bag of items
for instrumenting a metric representation.
However, no such natural instrumentation
is available for complex patterns, such as a sequence, or a graph.
Sometimes, n-grams
are used for metric embedding of sequences [16],
and topological
measures,
such as
centralities, eccentricity, egonet degree, egonet size, and diameter are used for feature
representation of graphs [17].
While the above feature representation may work well
for the task of traditional sequence or graph classification, they do not work well for
frequent patterns which are numerous and much smaller in size.
PREVIEW
7
In [14], we used a bag of items/edges based technique to find feature representation
of set and graph type patterns.
In [15] for graph patterns, we improve the represen-
tation by considering topological
information of the graph in the bag in terms of 3
and 4 size induced subgraphs in the pattern.
Such crude representation for a complex
pattern like the graph is unable to produce a satisfactory performance.
As an alter-
native, we seek a solution to build a generic IPIPD framework using the unsupervised
feature learning in traditional
and neural
network domain.
These methods help an
analyst discover features automatically, thus obviating feature engineering using do-
main knowledge.
We develop a technique called “Pattern2Vec” that computes the
metric representation of
graph and sequence patterns using traditional
single layer
neural network.
“Pattern2Vec” map each pattern into a sentence and the pattern ele-
ments (events in a sequence or edges in a graph) into words.
Afterward, it leverages a
language model similar to [18] for finding d-dimensional feature vector representation
of the patterns.
We experimentally show that such a technique performs better than
the existing ad-hoc metric embedding.
1.5
Real-life Application of Interactive Personalized Interesting Pattern
Discovery
To demonstrate the applicability of
interactive personalized interesting pattern
discovery in a real world setting, we perform a case study in the real-estate domain.
Generally,
the success of
a home searching process depends on a user’s ability to
construct a well-defined search query.
It also depends on her patience while going
through the hundreds of houses that are returned by the search engine.
This assess-
ment is particularly challenging for new home buyers,
who are sometimes not even
familiar with all
different home features.
The overall
process of
selecting the right
home takes time;
for 40% of first-time home buyers,
the lag time between research
and action (buying a home) is around 120 days [19].
Given that home buying is a
significant investment,
most home buyers take help from an experienced real
estate
PREVIEW
8
agent who can read the buyer’s mind as soon as possible and show her the home that
is just the right one for her.
Our developed IPIPD system named RAVEN in this setup works just like a
virtual
real
estate agent for the home buyers,
where each house can be thought of
as a set type transaction and house features as the items in the transaction.
In each
iteration,
RAVEN presents a set of
patterns which are a summary set of
features
of
the houses in the data.
By utilizing the feedback over the quality of
patterns,
RAVEN gradually learns the user’s interestingness criteria on the house features.
Finally, using the learned model, RAVEN identifies the house summaries (patterns)
as well as the houses that the user will prefer.
1.6
Organization of the Dissertation
The remainder
of
this dissertation is organized as follows.
In Chapter 2,
we
discuss background on traditional
frequent pattern mining and related works from
pattern summarization and interactive pattern discovery domain.
In Chapter 3,
we
discuss the sampling based approach of
personalized interesting pattern discovery,
work published in the Information and Knowledge Management (CIKM) conference,
2012 [14].
In Statistical
Analysis and Data Mining journal
we further published an
extended version of this work [15].
In Chapter 4, we discuss “Pattern2Vec” approach
for computing effective feature vector representation of
patterns that we leverage
to build generic interactive pattern discovery framework.
In Chapter 5,
we discuss
the softmax classification and gradient boosted regression tree based IPIPD system
called PRIIME.
We submitted PRIIME in the IEEE Big Data conference,
2016.
In Chapter 6,
we present a web-based smart house discovery tool
called RAVEN,
that is build upon the concept of personalization interesting pattern discovery.
We
submitted RAVEN in Web Search and Data Mining (WSDM) conference, 2017.
We
conclude this dissertation with a conclusion and future works (Chapter 7).
PREVIEW
