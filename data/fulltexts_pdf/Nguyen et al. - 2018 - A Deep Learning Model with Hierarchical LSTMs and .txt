A Deep Learning Model with Hierarchical LSTMs and
Supervised Attention for Anti-Phishing
Minh Nguyen
Hanoi University of Science
and Technology
Hanoi, Vietnam
minh.nv142950@sis.hust.edu.vn
Toan Nguyen
New York University
Brooklyn, New York, USA
toan.v.nguyen@nyu.edu
Thien Huu Nguyen
University of Oregon
Eugene, Oregon, USA
thien@cs.uoregon.edu
ABSTRACT
Anti-phishing aims to detect phishing content/documents
in a pool
of
textual
data.
This is an important problem
in cybersecurity that can help to guard users from fraudu-
lent information.
Natural language processing (NLP) offers
a natural
solution for this problem as it is capable of ana-
lyzing the textual content to perform intelligent recognition.
In this work,
we investigate state-of-the-art techniques for
text categorization in NLP to address the problem of anti-
phishing for emails (i.e,
predicting if
an email
is phishing
or not).
These techniques are based on deep learning mod-
els that have attracted much attention from the community
recently.
In particular,
we present a framework with hier-
archical long short-term memory networks (H-LSTMs) and
attention mechanisms to model the emails simultaneously at
the word and the sentence level.
Our expectation is to pro-
duce an effective model
for anti-phishing and demonstrate
the effectiveness of deep learning for problems in cybersecu-
rity.
Keywords
Phishing, Deep Learning, NLP, H-LSTMs, Email Classifica-
tion, Attentive LSTMs
1.
INTRODUCTION
Despite being one of
the oldest tactics,
email
phishing re-
mains the most common attack used by cybercriminals [2]
due to its effectiveness.
Phishing attacks exploit users’
in-
ability to distinguish between legitimate information from
fake ones sent to them [9, 33, 34, 32].
In an email phishing
campaign, attackers send emails appearing to be from well-
known enterprises or organizations directly to their victims
or by spoofed emails [35].
These emails try to lure victims to
divulge their private information [17,
33,
32]
or to visit an
impersonated site (i.e.,
a fake banking website),
on which
they will
be asked for passwords,
credit card numbers or
other sensitive information.
The recent hack of a high pro-
file US politician (usually referred as “John Podesta’s hack”)
is a famous example of this type of attack.
It was all started
Copyright is held by the author/owner.
Permission to make digital or hard
copies of all or part of this work for personal or classroom use is granted
without fee.
In: R. Verma, A. Das.
(eds.): Proceedings of the 1st Anti-Phishing Shared
Pilot
at
4th ACM International
Workshop on Security and Privacy Ana-
lytics (IWSPA 2018)
Tempe,
Arizona,
USA,
21–03–2018,
published at
http://ceur-ws.org
by a spoofed email
sent to the victim asking him to reset
his Gmail
password by clicking on a link in the email
[1].
The technique of email
phishing may seem simple,
yet the
damage it makes is huge.
In the US alone,
the estimated
cost of
phishing emails to business is half
a billion dollars
per year [3].
Numerous methods have been proposed to automatically de-
tect phishing emails [7,
11,
4,
14].
Chandrasekaran et.
al
proposed to use structural properties of emails and Support
Vector Machines (SVM) to classify phishing emails [8].
In
[4],
Abu-Nimeh et.
al
evaluated six machine learning clas-
sifiers on a public phishing email dataset using proposed 43
features.
Gupta et.
al [14] presented a nice survey on recent
state-of-the-art research on phishing detection.
However,
these methods mainly rely on feature engineering efforts to
generate characteristics (features) to represent emails,
over
which machine learning methods can be applied to perform
the task.
Such feature engineering is often done manually
and still
requires much labor and domain expertise.
This
has hindered the portability of the systems to new domains
and limited the performance of the current systems.
In order to overcome this problem, our work focuses on deep
learning techniques to solve the problem of phishing email
detection.
The major benefit of deep learning is its ability
to automatically induce effective and task-specific represen-
tations from data that can be used as features to recognize
phishing emails.
As deep learning has been shown to achieve
state-of-the-art performance for many natural language pro-
cessing tasks, including text categorization [12, 19], informa-
tion extraction [28,
27,
29],
machine translation [5],
among
others,
we expect that it would also help to build effective
systems for phishing email detection.
We present a new deep learning model to solve the problem
of
email
phishing prediction using hierarchical
long short-
term memory networks (H-LSTMs) augmented with super-
vised attention technique.
In the hierarchical LSTM model
[37], emails are considered as hierarchical architectures with
words in the lower level
(the word level) and sentences in
the upper level (the sentence level).
LSTM models are first
implemented in the word level
whose results are passed to
LSTM models
in the sentence level
to generate a repre-
sentation vector for the entire email.
The outputs of
the
LSTM models in the two levels are combined using the at-
tention mechanism [5]
that assigns contribution weights to
the words and sentences in the emails.
A header network
is also integrated to model the headers of the emails if they
are available.
In addition,
we propose a novel
technique to
1
arXiv:1805.01554v1 [cs.CR] 3 May 2018
supervise the attention mechanism [24,
21,
22] at the word
level
of
the hierarchical
LSTMs based on the appearance
rank of
the words in the vocabulary.
Experiments on the
datasets for phishing email
detection in the First Security
and Privacy Analytics Anti-Phishing Shared Task (IWSPA-
AP 2018) [10] demonstrate the benefits of the proposed mod-
els,
being ranked among the top positions among the par-
ticipating systems of the shared task (in term of the perfor-
mance on the unseen test data).
2.
RELATED WORK
Phishing email
detection is a classic problem;
however,
re-
search on this topic often has the same limitation:
there
is no official
and big data set for it.
Most previous works
typically used a public set consists of
legitimate or “ham”
emails
1
and another public set of phishing emails
2
for their
classification evaluation [11, 7, 6, 15, 38].
Other works used
private but small
data sets[8,
4].
In addition,
the ratio be-
tween phishing and legitimate emails in these data sets was
typically balanced.
This is not the case in the real-world sce-
nario where the number of legitimate emails is much larger
than that of
phishing emails.
Our current work relies on
larger data sets with unbalanced distributions of
phishing
and legitimate emails collected for the the First Security and
Privacy Analytics Anti-Phishing Shared Task (IWSPA-AP
2018) [10].
Besides the limitation of small data sets, the previous work
has extensively relied on feature engineering to manually
find representative features for the problem.
Apart from
features extracted from emails,
[20]
also uses a blacklist of
phishing webistes to get an additional
feature for urls ap-
pearing in emails.
Some neural
network systems are also
introduced to detect such blacklists [26,
23].
This is unde-
sirable because these engineered features need to be updated
once new types of phishing emails with new content are pre-
sented.
Our work differs from the previous work in this
area in that we automate the feature engineering process
using a deep learning model.
This allows us to automat-
ically learn effective features for phishing email
detection
from data.
Deep learning has recently been employed for
feature extraction with success on many natural
language
processing problems [28, 27].
3.
PROPOSED MODEL
Phishing email
detection is a binary classification problem
that can be formalized as follow.
Let e = {b, s} be an email
in which b and s are the body
content and header of the email
respectively.
Let y the bi-
nary variable to indicate whether e is a phishing email
or
not (y = 1 if e is a phishing email and y = 0 otherwise).
In
order to predict the legitimacy of the email,
our goal
is to
estimate the probability P (y = 1|e) = P (y = 1|b, s).
In the
following,
we will
describe our methods to model
the body
b and header s with the body network and header network
respectively to achieve this goal.
3.1
Body Network with Hierarchical LSTMs
For the body b,
we view it as a sequence of
sentences b =
(u
1
, u
2
, . . . , u
L
) where u
i
is the i-th sentence and L is the
number of sentences in the email body b.
Each sentence u
i
is
1
https://spamassassin.apache.org/old/publiccorpus/
2
https://monkey.org/ jose/phishing/
in turn a sequence of words/tokens u
i
= (v
i,1
, v
i,2
, . . . , v
i,K
)
with v
i,j
as the j-th token in u
i
and K as the length of
the sentence.
Note that we set L and K to the fixed values
by padding the sentences u
i
and the body b with dummy
symbols.
As there are two levels of
information in b (i.e,
the word
level with the words v
i,j
and the sentence level with the sen-
tence u
i
),
we consider a hierarchical
network that involves
two layers of bidirectional long short-term memory networks
(LSTMs) to model such information.
In particular, the first
layer consumes the words in the sentences via the embedding
module,
the bidirectional
LSTM module and the attention
module to obtain representation vectors for every sentence
u
i
in b (the word level
layer).
Afterward,
the second net-
work layer combines the representation vectors from the first
layer with another bidirectional LSTM and attention mod-
ule,
leading to a representation vector for the whole body
email b (the sentence level layer).
This body representation
vector would then be used as features to estimate P (y|b, s)
and make the prediction for the initial email e.
3.1.1
The Word Level Layer
Embedding
In the word level layer, every word v
i,j
in each
sentence u
i
in b is first transformed into its embedding vec-
tor w
i,j
.
In this paper, w
i,j
is retrieved by taking the corre-
sponding column vector in the word embedding matrix W
e
[25]
that has been pre-trained from a large corpus:
w
i,j
=
W
e
[v
i,j
]
(each column in the matrix W
e
corresponds to a
word in the vocabulary).
As the result of
this embedding
step,
every sentence u
i
= (v
i,1
, v
i,2
, . . . , v
i,K
) in b would be
converted into a sequence of
vectors (w
i,1
, w
i,2
, . . . , w
i,K
),
constituting the inputs for the bidirectional LSTM model in
the next step.
Bidirectional LSTMs for the word level
This module em-
ploys two LSTMs [16,
13]
that run over each input vector
sequence (w
i,1
, w
i,2
, . . . , w
i,K
) via two different directions,
i.e, forward (from w
i,1
to w
i,K
) and backward (from w
i,K
to
w
i,1
).
Along with their operations, the forward LSTM gener-
ates the forward hidden vector sequence (
−−→
h
i,1
,
−−→
h
i,2
, . . . ,
−−→
h
i,K
)
while the backward LSTM produce the backward hidden
vector sequence (
←−−
h
i,1
,
←−−
h
i,2
, . . . ,
←−−
h
i,K
).
These two hidden vec-
tor sequences are then concatenated at each position, result-
ing in the new hidden vector sequence (h
i,1
, h
i,2
, . . . , h
i,K
)
for the sentence u
i
in b where h
i,j
= [
−→
h
i,j
,
←−
h
i,j
].
The notable
characteristics of
the hidden vector h
i,j
is that it encodes
the context information over the whole sentence u
i
due to
the recurrent property of the forward and backward LSTMs
although a greater focus is put at the current word v
i,j
.
Attention
In this module,
the vectors in the hidden vector
sequence (h
i,1
, h
i,j,2
, . . . , h
i,K
) are combined to generate a
single representation vector for the initial sentence u
i
.
The
attention mechanism [37]
seeks to do this by computing a
weighted sum of the vectors in the sequence.
Each hidden
vector h
i,j
would be assigned to a weight α
i,j
to estimate its
importance/contribution in the representation vector for u
i
for the phishing prediction of the email e.
In this work, the
weight α
i,j
for h
i,j
is computed by:
2
Figure 1:
Hierarchical LSTMs.
α
i,j
=
exp(a
>
i,j
w
a
)
P
j
0
exp(a
>
i,j
0
w
a
)
(1)
in which
a
i,j
= tanh(W
att
h
i,j
+ b
att
)
(2)
Here, W
att
, b
att
and w
a
are the model parameters that would
be learnt during the training process.
Consequently,
the
representation vector ˆ
u
i
for the sentence u
i
in b would be:
ˆ
u
i
=
X
j
α
i,j
h
i,j
(3)
After the word level
layer completes its operation on every
sentence of b = (u
1
, u
2
, . . . , u
L
),
we obtain a corresponding
sequence of sentence representation vectors (ˆ
u
1
, ˆ
u
2
, . . . , ˆ
u
L
).
This vector sequence would be combined in the next sen-
tence level
layer to generate a single vector to represent b
for phishing prediction.
3.1.2
The Sentence Level Layer
The sentence level layer processes the vector sequence (ˆ
u
1
, ˆ
u
2
, . . . , ˆ
u
L
)
in the same way that the word level
layer has employed
for the vector sequence (w
i,1
, w
i,2
, . . . , w
i,K
) for each sen-
tence u
i
.
Specifically, (ˆ
u
1
, ˆ
u
2
, . . . , ˆ
u
L
) is also first fed into a
bidirectional
LSTM module (i.e,
with a forward and back-
ward LSTM) whose results are concatenated at each posi-
tion to produce the corresponding hidden vector sequence
(
ˆ
h
1
,
ˆ
h
2
, . . . ,
ˆ
h
L
).
In the next step with the attention mod-
ule, the vectors in (
ˆ
h
1
,
ˆ
h
2
, . . . ,
ˆ
h
L
) are weighted and summed
to finally generate the representation vector r
b
for the email
body b of e.
Assuming the attention weights for (
ˆ
h
1
,
ˆ
h
2
, . . . ,
ˆ
h
L
)
are (β
1
, β
2
, . . . , β
L
) respectively.
the body vector r
b
is then
computed by:
r
b
=
X
i
β
i
ˆ
h
i
(4)
Note that the model parameters of the bidirectional LSTM
modules (and the attention modules) in the word level layer
and the sentence level layer are separate and they are both
learnt in a single training process.
Figure 1 shows the overview
of the body network with hierarchical LSTMs and attention.
Once the body vector r
b
has been computed, we can use it
as features to estimate the phishing probability via:
P (y = 1|b, s) = σ(W
out
r
b
+ b
out
)
(5)
where W
out
and b
out
are the model parameters and σ is the
logistic function.
3.2
Header Network
The probability estimation in Equation 5 does not consider
the headers of the emails.
For the email datasets with head-
ers available, we can model the headers with a separate net-
work and use the resulting representation as additional fea-
tures to estimate the phishing probability.
In this work, we
consider the header s of the initial email e as a sequence of
words/tokens:
(x
i
, x
2
, . . . , x
H
) where x
i
is the i-th word in
the header and H is the length of the header.
In order to
compute the representation vector r
s
for s, we also employ
the same network architecture as the word level layer in the
body network using separate modules for embedding mod-
ule,
bidirectional
LSTM,
and attention (i.e,
Section 3.1.1).
An overview of this header network is presented in Figure 2.
Once the header representation vector r
s
is generated,
we
concatenate it with the body representation vector r
b
ob-
tained from the body network,
leading to the final
rep-
resentation vector r = [r
b
, r
s
]
to compute the probability
P (y = 1|b, s) = σ(W
sub
r + b
sub
) (W
sub
and b
sub
are model
parameters).
Figure 2:
Hierarchical LSTMs with header network.
In order to train the models in this work,
we minimize the
negative log-likelihood of the models on a training dataset in
which the negative log-likelihood for the email e is computed
by:
L
c
= − log(P (y = 1|e))
(6)
The model
we have described so far is called H-LSTMs for
convenience.
3.3
Supervised Attention
The attention mechanism in the body and header networks is
expected to assign high weights for the informative words/sentences
3
and downgrade the irrelevant words/sentences for phishing
detection in the emails.
However,
this ideal
operation can
only be achieved when an enormous training dataset is pro-
vided to train the models.
In our case of phishing email de-
tection,
the size of the training dataset is not large enough
and we might not be able to exploit the full
advantages of
the attention.
In this work, we seek for useful heuristics for
the problem and inject them into the models to facilitate
the operation of
the attention mechanism.
In particular,
we would first heuristically decide a score for every word
in the sentences so that the words with higher scores are
considered as being more important for phishing detection
than those with lower scores.
Afterward, the models would
be encouraged to produce attention weights for words that
are close to their heuristic importance scores.
The expec-
tation is that this mechanism would help to introduce our
intuition into the attention weights to compensate for the
small
scale of
the training dataset,
potentially leading to
a better performance of the models.
Assuming the impor-
tance scores for the words in the sentence (v
i,1
, v
i,2
, . . . , v
i,K
)
be (g
i,1
, g
i,2
, . . . , g
i,K
) respectively,
we force the attention
weights (α
i,1
, α
i,2
, . . . , α
i,K
) (Equation 1) to be close to the
importance scores by penalizing the models that render large
square difference between the attention weights and the im-
portance scores.
This amounts to adding the square differ-
ence into the objective function in Equation 6:
L
e
= L
c
+ λ
X
i,j
(g
i,j
− α
i,j
)
2
(7)
where λ is a trade-off constant.
Importance Score Computation
In order to compute the
importance scores, our intuition is that a word is important
for phishing detection if
it appears frequently in phishing
emails and less frequently in legitimate emails.
The fact
that an important word does not appear in many legitimate
emails helps to eliminate the common words that are used in
most documents.
Consequently, the frequent words that are
specific to the phishing emails would receive higher impor-
tance scores in our method.
Note that our method to find
the important words for phishing emails is different from the
prior work that has only considered the most frequent words
in the phishing emails and ignored their appearance in the
legitimate emails.
We compute the importance scores as follow.
For every word
v in the vocabulary,
we count
the number
of
the phish-
ing and legitimate emails in a training dataset that con-
tain the word.
We call
the results as the phishing email
frequency and the legitimate email
frequency respectively
for v.
In the next step,
we sort the words in the vocabu-
lary based on its phishing and legitimate email
frequencies
in the descending order.
After that,
a word v would have
a phishing rank (phishingRank(v)) and a legitimate rank
(legitimateRank(v)) in the sorted word sequences based on
the phishing and legitimate frequencies (the higher the rank
is, the less the frequency is).
Given these ranks, the unnor-
malized importance score for v is computed by:
3
3
The actual important scores of the words we use in Equa-
tion 7 are normalized for each sentence.
score[v] =
legitimateRank[v]
phishingRank[v]
(8)
The rationale for this formula is that a word would have a
high importance score for phishing prediction if
its legiti-
mate rank is high and its phishing rank is low.
Note that
we use the ranks of the words instead of the frequencies be-
cause the frequencies are affected by the size of the training
dataset, potentially making the scores unstable.
The ranks
are less affected by the dataset size and provide a more stable
measure.
Table 1 demonstrates the top 20 words with the
highest unnormalized importance scores in our vocabulary.
Table 1:
Top 20 words with the highest scores.
account
21.45
your
15.00
click
14.11
mailbox
9.59
cornell
9.58
link
9.37
verify
8.83
customer
8.63
access
8.50
reserved
8.03
dear
7.85
log
7.70
accounts
7.61
paypal
7.52
complete
7.37
service
7.15
protect
6.95
secure
6.94
mail
6.70
clicking
6.63
The H-LSTMs model augmented with the supervised atten-
tion mechanism above is called H-LSTM+supervised in the
experiments.
3.3.1
Training
We train the models in this work with stochastic gradient
descent, shuffled mini-batches, Adam update rules [18].
The
gradients are computed via back-propagation while dropout
is used for regularization [36].
We also implement gradient
clipping to rescale the Frobenius norms of the non-embedding
weights if they exceed a predefined threshold.
4.
EVALUATION
4.1
Datasets and Preprocessing
The models in this work are developed to participate in the
First Security and Privacy Analytics Anti-Phishing Shared
Task (IWSPA-AP 2018) [10].
The organizers provide two
datasets to train the models for email phishing recognition.
The first dataset involves emails that only have the body
part (called data-no-header ) while the second dataset con-
tains emails with both bodies and headers (called data-full-
header.
These two datasets translate into two shared tasks
to be solved by the participants.
The statistics of the train-
ing data for these two datasets are shown in Table 2.
The raw test data (i.e,
without labels) for these datasets
are released to the participants at a specified time.
The
4
Datasets
#legit
#phish
data-no-header
5092
629
data-full-header
4082
503
Table 2:
Statistics of
the data-no-header and data-
full-header
datasets.
#legit
and #phish are the
numbers of
legitimate and phishing emails respec-
tively.
participants would have one week to run their systems on
such raw test data and submit the results to the organizers
for evaluation.
Regarding the preprocessing procedure for the datasets, we
notice that a large part of
the text in the email
bodies is
quite unstructured.
The sentences are often short and/or
not clearly separated by the ending-sentence symbols (i.e,
{.
!
?}).
In order to split the bodies of
the emails into
sentences for our models, we develope an in-house sentence
splitter specially designed for the datasets.
In particular,
we determine the beginning of
a sentence by considering
if
the first word of
a new line is capitalized or not,
or if
a capitalized word is immediately followed by an ending-
sentence symbol.
The sentences whose lengths (numbers
of
words) are less than 3 are combined to create a longer
sentence.
This reduces the number of sentences significantly
and expands the context for the words in the sentences as
they are processed by the models.
Figure 3 shows a phishing
email from the datasets.
Figure 3:
A case in which splitting body into sen-
tences cannot be done as usual.
(Phishing email:
28.txt in data-no-header).
4.2
Baselines
In order to see how well
the proposed deep learning mod-
els (i.e, H-LSTMs and H-LSTMs+supervised) perform with
respect to the traditional
methods for email
phishing de-
tection,
we compare the proposed models with a baseline
model
based on Support Vector Machines (SVM) [8].
We
use the tf-idf scores of the words in the vocabulary as the
features for this baseline [8].
Note that since the email
ad-
dresses and urls in the provided datasets have been mostly
hidden to protect personal information, we cannot use them
as features in our SVM baselines as do the previous systems.
We employ the implementation of linear and nonlinear SVM
from the sklearn library [30] for which the tf-idf represen-
tations of the emails are obtained via the gensim toolkit [31].
4.3
Hyper-parameter Selection
As the size of
the provided datasets is small
and no de-
velopment data is included,
we use a 5-fold stratified cross
validation on the training data of the provided datasets to
search for the best hyper-parameters for the models.
The
hyper-parameters we found are as follows.
The size of word embedding vector is 300 while the cell sizes
are set to 60 for all the LSTMs in the body and header net-
works.
The size of attention vectors at the attention modules
for the body and header networks are also set to 60.
The λ
coefficient for supervised attention is set to 0.1, the thresh-
old for gradient clipping is 0.3 and the drop rate for drop-out
is 0.5.
For the Adam update rule,
we use the learning rate
of 0.0025.
Finally, we set C = 10.0 for the linear SVM base-
line.
The nonlinear version of SVM we use is C-SVC with
radial basis function kernel and (C, γ) = (50.0, 0.1).
4.4
Results
In the experiments below,
we employ the precision,
recall
and F1-score to evaluate the performance of the models for
detecting phishing emails.
In addition, the proposed models
H-LSTMs and H-LSTMs+supervised only utilize the header
network in the evaluation on data-full-header.
Data without header
In the first experiment, we compare
the proposed models with the SVM baselines in two different
settings when the email headers are not considered (the first
shared task).
In particular, in the first setting, we use data-
no-header as the training data and perform a 5-fold stratified
cross-validation to evaluate the models.
In the second set-
ting, data-no-header is also utilized as the training data, but
the bodies extracted from data-full-header (along with the
corresponding labels) are employed as the test data.
The
results of
the first setting are shown in Table 3 while the
results of the second setting are presented in Table 4.
Models
Precision
Recall
F1
H-LSTMs+supervised
0.9784
0.9466
0.9621
H-LSTMs
0.9638
0.9448
0.9542
Linear SVM+tfidf
0.9824
0.8856
0.9313
Linear SVM+embedding
0.9529
0.9206
0.9364
Linear SVM+tfidf+embedding
0.9837
0.9253
0.9536
Kernel SVM+tfidf
0.9684
0.8730
0.9180
Kernel SVM+embedding
0.9408
0.9141
0.9273
Kernel SVM+tfidf+embedding
0.9714
0.9174
0.9436
Table 3:
Performance comparison between the pro-
posed models H-LSTMs and H-LSTMs+supervised
with the baseline models Linear and Kernel SVM.
Table 4:
Performance of all models on the test data
(data-full-headers).
Models
Precision
Recall
F1
H-LSTMs+supervised
0.8892
0.7395
0.8075
H-LSTMs
0.8934
0.7054
0.7883
Linear SVM+tfidf
0.8864
0.6978
0.7809
Linear SVM+embedding
0.8112
0.6918
0.7468
Linear SVM+tfidf+embedding
0.8695
0.7018
0.7767
Kernel SVM+tfidf
0.8698
0.7038
0.7780
Kernel SVM+embedding
0.8216
0.6501
0.7259
Kernel SVM+tfidf+embedding
0.8564
0.6937
0.7665
As we can see from the tables,
the two versions of
hier-
archical LSTMs (i.e,
H-LSTMs and H-LSTMs+supervised)
outperform the baseline models in both experiment settings.
5
The performance improvement is significant with large mar-
gins (up to 3% improvement on the absolute F1 score in the
first experiment setting).
The main gain is due to the recall,
demonstrating the generalization advantages of the proposed
deep learning models over the traditional methods for phish-
ing detection with SVM. Comparing H-LSTMs+supervised
and H-LSTMs, we see that H-LSTMs+supervised is consis-
tently better than H-LSTMs with significant improvement
in the second setting.
This shows the benefits of supervised
attention for hierarchical
LSTM models for email
phishing
detection.
Finally,
we see that the performance in the first
setting is in general
much better than those in the second
setting.
We attribute this to the fact that text data in data-
no-header and data-full-header is quite different, leading to
the mismatch between data distributions of the training data
and test data in the second experiment setting.
In the final submission for the first shared task (i.e, without
email
headers),
we combine the training data from data-
no-header with the extracted bodies (along with the corre-
sponding labels) from the training data of data-full-header
to generate a new training set.
As H-LSTM+supervised is
the best model in this development experiment, we train it
on the new training set and use the trained model to make
predictions for the actual test set of the first shared task.
Data with full header
In this experiment, we aim to eval-
uate if the header network can help to improve the perfor-
mance of H-LSTMs.
We take the training dataset from data-
full-header to perform a 5-fold cross-validation evaluation.
The performance of H-LSTMs when the header network is
included or excluded is shown in Table 5.
Table 5:
Cross-validation performance of H-LSTMs
with using headers compared to the original version.
Models
Precision
Recall
F1
H-LSTMs (only body)
0.9732
0.9534
0.9631
H-LSTMs + headers
0.9816
0.9596
0.9705
From the table, we see that the header network is also help-
ful for H-LSTMs as it helps to improve the performance of
H-LSTMs for the dataset with email
headers (an 0.7% im-
provement on the F1 score).
In the final submission for the second shared task (i.e, with
email headers), we simply train our best model in this setting
(i.e,
H-LSTM+supervised) on the training dataset of data-
full-header.
The time for the training and test process of the proposed
models is shown in the Table 6.
Note that the training time
of H-LSTMs+headers+supervised is longer than that of H-
LSTMs+supervised since the first model’s training data in-
cludes both the original training data of the first task and the
extracted bodies from the training data of the second task.
The test data of the first task with H-LSTMs+supervised is
also larger than that of the second task with
H-LSTMs+headers+supervised.
Comparision with the participating systems on the ac-
tual
test
sets
Tables 7 and 8 show the best performance
on the actual
test data of all
the teams that participate in
the shared tasks.
Table 7 reports the performance for the
first shared task (i.e,
without email
headers) while Table
Table 6:
Training and test times of our models.
Models
Training time
Test time
H-LSTMs+supervised
3.7 hours
4 minutes
H-LSTMs+headers+supervised
1.5 hours
1 minute
8 presents the performance for the second shared task (i.e,
with email
headers).
These performance is measured and
released by the organizers.
The performance of the systems
we submitted is shown in the rows with our team name (i.e,
TripleN ).
Table 7:
The best performance of
all
the partici-
pating teams in the first shared task with no email
headers.
Teams
Precision
Recall
F1
TripleN (our team)
0.981
0.978
0.979
Security-CEN@Amrita
0.962
0.989
0.975
Amrita-NLP
0.972
0.974
0.973
CEN-DeepSpam
0.951
0.964
0.958
CENSec@Amrita
0.914
0.998
0.954
CEN-SecureNLP
0.890
1.0
0.942
CEN-AISecurity
0.936
0.910
0.923
Crypt Coyotes
0.936
0.910
0.923
Table 8:
The best performance of
all
the partici-
pating teams in the second shared task with email
headers.
Teams
Precision
Recall
F1
Amrita-NLP
0.998
0.994
0.996
TripleN (our team)
0.990
0.992
0.991
CEN-DeepSpam
1.000
0.978
0.989
Security-CEN@Amrita
0.998
0.976
0.987
CENSec@Amrita
0.882
1.000
0.937
CEN-AISecurity
0.957
0.900
0.928
CEN-SecureNLP
0.880
0.971
0.924
Crypt Coyotes
0.960
0.863
0.909
As we can see from the tables, our systems achieve the best
performance for the first shared task and the second best
performance for the second shared task.
These results are
very promising and demonstrate the advantages of the pro-
posed methods in particular and deep learning in general for
the problem of email phishing recognition.
5.
CONCLUSIONS
We present a novel
deep learning model
to detect phishing
emails.
Our model
employs hierarchical
attentive LSTMs
to model
the email
bodies at both the word level
and the
sentence level.
A header network with attentive LSTMs is
also incorporated to model the headers of the emails.
In the
model, we propose a novel supervised attention technique to
improve the performance using the email frequency ranking
of
the words in the vocabulary.
Several
experiments are
conducted to demonstrate the benefits of the proposed deep
learning model.
6.
REFERENCES
[1]
How john podesta’s emails were hacked, 2016.
Retrieved May 03, 2018 from
6
https://www.forbes.com/sites/kevinmurnane/2016/10/21/how-
john-podestas-emails-were-hacked-and-how-to-prevent-
it-from-happening-to-you/.
[2]
2017 data breach report finds phishing, email attacks
still potent, 2017. Retrieved May 05, 2018 from
https://digitalguardian.com/blog/2017-data-breach-
report-finds-phishing-email-attacks-still-potent.
[3]
Phishing scams cost american businesses half a billion
dollars a year, 2017. Retrieved May 03, 2018 from
https://www.forbes.com/sites/leemathews/2017/05/05/phishing-
scams-cost-american-businesses-half-a-billion-dollars-a-
year/.
[4]
S. Abu-Nimeh, D. Nappa, X. Wang, and S. Nair. A
comparison of machine learning techniques for
phishing detection. In Proceedings of the anti-phishing
working groups 2nd annual
eCrime researchers
summit, pages 60–69. ACM, 2007.
[5]
D. Bahdanau, K. Cho, and Y. Bengio. Neural machine
translation by jointly learning to align and translate.
In arXiv preprint arXiv:1409.0473, 2014.
[6]
R. Basnet, S. Mukkamala, and A. H. Sung. Detection
of phishing attacks:
A machine learning approach. In
Soft Computing Applications in Industry, pages
373–383. Springer, 2008.
[7]
A. Bergholz, J. H. Chang, G. Paass, F. Reichartz, and
S. Strobel. Improved phishing detection using
model-based features. In CEAS, 2008.
[8]
M. Chandrasekaran, K. Narayanan, and
S. Upadhyaya. Phishing email detection based on
structural properties. In NYS Cyber Security
Conference, volume 3, 2006.
[9]
R. Dhamija, J. D. Tygar, and M. Hearst. Why
phishing works. In Proceedings of the SIGCHI
conference on Human Factors in computing systems,
pages 581–590. ACM, 2006.
[10]
A. Elaassal, A. Das, S. Baki, L. De Moraes, and
R. Verma. Iwspa-ap:
Anti-phising shared task at acm
international workshop on security and privacy
analytics. In Proceedings of the 1st IWSPA
Anti-Phishing Shared Task. CEUR, 2018.
[11]
I. Fette, N. Sadeh, and A. Tomasic. Learning to detect
phishing emails. pages 649–656. ACM, 2007.
[12]
X. Glorot, A. Bordes, and Y. Bengio. Domain
adaptation for large-scale sentiment classification:
A
deep learning approach. In Proceedings of the 28th
international
conference on machine learning
(ICML-11), pages 513–520, 2011.
[13]
A. Graves and J. Schmidhuber. Framewise phoneme
classification with bidirectional lstm and other neural
network architectures. Neural
Networks,
18(5-6):602–610, 2005.
[14]
B. Gupta, A. Tewari, A. K. Jain, and D. P. Agrawal.
Fighting against phishing attacks:
state of the art and
future challenges. Neural
Computing and Applications,
28(12):3629–3654, 2017.
[15]
I. R. A. Hamid and J. Abawajy. Hybrid feature
selection for phishing email detection. In International
Conference on Algorithms and Architectures for
Parallel
Processing, pages 266–275. Springer, 2011.
[16]
S. Hochreiter and J. Schmidhuber. Long short-term
memory. In Neural
Computation, 1997.
[17]
T. N. Jagatic, N. A. Johnson, M. Jakobsson, and
F. Menczer. Social phishing. Communications of the
ACM, 50(10):94–100, 2007.
[18]
D. P. Kingma and J. Ba. Adam:
A Method for
Stochastic Optimization, 2014.
[19]
S. Lai, L. Xu, K. Liu, and J. Zhao. Recurrent
convolutional neural networks for text classification. In
AAAI, volume 333, pages 2267–2273, 2015.
[20]
V. S. Lakshmi and M. Vijaya. Efficient prediction of
phishing websites using supervised learning
algorithms. Procedia Engineering, 30:798–805, 2012.
[21]
L. Liu, LemLiu, M. Utiyama, A. Finch, a. Sumita,
M. Utiyama, A. Finch, and E. Sumita. Neural
machine translation with supervised attention. arXiv
preprint arXiv:1609.04186, 2016.
[22]
S. Liu, Y. Chen, K. Liu, and J. Zhao. Exploiting
argument information to improve event detection via
supervised attention mechanisms. In Proceedings of
the 55th Annual
Meeting of the Association for
Computational
Linguistics (Volume 1:
Long Papers),
volume 1, pages 1789–1798, 2017.
[23]
A. Martin, N. Anutthamaa, M. Sathyavathy, M. M. S.
Francois, D. V. P. Venkatesan, et al. A framework for
predicting phishing websites using neural networks.
arXiv preprint arXiv:1109.1074, 2011.
[24]
H. Mi, Z. Wang, and A. Ittycheriah. Supervised
attentions for neural machine translation. arXiv
preprint arXiv:1608.00112, 2016.
[25]
T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and
J. Dean. Distributed representations of words and
phrases and their compositionality. In Advances in
neural
information processing systems, pages
3111–3119, 2013.
[26]
R. M. Mohammad, F. Thabtah, and L. McCluskey.
Predicting phishing websites based on self-structuring
neural network. Neural
Computing and Applications,
25(2):443–458, 2014.
[27]
T. H. Nguyen and R. Grishman. Event detection and
domain adaptation with convolutional neural
networks. In Proceedings of the 53rd Annual
Meeting
of the Association for Computational
Linguistics and
the 7th International
Joint Conference on Natural
Language Processing (Volume 2:
Short Papers),
volume 2, pages 365–371, 2015.
[28]
T. H. Nguyen and R. Grishman. Relation extraction:
Perspective from convolutional neural networks. In
Proceedings of the 1st Workshop on Vector Space
Modeling for Natural
Language Processing, pages
39–48, 2015.
[29]
T. H. Nguyen and R. Grishman. Modeling skip-grams
for event detection with convolutional neural networks.
In Proceedings of the 2016 Conference on Empirical
Methods in Natural
Language Processing, 2016.
[30]
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn:
Machine learning in
Python. Journal
of Machine Learning Research,
12:2825–2830, 2011.
[31]
R.
ˇ
Reh˚uˇrek and P. Sojka. Software Framework for
Topic Modelling with Large Corpora. In Proceedings of
the LREC 2010 Workshop on New Challenges for NLP
7
Frameworks, pages 45–50, Valletta, Malta, May 2010.
ELRA. http://is.muni.cz/publication/884893/en.
[32]
H. Siadati, T. Nguyen, P. Gupta, M. Jakobsson, and
N. Memon. Mind your smses:
Mitigating social
engineering in second factor authentication.
Computers & Security, 65:14–28, 2017.
[33]
H. Siadati, T. Nguyen, and N. Memon. Verification
code forwarding attack (short paper). In International
Conference on Passwords, pages 65–71. Springer, 2015.
[34]
H. Siadati, T. Nguyen, and N. Memon. X-platform
phishing:
Abusing trust for targeted attacks short
paper. In International
Conference on Financial
Cryptography and Data Security, pages 587–596.
Springer, 2017.
[35]
D. Singer. Identification of spoofed email, Aug. 25
2005. US Patent App. 10/754,220.
[36]
N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever,
R. Salakhutdinov, and Y. Bengio. Dropout:
A simple
way to prevent neural
networks from overfitting, 2014.
[37]
Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and
E. Hovy. Hierarchical attention networks for document
classification. In Proceedings of the 2016 Conference of
the North American Chapter of the Association for
Computational
Linguistics:
Human Language
Technologies, pages 1480–1489, 2016.
[38]
N. Zhang and Y. Yuan. Phishing detection using
neural network. CS229 lecture notes, 2012.
8
