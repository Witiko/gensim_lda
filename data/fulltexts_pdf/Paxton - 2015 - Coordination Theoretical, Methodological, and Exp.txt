UC Merced
UC Merced Electronic Theses and Dissertations
Title
Coordination: Theoretical, Methodological, and Experimental Perspectives
Permalink
https://escholarship.org/uc/item/5tx5s7zh
Author
Paxton, Alexandra
Publication Date
2015-01-01
Peer reviewed|Thesis/dissertation
eScholarship.org
Powered by the California Digital Library
University of California
UNIVERSITY OF CALIFORNIA, MERCED
Coordination:
Theoretical, Methodological, and Experimental
Perspectives
A dissertation submitted in partial satisfaction of the requirements
for the degree Doctor of Philosophy
in
Cognitive and Information Sciences
by
Alexandra Erin Paxton
Committee in charge:
Professor Rick Dale, Chair
Professor Teenie Matlock
Professor Jeff Yoshimi
2015
Chapter 3
c
2015 Psychonomic Society, Inc.(with permission of Springer)
All other chapters
c
2015 Alexandra Erin Paxton
All rights reserved
The dissertation of Alexandra Erin Paxton is approved, and it is
acceptable
in quality and form for publication on microfilm and electronically:
Professor Rick Dale, Chair
Professor Teenie Matlock
Professor Jeffrey Yoshimi
University of California, Merced
2015
iii
This dissertation is dedicated to the family and friends
whose constant love and support got me through this with my sanity:
to my incredible husband, Dale Paxton,
who has been a better partner on this road
than I could have ever imagined;
to my friends,
who offered encouragement, perspective,
open tables, and amazing company;
and to my family,
who sparked a lifelong passion for knowledge
and cheered me on even from half a world away.
iv
Contents
List of Figures
viii
List of Tables
x
Acknowledgements
xi
Curriculum Vita
xii
Abstract
xxiii
1
Introduction
1
1.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1
1.2
Interpersonal Coordination
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1
1.2.1
Theoretical Perspectives .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
1
1.2.2
Methodology
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
2
1.2.3
Experimental Investigations .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
3
1.3
Motivation and Previous Work
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
3
1.4
The Present Work
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
4
2
A data–driven approach to disambiguating the terminology of
inter-
personal similarity
5
2.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
5
2.1.1
Accommodation
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
6
2.1.2
Adaptation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
6
2.1.3
Alignment .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7
2.1.4
Chameleon Effect or Mimicry .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7
2.1.5
Contagion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
8
2.1.6
Mirroring and the Mirror Neuron System .
.
.
.
.
.
.
.
.
.
.
.
.
9
2.1.7
Synergy or Coordinative Structure
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
2.1.8
Synchrony .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
2.1.9
The Present Study .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
2.2
Materials
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11
2.2.1
Corpus Creation and Preparation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
11
2.2.2
Analyses .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
12
2.3
Results .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
13
2.3.1
Keyword Analysis with LSA
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
13
2.3.2
Abstract Analysis with LDA .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
2.3.3
Abstract Analysis with LSA .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
2.3.4
Abstract Analysis with Deep Learning .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
2.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
v
2.4.1
Specialization:
Research Questions, not Terms
.
.
.
.
.
.
.
.
.
.
20
2.4.2
Broad Usage:
Coordination .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
2.4.3
Limitations and Future Directions
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
21
2.4.4
Conclusion
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
3
PsyGlass:
Capitalizing on Google Glass for naturalistic data collection 24
3.1
Research opportunities for wearable technologies
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.1.1
Previous research with wearable technology .
.
.
.
.
.
.
.
.
.
.
.
26
3.1.2
Existing work utilizing Google Glass
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.2
PsyGlass:
A framework for Glass in behavioral research
.
.
.
.
.
.
.
.
.
27
3.2.1
PsyGlass experimenter console
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
27
3.2.2
PsyGlass Glassware
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.2.3
Potential applications for PsyGlass .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
29
3.3
Example PsyGlass application:
Convergence during interaction .
.
.
.
.
30
3.3.1
Method
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
3.3.2
Results
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
3.3.3
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
3.4
Using PsyGlass:
Recommendations and limitations .
.
.
.
.
.
.
.
.
.
.
.
33
3.5
General discussion
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
35
3.5.1
Update regarding purchasing Google Glass
.
.
.
.
.
.
.
.
.
.
.
.
35
3.5.2
Future directions for PsyGlass and wearable technology
.
.
.
.
.
35
3.6
Author note .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
3.7
Appendix
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
36
3.7.1
Accessing PsyGlass Glassware (see Fig.
3.5) .
.
.
.
.
.
.
.
.
.
.
.
36
3.7.2
PsyGlass Glassware data collection flow (see Fig.
3.6)
.
.
.
.
.
.
36
4
Context–dependent gaze coordination
40
4.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
40
4.1.1
Interpersonal Coordination, Rapport, and Comprehension .
.
.
.
40
4.1.2
Conflict and Coordination .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
4.1.3
The Present Study .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
4.2
Method
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
4.2.1
Participants .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
4.2.2
Materials and Procedure .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
4.2.3
Analyses .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45
4.2.4
Data Preparation .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
4.3
Results .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
4.3.1
General Patterns
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
4.3.2
Planned Analyses .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
47
4.3.3
Exploratory Analyses
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
49
4.4
Discussion .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
4.4.1
Coordination in Conflict .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
4.4.2
Understanding Gaze Coordination
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
50
4.4.3
Limitations and Future Directions
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
51
4.4.4
Conclusion
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
4.5
Acknowledgements
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
52
5
Discussion
53
5.1
Introduction .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
53
5.2
Data–Driven Explorations of Terminology .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
53
5.3
Developing and Deploying Methods .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
54
5.4
Building Theory through Experiments
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
5.5
Conclusion
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
55
vi
References
57
vii
List of Figures
2.1
Network of
top author-generated keywords in corpus.
Each node is a
single keyword,
and connections are determined by the cosine similarity
scores (in the 300-dimension keyword LSA space) between two nodes.
Multi-word keywords are graphed with an underscore between each word.
Keywords with red nodes are (unigram) key terms under consideration in
this paper.
Connections are drawn according to strength (see legend).
.
14
2.2
Projection of multidimensional LDA topic distribution onto two-dimensional
space.
The top 10 lexical items in each topic may be found in Table 2.1
under the appropriately numbered topic.
This visualization was created
in R (R Development Core Team,
2008) with LDAvis package (Sievert
& Shirley, 2014), using an LDA model implemented in the topicmodels
package (Gr¨
un & Hornik, 2011).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16
2.3
Network of LSA-identified relations across key terms in abstract corpus.
Each node is a single term from a key term group,
and connections are
determined by the cosine similarity scores (in the 300-dimension abstract
LSA space) between two nodes.
Connections are drawn according to
strength (see legend). .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
2.4
Distribution of neighborhood densities of each group of terms generated
by LSA and deep learning (DL) methods.
Term groups (on y-axis) are
presented as stems,
and the strength of
the relationship between its 20
nearest neighbors are charted along the x -axis.
Neighborhoods generated
by LSA (in green) and DL (in yellow) are presented side-by-side for each
group.
Lines inside each “violin” are a single cosine value within the
20 nearest neighbors from each method.
Created in Python with the
seaborn package (Waskom et al., 2015).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
3.1
Photo of Google Glass (Google, Inc.:
www.google.com/glass ) .
.
.
.
.
.
25
3.2
PsyGlass framework flow and the programming and/or markup languages
of each component (listed in parentheses).
In the experimenter console’s
current form,
the researcher can use it to update visual
displays on one
or more connected Glass devices while collecting accelerometer data from
each
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.3
PsyGlass experimenter console.
From here, the experimenter can manage
the connection between the connected Google Glass device(s) and the
server,
initiate data collection sessions,
and update the Glass screen(s)
with text and/or color
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
29
viii
3.4
Interaction plot of
the linear mixed-effects model
for our sample appli-
cation,
predicting interpersonal
synchrony (r :
y -axis) as a function of
condition (blue = noise,
orange = dual
task) across lags of ± 2,000 ms
(x -axis).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
33
3.5
PsyGlass Glassware flow for navigating to the data collection study (“Main
Activity”).
The Main Activity can be accessed in two ways:
navigating
with the touchpad (Path A) or through voice commands (Path B).
.
.
.
38
3.6
PsyGlass Glassware flow for initializing and terminating data collection
(left;
“Game Activity”) and for uploading the session data to the server
(right; “Settings Activity” leading to “Upload Activity”).
.
.
.
.
.
.
.
.
39
4.1
Gaze coordination by lag and opinion congruence between speakers and
listeners.
Shaded bars indicate standard error.
Second-order polynomials
are fitted (in black) over each group.
Negative lag indicates a listener-
leading trend in gaze patterns;
positive lag indicates a speaker-leading
trend.
Plot
generated in R (R Development
Core Team,
2008)
with
ggplot2 (Wickham, 2009).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48
ix
List of Tables
2.1
Top 10 words included in each topic from LDA analysis over abstracts,
ranked descending by weight.
Each topic’s model-over-model stability—
as a percentage of
10 runs—is included in parentheses under its name.
Topic labels included in quotations under model-over-model stability. .
.
23
4.1
Summary of
total
speaker data.
Breakdown of
percentage of
speakers
(with n in parentheses) in each opinion of each topic, along with whether
speakers showed a majority of one opinion on a topic (“dominant-view”)
or whether speakers’ opinions were relatively equally divided between the
two (“mixed-view”).
Asterisk indicates majority opinion in “dominant”
topics.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
x
Acknowledgements
I would first like to thank my dedicated committee members—Rick Dale, Teenie
Matlock, and Jeff Yoshimi—for their continued support during my graduate career.
Each
encouraged my growth not only as an independent researcher but also as a contributing
member of a vibrant research community.
Thanks (first and foremost) to Rick Dale for unparalleled support as my aca-
demic advisor and mentor.
Thank you for helping me find my love of research and for
encouraging me follow it down this unexpected path.
Thanks for encouraging me to
pursue wildly interdisciplinary questions and multimodal tools to forge my own path—
while emphasizing the highly collaborative spirit of
modern science.
Thanks for your
constant enthusiasm and constructive guidance through all of it.
Thanks to Teenie Matlock for reminding me to keep an eye toward the deeper
meaning of
language and for inspiring in me a dedication to cultivate a diverse but
unified community wherever I am.
Thanks to Jeff Yoshimi
for pushing me to consider
the broader implications of
my work and for giving me a profound appreciation for
philosophy’s role in cognitive science.
Thanks to both of you for your honesty, positivity,
and advice, both as committee members and mentors.
I’d also like to thank all
of the other members (past and present) of the UC
Merced Cognitive and Information Sciences group who have helped create a truly out-
standing intellectual
community.
From undergraduate research assistants to graduate
students to faculty members, this community challenges its members to grow and sup-
ports us as we do.
It has been a joy to be part of it.
Finally,
I
would like to thank the University of
California,
Merced and its
Cognitive and Information Sciences group for their support—including generous finan-
cial
support—over the course of
my graduate career here.
I would also like to thank
the UC Merced Graduate Division for financial
support through the Graduate Dean’s
Dissertation Fellowship (AY 2015-2016).
- - -
The text of Chapter 2 of this dissertation will be submitted for publication with
co-author Rick Dale.
The text of Chapter 3 is a reprint (with permission of Springer) of
the article “PsyGlass:
Capitalizing on Google Glass for Naturalistic Data Collection” as
it appeared in Behavior Research Methods, which was co-authored by Kevin Rodriguez
and Rick Dale.
The text of Chapter 4 will be submitted for publication with co-authors
Rick Dale and Daniel C. Richardson.
xi
Curriculum Vita
Alexandra E. Paxton
(N
´
ee Loan)
paxton.alexandra@gmail.com
http://www.alexandrapaxton.com
Education
2011–2015
PhD in Cognitive and Information Sciences
University of California, Merced
2010–2011
Graduate Studies
University of Memphis (Memphis, TN)
2009
BA, summa cum laude, Psychology and English (minor:
Spanish)
With Distinction from the Harding University Honors College
Harding University (Searcy, AR)
Peer-Reviewed Journal Articles
Mentees’ names underlined.
Main, A., Paxton, A., & Dale, R. (under review).
An exploratory analysis of dynamic
emotion regulation between mothers and adolescents during conflict discussions.
Abney, D., Paxton, A., Dale, R., & Kello, C. (in press).
Movement dynamics reflect a
functional role for weak coupling and role structure in dyadic problem solving.
Cognitive Processing.
Paxton, A., Rodriguez, K., & Dale, R. (2015).
PsyGlass:
Capitalizing on Google Glass
for naturalistic data collection.
Behavior Research Methods, 47 (3), 608-619.
Fusaroli,
R.,
Perlman,
M.,
Mislove,
A.,
Paxton,
A.,
Matlock,
T.,
& Dale,
R.
(2015).
Timescales of massive human entrainment.
PLOS ONE, 10 (4), e0122742.
xii
Abney, D., Paxton, A., Kello, C., & Dale, R. (2014).
Complexity matching in dyadic
interaction.
Journal
of Experimental
Psychology:
General, 143 (6), 2304-2315.
Paxton, A., & Dale, R. (2013).
Argument disrupts interpersonal synchrony.
Quarterly
Journal
of Experimental
Psychology, 66 (11), 2092-2102.
Paxton, A., & Dale, R. (2013).
Frame-differencing methods for measuring bodily syn-
chrony in conversation.
Behavior Research Methods, 45 (2), 329-343.
Tollefsen,
D.,
Dale,
R.,
& Paxton,
A.
(2013).
Alignment,
transactive memory,
and
collective cognitive systems.
Review of Philosophy and Psychology, 4 (1), 49-64.
Refereed Conference Proceedings
Paxton,
A.,
Roche,
J.,
& Tanenhaus,
M.
(2015).
Communicative efficiency and mis-
communication:
The costs and benefits of variable language production.
In D.
C. Noelle, R. Dale, A. S. Warlaumont, J. Yoshimi, T. Matlock, C. D. Jennings,
& P. P. Maglio (Eds.), Proceedings of the 37
th
Annual
Meeting of the Cognitive
Science Society.
Austin, TX: Cognitive Science Society.
Paxton,
A.,
& Dale,
R.
(2014).
Leveraging linguistic content and debater traits to
predict debate outcomes.
In P. M. Bello, M. Guarini, M. McShane, & B. Scas-
sellati (Eds.), Proceedings of the 36
th
Annual
Meeting of the Cognitive Science
Society.
Austin, TX: Cognitive Science Society.
Paxton,
A.,
Abney,
D,
Kello,
C.
T.,
& Dale,
R.
(2014).
Network analysis of
multi-
modal,
multiscale coordination in dyadic problem solving.
In P.
M.
Bello,
M.
Guarini,
M.
McShane,
& B.
Scassellati
(Eds.),
Proceedings of the 36
th
Annual
Meeting of the Cognitive Science Society.
Austin, TX: Cognitive Science Society.
Paxton,
A.,
Roche,
J.
M.,
Ibarra,
A.,
& Tanenhaus,
M.
K.
(2014).
Failure to (mis)–
communicate:
Linguistic convergence,
lexical
choice,
and communicative suc-
cess in dyadic problem solving.
In P.
M.
Bello,
M.
Guarini,
M.
McShane,
&
B.
Scassellati
(Eds.),
Proceedings of
the 36
th
Annual
Meeting of
the Cognitive
Science Society.
Austin, TX: Cognitive Science Society.
Paxton, A., & Dale, R. (2013).
Multimodal networks of interpersonal interaction and
conversational contexts.
In M. Knauff, M. Pauen, N. Sebanz, & I. Wachsmuth
(Eds.), Proceedings of the 35
th
Annual Meeting of the Cognitive Science Society.
Austin, TX: Cognitive Science Society.
Roche, J., Paxton, A., Ibarra, A., & Tanenhaus, M. (2013).
From minor mishap to ma-
jor catastrophe:
Lexical choice in miscommunication.
In M. Knauff, M. Pauen,
N. Sebanz, & I. Wachsmuth (Eds.), Proceedings of the 35
th
Annual
Meeting of
the Cognitive Science Society.
Austin, TX: Cognitive Science Society.
xiii
Drew,
A.
H.,
Paxton,
A.,
Kello,
C.,
& Dale,
R.
(2013).
Complexity matching in
dyadic interactions.
In P.
Passos,
J.
Barrieros,
R.
Cordovil,
D.
Ara´
ujo,
& F.
Melo (Eds.),
Studies in Perception and Action XII:
Proceedings from the Sev-
enteenth International
Conference on Perception and Action.
Technical Reports and Other Publications
Paxton,
A.,
Dale,
R.,
& Richardson,
D.
C.
(in press).
Social
coordination of
verbal
and nonverbal behaviors.
In P. Passos, K. Davids, and C. Jia Yi (Eds.), Inter-
personal
coordination and performance in social
systems.
Routledge.
Fusaroli,
R.,
Perlman,
M.,
Mislove,
A.,
Paxton,
A.,
Matlock,
T.,
& Dale,
R.
(2014).
Timescales of massive human entrainment.
arXiv:1410.8105 [physics.soc-ph].
Paxton,
A.,
& Dale,
R.
(2013).
B(eo)W(u)LF:
Facilitating recurrence analysis on
multi-level
language.
arXiv:1308.2696 [cs.CL].
Conference Presentations
Asterisk denotes presenter, if not presented by first author.
Mentees’ names underlined.
Paxton, A., & Dale, R. (2015, November).
Data–driven theory:
Using NLP and deep
learning in metascientific analyses.
Paper presented at the 45
th
Annual Meet-
ing of the Society for Computers in Psychology.
Chicago, IL.
Duran, N., Fusaroli, R., & Paxton, A. (2015, November).
Assessing lexical, syntactic,
and conceptual
turn-by-turn alignment in conversations involving conflict and
deception.
Paper presented at the 45
th
Annual Meeting of the Society for Com-
puters in Psychology.
Chicago, IL.
Main,
A.,
Dale,
R.,
& Paxton,
A. (2015,
July).
An exploratory analysis of
dynamic
emotional
communication between parents and adolescents during conflict dis-
cussions.
Paper presented at the meeting of the International
Society for Re-
search on Emotion.
Paxton,
A.,
& Dale,
R.
(2015,
May).
Adaptive interpersonal
dynamics in commu-
nication.
Paper presented at the 27
th
Annual
Meeting of
the Association for
Psychological Sciences.
New York, NY.
Fusaroli,
R.,
Perlman,
M.,
Mislove,
A.,
Paxton,
A.,
Matlock,
T.,
& Dale,
R.
(2015,
May).
Timescales of massive human entrainment.
Paper presented at the In-
ternational Conference of Computational Social Science.
Helsinki, Finland.
Rodriguez,
K.,
Paxton,
A.,* & Dale,
R.
(2014,
November).
Cutting the cord:
Capi-
talizing on Google Glass for naturalistic interaction research.
Paper presented
xiv
at the 44
th
Annual Meeting of the Society for Computers in Psychology.
Long
Beach, CA.
Paxton, A., & Dale, R.* (2014, November).
The effects of low-level
distractors on the
dynamics of conversation.
Paper presented at the 55
th
Annual Meeting of the
Psychonomic Society.
Long Beach, CA.
Paxton,
A.,
Roche,
J.
M.,
Ibarra,
A.,
& Tanenhaus,
M.
K.
(2014,
July).
Failure to
(mis)–communicate:
Linguistic convergence, lexical
choice, and communicative
success in dyadic problem solving.
Paper presented at the 36
th
Annual Meeting
of the Cognitive Science Society.
Quebec City, Canada.
Lichtenstein, P., Paxton, A.,* & Dale, R. (2014, July).
Hand–to–hand conflict and con-
sensus:
Gestural
alignment
in argumentative versus affiliative conversations.
Paper presented at the 6
th
meeting of
the International
Society for Gesture
Studies.
San Diego, CA.
Paxton, A., & Dale, R. (2013, November).
Keeping time:
Dynamics in text analysis.
Paper presented at the 43rd annual
meeting of
the Society for Computers in
Psychology.
Toronto, Canada.
Paxton, A., & Dale, R. (2013, August).
B(eo)W(u)LF: Facilitating multi-level
recur-
rence analysis in language.
Paper presented at the 5
th
Recurrence Plot Sympo-
sium, Chicago, IL.
Paxton, A., & Dale, R. (2013, July).
Multimodal networks of interpersonal interaction
and conversational
context.
Paper presented at the 35
th
annual meeting of the
Cognitive Science Society.
Berlin, Germany.
Dale,
R.,
Paxton,
A.,
& Duran,
N.
(2013,
May).
How interactive goals shape the co-
ordination of body and speech during conversation.
Paper presented at the 25
th
annual meeting of the Association for Psychological Science.
Washington, DC.
Paxton, A., & Dale, R. (2012, November).
Linguistic alignment in debate.
Paper pre-
sented at the 42nd annual meeting of the Society for Computers in Psychology.
Minneapolis, MN.
Dale,
R.,
& Paxton,
A. (2012,
August).
Eigendialog:
Bernstein’s problem in human
interaction.
Paper presented at the Guy Van Orden Workshop on Cognition
and Dynamics.
University of Connecticut, Storrs, CT.
Loan,
A.
(2009).
Respondent
residency and survey prompt
on community’s percep-
tion.
Paper presented at the annual Arkansas Student Psychology Symposium.
Siloam Springs, AR.
Loan,
A.
(2008).
Ethnicity of
respondent
and image on perception of
adolescent’s
self–esteem.
Paper presented at the annual Arkansas Student Psychology Sym-
posium.
Jonesboro, AR.
xv
Refereed Posters
Asterisk denotes presenter, if not presented by first author.
Paxton,
A.,* Roche,
J.,* & Tanenhaus,
M.
(2015,
July).
Communicative efficiency
and miscommunication:
The costs and benefits of variable language production.
Poster presented at the 36
th
Annual Meeting of the Cognitive Science Society,
Quebec City, Canada.
Paxton,
A.,
& Dale,
R.
(2014,
July).
Leveraging linguistic content and debater traits
to predict debate outcomes.
Poster presented at the 36
th
Annual Meeting of the
Cognitive Science Society, Quebec City, Canada.
Paxton,
A.,
Abney,
D.
H.,
Kello,
C.
T.,
& Dale,
R.
(2014,
July).
Network analysis
of
multimodal,
multiscale coordination in dyadic problem solving.
Poster pre-
sented at the 36
th
Annual
Meeting of
the Cognitive Science Society,
Quebec
City, Canada.
Abney, D. H., Paxton, A., Kello, C. K., & Dale, R. (2014).
Multimodal
and multiscale
interpersonal interaction in a joint problem solving task.
Poster presented at the
26
th
Annual Meeting of the American Psychological Society, San Francisco, CA.
Roche,
J.,
Paxton,
A.,* Ibarra,
A.,
& Tanenhaus,
M.
(2013,
August).
From minor
mishap to major catastrophe:
Lexical
choice in miscommunication.
Poster pre-
sented at the 35
th
annual
meeting of
the Cognitive Science Society.
Berlin,
Germany.
Paxton,
A.,
& Dale,
R. (2013,
May).
Breakdown:
Conflict’s fundamental
reorganiza-
tion of coordinated systems.
Poster presented at the 25
th
annual meeting of the
Association for Psychological Science, Washington, DC.
Paxton,
A.,
& Dale,
R.
(2012,
November).
Integrating body and speech in conversa-
tional contexts.
Poster presented at the 53rd annual meeting of the Psychonomic
Society, Minneapolis, MN.
Paxton, A., & Dale, R. (2011, November).
Alignment and argument.
Poster presented
at the 52nd annual meeting of the Psychonomic Society, Seattle, WA.
Paxton, A., & Dale, R. (2011, November).
Multimodal
synchrony:
Tracking body and
voice in an affordable behavioral
recording setup.
Poster presented at the 41
st
annual meeting of the Society for Computers in Psychology, Seattle, WA.
xvi
Open–Submission Posters
Asterisk denotes presenter, if not presented by first author.
Abney, D.H., Paxton, A., Kello, C.T., & Dale, R. (2013, August).
Complexity match-
ing in dyadic interaction.
Poster presented at the 35
th
annual
meeting of the
Cognitive Science Society, Berlin, Germany.
Loan,
A.,
& Dale,
R.
(2011,
June).
Coordinating arguments:
Embodied synchrony
in argumentative and affiliative interactions.
Poster presented at the American
Psychological Association’s Advanced Training Institute for Nonlinear Methods,
Cincinnati, OH.
Loan,
A.,
Cossel,
T.
K.,
Tillery,
R.,
Schoffstall,
C.
L.,
& Cohen,
R.
(2010,
October).
Who’s online? Boys’ and girls’ computer use.
Poster presented at the annual
meeting of the Tennessee Psychological Association, Nashville, TN.
Invited Talks and Lectures
Paxton,
A.
(2015,
October).
Interpersonal
dynamics:
Exploring conversation as a
dynamical
system.
Cognitive Science Colloquium,
Department of
Psychology,
University of Memphis, Memphis, TN.
Paxton,
A.
(2015,
May).
Scales of
influence:
How conflict
changes bodies,
voices,
and minds.
Computational
Cognitive Science Lab,
University of
California,
Berkeley, Berkeley, CA.
Paxton, A. (2015, April).
Conversation:
Complex system, complex signals.
Cognitive
Science Brown Bag, Department of Psychological Sciences, Kent State Univer-
sity, Kent, OH.
Paxton, A. (2015, April).
PsyGlass:
Using Google Glass to quantify conversation and
interaction.
College of
Education,
Health,
and Human Services,
Kent State
University, Kent, OH.
Paxton, A. (2015, February).
Conflict:
An exploration of context-dependent behavioral
coordination.
Department of Psychology Colloquium,
University of California,
Santa Cruz.
Santa Cruz, CA.
Paxton,
A.
(2014,
September).
Here for an argument:
Conflict
in laboratory and
real–world settings.
CogNetwork Meeting,
University of
California,
Berkeley.
Berkeley, CA.
Paxton,
A. (2013, November).
Exploring interaction through conflict.
Department of
Psychology, University of Rochester.
Rochester, NY.
Paxton,
A. (2013,
November).
Conflict as joint action.
Lecture for BCS 310 (Senior
Seminar:
Joint Action), University of Rochester.
Rochester, NY.
Workshops
Paxton,
A.
(2013,
November).
An introduction to cross-correlation.
Workshop for
Department of Psychology, University of Rochester, Rochester, NY.
xvii
Local Presentations
Asterisk denotes presenter, if not presented by first author.
Mentees’ names underlined.
Oakes, B.,* Patel, P.,* Paxton, A., & Dale, R. (2015, March).
Influence of visual cues
in language production.
Poster presented at the 8
th
annual
Research Week,
University of California, Merced, CA.
Carey, K.,* Willson, K.,* Paxton, A., & Dale, R. (2015, March).
Kinesics of common
conversations.
Poster presented at the 8
th
annual Research Week, University of
California, Merced, CA.
Paxton,
A.,
& Dale,
R.
(2013,
March).
Contextual
effects on speech and movement
patterns in conversation.
Poster presented at the 6
th
annual
Research Week,
University of California, Merced, CA.
Loan, A. (2008).
“But words can never hurt me”:
The psychological
role of Nadsat in
A Clockwork Orange.
Honors thesis presented and defended,
English Depart-
ment, Harding University, Searcy, AR.
Funding and Awards
2015
Cognitive and Information Sciences Research Award ($900)
University of California, Merced
2015
Cognitive and Information Sciences Travel Award ($800)
University of California, Merced
2015
Cognitive and Information Sciences Summer Fellowship ($2,250)
University of California, Merced
2014
Cognitive and Information Sciences Travel Fellowship ($1,050)
University of California, Merced
2014
Cognitive and Information Sciences Summer Fellowship ($3,800)
University of California, Merced
2013
Cognitive and Information Sciences Graduate Award ($1,180)
University of California, Merced
2013
Psychonomic Society Travel and Networking Award ($1,000)
Women in Cognitive Science
2013
Center for Humanities Individual Research Grant ($2,000)
University of California, Merced
2013
Cognitive Science Society Student Travel Grant ($599)
Robert J. Glushko and Pamela Samuelson Foundation
2013
Student Caucus Travel Assistance Award ($200)
Association for Psychological Science
2013
Cognitive and Information Sciences Summer Workshop Fellowship ($750)
University of California, Merced
2013
Cognitive and Information Sciences Travel Fellowship ($2,000)
University of California, Merced
2013
Cognitive and Information Sciences Summer Fellowship ($2,500)
University of California, Merced
2013
Graduate Student Nominee, Outstanding Woman of UC Merced
University of California, Merced
xviii
2012
John Castellan Award for Best Student Paper
Society for Computers in Psychology
2012
Summer Training Scholarship ($1,200)
University of California, Merced
2012
Graduate Division General Fellowship ($3,885)
University of California, Merced
2011
Graduate Student Coordinating Committee Travel Award
University of Memphis ($400)
2009
Who’s Who Among Students in American Universities and Colleges
2009
Outstanding Research Award for the Behavioral Sciences Department
Harding University
2005–2009
Dean’s List
Harding University
2005–2009
Arkansas Distinguished Governor’s Scholar ($40,000)
2005–2009
Full Tuition National Merit Scholarship
Harding University
2005
National Merit Scholar
Professional Affiliations
2015–present
Psychonomic Society (Student Member)
2013–present
Women in Cognitive Science
2013–present
Cognitive Science Society (Graduate Student Member)
2012–present
Association for Psychological Science (Graduate Student Affiliate)
2011–present
Society for Computers in Psychology
2007–present
Psi Chi
2011, 2013
American Psychological Association (Graduate Student Affiliate)
2008-2009
Alpha Chi Honor Society
2007-2009
Sigma Tau Delta
2005-2006
Phi Eta Sigma
2005-2009
American Studies Institute
Teaching Experience
Instructor of Record
Summer 2015
Research Methods (COGS 105)
University of California, Merced (Merced, CA)
Teaching Assistant
Spring 2015
Research Methods (COGS 105)
Instructor of Record:
Dr.
Rick Dale
xix
University of California, Merced (Merced, CA)
Fall 2014
Modern Everyday Cognition (COGS 127)
Instructor of Record:
Dr.
Rick Dale
University of California, Merced (Merced, CA)
Spring 2014
Complex Adaptive Systems (COGS 180)
Instructor of Record:
Dr.
Michael Spivey
University of California, Merced (Merced, CA)
Fall 2013
Introduction to Philosophy (PHIL 001)
Instructor of Record:
Dr.
Rolf Johansson
University of California, Merced (Merced, CA)
Spring 2013
Cognitive Neuroscience (COGS 130)
Instructor of Record:
Dr.
Anne Warlaumont
University of California, Merced (Merced, CA)
Fall 2012
Judgment & Decision Making (COGS/ECON/MGMT/POLI 153)
Instructor of Record:
Dr.
Evan Heit
University of California, Merced (Merced, CA)
Fall 2011
Philosophy of Cognitive Science (COGS/PHIL 110)
Instructor of Record:
Dr.
Jeff Yoshimi
University of California, Merced (Merced, CA)
Fall 2010
Child Psychology (PSYC 3103)
Instructor of Record:
Dr.
Theresa Okwumabua
University of Memphis (Memphis, TN)
Fall 2008
Departmental Teaching Assistant
Psychology Department
Harding University (Searcy, AR)
Additional Related Work
2008–2009
University Tutor
Academic Resource Center
Harding University (Searcy, AR)
Paid Research Experience
December 2014–January 2015
Graduate Research Assistant
Dr.
Rick Dale
University of California, Merced (Merced, CA)
May–August 2013
Graduate Research Assistant
Dr.
Rick Dale
University of California, Merced (Merced, CA)
December 2012–January 2013
Graduate Research Assistant
Dr.
Rick Dale
University of California, Merced (Merced, CA)
January–August 2012
Graduate Research Assistant
Dr.
Rick Dale
xx
University of California, Merced (Merced, CA)
January–August 2011
Graduate Research Assistant
Dr.
Rick Dale
University of California, Merced (Merced, CA)
Professional Service
2013–2015
Subject pool coordinator and SONA Systems administrator
University of California, Merced (Merced, CA)
2013–2015
Member of Institutional Review Board
University of California, Merced (Merced, CA)
2015
Reviewer:
Behavior Research Methods;
Cognitive Processing;
Journal
of
Nonverbal
Behavior; PLOS ONE
2015
Volunteer at the 37
th
annual meeting of the Cognitive Science Society
2015
Founder, Graduate Student Writing Club
University of California, Merced (Merced, CA)
2014
Reviewer:
Cognitive Science; PLOS ONE ; Behavior Research Methods
2014
Volunteer
at
the 44
th
annual
meeting of
the Society for
Computers
in
Psychology
2013
Ad hoc reviewer:
Applied Psychophysiology and Biofeedback ;
Behavior
Research Methods;
Current Biology;
Journal
of
Experimental
Psychology:
General
2013
Volunteer at the 25
th
annual
meeting of the Association for Psychological
Science
2013
Reviewer:
Association for Psychological Science Student Caucus’s Student
Research Award
2012
Volunteer at the 42nd annual
meeting of
the Society for Computers in
Psychology
2012
Ad hoc reviewer:
Speech Communication
2012
Co-organizer for the Cognitive and Information Sciences Graduate Student
and Faculty Meeting seminar series
University of California, Merced (Merced, CA)
2011
Secretary for the Graduate Student Coordinating Committee
University of Memphis (Memphis, TN)
2010–2011
Subject pool coordinator and SONA systems administrator
University of Memphis (Memphis, TN)
2006–2009
Member of Academic Integrity Committee for revising academic standards
Harding University (Searcy, AR)
2007
Statistics lab proctor
Harding University (Searcy, AR)
xxi
Training and Unpaid Research Experience
2014
Dan Mirman’s Introduction to Growth Curve Modeling Workshop (36
th
Annual Meeting of the Cognitive Science Society, Quebec City, Canada)
2013
American Psychological Association’s Advanced Training Institute for Ex-
ploratory Data Mining in Behavioral Research (Davis, CA)
2012
Office of Research Development Services Workshop Series on Writing Com-
petitive Research Proposals (University of California, Merced)
2012
Guy
Van
Orden
Workshop
on
Cognitive
Dynamics
(University
of
Connecticut)
2012
Sixth Annual
Empirical
Methods
for
Cognitive
Linguistics
Workshop
(EMCL 6)
2011
American Psychological Association’s Advanced Training Institute for Non-
linear Methods (Cincinnati, OH)
2011
Statistical programming seminar (University of Memphis)
2008
Designed an online developmental psychology course and associated mate-
rials with Dr.
Glen Adams (Harding University)
Mentoring and Diversity
2013–present
Graduate student mentor in Peer Mentor Program (University of California,
Merced)
2015
Mentees K.
Carey and K.
Willson:
Winners of 8
th
annual
Research Week
Undergraduate Poster Competition (University of California, Merced)
2012–2013
Member of
Board of
Directors for Merced RRDG,
a 501(c)(3) nonprofit
organization dedicated to promoting athleticism and health behaviors in
women and children
2008, 2010, 2011
Volunteer counselor at Camp Concern, a summer camp for urban youth in
Pittsburgh, PA
2008–2009
Circle K International
Press
September 2013
Grad research at CogSci ’13.
CogSci @ UC Merced.
March 2012
A student of synchrony.
gradPSYCH Magazine.
March 2012
Cognitive science student studies conflict.
University News.
March 2012
UC Merced Connect:
Student
studying subconscious
synchronization.
Merced Sun-Star.
xxii
Abstract
Interpersonal coordination broadly captures the ways in which interacting in-
dividuals become more similar over time in their behavior,
cognition,
and affect over
time.
The research area around interpersonal
coordination is poised to yield unique
insights into questions of human communication, interaction, and social behavior.
As a
field, interpersonal coordination still has immense room to grow—providing an exciting
challenge to interdisciplinary researchers.
Interpersonal coordination has enjoyed an ex-
plosion of interest in recent years,
making these challenges even more urgent.
Here,
in
collaboration with various coauthors, I present three projects that address some of the
key theoretical, methodological, and experimental issues facing the research area today.
First,
I present a data-driven exploration of the terminology surrounding in-
terpersonal coordination (Paxton & Dale, in preparation).
From alignment to synergy,
there are handfuls of terms that are used to describe this social phenomenon, with little
to no agreement across the field on their relation to one another.
Using scientometric
and corpus analysis tools,
the first project analyzes a corpus of thousands of abstracts
on related research to shed some light on the implicit structure in the data.
Next, I introduce PsyGlass, an open-source application that turns Google Glass
into a tool for naturalistic data collection (Paxton, Rodriguez, & Dale, 2015, Behavior
Research Methods).
The inherently social nature of interpersonal coordination poses an
interesting problem to cognitive scientists who must attempt to balance external validity
with experimenter control.
PsyGlass is designed for naturalistic exploration of theory-
driven questions in interpersonal interaction by facilitating surreptitious data collection
and moment-to-moment control over participant visual stimuli.
Finally, I explore how context modulates patterns of coordination in gaze pat-
terns (Paxton,
Dale,
& D.
C.
Richardson,
in preparation).
This chapter contributes
to emerging work that explores how higher-level
social
factors can alter patterns of
coordination by focusing on conflict.
This dissertation, Coordination:
Theoretical, Methodological, and Experimental
Perspectives,
is submitted by Alexandra Paxton in 2015 in partial
fulfillment of
the
degree Doctor of Philosophy in Cognitive and Information Sciences at the University of
California, Merced, under the guidance of dissertation committee chair Rick Dale.
xxiii
Chapter 1
Introduction
1.1
Introduction
Our lives are marked, supported, and enriched by social interaction.
As part of
a complex social ecosystem, we are often aware of the powerful effects that our behavior
can have on others.
We tend to be less aware, however, of our much more subtle ties—
the interconnectedness of our language,
movement,
and emotion with around us.
The
field of interpersonal
coordination
1
characterizes that subtle web of connectedness and
the low “hum” of social resonance.
1.2
Interpersonal Coordination
As an exciting but relatively young frontier in cognitive science, the interdisci-
plinary research area that has sprung up around interpersonal coordination is rife with
important unsolved issues.
In this dissertation,
I
am chiefly interested in exploring
pressing issues in three main considerations:
theoretical perspectives, methodology, and
experimental
investigations.
Each of these very broad areas still
have enormous room
for growth as the field matures;
the present work is chiefly concerned with one or two
issues within each area.
1.2.1
Theoretical Perspectives
From its immediate origins in clinical (Condon & Ogston, 1966) and develop-
mental (Condon & Sander, 1974) psychology—and more distant origins in early health
psychology and public health (Glad & Adesso,
1976;
Polansky,
Lippitt,
& Redl,
1950;
Wheeler, 1966)—the study of interpersonal coordination has thrived in recent decades.
Known by various names,
related research into interpersonal
coordination has spread
to include a wide variety of perspectives,
from affect (e.g.,
Butler,
2011) to movement
(e.g.,
M.
J.
Richardson,
Marsh,
Isenhower,
Goodman,
& Schmidt,
2007) to language
(e.g.,
Niederhoffer & Pennebaker,
2002).
Although these perspectives largely evolved
distinct from one another,
theoretical
proposals (e.g.,
Pickering & Garrod,
2004) and
experimental
work (e.g.,
Paxton,
Abney,
Kello, & Dale,
2014) have begun to integrate
our understanding of coordination across communication modalities, forming a picture
of coordination as a multimodal and multiscale phenomenon.
1
As I discuss in greater detail later, I understand there is a distinct lack of agreement within the field
on what to call this phenomenon.
For ease and brevity,
I will use “coordination” to refer to it during
the introduction.
Subsequent chapters will each include operational definitions for the phenomenon.
1
2
At the same time, new perspectives are pushing the field to reexamine the struc-
ture of interpersonal coordination.
Coordination has largely revolved around the study
of similar affect, behavior, and cognition performed in temporal proximity, but ideas of
interpersonal synergies (Riley, Richardson, Shockley, & Ramenzoni, 2011) have begun to
challenge this dominant perspective.
Rather than interpreting coordination as a simple
“similar is better” view, the emerging theoretical viewpoint suggests that interpersonal
coordination is an adaptive emergent property of
interaction that is context-sensitive
and highly dynamic (Abney,
Paxton,
Dale,
& Kello,
in press).
While still
in its early
stages,
this idea has been increasingly supported by work demonstrating the context-
sensitivity of coordination (e.g., Paxton & Dale, 2013a; Miles, Griffiths, Richardson, &
Macrae,
2010) and highlighting how harmful
simple similarity can be in some settings
(e.g., Fusaroli et al., 2012; Main, Paxton, & Dale, under review).
This research area has grown immensely due to increased popularity over the
past several
decades.
Its fundamentally interdisciplinary nature ties together lines of
research from numerous fields,
from psychotherapy (e.g.,
Nagaoka & Komori,
2008)
to marketing (e.g.,
Ramanathan & McGill,
2007).
This fractured history poses an
interesting challenge to the field:
Not only are there more than a dozen terms used to
describe the phenomenon
2
, but there is little to no consensus about their relation to one
another.
As the field grows and grapples with the very nature of coordination, creating
and understanding the language of coordination becomes increasingly urgent.
1.2.2
Methodology
The varied origins of the research area—along with its spreading influence—
have led to the study of coordination through a variety of methodologies.
For example,
researchers have approached affective coordination by analyzing video-recorded interac-
tions (e.g.,
Main et al.,
under review;
Sadler,
Ethier,
Gunn,
Duong,
& Woody,
2009;
Randall, Post, Reed, & Butler, 2013) or by exploring changes in cortisol (e.g., Saxbe &
Repetti, 2010).
Quantifications of linguistic coordination include linguistic content (e.g.,
Niederhoffer & Pennebaker,
2002;
Fusaroli
et al.,
2012),
acoustic signals (e.g.,
Abney,
Paxton, Dale, & Kello, 2014; Paxton et al., 2014), or modeling meaning in social media
activity (e.g., Garimella, Morales, Gionis, & Mathioudakis, 2015).
Naturally, the oper-
ationalization of coordination changes with the specific communication channel
under
consideration, and coordination research in nearly all modalities is adapting to changes
in technology and society.
Accordingly, movement coordination is undergoing significant change as tech-
nology begins to offer alternatives to a traditionally labor-intensive process.
Some of the
very earliest work in this area quantified interpersonal coordination through meticulous
frame-by-frame hand-coding of
video recordings (Condon & Ogston,
1966;
Condon &
Sander, 1974).
Hand-coding is still practiced, although often in more moderate forms—
like watching videos to count or chart specific behaviors (e.g.,
Chartrand & Bargh,
1999; Louwerse, Dale, Bard, & Jeuniaux, 2012; Grammer, Kruck, & Magnusson, 1998).
As computational power increases and high-resolution technology becomes cheaper, au-
tomated measures of
behavioral
coordination are becoming increasingly widespread—
including frame-differencing measures for analyzing video (e.g., Paxton & Dale, 2013b)
and motion-tracking systems (e.g., M. J. Richardson et al., 2007).
Even as methods improve for quantifying coordination, research on coordination—
especially movement coordination—is still marked by a steep trade-off between experi-
mental control and external validity.
Many of the experimental manipulations needed to
better understand important parameters of coordination often have required stilted or
2
An inexhaustive list includes accommodation, adaptation, alignment, contagion, congruency, coor-
dination, coupling, entrainment, imitation, mimicry, social tuning, synchrony, and synergy.
3
artificial laboratory setups, somewhat removing the laboratory behavior from its natural
habitat.
Conversely, more observational setups can capture slice-of-life coordination but
are therefore fairly limited in their ability to create settings that can push coordination
outside its usual
parameters.
With this trade-off in current technologies,
pioneering
new methods may help bridge the gap between naturalistic paradigms and experimental
control.
1.2.3
Experimental Investigations
As coordination research matures as a field, lines of inquiry within it are begin-
ning to expand, moving beyond questions of whether we coordinate to deeper questions
of how and why we coordinate.
Some of the more popular interests include how indi-
vidual traits (e.g., Tschacher, Rees, & Ramseyer, 2014; Bos, Bouhuys, Geerts, Van Os,
& Ormel, 2006) or different relationship qualities (e.g., Main et al., under review; Ram-
seyer & Tschacher, 2011) affect coordination.
Relatively less focus has historically been
placed on larger-scale contextual
factors.
The majority of
previous research explores
coordination during task-based (e.g.,
Hove & Risen,
2009;
Louwerse et al.,
2012),
af-
fectively neutral
(e.g.,
Condon & Sander,
1974),
or affiliative (e.g.,
Koss & Rosenthal,
1997) interactions.
This is not universally the case,
however.
One of
the earliest lines of
re-
search emerged with ideas about how broader social
factors—especially social
group
membership—could modulate coordination (e.g., Giles, Taylor, & Bourhis, 1973).
Other
work has explored the importance of social pacts and perceptions in influencing coordi-
nation across both high- and low-level
behavioral
measures (e.g.,
Lakin,
Chartrand,
&
Arkin, 2008; Miles et al., 2010; Miles, Lumsden, Richardson, & Macrae, 2011).
To date,
however, only a small slice of possible communicative contexts—whether people are in-
teracting in friendly conversation,
task-directed interactions,
or even arguments—have
been explored.
Decades of previous research have demonstrated that coordination exists across
a number of
modalities during interaction (see Chapter 2).
The challenge facing the
field now is to understand what function coordination might serve and how it emerges.
One step in this vital
new path in the evolution of coordination is to understand how
communicative context shapes coordination.
1.3
Motivation and Previous Work
Over the past several
years,
my research program has quantified the context-
dependence of multimodal behavior during interaction.
This work has primarily explored
how conflict (as a communicative context) changes the nature of behavior, communica-
tion, and interaction (e.g., Abney et al., 2014; Paxton & Dale, 2013a; Main et al., under
review; Paxton & Dale, 2013c, in preparation).
Studies of other communicative contexts
(e.g., task-based interactions; Abney et al., in press; Paxton, Roche, & Tanenhaus, 2015;
Paxton et al., 2014) support this primary focus, highlighting the context-dependent na-
ture of interpersonal dynamics by providing a contrasting contextual lens.
Coordination has been one of my strongest influences in shaping my perspec-
tive, methodology, and questions, and I have been grappling with deep underlying issues
within interpersonal coordination.
Some of my earliest work provided researchers with
an open-source tool
to analyze movement in video recordings (Paxton & Dale,
2013b)
and presented the first theoretically motivated exploration of coordination and conflict
(Paxton & Dale, 2013a).
Interpersonal coordination has since remained a core concern
within my research program.
This dissertation carries and extends this central interest
by addressing pressing issues within the coordination literature.
4
1.4
The Present Work
This dissertation is centered on questions within the theoretical, methodolog-
ical,
and experimental
domains of
the coordination research area.
These are highly
interrelated areas of growth for this research area.
As a cognitive scientist with a com-
putational
social
science perspective,
I
feel
these three strands of
the research area
should also be reflected in my own work—simultaneously pushing theory, methods, and
experimental findings within coordination.
The first section confronts the mystery surrounding the terminology of coordi-
nation with data-driven perspectives on the various terms used to describe it.
The wide
variety of coordination-related terms has led to a scattered research area, and researchers
have no agreed-upon understanding of what each term means nor how each term relates
to one another.
Building from previous subjective efforts to classify these terms (Butler,
2011; Delaherche et al., 2012), this section uses multiple semantic analyses to understand
the state of the terminological field.
The next section introduces PsyGlass, a new method for both quantifying be-
havior and giving experimenters moment-to-moment control
over participant stimuli
during naturalistic paradigms.
Like previous work (Paxton & Dale,
2013b),
PsyGlass
is meant to facilitate objective quantification of behavior even for researchers with rela-
tively little funding or programming experience—but it adds the ability for researchers
to present participants with on-the-fly instructions, subtle stimuli, and more.
Although
it can be used to address a variety of research questions, PsyGlass was developed to help
bridge the gap between naturalistic settings and strong experimental control in interper-
sonal coordination research.
This chapter provides an overview of wearable technology
in cognitive science,
outlines PsyGlass,
and presents a brief study on interpersonal
co-
ordination as an example of how PsyGlass can be used to extend traditional questions
in cognitive science.
The final
section looks at how patterns of
gaze coordination are modulated
by communicative context.
Results from previous work have demonstrated that gaze
coordination occurs between interlocutors during speech and suggested that this gaze
coordination is causally linked to comprehension (D.
C.
Richardson & Dale,
2005).
However,
this previous work only examined relatively neutral
conversational
contexts.
At the same time, the support for a causal relationship between gaze coordination and
comprehension provides an intriguing test ground for exploring the effects of
context.
This is especially true for conflict,
a conversational
context demonstrated to reduce
or break interpersonal
coordination in movement (Paxton & Dale,
2013a) and speech
(Abney et al., 2014;
Paxton & Dale, 2013c).
This final section explores how context—
whether participants agree or disagree about a given topic—modulates gaze coordination
patterns.
Chapter 2
A data–driven approach to
disambiguating the
terminology of interpersonal
similarity
2.1
Introduction
A relatively new field of
study has emerged over the past several
decades,
investigating how and why interacting individuals become more similar in affect,
be-
havior,
and cognition over time.
These researchers approach the question from one or
more of a number of diverse perspectives:
clinical psychology (e.g., Condon & Ogston,
1966;
Nagaoka & Komori,
2008;
Ramseyer & Tschacher,
2011),
cognitive psychology
(e.g.,
Chartrand & Bargh,
1999;
Dale,
Kirkham,
& Richardson,
2011),
developmental
psychology (e.g., Bernieri, Reznick, & Rosenthal, 1988; Condon & Sander, 1974; Criss,
Shaw, & Ingoldsby, 2003), emotion and rapport (e.g., Grammer et al., 1998; LaFrance,
1979; Lakin & Chartrand, 2003), joint action (e.g., Knoblich & Jordan, 2003; Tollefsen,
Dale,
& Paxton,
2013;
Valdesolo,
Ouyang,
& DeSteno,
2010),
psycholinguistics (e.g.,
Brennan & Clark,
1996;
Niederhoffer & Pennebaker,
2002;
Pickering & Garrod,
2004),
motor control
(e.g.,
M.
J.
Richardson et al.,
2007;
Riley et al.,
2011;
Shockley,
San-
tana, & Fowler, 2003; Turvey, 1990), neuroscience (e.g., Hasson, Ghazanfar, Galantucci,
Garrod, & Keysers, 2012; Konvalinka & Roepstorff, 2012; Stephens, Silbert, & Hasson,
2010),
physiology (e.g.,
Helm,
Sbarra,
& Ferrer,
2012;
Saxbe & Repetti,
2010),
social
perception (e.g.,
Bernieri,
Davis,
Rosenthal,
& Knee,
1994),
and speech and language
(e.g., McFarland, 2001).
Attention from so many fields has led to a deeper understanding of the phe-
nomenon, but it has also created a constellation of terms with no clear set of relations
among them.
This has led to the growth of a series of splintered literatures across indi-
vidual research areas.
While some researchers appear to use the terms interchangeably,
others appear to use specific terms to denote specific theoretical stances.
However, there
has been to date no consensus about how these terms should be treated.
The interdisciplinarity and multimodality of this research area is an incredible
strength with great possibilities.
We believe it is in the best interest of the research area
to begin to understand and perhaps even resolve these differences.
We start our work
with a review of the current state of this research area by presenting some of the most
5
6
common terms and important findings related to each.
We review eight unique terms,
presented in alphabetical order:
accommodation, adaptation, alignment, the chameleon
effect (or mimicry),
contagion,
mirroring (and the mirror neuron system),
synergy (or
coordinative structures), and synchrony.
1
2.1.1
Accommodation
Communication Accommodation Theory (CAT)—also known as accommoda-
tion theory and Speech Accommodation Theory—was one of
the earliest attempts to
establish a theory for this phenomenon.
CAT emerged with a strong eye interpersonal
factors to help explain the how social forces at multiple scales affect speech (e.g., Bourhis,
Giles, & Lambert, 1975; Giles, Taylor, & Bourhis, 1977; Giles, Coupland, & Coupland,
1991).
Many of the first works were concerned with the strategic convergence and di-
vergence of speech according to contextual demands, including social distance between
speaker and listener and social perception of the speaker by the listener (e.g., Bourhis et
al., 1975; Giles, 1973; Giles et al., 1973; Larsen, Martin, & Giles, 1977; Simard, Taylor,
& Giles, 1976).
Giles (1973) suggested that interlocutors strengthen interpersonal bonds
through the use of more similar speech (i.e.,
convergence) and that interlocutors may
distance themselves from one another through the adoption of more distinct speech (i.e.,
divergence).
The underlying assumptions in those views—that convergence and divergence
are (a) to some extent intentional
and (b) inextricably tied to social
dynamics and
context—became and remained central
to CAT (e.g.,
Beˇ
nuˇs et al.,
2014).
Later work
expanded CAT to explore additional sociolinguisic concerns, from implicit cultural fac-
tors (Babel,
2010) to maintaining cultural
distinctiveness (Clachar,
1997) to listeners’
causal attributions for speakers’ convergence or divergence (Simard et al., 1976).
CAT
has also grown to include additional communication modalities (for review, see Giles et
al., 1991).
2.1.2
Adaptation
Perhaps the most unique aspect of the partner-specific adaptation (also called
talker-specific adaptation or simply adaptation view is its strong stance on the inten-
tionality of the process (e.g., Brennan & Hanna, 2009).
The adaptation view is loosely
connected across several terms but is most recognizable in the use of several key terms
and associated core beliefs.
Common ground —the shared goals and information be-
tween interlocutors—is essential to successful interaction, and interlocutors continue the
grounding process throughout an interaction (e.g.,
Brennan,
Galati,
& Kuhlen,
2010;
H.
H.
Clark & Krych,
2004).
Through grounding,
interlocutors intentionally adapt
their behavior to partner- and situational-specific needs (e.g., Brennan & Hanna, 2009;
Bangerter & Clark,
2003;
Rogers,
Fay,
& Maybery,
2013).
One of the most noticeable
avenues of
adaptation is through interlocutors’
use of
conceptual
or referential
pacts,
mutually adopted terms and phrases that create a communicative shorthand based on
the interlocutors’ shared history (e.g., Brennan & Clark, 1996; Brennan et al., 2010).
In this view, both parties in conversation—speakers and listeners—are actively
involved in the joint creation of meaning and in the adaptation process.
Speakers en-
gage in audience design to facilitate listener understanding by selectively including or
excluding information (e.g., Galati & Brennan, 2010) while monitoring listeners’ compre-
hension (e.g., H. H. Clark & Krych, 2004).
Meanwhile, listeners employ partner-specific
1
We recognize that the terms listed are not exhaustive,
that some individuals use these terms in
other ways,
and that some individuals use several
terms interchangeably.
This is emblematic of
the
current terminological uncertainty that we hope to highlight in this paper.
7
processing that helps them to quickly adapt to speakers’
idiosyncrasies (e.g.,
accents;
Trude & Brown-Schmidt, 2012 and the dyad’s interaction history (e.g., referential pacts;
Brown-Schmidt,
2009.
Like CAT (e.g.,
Giles et al.,
1991),
adaptation has its roots in
linguistic or lexical
behaviors (e.g.,
accents;
Brennan & Clark,
1996.
Recent work has
explored adaptation in other aspects of communication, like gesture (e.g., Mol, Krahmer,
Maes, & Swerts, 2012) and speech perception (e.g., Trude & Brown-Schmidt, 2012).
2.1.3
Alignment
The interactive alignment theory proposed by (Pickering & Garrod,
2004) is
perhaps one of
the best-known theories in this area.
Interpersonal
alignment relies
heavily on priming as a causal mechanism (e.g., Branigan, Pickering, & Cleland, 2000;
Cleland & Pickering,
2003;
Ferreira & Bock,
2006;
Mol
et al.,
2012).
Alignment is
accordingly considered a largely unintentional process (Pickering & Garrod, 2004).
Al-
though the interactive alignment account grew out of
a psycholinguistic perspective,
Pickering and Garrod (2004) propose even in their seminal work that individuals should
align across multiple timescales (e.g.,
phonemes,
lexical
choice,
syntactic construction)
and modalities (e.g., speech, cognition).
The modalities and timescales are believed to
support one another,
such that alignment along one dimension can increase alignment
in other dimensions (e.g., Menenti, Pickering, & Garrod, 2012; Reitter, Moore, & Keller,
2006).
This explicit multidimensionality is one of the most defining and unique elements
of the theory.
The relative popularity of the interactive alignment account has led to its ap-
plication in a number of
fields and to a number of
questions.
For example,
recent
efforts in neuroscience have sought possible neural
mechanisms under the alignment
account (Menenti
et al.,
2012) and have explored alignment of neural
patterns during
conversation (Hasson et al.,
2012;
Stephens et al.,
2010).
Advances in automated text
analysis (e.g., Niederhoffer & Pennebaker, 2002) have facilitated questions of lexical and
syntactic alignment of
transcripts (e.g.,
of
police interrogations in B.
H.
Richardson,
Taylor,
Snook,
Conchie,
& Bennell,
2014 and of online text (e.g.,
in multiparty health
forums in Wang, Reitter, & Yen, 2014.
However, the popularity of the view has led re-
lated terms—like “alignment”—to be used in situations in which no exclusive theoretical
stance is denoted (e.g., Dale et al., 2011; Healey, Swoboda, Umata, & King, 2007).
2.1.4
Chameleon Effect or Mimicry
Introduced by Chartrand and Bargh (1999), the chameleon effect—also referred
to as unconscious human mimicry or simply mimicry—relies upon the perception-action
link in explaining the humans’
tendencies to perform similar movements and adopt
similar postures.
Investigations on movement-based mimicry predated Chartrand and
Bargh (1999)’s findings (e.g.,
Bavelas,
Black,
Lemery,
& Mullett,
1986),
but the term
mimicry has since largely grown up around the chameleon effect.
Despite its early focus
on movement specifically,
the area has come to encompass other forms of
mimicry as
well
(e.g.,
language,
emotion;
Chartrand & Dalton,
2008.
From its first appearance,
the chameleon effect has been centrally concerned with the (a) social implications and
(b) evolutionary basis of behavioral
similarity (e.g.,
Chartrand & Bargh,
1999;
Lakin,
Jefferis,
Cheng,
& Chartrand,
2003;
van Baaren,
Janssen,
Chartrand,
& Dijksterhuis,
2009).
The chameleon effect often couches findings within the idea that mimicry breeds
affiliation (e.g., Chartrand & Dalton, 2008).
The link between similarity and rapport has
been studied by researchers across the theoretical
spectrum (e.g.,
Giles,
1973;
Tickle-
Degnen & Rosenthal,
1990),
but the connection between mimicry and positive social
emotions is perhaps most strongly emphasized by those within the chameleon effect
8
area (e.g., van Baaren et al., 2009).
The emphasis the evolutionary significance of interpersonal behavioral similari-
ties is another hallmark of research under this theory (e.g., Lakin et al., 2003).
Mimicry’s
link to positive social emotions has been suggested as a means to signal in-group mem-
bership (e.g., Lakin et al., 2008), to deepen interpersonal (e.g., van Baaren et al., 2009)
and group (e.g.,
Ashton-James,
van Baaren,
Chartrand,
Decety,
& Karremans,
2007)
ties,
and to increase prosocial
behavior (e.g.,
Ashton-James et al.,
2007;
van Baaren,
Holland, Kawakami, & van Knippenberg, 2004).
Moreover, the chameleon effect posits
that mimicry occurs unconsciously,
as an almost automatic response to the social
en-
vironment (e.g.,
Chartrand & Bargh,
1999;
Chartrand & Dalton,
2008;
van Baaren et
al.,
2009).
Under this view,
mimicry is believed to have evolved to support social
in-
teractions and basic survival at the group level by facilitating links between individuals
without requiring more costly and overt social signaling (e.g., Lakin et al., 2003).
2.1.5
Contagion
Affective or emotional contagion describes the ways in which individuals affect
and are affected by the emotional states of others (e.g., Hatfield, Cacioppo, & Rapson,
1993).
Research supports contagion effects during interaction (e.g., Neumann & Strack,
2000;
Pugh,
2001;
Rozin & Royzman,
2001) and through more static,
priming-based
methods (e.g., Erisen, Lodge, & Taber, 2014).
Suggested mechanisms for affective con-
tagion include the perception-action link (e.g.,
McIntosh,
2006;
Neumann & Strack,
2000) and the mirror neuron system
2
(e.g.,
Nummenmaa,
Hirvonen,
Parkkola,
& Hi-
etanen,
2008).
However,
recent analyses of
social
networks have demonstrated that
affect can spread without direct observation (e.g., Kramer, Guillory, & Hancock, 2014),
indicating that additional processes may play a role in contagion.
Behavioral
contagion describes how complex behaviors spread across individ-
uals,
often with stronger allusions to biological
contagion (e.g.,
Jones & Jones,
1995)
than is seen in work on affective contagion.
These behaviors are generally not the
kinds of low-level behaviors traditionally targeted by work employing other terminology,
like interpersonal synchrony (e.g., infants’ overall body movements; Condon & Sander,
1974 or mimicry (e.g.,
finger tapping;
Chartrand & Bargh,
1999.
Instead,
behavioral
contagion tends to focus on higher-level
behaviors with applied implications.
For ex-
ample,
clinical
investigations have examined behavioral
contagion of
suicide (Gould,
Jamieson, & Romer, 2003) and antisocial behaviors (Wheeler, 1966); social explorations
have targeted contagion of behaviors as varied as product adoption (Aral, Muchnik, &
Sundararajan,
2009),
voting (Bond et al.,
2012),
smoking (Glad & Adesso,
1976),
and
popularity (Marks, Cillessen, & Crick, 2012).
Contrasting with largely dyad-level
analyses under other terminological
um-
brellas,
researchers in contagion-based areas combine dyadic-level
(e.g.,
Neumann &
Strack,
2000;
Nummenmaa et al.,
2008;
Pugh,
2001) and group-
or population-level
(e.g.,
Barsade,
2002;
Glad & Adesso,
1976;
Jones & Jones,
1995;
Marks et al.,
2012;
Polansky et al., 1950) analyses of interpersonal influence.
The increasing availability of
online behavior and social network data has created new opportunities for both affective
(e.g., Christakis & Fowler, 2013; Coviello et al., 2014; Kramer et al., 2014) and behav-
ioral (Aral et al., 2009; Bond et al., 2012; Christakis & Fowler, 2013) contagion research
that complement traditional investigations of face-to-face interaction.
2
See “Mirroring and the mirror neuron system” section.
9
2.1.6
Mirroring and the Mirror Neuron System
First
discovered in the F5 area of
the macaque premotor
cortex (Gallese,
Fadiga, Fogassi, & Rizzolatti, 1996; Rizzolatti, Fadiga, Gallese, & Fogassi, 1996), mirror
neurons in macaques fire during both the observation and the performance of primar-
ily goal-directed,
object-effector actions (for review,
see Rizzolatti
& Craighero,
2004.
The search for human homologues has led to the postulation of a mirror neuron system
(MNS). The proposed MNS includes several brain regions that, together, function sim-
ilarly to mirror neurons:
the superior temporal
sulcus,
the inferior frontal
cortex,
and
the rostral part of the inferior parietal lobule (Iacoboni, 2005).
However, the human MNS appears to be more socially driven than the macaque
mirror neurons.
Unlike macaque mirror neurons (cf.
Gallese et al.,
1996;
Rizzolatti
et
al.,
1996,
the MNS activates even when observing incidental
(i.e.,
non-goal-directed;
Rizzolatti
& Craighero,
2004 or non-intended (e.g.,
tripping;
Buccino et al.,
2007 ac-
tions.
Moreover, levels of MNS activation differ according to contextual factors, like an
observer’s level
of
expertise in the behavior (e.g.,
dancers and martial
artists;
Calvo-
Merino,
Glaser,
Gr`ezes,
Passingham,
& Haggard,
2005) or the complementarity of be-
havior between observer and observed (e.g.,
grip shapes;
Newman-Norlund,
van Schie,
van Zuijlen, & Bekkering, 2007).
Coupled with activation in the limbic system and the
insula,
evidence suggests that the MNS is activated during the mirroring (or sponta-
neous imitation) of others’ affective displays (e.g., L. Carr, Iacoboni, Dubeau, Mazziotta,
& Lenzi, 2003; Iacoboni, 2005).
These capacities of the MNS have led to its adoption as an explanatory mech-
anism of
various aspects of
human social
cognition,
particularly empathy and action
understanding (e.g.,
Calvo-Merino et al.,
2005;
L.
Carr et al.,
2003;
Iacoboni,
2005;
Oberman,
Pineda,
& Ramachandran,
2007;
Oberman & Ramachandran,
2007;
Pfeifer,
Iacoboni,
Mazziotta,
& Dapretto,
2008).
Some have criticized claims made by mirror
neuron research as overreaching (e.g.,
Hickok,
2009) or as incomplete explanations of
target phenomena (e.g., Hamilton, Brindley, & Frith, 2007).
However, the mirror neuron
system has found acceptance as a possible neural
mechanism for the tendency toward
interpersonal similarity (with varying degrees of explanatory power; cf.
Brass & Heyes,
2005;
Iacoboni,
2005) in several
theoretical
stances mentioned in the present article
(e.g.,
Dijksterhuis,
Smith,
van Baaren,
& Wigboldus,
2005;
Nummenmaa et al.,
2008;
McIntosh, 2006;
Menenti et al., 2012;
Ramseyer & Tschacher, 2008;
van Baaren et al.,
2004), spanning both representational and embodied accounts of imitation (E. W. Carr
& Winkielman, 2014; Pineda, 2008).
2.1.7
Synergy or Coordinative Structure
Borrowed from the motor control literature (e.g., Bernstein, 1967), the interper-
sonal synergies view posits that interacting individuals should adapt themselves flexibly
to one another and to the needs of the situation (Riley et al., 2011).
In the motor system,
muscle synergies or coordinative structures reduce the effective degrees of
freedom by
creating soft-assembled muscle groupings that act as a single unit, diminishing the strain
on motor control through lower functional
degrees of freedom (e.g., d’Avella, Saltiel, &
Bizzi, 2003; Tresch & Jarc, 2009; Turvey, 2007).
Essentially, synergies minimize variabil-
ity in task-relevant domains while allowing variability in non-relevant domains to range
freely in the system’s attempt to reach a goal
(e.g.,
Kelso,
Tuller,
Vatikiotis-Bateson,
& Fowler,
1984).
This results in a goal-focused,
context-sensitive,
and perturbation-
adaptive view of motor control (Turvey, 1990).
Interpersonal synergies apply these ideas beyond the individual to interpersonal
interaction.
Viewing the dyad as a soft-assembled system,
the interpersonal
synergies
view suggests increasing interpersonal
similarity alone may not necessarily result in
10
the most optimal
configuration for patterns of interpersonal
interactions (Riley et al.,
2011).
Instead, a combination of complementarity and similarity of various communica-
tive channels and behaviors may be required, as supported by recent experimental work
(e.g.,
Fusaroli
et al.,
2012;
Abney et al.,
in press).
The structure of the interpersonal
synergies—as with muscle synergies—are posited to be context-sensitive,
resulting in
a soft-assembled and adaptable dyadic system highly dependent on the individuals in-
volved and the context demands (Dale,
Fusaroli,
Duran,
& Richardson,
2014;
Paxton,
Dale, & Richardson, in press).
The idea of interpersonal
synergies has since spread beyond its initial
use in
interpersonal motor or movement synergies (Black, Riley, & McCord, 2007; Riley et al.,
2011; Ramenzoni, Riley, Shockley, & Baker, 2012; Abney et al., in press).
Recent work
has applied the idea to linguistics (Fusaroli
et al.,
2012;
Fusaroli,
Raczaszek-Leonardi,
& Tyl´en,
2014) and multimodal
communication (Paxton et al.,
2014).
Related work
on flexible coordinative structures in social
interaction or conversation more broadly
(Schmidt & Richardson, 2008; Shockley, Richardson, & Dale, 2009)—although predating
Riley et al.’s (2011) theoretical
piece introducing interpersonal
synergies—should be
considered as stemming from the same originating field,
as the phrase has a similar
origin in the motor control literature (e.g., Kelso et al., 1984).
2.1.8
Synchrony
Synchrony—also known as interactional synchrony or interpersonal synchrony—
is one of the oldest and most commonly used terms, again stemming from work on move-
ment (Condon & Ogston, 1966; Condon & Sander, 1974).
Work under this term tends
to focus on phase-locked movement of specific effectors (e.g.,
finger tapping in Hove &
Risen, 2009; hand movement in Macrae, Duffy, Miles, & Lawrence, 2008; arm movement
in Miles et al.,
2011;
rocking in M.
J.
Richardson et al.,
2007) or overall
body move-
ment (e.g.,
Nagaoka & Komori,
2008;
Paxton & Dale,
2013a;
Ramseyer & Tschacher,
2011).
Research under these terms often target phase-locked relations between behav-
ioral
signals,
linking it to the term entrainment
(e.g.,
Miles,
Nind,
& Macrae,
2009;
M.
J.
Richardson et al.,
2007).
However,
synchrony also has been used during explo-
rations of atemporal
phenomena (e.g.,
written language use in Ireland & Pennebaker,
2010), behavior with looser temporal structure (e.g., subjective evaluations of movement
tempo in Koss & Rosenthal, 1997), or non-movement phase-locked behavior (e.g., affect
in Sadler et al., 2009; gesture and speech in Wagner, Malisz, & Kopp, 2014).
Interpersonal synchrony is often investigated with an eye to its social or com-
municative consequences.
The rapport-synchrony link has been upheld in numerous
articles (e.g.,
Bernieri
et al.,
1994;
Hove & Risen,
2009;
Cacioppo et al.,
2014),
and
related work has tied synchrony to other social factors, like group cohesion (e.g., Wilter-
muth & Heath,
2009;
Miles et al.,
2011),
prosocial
behaviors (e.g.,
Valdesolo et al.,
2010;
Cirelli,
Einarson,
& Trainor,
2014),
or adherence to social
norms (e.g.,
Miles et
al., 2010).
Improved mechanisms associated with communication—like improved mem-
ory (e.g., Macrae et al., 2008)—have also been associated with interpersonal synchrony.
In light of these findings, it is unsurprising that interpersonal synchrony has been used
as a lens to study outcomes in patient-clinician (e.g., Koss & Rosenthal, 1997; Nagaoka
& Komori, 2008; Ramseyer & Tschacher, 2008, 2011) and parent-child (e.g., Bernieri et
al., 1988; Criss et al., 2003; Main et al., under review) relationships.
2.1.9
The Present Study
This research area is currently divided by its scattered terminology.
To the
authors’
knowledge,
there has only been one formal
attempt to create a taxonomy for
11
this research area (Delaherche et al., 2012).
3
While an important first step, it was largely
subjective:
The definitions of each term and their relations to one another were grounded
in existing work but were nevertheless based on the authors’ own categorizations.
To this end, we here present a first attempt to objectively relate existing terms
within the field to one another,
inspired by recent pushes in metascientific or sciento-
metric analyses (e.g., Griffiths & Steyvers, 2004; Bergmann, Dale, Sattari, Heit, & Bhat,
accepted).
Using abstracts pulled from a wide variety of research works related to this
area,
we use automated classification techniques to uncover the existing implicit rela-
tionships across the terms as they are currently used.
This allows the work within this
research area to speak for itself,
rather than creating a pre-specified structure through
which the existing literature should be viewed.
The present study analyzes 11 terms:
accommodation,
adaptation,
alignment,
contagion, convergence, coordination, entrainment, mimicry, mirroring, synchrony, and
synergy.
Of course,
this is by no means an exhaustive list of possible terms describing
interpersonal similarity.
We chose to focus on these terms based upon their prevalence
and/or claims of specialized (typically theory-specific) definitions.
The present study has two main goals.
First,
we seek to identify possible
groupings of terms.
By relying on metascientific analysis techniques, we can look within
the data to find the most salient dimensions along which to divide the data.
If
the
meaning of these terms are distinct and well-defined,
automatically identified clusters
within the data should fall
along such differences.
If
these terms are somewhat less
important to the core ideas within the research area,
we should find groups emerge
along other lines (e.g., specific domains of cognitive science).
Second, we hope to identify one or more term(s) that could be used in a more
general fashion based on their current usage patterns.
Although the use of more special-
ized terms be useful in signaling specific concepts, providing a single term as a catch-all
“umbrella” term may be useful for researchers when discussing their works or choosing
publication keywords.
We do not claim that this will
be a panacea for this important
problem within the field.
However, identifying a single umbrella term that can be used
by all researchers—in addition to any more specific keywords—may provide a crucial tool
for both producers and consumers of the research within this research area,
especially
while more granular definitions and relations can be identified.
Importantly,
we recognize that analyses like these are not a substitute for
critical thinking.
Instead, we view them as important tools for conscious theory-building.
We hope that the present work will
provide additional
momentum—and vital
data—
towards solving an important problem for this research area.
2.2
Materials
2.2.1
Corpus Creation and Preparation
We compiled a corpus of
abstracts from scientific research on interpersonal
similarity.
Abstracts were scraped from Thomson Reuter’s Web of Science
(http://www.wokinfo.com/)
with a series of
searches for
English-language abstracts
within the “Psychology” subject field.
Abstracts were automatically identified and
scraped for analysis by performing separate searches for each of the following 11 phrases
(with asterisks as wildcard characters):
interpersonal
accommod*,
interpersonal
adap-
tat*,
interpersonal
alignm*,
interpersonal
contagion,
interpersonal
converg*,
interper-
sonal coordin*, interpersonal entrainmen*, interpersonal mimic*, interpersonal mirror*,
3
One additional
attempt (Butler,
2011) specifically targeted emotion temporal
dynamics,
not the
field overall.
This was also largely subjective and divided terms by the methods associated with each
term.
12
interpersonal
synchron*,
and interpersonal
synerg*.
Duplicate records were then re-
moved,
and punctuation,
digits,
common stopwords
4
,
words with fewer than 3 charac-
ters,
and words that appeared in fewer than 5 unique abstracts were removed from all
abstracts.
After creating the initial
corpus,
we found that the interpersonal
adaptat*
search made up nearly half of the data in the corpus.
Upon closer examination of the
data, we found that a large number of these abstracts targeted a different phenomenon
than that under consideration in the current paper.
Therefore, our final corpus excluded
any abstracts that were obtained solely with that keywords search, although those that
were also identified in other keyword searches were retained.
The final
corpus comprised 2,540 unique abstracts in 668 unique publication
sources.
After cleaning the data (described above),
the corpus included 234,721 total
words and 4,969 unique words.
A total of 5,903 unique authors were represented in the
corpus
5
,
with an average of 3.31 authors per article.
The corpus included 16,971 total
keywords and 5,115 unique keywords.
Publication dates ranged from 1991 to 2015.
While this sample size may not be as large as other scientometric analyses,
the sample size is still
quite large in the context of the current analysis.
Much larger
scientometric analyses that rely on tens of thousands of abstracts focus on science writ
large (e.g.,
Griffiths & Steyvers,
2004) or on an entire branch of
scientific research
(e.g.,
Bergmann et al.,
accepted).
By contrast,
the current analyses use scientometric
analyses to better understand a single,
still
relatively young offshoot of
a branch of
scientific research.
This will necessarily lead to a smaller sample size, but the specificity
and depth of the sample will facilitate finely tuned interpretation of these data.
2.2.2
Analyses
We utilized three types of natural language processing (NLP) analyses:
latent
semantic analysis (LSA), latent Dirichlet allocation (LDA), and a neural-networks deep
learning approach.
Together,
these three approaches allowed us to look for robust,
convergent trends within the data.
Unlike other text analysis tools (e.g.,
Pennebaker,
Booth, & Francis, 2007), these methods are not pre-programmed with word meanings,
parsers, or dictionaries.
Instead, these methods identify underlying structure within the
data while remaining agnostic to the interpretation of the identified structures.
Below,
we briefly introduce each and provide additional resources for further detail.
Latent Semantic Analysis
Latent semantic analysis (LSA; Landauer, Foltz, & Laham, 1998) is a dimen-
sionality reduction tool
often used to find underlying concepts across texts.
LSA de-
termines the meanings of
words through their co-occurrence with other words across
various, allowing LSA to identify similarities based solely on the target corpus by com-
paring how each word and text “loads” on various dimensions.
These dimensions are
neither labeled nor interpreted by LSA: LSA simply pulls apart the data.
Users are free
to interpret individual dimensions or to simply use the loadings across all dimensions for
words or texts.
Similarity is calculated as the cosine of the target vectors representing
the target word or text,
and the resulting value serves as a correlation in the targeted
n-dimensional
space.
All
LSA models in the present analyses rely on 300-dimensional
spaces (cf.
Landauer, McNamara, Dennis, & Kintsch, 2013).
4
Using the English stopwords list from the nltk Python module (Bird, Klein, & Loper, 2009).
We
expanded this list to include the following lexical
items:
across,
also,
among,
beside,
may,
however,
within, yet, and longhand numbers zero through ten.
5
A total of 4,723 unique author surnames were included.
13
Latent Dirichlet Allocation
Latent Dirichlet allocation (LDA) is a generative probabilistic topic modelling
technique that allows users to identify underlying topics within a given corpus (e.g., Blei,
Ng,
& Jordan,
2003;
Griffiths & Steyvers,
2004).
Essentially,
LDA interprets lexical
items by estimating the probabilistic distribution of underlying concepts that make up
each document (i.e.,
in our case,
each abstract).
6
LDA identifies underlying structure
within the corpus but does not attempt to label
the emerging topics for the user.
We
implement LDA using the topicmodels package (Gr¨
un & Hornik,
2011) package in R
(R Development Core Team, 2008).
Additional information on the specific LDA model
is provided in the Results section.
Deep Learning Methods
Deep learning (DL) is a class of machine learning techniques that takes a neural
networks approach to unsupervised classification.
We implement deep learning over our
corpus with gensim’s (
ˇ
Reh˚uˇrek & Sojka,
2010) word2vec algorithm,
a Python-based
instantiation of
recent work by Mikolov and colleagues (Mikolov,
Chen,
Corrado,
&
Dean, 2013; Mikolov, Sutskever, Chen, Corrado, & Dean, 2013).
The method essentially
creates a probabilisitic representation of
the relations between words within a given
space through a “skip-gram” approach to estimating that space.
Rather than relying
on existing semantic models (e.g.,
Google News;
Mikolov,
Chen,
et al.,
2013;
Mikolov,
Sutskever, et al., 2013), we created novel semantic models using our corpus of abstracts.
This ensures that all
results will
speak strictly to related scientific uses of these words
within this research area.
2.3
Results
2.3.1
Keyword Analysis with LSA
As a first-pass analysis,
we explored patterns of
author-generated keywords.
This provides a glimpse into authors’
self-identification with these different terms as
a sort of
proxy for a more explicit probing of
experts’
understanding of
the relation
between the terms.
We chose to rely solely on LSA (rather than including LDA or DL)
to analyze the author-generated keywords,
given the relatively small
amount of
these
data.
We modeled the author-generated keyword data in a unique 300-dimensional space
built from all author-generated keywords for each abstract included in the final corpus.
Multi-word keywords were treated as distinct units to retain intended author meaning.
These connections are visualized in Figure 2.1,
which features the strongest
positive and negative connections in this network (see legend).
Interestingly, no strong
negative connections emerge between the terms in this network.
All
terms are either
too weakly related to be included in the graph or are positively related to one another.
Surprisingly,
synchrony—one of
the oldest and most widely used terms—appears in
only 46 abstracts and is not strongly connected to any other term,
although related
term entrainment is.
Coordination emerges as a relatively diffuse term within this network.
Co-
ordination—including more specific variants of
coordination (i.e.,
unintentional
inter-
personal
coordination and bimanual
coordination)—is densely connected both to other
key terms and to other top keywords.
However,
these author-generated keywords are
6
For an excellent conceptual introduction to probabilistic topic modeling—including LDA—see Blei
(2012).
14
Figure 2.1:
Network of top author-generated keywords in corpus.
Each node is a single
keyword,
and connections are determined by the cosine similarity scores (in the 300-
dimension keyword LSA space) between two nodes.
Multi-word keywords are graphed
with an underscore between each word.
Keywords with red nodes are (unigram) key
terms under consideration in this paper.
Connections are drawn according to strength
(see legend).
not strongly related to one another,
further supporting the idea of a more distributed
meaning of the term.
Several
small
clusters
emerge from these data.
For
example,
a cluster
of
movement-related keywords is most closely linked with key terms mirror, synergies, and
entrainment.
Interestingly, we also see mirror on the fringe of a cluster of neuroscience-
related terms (cf.
Calvo-Merino et al.,
2005).
Alignment
is linked to words related to
conversation,
which is consistent with its beginning in language contexts (Pickering &
Garrod, 2004).
Synergies—arguably one of the newest terms in this area—bridges these
two groups and is related to both language (cf.
Fusaroli et al., 2012) and movement (cf.
Riley et al., 2011).
We also see relationships between key terms,
either linked directly or by one
intervening word.
For example,
entrainment
and mirror are directly positively linked,
and both are further linked to joint
action.
Mirrors and alignment
are also directly
linked,
although they share no other strong connections.
Alignment
and synergies are
linked via conversation,
while three key terms—adaptation,
mimicry,
and mirror —are
all directly connected to unintentional
interpersonal
coordination.
Taken together,
the results from the keyword analysis support the idea that
these terms may not be strongly distinct from one another but may still
belong to
fuzzy domains.
Some terms may be competing for the same conceptual
territory,
as
15
demonstrated by their common links.
At the same time,
clusters of author-generated
keywords—including key terms—appear to emerge along the domain of
study (e.g.,
language, movement, neuroscience).
It is important to emphasize that we cannot say that these terms are synonyms
simply because LSA identifies a positive relation between them.
LSA is notoriously
unable to differentiate between synonyms and antonyms,
as patterns of co-occurrence
between antonyms are often similar to patterns of
co-occurrence between synonyms
(Landauer et al., 1998).
For this reason, we simply use LSA to highlight whether these
key terms are perhaps vying for similar spaces—regardless of whether their interpreta-
tions of those spaces are compatible with one another.
Again, this keyword analysis offers a glimpse at the more explicit level of cat-
egorization of these terms:
Authors are self-identifying their works as belonging to one
or more of these camps.
As a result,
the patterns of relationships that occur between
these terms may be somewhat biased by the authors’
own conceptualizations of
the
terminological
landscape.
The following analyses address this by moving away from
author-generated keywords to examine more implicit relations that underlie authors’
abstracts.
2.3.2
Abstract Analysis with LDA
Unexpectedly, we found that the probabilistic topic space was not particularly
well-separated in our initial
explorations.
Initial
models were highly unstable,
with
model-over-model topic stability (with new random seeds) as low as 30% for some topics.
As a result,
we systematically compared (1) data cleaning and preparation techniques
and (2) LDA model parameters to create the most stable topic models possible.
The data processing and preparation procedures described in the Method sec-
tion were chosen based on their ability to yield the most stable LDA model.
Consis-
tent with prior work and recommendations (Griffiths & Steyvers, 2004; Gr¨
un & Hornik,
2011), the model used Gibbs sampling, a fixed prior (β) of 0.1, and a constant α of 50/T.
After comparing models with various T, we selected a model with 10 topics, maximizing
model-over-model
topic stability while also accounting for human interpretability (cf.
Chang, Boyd-Graber, Wang, Gerrish, & Blei, 2009) and topic coherence.
The top 10 words for each topic in the model are presented in Table 2.1, along
with our label
for each topic.
Figure 2.2 projects the topics into a two-dimensional
space.
Based on the distribution of the topics and words in each, we interpret the x -axis
(PC1) as an individual-level/population-level (negative x -positive x ) dimension and the
y-axis (PC2) as a personal/abstract (negative y-positive y) dimension.
The numbering
of these topics is not indicative of any rank ordering and is simply for identification.
As
noted above each list in Table 2.1, the broad topics are persistent across runs, although
individual lexical items are somewhat less stable.
The most striking result from the LDA model is the nature of the topics.
The
most salient dimensions of
the corpus—as identified by this probabilisitic model—lie
in the broad research areas and modalities,
not specific terms.
The rich diversity of
the research areas identified in the topics is reassuring on a conceptual level, given the
impression of interdisciplinarity of this field.
By contrast, if the terms used to describe
the phenomenon were the most important lines of
division for the corpus,
we would
expect to see these topics emerge with strong connection to specific terms.
This is
especially important to note given that the corpus itself was generated using searches
with these terms across the entire field of psychology, not research questions.
These results
broadly support
findings
from the author-generated keyword
model.
In the author-generated keyword model,
we found clusters emerging around
research topics rather than specific terms,
with multiple terms sometimes occurring in
16
Figure 2.2:
Projection of multidimensional LDA topic distribution onto two-dimensional
space.
The top 10 lexical
items in each topic may be found in Table 2.1 under the
appropriately numbered topic.
This visualization was created in R (R Development
Core Team, 2008) with LDAvis package (Sievert & Shirley, 2014), using an LDA model
implemented in the topicmodels package (Gr¨
un & Hornik, 2011).
17
a single cluster.
Results from the LDA model—constructed with a much larger and
richer dataset—are similarly structured.
Interestingly,
we find several
parallels to the
LDA topics in some clusters from the keyword model,
including clusters around neu-
roscience and movement dynamics (see Figure 2.1),
highlighting the robust nature of
these differences.
2.3.3
Abstract Analysis with LSA
We modeled the abstract data with LSA in a new 300-dimensional space (i.e.,
not the author-generated keyword space).
We first visualized the relations exclusively
between the key term groups in a network.
To do so, we extracted the high-dimensional
vectors for all words in each key term group (e.g., for alignment :
align, aligns, aligning,
aligned,
alignment ).
We computed pairwise similarity scores for all
possible pairs of
these key terms within the abstract corpus as cosines in the high-dimensional
space.
The resulting network allows us to investigate just the relations among the key terms
(see Figure 2.3).
The visualization provides some preliminary insights into term relations in
this space.
As with the author-generated keyword space,
we again see some clusters
emerge with multiple key terms,
although restricting the visualization to include only
key terms strips the broader context (e.g., intervening relations).
At the same time, the
larger semantic space provides the opportunity to see new comparisons within each key
term group.
From this,
we see some key term groups with diffuse meanings across the
constituent terms (e.g., synchrony and adaptation words), while other terms have very
exclusively (or nearly exclusively) interconnected networks (e.g., mimicry and synergy).
Next,
we compared the neighborhood density of the key terms by identifying
the top 20 connections for each overarching group of key terms.
To determine whether
these terms are used in reliably different ways,
we performed a one-way ANOVA over
the cosine distances for the top 20 connections across the 11 key term groups.
Results of
the model
highlight significant differences in the neighborhood densities of each group
[F(10, 209) = 82.36, p <.00001].
This suggests that these terms are not used uniformly:
Instead, these terms differ in their neighborhood density, which can be interpreted as a
sign of specificity or interrelatedness.
A post-hoc pairwise Tukey test showed reliable patterns of
variation across
the term groups.
For example,
synergies
demonstrated the most tightly connected
neighborhood of the terms, and contagion appears to be the most weakly connected to
its 20 closest neighbors.
Interestingly,
the mean neighbor cosines values for many of
these terms are below .5,
suggesting only a moderate relationship among their closest
neighbors (e.g.,
convergence,
alignment,
coordination,
and synchrony).
These weak-
to-moderate results may suggest that the patterns of
use of
these key terms are not
characteristic or unique enough to create strong connections to their closest neighbors.
2.3.4
Abstract Analysis with Deep Learning
Deep learning (DL) is a useful
addition to these analyses given its reliable
detection of relationships between words,
even in relatively sparse data (e.g.,
Mikolov,
Sutskever, et al., 2013).
Therefore, we complement our frequentist analysis of the space
(LSA) using a neural-networks approach to estimating the same space.
This allows us
to explore subtler relations among the terms that may be not appear frequently enough
to be detected by LSA.
As with LSA,
word2vec—the specific DL method used here—encodes mean-
ing of
a single word as a high-dimensional
vector within a given semantic space.
We
generated a probabilistic semantic space using the abstract data and extracted vectors
18
Figure 2.3:
Network of
LSA-identified relations across key terms in abstract corpus.
Each node is a single term from a key term group,
and connections are determined
by the cosine similarity scores (in the 300-dimension abstract LSA space) between two
nodes.
Connections are drawn according to strength (see legend).
19
Figure 2.4:
Distribution of
neighborhood densities of
each group of
terms generated
by LSA and deep learning (DL) methods.
Term groups (on y-axis) are presented as
stems, and the strength of the relationship between its 20 nearest neighbors are charted
along the x -axis.
Neighborhoods generated by LSA (in green) and DL (in yellow) are
presented side-by-side for each group.
Lines inside each “violin” are a single cosine value
within the 20 nearest neighbors from each method.
Created in Python with the seaborn
package (Waskom et al., 2015).
for each word in the corpus.
We then identified the nearest neighbors for each of the
11 key term groups as the 20 most strongly related words (identified by highest cosine
value between high-dimensional vectors) to any word within the group.
To determine whether there were any differences in neighborhood densities
identified with DL,
we performed one-way ANOVA over the neighborhoods of
each
key term group.
Term group significantly predicted cosine strength of
the 20 nearest
neighbors [F(10,
209) = 9.95,
p <.00001]
(see Figure 2.4).
Consistent with the LSA
neighborhood results,
this suggests that there are reliable differences in neighborhood
characteristics for each of these key terms in the DL model.
A post-hoc pairwise Tukey analysis of this ANOVA again revealed interesting
patterns in the data,
although not entirely consistent with the LSA results.
Notably,
the cosine values appeared to much lower for all
terms in the DL model.
Given these
differences, we compared the neighborhoods of the key terms generated by LSA and DL.
A paired-samples t -test of the key term neighborhoods found a significant difference in
the neighborhood densities for the two models, t (219) = 16.58, p <.0001.
A supporting
2 (model) by 11 (key term group) ANOVA found a significant effect of model [F(1, 418)
= 470.19, p <.0001], key term group [F(10, 418) = 53.30, p <.0001], and the interaction
term [F(10, 418) = 24.64, p <.0001].
A follow-up Tukey comparison of means found that nearly half of the terms—
adaptation,
alignment,
entrain,
mimicry,
mirror,
and synergy—showed significantly
denser LSA neighborhoods than DL neighborhoods (all
ps <.0001).
Results from the
other half of the terms did not significantly differ between the two models (i.e., accommo-
dation,
contagion,
convergence,
coordination,
and synchrony).
The differences between
the two models, then, were largely driven by terms that are proposed (by some) to have
specific theoretical
connotations.
This supports the idea that researchers may be at-
20
tempting to use these terms in specialized ways—even though the underlying meanings
of the terms are less well-specified.
2.4
Discussion
Work from a large and growing research area has sought to answer why and
how people become more similar.
From affective dynamics to motor control, numerous
important empirical
findings have been presented under a number of
different terms.
This increased attention has led to an improved understanding of the phenomenon, but
it has not yet led to a unified terminology that could facilitate conversation across the
research community.
The present research has provided the first quantitative attempt to
clarify this terminological confusion through a data-driven exploration of the literature
surrounding 11 terms:
accommodation,
adaptation,
alignment,
coordination,
contagion,
convergence, entrainment, mimicry, mirroring, synchrony, and synergy.
We incorporated multiple analyses for a converging understanding of the field,
combining frequentist (i.e.,
latent semantic analysis or LSA),
probabilistic (i.e.,
latent
Dirichlet allocation or LDA) and neural networks (i.e., deep learning or DL) perspectives.
Although we have found a number of interesting patterns within the data, we set out in
our analyses to identify (1) underlying dimensions for meaningful clusters in the data and
(2) a term that could be used as a broad indicator of the phenomenon.
We summarize
the most relevant points to each of these two goals below.
2.4.1
Specialization:
Research Questions, not Terms
Different authors present different perspectives on the terminology of interper-
sonal
similarity,
often with conflicting ideas on the specific meanings denoted by each
term.
One perspective is that these terms may represent various theoretical stances.
To
test this idea, we used LSA and LDA to extract the most cohesive groups from the data.
Our results from these complementary analyses suggest that the research domain of the
similarity is a much more salient grouping of the data than the specific used to describe
that similarity.
From analyzing patterns of
author-generated keywords to automatic
topic identification, we consistently find that the abstracts separate by area of study or
type of question, not term.
2.4.2
Broad Usage:
Coordination
Even while some authors insist that there are strong delineations between these
terms, others treat the terms interchangeably.
Still others want to employ broad “um-
brella” terms that can simply identify the phenomena without implying any specific
theoretical stance.
To investigate whether any terms in the literature could be suitable
candidates to fill
such a role,
we explored the connectedness of
the semantic spaces
for the terms.
From these analyses,
we identified coordination and synchrony as two
possibilities.
Converging evidence from three analyses—LSA over
author-generated key-
words,
LSA over abstract text,
and DL over abstract text—support intuitions that
coordination is a broad term with diffuse meaning.
Model results from author-generated
keywords show that coordination and similar words act as “hub” terms, with numerous
moderate connections to many other keywords (including other key terms) but no strong
connections to one another.
Analyses of the abstract text show coordination has a more
diffuse definition in high-dimensional space—not the tightly knit neighborhoods that we
would expect to see with a very specialized term.
21
We find some similar results for the term synchrony, though not entirely iden-
tical.
Interestingly,
the term is surprisingly underrepresented in the author-generated
keywords in the corpus did not appear in the network generated by that semantic space,
so we can only draw conclusions from its appearance in the abstract LSA and DL mod-
els.
Post-hoc tests of these analyses find no significant difference in the distributions of
synchrony and coordination in the DL model
(p = .33),
although synchrony is signifi-
cantly more specialized than coordination in the LSA model (p <.001).
These conflicting
results are interesting given the neighborhood densities (or level
of
specialization) for
each term separately do not significantly differ between DL and LSA models.
This may
suggest that synchrony is approaching the broad use of coordination but with a slightly
more specialized use.
Taken together,
our findings suggest that coordination may be able to serve
as the umbrella term we sought to identify.
Based on its current levels of prevalence,
diffuse meaning, and frequent interconnectedness to other key terms, coordination could
easily be adopted as a broad term to denote the phenomenon without taking a stance on
theoretical issues.
Similar patterns of usage suggest that synchrony—one of the oldest
terms in this field—could fill a similar function, but interesting differences between the
two require further exploration.
2.4.3
Limitations and Future Directions
While an important first step towards a solution,
this work can only be part
of the solution.
Much additional work—including further qualitative (cf.
Butler, 2011;
Delaherche et al., 2012) and quantitative analyses—should be done to help resolve this
issue.
From the quantitative perspective undertaken in the present analyses, the current
work has several limitations that serve as opportunities for future direction.
First,
the underlying reason for this consistency across different models has
not been addressed here.
These terms may be strongly linked to different research
areas because the authors are approaching the question from a particular background
in cognitive science (e.g.,
developmental
psychology,
neuroscience,
social
psychology)
with unique terminological
trends.
(For example,
are similar body movements labeled
as accommodation by linguists and as mirroring by neuroscientsts?) On the other hand,
it could be that the modality under consideration (e.g., affect, language, movement)—
regardless of the author’s specific discipline—is the primary driver of these term groups.
(For example, do both linguists and neuroscientists talk about similar body movement
as synchrony but similar affect as contagion?)
Understanding the reason for these
differences may help come to a better resolution to the current problem.
Second,
the use of
abstracts instead of
entire works may wash out nuances
across the terms and categories.
The 100-word abstract may force researchers to choose
more common terms over their preferred terms in order to communicate with a wider
audience,
or the limited space may instead force researchers to focus simply on their
theoretical
view rather than relating it to other theoretical
stances.
Future work may
compare model results using abstracts only with model results from using entire articles.
Third,
the current efforts could be expanded to include other terms.
While
we have chosen 11 prevalent and/or theory-related terms for the current analysis, other
terms also exist within the research area (e.g., coupling, imitation).
Future work could
expand the scope of these analyses to include these additional
terms—and perhaps to
create a comprehensive list of all terms.
Finally, we understand that these articles are situated within a much broader
(and often highly interdisciplinary) context.
We restricted ourselves only to articles
within this very specific domain of interpersonal similarity in order to get a fine-grained
picture of the field, but understanding the terms’ relation to the larger literature would
22
be incredibly valuable as well.
By looking only at the fine-grained trends,
we may be
missing valuable data that could shed light on how (and why) these different terms are
used.
2.4.4
Conclusion
The study of interpersonal similarity and related behaviors helps us understand
a vital part of human social behavior.
However, this research area is currently plagued
by scattered terminology with little consensus on how these terms fit together.
We turn
metascientific methods into a tool for conscious theory-building that can help resolve an
important issue within this research area.
We present data-driven explorations of the
field that highlight the importance of the research topic—not terminology—in defining
our research area.
After exploring 11 of the most common terms, we propose that coor-
dination could be used as a theory-neutral umbrella term to describe the phenomenon
as the field continues to define itself, its phenomenon, and its terminology.
23
Table 2.1:
Top 10 words included in each topic from LDA analysis over abstracts, ranked
descending by weight.
Each topic’s model-over-model
stability—as a percentage of 10
runs—is included in parentheses under its name.
Topic labels included in quotations
under model-over-model stability.
Topic 1
Topic 2
Topic 3
Topic 4
Topic 5
(100%)
(100%)
(100%)
(100%)
(100%)
“social
theory”
“psycho-
metrics”
“health”
“movement
dynamics”
“interpersonal
communica-
tion”
social
validity
health
coordination
synchrony
research
scale
patients
interpersonal
interaction
processes
factor
treatment
phase
participants
interpersonal
interpersonal
care
movements
task
cognitive
convergent
patient
task
coordination
theory
personality
study
participants
behavior
perspective
measures
family
time
movement
model
measure
data
performance
joint
understanding
self
support
results
social
Topic 6
Topic 7
Topic 8
Topic 9
Topic 10
(90%)
(80%)
(100%)
(90%)
(100%)
“groups
and
teams”
“romantic
relation-
ships”
“neuroscience”
“affect”
“developmental”
group
relationship
social
emotional
children
social
self
brain
social
social
study
women
mirror
participants
age
groups
study
system
self
child
communication
relationships
neural
interpersonal
peer
team
partner
actions
facial
behavior
results
interpersonal
empathy
mimicry
school
performance
sexual
action
emotions
development
trust
men
activity
study
infants
members
sex
cortex
people
early
Chapter 3
PsyGlass:
Capitalizing on
Google Glass for naturalistic
data collection
Cognitive and social
scientists often efficiently leverage commercial
technolo-
gies to enhance behavioral
measurements in experimental
paradigms.
For example,
the ubiquity of
the personal
computer permits easy computer-mouse tracking,
allow-
ing researchers to investigate the continuous dynamics of cognition and decision-making
over time by charting mouse-movement trajectories during computer-based experiments
(e.g., Freeman & Ambady, 2010; Huette & McMurray, 2010; Spivey & Dale, 2006).
As
video game consoles opened their platforms to developers,
researchers have targeted
the Nintendo Wii
and Microsoft Kinect as opportunities for new behavioral
tracking
techniques.
The Nintendo Wii
became an extension of
the mouse-tracking paradigm,
allowing researchers to track free arm movements during choice selection (e.g.,
Dale,
Roche,
Snyder, & McCall,
2008;
Duran,
Dale, & McNamara,
2010),
and the Microsoft
Kinect provided highly affordable motion-tracking of overall body movements and spe-
cific effectors (e.g., Alexiadis et al., 2011; R. A. Clark et al., 2012; Oikonomidis, Kyriazis,
& Argyros, 2011).
Increasing computer availability and online presence has brought op-
portunities for worldwide data collection through services such as Amazon Mechanical
Turk (e.g., Crump, McDonnell, & Gureckis, 2013; Paolacci, Chandler, & Ipeirotis, 2010).
The recent explosion of open mobile application (“app”) development has provided re-
searchers with the opportunity to integrate mobile phone technology into studies in and
out of the lab (e.g., Gaggioli et al., 2013; Henze, Pielot, Poppinga, Schinke, & Boll, 2011;
Miller,
2012;
Raento,
Oulasvirta,
& Eagle,
2009).
These are,
naturally,
just a handful
of examples among many adaptations of technology for research purposes.
Over the past decade,
a new breed of
technology has emerged and is poised
to generate new experimental
and methodological
explorations.
Numerous segments
of the technology industry have moved into wearable technologies as a new avenue for
products and services.
From smart watches to fitness trackers,
these devices offer a
range of
services with a variety of
applications and intended audiences that can be
integrated into behavioral applications (e.g., Goodwin, Velicer, & Intille, 2008; Klonoff,
2014; Picard & Healey, 1997; Starner et al., 1997).
One well-known wearable technology
is Google Glass (Google, Inc.), a multipurpose device worn on the face like glasses (see
Fig.
3.1).
Its range of functionalities and its openness to developers make it a potentially
powerful tool for cognitive and social science research, both in and out of the lab.
Through research-based apps, Google Glass can provide researchers with real-
24
25
Figure 3.1:
Photo of Google Glass (Google, Inc.:
www.google.com/glass )
time control of even very subtle stimuli while unobtrusively tracking various behavioral
measures.
Glass can present wearers with visual stimuli on a small screen just over the
right eye and with audio stimuli
through a bone conduction transducer or proprietary
earbuds.
Wearers navigate Glass through voice command and with a small
touchpad
over the right temple.
The device can capture high-resolution videos and photos,
and
researchers can track wearers’ head movements with on-board three-axis gyroscope and
accelerometer sensors.
Glass also includes on-board memory,
wireless capabilities,
and
Google’s Android mobile operating system.
1
Here,
we first briefly review prior work that has used wearable technologies
broadly and Glass specifically.
We then introduce PsyGlass, our open-source platform for
incorporating Glass into behavioral research that taps into some of these capabilities for
naturalistic experimental work.
As an example application for developing experimental
paradigms with PsyGlass,
we present a simple behavioral
experiment that uses Glass
both to present visual stimuli to participants and track participants’ movements during a
naturalistic interaction task.
We end with a list of recommendations for using PsyGlass,
our goals for expanding its capabilities, and a brief discussion of how wearable technology
can contribute to behavioral research.
1
This information is current as of
December 2014 and describes the Glass Explorer model
(ver-
sion 2).
Detailed specifications
are
freely available
through Google
Developer’s
Glass
resources
(http://developers.google.com/glass).
26
3.1
Research opportunities for wearable technologies
Wearable technologies can give researchers the opportunity to track and quan-
tify behavior in new ways.
As technology has miniaturized while becoming more power-
ful, cognitive and social scientists have already begun looking for ways to incorporate it
into research paradigms (e.g., Goodwin et al., 2008).
Wearable technology is still a rel-
atively underutilized methodology,
but a growing number of researchers have adopted
it in some behavioral
and health-related domains.
Although some of
the capabilities
provided by other wearable technologies may not be possible to implement with Glass,
we here provide a brief history of wearable technology research, to establish wearables’
existing foundation in research and to spark ideas for the kinds of questions to which
Glass (and PsyGlass) could be applied.
3.1.1
Previous research with wearable technology
Interest in wearable technology in research-related settings has existed for quite
some time.
However, until recent advances in developer-friendly commercial technology
such as Google Glass,
many researchers have had to engineer their own wearable so-
lutions.
For instance,
affective researchers have been engineering wearable solutions
to track and classify affect for nearly two decades (e.g.,
Lee & Kwon,
2010;
Picard &
Healey,
1997).
Since then,
wearable technology has spread to other domains–most no-
tably,
to the health sciences (e.g.,
Moens et al.,
2014;
Moens,
van Noorden,
& Leman,
2010; for a review, see Pantelopoulos & Bourbakis, 2008).
One of the most prominent examples of wearable technologies in the behavioral
sciences to date has been the sociometric badge, developed to provide a host of metrics
on individual
and group behaviors (e.g.,
Lepri
et al.,
2012;
Olgu´ın Olgu´ın,
Gloor,
&
Pentland,
2009;
Olgu´ın Olgu´ın,
Waber,
et al.,
2009;
Pentland,
2010;
Waber et al.,
2011).
The sociometric badge has been applied most heavily in analyses of workplace
behavior and interactions (e.g., for describing a research network in Lepri et al., 2012; or
in a hospital in Olgu´ın Olgu´ın, Gloor, & Pentland, 2009), exploring connections between
workplace activities and social factors in largely observational-style studies.
For more on
sociometric badges and related work, see the review articles by Olgu´ın Olgu´ın, Waber,
et al. (2009) and Waber et al. (2011).
3.1.2
Existing work utilizing Google Glass
Over the past year,
there has been growing excitement about applying Glass
in research,
although the majority of published scientific work to date comprises com-
mentaries.
To the authors’
knowledge,
Glass has been featured in only one published
experimental study in the behavioral sciences (Ishimaru et al., 2014).
However, interest
in Glass has surged in other research areas, especially the health sciences.
The health sciences are arguably one of
the areas most interested in Glass,
particularly as assistive tools.
Recent commentaries have touted possible uses for Glass
in laboratories (Chai
et al.,
2014;
Parviz,
2014) or as assistive devices (Hernandez &
Picard,
2014).
From surgical
assistance (Armstrong,
Rankin,
Giovinco,
Mills,
& Mat-
suoka,
2014) to dietary tracking (Mauerhoefer,
Kawelke,
Poliakov,
Olivier,
& Foster,
2014) to perceptions of health-related Glass use (McNaney et al.,
2014),
many prelim-
inary integrations of Glass into the medical and health sciences have capitalized solely
on existing Glass capabilities without additional
app development.
Only a handful
of
researchers have developed specialized apps with a variety of health science applications,
such as facilitating food shopping (Wall, Ray, Pathak, & Lin, 2014), augmenting conver-
sation for individuals with visual
impairment (Anam,
Alam,
& Yeasin,
2014a,
2014b),
and assisting biomedical technicians (Feng et al., 2014).
27
Other research areas have also begun to incorporate Glass,
albeit to a lesser
extent than in the health sciences.
To the authors’ knowledge, only Ishimaru et al. (2014)
have incorporated Glass into cognitive science,
2
investigating how blink patterns and
head movements can be used to categorize wearers’ everyday activities.
In the domain of
human-computer interaction, He, Chaparro, and Haskins (2014) have developed a Glass
app called “USee” that can be used to facilitate usability testing,
providing separate
components for participants, researchers, and other observers.
Despite this rising interest, the programming requirements for developing Glass
apps could pose a significant barrier to entry for many cognitive and social
scientists.
Our goal is to lower this barrier by providing a framework for incorporating Glass that
can be adjusted to individual
research needs.
By opening the application to commu-
nity development,
we hope to promote the important ethos of shared resources and to
encourage others to grow the application with us.
3.2
PsyGlass:
A framework for Glass in behavioral
research
Google Glass provides behavioral,
cognitive,
and social
scientists with many
methodological and measurement possibilities as a research tool.
Glass can simultane-
ously present stimuli and track various behavioral metrics, all while remaining relatively
unobtrusive,
cost-effective,
and portable.
However,
developing research apps for Glass
currently requires researchers to develop projects entirely on their own.
We believethat
a centralized resource with functioning example code and guidance through the devel-
opment process could make Glass more accessible to a wider scientific audience.
To that end, we have created PsyGlass, an open-source framework for incorpo-
rating Google Glass into cognitive and social science research.
All code for the PsyGlass
framework is freely available through GitHub (GitHub,
Inc.:
www.github.com),
allow-
ing the research community to use, expand, and refine the project.
The code is jointly
hosted by all
three coauthors and can be found in the PsyGlass repository on GitHub
(http://github.com/a-paxton/PsyGlass).
PsyGlass facilitates data collection and moment-to-moment experimenter con-
trol
over
stimuli
on connected Glass
devices.
Currently,
PsyGlass
supports
single-
participant or dyadic research, although it can be adapted to include additional partic-
ipants.
The framework (see Fig.
??) includes a Web-based experimenter console and
specially designed Glassware (i.e., a Glass app) built using Android Studio (Google, Inc.;
http://developer.android.com/sdk/).
PsyGlass currently presents only visual data and
collects only accelerometer data, although we are working to expand data collection and
stimulus presentation to other modalities, as well (see the Future Directions section).
3.2.1
PsyGlass experimenter console
The experimenter console is a streamlined Web interface that allows the ex-
perimenter to manipulate connected Glass visual
displays (see Fig.
3.3).
The console
provides separate controls for up to two Glass devices, allowing the experimenter to up-
date text and the background color displayed to each.
With relatively basic JavaScript
capabilities,
experimenters may modify the console as desired to provide more auto-
mated solutions for one or more connected devices (e.g., presenting colors or words from
a list at random).
2
Some of the cited works from the health sciences have had behavioral components, but such works
are primarily focused on health and/or medical applications.
28
Figure 3.2:
PsyGlass framework flow and the programming and/or markup languages of
each component (listed in parentheses).
In the experimenter console’s current form, the
researcher can use it to update visual displays on one or more connected Glass devices
while collecting accelerometer data from each
The console also manages the connection between the server and the Glass.
The experimenter can use the console to open the initial
server connection for the
Glass.
Once all
Glass devices are connected,
the experimenter can initiate the data
collection session simultaneously across all devices to ensure time-locked data collection
and stimulus presentation.
The console provides the experimenter with updates about
each server-Glass connection (e.g.,
latency) while the Glass devices are connected to
the server.
Once data collection is finished, the console allows the researcher to end the
data collection session (again, simultaneously across all connected devices) and close the
server connection for both Glass devices.
3.2.2
PsyGlass Glassware
The PsyGlass Glassware allows the experimenter to update the visual
dis-
play on the basis of stimuli
sent from the experimenter console while recording three-
dimensional accelerometer data.
Once the server connection has been opened from the
console,
the wearer (or the experimenter) can initiate the server-to-Glass connection
with the Glassware.
After the console opens the data collection session, the Glassware
regularly checks the server (by default at 4 Hz, or every 250 ms) to check for visual dis-
play updates issued from the console.
Time-stamped x,
y,
z accelerometer sensor data
are logged on a local text file every 4 ms (250 Hz, by default) until the data collection
session has been ended.
After data collection has finished, the experimenter can upload the accelerom-
eter data stored locally on the device to the server.
Collecting and storing the data on
the Glass helps prevent overheating of the device and preserves battery life,
but data
could be streamed continuously to the server with some changes to the PsyGlass frame-
work.
Data are saved to the server as a tab-delimited text file.
To save space on the
device, the previous session’s data are deleted locally once a new data collection session
is initiated.
More information on the Glassware workflow is included in the Appendix.
29
Figure 3.3:
PsyGlass experimenter console.
From here,
the experimenter can manage
the connection between the connected Google Glass device(s) and the server,
initiate
data collection sessions, and update the Glass screen(s) with text and/or color
3.2.3
Potential applications for PsyGlass
Although our initial interest in Glass grew from our studies of bodily synchrony
during face-to-face dyadic interaction (Paxton & Dale, 2013a), it can be easily adapted
for other settings.
For example,
researchers interested in humans’
exploration of their
environment might track movement while providing visual cues on the display, whereas
a study on language production might introduce distractors or incongruent lexical items
on participants’
screens.
In dyadic studies,
researchers can use Glass to support naive
confederate designs:
A lexical cue or prearranged visual signal (e.g., color, shape) could
serve as an instruction to lie to their partner during a conversation or to act confused
while completing a map task.
These are,
of
course,
only a few brief
examples,
but
they highlight one of the most compelling features of PsyGlass:
targeted control over a
participant’s stimuli on the fly, even in highly naturalistic settings.
To demonstrate how PsyGlass can be used to facilitate behavioral
research,
we present data below from an experiment investigating how individuals compensate
for distraction during conversation.
3
This preliminary study demonstrates how Glass
may open opportunities for new experimental designs with distinct theoretical implica-
tions.
We believe that Glass presents a unique opportunity for interpersonal behavioral
research,
given its commercial
availability,
4
relative affordability,
and array of sensing
capabilities.
The experimental
design,
data collection procedures,
and data analysis
provide a concrete example of
how PsyGlass can be deployed to extend theory-rich
questions into new domains.
3
These data are part of a larger ongoing research project investigating how interaction is affected by
various contextual pressures.
4
The protocol
for purchasing Google Glass has changed.
Further information is provided in the
General Discussion.
30
3.3
Example PsyGlass application:
Convergence dur-
ing interaction
Interpersonal convergence or synchrony broadly describes how individuals be-
come increasingly similar over time while they interact (e.g.,
Shockley et al.,
2009).
Previous research suggests that one benefit of convergence may be to help individuals
overcome impoverished communication signals.
For instance,
individuals’
head move-
ments synchronize more strongly during conversation with high ambient noise, as com-
pared with conversation in an otherwise silent room (Boker,
Rotondo,
Xu,
& King,
2002).
These findings support the idea that interpersonal convergence may be vital to
comprehension (e.g., D. C. Richardson & Dale, 2005; Shockley et al., 2009), perhaps by
serving as a scaffold to support key aspects of the interaction in a synergistic account
of interpersonal
coordination (e.g.,
Riley et al.,
2011;
Fusaroli
et al.,
2012;
Dale et al.,
2014).
Building from Boker and colleagues’ (2002) findings in the auditory domain, in
the present study we tested whether low-level visual distractors—analogues to auditory
distractors—increase interpersonal
movement synchrony during friendly conversations.
We compared participants’
head movements during conversation (a) combined with a
dual-task paradigm and (b) in the presence of “visual noise.” Using PsyGlass, we were
able to present visual stimuli separately to each participant while surreptitiously collect-
ing high-resolution head movement data.
We anticipated that dyads would synchronize
more during the “noise” condition (cf.
the auditory noise in Boker et al.,
2002).
We
chose the dual-task condition as a comparison condition that could decrease interper-
sonal synchrony, given a constellation of previous findings (e.g., regarding working mem-
ory and synchrony in Miles et al., 2009; and working memory and dual-task paradigms
in Phillips, Tunstall, & Channon, 2007).
3.3.1
Method
Setting up PsyGlass
Once our experiment was designed,
we took a series of
steps to set up the
technical
foundation for PsyGlass.
As a dyadic interaction study,
we prepared two
Glass devices,
one for each participant.
First,
the native Java code for PsyGlass must
be compiled onto the Glass devices.
The Java code distributed on GitHub (linked above)
can be compiled in the Glass software development kit environment (called the “GDK”);
Google’s documentation for this process is quite thorough.
5
Second,
to accompany
PsyGlass on the Glass devices, we developed JavaScript code that controls the PsyGlass
experimenter console.
This JavaScript code (also included on GitHub) controls the
nature and timing of the stimuli
(described below).
Third,
we installed the PHP code
on a server that coordinates data collection through the experimenter’s browser in order
to share the Glass devices’
data with the server.
Importantly,
this setup requires that
the experimenter’s computer and the two Glass devices be connected to the Internet
during the entire experiment.
Participants
In return for course credit,
30 undergraduate students from the University of
California, Merced, participated as 15 volunteer dyads, none of whom reported knowing
one another.
Each dyad was randomly assigned to either the noise (n = 7) or the dual-
task (n = 8) condition.
Due to connectivity issues,
one dyad’s data (from the noise
5
For a quick demonstration, see https://developers.google.com/glass/develop/gdk/quick-start.
31
condition) were removed from the present analyses,
since fewer than 3 min of
usable
movement data were recorded.
(See the notes about connectivity issues in the General
Discussion.)
Materials and procedure
After completing several
questionnaires (not analyzed here),
the participants
were seated facing one another in two stationary chairs approximately 3 feet 2 in.
away
from one another in a semi-enclosed space within a private room.
Both chairs were
seated in profile to a small
table with an iMac 27-in.
(Apple,
Inc.)
computer several
yards away, from which the experimenter would run the PsyGlass experimenter console
in the following experiment.
Participants were then given 3 min to get acquainted
without the experimenter present.
Once the experimenter returned,
each participant was given a Google Glass
with the PsyGlass Glassware and went through a brief setup process to become familiar
with the device.
The experimenter first described the Glass to the participants (i.e.,
explaining what the display and touchscreen were) and helped the participants properly
fit the Glass to their faces.
The experimenter then verbally guided participants through
initializing the PsyGlass Glassware, providing the participants some experience with the
device before beginning the experiment.
The experimenter tested participants’ ability to
fully see the Glass by ostensibly checking its connection, using the PsyGlass experimenter
console to present participants with either one word (i.e.,
“Glass” or “test”) or color
(i.e., red code #FF0000 or blue code #0000FF) and asking them to report what change
they saw on their screen.
Crucially,
all
dyads were then told that their Glass display would switch be-
tween blue and red during the experiment.
To implement this,
we created a version
of the PsyGlass experimenter console that updated the screen color once per second (1
Hz), with a .9 probability of a blue screen and a .1 probability of a red screen.
6
Dyads
assigned to the dual-task condition were told to remember each time the screen turned
red and that they would be asked to write down that number at the end of
the con-
versation.
This condition is akin to a dual-task oddball paradigm (Squires,
Squires, &
Hillyard,
1975).
Dyads assigned to the noise condition were told that these switching
colors were due to a bug in the programming and that they could ignore the changing
screen during their conversation.
All
dyads were then asked to hold an 8-min conversation with one another
about popular media and entertainment (mean length = 8.12 min).
After the remainder
of the experiment,
7
participants were thanked and debriefed.
Analyses
Data were trimmed to exclude the calibration and instruction periods, retaining
only the conversational data.
The mean length of recorded movement data was 7.7 min
(range = 4.17-8.86 min), largely due to connectivity errors in two of the included dyads.
We converted the x, y, z accelerometer data for each participant into Euclidean distances
to create a single metric of head movement over time, and then applied a second-order
Butterworth filter to smooth the data.
Cross-correlation coefficients (r ) served as our
metric of
interpersonal
synchrony,
since they have been a fairly common metric for
synchrony in previous research (e.g., D. C. Richardson, Dale, & Tomlinson, 2009).
Cross-
correlation provides a measure of the influence between individuals across windows of
6
If
the updated color was the same as the current color,
the screen did not appear to change or
flicker.
7
Which included subsequent
conditions
not
analyzed here,
beyond the
scope
of
the
current
demonstration.
32
time:
By correlating individuals’ time series at varying lags, we could measure the degree
to which individuals were affecting one another more broadly.
Following from previous
research (Ramseyer & Tschacher,
2014),
we calculated cross-correlation r s within a ±
2,000-ms window
3.3.2
Results
The data were analyzed primarily using a linear mixed-effects model.
The
random-effects structure (using random slopes and intercepts) was kept as maximal as
possible (Baayen, Davidson, & Bates, 2008; Barr, Levy, Scheepers, & Tily, 2013).
Dyad
membership was included as the sole random effect.
The condition was dummy-coded
prior to inclusion (0 = noise,1= dual-task ).
All
other variables—including interaction
terms—were centered and standardized (Baayen et al., 2008) prior to being entered into
the model.
This model
served two purposes:
(a) to replicate previous findings of
time-
locked synchrony of head movements during conversation (Ramseyer & Tschacher, 2014)
and (b) to explore whether low-level
visual
distractors would negatively impact that
synchrony relative to increased working memory load.
The model
predicted r —our
measure of interpersonal synchrony or convergence—with lag (± 2,000 ms) and condition
(dual-task = 1) as independent variables.
As anticipated, increases in lag significantly predicted decreases in r, providing
evidence for in-phase interpersonal
synchrony of head movements during conversation
(β = –.50, p <.0001).
The main effect of lag indicated that partners’ head movements
were most strongly correlated at lag 0—that is,
in moment-to-moment comparisons.
The correlation decreased as the time series were compared at increasingly disparate
points.
However,
contrary to our hypothesis,
we found no significant difference be-
tween the noise and dual-task conditions (β = .19,
p >.30),
nor a significant effect
of
the interaction term (β = –.03,
p >.60).
In fact,
the trend suggests that the op-
posite might be the case,
with the dual-task condition being associated with higher
cross-correlation coefficients (see Fig.
3.4).
A two-sample t -test of
the centered and
standardized cross-correlation coefficients only at lag 0 showed a marginally significant
increase in interpersonal synchrony during the dual-task condition, t (13) = –2.1, p <.06.
3.3.3
Discussion
In the present study, we explored how interpersonal dynamics during natural-
istic conversation are affected by environmental
factors.
Inspired by previous work in
the auditory domain (Boker et al.,
2002),
we investigated how visual
distractors and
increased working memory load differentially affect interpersonal
synchrony by using
PsyGlass to quantify head movements.
Although we replicated previous findings of head movement synchrony gener-
ally (Ramseyer & Tschacher, 2014), we found conflicting evidence for the impact of these
conditions on synchrony.
Although the longer-range convergence was not significantly
different between the two conditions, moment-to-moment (i.e., in-phase) synchrony was
marginally higher in the dual-task condition,
contrary to our expectations.
These un-
expected results could have several
implications for this literature,
to be disentangled
with follow-up work.
First,
the results could suggest that—although higher working
memory load may increase lag-0 synchrony—convergence unfolds similarly over a longer
timescale, regardless of the nature of the external visual stimuli.
Second, these findings could suggest a reframing of the conditions in the present
study as compared with those used by Boker et al. (2002).
Rather than interpreting the
33
Figure 3.4:
Interaction plot of the linear mixed-effects model for our sample application,
predicting interpersonal synchrony (r :
y-axis) as a function of condition (blue = noise,
orange = dual task) across lags of ± 2,000 ms (x -axis).
auditory noise as a distractor, it might in fact have been more similar to the dual-task
condition than the visual-noise condition:
Both ambient noise and the dual
task may
be more task relevant and less easily ignored during conversation than the irregular
blue-to-red screen switches.
Perhaps the key element is that distractors should in some
way be unavoidable during interaction.
3.4
Using PsyGlass:
Recommendations and limita-
tions
Below we compile a number of
recommendations and limitations to consider
when using Google Glass with PsyGlass.
These items to consider should be useful
for
practical concerns about experimental design and data analysis with PsyGlass.
No prior Android experience is required,
although it can be helpful.
Prior
experience with programming of
some kind can be incredibly beneficial,
especially in
Java.
However,
resources for Glass,
Android,
Java,
and JavaScript programming are
widely available online through various online tutorials and forums.
Note that compiling
PsyGlass will
require following the basic GDK instructions (see the Method section
above).
Troubleshooting modifications to PsyGlass can take time, especially for those
new to Android and Glass development.
Those new to Android coding should first famil-
iarize themselves with the basic PsyGlass program and start with incremental changes
to the code,
building to larger extensions.
Numerous developer resources for Android
and Glass are available through third-party sources (e.g., programming forums, tutorial
websites) and Google Developers (Google, Inc.:
https://developers.google.com/).
In its current form,
PsyGlass is very battery-intensive.
Researchers may con-
sider reducing the computational
strain (e.g.,
by reducing the sampling rate) if
using
the application for extended periods of time,
to preserve battery life.
In our example
34
experiment,
PsyGlass actively ran for a maximum of
20 min per data collection ses-
sion.
8
By charging the Glass devices for up to 20 min between data collection sessions,
we were able to run up to four back-to-back data collection sessions without battery
problems.
We imagine that this pattern could continue for longer but cannot say so
from experience.
The on-board computer for Glass (which sits alongside the wearer’s right tem-
ple) can become quite warm to the touch after extended intensive use or charging.
Al-
though a very small number of participants commented on this warmth, no participants
reported it as being uncomfortable,
even when the Glass had been in use or charging
for up to 3 h before their data collection session.
Because the Glass display does not have an opaque backing,
nearby parties
may be able to see some of the stimuli presented on the Glass display.
Bright colors are
the most easily noticeable, being recognizable from farther away than 45 feet.
9
Although
the presence of most text or shapes is perceivable from approximately 90 in., large text
and shapes are somewhat identifiable as close as 21 in.
and are distinctly readable by
around 14 in.
away.
Small text, however, is unreadable even at 6 in.
Researchers should
take this into account and perform preliminary tests to ensure that it will not impinge
on the experimental goals (e.g., during deception-based tasks).
However, we have heard
reports of
others attaching lightweight backings to the Glass,
which may serve as a
solution in these cases.
Although Google Glass is designed to be worn over regular glasses,
it can
be somewhat difficult for some wearers to comfortably wear Glass while being able to
easily see the entire screen.
In some cases—like our color-based example study— being
able to see most of
the screen clearly should suffice.
However,
this may be an issue
for experimental
designs relying on text-based prompts or stimuli.
Researchers may
consider altering their experimental
design or restricting participant eligibility in such
cases.
Many participants will likely have had little to no prior experience using Google
Glass.
Anecdotally, many of our participants commented on how “exciting” or “weird”
Glass was.
We recommend that researchers at least briefly introduce Glass to partici-
pants before beginning the experiment.
An introduction to Glass minimizes participants’
awkwardness with the device and reduces the chance that participants will
interfere
with key Glass capabilities during the experiment (e.g., by brushing the touchpad).
Re-
searchers may use our protocol—reported in the Materials and Procedure section—as a
guide.
The framework is currently designed to protect data transfer between the server
and connected Glass devices.
Therefore, problems with wireless Internet connections can
cause PsyGlass to terminate the data collection session or disconnect the Glass from the
server entirely.
All
data prior to termination are still
saved locally on the device.
By
prioritizing connectivity,
PsyGlass is able to ensure that all
commands are executed
as intended,
but this may be an issue for individuals who have unreliable or difficult
wireless networks.
This can currently be changed by reprogramming PsyGlass, and we
hope to release an alternate version that is more forgiving in this area.
Researchers may consider applying down-sampling procedures,
band-pass fil-
ters,
or moving averages for their data analysis,
depending on project needs and the
standard practices of
relevant target research area(s).
The high-resolution movement
data provide high statistical
power for time series analyses,
but this power may not
always be needed.
An example of
data manipulation and filtering has been provided
above in the Analyses section.
8
Due to additional conditions outside of the scope of the present article.
9
Measured from the nose of wearer to the nose of viewer in a well-lit room, with the viewer having
normal, uncorrected vision.
35
3.5
General discussion
Wearable technology can provide researchers with opportunities to explore nat-
uralistic behavior dynamics both in and out of the lab.
PsyGlass capitalizes on Google
Glass to give researchers a stimulus presentation and data collection tool
in an eas-
ily customizable,
open-source framework.
We have provided an example application
of
PsyGlass to dyadic interaction research,
but the paradigm is open to single-
and
multiparticipant studies.
We welcome other researchers to join us in using or expand-
ing PsyGlass on GitHub (www.github.com/a-paxton/PsyGlass).
The openness of
the
Google Glass developer community stands as a resource for researchers interested in
tapping into other dimensions of the Google Glass, from audio stimulus presentation to
eye-camera recording.
3.5.1
Update regarding purchasing Google Glass
Google has recently shifted the Glass program to focus more on developers and
enterprise needs through its “Glass at Work” program
(https://developers.google.com/glass/distribute/glass-at-work).
At the time of
writ-
ing,
those interested in purchasing Glass for research or educational
needs may con-
tact the Glass at Work program at glass-edu@google.com.
Any changes or additional
relevant information will
be included on the readme file at the PsyGlass repository
(http://github.com/a-paxton/PsyGlass).
3.5.2
Future directions for PsyGlass and wearable technology
Wearable solutions like PsyGlass and other tools (e.g.,
Olgu´ın Olgu´ın,
Gloor,
& Pentland, 2009) are helping researchers increase external validity and target the real-
world behaviors that they are interested in exploring.
Especially for complex behaviors
like interaction,
researchers must balance experimental
controls with experimental
de-
signs targeting naturalistic behaviors.
By providing wireless,
portable,
minimalistic
behavior tracking,
wearable technology can unobtrusively quantify behavioral
metrics
and give moment-to-moment control
over stimulus presentation.
These represent an
addition to our tools for creating naturalistic,
externally valid experiments that tap
into the real-world behaviors we seek to capture.
With PsyGlass, we hope to lower the
barriers to entry for other researchers who are interested in capitalizing on these new
opportunities.
In that vein, we intend to continue to expand PsyGlass as a methodological tool
that can contribute to theoretical
inquiry.
Our basic goals include tapping additional
Glass capabilities for data collection (e.g., gyroscope, eye-camera capture) and stimulus
presentation (e.g., audio) to give researchers more experimental design and multimodal
options.
We have already created optional modules to implement lexical decision tasks
on PsyGlass, available on GitHub.
We hope to provide a suite of collection and presen-
tation options that others can use to cobble together versions of PsyGlass that fit their
needs.
Our first goal for major expansion is to create a way for partners’ Glass devices
to be interactively updated by each another—for instance,
by having the amplitude of
movement of one Glass (measured by the accelerometer) update the visual stimuli of a
second, connected Glass.
In doing so, PsyGlass can subtly prompt interaction dynamics
and alter interpersonal
behaviors on the basis of
prespecified events.
By putting the
code onto an open community for programmers, we hope to encourage others to join us
in our expansion and refinement of the PsyGlass tool.
36
3.6
Author note
We thank UC Merced undergraduate research assistants Keith Willson, Krina
Patel,
and Kyle Carey for their assistance in data collection for the example PsyGlass
application.
3.7
Appendix
3.7.1
Accessing PsyGlass Glassware (see Fig.
3.5)
Through the touchpad
Navigate to the Home card.
Tap once to view a list of commands.
Navigate
to “Show Demo” and tap once.
If
you are not immediately taken to the PsyGlass
immersion, navigate to “Sample Experiment” and tap once.
Through voice commands
Say “ok glass.” A menu with a list of voice commands will pop up.
Say “Show
me a demo with.”
If
you are not immediately taken to the PsyGlass immersion,
say
“Sample Experiment.”
3.7.2
PsyGlass Glassware data collection flow (see Fig.
3.6)
Main activity
This is the first activity with which the user is presented.
The user sees the
title card and is prompted to tap the device for options.
Tapping the device brings up
an options menu with two items:
“Start” and “Settings.” Selecting the first option takes
the user to the Game Activity,
and selecting the second takes the user to the Settings
Activity.
Swiping down on the device will return the user to the Google Glass timeline.
Game activity
This is the activity in which the actual
experiment and data collection take
place.
First, the device attempts to connect to the server, which must first be initiated
from the experimenter console.
Once connected, it will continuously poll the server for
updates, and the server guides the device through the data collection session.
During the
session, the server dictates when the device should start collecting data, when it should
change the display of
the device,
and when to stop collecting data.
Data collection
involves writing accelerometer sensor readings to a text file on a local device.
Tapping
the device brings up the options menu with the “Finish” item.
Selecting this item forces
the device to close its connection to the server,
close the sensor,
finish writing to the
text file, and return the user to Main Activity.
Settings activity
This activity presents the Data card, which contains four fields with informa-
tion.
The first field shows the device ID, given to the device by the server at the start of
the most recent experiment; device ID numbers begin at 0 and are assigned sequentially
according to server connection order.
The second and third fields show the date and
time of when the session of the experiment was conducted.
The fourth field shows the
duration of the session of the experiment conducted.
These fields on the card will
be
empty if no experiment has been conducted on the device.
Tapping on the device with
37
this card active will
bring up an options menu with the “Upload Data” item,
which
allows the user to upload the data collected from the latest experiment.
Selecting the
item takes the user to the Upload Activity.
Swiping down on the device will return the
user to Main Activity.
Upload activity
This is the activity in which the application uploads data to the server.
The
application prepares the internal
text file containing experimental
data and streams
the content to the server.
Tapping on the device brings up the options menu with the
“Cancel
Upload” item.
Selecting this item will
close the text file,
close the connection
to the server, and return the user to Settings Activity.
38
Figure 3.5:
PsyGlass Glassware flow for navigating to the data collection study (“Main
Activity”).
The Main Activity can be accessed in two ways:
navigating with the touch-
pad (Path A) or through voice commands (Path B).
39
Figure 3.6:
PsyGlass Glassware flow for initializing and terminating data collection (left;
“Game Activity”) and for uploading the session data to the server (right;
“Settings
Activity” leading to “Upload Activity”).
Chapter 4
Context–dependent gaze
coordination
4.1
Introduction
Decades of research on interpersonal coordination highlight the interconnected-
ness of the human social experience.
From holding a conversation to solving a puzzle, we
tend to become more similar over time in our speech (e.g., Niederhoffer & Pennebaker,
2002), affect (e.g., Randall et al., 2013), and movement (e.g., Chartrand & Bargh, 1999)
through our shared experience.
This similarity stretches across time scales, from correla-
tions of the moment-to-moment fluctuations in a behavior (e.g., Hove & Risen, 2009) to
overarching patterns in the statistical distributions of a behavior over time (e.g., Abney
et al., 2014).
Although coordination appears to be nearly ubiquitous, growing work is begin-
ning to establish limiting parameters.
Communicative context—the type of interaction
in which individuals are engaged—may be one crucial parameter that modulates inter-
personal coordination.
For example, compared to friendly interactions, conflict decreases
coordination (e.g.,
Paxton & Dale,
2013a).
The present study contributes to crucial
unanswered questions about what might be driving these context-dependent changes in
coordination.
4.1.1
Interpersonal Coordination, Rapport, and Comprehension
Despite vast evidence for the existence of coordination, its purpose is relatively
less well
understood.
While the overarching nature of coordination is being currently
being debated (cf.
Riley et al., 2011; Abney et al., in press; Pickering & Garrod, 2004;
Lakin et al., 2003), there are several properties of coordination that have received rela-
tively widespread acceptance.
In the present work, we examine two of these properties:
the relation of coordination to social bonding and to comprehension.
First, coordination is closely tied to social bonding.
Previous research consis-
tently supports a bidirectional
link between coordination and rapport.
Both low-level
(e.g., Hove & Risen, 2009) and higher-level (e.g., Chartrand & Bargh, 1999) motor co-
ordination increases liking and rapport.
Similarly, greater liking and rapport improves
coordination (e.g., Lakin & Chartrand, 2003;
Giles et al., 1991).
Although the specific
details and mechanisms of this relationship may be under some dispute, coordination is
widely acknowledged as both rapport-building and rapport-reflective.
Second,
coordination is linked to comprehension.
A large portion of
this re-
search has focused on gaze coordination specifically, demonstrating how important the
40
41
timing of joint visual attention is to understanding.
Gaze coordination has been causally
linked to comprehension (D.
C.
Richardson & Dale,
2005) and is sensitive to shared
experiences and other forms of
common ground (e.g.,
D.
C.
Richardson et al.,
2012;
D.
C.
Richardson,
Dale,
& Kirkham,
2007;
D.
C.
Richardson et al.,
2009).
Other
forms of coordination can also increase or facilitate comprehension, even while working
together with gaze coordination (e.g., linguistic coordination; Dale et al., 2011).
Inter-
estingly, even intrapersonal
coordination during speaking—the subtle, congruent timing
of
gesture and speech to complement one another—increases listener comprehension
(Woodall & Burgoon, 1981).
While this idea is pivotal to some theories of coordination
(e.g.,
Garrod & Pickering,
2009;
Pickering & Garrod,
2013),
the ties to understanding
are commonly accepted as an important property of coordination.
4.1.2
Conflict and Coordination
Traditionally,
research on interpersonal
coordination has tended to focus on
task-based (e.g., Dale et al., 2011), affectively neutral (e.g., Condon & Sander, 1974), or
affiliative (e.g., Chartrand & Bargh, 1999) interactions.
This body of work has provided
us with important insights into how we move (e.g.,
Chartrand & Bargh,
1999),
feel
(e.g.,
Randall
et al.,
2013),
work (e.g.,
Dale et al.,
2011),
and talk (e.g.,
Niederhoffer
& Pennebaker,
2002) together.
Conflict,
by contrast,
has been relatively understudied
within research on interpersonal coordination.
While conflict may be one of the most negative and unpleasant communicative
contexts (Bell
& Song,
2005),
it follows us through our lives and social
experiences
(Birditt,
Fingerman,
& Almeida,
2005).
Understanding its effects on the subtle but
nearly omnipresent threads of coordination will help better characterize not only conflict
specifically but coordination and interaction more broadly.
To that end,
recent efforts
have begun to explore how conflict changes coordination (e.g.,
Paxton & Dale,
2013a;
Abney et al., 2014).
Congruent with the idea that interaction is a highly adaptive complex system
(e.g., Shockley et al., 2009; Abney et al., in press; Riley et al., 2011), conflict appears to
drastically alter the structure of interpersonal
coordination across multiple modalities.
The subtle gross motor movement coordination usually seen in conversation disappears
during conflict (Paxton & Dale, 2013a), and co-speech decreases significantly compared
to friendly conversation (Paxton & Dale, 2013c).
Even longer-scale distribution of speech
turns becomes more dissimilar (Abney et al., 2014).
Interestingly, conflict can increase
dysfunctional
coordination patterns:
Stronger conflict is linked to increased coordination
of negative affect (Main et al., under review).
Together, these findings suggest that conflict’s inherent negativity (Bell & Song,
2005) and associated difficulties with perspective-taking (Frantz & Janoff-Bulman, 2000)
may clash with the rapport-building effects of coordination (e.g., Hove & Risen, 2009).
However,
the reasons for these changes—especially the breakdown of
coordination in
movement and speech—are poorly understood.
The present study explores potential
causes by targeting a new domain for research in conflict and coordination:
gaze.
4.1.3
The Present Study
The present study explores the context-sensitivity of
gaze coordination.
We
take the view that conversation is a complex adaptive system (Paxton et al., in press).
As such,
patterns of
gaze coordination should be sensitive to various individual
and
interpersonal environmental constraints (e.g., goals; Shockley et al., 2009).
Here,
we examine conversational
context as one possible environmental
con-
straint.
The present study explores whether congruency of opinion—either agreeing or
42
disagreeing with a given opinion—will modulate gaze coupling between speakers and lis-
teners.
However, as the first explicit exploration of conflict’s effects on gaze coupling,
1
we approached the study with competing hypotheses about two possible outcomes.
In
both cases,
we anticipate that coupling between speakers and listeners will
be slightly
time-lagged;
listeners should demonstrate the same gaze dynamics as the speaker but
with a slight delay (D. C. Richardson & Dale, 2005).
Gaze coordination (or coupling) between speakers and listeners has been causally
linked to increased comprehension (D.
C.
Richardson & Dale,
2005).
A proposed
mechanism for this coordination is tied to the effects of
language on joint attention
(D. C. Richardson et al., 2007):
As speakers allude to objects within the environment,
listeners attend to the relevant object while processing incoming speech.
Therefore, we
may see that gaze coordination is not affected by the communicative contexts under
consideration here.
One hypothesis (H
1
) is that gaze coordination remains unchanged,
regardless of opinion congruency.
H
1
:
Gaze coupling between listeners and speakers with congruent opinions
should not significantly differ from gaze coupling between listeners and speakers
with incongruent opinions.
At the same time, conflict is associated with a sharp decrease in coordination
other communication channels (e.g., Paxton & Dale, 2013c, 2013a; Abney et al., 2014).
We may find that conflict or disagreement has a similar effect on gaze;
the driving
mechanism behind gaze coupling (e.g., joint attention) may also be sensitive to high-level
cognitive constraints.
Accordingly, the second hypothesis (H
2
) is that gaze coordination
decreases
for incongruent opinions (i.e.,
disagreement),
as compared with congruent
opinions (i.e., agreement).
H
2
:
Gaze coupling between listeners and speakers with congruent opinions
should be significantly higher than gaze coupling between listeners and speakers
with incongruent opinions.
A major goal
of
the current study is to help shed light on the mechanisms
leading to the decrease in coordination during conflict.
If
our results support H
2
,
it
may suggest that conflict may be characterized by a fundamental lack of understanding.
Essentially,
under this perspective,
the lack of
coordination we see in movement and
speech may reflect a lack of
common ground,
perspective-taking,
or other cognitive
alignment.
The failure to be “on the same wavelength” may resonate through the
interpersonal system, disrupting coordination.
However,
if
our results support H
1
,
it may suggest that the breakdown in
coordination that we see in other behaviors during conflict is not due simply to a lack of
comprehension.
Again,
given the causal
link between comprehension and coordination
(D. C. Richardson & Dale,
2005),
we may find that interlocutors are perfectly capable
of comprehending their partner.
Viewing conversation as a complex adaptive system,
not all perturbations will affect each subsystem similarly; support for H
1
would suggest
that the mechanisms underlying gaze coupling are resilient in the face of conflict.
4.2
Method
4.2.1
Participants
Participants were 50 undergraduate students from the University of California,
Merced (mean age = 20.12 years;
females = 30).
All
received course credit as com-
1
D.
C.
Richardson et al.
(2009) examined gaze coupling during discussions of controversial
topics,
but differences of opinion between interlocutors were not analyzed.
43
Table 4.1:
Summary of total speaker data.
Breakdown of percentage of speakers (with
n in parentheses) in each opinion of each topic, along with whether speakers showed a
majority of one opinion on a topic (“dominant-view”) or whether speakers’ opinions were
relatively equally divided between the two (“mixed-view”).
Asterisk indicates majority
opinion in “dominant” topics.
Topic Class
Topic
Opinion
Speakers
dominant-view
abortion
neither
11.1% (n = 3)
pro-choice *
74.1% (n = 20)
pro-life
14.8% (n = 4)
higher taxes for rich Americans
against
22.2% (n = 6)
for *
66.7% (n = 18)
neither
11.1% (n = 3)
legalizing marijuana
against
18.5% (n = 5)
for *
77.8% (n = 21)
neither
3.7% (n = 1)
marriage equality
against
3.8% (n = 1)
for *
92.3% (n = 24)
neither
3.8% (n = 1)
mixed-view
death penalty
against
50% (n = 13)
for
42.3% (n = 11)
neither
7.7% (n = 2)
“junk food” tax
against
56% (n = 14)
for
44% (n = 11)
lowering U.S. drinking age
against
50% (n = 13)
for
50% (n = 13)
pensation.
All
participants reported conversational
fluency in English and normal
or
corrected-to-normal hearing and vision.
Each participant was recruited as a member of
one of
two groups:
speakers
(included n = 4;
females = 3) and listeners (n = 46;
females = 27).
An additional
18 participants were recruited as listeners (with similar demographic characteristics)
but were not included because of technical
problems during data collection.
Technical
problems during data collection also resulted in the loss of some segments for some of the
included 46 listeners (mean trials per included listener = 8.74; mean included listeners
per segment = 40.2).
4.2.2
Materials and Procedure
After the informed consent process, all experimental procedures were performed
through SMI’s Experimenter Center software (version 3.5;
SensoMotoric Instruments,
2015).
Participant gaze was tracked throughout the experiment with SMI’s RED-m re-
mote eye tracker.
The eye tracker was calibrated once at the beginning of the experiment
and was re-calibrated prior to each topic.
All participants first completed a brief demographics survey and a sociopolit-
ical
questionnaire.
Similar to some of our previous work (Paxton & Dale,
2013a),
the
questionnaire asked participants to write their opinions about seven (7) topics with neu-
trally worded prompts, presented in random order:
abortion, legalization of marijuana,
the death penalty,
marriage equality,
2
“junk food” tax,
lowering the U.S. drinking age
to 18 years old,
and whether rich Americans should be taxed at a higher rate.
After
2
Described to participants as “gay and lesbian marriage.”
44
writing his or her opinion in an open-response text box, each participant then indicated
his or her opinion strength for that topic on a 1 (feel very weakly ) to 4 (feel very strongly )
scale.
These seven topics formed the foundation of
the current experimental
mate-
rials.
During each of
the target trials (described below),
participants were shown a
collage about each topic.
Each collage comprised six (6) images (all of relatively similar
size) balanced for valence,
size,
and visual
information.
Participants in the speaker
group viewed each collage while producing a persuasive monologue about the topic.
Participants in the listener group viewed each collage while listening to one of the re-
lated persuasive monologues produced by a participant in other group.
We describe the
unique features of data collection for each group below.
Speakers
After completing the demographics survey and opinion questionnaire, speakers
were given written instructions to explain their opinions about several topics out loud.
Speakers were instructed to discuss only the given topic and very related topics during
each monologue,
to take as much time as needed to fully explain their opinion,
and to
try to be as persuasive as possible.
These instructions were presented before beginning
the monologue production phase and again on each slide presenting a new topic.
All
topics were presented in random order.
Twenty-seven (27) students participated in this phase for course credit,
al-
though equipment error resulted in the loss of some monologue topics for some speakers
(see Table 4.1).
From these data,
we selected only the most passionate,
persuasive
monologue for each side of
each topic as stimuli
for the listener phase.
Two trained
research assistants blind to study hypotheses rated each monologue on two,
five-point
scales (i.e.,
passion and persuasiveness).
The 5-point scales were then collapsed into
ratings of
low (1-2),
medium (3),
and high (4-5).
Linear-weighted Cohen’s kappa—a
measure of
interrater reliability—between the two raters reached .72 for passion and
.75 for persuasiveness.
Of the 27 total speakers, 20 gave permission to use their mono-
logues as stimuli in the next phase.
We narrowed these released monologues to include
only those that lasted at least 80 seconds and were rated as high in both passion and
persuasiveness by both raters.
(We refer to these as “candidate monologues” below).
Unexpectedly, we found that 4 of the 7 topics failed to solicit monologues rated
as high in passion and persuasiveness by both raters:
abortion, legalization of marijuana,
marriage equality,
and taxation of rich Americans.
In these topics,
at least two-thirds
(66.7%) of speakers endorsed a single side (see Table 4.1).
The remaining 3 topics were
represented by roughly equal numbers of monologues on each side of the topic across all
speakers and included candidate monologues on both sides of the issue.
We will
refer
to the former as dominant-view topics and to the latter as mixed-view topics,
due to
the distribution of opinions on the topic in our sample.
We discuss this further in the
Analysis section.
From the candidate monologues,
we identified 10 monologues from 4 speak-
ers (as reported in the Participants section).
Some topics and/or sides of topics were
represented by only one candidate monologue;
in these cases,
we used this monologue.
If multiple candidate monologues existed for one side of any given topic,
we chose the
stimuli
to maximize the number of
unique speakers in our stimuli
and to control
for
monologue length.
For the dominant-view topics with multiple candidate monologues,
we selected monologues that were close in length to the mean duration of
the chosen
stimuli for the other 3 topics.
45
Listeners
After completing the demographics survey and opinion questionnaire, listeners
were told that they would be listening to a number of
other people’s opinions about
various topics and that they would be asked questions immediately following each opin-
ion.
All listeners were then presented each of the 10 monologues—presented in random
order—by over-ear headphone.
Immediately following each monologue,
listeners were
asked five (5) randomized Likert-style questions about the monologue, including a ques-
tion of how much the listener agreed with the speaker overall (from strongly disagree [1]
to strongly agree [4] ).
4.2.3
Analyses
Planned Analyses
We quantified the coordination between speakers’ and listeners’ gaze patterns
during each monologue using cross-recurrence quantification analysis,
a nonlinear data
analysis technique that quantifies similarities in states between signals.
As with
D. C. Richardson and Dale (2005), the present study is interested in exploring the sim-
ilarities between the gaze time series of speakers producing a monologue and listeners
hearing the same monologue.
Essentially,
CRQA allows us to explore whether partici-
pants’ gaze patterns explored similar regions of the screen over time.
CRQA views the
speaker-listener pair as a system and characterizes that system with a variety of different
parameters.
For more on CRQA and recurrence quantification analysis, Marwan (2008)
and Coco and Dale (2014) provide excellent reviews.
We performed CRQA between the speaker and each listener for each mono-
logue (cf.
D.
C.
Richardson & Dale,
2005).
We designated areas of
interest (AOIs)
for each image in each collage.
Speaker and listener gaze patterns relative to these
AOIs were downsampled from 120 Hz to 100 Hz.
We then performed CRQA over each
listener-speaker time series pair using the crqa package (Coco & Dale,
2014) in R (R
Development Core Team, 2008).
The resulting recurrence rate quantifies to what degree
the speaker and listener gaze patterns were coupled during the monologue.
Our planned analyses primarily explore differences in coordination patterns by
opinion congruence (i.e., listener’s agreement or disagreement with the speaker).
Using
CRQA as our measure of gaze coupling, we will examine how and whether the relative
time course (i.e., lag) of gaze dynamics is affected by the higher-level cognitive conditions
of opinion congruence.
Exploratory Analyses
As mentioned in the Materials and Procedure section, we found an unexpected
pattern in the speaker monologues:
Some topics clearly had a dominant opinion, while
views of
other topics were split across roughly equal
numbers of
speakers (see Table
4.1).
Because we did not expect to find these differences in the distributions of speaker
opinions,
we did not begin the experiment with hypotheses about differences between
dominant-view and mixed-view topics.
However,
we believed that exploring these dif-
ferences could shed light on whether the broader social
environment—either itself
or
through an interaction with personal opinion—alters patterns of gaze coordination.
This
could provide important insights into how larger-scale social context might shape indi-
vidual dynamics.
Importantly,
we do not claim that (1) the dominant-view topics nor (2) the
majority opinion within the dominant-view topics identified in our sample are themselves
universally dominant.
We recognize that there are a wide variety of opinions on these
46
topics and that distributions over these opinions likely differ by region and community.
Using the opinions of
the community from which our speaker sample was taken,
the
present analysis may shed light on how majority opinions
broadly—rather than the
specific opinions included here—might shape gaze dynamics.
4.2.4
Data Preparation
Given participant freedom method afforded by the desktop-mounted eye tracker,
our data—especially the listener data—were characterized by significant portions of
missing data (i.e.,
eye tracking samples in which participants’
gaze were recorded as
looking at something other than the computer screen).
On average, listening trials were
missing gaze data for approximately 33% of possible samples (again,
taken at 100Hz).
We believe this is due to two parameters of the task.
First, the unobtrusive eye tracker
allows listeners to engage in naturalistic gaze and movement patterns rather than re-
stricting them to look only at the screen.
All participants were told that they would be
eye-tracked during the experiment, but we included no explicit instructions to look only
at the screen, since we did not want to change their natural gaze patterns.
Second, the visual stimuli were abstractly related to the audio clips, but they
were not as concretely related as previous similar work (cf.
pictures of
characters in
the speaker’s narrative; D. C. Richardson & Dale, 2005).
As a result, these images may
have been somewhat less compelling to the listener.
This may have exacerbated the first
concern,
as participants may have been less invested in looking at the accompanying
images.
We dealt with these missing data by matching speakers and listeners for each
time point for each pair.
For each pair, we then excluded any time points at which either
speaker or listener had missing data.
Unfortunately, this problem led us to exclude all
data for the “against” side of the “lowering U.S. drinking age” segment, but the mean
number of listeners per included segment was identical (M = 40.2).
These missing samples also lead to interesting concerns with interpretations of
the CRQA analyses.
CRQA is typically used to explore the timing of
events relative
to one another, using the sampling rate as a means of anchoring the relative time scale
(cf.
D.
C.
Richardson & Dale,
2005;
Main et al.,
under review).
In order to interpret
CRQA analyses in this way, the time series over which CRQA was calculated must have
largely regular, reliable sampling.
The missing data in our time series therefore preclude
us from making any strong claims about the interpretation of such timing.
Instead of
interpreting the timing of the lag, we will only be able to address the relative dynamics
over time—whether broad, time-free patterns in coordination change as the relative time
between listener and speaker gaze events increases or decreases.
4.3
Results
To quantify coordination,
we relied on recurrence (%rec) within a window of
±300 samples, consistent with previous research (D. C. Richardson & Dale, 2005; Paxton
& Dale, 2013a; Abney et al., in press).
Listeners’ self-reported Likert-style ratings were
dummy-coded into a dichotomous variable of
broad disagreement (0;
originally,
1-2)
and broad agreement (1;
originally,
3-4).
Agreement ratings were skewed positively:
Listeners self-reported broad agreement with the speaker in 67.7% of all 362 ratings.
4.3.1
General Patterns
Our first analyses of general recurrence patterns largely focused on two metrics
of CRQA: maximum recurrence and maximum lag.
Maximum recurrence simply takes
47
the maximum recurrence value (%rec) of each speaker-listener gaze time series within the
±300-sample window.
Maximum lag is the relative lag at which maximum recurrence
occurred for each speaker-listener pair.
A one-sample t -test showed that the maximum lag for all speaker-listener pairs
was significantly different from 0, t (361) = 31.17, p <.0001.
Separate t -tests confirm that
these differences hold for both agreement (t (244) = 26.19, p <.0001) and disagreement
(t (116) = 16.99, p <.0001).
This supports previous research that finds a reliable delay
between speakers’ and listeners’ coupled gaze patterns (D. C. Richardson & Dale, 2005).
Similar results hold for tests of
maximum recurrence.
A one-sample t -test
showed that maximum recurrence for all
speaker-listener pairs significantly differ from
0, t (322) = 30.89, p <.0001.
Again, t -tests confirm these patterns hold during listener
agreement (t (217) = 27.73, p <.0001) and disagreement (t (104) = 15.68, p <.0001).
A one-sample t -test showed that the maximum lag for all speaker-listener pairs
was significantly different from 0, t (361) = 37.63, p <.0001.
Separate t -tests confirm that
these differences hold for both agreement (t (244) = 34.63, p <.0001) and disagreement
(t (116) = 18.75, p <.0001).
This supports previous research that finds a reliable delay
between speakers’ and listeners’ coupled gaze patterns (D. C. Richardson & Dale, 2005).
Despite visual
trends (see Figure 4.1),
we find no reliable differences in max-
imum lag and maximum recurrence by opinion congruence.
Mean maximum lag was
317.59 samples for listener agreement and 286.92 samples for listener disagreement.
Mean maximum recurrence was 0.24 for listener agreement and 0.27 for listener dis-
agreement.
Two separate linear mixed-effects models
3
revealed no significant effect of
congruence played in predicting maximum recurrence (B = -0.02, p = .44) but found a
trend towards a significantly higher maximum lag (i.e.,
longer delay) in agreement (B
= 34.99, p = .10).
4.3.2
Planned Analyses
After the brief exploration of basic patterns and differences, we moved on to our
planned analyses.
Data were analyzed with a series of linear mixed-effects models using
audio clip and listener as non-nested random intercepts with maximal allowable random
slopes.
All variables—including interaction terms—were centered and standardized prior
to being entered into these models.
Standardizing the data allows the resulting β values
to be interpreted as effect sizes (cf.
Keith, 2005).
Linear mixed-effects models were built
with the lme4 package (Bates, M¨
achler, Bolker, & Walker, 2015) in R (R Development
Core Team, 2008).
The first model predicted recurrence (%rec) with opinion congruence and lag.
Neither the main effect of lag (β = .05, p = .19) nor the interaction of lag and opinion
congruence (β = -.03, p = .43) reached statistical significance.
The main effect of opinion
congruence (β = .003, p = .07) trended toward but did not reach significance.
Given the nonlinear shape of the data (see Figure 4.1), we used growth curve
analyses to model the unfolding of the data over lag (Mirman, Dixon, & Magnuson, 2008;
Mirman, 2014).
While growth curve analyses emerged to model patterns over time (e.g.,
Paxton,
Roche,
& Tanenhaus,
2015),
it can also be used to model
patterns in relative
time or lag (e.g., Main et al., under review).
In the next model, we include linear (first-
order orthogonal
polynomial) and quadratic (second-order orthogonal
polynomial) lag
terms.
Including both first- and second-order orthogonal
polynomial
terms decouples
linear and quadratic lag from one another, allowing each to be interpreted independently
in the model results (Mirman et al., 2008).
As mentioned earlier, we cannot interpret the
time course of these effects precisely due to the missing data, but the time-free relative
patterns reflected in the analyses should provide insight into the gaze dynamics.
3
With maximal random intercepts for listener and audio clip.
48
Figure 4.1:
Gaze coordination by lag and opinion congruence between speakers and
listeners.
Shaded bars indicate standard error.
Second-order polynomials are fitted (in
black) over each group.
Negative lag indicates a listener-leading trend in gaze patterns;
positive lag indicates a speaker-leading trend.
Plot generated in R (R Development Core
Team, 2008) with ggplot2 (Wickham, 2009).
49
Our second model predicted %rec with opinion congruence, linear lag, quadratic
lag, and all possible two-way interactions.
(We chose not to include the three-way inter-
action to simplify interpretability of all possible effects.) Main effects for linear lag (β =
.02, p = .54), quadratic lag (β = -.01, p = .82), and opinion congruence (β = -.002, p =
.98) all failed to reach statistical significance, as did the interaction term between linear
and quadratic lag significance (β = -.002,
p = .50).
However,
the two-way interaction
terms for opinion congruence with linear lag (β = .01, p <.0001) and quadratic lag (β
= -.01,
p <.005) both reached significance with relatively small
but reliable effects on
gaze coupling.
Taken together,
results from our planned analyses partially support both H
1
and H
2
.
As demonstrated in Figure 4.1, the significant interaction term between opinion
congruence and quadratic lag is indicative of a tighter temporal coupling of gaze in the
agreement condition.
The interaction between linear lag and opinion congruency further
supports the existence of a stronger effect of temporal coupling among those who agree:
While there may be more pervasive coupling for listeners who disagree,
there appears
to be a sharper jump in coupling around synchrony (lag 0) with the speaker’s gaze.
In
other words, although disagreement does not significantly decrease the overall amount of
gaze coordination (supporting H
1
),
we do find that agreement the moment-to-moment
unfolding of the gaze dynamics by leading to a tighter temporal coupling at a faster rate
(supporting H
2
).
4.3.3
Exploratory Analyses
Our next set of
analyses explored how topic class—whether opinions on the
topic are dominated by a single view or are relatively equally distributed across multiple
perspectives—influences gaze coupling.
As with our models in the Planned Analyses
section, we analyzed the data with a series of mixed-effects models, with all terms having
been centered and standardized prior to model creation.
All models were created with
the maximal random effects structure permitted to achieve convergence.
The first exploratory model predicted %rec with lag, opinion congruence, and
topic class,
along with all two-way interactions.
(Again,
the three-way interaction was
not included in order to simplify interpretations of results.) Lag (β = .02, p = .58), topic
class (β = .11,
p = .34),
and opinion congruence (β = .01,
p = .85) failed to achieve
significance as main terms in the model.
The model also found no significant effects of
the interaction terms between topic class and lag (β = .006, p = .80) and topic class and
opinion congruence (β = -.006, p = .91).
The interaction of lag and opinion congruence
again contributed a small but reliable effect to the model (β = .01, p <.0001).
The second exploratory model
included linear and quadratic lag terms (as
described previously), opinion congruence, topic class, and all possible two-way interac-
tions.
In this model,
we again find significant effects only for the interaction between
linear lag and opinion congruence (β = .01,
p <.0001) and quadratic lag and opinion
congruence (β = -.006,
p <.0001).
All
other effects failed to reach significance in the
model (all ps >.40).
The results from these two models suggest that the general
social
consensus
around a given topic—that is, whether the topic is currently contentious within a specific
social
environment—does not account for our observed effects of gaze coordination in
the current dataset.
Results suggest that personal
agreement or disagreement plays a
more important role in characterizing the gaze dynamics than does the wider social
consensus at the time.
50
4.4
Discussion
During conversation, the ability to coordinate attention is crucial to mutual un-
derstanding.
However, different communicative contexts bring with them unique inter-
personal (and intrapersonal) pressures.
While the major goal in listening to a story may
simply lie in following the narrative arc, responses to charged sociopolitical opinions—
especially opposing opinions—may not be so straightforward.
The current research is
the first to explore this idea by quantifying gaze coordination between speakers and
listeners in unscripted persuasive monologues.
While previous research supports the importance of gaze coordination during
storytelling narratives (D.
C.
Richardson & Dale,
2005),
the present work addresses
how personal
opinion affects how gaze coordination.
We began with two competing
hypotheses:
that gaze coupling would be unaffected in the face of
disagreement (H
1
)
or that gaze coupling would be significantly lower in the face of
disagreement (H
2
).
The results of several models partially supported both competing hypotheses.
While we
found no significant effect of opinion congruence on the overall amount of gaze coupling,
we did find that a listener’s gaze tended to be more tightly coupled in time to the
speaker’s when he or she agreed with the speaker’s opinion.
4.4.1
Coordination in Conflict
This pattern of results supports the idea of coordination as being an emergent,
context-sensitive property of
interaction (Paxton et al.,
in press).
Previous work has
found that conflict decreases coordination of body movement (Paxton & Dale,
2013a)
and speech (Abney et al., 2014), but the present analyses suggest that conflict (or dis-
agreement) may not exert a universal coordination-breaking effect on behaviors.
Instead,
we find that rates of gaze coupling are no different in agreement than in disagreement—
with a trend toward significantly higher
recurrence in disagreement.
Therefore,
the
present work suggests that the gaze system is robust to conversational
context as a
perturbation.
The subtle differences between gaze patterns across opinion congruence sug-
gest that we cannot attribute the decrease in coordination observed in other behavioral
channels (e.g., Paxton & Dale, 2013a; Abney et al., 2014) to simple misunderstanding or
failure to coordinate attention.
Given the causal
link between gaze coupling and com-
prehension (D.
C.
Richardson & Dale,
2005),
if the effects of argument were reducible
to a failure in comprehension,
we would expect to find some evidence of
this in the
gaze coupling data.
However,
the current data cannot support simple communication
breakdown as the explanation for conflict’s negative effects on other types of behavioral
coordination.
While this single study cannot completely rule out lack of
understanding as
a contributor to breakdown in coordination observed during conflict,
its lack of effect
in the present study may help suggest alternative mechanisms.
For example,
previous
studies on conflict and coordination have relied on studies of face-to-face interaction (e.g.,
Paxton & Dale, 2013a; Abney et al., 2014), standing in contrast to the present study’s
non-interactive contexts.
Social dynamics (e.g., saving face, pro forma social behavior)—
which may be functionally nonexistent when sitting and listening to a recording by
oneself—may therefore be a good candidate for the decrease in coordination observed
during conflict.
4.4.2
Understanding Gaze Coordination
In addition to deepening our understanding of
coordination’s context sensi-
tivity, the present work also contributes to research of gaze coordination more broadly.
51
There are several salient differences between the present study and the previous work on
which we are building (D. C. Richardson & Dale, 2005).
First—and most importantly—
the present study used naturalistic, unplanned persuasive monologues with tangentially
related visual stimuli, rather than images of characters directly related to the speaker’s
narrative.
The different nature of the visual stimuli in the present study may contribute
to the relatively lower amount of gaze coupling found in the present data (cf.
maximum
recurrence of .14-.16 in D. C. Richardson & Dale, 2005).
Second,
the free-form nature of the current monologues may have provided a
less linear structure than a narrative arc based on an episode of
a mutually familiar
television sitcom.
The images presented to participants here were abstractly related to
the topic,
but in our careful
listening to these audio clips,
we found very few (if any)
explicit references to any of
the images by speakers.
Furthermore,
the images were
not deeply related to one another beyond the broad topic at hand.
This may have
led to a less predictable stimulus for listeners,
further decreasing the amount of
gaze
coordination.
Despite these differences, however, we still find gaze coupling between speakers
and listeners in the present study.
This suggests that gaze coordination is robust (but
still sensitive) to the informativeness and richness of the visual environment.
Even in the
face of the relatively less explicitly informative or salient visual information, listeners and
speakers spontaneously couple their gaze, supporting previous claims of the importance
of gaze coordination to communication (D. C. Richardson & Dale, 2005).
4.4.3
Limitations and Future Directions
The current work has several
limitations.
First,
listeners were overall
more
likely to report broad agreement with a speaker’s opinion than broad disagreement.
By asking listeners to report whether they agreed or disagreed with each monologue,
we allowed their opinions to be somewhat “fuzzy”:
Listeners could report agreeing with
both sides of an issue.
This allows for a much more flexible and realistic understanding of
opinion formation and beliefs, but the skewed agreement distribution should nevertheless
be controlled or addressed in future studies.
Future work may attempt to get more equal
distributions of agreement with opinions,
perhaps using more opinionated populations
(e.g., those with strong political affiliations) or more polarizing topics.
It may also be useful
to question listeners more thoroughly on the nature
of this agreement or disagreement,
perhaps by asking them why exactly they agree or
disagree.
Although we solicited listeners’ written opinions about these topics before they
began the listening phase,
we chose to rely on listeners’
own self-reports of agreement
or disagreement.
A close examination of
possible differences between initial
stances
and later agreement ratings could provide interesting insights into patterns of opinion
flexibility and cognitive processes.
The second major limitation lies in the missing gaze time series data.
The desk-
mounted eye tracker we used allows us to capture more naturalistic gaze behavior, but
that freedom can lead to more limited data.
Future data analysis may consider video-
recording listeners to account for their behavior.
For example, there may be interesting
interactions between opinion congruence and a listener’s willingness to engage with the
on-screen stimuli.
Recording participants’ behavior would provide important additional
data to dive more deeply into these questions.
Finally, future work may also include presenting highly persuasive monologues
for non-dominant perspectives in dominant-view topics as well.
While we provided
some preliminary analyses of topic class (i.e., dominant- vs.
mixed-view topics), none of
our speakers produced sufficiently persuasive non-dominant perspectives for dominant-
view topics.
Comparing gaze dynamics during strong opinions on each side of
both
52
topic classes is needed to rule out possible alternative explanations for our exploratory
analysis models.
4.4.4
Conclusion
Gaze coupling between speakers and listeners plays a vital
role in facilitating
communication by increasing understanding.
Here, we present evidence that gaze cou-
pling is robust to personal opinion.
Using spontaneously generated persuasive opinions
about controversial
topics,
we found that disagreeing with someone else’s opinion did
not lead to lower overall
amounts of gaze coupling.
Our findings stand in contrast to
previous findings that coordination of
other behaviors—like speech and movement—
decrease during disagreement and conflict.
We see our results as further support for
viewing coordination as an emergent, context-sensitive property of interaction.
4.5
Acknowledgements
We would like to thank research assistants Alex Lau,
Nicolas Rodriguez,
and
Amanda Varela for their help in creating collage stimuli and research assistants Neekole
Acorda, Nicole Hvid, Krina Patel, Pooja Patel, and Keith Willson for their help in data
collection.
Chapter 5
Discussion
5.1
Introduction
Research on interpersonal coordination provides valuable insights into an essen-
tial part of human behavior and the human social experience.
However, as a relatively
new research area,
coordination still
faces numerous important issues.
Many of
these
issues are tightly linked,
and effective solutions to the problems will
address multiple
issues from interdisciplinary perspectives.
This dissertation has addressed three important current problems within the
interpersonal
research area from such a perspective.
Chapter 2 used computational
modeling and large-scale data analysis tools for a data-driven analysis of nearly a dozen
related terms within the field.
Chapter 3 presented an open-source method for extending
experimental control and objective quantification of behavior in naturalistic paradigms.
Finally,
Chapter 4 applied eye tracking—a classic cognitive science research method—
to support the view of coordination as an emergent property of conversation.
Below, I
summarize the important findings and contributions from each of these chapters.
5.2
Data–Driven Explorations of Terminology
One of the single biggest problems facing coordination research is—arguably—
the confusion over the terms used to describe the phenomenon and how these terms
relate to one another.
We can find research under over a dozen different terms,
from
alignment
to synergy.
To make matters worse,
nearly all
of
these terms are used in
wildly different contexts with a host of subtle meanings,
with no clear or agreed-upon
understanding of their relations to one another.
This problem has a variety of serious
consequences for the field,
like creating isolated pockets of findings for different terms
with very little cross-pollination among them.
At least two qualitative attempts have been made to create taxonomies related
to this research area.
Both Delaherche et al.
(2012) and Butler (2011) tied their work
closely to the methodology used to study the phenomenon,
but each did so within
separate realms.
Butler’s analysis largely focused on affective similarity and influence;
Delaherche et al.
took a wider view of
the field.
Both of
these were excellent,
useful
works, but both were subjective interpretations of the terminological landscape.
Chapter 2 contributes a quantitative perspective on this issue.
The paper—
which will be submitted for publication with coauthor Rick Dale—capitalizes on large-
scale text analysis tools for an objective look at the uses of these terms across the research
area.
We collected and analyzed a novel corpus of over 2,500 abstracts on interpersonal
53
54
coordination and 10 other common and/or theory-related terms with two broad goals.
We sought to identify (1) the dimensions that best characterized differences within this
field and (2) a few possible terms that could be possibly be used as theory-free catch-all
terms to describe the phenomenon.
To achieve these goals,
we analyzed the corpus with three complementary
analyses:
latent semantic analysis (Landauer et al.,
1998),
latent Dirichlet allocation
(Griffiths & Steyvers,
2004),
and deep learning methods (Mikolov,
Sutskever,
et al.,
2013).
In line with our first goal for the paper, we explored the semantic space to identify
natural groups among the data broadly.
Our results pointed to research topic—whether
researchers are studying similarity in language,
movement,
or neural
activity—as gen-
erating the most descriptive clusters within the data.
We found that the meanings of
these terms, then, were not as well-defined as some claim.
In keeping with our second goal,
after comparing the existing usage patterns
for each term across the corpus,
we identified coordination as the best candidate for a
general
term,
with synchrony as a potential
second.
We chose the term based on its
relatively diffuse (i.e., not specialized) meaning across the research area, along with its
hub-like connections with numerous other terms.
Hopefully,
proposing an “umbrella”
term based on properties of
current use will
facilitate its adoption,
even if
only as a
relatively blunt tool while the field grapples with a more refined solution to the problem.
Beyond its
immediate relevance to the field of
interpersonal
coordination,
Chapter 2 also serves as a proof
of
concept for the usefulness of
scientometric anal-
yses for conscious theory-building.
Previous work has already established the value of
scientometrics in characterizing science writ large (e.g.,
Griffiths & Steyvers,
2004) or
within a broad domain of science (e.g., Bergmann et al., accepted) Rather than supplant-
ing careful
thought and reasoning,
this chapter provides an example of the usefulness
of
corpus analysis tools in better understanding a single subfield of
research through
data-driven insights.
5.3
Developing and Deploying Methods
A constellation of
important concerns surrounding the current methodology
of the research area can broadly be grouped into two clusters.
First,
we must balance
concerns of external validity with the need for experimental control.
Many researchers
have developed clever and resourceful solutions to this problem (e.g., Miles et al., 2010),
but we must continue to find new ways of
facilitating careful
experimental
control
in
naturalistic settings.
Second,
we need to find unobtrusive,
scalable,
and resource-effective methods
to objectively quantify interpersonal coordination.
While the field is moving away from
labor- and time-intensive hand-coding analyses (cf.
Condon & Sander,
1974),
possible
replacements have been adopted relatively slowly.
Ideally, these new alternatives should
be relatively affordable, easily implemented, and widely available to provide a low bar-
rier to entry for interested researchers of
all
experience levels,
skill
sets,
and funding
capabilities.
Especially given the importance of timing to the phenomenon,
we must take
advantage of the growing availability of relatively cheap computational power to achieve
these goals.
Doing so will allow the field to move toward automatic objective analysis of
movement, speech, affect, and other behavioral channels while minimizing investments of
time and funds.
One prime candidate for such methods, then, lies in wearable technology.
Toward that end,
my collaborators and I developed PsyGlass (Paxton,
Ro-
driguez, & Dale, 2015), an open-source application for Google Glass to facilitate natu-
ralistic experimental designs.
This project pairs a commercially available product with
collaborative-friendly code to provide researchers with strong experimental control and
55
high-resolution data collection.
PsyGlass can easily be tailored to a variety of situations,
but it was specifically created to facilitate our study of interpersonal coordination.
Chap-
ter 3 of this dissertation presented PsyGlass,
a brief history of wearable technology in
cognitive science-related research, and a brief example of how PsyGlass can be deployed
in a study of interpersonal coordination.
5.4
Building Theory through Experiments
Within research on interpersonal
coordination,
a relatively new but rapidly
growing perspective views coordination as an emergent property of conversation,
pro-
posed to be a complex dynamical
system (e.g.,
Riley et al.,
2011;
Dale et al.,
2014;
Fusaroli & Tyl´en, 2012).
One idea associated with this perspective, then, is that coor-
dination should be context-sensitive, adapting and responding to the pressures exerted
by the environment.
Previous experimental
work has found support for this idea by
noting context-induced changes in the function and appearance of coordination in body
movement (Paxton & Dale,
2013a),
speech (Abney et al.,
2014),
language (Fusaroli
et
al., 2012), and more.
In my final chapter, I present experimental evidence—to be sub-
mitted with coauthors Rick Dale and Daniel C. Richardson—that explores the context-
sensitivity of gaze coordination.
Previous work has shown that speakers’
and listeners’
gaze patterns become
coordinated (or coupled)—albeit with a brief delay—during interaction.
For example,
D. C. Richardson and Dale (2005) found that participants who are listening to a recorded
narrative about a television sitcom episode will
exhibit the same gaze patterns as the
speaker who produced the monologue (with an approximately 2-second delay).
Further-
more, gaze is an incredibly interesting test case for the context-sensitivity of coordination
given its causal link between gaze coordination and understanding (D. C. Richardson &
Dale, 2005).
Chapter 4 extends these findings to explore gaze coordination during disagree-
ment.
Combining gaze and conflict allows us to simultaneously examine the context-
sensitivity of gaze coordination and investigate a possible mechanism for the decrease
in behavioral coordination often seen in conflict (e.g., Paxton & Dale, 2013a; Abney et
al., 2014).
To answer these questions, we recorded persuasive monologues on 7 contentious
sociopolitical
topics,
along with the gaze patterns of the speakers.
We later presented
these recorded monologues to other participants while tracking their gaze and then
asked the listeners to rate their agreement with each speaker.
Analyzing these data
with CRQA,
we find that—while the overall
levels of gaze coordination are not signif-
icantly different—we do find evidence for more tightly-coupled gaze between speakers
and listeners at peak coordination.
Our results suggest that gaze coordination is largely
robust but still
somewhat
sensitive to disagreement as a conversational
context.
Our
findings also suggest that the coordination-reducing effects of argument cannot be solely
explained by a lack of understanding between speaker and listener.
5.5
Conclusion
The research area around interpersonal coordination is poised to yield unique
insights into questions of human communication, interaction, and social behavior.
As a
field, interpersonal coordination still has immense room to grow—providing an exciting
challenge to interdisciplinary researchers.
Interpersonal
coordination is facing an ex-
plosion of interest in recent years,
making these challenges even more urgent.
Here,
in
collaboration with various coauthors, I have presented three projects that address some
56
of the key theoretical, methodological, and experimental issues facing the research area
today.
Rather than seeing each of them as separate concerns, I view development along
these three dimensions—theory,
methods,
and experimental
research—as inextricably
linked to one another and to the field’s continued growth.
References
Abney, D. H., Paxton, A., Dale, R., & Kello, C.
(in press).
Movement dynamics reflect
a functional
role for weak coupling and role structure in dyadic problem solving.
Cognitive Processing.
Abney,
D.
H.,
Paxton,
A.,
Dale,
R.,
& Kello,
C.
T.
(2014).
Complexity matching
in dyadic conversation.
Journal
of
Experimental
Psychology:
General ,
143 (6),
2304–2315.
Alexiadis, D. S., Kelly, P., Daras, P., O’Connor, N. E., Boubekeur, T., & Moussa, M. B.
(2011).
Evaluating a dancer’s performance using Kinect–based skeleton tracking.
In Proceedings of the 19th acm international
conference on multimedia (pp. 659–
662).
New York, NY, USA: ACM.
Anam,
A.
I.,
Alam,
S.,
& Yeasin,
M.
(2014a).
Expression:
A dyadic conversation
aid using Google Glass for people with visual impairments.
In Proceedings of the
2014 acm international
joint conference on pervasive and ubiquitous computing:
Adjunct publication (pp. 211–214).
Anam, A. I., Alam, S., & Yeasin, M. (2014b). Expression:
A Google Glass based assistive
solution for social signal processing.
In Proceedings of the 16th international
acm
sigaccess conference on computers & accessibility (pp. 295–296).
New York,
NY,
USA: ACM.
Aral,
S.,
Muchnik,
L.,
& Sundararajan,
A.
(2009).
Distinguishing influence-based
contagion from homophily-driven diffusion in dynamic networks.
Proceedings of
the National
Academy of Sciences, 106 (51), 21544–21549.
Armstrong, D. G., Rankin, T. M., Giovinco, N. A., Mills, J. L., & Matsuoka, Y.
(2014).
A heads–up display for diabetic limb salvage surgery a view through the Google
looking Glass.
Journal
of Diabetes Science and Sechnology, 951–956.
Ashton-James,
C.,
van Baaren,
R.
B.,
Chartrand,
T.
L.,
Decety,
J.,
& Karremans,
J.
(2007).
Mimicry and me:
The impact of
mimicry on self-construal.
Social
Cognition, 25 (4), 518–535.
Baayen,
R.
H.,
Davidson,
D.
J.,
& Bates,
D.
M.
(2008).
Mixed–effects modeling with
crossed random effects for subjects and items.
Journal
of Memory and Language,
59 (4), 390–412.
Babel, M. (2010). Dialect divergence and convergence in New Zealand English. Language
in Society, 39 (4), 437–456.
Bangerter, A., & Clark, H. H. (2003). Navigating joint projects with dialogue. Cognitive
Science, 27 (2), 195–225.
Barr,
D.
J.,
Levy,
R.,
Scheepers,
C.,
& Tily,
H.
J.
(2013).
Random effects structure
for confirmatory hypothesis testing:
Keep it maximal.
Journal
of
Memory and
Language, 68 (3), 255–278.
Barsade, S. G. (2002). The ripple effect:
Emotional contagion and its influence on group
behavior.
Administrative Science Quarterly, 47 (4), 644–675.
Bates,
D.,
M¨achler,
M.,
Bolker,
B.,
& Walker,
S.
(2015).
Fitting linear
mixed-
effects models using lme4.
Journal
of
Statistical
Software,
67 (1),
1–48.
doi:
57
58
10.18637/jss.v067.i01
Bavelas,
J.
B.,
Black,
A.,
Lemery,
C.
R.,
& Mullett,
J.
(1986).
“I
show how you
feel”:
Motor mimicry as a communicative act.
Journal
of Personality and Social
Psychology, 50 (2), 322–329.
Bell, C., & Song, F.
(2005).
Emotions in the conflict process:
An application of the cog-
nitive appraisal model of emotions to conflict management.
International
Journal
of Conflict Management, 16 (1), 30–54.
Beˇ
nuˇs,
ˇ
S., Gravano, A., Levitan, R., Levitan, S. I., Willson, L., & Hirschberg, J.
(2014).
Entrainment,
dominance and alliance in Supreme Court hearings.
Knowledge-
Based Systems, 71 , 3–14.
Bergmann, T., Dale, R., Sattari, N., Heit, N., & Bhat, H. S.
(accepted).
The interdis-
ciplinarity of collaborations in cognitive science.
Cognitive Science.
Bernieri,
F.
J.,
Davis,
J.
M.,
Rosenthal,
R.,
& Knee,
C.
R.
(1994).
Interactional
synchrony and rapport:
Measuring synchrony in displays devoid of
sound and
facial affect.
Personality and Social
Psychology Bulletin, 20 (3), 303–311.
Bernieri, F. J., Reznick, J. S., & Rosenthal, R. (1988). Synchrony, pseudosynchrony, and
dissynchrony:
measuring the entrainment process in mother-infant interactions.
Journal
of personality and social
psychology, 54 (2), 243–253.
Bernstein,
N.
A.
(1967).
The co-ordination and regulation of
movements.
Pergamon
Press Ltd.
Bird,
S.,
Klein,
E.,
& Loper,
E.
(2009).
Natural
language processing with python.
O’Reilly Media, Inc.
Birditt, K. S., Fingerman, K. L., & Almeida, D. M.
(2005).
Age differences in exposure
and reactions to interpersonal tensions:
A daily diary study. Psychology and Aging,
20 (2), 330-340.
Black, D. P., Riley, M. A., & McCord, C. K. (2007). Synergies in intra-and interpersonal
interlimb rhythmic coordination.
Motor Control , 11 (4), 348–373.
Blei,
D.
M.
(2012).
Probabilistic topic models.
Communications of
the ACM ,
55 (4),
77–84.
doi:
10.1145/2133806.2133826
Blei, D. M., Ng, A. Y., & Jordan, M. I.
(2003).
Latent dirichlet allocation.
Journal
of
Machine Learning Research, 3 , 993–1022.
Boker, S. M., Rotondo, J. L., Xu, M., & King, K.
(2002).
Windowed cross–correlation
and peak picking for the analysis of variability in the association between behav-
ioral time series.
Psychological
Methods, 7 (3), 338–355.
Bond,
R.
M.,
Fariss,
C.
J.,
Jones,
J.
J.,
Kramer,
A.
D.,
Marlow,
C.,
Settle,
J.
E.,
& Fowler,
J.
H.
(2012).
A 61-million-person experiment in social
influence and
political mobilization.
Nature, 489 (7415), 295–298.
Bos,
E.
H.,
Bouhuys,
A.
L.,
Geerts,
E.,
Van Os,
T.
W.,
& Ormel,
J.
(2006).
Lack of
association between conversation partners’ nonverbal behavior predicts recurrence
of depression, independently of personality.
Psychiatry Research, 142 (1), 79–88.
Bourhis, R. Y., Giles, H., & Lambert, W. E.
(1975).
Social consequences of accommo-
dating one’s style of speech:
A cross-national investigation.
International
Journal
of the Sociology of Language, 1975 (6), 55–72.
Branigan, H. P., Pickering, M. J., & Cleland, A. A.
(2000).
Syntactic co-ordination in
dialogue.
Cognition, 75 (2), B13–B25.
Brass,
M.,
& Heyes,
C.
(2005).
Imitation:
Is cognitive neuroscience solving the corre-
spondence problem? Trends in Cognitive Sciences, 9 (10), 489–495.
Brennan, S. E., & Clark, H. H.
(1996).
Conceptual pacts and lexical choice in conver-
sation.
Journal
of
Experimental
Psychology:
Learning,
Memory,
and Cognition,
22 (6), 1482–1493.
Brennan,
S.
E.,
Galati,
A.,
& Kuhlen,
A.
K.
(2010).
Two minds,
one dialog:
Coordi-
nating speaking and understanding.
In B.
H.
Ross (Ed.),
Psychology of learning
59
and motivation (Vol. 53, pp. 301–344).
Burlington:
Academic Press.
Brennan, S. E., & Hanna, J. E.
(2009).
Partner-specific adaptation in dialog.
Topics in
Cognitive Science, 1 (2), 274–291.
Brown-Schmidt,
S.
(2009).
Partner-specific interpretation of
maintained referential
precedents during interactive dialog.
Journal
of
Memory and Language,
61 (2),
171–190.
Buccino,
G.,
Baumgaertner,
A.,
Colle,
L.,
Buechel,
C.,
Rizzolatti,
G.,
& Binkofski,
F.
(2007).
The neural
basis for understanding non-intended actions.
Neuroimage,
36 , T119–T127.
Butler, E. A.
(2011).
Temporal interpersonal emotion systems:
The “TIES” that form
relationships.
Personality and Social
Psychology Review , 15 (4), 367–393.
Cacioppo, S., Zhou, H., Monteleone, G., Majka, E., Quinn, K., Ball, A., . . .
Cacioppo,
J.
(2014).
You are in sync with me:
Neural correlates of interpersonal synchrony
with a partner.
Neuroscience, 277 , 842–858.
Calvo-Merino, B., Glaser, D. E., Gr`ezes, J., Passingham, R. E., & Haggard, P.
(2005).
Action observation and acquired motor skills:
An fMRI study with expert dancers.
Cerebral
Cortex , 15 (8), 1243–1249.
Carr,
E.
W.,
& Winkielman,
P.
(2014).
When mirroring is both simple and ‘smart’:
How mimicry can be embodied,
adaptive,
and non-representational.
Frontiers in
Human Neuroscience, 8 .
Carr, L., Iacoboni, M., Dubeau, M.-C., Mazziotta, J. C., & Lenzi, G. L.
(2003).
Neural
mechanisms of empathy in humans:
A relay from neural systems for imitation to
limbic areas. Proceedings of the National Academy of Sciences, 100 (9), 5497–5502.
Chai,
P.
R.,
Wu,
R.
Y.,
Ranney,
M.
L.,
Porter,
P.
S.,
Babu,
K.
M.,
& Boyer,
E.
W.
(2014). The virtual toxicology service:
Wearable head-mounted devices for medical
toxicology.
Journal
of Medical
Toxicology, 10 (4), 382–387.
Chang,
J.,
Boyd-Graber,
J.,
Wang,
C.,
Gerrish,
S.,
& Blei,
D.
M.
(2009).
Reading
tea leaves:
How humans interpret topic models.
In Neural
information processing
systems.
Chartrand, T. L., & Bargh, J. A. (1999). The chameleon effect:
The perception–behavior
link and social
interaction.
Journal
of Personality and Social
Psychology,
76 (6),
893–910.
Chartrand,
T.
L.,
& Dalton,
A.
N.
(2008).
Mimicry:
Its ubiquity,
importance,
and
functionality.
In Oxford handbook of
human action (pp.
458–483).
New York:
Oxford University Press.
Christakis, N. A., & Fowler, J. H.
(2013).
Social contagion theory:
Examining dynamic
social networks and human behavior.
Statistics in Medicine, 32 (4), 556–577.
Cirelli, L. K., Einarson, K. M., & Trainor, L. J. (2014). Interpersonal synchrony increases
prosocial behavior in infants.
Developmental
Science, 17 (6), 1003–1011.
Clachar, A. (1997). Resistance to the English language in Puerto Rico:
Toward a theory
of language and intergroup distinctiveness.
Linguistics and Education,
9 (1),
69–
98.
Clark, H. H., & Krych, M. A.
(2004).
Speaking while monitoring addressees for under-
standing.
Journal
of Memory and Language, 50 (1), 62–81.
Clark, R. A., Pua, Y.-H., Fortin, K., Ritchie, C., Webster, K. E., Denehy, L., & Bryant,
A. L.
(2012).
Validity of the Microsoft Kinect for assessment of postural control.
Gait & Posture, 36 (3), 372–377.
Cleland, A. A., & Pickering, M. J.
(2003).
The use of lexical and syntactic information
in language production:
Evidence from the priming of
noun-phrase structure.
Journal
of Memory and Language, 49 (2), 214–230.
Coco, M. I., & Dale, R.
(2014).
Cross-recurrence quantification analysis of categorical
and continuous time series:
An R package.
Frontiers in psychology, 5 .
60
Condon, W. S., & Ogston, W. D. (1966). Sound film analysis of normal and pathological
behavior patterns.
Journal
of Nervous and Mental
Disease, 143 (4), 338–347.
Condon, W. S., & Sander, L. W.
(1974).
Neonate movement is synchronized with adult
speech:
Interactional participation and language acquisition.
Science, 183 (4120),
99–101.
Coviello, L., Sohn, Y., Kramer, A. D., Marlow, C., Franceschetti, M., Christakis, N. A.,
& Fowler, J. H.
(2014).
Detecting emotional contagion in massive social networks.
PloS One, 9 (3), e90315.
Criss, M. M., Shaw, D. S., & Ingoldsby, E. M.
(2003).
Mother–son positive synchrony
in middle childhood:
Relation to antisocial behavior.
Social
Development , 12 (3),
379–400.
Crump,
M.
J.,
McDonnell,
J.
V.,
& Gureckis,
T.
M.
(2013).
Evaluating Amazon’s
Mechanical
Turk as a tool
for experimental
behavioral
research.
PloS one,
8 (3),
e57410.
Dale,
R.,
Fusaroli,
R.,
Duran,
N.,
& Richardson,
D.
C.
(2014).
The self-organization
of human interaction.
In The psychology of learning and motivation (Vol. 59, pp.
43–95).
San Diego, CA: Elsevier Academic Press.
Dale, R., Kirkham, N. Z., & Richardson, D. C.
(2011).
The dynamics of reference and
shared visual attention.
Frontiers in Psychology, 2 .
Dale,
R.,
Roche,
J.,
Snyder,
K.,
& McCall,
R.
(2008,
03).
Exploring action dynamics
as an index of paired-associate learning.
PLoS ONE , 3 (3), e1728.
d’Avella,
A.,
Saltiel,
P.,
& Bizzi,
E.
(2003).
Combinations of muscle synergies in the
construction of a natural motor behavior.
Nature Neuroscience, 6 (3), 300–308.
Delaherche,
E.,
Chetouani,
M.,
Mahdhaoui,
A.,
Saint-Georges,
C.,
Viaux,
S.,
& Co-
hen,
D.
(2012).
Interpersonal synchrony:
A survey of evaluation methods across
disciplines.
IEEE Transactions on Affective Computing, 3 (3), 349–365.
Dijksterhuis,
A.,
Smith,
P.
K.,
van Baaren,
R.
B.,
& Wigboldus,
D.
H.
(2005).
The
unconscious consumer:
Effects of environment on consumer behavior.
Journal
of
Consumer Psychology, 15 (3), 193–202.
Duran, N. D., Dale, R., & McNamara, D. S. (2010). The action dynamics of overcoming
the truth.
Psychonomic Bulletin & Review , 17 (4), 486–491.
Erisen,
C.,
Lodge,
M., & Taber,
C. S.
(2014).
Affective contagion in effortful political
thinking.
Political
Psychology, 35 (2), 187–206.
Feng,
S.,
Caire,
R.,
Cortazar,
B.,
Turan,
M.,
Wong,
A.,
& Ozcan,
A.
(2014).
Im-
munochromatographic diagnostic test analysis using Google Glass.
ACS Nano,
8 (3), 3069–3079.
Ferreira, V. S., & Bock, K.
(2006).
The functions of structural priming.
Language and
Cognitive Processes, 21 (7-8), 1011–1029.
Frantz,
C.
M.,
& Janoff-Bulman,
R.
(2000).
Considering both sides:
The limits of
perspective taking.
Basic and Applied Social
Psychology, 22 (1), 31–42.
Freeman,
J.
B.,
& Ambady,
N.
(2010).
Mousetracker:
Software for studying real-time
mental
processing using a computer mouse-tracking method.
Behavior Research
Methods, 42 (1), 226–241.
Fusaroli,
R.,
Bahrami,
B.,
Olsen,
K.,
Roepstorff,
A.,
Rees,
G.,
Frith,
C.,
& Tyl´en,
K.
(2012).
Coming to terms:
Quantifying the benefits of linguistic coordination.
Psychological
Science, 23 (8), 931–939.
Fusaroli,
R.,
Raczaszek-Leonardi,
J.,
& Tyl´en,
K.
(2014).
Dialog as interpersonal
synergy.
New Ideas in Psychology, 32 , 147–157.
Fusaroli, R., & Tyl´en, K. (2012). Carving language for social coordination:
A dynamical
approach.
Interaction Studies, 13 (1), 103–124.
Gaggioli,
A.,
Pioggia,
G.,
Tartarisco,
G.,
Baldus,
G.,
Corda,
D.,
Cipresso,
P.,
& Riva,
G.
(2013).
A mobile data collection platform for mental health research.
Personal
61
and Ubiquitous Computing, 17 (2), 241–251.
Galati, A., & Brennan, S. E. (2010). Attenuating information in spoken communication:
For the speaker, or for the addressee?
Journal
of Memory and Language, 62 (1),
35–51.
Gallese,
V.,
Fadiga,
L.,
Fogassi,
L., & Rizzolatti,
G.
(1996).
Action recognition in the
premotor cortex.
Brain, 119 (2), 593–610.
Garimella, K., Morales, G. D. F., Gionis, A., & Mathioudakis, M.
(2015).
Quantifying
controversy in social media.
arXiv:1507.05224 [cs.SI] .
Garrod, S., & Pickering, M. J.
(2009).
Joint action, interactive alignment, and dialog.
Topics in Cognitive Science, 1 (2), 292–304.
Giles, H.
(1973).
Accent mobility:
A model and some data.
Anthropological Linguistics,
87–105.
Giles, H., Coupland, N., & Coupland, J.
(1991).
Accommodation theory:
Communica-
tion, context, and consequence.
In H. Giles, N. Coupland, & J. Coupland (Eds.),
Contexts of accommodation:
Developments in applied sociolinguistics (pp. 1–68).
New York, NY: Cambridge University Press.
Giles,
H.,
Taylor,
D.
M.,
& Bourhis,
R.
(1973).
Towards a theory of
interpersonal
accommodation through language:
Some canadian data.
Language in Society,
2 (2), 177–192.
Giles, H., Taylor, D. M., & Bourhis, R. Y. (1977). Dimensions of welsh identity. European
Journal
of Social
Psychology, 7 (2), 165–174.
Glad, W., & Adesso, V. J.
(1976).
The relative importance of socially induced tension
and behavioral contagion for smoking behavior.
Journal
of Abnormal
Psychology,
85 (1), 119–121.
Goodwin,
M.
S.,
Velicer,
W.
F.,
& Intille,
S.
S.
(2008).
Telemetric monitoring in the
behavior sciences.
Behavior Research Methods, 40 (1), 328–341.
Gould, M., Jamieson, P., & Romer, D.
(2003).
Media contagion and suicide among the
young.
American Behavioral
Scientist , 46 (9), 1269–1284.
Grammer, K., Kruck, K. B., & Magnusson, M. S. (1998). The courtship dance:
Patterns
of
nonverbal
synchronization in opposite-sex encounters.
Journal
of
Nonverbal
behavior , 22 (1), 3–29.
Griffiths,
T.
L.,
& Steyvers,
M.
(2004).
Finding scientific topics.
Proceedings of
the
National
Academy of Sciences, 101 (suppl 1), 5228–5235.
Gr¨
un,
B.,
& Hornik,
K.
(2011).
topicmodels:
An R package for fitting topic models.
Journal
of Statistical
Software, 40 (13), 1–30.
Hamilton,
A.
F.
d.
C.,
Brindley,
R.
M.,
& Frith,
U.
(2007).
Imitation and action
understanding in autistic spectrum disorders:
How valid is the hypothesis of
a
deficit in the mirror neuron system? Neuropsychologia, 45 (8), 1859–1868.
Hasson, U., Ghazanfar, A. A., Galantucci, B., Garrod, S., & Keysers, C.
(2012).
Brain-
to-brain coupling:
A mechanism for creating and sharing a social
world.
Trends
in Cognitive Sciences, 16 (2), 114–121.
Hatfield,
E.,
Cacioppo,
J.
T.,
& Rapson,
R.
L.
(1993).
Emotional
contagion (Vol.
2)
(No. 3).
Cambridge university press.
He,
J.,
Chaparro,
B.
S.,
& Haskins,
C.
(2014).
Usee:
A mobile usability research tool
using Google Glass.
In Proceedings of the human factors and ergonomics society
annual
meeting (Vol. 58, pp. 1242–1246).
Healey, P. G., Swoboda, N., Umata, I., & King, J.
(2007).
Graphical language games:
Interactional constraints on representational form.
Cognitive Science, 31 (2), 285–
309.
Helm,
J.
L.,
Sbarra,
D.,
& Ferrer,
E.
(2012).
Assessing cross-partner associations in
physiological
responses via coupled oscillator models.
Emotion,
12 (4),
748.
doi:
10.1037/a0025036
62
Henze,
N.,
Pielot,
M.,
Poppinga,
B.,
Schinke,
T.,
& Boll,
S.
(2011).
My app is an
experiment:
Experience from user studies in mobile app stores.
International
Journal
of Mobile Human Computer Interaction, 3 (4), 71–91.
Hernandez, J., & Picard, R. W.
(2014).
Senseglass:
Using Google Glass to sense daily
emotions.
In Proceedings of
the 27th annual
acm symposium on user interface
software and technology (pp. 77–78).
Hickok, G. (2009). Eight problems for the mirror neuron theory of action understanding
in monkeys and humans.
Journal
of Cognitive Neuroscience, 21 (7), 1229–1243.
Hove,
M.
J.,
& Risen,
J.
L.
(2009).
It’s all
in the timing:
Interpersonal
synchrony
increases affiliation.
Social
Cognition, 27 (6), 949–960.
Huette,
S.,
& McMurray,
B.
(2010).
Continuous dynamics of
color categorization.
Psychonomic Bulletin & Review , 17 (3), 348-354.
Iacoboni, M. (2005). Neural mechanisms of imitation. Current Opinion in Neurobiology,
15 (6), 632–637.
Ireland,
M.
E.,
& Pennebaker,
J.
W.
(2010).
Language style matching in writing:
Synchrony in essays,
correspondence,
and poetry.
Journal
of
Personality and
Social
Psychology, 99 (3), 549–571.
Ishimaru, S., Kunze, K., Kise, K., Weppner, J., Dengel, A., Lukowicz, P., & Bulling, A.
(2014).
In the blink of an eye:
Combining head motion and eye blink frequency
for activity recognition with Google Glass.
In Proceedings of
the 5th augmented
human international
conference (pp. 1–4).
New York, NY, USA: ACM.
Jones, M. B., & Jones, D.
(1995).
Preferred pathways of behavioral contagion.
Journal
of Psychiatric Research, 29 (3), 193–209.
Keith, T. Z.
(2005).
Multiple regression and beyond.
Boston:
Pearson Education.
Kelso,
J.
S.,
Tuller,
B.,
Vatikiotis-Bateson,
E.,
& Fowler,
C.
A.
(1984).
Functionally
specific articulatory cooperation following jaw perturbations during speech:
Ev-
idence for coordinative structures.
Journal
of
Experimental
Psychology:
Human
Perception and Performance, 10 (6), 812–832.
Klonoff, D. C.
(2014).
New wearable computers move ahead:
Google Glass and smart
wigs.
Journal
of Diabetes Science and Technology, 8 (1), 3-5.
Knoblich,
G.,
& Jordan,
J.
S.
(2003).
Action coordination in groups and individuals:
Learning anticipatory control.
Journal
of
Experimental
Psychology:
Learning,
Memory, and Cognition, 29 (5), 1006.
Konvalinka, I., & Roepstorff, A. (2012). The two-brain approach:
How can mutually in-
teracting brains teach us something about social interaction? Frontiers in Human
Neuroscience, 6 .
Koss,
T.,
& Rosenthal,
R.
(1997).
Interactional
synchrony,
positivity,
and patient
satisfaction in the physician-patient relationship.
Medical
Care,
35 (11),
1158–
1163.
Kramer,
A.
D.,
Guillory,
J.
E.,
& Hancock,
J.
T.
(2014).
Experimental
evidence of
massive-scale emotional
contagion through social
networks.
Proceedings of
the
National
Academy of Sciences, 111 (24), 8788–8790.
LaFrance, M. (1979). Nonverbal synchrony and rapport:
Analysis by the cross-lag panel
technique.
Social
Psychology Quarterly, 66–70.
Lakin,
J.
L.,
& Chartrand,
T.
L.
(2003).
Using nonconscious behavioral
mimicry to
create affiliation and rapport.
Psychological
Science, 14 (4), 334–339.
Lakin, J. L., Chartrand, T. L., & Arkin, R. M.
(2008).
I am too just like you:
Noncon-
scious mimicry as an automatic behavioral
response to social
exclusion.
Psycho-
logical
Science, 19 (8), 816–822.
Lakin, J. L., Jefferis, V. E., Cheng, C. M., & Chartrand, T. L.
(2003).
The chameleon
effect as social
glue:
Evidence for the evolutionary significance of
nonconscious
mimicry.
Journal
of Nonverbal
Behavior , 27 (3), 145–162.
63
Landauer, T. K., Foltz, P. W., & Laham, D.
(1998).
An introduction to latent semantic
analysis.
Discourse Processes, 25 (2-3), 259–284.
Landauer,
T.
K.,
McNamara,
D.
S.,
Dennis,
S.,
& Kintsch,
W.
(2013).
Handbook of
latent semantic analysis.
Psychology Press.
Larsen, K. S., Martin, H. J., & Giles, H. (1977). Anticipated social cost and interpersonal
accomodation [sic].
Human Communication Research, 3 (4), 303–308.
Lee, H., & Kwon, J. (2010). Combining context–awareness with wearable computing for
emotion–based contents service.
International
Journal
of
Advanced Science and
Technology, 22 (1), 13–24.
Lepri, B., Staiano, J., Rigato, G., Kalimeri, K., Finnerty, A., Pianesi, F., . . .
Pentland,
A.
(2012).
The sociometric badges corpus:
A multilevel
behavioral
dataset for
social behavior in complex organizations.
In Proceedings of the 2012 international
conference on privacy, security, risk and trust (passat) and the 2012 international
conference on social
computing (socialcom) (pp. 623–628).
Louwerse, M. M., Dale, R., Bard, E. G., & Jeuniaux, P.
(2012).
Behavior matching in
multimodal communication is synchronized. Cognitive Science, 36 (8), 1404–1426.
Macrae, C. N., Duffy, O. K., Miles, L. K., & Lawrence, J. (2008). A case of hand waving:
Action synchrony and person perception.
Cognition, 109 (1), 152–156.
Main,
A.,
Paxton,
A., & Dale,
R.
(under review).
An exploratory analysis of affective
dynamics between mothers and adolescents during conflict discussions.
Marks,
P.
E.,
Cillessen,
A.
H.,
& Crick,
N.
R.
(2012).
Popularity contagion among
adolescents.
Social
Development , 21 (3), 501–521.
Marwan,
N.
(2008).
A historical
review of
recurrence plots.
The European Physical
Journal
Special
Topics, 164 (1), 3–12.
Mauerhoefer,
L.,
Kawelke,
P.,
Poliakov,
I.,
Olivier,
P.,
& Foster,
E.
(2014).
An explo-
ration of the feasibility of using Google Glass for dietary assessment
(Tech.
Rep.
No. No. CS-TR-1419).
Newcastle upon Tyne, UK: Newcastle University.
McFarland, D. H.
(2001).
Respiratory markers of conversational interaction.
Journal of
Speech, Language, and Hearing Research, 44 (1), 128–143.
McIntosh,
D.
N.
(2006).
Spontaneous facial
mimicry,
liking and emotional
contagion.
Polish Psychological
Bulletin, 37 (1), 31–42.
McNaney,
R.,
Vines,
J.,
Roggen,
D.,
Balaam,
M.,
Zhang,
P.,
Poliakov,
I.,
& Olivier,
P.
(2014).
Exploring the acceptability of
Google Glass as an everyday assistive
device for people with Parkinson’s.
In Proceedings of
the sigchi
conference on
human factors in computing systems (pp. 2551–2554).
Menenti,
L.,
Pickering,
M.
J.,
& Garrod,
S.
C.
(2012).
Toward a neural
basis of
interactive alignment in conversation.
Frontiers in Human Neuroscience, 6 , 185.
Mikolov,
T.,
Chen,
K.,
Corrado,
G.,
& Dean,
J.
(2013).
Efficient estimation of word
representations in vector space.
arXiv , 1301.3781v3[cs.CL].
Mikolov,
T.,
Sutskever,
I.,
Chen,
K.,
Corrado,
G.
S.,
& Dean,
J.
(2013).
Distributed
representations of
words and phrases and their compositionality.
In C.
Burges,
L.
Bottou,
M.
Welling,
Z.
Ghahramani,
& K.
Weinberger (Eds.),
Advances in
neural
information processing systems (pp. 3111–3119).
Miles,
L.
K.,
Griffiths,
J.
L.,
Richardson,
M.
J.,
& Macrae,
C.
N.
(2010).
Too late to
coordinate:
Contextual
influences on behavioral
synchrony.
European Journal
of
Social
Psychology, 40 (1), 52–60.
Miles,
L.
K.,
Lumsden,
J.,
Richardson,
M.
J.,
& Macrae,
C.
N.
(2011).
Do birds of
a feather move together? Group membership and behavioral
synchrony.
Experi-
mental
Brain Research, 211 (3-4), 495–503.
Miles,
L.
K.,
Nind,
L.
K.,
& Macrae,
C.
N.
(2009).
The rhythm of rapport:
Interper-
sonal synchrony and social perception. Journal of Experimental Social Psychology,
45 (3), 585–589.
64
Miller, G.
(2012).
The smartphone psychology manifesto.
Perspectives on Psychological
Science, 7 (3), 221–237.
Mirman, D.
(2014).
Growth curve analysis and visualization using R.
CRC Press.
Mirman,
D.,
Dixon,
J.
A.,
& Magnuson,
J.
S.
(2008).
Statistical
and computational
models of
the visual
world paradigm:
Growth curves and individual
differences.
Journal
of memory and language, 59 (4), 475–494.
Moens,
B.,
Muller,
C.,
van Noorden,
L.,
Franˇek,
M.,
Celie,
B.,
Boone,
J.,
. . .
Leman,
M.
(2014).
Encouraging spontaneous synchronisation with D-Jogger, an adaptive
music player that aligns movement and music.
PloS one, 9 (12), e114234.
Moens,
B.,
van Noorden,
L.,
& Leman,
M.
(2010).
D-jogger:
Syncing music with
walking.
In Proceedings of
the 7th sound and music computing conference (pp.
451–456).
New York, NY.
Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2012). Adaptation in gesture:
Converging
hands or converging minds? Journal
of Memory and Language, 66 (1), 249–264.
Nagaoka,
C.,
& Komori,
M.
(2008).
Body movement synchrony in psychotherapeutic
counseling:
A study using the video-based quantification method.
IEICE Trans-
actions on Information and Systems, 91 (6), 1634–1640.
Neumann, R., & Strack, F.
(2000).
“Mood contagion”:
The automatic transfer of mood
between persons.
Journal
of Personality and Social
Psychology, 79 (2), 211–223.
Newman-Norlund, R. D., van Schie, H. T., van Zuijlen, A. M., & Bekkering, H.
(2007).
The mirror neuron system is more active during complementary compared with
imitative action.
Nature Neuroscience, 10 (7), 817–818.
Niederhoffer,
K.
G.,
& Pennebaker,
J.
W.
(2002).
Linguistic style matching in social
interaction.
Journal
of Language and Social
Psychology, 21 (4), 337–360.
Nummenmaa,
L.,
Hirvonen,
J.,
Parkkola,
R.,
& Hietanen,
J.
K.
(2008).
Is emotional
contagion special? An fMRI study on neural
systems for affective and cognitive
empathy.
Neuroimage, 43 (3), 571–580.
Oberman, L. M., Pineda, J. A., & Ramachandran, V. S. (2007). The human mirror neu-
ron system:
A link between action observation and social skills.
Social
Cognitive
and Affective Neuroscience, 2 (1), 62–66.
Oberman,
L.
M.,
& Ramachandran,
V.
S.
(2007).
The simulating social
mind:
The
role of the mirror neuron system and simulation in the social and communicative
deficits of autism spectrum disorders.
Psychological
Bulletin, 133 (2), 310–327.
Oikonomidis,
I.,
Kyriazis,
N.,
& Argyros,
A.
A.
(2011).
Efficient model-based 3D
tracking of hand articulations using Kinect.
In J. Hoey, S. McKenna, & E. Trucco
(Eds.),
Proceedings of
the british machine vision conference (p.
101.1?101.11).
Durham, UK: BMVA Press.
Olgu´ın Olgu´ın,
D.,
Gloor,
P.
A.,
& Pentland,
A.
S.
(2009).
Capturing individual
and
group behavior with wearable sensors. In Papers from the AAAI spring symposium
on human behavior modeling (pp. 68–74).
Menlo Park, CA: AAAI Press.
Olgu´ın Olgu´ın, D., Waber, B. N., Kim, T., Mohan, A., Ara, K., & Pentland, A.
(2009).
Sensible organizations:
Technology and methodology for automatically measuring
organizational
behavior.
IEEE Transactions on Systems,
Man,
and Cybernetics.
Part B, Cybernetics, 39 , 43–55.
Pantelopoulos, A., & Bourbakis, N.
(2008).
A survey on wearable biosensor systems for
health monitoring.
In Proceedings of the 30th annual
international
engineering in
medicine and biology society conference (pp. 4887–4890).
Piscataway, NJ.
Paolacci, G., Chandler, J., & Ipeirotis, P. G.
(2010).
Running experiments on Amazon
Mechanical Turk.
Judgment and Decision Making, 5 (5), 411–419.
Parviz,
B.
A.
(2014).
Of
molecules,
medicine,
and Google Glass.
ACS Nano,
8 (3),
1956–1957.
65
Paxton, A., Abney, D., Kello, C. K., & Dale, R. (2014). Network analysis of multimodal,
multiscale coordination in dyadic problem solving.
In P.
M.
Bello,
M.
Guarini,
M.
McShane,
& B.
Scassellati
(Eds.),
Proceedings of the 36th Annual
Meeting of
the Cognitive Science Society.
Austin, TX: Cognitive Science Society.
Paxton, A., & Dale, R.
(2013a).
Argument disrupts interpersonal synchrony.
Quarterly
Journal
of Experimental
Psychology, 11 (66), 2092–2102.
Paxton,
A.,
& Dale,
R.
(2013b).
Frame-differencing methods for measuring bodily
synchrony in conversation.
Behavior Research Methods, 45 (2), 329–343.
Paxton, A., & Dale, R.
(2013c).
Multimodal networks of interpersonal interaction and
conversational
contexts.
In M.
Knauff,
M.
Pauen,
N.
Sebanz,
& I.
Wachsmuth
(Eds.),
Proceedings of the 35th Annual
Meeting of the Cognitive Science Society.
Austin, TX: Cognitive Science Society.
Paxton, A., & Dale, R.
(in preparation).
Debate in the wild:
The moderation of group
membership in predicting debate outcomes.
Paxton, A., Dale, R., & Richardson, D. C.
(in press).
Social coordination of verbal and
nonverbal
behaviors.
In P.
Passos,
K.
Davids,
& C.
J.
Yi
(Eds.),
Interpersonal
coordination and performance in social
systems.
Routledge.
Paxton,
A.,
Roche,
J. M., & Tanenhaus,
M. K.
(2015).
Communicative efficiency and
miscommunication:
The costs and benefits of
variable language production.
In
D. C. Noelle et al. (Eds.), Proceedings of the 37th Annual Meeting of the Cognitive
Science Society.
Austin, TX: Cognitive Science Society.
Paxton, A., Rodriguez, K., & Dale, R.
(2015).
Psyglass:
Capitalizing on Google Glass
for naturalistic data collection.
Behavior Research Methods, 47 , 608–619.
Pennebaker,
J.
W.,
Booth,
R.
J.,
& Francis,
M.
E.
(2007).
Linguistic Inquiry and
Word Count (LIWC): A computerized text analysis program [Computer software].
Austin, TX.
Retrieved from liwc.net
Pentland, A.
(2010).
Honest signals.
Cambridge, MA: MIT Press.
Pfeifer, J. H., Iacoboni, M., Mazziotta, J. C., & Dapretto, M.
(2008).
Mirroring others’
emotions relates to empathy and interpersonal competence in children.
Neuroim-
age, 39 (4), 2076–2085.
Phillips,
L.
H.,
Tunstall,
M.,
& Channon,
S.
(2007).
Exploring the role of
working
memory in dynamic social cue decoding using dual task methodology.
Journal
of
Nonverbal
Behavior , 31 (2), 137–152.
Picard,
R. W., & Healey,
J.
(1997).
Affective wearables.
Personal
Technologies,
1 (4),
231–240.
Pickering,
M.
J.,
& Garrod,
S.
(2004).
Toward a mechanistic psychology of dialogue.
Behavioral
and Brain Sciences, 27 (2), 169–190.
Pickering, M. J., & Garrod, S. (2013). An integrated theory of language production and
comprehension.
Behavioral
and Brain Sciences, 36 (04), 329–347.
Pineda,
J.
A.
(2008).
Sensorimotor cortex as a critical
component of
an ‘extended’
mirror neuron system:
Does it solve the development, correspondence, and control
problems in mirroring.
Behavioral
and Brain Functions, 4 (47), 1–16.
Polansky, N., Lippitt, R., & Redl, F.
(1950).
An investigation of behavioral contagion
in groups.
Human Relations, 3 (4), 319–348.
Pugh, S. D.
(2001).
Service with a smile:
Emotional contagion in the service encounter.
Academy of Management Journal , 44 (5), 1018–1027.
R Development Core Team.
(2008).
R:
A language and environment for statistical
computing [Computer software manual].
Vienna, Austria.
Raento,
M.,
Oulasvirta,
A.,
& Eagle,
N.
(2009).
Smartphones:
An emerging tool
for
social scientists.
Sociological
Methods Research, 37 (3), 426–454.
Ramanathan,
S.,
& McGill,
A.
L.
(2007).
Consuming with others:
Social
influences
on moment-to-moment and retrospective evaluations of an experience.
Journal
of
66
Consumer Research, 34 (4), 506–524.
Ramenzoni, V. C., Riley, M. A., Shockley, K., & Baker, A. A.
(2012).
Interpersonal and
intrapersonal
coordinative modes for joint and single task performance.
Human
Movement Science, 31 (5), 1253–1267.
Ramseyer, F., & Tschacher, W.
(2008).
Synchrony in dyadic psychotherapy sessions.
In
Simultaneity:
Temporal
structures and observer perspectives (pp.
329–347).
Sin-
gapore:
World Scientific.
Ramseyer,
F.,
& Tschacher,
W.
(2011).
Nonverbal
synchrony in psychotherapy:
Co-
ordinated body movement reflects relationship quality and outcome.
Journal
of
Consulting and Clinical
Psychology, 79 (3), 284–295.
Ramseyer,
F.,
& Tschacher,
W.
(2014).
Nonverbal
synchrony of
head– and body–
movement in psychotherapy:
different signals have different associations with out-
come.
Frontiers in Psychology, 5 (979).
Randall, A. K., Post, J. H., Reed, R. G., & Butler, E. A.
(2013).
Cooperating with your
romantic partner:
Associations with interpersonal emotion coordination.
Journal
of Social
and Personal
Relationships, 30 (8), 1072-1095.
ˇ
Reh˚uˇrek, R., & Sojka, P.
(2010, May 22).
Software framework for topic modelling with
large corpora.
In Proceedings of the LREC 2010 Workshop on New Challenges for
NLP Frameworks (pp. 45–50).
Valletta, Malta:
ELRA.
Reitter,
D.,
Moore,
J.
D.,
& Keller,
F.
(2006).
Priming of
syntactic rules in task-
oriented dialogue and spontaneous conversation.
In R. Sun (Ed.),
Proceedings of
the 28th annual
meeting of the Cognitive Science Society (pp.
685–690).
Austin,
TX: Cognitive Science Society.
Richardson,
B.
H.,
Taylor,
P.
J.,
Snook,
B.,
Conchie,
S.
M.,
& Bennell,
C.
(2014).
Language style matching and police interrogation outcomes.
Law and Human
Behavior , 38 (4), 357–366.
Richardson,
D.
C.,
& Dale,
R.
(2005).
Looking to understand:
The coupling between
speakers’
and listeners’
eye movements and its relationship to discourse compre-
hension.
Cognitive Science, 29 (6), 1045–1060.
Richardson,
D.
C.,
Dale,
R.,
& Kirkham,
N.
Z.
(2007).
The art of
conversation is
coordination:
Common ground and the coupling of eye movements during dialogue.
Psychological
Science, 18 (5), 407–413.
Richardson, D. C., Dale, R., & Tomlinson, J. M.
(2009).
Conversation, gaze coordina-
tion, and beliefs about visual context.
Cognitive Science, 33 (8), 1468–1482.
Richardson,
D.
C.,
Street,
C.
N.,
Tan,
J.
Y.,
Kirkham,
N.
Z.,
Hoover,
M.
A.,
& Ca-
vanaugh,
A.
G.
(2012).
Joint perception:
Gaze and social
context.
Frontiers in
human neuroscience, 6 .
Richardson, M. J., Marsh, K. L., Isenhower, R. W., Goodman, J. R., & Schmidt, R. C.
(2007). Rocking together:
Dynamics of intentional and unintentional interpersonal
coordination.
Human Movement Science, 26 (6), 867–891.
Riley, M. A., Richardson, M. J., Shockley, K., & Ramenzoni, V. C. (2011). Interpersonal
synergies.
Frontiers in Psychology, 2 .
Rizzolatti,
G.,
& Craighero,
L.
(2004).
The mirror-neuron system.
Annual
Review of
Neuroscience, 27 (1), 169–192.
Rizzolatti,
G.,
Fadiga,
L.,
Gallese,
V.,
& Fogassi,
L.
(1996).
Premotor cortex and the
recognition of motor actions.
Cognitive Brain Research, 3 (2), 131–141.
Rogers, S. L., Fay, N., & Maybery, M. (2013). Audience design through social interaction
during group discussion.
PloS One, 8 (2), e57211.
Rozin,
P.,
& Royzman,
E.
B.
(2001).
Negativity bias,
negativity dominance,
and
contagion.
Personality and Social
Psychology Review , 5 (4), 296–320.
Sadler,
P.,
Ethier,
N.,
Gunn,
G.
R.,
Duong,
D.,
& Woody,
E.
(2009).
Are we on
the same wavelength? Interpersonal
complementarity as shared cyclical
patterns
67
during interactions.
Journal
of
Personality and Social
Psychology,
97 (6),
1005–
1020.
Saxbe,
D.,
& Repetti,
R.
L.
(2010).
For better or worse?
Coregulation of
couples?
cortisol
levels and mood states.
Journal
of
Personality and Social
Psychology,
98 (1), 92–103.
Schmidt,
R., & Richardson,
M. J.
(2008).
Dynamics of interpersonal coordination.
In
A. Fuchs & V. Jirsa (Eds.), Coordination:
Neural, behavioral, and social dynamics
(pp. 281–308).
Berlin:
Springer.
SensoMotoric
Instruments.
(2015).
Experimenter
Center.
Retrieved
from
http://www.smivision.com/
Shockley,
K.,
Richardson,
D.
C.,
& Dale,
R.
(2009).
Conversation and coordinative
structures.
Topics in Cognitive Science, 1 (2), 305–319.
Shockley,
K.,
Santana,
M.-V.,
& Fowler,
C.
A.
(2003).
Mutual
interpersonal
postu-
ral constraints are involved in cooperative conversation.
Journal
of Experimental
Psychology:
Human Perception and Performance, 29 (2), 326–332.
Sievert, C., & Shirley, K. E.
(2014).
Ldavis:
A method for visualizing and interpreting
topics.
In Proceedings of the workshop on interactive language learning, visualiza-
tion, and interfaces (pp. 63–70).
Simard, L. M., Taylor, D. M., & Giles, H. (1976). Attribution processes and interpersonal
accommodation in a bilingual setting.
Language and Speech, 19 (4), 374–387.
Spivey, M. J., & Dale, R.
(2006).
Continuous dynamics in real–time cognition.
Current
Directions in Psychological
Science, 15 (5), 207–211.
Squires, N. K., Squires, K. C., & Hillyard, S. A.
(1975).
Two varieties of long–latency
positive waves evoked by unpredictable auditory stimuli in man. Electroencephalog-
raphy and Clinical
Neurophysiology, 38 (4), 387–401.
Starner,
T.,
Mann,
S.,
Rhodes,
B.,
Levine,
J.,
Healey,
J.,
Kirsch,
D.,
. . .
Pentland,
A.
(1997).
Augmented reality through wearable computing.
Presence:
Teleoperators
and Virtual
Environments, 6 (4), 386–398.
Stephens,
G.
J.,
Silbert,
L.
J.,
& Hasson,
U.
(2010).
Speaker–listener neural
coupling
underlies successful communication.
Proceedings of the National
Academy of Sci-
ences, 107 (32), 14425–14430.
Tickle-Degnen,
L.,
& Rosenthal,
R.
(1990).
The nature of
rapport and its nonverbal
correlates.
Psychological
Inquiry , 1 (4), 285–293.
Tollefsen,
D.
P.,
Dale,
R.,
& Paxton,
A.
(2013).
Alignment,
transactive memory,
and
collective cognitive systems.
Review of Philosophy and Psychology, 4 (1), 49–64.
Tresch,
M. C., & Jarc,
A.
(2009).
The case for and against muscle synergies.
Current
Opinion in Neurobiology, 19 (6), 601–607.
Trude, A. M., & Brown-Schmidt, S. (2012). Talker-specific perceptual adaptation during
online speech perception.
Language and Cognitive Processes, 27 (7–8), 979–1001.
Tschacher,
W.,
Rees,
G.
M.,
& Ramseyer,
F.
(2014).
Nonverbal
synchrony and affect
in dyadic interactions.
Frontiers in Psychology, 5 , 1323.
Turvey, M. T.
(1990).
Coordination.
American Psychologist , 45 (8), 938–953.
Turvey, M. T. (2007). Action and perception at the level of synergies. Human Movement
Science, 26 (4), 657–697.
Valdesolo, P., Ouyang, J., & DeSteno, D. (2010). The rhythm of joint action:
Synchrony
promotes cooperative ability.
Journal
of
Experimental
Social
Psychology,
46 (4),
693–695.
van Baaren,
R.
B.,
Holland,
R.
W.,
Kawakami,
K.,
& van Knippenberg,
A.
(2004).
Mimicry and prosocial behavior.
Psychological
Science, 15 (1), 71–74.
van Baaren, R. B., Janssen, L., Chartrand, T. L., & Dijksterhuis, A.
(2009).
Where is
the love? The social aspects of mimicry.
Philosophical
Transactions of the Royal
Society B: Biological
Sciences, 364 (1528), 2381–2389.
68
Waber,
B.
N.,
Aral,
S.,
Olguin Olguin,
D.,
Wu,
L.,
Brynjolfsson,
E.,
& Pentland,
A.
(2011).
Sociometric badges:
A new tool
for IS research.
Social
Science Research
Network , 1789103.
Wagner,
P.,
Malisz,
Z.,
& Kopp,
S.
(2014).
Gesture and speech in interaction:
An
overview.
Speech Communication, 57 , 209–232.
Wall,
D.,
Ray,
W.,
Pathak,
R.
D.,
& Lin,
S.
M.
(2014).
A Google Glass application
to support shoppers with dietary management of
diabetes.
Journal
of
Diabetes
Science and Technology, 8 (6), 1245–1246.
Wang, Y., Reitter, D., & Yen, J.
(2014).
Linguistic adaptation in conversation threads:
Analyzing alignment in online health communities. In V. Demberg & T. O’Donnell
(Eds.), Proceedings of the fifth workshop on cognitive modeling and computational
linguistics (pp. 55–62).
Stroudsburg, Pennsylvania.
Waskom,
M.,
Botvinnik,
O.,
Hobson,
P.,
Warmenhoven,
J.,
Cole,
J.
B.,
Halchenko,
Y.,
. . .
et al.
(2015).
seaborn:
v0.6.0 (june 2015).
Zenodo.
Retrieved from
http://dx.doi.org/10.5281/zenodo.19108
doi:
10.5281/zenodo.19108
Wheeler,
L.
(1966).
Toward a theory of
behavioral
contagion.
Psychological
Review ,
73 (2), 179–192.
Wickham, H.
(2009).
ggplot2:
Elegant graphics for data analysis.
New York:
Springer.
Wiltermuth,
S.
S.,
& Heath,
C.
(2009).
Synchrony and cooperation.
Psychological
Science, 20 (1), 1–5.
Woodall,
W.
G.,
& Burgoon,
J.
K.
(1981).
The effects of
nonverbal
synchrony on
message comprehension and persuasiveness.
Journal of Nonverbal Behavior , 5 (4),
207–223.
