Studia Ekonomiczne. Zeszyty Naukowe
Uniwersytetu Ekonomicznego w Katowicach 
ISSN 2083-8611 Nr 296 · 2016 
Informatyka i Ekonometria 6 
Nina Rizun 
Gdansk University of Technology 
Faculty of Management and Economics 
Department of Applied Informatics in Management 
nina.rizun@zie.pg.gda.pl 
Yurii Taranenko 
Alfred Nobel University, Dnipropetrovs’k 
Department of Applied Linguistics 
and Methods of Teaching Foreign Languages 
taranen@rambler.ru
THE METHOD OF A TWO-LEVEL TEXT-MEANING 
SIMILARITY APPROXIMATION 
OF THE CUSTOMERS’ OPINIONS 
Summary: The method of two-level text-meaning similarity approximation, consisting 
in the implementation of the classification of the stages of text opinions of customers and 
identifying their rank quality level was developed. Proposed and proved the significance 
of major hypotheses, put as the basis of the developed methodology, notably about the 
significance of suggestions about the existence of analogies between mathematical bases 
of the theory of Latent Semantic Analysis, based on the analysis of semantic relationship 
between the variables and degree of participation of the document or term in the corre-
sponding concept of the document data, and instruments of the theory of Social Network 
Analysis, directed at revealing the features of objects on the basis of information about 
structure and strength of their interaction. The Contextual Cluster Structure, as well as 
Quantitative Ranking evaluation for interpreting the quality level of estimated custom-
ers’ opinion has formed. 
Keywords: text-meaning, Latent Semantic Analysis, Social Network Analysis.
Introduction 
Large number of opinions is easily accessible nowadays. It is desirable to 
understand their properties as they potentially contain valuable business infor-
Paweł Kapłański 
Gdansk University of Technology 
Faculty of Management and Economics 
Department of Applied Informatics in Management 
pawel.kaplanski@zie.pg.gda.pl 
The method of a two-level text-meaning similarity approximation... 
65 
mation. Opinion mining (or sentiment analysis) tries to extract this valuable 
information using complex and Semantic Analysis Algorithms. 
There exist a few ways of texts semantic analysis, which can be divided in-
to the following groups [1]: linguistic analysis and statistical analysis. 
The first group is oriented at defining the sense by the semantic structure of 
the text and includes lexical, morphological and syntactic analysis. At the pre-
sent time, there are no established approaches to realization of the task of semat-
ic analysis of text information. It is mostly caused by the exceptional complexity 
of the problem and by the insufficiency of the studies in the scientific direction 
of artificial intelligence systems creation. 
The second group, as a rule, includes frequency analysis with its variations. 
The analysis consists of counting the number of words repetitions in a text and 
applying the results for particular objectives. Different options of various reali-
zations of words calculation and the further results processing create a wide 
specter of methods and algorithms, suggested in this class. 
From the other hand, clustering problem solving, especially in the context 
of its application for the analysis of text messages, is fundamentally ambiguous, 
and there are several reasons [2-5]. 
Firstly, there does not exist a clustering quality criterion, which is definitely 
the best. There is a number of quite reasonable criteria, as well as a number of 
algorithms that do not have clearly expressed criterion, but perform reasonable 
clustering “by construction”. All of them can give different results. 
Secondly, the number of clusters is usually not known in advance and are 
set in accordance with some subjective criteria. 
Thirdly, the clustering result depends strongly on the metric ρ, the choice of 
which is typically subjective and also determined by the expert. 
1. Theoretical justification 
One of the most effective statistical approaches is the Latent Semantic 
Analysis (or the Latent Semantic Indexing). Latent Semantic Analysis (LSA) – 
is a method for discovering hidden concepts in document data. Each document 
and term (word) is then expressed as a vector with elements corresponding to 
these concepts. Each element in a vector gives the degree of participation of the 
document or term in the corresponding concept. The goal is not to describe the 
concepts verbally, but to be able to represent the documents and terms in a uni-
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
66 
fied way for exposing document-document, document-term, and term-term simi-
larities or semantic relationship, which is otherwise hidden [6, 7]. 
The method of Latent Semantic Analysis enables the extraction of context-
dependent meanings of words with the help of statistical processing of large sets 
of text data. This method is based on the principles of analyzing the main com-
ponents, which are applied in the creation of artificial neural networks. The to-
tality of all contexts, in which the word is found, sets a number of reciprocal 
restrictions that allow defining the similarity of words’ meanings and words’ sets 
between each other. It allows to model separate cognitive and psycho-linguistic 
processes of a man. 
There exist the following practical tasks with the application of LSA [8-11]: 
–
document comparison (their clustering and classification); 
–
search of similar documents in different languages – after the analysis of 
translated documents base; 
–
search of documents on the selected terms. 
The Latent Semantic Analysis deals well with the problem of synonymy, 
but partially with the problem of polysemy, because every word is defined by 
one point in the space. This analysis also enables conduction of documents’ au-
tomatic categorization, based on their similarity of conceptual content. Inde-
pendency on language is also one of the advantages of LSA (since it is a mathe-
matical approach). The disadvantage of the method is the decrease of the speed 
of calculation with the increase of output data volume (for instance, in the SVD- 
-decomposition). 
The analysis of networks and networked systems, however, has a long tradi-
tion in economics, and an even longer history of graph theory in discrete math-
ematics [12-14]. From the late 1990s onwards, research on social networks has 
branched onto a number of fields, and has been generally carried out under the 
umbrella term of complex networks, a new emerging area in which networks are 
studied in several domains, using data from a wide variety of sources. The clas-
ses of networks studied include computer, biological, financial, medical, physi-
cal, and transportation networks, among many others. 
In a graph, we call a unit – whether an individual, a company, an indicator – 
a vertex or a node. A tie between two nodes indicates presence of the relation-
ship connecting them. Absence of a tie indicates absence of the relationship. 
A tie with a direction is called an arc, and a tie without a direction is called an 
edge. One could also note the value or volume of flow as the weight of a tie and 
thus obtain a network that would then be a weighted digraph. 
The method of a two-level text-meaning similarity approximation... 
67 
A primary use of graph theory in social network analysis is to identify “im-
portant” actors. Centrality and prestige concepts seek to quantify graph theoretic 
ideas about an individual actor’s prominence within a network by summarizing 
structural relations among the G-nodes. Group-level indexes of centralization 
and prestige assess the dispersion or inequality among all actors’ prominences. 
The three most widely used centrality measures are degree, closeness, and be-
tweenness [15-17]. 
The goal of research using social network analysis (SNA) mainly is to un-
derstand the general properties of the data, which is represented with using the 
networks, often by analyzing large datasets collected with the aid of technology. 
The data is often abstracted at the level at which the networks are treated as large 
graphs, often with little or no concern on whether the nodes (actors) represent 
people, companies, indicators, or other entities. Such an abstraction is possible 
because in many ways the problems addressed in complex network research are 
similar across different domains. Relevant problems include understanding of 
the structure of the networks (i.e., by identifying underlying properties of the 
link and edge structures), the evolution of such structures (i.e., how the networks 
change over time), and how information propagates within the networks. 
The objective of this work consists in developing the method of a two-level 
text-meaning similarity approximation, which contains the realization of the 
stages of Contextual Clustering of customers’ text opinions and Quantitative 
Rank identification and aims to fill the scientific gaps in the area of the absence 
the universal method of the contextual and structural clustering of the textual 
messages taking into account the semantical and statistical specificity at the 
same time. The methodology is based on justifying the hypothesis of existing 
analogy between mathematical foundations of the Latent Semantic Analysis and 
the theory of Social Network Analysis. 
The first chapter introduce the theoretical justification of the Contextual 
Clustering problem. The second chapter contain the research methodology frag-
ments, which presupposed the data source and usage of variables describing, 
development of the algorithm of the text-meaning discovering on the basis of 
mathematical tools of the LSA and SNA theories instruments and development 
of the algorithm of contextual clustering of customers’ text opinions and quanti-
tative rank identification. The third chapter proposed the discussion about the 
experimental results and finding. The conclusions and further research direction 
placed in the fifth part of the paper. 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
68 
2. The research methodology fragments 
The two-level method of the text-meaning similarity approximation, sug-
gested by the authors, lies in the basis of the following hypotheses: 
Hypothesis 1. The process of identification of customers’ text-opinions about the 
used product (service) can be realized as a sequence of the follow-
ing stages: division of the examined documents into Clusters by 
means of defining Contextual Interdependencies between the set 
of documents and the Quantitative Rank identification. 
Hypothesis 2. It is mathematically and methodologically justified (significant) to 
draw an analogy between mathematical bases of the theory of La-
tent Semantic Analysis, based on the analysis of semantic rela-
tionship between the variables and degree of participation of the 
document or term in the corresponding concept of the document 
data, and instruments of the theory of Social Network Analysis, 
directed at revealing the features of objects on the basis of infor-
mation about structure and strength of their interaction. 
The suggested method of identification and clustering of customers’ opin-
ions with the possibility of rank evaluation of qualitative level of products’ eval-
uation, based on the above-mentioned hypotheses, includes the following stages 
(Figure 1). 
Figure 1. The stages of the method of identification and clustering of customers’ opinions 
2.1. Data Source and Usage of Variables 
As the experimental data for the research and approbation of the developed 
method the authors have used opinions of customers of the Starbucks Coffee 
Houses, received from the official page of Starbucks Coffee Company. Because 
of the fact that the developed methodology is aimed at the evaluation of text 
information, quantitative evaluations of Starbucks service quality were removed 
from the processed texts. 
Data Sampling 
Opinion 1 
…… 
Opinion N 
Text-Meaning 
Discovering
LSA
SNA 
Clustering 
Cluster
1 
Cluster
N 
……
Ranking 
Index
1 
Index
N 
…… 
The method of a two-level text-meaning similarity approximation... 
69 
2.2. Development of the Algorithm of the Text-Meaning Discovering 
on the Basis of Mathematical Tools of the LSA and SNA 
Theories Instruments 
The objectives of this stage are: 
•
development of the algorithm of the text-meaning discovering for receiving 
the quantitative measure of customers’ text-opinions similarity; 
•
confirming the significance of Hypothesis 2 about the existence of analogy 
between mathematical and methodological bases of LSA and SNA in the 
process of developing the algorithm of the two-level text-meaning similarity 
approximation. 
For this purpose realization we will briefly examine the mathematical in-
struments, used as the basis of the suggested algorithm of customers’ text opin-
ions classification, and then we will analyze the results of their application for 
a particular example. 
The phases of the developed Algorithm of Customers’ Opinions Text- 
-Meaning Discovering are presented in the Figure 2. 
Figure 2. The phases of the Algorithm of Customers’ Opinions Text-Meaning Discovering 
The phase Words Mining is the preparative for realizing the Algorithm of 
Classification of Customers’ Text Opinions and presents sequential procedures 
of removing words, which do not have any sense load (prepositions, pronouns, 
etc.); removing words that are found only once in the whole document; stem-
ming (finding the word’s stem – for instance, the Porter’s rule). 
On the basis on the Words Mining phase results two levels of the Text- 
-meaning Discovering must be implemented: the level of the Latent Semantic 
Analysis and the level of the Social Network Analysis text-meaning discovering 
implementation. 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
70 
2.2.1. Finding the semantic of customers’ text-opinions similarity 
(level of the Latent Semantic Analysis) 
As the scientific background for the level of customers’ text-opinions docu-
ments similarity evaluation we propose to use the phenomena of semantic similari-
ty between the documents, which could be revealed via using the Latent Semantic 
Analysis instruments. In this paragraph we proposed authors version of using this 
instruments for finding the semantic of customers’ text-opinions similarity. 
The phase of Forming the Frequency Matrix FR contains the process of 
building the matrix relative frequency of the w-th word occurrence in document t: 
df
)
t
,
w
(
k
)
t
,
w
(
tf
=
, (1) 
where: 
)
L
,
w
(
k
t
– the number of w-th word occurrences in the text t; 
df – the total number of words in the text of t. 
The phase of Frequency Matrix TF-IDF Transformation is the process of 
the obtaining the statistical measure 
i
w
F
used for evaluation of the significance 
of the word in the context of the document, which is part of the list of analyzed 
documents: 
df
D
log
tf
IDF
TF
F
2
w
i
⋅
⋅
=
×
=
, (2) 
where: 
tf – words frequency (in the document); 
D – total number of documents in the collection. 
The phase of finding the Point of Reference in the scale of the quantitative 
measure of customers’ text-opinions similarity determination can serve to coor-
dinate the term with the highest total weight: 
}
F
max{
F
n
1
i
PR
i
w
i
w
∑
=
=
. (3) 
The high weight of this term among the customer’s text-opinions collection 
indicates the presence of at least one cluster, the center of which is this centroid 
term (term group). 
The phase of the Singular Value Decomposition (SVD-transformation) is 
the process which allows reflecting basic structure of the different dependencies 
The method of a two-level text-meaning similarity approximation... 
71 
that are present in the original matrix [18]. The mathematical basis of the meth-
od is as follows: 
Formally let A be the m × n words-document matrix of a collection of doc-
uments. Each column of A corresponds to a document. The values of the matrix 
elements 
]
j
,
i
[
A
represent the frequency identifications 
i
w
F
of the term occur-
rence w
i
in the document t
j
: 
i
w
F
]
j
,
i
[
A
=
. The dimensions of A, m and n, corre-
spond to the number of words and documents, respectively, in the collection. 
Observe that 
A
A
B
T
=
is the document-document matrix. If documents i 
and j have b words in common, then 
b
]
j
,
i
[
B
=
. On the other hand, 
T
AA
C
=
is the word-word matrix. If terms i and j occur together in c documents then 
c
]
j
,
i
[
C
=
. Clearly, both B and C are square and symmetric; B is an m × m 
matrix, whereas C is an n × n matrix. Now, we perform an Singular Value De-
composition on A using matrices B and C as described in the previous section: 
T
U
S
A
Σ
=
, (4) 
where: 
S − the matrix of the eigenvectors of B, 
U – the matrix of the eigenvectors of C, 
Σ
− the diagonal matrix of the singular values obtained as square roots of the 
eigenvalues of B. 
In LSA we ignore these small singular values and replace them by 0. Let us 
say that we only keep k singular values in Σ. Then Σ will be all zeros except the 
first k entries along its diagonal. As such, we can reduce matrix Σ into 
k
Σ
which 
is an k × k matrix containing only the k singular values that we keep, and also 
reduce 
S
and 
T
U
, into 
k
S
and 
T
k
U
, to have k columns and rows, respectively. 
Of course, all these matrix parts that we throw out would have been zeroed any-
way by the zeros in 
Σ
. Matrix A is now approximated by: 
T
k
k
k
k
U
S
A
Σ
=
(5) 
Observe that, since
k
S
,
k
Σ
and 
T
k
U
are m × k, k × k, and k × n matrices, their 
product, A
k
is again an m × n matrix. Intuitively, the k remaining ingredients of 
the eigenvectors in S and U correspond to k “hidden concepts” where the terms 
and documents participate. The words and documents have now a new represen-
tation in words of these hidden concepts. Namely, the words are represented by 
the indexed vectors-models of the m × k matrix
k
k
S
Σ
, whereas the documents by 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
72 
the column vectors the k × n matrix 
T
k
k
U
Σ
(coordinates of the words and the 
documents in the common k-dimension space – the so-called hypothesis space). 
The stage of the Measure of the Documents Similarity formation. According 
to the authors, as an instrument of the documents’ similarity degree identifica-
tion, it is advisable to use the reference dimensional coordinate 
i
t
dist
– the dis-
tance between the indexed vectors-models of the documents and coordinates of 
a point of reference in the scale of the customer’s text-opinions collection close-
ness determination. 
Taking into account the heuristics introduced in consideration with deter-
mining the relative dimensional coordinates
i
t
dist
, it is encouraged to use the 
following author's concepts of standard distance metrics: 
−
Euclid’s measure
∑
=
−
=
m
1
i
2
i
i
t
)
y
x
(
dist
i
, where x – vector of the document, 
y – point of reference words vector; 
−
Cosine of the edge between the vectors: 
y
x
y
x
cos
dist
i
t
⋅
⋅
=
θ
=
, where x,
⋅
y – 
scalar product of the vectors, 
x
и 
y
– quota of the vectors, which are cal-
culated by the formulas: 
∑
=
=
n
i
1
i
2
i
x
x
, 
∑
=
=
n
i
1
i
2
i
y
y
(6) 
Then, the measure of similarity
i
,
1
i
K
+
between pairs of documents is justified 
to consider the difference between the values of their relative spatial coordinates
i
t
dist
: 
i
1
i
i
,
1
i
dist
dist
K
−
=
+
+
. (7) 
While documents shall be sorted in ascending order of values
i
t
dist
. 
As a result of this phase of the algorithm of the text-meaning discovering 
we can receive the vector of the quantitative measure of customers’ text- 
-opinions semantic similarity
i
,
1
i
K
+
. 
The method of a two-level text-meaning similarity approximation... 
73 
2.2.2. Finding the structural of customers’ text-opinions similarity 
(level of the Social Network Analysis) 
As the scientific background for the level of customers’ text-opinions doc-
uments similarity evaluation we propose to use the phenomena of structural 
similarity between frequency characteristics of the common words, found in the 
documents. In this paragraph we proposed authors version of using the of Social 
Network Analysis instruments for finding the structural of customers’ text- 
-opinions similarity. 
The phase of the Correlation Matrix 
{ }
ij
r
W
=
forming – as a measure of 
the dependencies between the analyzed of customers’ text-opinions 
ij
r
on the 
basis of TF-IDF transformed frequency matrix. This matrix is the basis for ap-
plying the modularity optimization algorithm of the SNA theory. 
The phase Modularity Optimization algorithm implementation. For realiz-
ing this algorithm we need to presented the dependencies between the analyzed 
of customers’ text-opinions as a graph, in which the nodes are the text-opinions 
documents, and edges – correlation dependencies between those documents with 
weight
ij
r
. 
Modularity is a metric that was proposed by Newman and Girvan in refer-
ence [19, 20]. It quantifies the quality of a community assignment by measuring 
how much more dense the connections are within communities compared to 
what they would be in a particular type of random network. One of the mathe-
matical definitions of modularity was proposed in the original paper on the Lou-
vain method [18]: 
(
)
j
i
j
,
i
j
i
ij
c
,
c
m
2
k
k
r
m
2
1
Q
δ
⎥
⎦
⎤
⎢
⎣
⎡
−
=
∑
, (8) 
where: 
∑
=
j
ij
i
r
k
− the total the weighted degree of node i (weighted-degree of a node 
is the sum of the weights of all links attached to node i); 
∑
=
j
,
i
ij
r
2
1
m
− the total link weight in the network overall. 
The Kronecker delta 
(
)
j
i
c
,
c
δ
is 1 when nodes i and j are assigned to the 
same community and 0 otherwise. Consider one of the terms in the sum. Re-
member that 
i
k
is the total the weighted degree of node i, 
m
2
k
j
– the average 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
74 
fraction of this weight that would be assigned to node j, if node i assigned its 
link weight randomly to other nodes in proportion to their own link weights). 
Then, 
m
2
k
k
A
j
i
ij
−
measures how strongly nodes i and j are in the real network, 
compared to how strongly connected we would expect them to be in a random 
network of the type described above. 
In our case, we can transform the classical definition of the Modularity met-
ric as the following: 
Modularity is number of edges, which are the correlation relationships 
ij
r
between the documents on the bases of the co-occurrence of the words, falling 
within text-opinion documents with common structure (clusters) minus the ex-
pected number in an equivalent documents network with edges placed at random. 
The problem of modularity optimization can be thought of as assigning 
communities such that the elements of the sum that contribute are as positive as 
possible. Larger modularity Q indicates better communities. Q~ = 0.3-0.7 indi-
cates good partitions. 
As a result of this phase of the algorithm of the text-meaning discovering 
we can receive the vector of the modularity classes Q – quantitative measure of 
customers’ text-opinions structural similarity modularity classes Q. 
2.3. Development of the algorithm of contextual clustering 
of customers’ text opinions and quantitative rank identification 
The objective of this stage is to confirm significance of Hypothesis 1 about 
the possibility to identify the opinions of customers by realization of the proce-
dure of dividing the analyzed documents into clusters and subsequent rank iden-
tification of the qualitative evaluation level with the help of applying the instru-
ments of the LSA and SNA analysis. 
For realization of this objective the following phase’s implementation are 
proposed: 
1.
Partition of the customers’ text-opinions on the contextual clusters via apply-
ing the k-means algorithms for clustering of the vector of the quantitative 
measure of customers’ text-opinions contextual similarity 
i
,
1
i
K
+
. 
2.
Qualitative interpretation of the 
i
,
1
i
K
+
ranges, which was adopted as a meas-
ure of the relevance to the main revealed context of the customers’ text- 
-opinions set. 
The method of a two-level text-meaning similarity approximation... 
75 
3.
Comparing the results of the contextual clusters (LSA implementation) and 
structural modularity classes (SNA implementation) for making the final de-
cision. 
3. Experimental results and finding 
As mentioned above, we will consider testing the developed algorithm on 
the example of analysis of the opinions of 32 customers of the Starbucks Coffee 
Houses, obtained from the official web-page. A fragment of the analyzed list of 
opinions is presented in the Table 1: 
Table 1. The fragment of the analyzing documents list 
Documents 
ID 
Opinion 
Doc_0 
Coffee quality is not good. Coffees are good with caramel, chocolate, cream... but if you 
order an espresso is like to drink dirty water 
Doc_1 
I wanna rate Starbucks, and the people that work there. I had only good experience with 
them / Very polite and friendly stuff. I can say only good about them and their coffee 
Doc_2 
The only one advantage is the wi-fi connection... 
Doc_3 
I want to rate just one specific store, it’s in Reading, PA, I don’t remember street name, 
but the building number is 2113 if I’m not wrong. I came there on Easter Sunday, just to 
get coffee, so what I want to mention that if to compare with other stores across the 
country (I’m traveling a lot), this one was very clean, well-organized, sugar and dairy 
station had all verity of things. Personnel was very polite and friendly. Good team work. 
Well done guys!!!!. Wish you all the best!!! 
Doc_4 
Always had good experiences with them… really quick and friendly staff... plus I am 
a coffee addict so I love that there is a Starbucks everywhere I go… 
… 
… 
Fragment of the experimental results of the Frequency Matrix FR obtaining 
is the following (totally 270 words are selected). 
Table 2. The fragment of the Frequency Matrix FR 
Doc_0 
Doc_1 
Doc_2 
Doc_3 
Doc_4 
Doc_5 
Doc_6 
Doc_7 
… 
about 
0 
1 
0 
0 
0 
0 
0 
0 
… 
accent 
0 
0 
0 
0 
0 
0 
0 
0 
… 
acknowledg 
0 
0 
0 
0 
0 
0 
0 
0 
… 
addict 
0 
0 
0 
0 
1 
0 
0 
0 
… 
after 
0 
0 
0 
0 
0 
0 
1 
0 
… 
again 
0 
0 
0 
0 
0 
0 
0 
0 
… 
all 
0 
0 
0 
2 
0 
1 
0 
0 
… 
almost 
0 
0 
0 
0 
0 
0 
0 
0 
… 
alreadi 
0 
0 
0 
0 
0 
0 
0 
0 
… 
alway 
0 
0 
0 
0 
1 
0 
0 
0 
… 
amex 
0 
0 
0 
0 
0 
0 
0 
0 
… 
amount 
0 
0 
0 
0 
0 
0 
0 
0 
… 
… 
… 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
76 
Fragment of the experimental results Frequency Matrix TF-IDF Transfor-
mation and total weight obtaining are the following (Table 3). 
Table 3. The fragment of the Frequency Matrix TF-IDF Transformation 
Doc_0 
Doc_1 
Doc_2 
Doc_3 
Doc_4 
Doc_5 
Doc_6 
Doc_7 
… 
PR
i
w
F
love 
0 
0 
0 
0 
0,14 
0 
0 
0 
… 
1,16 
servic 
0 
0 
0 
0 
0 
0,05 
0 
0 
… 
1,14 
excel 
0 
0 
0 
0 
0 
0 
0 
0 
… 
0,94 
alway 
0 
0 
0 
0 
0,19 
0 
0 
0 
… 
0,87 
one 
0 
0 
0,46 
0,08 
0 
0 
0 
0,11 
… 
0,87 
onli 
0 
0,2 
0,46 
0 
0 
0 
0 
0 
… 
0,83 
the 
0 
0 
0,36 
0 
0 
0,07 
0 
0,04 
… 
0,81 
good 
0,18 
0,18 
0 
0,04 
0,13 
0,04 
0,07 
0 
… 
0,77 
your 
0 
0 
0 
0 
0 
0 
0 
0 
… 
0,76 
coffe 
0,09 
0,05 
0 
0,02 
0,06 
0 
0 
0,03 
… 
0,72 
nice 
0 
0 
0 
0 
0 
0 
0 
0 
… 
0,72 
product 
0 
0 
0 
0 
0 
0 
0 
0 
… 
0,72 
… 
… 
The word “love” is used as the Point of Reference, which at the same time 
is determine the main context of the documents set. Suppose we set k = 2, i.e. we 
will consider only the first two singular values. Then we have: 
⎥
⎦
⎤
⎢
⎣
⎡
=
Σ
98
,
0
0
0
15
,
1
2
about 
−0,0086 
0,0057 
accent 
−0,0011 
−0,0004 
acknowledg 
−0,0023 
0,0019 
addict 
−0,0305 
0,0171 
after 
−0,0041 
0,0025 
again 
−0,0015 
0,001 
S
k
=
all 
−0,0056 
0,0028 
almost 
−0,0034 
0,001 
alreadi 
−0,0011 
0,0006 
alway 
−0,2459 
0,3619 
am 
−0,006 
−0,0062 
amex 
−0,0039 
0,0021 
amount 
−0,0333 
0,0815 
… 
…. 
… 
Doc_0 
Doc_1
Doc_2
Doc_3
Doc_4
Doc_5
Doc_6
Doc_7
T
k
U
=
0,02 
0,06
0,03
0,02
0,06
0,04
0,02
0,01
… 
−0,02 
−0,09
0,02
0
−0,09
0,01
0,01
0,01
… 
The words in the concept space are represented by the row vectors of 
2
S
whereas the documents by the column vectors of 
T
2
U
. In fact we scale the (two) 
coordinates of these vectors by multiplying with the corresponding singular val-
The method of a two-level text-meaning similarity approximation... 
77 
ues of 
2
Σ
and thus represent the terms by the row vectors of 
2
2
S
Σ
and the doc-
uments by the column vectors of 
T
2
2
U
Σ
.
Calculation of the measure of semantic similarity was conducted with the 
use of the Cosine measures. The examples of the experimental results of the 
measure of similarity 
i
,
1
i
K
+
calculation are presented in the Table 4 and fragmen-
tary in the Figure 3: 
Table 4. The example of the experimental results of the measure 
of similarity 
i
,
1
i
K
+
calculation 
Documents 
i
,
1
i
K
+
Common (key) words 
1,4 
0,038 
experi, coffee, good 
14, 4 
0,049 
coffee, love 
12, 14 
0,094 
starbuck, love, coffe 
26, 12 
0,139 
coffe, friend 
4, 26 
0,285 
alway, friend, coffe, love, starbuck 
26, 16 
0,371 
chocol, me, love time, starbuck 
12, 3 
0,482 
starbuck, from 
26, 25 
0,560 
coffe, amout, veri, shop 
14, 25 
0,63 
coffe, shop, well, starbuck 
31, 25 
0,682 
starbuck, like 
17, 3 
0,740 
starbuck, been, all, like 
23, 26 
0,750 
starbuck, customer,servic 
26, 28 
0,760 
servic, coffe 
14, 22 
0,790 
coffe, fan, shop 
8, 12 
0,810 
starbuck, food 
12, 25 
0,820 
friend, coffe, like, starbuck 
25, 27 
0,850 
starbuck, love,servic, coffe 
21, 4 
0,850 
coffe, shop 
14, 19 
0,900 
starbuck, coffe, shop, like 
11, 22 
1,100 
Starbuck, not 
10, 24 
1,193 
starbuck, staff, coffe, , nothing 
24, 11 
1,207 
starbuck, not, or, me, make, custom, day, becaus, unfortun, 
went, off, one, want, buy, from, coffe, all, back, veri, time 
24, 9 
1,220 
starbuck, not, good 
11, 10 
1,239 
starbuck, store, time, been, all, like, custom, contact, or, went, 
me, becaus, anyth, who, back, be, refus, out, said, anoth, two, 
three, day 
24, 23 
1,310 
servic, starbuck 
28, 10 
1,320 
starbuck, becaus 
0, 20 
1,500 
coffe, good, but 
21, 23 
1,540 
order, coffe, like, caramel, not, good 
6, 7 
1,610 
say, like, not, good, put, sticker 
20, 18 
1,750 
starbuck, wait, serviс 
30, 6 
1,857 
not, after 
18, 29 
1,908 
starbuck, locat, seem, their, than, not, or, visit, week, those, 
someth, get, from 
5, 15 
1,948 
want, one, not, good, countri, travel, veri, all, thing 
13, 7 
1,986 
card, say, becaus, all 
7, 0 
1,993 
coffe, like, good 
2, 8 
2,000 
one, starbuck, day 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
78 
Figure 3. The fragment of the LSA tools implementation experimental results 
Source: Results of the experiments. 
For receiving the quantitative measure of customers’ text-opinions struc-
tural similarity modularity classes Q the stage of modularity optimization of the 
SNA theory algorithm was conducted. The matrix of correlation relationships 
{ }
ij
r
W
=
between the documents on the bases of the co-occurrence of the words 
was obtained (Table 5). 
Table 5. The Fragment of the Experimental Results of Correlation Matrix W 
Doc_0
Doc_1 
Doc_2 
Doc_3
Doc_4
Doc_5
Doc_6
Doc_7
Doc_8
Doc_9 
Doc_10 
Doc_0 
1,000 
Doc_1 
0,305 
1,000 
Doc_2 
−0,018
0,324 
1,000 
Doc_3 
0,123 
0,236 
0,194 
1,000 
Doc_4 
0,270 
0,425 
−0,017 
0,089 
1,000 
Doc_5 
0,063 
0,063 
−0,027 
0,067 
−0,005
1,000 
Doc_6 
0,251 
0,104 
−0,018 
0,029 
0,090 
0,078 
1,000 
Doc_7 
0,214 
0,080 
0,241 
0,237 
0,068 
−0,016
0,210 
1,000 
Doc_8 
0,013 
0,073 
−0,020 
0,122 
0,035 
−0,072
−0,049
0,079 
1,000 
Doc_9 
0,153 
0,127 
0,043 
−0,039
0,027 
−0,046
0,072 
0,118 
0,018 
1,000 
Doc_10 
0,091 
0,040 
−0,027 
0,070 
0,008 
0,017 
0,000 
0,139 
0,063 
0,204 
1,000 
The method of a two-level text-meaning similarity approximation... 
79 
On the basis of this matrix the Modularity optimixzation algorithm was 
inmlamented. As a result – the 4 Modularity classes Q as quantitative measures 
of customers’ text-opinions structural similarity modularity classes with the 
Modularity coefficient 0,61 was received (Figure 4, Table 6). 
Figure 4. The results of the modularity optimization algorithm realization 
Source: Results of the experiments. 
Table 6. The example of the experimental results of the modularity optimization 
algorithm realization 
Documents 
Weighted Degree k
i
Modularity Class 
1 
2 
3 
Doc_1 
3,208856 
0 
Doc_12 
4,236518 
0 
Doc_14 
4,296015 
0 
Doc_15 
4,181601 
0 
Doc_16 
3,73195 
0 
Doc_17 
1,238412 
0 
Doc_19 
4,662027 
0 
Doc_25 
1,068756 
0 
Doc_26 
3,109359 
0 
Doc_27 
1,028323 
0 
Doc_3 
2,166251 
0 
Doc_31 
4,404249 
0 
Doc_4 
4,289584 
0 
Doc_21 
2,757831 
1 
Doc_22 
1,4592 
1 
Doc_23 
0,751695 
1 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
80 
Table 6 cont. 
1 
2 
3 
Doc_28 
3,001274 
1 
Doc_29 
0,845228 
1 
Doc_8 
1,044076 
1 
Doc_10 
1,84973 
2 
Doc_11 
2,756099 
2 
Doc_2 
1,971137 
2 
Doc_24 
3,676981 
2 
Doc_9 
2,201011 
2 
Doc_0 
3,193837 
3 
Doc_13 
1,05275 
3 
Doc_18 
3,599364 
3 
Doc_20 
1,857333 
3 
Doc_30 
2,057538 
3 
Doc_5 
1,550596 
3 
Doc_6 
1,358176 
3 
Doc_7 
3,964580 
3 
On the bases of the data, presented in the Table 4, the classical procedure of 
the k-means clustering algorithms was realized. As a result, were received: 
•
absolute and relative ranges of the Measure of Similarity with their qualita-
tive interpretation (Table 7): 
Table 7. Ranges of the similarity measure 
Cluster 
Measure of similarity 
range 
Relative rank of the 
evaluation 
Qualitative interpretation 
1 
[0,00; 0,5] 
[0,76; 1] 
very good 
2 
[0,51; 1,0] 
[0,51; 0,75] 
good 
3 
[1,10; 1,5] 
[0,26; 0,5] 
satisfactorily 
4 
[1,51; 2,0] 
[0;0,25] 
bad 
•
the lists of the customers’ text-opinions, belonging to contextual clusters and 
structural modularity classes (Table 8): 
Table 8. The example of the experimental results of the contextual cluster and structural 
modularity classes 
Clusters 
Contextual Clusters 
Clusters 
Structural Modularity Classes 
1 
1, 4, 12, 14, 16, 26 
− 
− 
2 
3, 15, 17, 19, 23, 25, 27, 31, 8, 21, 22, 
28 
2 
1, 3, 4, 12, 14, 15, 16, 17, 19, 25, 26, 
27, 31 
3 
8, 10, 11, 24, 22, 23, 28 
3 
2, 9, 10, 11, 24 
4 
0, 2, 5, 6, 7, 9, 13,18, 20, 29, 30, 8, 21, 
23 
4 
0, 5, 6, 7, 13,18, 20, 30 
− 
− 
5 
8, 21, 22, 23, 28, 29 
The method of a two-level text-meaning similarity approximation... 
81 
Comparing the results of the data of the Table 8 leads to the following re-
marks: 
1.
Belonging the documents of the Structural Modularity Classes two smaller 
Contextual clusters 1 and 2 allows: 
−
on the one hand, to establish the fact the presence of more subtle differ-
ences contextual and structural differences between the opininons, de-
scribing the qualitative interpretation of “Good”; 
−
on the other hand, the presence of distinction between the contextual and 
the structural specifics of the analyzed text-opinions, particularly pro-
nounced when comparing the documents of the different size. 
2.
The presence of the documents number 8, 21, 22, 28, 23, 21 simultaneously 
in several clusters may indicate too broad semantic context, or what is the 
same, the lack of dipole content compliance customers's opinion the key 
theme of the analyzed documents – “Evaluation the quality coffee at Star-
bucks network”. A brief visual analysis of the context of the selected docu-
ment allows to confirm this assumption – their content is really blurred. For 
the most cases authors express their, not related to the topic of the survey, 
emotions, gives examples of incidents from their own life and only casually 
refer to the main topic, including a reference to the previous authors’ opinion. 
In that regard, authors proposed to move these documents in a separate clus-
ter with the title of “Does not correspond to the topic”. 
3.
Some differences in the composition of the main documents clusters of can 
also be explained as the differences in the mathematical basis of the used 
methods, and the blurring of of the content of some customer opininons. 
In this connection, the authors propose the following concept of the adap-
tive algorithm of comparing the results of the contextual clusters and structural 
modularity classes for making the final decision: 
–
identification the common clusters between two results; 
–
isolation of the documents simultaneously belonging to several clusters in the 
separate cluster; 
–
adjustment of the obtained clusters and their qualitative interpretation based 
on the comparison results. 
As an example of this adaptive algorithm realisation could be the following 
identification and clustering of customers’ opinions results (Table 9). 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
82 
Table 9. The example of the clustering of customers’ opinions results 
Clusters 
Qualitative Interpretation 
Structural Modularity Classes 
1 
very good 
1, 4, 12, 14, 16, 26 
2 
good 
3, 15, 17, 19, 23, 25, 27, 31 
3 
satisfactorily 
2, 9, 10, 11, 24 
4 
bad 
0, 5, 6, 7, 13,18, 20, 30 
5 
does not correspond to the topic 
8, 21, 22, 23, 28, 29 
As software tools for the technical realization of the two-level text-meaning 
similarity approximation method in this paper proposed the usage of the devel-
oped by authors latent-semantic analysis’ software (based on the Python lan-
guage) and standard SNA applications (e.g. Gephi) [21, 22, pp. 180-187, 23]. 
Conclusions and further research direction 
Research contribution 
Thus, the method of two-level text-meaning similarity approximation, con-
sisting in the implementation of the classification of the stages of Contextual 
Clustering of customers’ text opinions and Quantitative Rank identification, 
have developed. The authors research contribution is to use this method for the 
express evaluation of customer opinion groups with the following main purpose: 
−
identification of the qualitative opinion’s structure; 
−
optimization the opinion’s search process – extracting the keywords for each 
clusters; 
−
cleaning the opinion’s documents set via finding the meaingless (with con-
nectinon on the evaluation context) opinion’s. 
The study limitation was not enough the sample size and studing only the 
specifice group of the textual opinions of the Starbucks Coffee Houses custom-
ers. That is why the future research presuppose to continue the studying the dif-
ferent types of the textual messages – both in terms of subject and size of the 
analyzed text 
Practical implementation 
Large number of opinions is easily accessible nowadays. It is desirable to 
understand their properties as they potentially contain valuable information. Ask 
Data Anything (ADA) is a system developed by Cognitum that is using a com-
bination of formal logic and statistical analysis to extract dimensions from the 
data and to expose the dimensions through a natural query language based inter-
face. Currently we are implementing the method of a two-level text-meaning 
The method of a two-level text-meaning similarity approximation... 
83 
similarity approximation to embed it in the ADA system for the Customers’ 
Opinions mining purposes as a part of joint collaboration with Cognitum com-
pany [24-26]. 
References 
[1] S. Deerwester, S.T. Dumais, G.W. Furnas, Th.K. Landauer, R. Harshman, Indexing 
by Latent Semantic Analysis, “Journal of the American Society for Information 
Science” 1990, No. 41(6), pp. 391-407. 
[2] J.I. Maletic, N. Valluri, Automatic Software Clustering via Latent Semantic Analysis, 
14
th
IEEE ASE’99, Cocoa Beach, FL October 12-15
th
1999, pp. 251-254. 
[3] J.R. Paulsen, H. Ramampiaro, Combining Latent Semantic Indexing and Clustering 
to Retrieve and Cluster Biomedical Information: A 2-Step Approach. NIK-2009 
conference, Proceedings of a Meeting Held 23-25 November 2009, Trondheim, 
Norway. 
[4] L. Jing, M.K. Ng, X. Yang, J.Z. Huang, A Text Clustering System Based on 
k-Means Type Subspace Clustering and Ontology. “International Journal of Intelli-
gent Technology” 2006, Vol. 1(2), pp. 91-103. 
[5] D. Roussinov, J. Leon Zhao, Text Clustering and Summary Techniques for CRM Mes-
sage 
Management, 
https://personal.cis.strath.ac.uk/dmitri.roussinov/Lim-Paper.pdf 
(accessed: 12.06.2016). 
[6] R. Řehůřek, Subspace Tracking for Latent Semantic Analysis [in:] European Con-
ference on Information Retrieval, Springer, Berlin-Heidelberg 2011, pp. 289-300. 
[7] T. Pedersen, Duluth: Word Sense Induction Applied to Web Page Clustering, Pro-
ceedings of the 7
th
International Workshop Semantic Evaluation (SemEval 2013), 
in conjunction with the Second Joint Conference on Lexical and Computational 
Semantics (*SEM-2013), 2013, pp. 202-206. 
[8] D. Jurgens, The S-Space Package: An Open Source Package for Word Space Mod-
els, Proceedings ACLDemos ’10, Proceedings of the ACL System Demonstrations, 
2010, pp. 30-35. 
[9] R. Řehůřek, P. Sojka, Software Framework for Topic Modelling with Large Cor-
pora, 
Proceedings 
of 
the 
LREC 
2010 
Workshop, 
New 
Challenges 
for 
NLP 
Frameworks, 2010, pp. 45-50. 
[10] T. Hofmann, Probabilistic Latent Semantic Indexing, Proceedings of The 22
nd
Annual International SIGIR Conference Research and Development in Information 
Retrieval, Berkeley 1999, pp. 50-57. 
[11] R.B. Bradford, An Empirical Study of Required Dimensionality for large-Scale 
Latent Semantic Indexing Applications, Proceedings of the 17
th
ACM Conference 
on Information and Knowledge Management, Santa Cruz, CA 2008, pp. 153-162. 
[12] R.K. Ahuja, Th.L. Magnanti, J.B. Orlin, Network Flows: Theory, Algorithms, and 
Applications, Prentice Hall, Englewood Cliffs, NJ 1993. 
Nina Rizun, Paweł Kapłański, Yurii Taranenko 
84 
[13] B. Bollobas, Modern Graph Theory, Springer, Berlin-Heidelberg 1998. 
[14] D. West, Introduction to Graph Theory, Prentice Hall, Upper Saddle River, NJ 1996. 
[15] L.C. Freeman, Centrality in Social Networks: Conceptual Clarification, “Social 
Networks” 1979, Vol. 1 (3), pp. 223-258. 
[16] L.C. Freeman, Visualizing Social Networks, “Journal of Social Structure” 2000, 
Vol. 1(1). 
[17] L.C. Freeman, The Development of Social Network Analysis: A Study in the Soci-
ology of Science, Empirical Press, Vancouver 2004. 
[18] A. Thomo, Latent Semantic Analysis, http://www.engr.uvic.ca/~seng474/svd.pdf 
(accessed: 1.06.2016). 
[19] M.E.J. Newman, M. Girvan, Finding and Evaluating Community Structure in 
Networks, “Physical Review” 2004, E. 69, 026113. 
[20] M.E.J. Newman, C. Moore, Finding Community Structure in Very Large Networks, 
“Physical Review” 2004, E 70, 066111. 
[21] P. Kapłanski, N. Rizun, Y. Taranenko, A. Seganti, Text-Mining Similarity Approx-
imation Operators for Opinion Mining in BI tools, Chapter: Proceeding of the 11
th
Scientific Conference “Internet in the Information Society-2016”, Publisher of 
University of Dąbrowa Górnicza, Dąbrowa Górnicza, pp. 121-141. 
[22] N. Rizun, P. Kapłanski, Y. Taranenko, Development and Research of the Text 
Messages Semantic Clustering Methodology, Third European Network Intelligence 
Conference, ENIC, Wroclaw 2016. 
[23] P. Kapłanski, N. Rizun, Y. Taranenko, A. Seganti, Text-Mining Similarity Approx-
imation Operators for Opinion Mining in BI tools [in:] M. Rostancki, P. Pikiewicz, 
K. Mączka, P. Buchwald, Proceeding of the 11
th
Scientific Conference “Internet in 
the Information Society-2016”, University of Dąbrowa Górnicza, Dąbrowa Gór-
nicza 2016, pp.121-141. 
[24] P. Kapłanski, P. Weichbroth, Cognitum Ontorion: Knowledge Representation and 
Reasoning System [in:] Position Papers of the 2015 Federated Conference on 
Computer Science and Information Systems, FedCSIS 2015, Łódz, Poland, Sep-
tember 13-16, 2015, http://dx.doi.org/10.15439/2015F17 (access: 28.05.2016). 
[25] P. Kapłanski, Controlled English Interface for Knowledge Bases, “Studia Informatica” 
2011, Vol. 32, No. 2A, pp. 485-494. 
[26] A. Wroblewska, P. Kaplanski, P. Zarzycki, I. Lugowska, Semantic Rules Represen-
tation in Controlled Natural Language in FluentEditor [in:] Human System Inter-
action (HSI), The 6
th
International Conference on IEEE, 2013, pp. 90-96. 
The method of a two-level text-meaning similarity approximation... 
85 
METODA DWUPOZIOMOWEGO PRZYBLIŻONEGO OBLICZENIA 
PODOBIEŃSTWA ZNACZENIA TEKSTÓW OPINII KLIENTÓW 
Streszczenie: Opracowano metodę dwupoziomowej aproksymacji podobieństwa – me-
todę przetwarzania tekstu, którą zastosowano w problemie klasyfikacji oraz do określa-
nia poziomu jakości klientów. Posługując się zaproponowaną w artykule metodyką, 
udowodniono istotność głównych hipotez, w szczególności hipotezy o istnieniu analogii 
pomiędzy podstawami matematycznymi LSA (ang. Latent Semantic Analysis), bazującej 
na analizie relacji semantycznej związku między stopniem udziału analogicznych pojęć 
w zbiorze dokumentów a narzędziami teorii analizy sieci społecznych (ang. Social Ne-
twork Analysis), która z kolei odsłaniania cechy obiektów na podstawie informacji na 
temat struktury ich wzajemnych powiązań. Z połączenia powyższych metod wyłoniła się 
struktura klastra kontekstu, dająca ocenę ilościową na potrzeby ranking poziomu jakości 
opinii szacowanych klientów. 
Słowa kluczowe: znaczenie tekstu, ukryta analiza semantyczna, analiza sieci społecznych. 
