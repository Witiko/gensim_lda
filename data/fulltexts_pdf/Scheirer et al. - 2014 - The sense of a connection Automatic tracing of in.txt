The sense of a connection:
Automatic tracing of intertextuality
by meaning
................................................................................................ ............................................................
Walter Scheirer
Harvard University,
Cambridge,
MA,
USA
Christopher Forstall
University of Geneva,
Geneva,
Switzerland
Neil
Coffee
University at Buffalo,
Buffalo,
NY,
USA
................................................................................................ .......................................
Abstract
In literary study,
intertextuality refers to the reuse of text,
where new meaning
or novel stylistic effects have been generated. Most typically in the digital huma-
nities,
algorithms for intertextual
analysis search for approximate lexical
corres-
pondence that
can be described as
paraphrase.
In this
article,
we look at
a
complimentary approach that more closely captures the behavior of the reader
when faced with meaningful
connections between texts in the absence of words
that have the same form or stem,
which constrains the match to semantics.
The
technique we employ for identifying such semantic intertextuality is the popular
natural language processing strategy of semantic analysis. Unlike the typical scen-
ario for semantic analysis,
where a corpus of long form documents is available,
we examine the far more limited textual
fragments that embody intertextuality.
We are primarily concerned with texts from antiquity,
where small
phrases or
passages often form the locus of comparison.
In this vein,
we look at a specific
case study of established parallels between book 1 of Lucan’s Civil War and all of
Vergil’s Aeneid.
Applying semantic analysis over these texts,
we are able to re-
cover parallels that lexical
matching cannot,
as well
as discover new and inter-
esting thematic matches between the two works.
................................................................................................ .................................................................................
1 Introduction
The recognition that poetic texts are often signifi-
cantly linked to their predecessors through shared
or similar language has been an important part of
the reading and study of
literature since antiquity.
More
recently,
however,
scholarly
interest
has
broadened beyond the verbatim reuse of
specific
phrases
1
to take in the great scope and subtlety of
intertextual connections.
2
The term intertext, coined
by Julia Kristeva (1986, p. 37), has come to be used
widely in literary studies to indicate linguistic simi-
larity that,
in presenting to the reader
a marked
connection
between
two
texts,
generates
new
meaning or novel
stylistic effects.
Emerging digital
methods now make it possible to trace this sort of
Correspondence:
Walter Scheirer,
Harvard
University,
Cambridge,
MA,
USA.
E-mail:
wscheirer@fas.harvard.edu
Digital
Scholarship in the Humanities ß The Author 2014.
Published by Oxford University Press on behalf of EADH.
All
rights reserved.
For Permissions,
please email:
journals.permissions@oup.com
1 of 14
doi:10.1093/llc/fqu058
Digital Scholarship in the Humanities Advance Access published December 2, 2014
intertextuality with some success.
Most
typically,
computational
approaches
search for
the type of
lexical
correspondences
that
can
be
loosely
described as paraphrase.
3
The process closely resem-
bles the manual identification of intertextuality still
commonly practiced by literary scholars,
including
the writers of commentaries (Coffee et al.,
2014).
This
same
work
has
demonstrated,
however,
that
meaningful
connections
between texts
occur
not
only via lexical
similarity but
also through a
broader
similarity of
meaning in the
absence
of
words that have the same form or stem.
4
The clas-
sicist Stephen Hinds describes this phenomenon as
a
‘poetic
of
corresponding
inexactitude,
which
draws on but also distances itself from the rigidities
of philological
and intertextualist fundamentalisms
alike’ (Hinds, 1998, p. 50). One study indicated that,
among a certain set of meaningful parallels between
two texts,
some 33% were made up by similarity of
meaning in the absence of
more than one shared
word (Coffee et al.,
2012,
p.
415).
Quite
remarkably,
human readers
are
rather
adept
at
identifying text
reuse
when faced with
such ‘inexactitude’,
where
a
predefined formula
for lexical
matching drawn from textual
criticism
would simply fail. For instance, consider the follow-
ing lines
from the Roman poet
Lucan,
which,
in
an epic simile,
characterize the once-great
general
Pompey on the eve of
the Roman Civil
War as a
tottering,
but still
venerated,
oak
5
:
qualis frugifero quercus sublimis in agro,
exuvias veteres populi sacrataque gestans
dona
ducum,
nec
iam validis
radicibus
haerens,
pondere fixa suo est; nudosque per aera ramos
effundens,
trunco,
non
frondibus,
efficit
umbram;
et quamvis primo nutet casura sub Euro,
tot circum silvae firmo se robore tollant,
sola tamen colitur.
(Lucan,
Civil
War 1.136–43)
Just as a lofty oak in a productive field,
bear-
ing the ancient spoils and consecrated gifts of
leaders,
but
no longer clinging with healthy
roots,
is
fixed in place
by its
own weight;
and spreading out bare branches through the
air,
it
casts
a shadow from its
trunk rather
than its leaves;
and,
although it
sways,
ready
to fall at the first easterly wind, while so many
of
the surrounding trees bear themselves up
on sturdy hardwood,
it alone is honored.
Commentators
6
on this poem have noted intertext-
ual
connections
to
several
passages
in
Vergil’s
Aeneid.
Among them is
another
simile,
this
one
comparing the doomed city of
Troy,
finally pene-
trated by the besieging Greeks,
to a moribund ash-
tree toppled by industrious peasants:
ac
veluti
summis
antiquam in
montibus
ornum
cum ferro
accisam crebrisque
bipennibus
instant
eruere agricolae certatim,—illa usque minatur
et tremefacta comam concusso vertice nutat,
volneribus donec paulatim evicta,
supremum
congemuit,
traxitque iugis avolsa ruinam.
(Vergil,
Aeneid 2.626–531)
Just as when farmers vie to uproot an ancient
ash-tree high in the mountains, hacked at with
a rain of blows from their iron axes—it keeps
threatening to fall,
and,
with its foliage trem-
bling,
its crown shaken,
it sways,
until,
over-
come little by little with its wounds, uprooted
from the ridge,
it
at
last
gives
a groan and
heaves forward its own collapse.
As readers,
how do we recognize that these two
texts are related, when they share just one distinctive
word,
‘sway’
(nuto)
7
?
We
see
a
resemblance
of
theme:
both texts
describe
a
tottering
old tree.
Both passages
also share a narrative function.
In
each case the tottering tree foreshadows the down-
fall of a hitherto stalwart bastion: the Trojan citadel
in the Aeneid, the republican general Pompey in the
Civil
War.
Indeed,
the two events appear intertext-
ually
connected:
the
capture
and destruction of
mythological
Troy anticipates the historical
defeat
and death of the Roman leader.
8
Theme,
narrative structure,
historical
and myth-
ical
events:
the ability of
poetic language to forge
connections
simultaneously among such different
sign-systems
is
precisely
what
Kristeva’s
original
broad notion of
intertextuality as ‘an intersection
W.
Scheirer et al.
2 of 14
Digital
Scholarship in the Humanities,
2014
of textual surfaces’ (Kristeva, 1986, p. 37) was meant
to encompass.
This view of intertextuality leads us
to think of
words,
even different but related ones,
as part
of
a continuum of
reuse and repurposing,
and so to see in our examples of epic collapse,
and
countless others, the potential for thematic material
from one context
to be redeployed in another to
new effect.
Given the complexity of
literary meaning that
arises
when readers
encounter
such instances
of
intertextuality,
how can we capture it
adequately
with a computer
model?
What
we
need,
in the
words
of
Hinds,
is
a ‘fuzzy logic’
that
is
flexible
enough to identify highly inexact
matches
often
based in thematic similarity (Hinds,
1998,
p.
50).
The
technique
we
employ
for
identifying
such
semantic intertextuality is the popular natural
lan-
guage
processing
strategy
of
semantic
analysis.
Algorithms
for semantic analysis
are typically de-
signed around the notion of
word co-occurrence.
That
is,
they start
from the assumption,
possibly
counterintuitive but well-demonstrated,
that words
that occur in the same contexts have related mean-
ings.
This assumption,
coupled with the cognitive
matching process
described above,
motivated the
design of Latent Semantic Indexing (LSI),
an early
and still
powerful
approach (Deerwester
et
al.,
1990).
The use of algorithms for semantic analysis,
including topic modeling (Blei,
2011),
has spread
from the practical
applications of natural
language
processing to become a popular
tool
for
literary
studies among digital
humanists.
Recent
work has
used
semantic
analysis
to
distinguish
between
genres,
produce an algorithmic historiography of
classical
scholarship,
and characterize sentiment in
political
writing.
9
These types of tasks fall
into what Jockers terms
macroanalysis
(Jockers,
2013),
which applies
the
tools
of
machine
learning to collect
quantifiable
evidence of literary phenomena over large corpora,
which might
consist
of
the collected works of
an
author,
whole genres,
and entire literatures.
When
instead used for
close
reading,
semantic
analysis
has
the potential
to reveal
the characteristics
and
behavior
of
the
language
elements
that
partici-
pate in intertextual
connections.
In this work,
we
are
concerned with texts
from antiquity
where
intertextuality
takes
the
form of
similar
small
phrases or passages,
as opposed to corpora of large
documents where semantic analysis is more com-
monly applied.
Let
us begin with an example of
how semantic
analysis can be applied to this sort of small
collec-
tion.
Consider
the following lines
of
Latin from
Lucan’s Civil
War as a simple corpus:
(1)
bella per Emathios plus quam civilia campos
iusque datum sceleri canimus
(2)
post
Cilicasne
vagos,
et
lassi
Pontica
regis
proelia,
barbarico vix consummata veneno,
ultima Pompeio dabitur provincia Caesar
(3)
sed non in Caesare tantum nomen erat,
nec
fama ducis: sed nescia virtus stare loco: solus-
que pudor,
non vincere bello
(4)
turba minor ritu sequitur succincta Gabino,
Vestalemque chorum ducit
vittata sacerdos,
Troianam soli cui fas vidisse Minervam
(5)
certe
populi,
quos
despicit
Arctos,
felices
errore
suo,
quos
ille
timorum maximus
haud urget,
leti metus
(6)
quodque (nefas) nullis inpune apparuit extis,
ecce,
videt
capiti
fibrarum increscere molem
alterius capitis
(7)
iam gelidas
Caesar
cursu superaverat
Alpes,
ingentisque
animo
motus,
bellumque
futurum ceperat.
ut
ventum est
parvi
Rubiconis ad undas
(8)
rupta quies populi,
stratisque excita iuventus
deripuit
sacris
adfixa penatibus
arma,
quae
pax longa dabat
(9)
non,
si
tumido me gurgite Ganges summo-
veat,
stabit
iam flumine Caesar in ullo,
post
Rubiconis aquas
Now suppose that we would like to find which of
the above lines, if any, have some thematic similarity
to the phrase Rubiconis
aquas
(‘the waters
of
the
Rubicon’). Given that Caesar is famously associated
with crossing the Rubicon,
if
a semantic analysis
approach were effective,
we would expect a search
for thematic material related to the Rubicon to turn
up phrases
in which Caesar appears.
To test
this
hypothesis,
we applied LSI
to search for
content
similar
to Rubiconis
aquas.
An in-depth look at
the LSI
algorithm,
including a description of
the
The sense of a connection
Digital
Scholarship in the Humanities,
2014
3 of 14
relevant parameters, follows in the next section. For
now,
let
us
simply consider
the top three results
returned when we perform this
test
with an LSI
approach,
using two topics and cosine distance:
As
the results
indicate,
the test
was
successful:
the search for thematic content
similar to ‘waters
of
the
Rubicon’
turned up passages
referring to
Caesar
as
the
top three
results.
In one
of
these
phrases,
the search for
meanings
similar
to those
of
Rubiconis
aquas
detected
mention
of
the
Rubicon itself,
along
with Caesar,
but
the
two
others
did not.
The results
also show substantial
precision.
The algorithm did not
recall
everything
related to Caesar,
but only hits rich in the martial
language
that
also
co-occurs
with
the
word
Rubicon,
an emblem of the civil
war.
This simple test suggests that material likely to be
thematically associated in the mind of
the reader
(Caesar and Rubicon) can also be identified through
semantic analysis.
The remainder of this article will
address in greater detail
a more complicated task.
Whereas we have just
demonstrated a search that
finds passages matching a phrase,
we turn now to
detecting semantic
similarity between two whole
passages.
The goal
of this sort of search is that the
reader
interested in finding
instances
of
textual
similarity absent
verbal
repetition will
ultimately
not
need to input
a search term,
as we have just
done,
but will
be able to simply search all
passages
of one given work against all
of those in another.
With this basic understanding of
our goals and
approach in place,
we can summarize the contribu-
tions we describe in the remainder of this article:
(1)
A methodology for applying semantic analysis
to
the
problem of
detecting
instances
of
intertextuality
without
strict
lexical
corres-
pondence (Sec.
2).
(2)
An extensive experimental
analysis that com-
pares
the
results
of
semantic
analysis
to
human analysis,
i.e.
scholarly commentaries
that compare two texts (Sec.
3).
(3)
A publically accessible web tool
that
allows
nonexperts
to apply
our
semantic
analysis
methodology to a large corpus of Latin writers
(Sec.
4).
(4)
The discovery of
thematic matches
between
Lucan’s
Civil
War
and Vergil’s
Aeneid not
previously
recorded by
commentators
that
were detected by our tool
(Sec.
4).
2 Methods
2.1 LSI approach
To find the passages that
best
match a particular
query phrase by context,
we need to not only gen-
erate a semantic model
but
also assess
similarity
within that
model
space.
For
this
purpose,
we
chose to use the LSI module of the Gensim
10
frame-
work
(Rehurek
and Sojka,
2010)
in a
custom
Python program.
The
underlying algorithm per-
forms a transformation on a set of
document vec-
tors
to draw out
latent
structure
in the
corpus,
and to reduce
dimensionality
for
computational
efficiency.
This is accomplished via Singular Value
Decomposition (SVD),
a matrix factorization tech-
nique in linear algebra.
A similarity search is then
1.
post Cilicasne vagos,
et lassi Pontica regis
proelia,
barbarico vix consummata veneno,
ultima
Pompeio dabitur provincia Caesar . . .?
(Civil
War 1.336–8)
After defeating roving Cilician pirates and after
battles on the Black sea with the fading king,
scarcely ended by barbaric poison,
will
Caesar now be handed over to Pompey as his
last charge?
2.
iam gelidas Caesar cursu superaverat Alpes,
ingentisque animo motus bellumque futurum
ceperat.
ut ventum est parvi Rubiconis ad undas.
(Civil
War 1.183–5)
Already Caesar had overcome the frozen Alps with
speed,
and in his heart he had anticipated the great
upheavals and war to come,
when he arrived at the
waters of the slender
Rubicon.
3.
sed non in Caesare tantum nomen erat,
nec fama
ducis:
sed nescia virtus stare loco:
solusque pudor,
non vincere bello.
(Civil
War 1.143–5)
But Caesar had not only a name and renown as a
general,
but also a courage incapable of standing
still,
and shame only at conquering without war.
W.
Scheirer et al.
4 of 14
Digital
Scholarship in the Humanities,
2014
performed in the resulting low rank transformation
space.
In order to provide enough contextual
informa-
tion
for
the
models
and
still
keep
the
input
highly localized to specific phrases, a window of ap-
proximately 500 characters around and including a
target line of text was always selected to form a pas-
sage considered a ‘query’. Similarly, a window of ap-
proximately 1000 characters around and including a
line
from the
text
we
wanted to match against
formed a passage considered a ‘document’.
Note
that each line from the text was used as a basis to
create a document,
resulting in a large measure of
overlap between documents as the window moved
across the text.
A collection of all
such documents
from a text
represents
a training corpus.
During
preprocessing,
the most
common 250 words from
the Tesserae corpus
11
were removed from consider-
ation. This list contains function words, as well as the
most common nouns, verbs, adjectives, and adverbs.
Each passage was then processed into a bag-of-words
representation, with the inflected form of each word
replaced with the set of all possible stems.
This was
done in lieu of typical lemmatization to increase the
amount of text available for training (see the discus-
sion of small sample sizes below).
Each LSI model for a corpus was trained using a
user-specified number of topics (i.e. the dimensions
retained after
SVD is
applied by the algorithm).
Similarity queries proceeded by projecting a query
passage and a corpus into the transformed model
space,
and assessing cosine similarity between the
query passage and each document in the corpus to
produce a set of match scores (in the range 1 to 1,
where
a
higher
score
indicates
a
better
match).
These scores were then sorted to provide a ranked
list
of
potential
matches.
The source code for this
algorithm is available publicly on Github as part of
the Tesserae web tool.
12
A mathematically inclined reader might ask why
we opted for LSI
instead of
a more flexible topic
modeling
approach
such
as
Latent
Dirichlet
Allocation
(LDA)
(Blei
et
al.,
2003).
During
the course of
this work,
we evaluated several
LDA
implementations
including
the
online
learning
technique provided by Gensim,
and the efficient
sampling-based
implementation
provided
by
MALLET (McCallum,
2002).
For
text
samples
as
small
as
our
passages,
these algorithms
were not
numerically stable,
i.e.
they produced radically dif-
ferent match scores for the exact same input across
multiple trials.
This is a significant problem for the
scholar attempting to search for instances of textual
reuse with some degree of confidence.
The cause is
an artifact of random bootstrapping (i.e. initializing
the algorithm with different random data each time
it
is
run)
with limited sampling.
The
minimum
sampling of text required for the statistical
estima-
tors to converge is something greater than what we
are providing—LDA is
most
typically applied to
long-form documents
and
any
implementation
must
make certain assumptions on its input.
This
is a key open issue in machine learning for the digi-
tal
humanities:
textual
analysis
for
forms
such as
poetry, song, or epigraphy will nearly always involve
small
samples.
13
Our testing revealed drift in only the least signifi-
cant digit of
the scores produced by Gensim’s LSI
implementation,
14
giving us enough stability to re-
liably replicate our results over any number of trials.
The
sizes
of
the
query
and document
passages
described above
were
determined experimentally
with numerical
stability
in mind.
Five
hundred
characters
for
the query and 1000 characters
for
the document
represent
the smallest
passage sizes
that
form a highly localized window around their
respective target
lines
(ensuring that
matches
are
not too broad),
while providing enough numerical
stability for the LSI algorithm.
For
comparison,
we also considered a simpler
semantic analysis approach without
the rank low-
ering of the LSI algorithm on the same texts.
Again
using the Gensim module,
we computed the cosine
distance between just the bag-of-words representa-
tions for a query passage and each passage in the
corpus
to produce a second set
of
match scores.
The goal
of
this comparison was to see what
LSI
adds beyond the basic language model.
According
to Deerwester et al.
(1990),
rank lowering helps us
find all
words that
are related to each document.
This is typically a much larger set
than the plain
bag-of-words
representation because
it
accounts
for
synonymy across
the corpus.
If
LSI
is
indeed
exploiting the ‘semantic structure’
of
our
corpus
The sense of a connection
Digital
Scholarship in the Humanities,
2014
5 of 14
via
low-rank approximation,
we
should observe
better match scores for relevant parallels compared
to this simple approach.
2.2 Experiment design
Our
baseline
for
experimentation is
the
n-gram
matching
capability
that
forms
the
core
of
the
Tesserae
search engine,
which is
freely
available
on the
web.
15
Briefly summarized,
the
matching
algorithm operates in two distinct
stages.
16
In the
first stage, all instances where a given unit (e.g. verse
line or phrase) in one text shares at least two words
with another unit in a different text are identified.
The words may be exact forms or lemmata.
In the
second stage,
the candidate matches are ranked by
the
relative
rarity and proximity of
their
shared
words.
The final
result
is a score that
reflects the
overall
strength of
the match,
if
some word reuse
is present.
We
validated our
approach with reference
to
two Latin epic poems,
Lucan’s Civil
War,
book 1,
and Vergil’s Aeneid. Civil War 1 consists of 695 hex-
ameter lines, while all of the Aeneid consists of 9896
hexameter
lines.
These
epics
are
generally
con-
sidered to have a deep and remarkable intertextual
relationship.
17
This
relationship is
attested in the
work of
scholarly commentators,
who,
as
expert
readers, document a variety of forms of intertextual
relationship, among them instances of shared mean-
ing. We therefore tested our results against a bench-
mark data set
assembled by the Tesserae Project
comprising
all
intertexts
between the
two texts
recorded by four major commentaries.
The ability
of the algorithm to replicate commentator decisions
is used as the measure of performance.
From previous
experiments
with the
Tesserae
search engine, we know that it is possible to identify
the majority of
known intertexts by searching for
sentences
that
share two or
more lemmata.
In a
test on a set of given samples, the word-based algo-
rithm missed thirty-five of the commentator paral-
lels,
however,
which accounted for one-third of the
benchmark set.
Analysis
of
such missed samples
suggests
that
they
consist
wholly or
partially
of
instances
of
similar
meaning,
without
shared
words (Coffee et
al.,
2012b,
2014).
This subset
of
the overall
benchmark represents a union of paral-
lels described in the four commentaries.
Of
these,
individual
commentators
identified thirty distinct
parallels,
while
two commentators
independently
identified each parallel
in the remaining five.
With
due allowance for the subjectivity of
the commen-
tators,
the objective of
this
work was
to see how
many of
the thirty-five missed intertexts could be
recovered by automatic matching by semantic con-
text rather than words.
3 Lucan-Vergil Benchmark Results
Our first
test
case was the following excerpt
from
book 1 of
the Civil
War,
where Lucan uses meta-
phorical
language to describe the abandonment of
Rome by its military age men (left panel
below).
qualis,
cum turbidus Auster
reppulit a Libycis inmensum Syrtibus aequor
fractaque veliferi sonuerunt pondera mali,
desilit in fluctus
deserta puppe magister
nauitaque et nondum sparsa conpage carinae
naufragium sibi quisque facit,
sic urbe relicta
in bellum fugitur.
nullum iam languidus aevo
evaluit revocare parens coniunxve maritum
fletibus,
aut
patrii,
dubiae dum vota salutis
conciperent,
tenuere lares;
nec limine quisquam
haesit et extremo tunc forsitan urbis amatae
plenus abit
visu:
ruit inrevocabile volgus.
o faciles dare summa deos eademque tueri
difficiles!
(Civil
War 1.498–511)
postquam res Asiae Priamique evertere gentem
immeritam visum superis,
ceciditque superbum
Ilium et omnis humo fumat Neptunia Troia,
diversa exsilia et desertas quaerere terras
auguriis agimur divum,
classemque sub ipsa
Antandro et Phrygiae molimur montibus Idae,
incerti quo fata ferant,
ubi sistere detur,
contrahimusque viros.
vix prima inceperat aestas
et pater Anchises
dare fatis vela iubebat,
litora cum patriae lacrimans portusque relinquo
et campos ubi Troia fuit.
feror exsul
in altum
cum sociis natoque penatibus et magnis dis.
(Aeneid 3.1–12)
(continued)
W.
Scheirer et al.
6 of 14
Digital
Scholarship in the Humanities,
2014
The major theme of these lines is abandonment,
in this case of
the city of Rome (sic urbe relicta in
bellum fugitur),
articulated in part through a simile
of
shipwreck
(desilit
in fluctus,
puppe
magister,
naufragium).
These lines are thought to be richly intertextual
with the
Aeneid.
The
commentator
Paul
Roche,
author of
the most recent and extensive commen-
tary on this part
of
Lucan’s epic,
notes numerous
parallels
18
in lines 504–7 alone (italicized in the left
panel above), particularly with book 2 of the Aeneid
2.
But Roche also remarks on a similarity with part
of Aeneid 3 that has no shared words,
making it a
good test
for
detecting resemblance
of
meaning
alone.
The relevant
passage from Aeneid 3 comes
at
the opening of
the book,
where Aeneas begins
the story of
his wanderings.
It is marked in italics
in the right panel
above.
This entire passage was in fact included in a top
match returned by our algorithm for the compari-
son above between Aeneid 3 and the Lucan passage.
Roche observes the contrast between Aeneas’s con-
cern for his family in flight
and the disregard for
their families shown by Romans fleeing their city in
Lucan’s epic (Roche,
2009,
pp.
504–507).
Our LSI
method responds to related themes over a longer
stretch of text. As in Lucan’s description of citizens’
flight
from Rome,
in the opening of
Aeneid 3 we
find pronounced themes of
abandonment
(diversa
exsilia et desertas quaerere terras,
litora cum patriae
lacrimans
portusque
relinquo)
intermingled
with
naval
imagery (classem,
vela,
portus).
This thematic
similarity creates
a connection between the texts
despite the absence of any significant lexical overlap
of
the kind targeted by Tesserae lexical
search and
other
text
reuse
search engines.
The
infrequent
words
common
to
both
texts
are
underlined
above,
illustrating that
the passages share none of
the compact,
word-level
n-grams
typically picked
out
in
scholarly
commentaries.
19
The
passages
could,
in theory,
be
identified as
similar
based
upon this
sparse collection of
shared words,
but
only by a search so minimally restrictive as to pro-
duce a flood of results.
Matching via semantic ana-
lysis
thus
brings
us
much more
directly
to the
thematic resemblance identified by Roche.
Taking this approach further,
we experimented
with the LSI
modeling to see how many of
the
thirty-five missing commentator
parallels
between
Civil
War book 1 and the Aeneid we could return
in the top fifty results,
on the assumption that this
was
a highly manageable number
for
scholars
to
check.
Passages
(queries)
from book 1 of
Civil
War were matched against all passages (documents)
found in individual
books of
the Aeneid,
and the
results
were
ranked in descending order
by LSI
Continued
Just as when the swirling south wind drives the vast
sea back from the Libyan Syrtes,
and the shattered
mass of
the mast,
with its sail,
groans,
the helmsman
abandons
the
stern and leaps
into the
waves;
and
though the
fittings
of
the
hull
are
not
yet
strewn
apart,
each sailor fashions his own personal
shipwreck;
so too they
desert the city and flee into
war.
Parents,
frail
with age,
cannot call
back their
sons,
nor wives,
by their tears,
their husbands;
nor
the ancestral
homes,
so long as they place their
hopes on an unlikely salvation.
No one hesitated on
his threshold,
to depart,
perhaps,
with a final
look,
filled with the love of
his city.
The crowd rushed on,
heedless.
How easily the gods
give everything,
how
little they care to preserve it.
(Civil
War 1.498–511)
After the gods saw fit to overturn the affairs of Asia
and visit undeserved punishment on the race of
Priam,
after proud Ilium had fallen and all
of Troy,
built by Neptune,
was a smoking ruin,
we were
driven by signs from the gods to seek exile far away
and find vacant lands.
Near Antander and the
mountains of Phrygian Ida we constructed a fleet,
though we were unsure where the fates were taking
us,
where we were to settle,
and we gathered our
men together.
Summer had only just begun and my
father Anchises ordered us to give sail
for our
destiny.
I wept as I left the shores and harbors of my
fatherland,
and the plains where once was Troy.
I
was cast,
an exile,
onto the high seas,
together with
my companions,
my son,
the spirits of my
household and the great gods above.
(Aeneid 3.1–12)
The sense of a connection
Digital
Scholarship in the Humanities,
2014
7 of 14
score. This search involved setting one arbitrary par-
ameter,
the number of topics (or dimensions) into
which the passages would be categorized by content.
For our experiment,
we evaluated each query at 10,
15,
and 20 topics,
and reported the parameter at
which a valid parallel
was found.
To provide the reader with a more thorough ana-
lysis of
the proposed approach,
we also computed
precision, the fraction of retrieved instances relevant
to a valid parallel, for each result. This was done by
counting the number of matches that contained text
from a valid parallel
and dividing by the fifty total
matches
we
always
considered to be
candidates.
Recall
from Sec.
2.1 that our approach generates a
large sampling of
overlapping windows,
meaning
that
it
is
possible to have multiple valid matches
per search instance.
This is a useful
feature for a
scholar,
in that we have good coverage of the con-
text
surrounding a target
line of
interest
from a
set
of
windows
that
overlap,
but
not
completely.
Table 1 List of missing Civil
War 1 (BC)—Aeneid (AEN) commentator parallels found by the LSI approach in the
top-50 results returned by the algorithm for each query
BC line
AEN line
Shared context
Topics
LSI rank
LSI
precision
BoW
rank
BoW
precision
1.60
1.291
Destiny of Caesar;
peace
10
3
0.18
86
0.00
1.139
4.441
The blowing wind;
tree
20
1
0.22
1
0.28
1.141
2.626
The blowing wind;
tree
15
1
0.32
45
0.00
1.193
2.774
An apparition
20
33
0.08
47
0.00
1.193
3.47
An apparition
15
42
0.06
145
0.00
1.291
11.492
Horses
20
26
0.02
212
0.00
1.490
11.142
Flight
15
17
0.22
23
0.08
1.504
2.634
Abandonment
15
3*
0.52
70
0.00
1.504
3.11
Abandonment;
Navy
15
4
0.16
215
0.00
1.673
2.199
Omens;
terror
15
31
0.02
162
0.00
1.676
4.68
Dido as Bacchant
15
1
0.40
2
0.08
1.676
6.48
Prophecy
15
39
0.44
148
0.00
1.695
6.102
Frenzied discussion
20
22
0.20
31
0.20
Both rank and precision are reported.
An asterisk denotes
a parallel
outside the missing parallel
set
also found by the lexical
matching algorithm of
the
Tesserae
search engine.
For
comparison,
the
corresponding ranks
and precision values
are
also
provided for a cosine distance between bag-of-words representations for each parallel.
In nearly every instance,
LSI outperformed
the simpler bag-of-words approach.
Comparing rank to precision,
it can be seen that lower ranks tend to be correlated with higher
precision.
Table 2 List of missing Civil
War 1 (BC)—Aeneid (AEN) commentator parallels found in
the top-50 results returned by the cosine distance between bag-of-words representations
BC line
AEN line
Shared context
BoW rank
BoW precision
1.1
4.628
War
48
0.02
1.8
12.313
Hostility
23
0.06
1.226
4.624
Broken treaty
13
0.10
1.226
12.435
Fortune
38
0.04
1.674
4.300
Dido as Bacchant
28
0.02
1.678
10.670
Questioning destination
17
0.16
1.685
2.554
Decapitation;
shore
45
0.08
These results are not found by the LSI approach. Compared to the LSI approach in a general sense,
we
find that the ranks tend to be much higher and precision much lower for this baseline, with no result in
this
table placing in the top 10 of
those returned.
Low precision scores
are also observed for this
experiment.
W.
Scheirer et al.
8 of 14
Digital
Scholarship in the Humanities,
2014
We
exploit
this
behavior
in our
user
interface
(described below in Sec.
4)
to highlight
relevant
passages of text.
Of
the thirty-five missing parallels,
the LSI ap-
proach returned twelve,
listed in Table 1. Several of
these results were ranked in the top five returned by
the algorithm for a given number of topics, indicat-
ing very strong thematic links.
One additional
par-
allel
also found by the n-gram matching algorithm
of
the Tesserae search engine was
returned as
a
rank-3 result.
Comparing the methods of
analysis,
we found that lower ranks tend to be correlated with
higher precision.
These results also provide a basis for comparing
our
LSI
method with the alternative approach of
cosine distance between bag-of-words
representa-
tions.
When testing the latter,
we observed much
higher
ranks
(indicating worse performance)
and
lower
precision values
for
most
of
the
parallels
in Table 1.
In many cases,
the ranks fall
outside of
the
top-50 results,
and are
not
considered valid
matches
by the
matching criteria of
this
article.
Scores
produced by this
simple model
were also
significantly
lower
than those
generated by
the
LSI approach.
In every instance LSI outperformed
the simpler bag-of-words approach.
Thus,
for this
corpus,
we can conclude that
by making use of
low-rank approximation to capture
the
broader
synonymy of
the corpus,
the LSI
approach yields
stronger
matches
that
appear
higher
up in the
rank order.
This
is
not
to say,
however,
that
the simpler
model
has been rendered useless.
Table 2 lists an
additional
set
of
missing
Civil
War
1—Aeneid
commentator
parallels
found in the
top-50
re-
sults
returned
by
the
cosine
distance
between
bag-of-words
representations.
These
parallels
are
not found by the LSI approach.
Similar to the re-
sults in Table 1,
we again observe higher ranks and
lower precision values for each parallel—not a single
Fig. 1 The public web interface to the algorithm described in this article. Parameters are presented to the user as a series
of drop-down menus. The user can click on any line in the ‘Target’ frame, which will initiate the LSI matching process
between the passage centered on the target line and all passages in the ‘Source’ frame. The Tesserae Project’s entire Latin
corpus is available for search.
The simple interface allows scholars with minimal
training in machine learning to
conduct sophisticated studies of semantic intertextuality at a large scale
The sense of a connection
Digital
Scholarship in the Humanities,
2014
9 of 14
one of these matches falls within the top-10 results.
This
indicates
that
even as
a weak approach,
the
simple bag-of-words model could be useful in com-
bination with other,
more powerful
approaches via
fusion (using a reasonably intelligent score analysis
algorithm) to improve the rank position of a match.
We are investigating this possibility in our ongoing
work.
4 A New Tool for the Study of
Intertextuality
Based on the
satisfactory
benchmark results,
we
designed an accessible front-end to the proposed
algorithm for more traditional
scholars of the clas-
sics.
Those interested in trying out
the algorithm
have free access to an easy-to-use web-based tool
via the Tesserae Project
Web site.
20
Figures 1 and
2 show the interface,
which provides simple drop-
down menus for all parameters (author, work, book,
and number of topics), and a point-and-click mech-
anism to allow the user to explore the texts while
reading. Scholars without significant training in ma-
chine learning will find this tool to be a convenient
starting
point
for
conducting
studies
related to
intertextuality and semantics
at
a large
scale.
At
the time of
this
writing,
sixty-one different
Latin
poets and prose writers are available for comparison.
An important
question is
whether
this
tool
(and the underlying LSI
algorithm) can be useful
in revealing new instances
of
text
reuse.
Ideally,
the approach should produce results beyond those
in our benchmark set that were noted by commen-
tators but missed by lemma matching.
To this end,
we
used
our
web
interface
to
visualize
other
strongly matching passages
between Civil
War
1
and the Aeneid,
using the lines from Civil War 1 in
Tables 1 and 2 as ‘targets’
(i.e.
queries) against the
passages from all of the ‘source’ books of the Aeneid.
This search turned up significant
thematic corres-
pondences not recorded by commentators,
listed in
Fig.
2 An example of a match between Civil
War 1.141 and Aeneid 2.262.
The entire passage highlighted on the left
represents the query centered on Civil War 1.141. To reduce visual clutter, we only highlight the lines matching passages
are centered upon on the right. The matches provide the scholar with an indication of the general neighborhood where
semantically similar text can be found. Intensity of the text in the right-hand frame indicates the strength of the match
(darker text means a stronger match)
W.
Scheirer et al.
10 of 14
Digital
Scholarship in the Humanities,
2014
Table
3.
These
included another
passage
in the
Aeneid that shares the themes of abandonment and
the sea with the lines around Civil War 1.504 quoted
above.
Here
sailors
flee
from the
shores
of
Polyphemus, and the related words are concentrated
in the first two lines:
Other passages were related by different common
themes.
The LSI algorithm identified the following
two passages
as
highly related,
and both in fact
describe
the god Bacchus,
though in almost
en-
tirely different
terms
(they share
just
one
word,
vertice):
We also found a similar correspondence between
text surrounding Civil War 1.676 and Aeneid 4.300–
3.
This
instance
contained both identical
words
(qualis,
per
urbem) and (near) synonyms
(attoni-
tam  excita,
urguentem  stimulant).
In sum,
then,
our
employment
of
LSI
proved
successful
for
the
needs
of
users,
in that
it
can
bring them swiftly to significant instances of seman-
tic
similarity not
previously recorded.
And as
a
sed fugite,
o miseri,
fugite atque ab litore funem
rumpite.
nam qualis quantusque cavo Polyphemus in antro
lanigeras claudit pecudes atque ubera pressat,
centum alii curva haec habitant ad litora vulgo
infandi Cyclopes et al.
tis montibus errant.
(Aeneid 3.639–44)
But flee,
you wretches,
flee and slash the cables
from the shore.
For as great and tall
as Polyphemus
is who lives in his hollow cave,
keeps wooly flocks,
and milks their udders,
a hundred such other
monstrous Cyclopes live together along the curved
shore,
and wander the steep mountains.
nam,
qualis vertice Pindi
Edonis Ogygio decurrit plena Lyaeo . . .
(Civil
War 1.674–5)
nec qui pampineis victor iuga flectit habenis
Liber,
agens celso Nysae de vertice tigris
(Aeneid 6.804–5)
For just as a Thracian bacchant,
filled
with Theban Bacchus,
rushes down from
the summit of Mount Pindus . . .
Nor did Bacchus,
who in victory guides his chariot
with reins of vine,
leading his tigers from the
summit of lofty Nysa,
[traverse as much land as
Augustus will
rule].
Table 3 Additional
thematic matches found between Civil
War 1 (BC) – Aeneid (AEN) by the LSI approach
BC Line
AEN Line
Shared Context
Topics
LSI Rank
BoW Rank
1.1
4.98
War
15
1
a
1
1.141
2.252
The blowing wind
15
6
128
1.291
11.291
Conquest
20
1
4
1.353
1.647
City;
nation
15
1
a
26
1.504
3.639
Abandonment;
nautical
imagery
20
2
129
1.676
6.809
Bacchus
15
1
81
1.676
4.304
Bacchus
10
36
295
These include highly specific parallels (a Bacchant in the passage around Civil War 1.676 and Bacchus around Aeneid 6.809 and Aeneid
4.304),
weaker parallels
with some lexical
correspondence (Civil
War
1.1 and Aeneid 4.98,
Civil
War 1.212 and Aeneid 1.647),
and interesting contextual parallels (a metaphorical
description of nautical abandonment around Civil War 1.291 and sailors fleeing
the shores of Polyphemus around Aeneid 3.639). Ranks are also provided for a cosine distance between bag-of-words representations.
As with the experiment shown in Table 1,
our LSI method consistently outperformed the simpler bag-of-words approach.
a
A parallel
also found by the lexical
matching algorithm of the Tesserae search engine.
The sense of a connection
Digital
Scholarship in the Humanities,
2014
11 of 14
computational
method,
in every case the LSI algo-
rithm again outperformed the simpler bag-of-words
approach.
5 Discussion
Our experiment demonstrates that LSI can be used
to
detect
intertextual
relationships
of
meaning
where
few or
no words
are
shared by
the
two
texts.
The same approach can in principle be ex-
tended to discover common themes and generic ma-
terial,
though computational
constraints
currently
make
it
impossible
to
conduct
a
rapid search
for
such material
over
very
large-scale
corpora.
The distinction between intertext and non-intertext
has always been fundamentally a heuristic one
21
that
can shift and change. If this sort of searching can be
brought to larger scales,
it will
likely begin to dis-
solve the border between the instances of intertext-
uality
most
frequently
noted by
scholars—tight
verbal correspondences—and the traditional under-
standing of similarities of mood and theme.
Acknowledgements
This
work
was
supported
by
the
National
Endowment
for
the Humanities
[Start-Up Grant
Award
#HD-51570-12].
We
thank
Prof.
Neil
Bernstein of
Ohio University,
who provided valu-
able feedback on an early draft of this work.
References
Allison,
S.,
Heuser,
R.,
Jockers,
M.
L.,
Moretti,
F.,
and
Witmore,
M.
(2012).
Quantitative
formalism:
an
experiment.
n þ 1,
13:
81–108.
Bamman,
D.
and Crane,
G.
(2008).
The
logic
and
discovery
of
textual
allusion.
In
Proceedings
of
the
Second
Workshop
on
Language
Technology
for
Cultural
Heritage
Data (LaTeCH 2008),
Marrakesh,
Morrocco.
Blei,
D.
(2011).
Probabilistic
topic
models.
Comminications of the ACM,
55(4):
77–84.
Blei,
D.,
Ng,
A.,
and Jordan,
M.
(2003).
Latent dirichlet
allocation.
Journal
of
Machine
Learning
Research,
3:
993–1022.
Bu
¨
chler,
M.,
Geßner,
A.,
Berti,
M.,
and Eckart,
T.
(2013).
Measuring the influence of a work by text re-
use.
Bulletin
of
the
Institute
of
Classical
Studies
Supplement,
122:
63–79.
Bu
¨
chler,
M.,
Crane,
G.,
Mueller,
M.,
Burns,
P.,
and
Heyer, G. (2011). One step closer to paraphrase detec-
tion
on
historical
texts.
Journal
of
the
Chicago
Colloquium on
Digital
Humanities
and
Computer
Science,
1(3).
Bu
¨
chler,
M.,
Geßner,
A.,
Eckart,
T.,
and Heyer,
G.
(2010).
Unsupervised detection and visualization of
textual
reuse
on ancient
greek texts.
Journal
of
the
Chicago
Colloquium on
Digital
Humanities
and
Computer Science,
1(2):
1–17.
Coffee,
N.,
Koenig,
J.-P.,
Poornima,
S.,
Forstall,
C.W.,
Ossewaarde, R., and Jacobson, S. (2012a). The tesserae
project:
intertextual
analysis
of
latin poetry.
Literary
and Linguistic Computing,
28(2):
221–228.
Coffee,
N.,
Koenig,
J.-P.,
Poornima,
S.,
Ossewarde,
R.,
Forstall,
C.,
and Jacobson,
S.
(2012b).
Intertextuality
in
the
digital
age.
Transactions
of
the
American
Philological
Association,
142(2):
381–419.
Coffee,
N.
(2012).
Intertextuality
in latin poetry.
In
Clayman,
D.
(ed.),
Oxford Bibliographies
in Classics.
New York:
Oxford University Press.
Coffee,
N.,
Forstall,
C.,
Buck,
T.,
Roache,
K.,
and
Jacobson,
S.
(2014).
Modeling the scholars:
detecting
intertextuality
through enhanced word-level
n-gram
matching. Literary and Linguistic Computing. http://tes-
serae.caset.buffalo.edu/blog/wp-content/uploads/2012/
10/Modeling-the-Scholars-2013-11-6LLC-preprint1.
pdf.
Conte, G. B. (1986). The Rhetoric of Imitation: Genre and
Poetic
Memory
in
Virgil
and
Other
Latin
Poets.
Translated
by
Charles
Segal.
Ithaca,
New York:
Cornell
University Press.
Deerwester,
S.,
Dumais,
S.,
Furnas,
G.,
Landauer,
T.,
and Harshman, R. (1990). Indexing by latent semantic
analysis. Journal of the American Society for Information
Science,
41(6):
391–407.
Eco, U. (2002). Borges and my anxiety of influence. In On
Literature.
Translated by Martin McLaughlin.
Orlando
FL:
Harcourt,
Inc.,
pp.
118–135.
Eder, M. (2014). Does size matter? authorship attribution,
small
samples,
big
problem.
Literary
and Linguistic
Computing.
http://llc.oxfordjournals.org/content/early/
2013/11/14/llc.fqt066.full.
Forstall,
C.
W.
and
Scheirer,
W.
J.
(2012).
Revealing
hidden
patterns
in
the
meter
of
W.
Scheirer et al.
12 of 14
Digital
Scholarship in the Humanities,
2014
Homer’s Iliad. In Proceedings of the Chicago Colloquium
on
Digital
Humanities
and
Computer
Science.
Chicago,
IL.
Forstall, C. W., Jacobson, S., and Scheirer, W. J. (2011).
Evidence
of
intertextuality:
investigating
Paul
the
Deacon’s
Angustae
Vitae.
Literary
and
Linguistic
Computing,
26(3):
285–296.
Ganascia,
J.-G.,
Glaudes,
P.,
and DeLungo,
A.
(2013).
Automatic detection of reuses and citations in literary
texts.
In Proceedings
of
Digital
Humanities.
Lincoln,
Nebraska.
Geßner,
A.,
Ko
¨
tteritzsch,
C.,
and Lauer,
G.
(2013).
Biblical
Intertextuality in the digital
world:
the tool
GERTRUDE.
In Proceedings
of
the
1st
International
Workshop
on
Collaborative
Annotations
in
Shared
Environment:
Metadata,
Vocabularies
and Techniques
in the Digital
Humanities.
Bologna,
Italy.
Heitland,
W.
E.
and Haskins,
C.
E.
(1887).
M.
Annaei
Lucani Pharsalia.
London:
G.
Bell.
Hinds, S. (1998).
Allusion and Intertext:
The Dynamics of
Appropriation in Roman Poetry.
New York:
Cambridge
University Press.
Horton,
R.,
Olsen,
M.,
and Roe,
G.
(2010).
Something
borrowed: sequence alignment and the identification of
similar passages in large text collections. Digital Studies/
Le champ nume
´
rique,
2(1).
Jockers,
M.
(2013).
Macroanalysis:
Digital
Methods
and
Literary
History.
Champaign:
University
of
Illinois
Press.
Kristeva, J. (1986). Word, Dialogue and Novel. In Moi, T.
(ed.),
The
Kristeva
Reader.
New York:
Columbia
University Press,
pp.
34–61.
Lee,
J.
(2007).
A Computational
Model
of Text Reuse in
Ancient
Literary
Texts.
In Proceedings
of
the
45th
Annual
Meeting
of
the
Association of
Computational
Linguistics.
Prague,
Czech Republic,
pp.
472–479.
McCallum,
A.
K.
(2002).
MALLET:
A Machine Learning
for
Language Toolkit.
http://mallet.cs.umass.edu (ac-
cessed 25 January 2014).
Mimno,
D.
(2012).
Computational
historiography:
data
mining in a century of
classics
journals.
Journal
on
Computing and Cultural
Heritage,
5(1):
3:1–3:19.
Nelson,
R.
K.
(2011).
Of
Monsters,
Men – And Topic
Modeling.
The
New York Times.
http://opinionator.
blogs.nytimes.com/2011/05/29/of-monsters-men-and-
topic-modeling (accessed 25 January 2014).
Rehurek,
R.
and Sojka,
P.
(2010).
Software framework
for topic modeling with large corpora. In Proceedings of
the LREC 2010 Workshop on New Challenges
for NLP
Frameworks.
Valletta,
Malta,
pp.
46–50.
Pucci,
J.
(1998).
The Full-Knowing Reader:
Allusion and
the
Power
of
the
Reader
in
the
Western
Literary
Tradition.
New Haven,
CT:
Yale University Press.
Roe, G. H. (2012). Intertextuality and influence in the age
of enlightenment:
sequence alignment applications for
humanities
research.
In
Proceedings
of
Digital
Humanities.
Hamburg,
Germany.
Roche,
P.
(ed.)
(2009).
Lucan:
De
bello civili.
Book 1.
Oxford:
Oxford University Press.
Schmitz,
T.
A.
(2002).
Modern Literary
Theory
and
Ancient
Texts:
An
Introduction.
Malden,
MA:
Blackwell
Publishing.
Smith,
D.
A.,
Cordelly,
R.,
and Dillony,
E.
M.
(2013).
Infectious Texts:
Modeling Text Reuse in Nineteenth-
Century
Newspapers.
In
Proceedings
of
the
IEEE
Workshop on Big Data and the Humanities.
California:
Santa Clara.
Thompson,
L.
and Brue
´
re,
R.
T.
(1968).
Lucan’s Use of
Vergilian Reminiscence.
Classical
Philology,
63:
1–21.
Viansino,
G.
(ed.)
(1995).
Marco Annaeo Lucano:
La
Guerra
Civile
(Farsaglia)
libri
I-V.
Milan:
Arnoldo
Mondadori.
Wills,
J.
(1996).
Repetition in Latin Poetry:
Figures
of
Allusion.
Oxford:
Clarendon Press.
Wolff,
M.
(2012).
Surveying a Corpus
with Alignment
Visualization and Topic Modeling.
In Proceedings
of
the
Chicago
Colloquium on Digital
Humanities
and
Computer Science.
Chicago,
Illinois.
Notes
1 In classical scholarship sometimes called loci similes, or
‘similar passages’, and typically consisting of (near) ver-
batim reuse of a two-word phrase.
2 Two useful
surveys
of
practices
within classical
phil-
ology
can
be
found
in
Pucci
(1998,
ch.
1)
and
Schmitz (2002,
ch.
5);
see also Coffee (2012).
3 Examples
include
global
linear
models
for
assessing
verse similarity in the New Testament
Gospels
(Lee,
2007);
unsupervised
detection
of
Greek
quotation
(Bu
¨
chler et al.,
2010),
and hash coding to detect reuse
and citations
in Lautre
´
amont
and Balzac
(Ganascia
et
al.,
2013).
More
flexible
sequence
alignment
approaches
(Horton et
al.,
2010;
Roe,
2012;
Wolff,
2012;
Smith et
al.,
2013),
inspired by related analysis
techniques in genetics,
are prevalent as well.
Most clo-
sely aligned with the goals of this present work are the
The sense of a connection
Digital
Scholarship in the Humanities,
2014
13 of 14
eTRACES (Bamman and Crane,
2008;
Bu
¨
chler et
al.,
2011,
2013;
Geßner et al.,
2013) and Tesserae (Forstall
et
al.,
2011;
Forstall
and Scheirer,
2012;
Coffee et
al.,
2012a,b,
2014) projects.
4 Wills
(1996,
ch.
1)
gives
an extensive set
of
textual
features that can serve as the basis for intertextual con-
nections,
with examples of each.
5 Latin texts
cited here
are
from the
Perseus
Digital
Library (see also Note 11 below);
translations are our
own.
6 For example,
Paul
Roche (2009,
ad loc.).
7 Excluding extremely common function words such as
et (‘and’) and in (‘in/on’).
8 The process of recognition does not necessarily proceed
in such an orderly fashion, however, from the concrete
to the abstract; rather, the alert reader is often sensitized
to the possibility of intertext in advance. This potential
for an intertextual
relationship to prime the reader to
see further connections is described in detail
by Wills
(1996,
pp.
26–27).
In general
terms,
‘a poetic sign sig-
nals
first
to the
other
signs
within the
poetic
sys-
tem. . .before signaling its
specific sense in a precise
context’ (Conte, 1986, p. 44). For example, Vergil him-
self
seems
already
to have
foreshadowed Pompey’s
death in his description of the death of Priam, patriarch
of
the Trojans
(Hinds,
1998,
p.
8).
Lucan’s
readers
might
well
have recognized the intertext
first
on this
basis
and only subsequently (or
never)
noticed the
reuse of nuto.
9 Allison et
al.
(2012),
Mimno
(2012),
and Nelson
(2011),
respectively.
10 http://radimrehurek.com/gensim/intro.html
11 The Tesserae Latin corpus
currently comprises
just
under
250 texts,
evenly divided between prose and
verse,
principally from the first
century BCE to the
third century CE.
Most
of
these texts
are sourced
from the Perseus Digital Library (http://www.perseus.
tufts.edu;
G.
Crane,
Editor).
For further information,
see http://tesserae.caset.buffalo.edu/sources.php.
12 https://github.com/tesserae
13 On difficulties associated with small
samples in liter-
ary applications of text analysis,
see,
e.g.
Eder (2014).
14 The Gensim module implements
scalable truncated
SVD in Python to calculate the low-rank approxima-
tion of a matrix. While there is no specific property of
LSI that makes it more suited to small
corpora,
this
particular SVD solver is stable for small
sample sizes,
making it
useful
for
the kinds
of
searches
demon-
strated here.
With a lack of good alternatives,
we rec-
ommend
that
other
researchers
consider
this
implementation for semantic analysis problems that
are constrained to small
sample sizes.
15 http://tesserae.caset.buffalo.edu
16 Additional
detail
can be found in the ‘Methodology’
section of Coffee et al
.
(2014).
17 The Lucan commentaries we consulted for this infor-
mation were Heitland and Haskins (1887), Thompson
and
Brue
´
re
(1968),
Viansino
(1995),
and
Roche
(2009).
18 (Roche, 2009), 312–313 records parallels between Civil
War
1.504–7
and Aeneid
2.635f.,
651–3,
657–70,
673–8,
707–25,
747–51;
3.11f.;
7.757f;
11.160f.
Most
are
contrastive,
evoking
the
difference
between
Aeneas’s concern for keeping his loved ones together
while fleeing Troy,
and the disregard for family ties
shown by those fleeing Rome in Civil
War.
19 Not underlined are the function words cum, et, and in,
which are extremely common and typically excluded
by even the shortest stop lists.
20 http://tesserae.caset.buffalo.edu/cgi-bin/lsa.pl
21 So,
for
example,
novelist
and semiotician Umberto
Eco,
in reflecting on the various intertextual
relation-
ships between his own fiction and that of Jorge Luis
Borges,
notes links of several
distinct types,
including
‘cases where I was not aware of
it,
but subsequently
readers. . .forced me
to recognize
that
Borges
had
influenced me
unconsciously’,
as
well
as
others
in
which a reminiscence of
Borges
in Eco’s
writing is
due rather
to a mutual
debt
to ‘preceding sources
and the universe of intertextuality’ (Eco, 2002, p. 121).
W.
Scheirer et al.
14 of 14
Digital
Scholarship in the Humanities,
2014
