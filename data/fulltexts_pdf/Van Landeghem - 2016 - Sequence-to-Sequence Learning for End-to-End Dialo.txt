Sequence-to-Sequence Learning 
for End-to-End Dialogue Systems 
Copyright © 2016, Oracle and/or its aﬃliates. All rights reserved. 
|
Jordy Van Landeghem
NLP Development intern
Oracle EMEA @ Barcelona
February, 2016
Project information
Assignee:
Jordy Van Landeghem
jordy.vlan@gmail.com
KU Leuven Promotor: 
Prof. dr. Sien Moens
sien.moens@cs.kuleuven.be
Manager & Supervisor:
dr. Fabrice Nauze
fabrice.nauze@oracle.com
Supervisor:
Sergiu Nisioi
sergiu.nisioi@oracle.com
Employment period: 
05/09/2016 – 05/12/2016 
Project duration
Final project outline

Algorithms: 
Seq2Seq: encoder-decoder LSTMs
Custom Seq2Vec + MiniBatch K-Means

Task: 
Research the potential of Seq2Seq learning for response generation
Review the ability to learn dialogue representations 

Experience:
Raw, unpreprocessed, unstructured chatlog data
Continuous-space clustered, preprocessed, more structured “dialogue” data

Performance: 
Constrained test input for model quality evaluation
Ground truth pairwise comparison 
Outline of talk
1.
Primer on recent academic-industrial contributions on automatically building 
dialogue systems 
2.
Experiments with the seq2seq framework and custom-defined methods 
3.
Discussion of experimented methods to solve identified or encountered problems 
4.
Conclusion summarizing the insights made in the project 
Background
Contextualisation
Traditional pipeline architecture
Good performance in small restricted domains
Time and labour-intensive feature engineering
Modules with separate specific objective function
Non-scalable to general domain, nor transferrable 
End-to-End Dialogue Systems
Single model trained directly and entirely on conversational data
Single objective function optimizing the full model
No feature engineering 

architecture engineering
Transferable to different domains & scalable to general domain!
Requires a LARGE conversational training dataset 
Data-driven dialogue modelling & generation
Copyright © 2016, Oracle and/or its aﬃliates. All rights reserved. 
|
1
0
There is strong evidence that over the next few years, dialogue research will quickly move towards large-scale 
data-driven model approaches, in particular in the form of end-to-end trainable systems as is the case for 
other language-related applications such as speech recognition, machine translation and information 
retrieval. (Serban et al. 2015: 39, my emphasis)
“Recent neural network architectures trained on large-scale corpora have shown promising results (Shang et 
al., 2015; Sordoni et al., 2015b; Vinyals and Le, 2015; Serban et al., 2015). However, they require having a 
sufficiently large dataset - in the hundreds of millions or even billions of words - in order to achieve these 
results.” (Serban et al. 2015: 3, my emphasis)
“Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging 
problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with 
human judgements of response quality (Liu et al., 2016). Yet having an accurate automatic evaluation
procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new models with 
fewer expensive human evaluations.” (Lowe et al. 2017:1, my emphasis)
Sequence to Sequence learning
Sutskever et al. (2014):
•
General end-to-end approach to sequence learning 
that makes minimal assumptions on the sequence structure
•
Flexible and powerful
•
Short AND long-term dependencies
•
GENERATIVE
•
multilayered Long Short-Term Memory (LSTM) to encode the input sequence to a 
vector of a fixed dimensionality, and then another deep LSTM to decode the target 
sequence from the vector.
modelling
Local dialogue context issue
Agent: Hi, my name is <NAME>. How may I help you?
Customer: I have a new computer running Windows 8. [Download the last game I 
purchased and there is no sound.]
Q1
[Are your games compatible with Windows 8?]
Q2
Agent: [Hi <NAME>, I am really sorry to hear that.]
PROMPT
Agent: [I can tell you that most of our games are definitely compatible with Win8]
A2
Agent: [Can you let me know the game <NAME>?]
A1
Customer: <GAME-TITLE>
Experiments
Experiments
1.
Dataset – Oracle proprietary
small-medium – troubleshooting – domain-specificity 
2.
Methods
Seq2Seq model
Output: “I am sorry” -- data biases
Custom Seq2Vec
Input: “nice clusters” – holds promise!
3.
Evaluation
Pairwise model comparison – manual evaluation set 
Customer: please void gage i am geetig anew car also can you give ac coupon so i could use it for myself and would changing my pass word 
help sorr about the spling i ment anew card
Agent: I'd either be able to refund the purchase or issue a coupon code for a different game. Our system would be unable to issue a refund and 
then also replace the game which would you prefer? [113918]
Customer: < insert long problem explanation >
Agent: Thanks for that info - to troubleshoot this kind of issue we have a tool called <TOOL> that we use to gather info on how the computer and 
game are communicating, to see what might be causing the issue. I'd like to send you an email with the steps explained in detail, to run it and 
send us the results back so we can see what's happening. If this is ok, is <EMAIL>@<DOMAIN> a good email to use? [250422]
Customer: I've got Adobe Air, Adobe Flash Player 11 Plugin and Flash Player Pro V5.4 
Agent: Ok. Let's uninstall the Flash Player 11 Plugin and Flash Player Pro. Then, we'll work on uninstalling and reinstalling the game [276206]
DIFFICULTY
human-human chatlogs from a customer support service hosted by a flash games website
•
21167 chatlogs, 400k utterances, 8M tokens
•
Technical and non-technical topics
Data
LSTM encoder-decoder architecture
Encoder-Decoder model
A Neural Conversation Model (Torch)
https://github.com/macournoyer/neuralconvo
Demo: http://neuralconvo.huggingface.co/
Custom Seq2vec
⌢
Word embeddings
Concatenated composition
Concatenated word representation
Averaged sequence representation
Mini batch K-means
K clusters of similar sequences 
Word averaging
Index-based retrieval 
vs. Max Cosine Similarity pairing
for cluster in list(set(clusterids)): #for cluster in list of clusters 
for i in xrange(0, len(clusterids)): #for possible agent sentences by index
if (clusterids[i] != cluster): #require index of sentences to be in cluster mapping
continue
sentence = sentences[i] #retrieve sentence by index
tokens = word_tokenize(sentence) #tokenize sentence
p1 = any2vec(models,tokens) #build sentence representation
originalindex = indices[i] #retrieve original index of sentence in dataset
originalslice = [sublist for sublist in fileranges \
if originalindex in sublist] #retrieve conversation bounds
primecandidates = [element for element in originalslice \
if originalindex > element] #retrieve candidates by index
candidates = [element for element in primecandidates \
if tag_sentences[element].startswith("customer")]
maxim = -1
if len(primecandidates) > 0:
for candidate in candidates: #for candidate customer sentence
p2 = full2vec[(full_sentences[candidate],candidate)]
#retrieve candidate customer sentence representation
cos = cosine_similarity(p1,p2)
#compute cosine similarity between agent sentence-candidate customer sentence
if cos > maxim:
#update maximum cosine similar sentence if new candidate is more similar
maxim = cos
best = candidate
most_similar = full_sentences[best]
#retrieve most similar customer sentence by index in full dataset
clusterlist.append(most_similar)
#add most similar customer sentence to form pair
clusterlist.append(sentence)
#add original within cluster agent sentence 
+ manual post-pruning of full clusters
Cluster 38 

PRUNE
Customer:
hi i have a question about <MEMBERSHIP> .
Agent:
sure thing
Customer:
okay i will look said did not install correctly . had to click on something and it is trying again . so we wait .
Agent:
sure thing
Customer:
i have called the bank and they have posted correctly . i would like to go and purchase game manually
Agent:
sure thing
Customer:
i will try that in just a sec 
Agent:
sure thing . goodbye
Cluster 227  PRUNE
Customer:
i am trying to buy the <GAME> today and use the <EVENT> code . it is not allowing me to neither use the code or buy what is 
wrong ? 
Agent:
hi <NAME> i ' m sorry to hear that
let me check this just a minute please .
Customer:
im really annoyed
Agent:
hi <NAME> i ' m sorry to hear that
what happened?
Customer:
I have purchased <GAME> after playing the hour trial i cannot get it to play now it freezes on the install screen
Agent:
hi <NAME> i am really sorry to hear that .
Cluster 294  KEEP
Customer:
thank you how will the money be refunded
Agent:
it will be refunded on your visa card . 
Customer:
was it refunded to my credit card then
Agent:
it was refunded to a card ending in <CODE> 
Customer:
how am i to receive that
Agent:
i would send the money back to the visa ending in <CODE>
Customer:
oh ok so do i have to do anything for next month pmt or will it be as before except a new card
Agent:
it should be exactly as before just on the visa card
Cluster 56 [specific game orders] 
Customer: jts the <GAME1> one
Agent: ok . the three games listed on your account all activated are <GAME1> <SEQUEL_GAME1> <GAME2> and <GAME3>
Customer: yes . are you able to see what the new games ordered are ?
Agent : i see that on your <MAIL>account you have 3 games <GAME1>, <GAME2> , <GAME3>
Customer : <AGENT> i donot see <GAME_misspelled> any more
Agent : are you refering to <GAME> ?
Customer: thats why i want you to look because i cant remember for sure because i also bought some for the pc yesterday
Agent: ok i ' m seeing the purchase of <GAME1> <GAME2> and <GAME3> for the mac does that sound right ?
Models and parametrization
training data size
# of logs / cluster
vocabulary
time per epoch
base seq2seq
292357
21167 logs
39089
6.5 hours
index seq2seq
256961
397 clusters
42844
6.5 hours
cossim seq2seq
282042
489 clusters
27499
6 hours
‘dataset’
0
‘approximate size of dataset to use (0 = all)’
‘maxVocabSize’
0
‘max number of words in the vocab (0 = no limit)’
‘cuda’
True
‘use CUDA toolkit for training’
‘hiddenSize’
500
‘number of hidden units in LSTM’
‘learningRate’
0.001
‘learning rate at t=0’
‘gradientClipping’
5
‘clip gradients at this value’
‘momentum’
0.9
‘momentum term’
‘minLR’
0.00001
‘minimum learning rate’
‘saturateEpoch’
20
‘epoch at which linear decayed LR will reach minLR’
‘maxEpoch’
30
‘maximum number of epochs to run’
‘batchSize’
10
‘mini-batch size’
‘EncodeLength’
60
‘Maximal Length of input sequence to Encode’
‘DecodeLength’
60
‘Maximal Length of output sequence to Decode’
General evaluation
Important source: “How NOT To Evaluate Your Dialogue System”
How to evaluate the model, the system and its output?

Created a test set containing 60 representative questions

Subjective evaluation 

Fuzzy binary scale (1 – 2 – 3)

Average scores over three participants 
Dialogue pattern similarity
Relevance of dialogue response
relevant 
quite relevant 
irrelevant 
1 
2 
3 
average score 
base seq2seq 
23.33% 
34.44% 
42.22% 
2.189 
index seq2seq 
34.44% 
31.67% 
33.89% 
1.994 
cossim seq2seq 
8.89% 
24.44% 
67.22% 
2.594 
22.18% 
30.13% 
47.69% 
2.1786 
Test customer input
i
' ll check my email and if i have any issue i ' ll get back yo you thank you
Model 1
Sounds like a plan. 
1,1,1
Model 2
Ok, absolutely.
1,1,2
Model 3
Hi i have a problem with a game i purchased on the 26th may i purchased.
3,3,3
Test ground root
that ' s perfect now that i ' m here is there anything else i can do for you ?
Conclusion
(1) Adapt data to algorithm
•
unsupervised representation for arbitrarily large units of text? Custom Seq2Vec
•
integrate sequence information? 
Seq2Seq-based architecture
ALGORITHM
DATA
MODEL
(2) Unsupervised methods for Dialogue Representation
a.
Word embeddings

2-layer predictive ANN for learning word representations:
building word vector representations from raw text 
Additional supervision (POS, chunk, NER…) possible for task-specific embeddings
b. Clustering

learning principal structure within an (unlabelled) dataset
c.
Encoder-decoder neural network 

data-driven generative model reproducing data distributions
MLE w.r.t. words in the training corpus -> next utterance prediction
absence of any explicit supervised signal (task completion/user satisfaction) 
Possible to condition on other (external) information, such as knowledge bases or user profiles
(3) Semi-supervised intent identification
Time & labour-intensive intent database construction requiring high domain expertise
Towards automation of scripting of a conversational agent
Construct intents in a more principled fashion and more efficiently 
o
Reuse and revaluation of backlogged service data
o
Exploiting domain knowledge present in the data
o
Gain insight into FAQ and Popular Answers
Unsupervised representation for dialogue pattern similarity
Challenges 
1.
Data (pre)processing and encoding-decoding
2.
Network designer choices and empirical parameter tuning
3.
Evaluation of model performance
4.
Relevance in answer generation 
References for illustrations and slide design
!-symbol, https://image.freepik.com/free-icon/warning-triangle-sign-with-exclamation-symbol-inside_318-30317.jpg
+-symbol, http://cdn.mysitemyway.com/icons-watermarks/simple-black/classica/classica_plus-sign-1/classica_plus-sign-1_simple-
black_512x512.png
LSTM, https://cdn-images-1.medium.com/max/800/1*laH0_xXEkFE0lKJu54gkFQ.png
Futurama pictures, Legal notice: "Futurama" TM and copyright FOX, its related entities and the Curiosity Company. All rights reserved.
Oracle Labs, slides’ design adapted from Oracle labs, Pallika Kanani’s ML talk of April 2016
RNN illustration, http://blog.josephwilk.net/images/blog/2012/10/recurrent_neural_network1.png
UFLDL Tutorial (Ng et al.) http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial
https://www.researchgate.net/figure/270477351_fig1_Fig-1-Architecture-of-the-Skip-gram-model-that-is-employed-to-learn-continuous-
vector
Extra chatbot modelling papers
[1] A Survey of Available Corpora for Building Data-Driven Dialogue Systems
[2] A Neural Conversational Model
[3] A Diversity-Promoting Objective Function for Neural Conversation Models
[4] A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues
[5] Sequence to Backward-Forward Sequences:A Content-Introducing Approach to Generative Short-Text Conversation
[6] A Persona-Based Neural Conversation Model
[7] Deep Reinforcement Learning for Dialogue Generation
[8] End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning
[9] A Network-based End-to-End Trainable Task-oriented Dialogue System
[10] Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems
[11] A Neural Network Approach to Context-Sensitive Generation of Conversational Responses
[12] Incorporating Copying Mechanism in Sequence-to-Sequence Learning
[13] A Dataset for Research on Short-Text Conversation
[14] The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems
[15] Neural Contextual Conversation Learning with Labeled Question-Answering Pairs
[16] The Ubuntu Chat Corpus
The set-out planning has been respected: 

Data collection

Document clustering as an initial exploration of the data

Data preprocessing

GPU setup

Construct three different training datasets (+ representation)

Encoded data as input for specific seq2seq implementation

Trained three seq2seq models with varying training input 

Build test set with representative dialogue situations

Evaluate different system’s generated responses on test set constrained input
Progress report
