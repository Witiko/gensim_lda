222
Verwendung von Textanalysekomponenten 
zur Verbesserung der Geo-Discovery 
mit Recommender-Systemen 
Bernhard VOCKNER und Manfred MITTLBOECK 
Reseach Studios Austria – iSpace, Salzburg · bernhard.vockner@stud.sbg.ac.at 
Zusammenfassung 
Recommender-Systeme finden bisher vorrangig in Internetshops wie Amazon Anwendung. 
Die Empfehlungen werden basierend auf Nutzerinteraktionen mit Suchresultaten von Pro-
dukten erstellt. Dies funktioniert umso besser, je mehr Nutzer aktiv sind und somit die 
Grundlage für die Berechnung von Empfehlungen bilden. Da wir in der Welt geographi-
scher Informationssysteme mit deutlich geringeren Nutzerzahlen rechnen können, schlagen 
wir vor, zusätzlich zu Empfehlungen basierend auf Nutzerinteraktionen auch Empfehlun-
gen basierend auf Berechnungen semantischer Textvergleiche durch Methoden wie Latent 
Semantic Analysis (LSA) zu generieren und in Suchportale räumlicher und nicht-räum-
licher Information zu integrieren. Diese Textvergleiche beruhen auf der Annahme, dass 
inhaltlich ähnliche Texte eher etwas gemeinsam haben und dementsprechend interessanter 
für Nutzer sind als Texte, die nur geringe Ähnlichkeiten aufweisen. Zur Validierung unse-
res Ansatzes wurde ein Prototyp der erweiterten Suchermöglichkeiten in das EnerGEO 
Geoportal integriert. 
1 
Einleitung 
Geoportale haben sich in zahlreichen Einrichtungen als zentrale Zugriffspunkte auf räumli-
che Information etabliert. Ein Geoportal stellt somit die Brücke dar, die Nutzer und Inhalte 
zusammenführt (T
ANG 
&
S
ELWOOD 
2005). Dennoch sind Nutzer in vielen Fällen mit den 
Suchresultaten nicht zufrieden. Dies gilt v. a. in Fällen, in denen eine sehr große Menge an 
Daten zu durchforsten ist (C
ROISIER 
2012). Um diese Anforderungen besser erfüllen zu 
können, präsentieren wir in diesem Aufsatz die Integration von semantischen Textanalyse-
methoden 
wie 
Latent 
Semantic 
Analysis 
(LSA) 
in 
Kombination 
mit 
Recommender-
Systemen zur Verbesserung der Suchergebnisse in Geoportalen. 
Als Basis für das Auffinden von Information sind Metadaten von räumlichen Daten und 
Diensten – am besten in Kombination mit nicht-räumlichen Informationsebenen wie klassi-
schen Dokumenten (PDF etc.) – unerlässlich. Metadaten werden in der Regel mit einer 
Kombination aus (semi-)automatischer Daten-Extraktion und nutzerspezifischen Einträgen 
erstellt. Diese Information wird in Recommender-Systeme integriert, welche den Nutzern 
als Suchergebnis eine zusätzliche Liste von geordneten Suchresultaten neben den klassi-
schen Text-Matching-Ergebnissen liefert. Diese basiert auf: 
1)
Betrachtungen und Bewertungen von anderen Nutzern. 
2)
Verknüpfungen, die automatisch durch semantische Textanalyse erstellt werden. 
Strobl, J., Blaschke, T., Griesebner, G. & Zagel, B. (Hrsg.) (2013): Angewandte Geoinformatik 2013. 
© Herbert Wichmann Verlag, VDE VERLAG GMBH, Berlin/Offenbach. ISBN 978-3-87907-533-1. 
Dieser Beitrag ist ein Open-Access-Beitrag, der unter den Bedingungen und unter den Auflagen der 
Creative Commons Attribution Lizenz verteilt wird (http://creativecommons.org/licenses/by/3.0/).
Verbesserung der Geo-Discovery mit Recommender-Systemen 
223 
2 
Recommender-gestützte Suchergebnisse 
Recommender-Systeme finden eine weite Verbreitung in Online-Shops wie Amazon. Dort 
dienen sie dem Zweck, Kunden Produkte anzubieten, die für diese möglicherweise auch 
von Interesse sein könnten. Die Empfehlungen selbst basieren auf Berechnungen, die in 
festlegbaren Intervallen im Hintergrund ablaufen. Im Allgemeinen nehmen Recommender-
Systeme darauf Bezug, was andere Nutzer betrachteten („View“), kauften („Buy“) und 
bewerteten („Rate“), indem die Klicks auf Inhalte von Algorithmen analysiert werden. 
Diese Inhalte können wie im Falle von Amazon Bücher oder CDs sein. Im Kontext von 
Geodateninfrastrukturen schlagen wir vor, sowohl räumliche, d. h. Vektor-, Rasterdaten 
und geographische Dienste als auch nicht-räumliche Informationen in Form von Dokumen-
ten durch Recommender-Systeme effizienter auffindbar zu machen. 
Um Recommender-Suchergebnisse in Geoportale zu integrieren, haben wir eine Analogie 
entwickelt, welche die beiden Konzepte miteinander verbindet. Abb. 1 zeigt den typischen 
Ablauf eines Nutzers, der mit den Suchresultaten in einem Geoportal interagiert. Das Auf-
finden („Find“) von Information kann dementsprechend mit dem Betrachten („View“) 
aufseiten der Recommender-Systeme gleichgesetzt werden. Die Verwendung („Use“), d. h. 
z. B. der Bezug eines Dienstes impliziert einen Kauf („Buy“), während das Bewerten von 
Inhalten („Rate“) in beiden Welten zu finden ist. 
Abb. 1: 
Analogie 
der 
Terminologie 
von 
Geoportalen 
und 
Recommender-Systemen 
(Quelle: eigene Darstellung 2013) 
Grundsätzlich funktionieren Recommender-Systeme umso besser, je mehr Nutzer Daten für 
die Berechnung von Empfehlungen durch ihre Interaktionen mit Suchergebnissen liefern. 
Gerade dies ist aber in Experten-Suchsystemen wie Geoportalen oft nicht der Fall. Um 
dieses Manko zu überwinden, schlagen wir als zusätzlichen Faktor zur Verbesserung der 
Suchergebnisse vor, neben den klassischen nutzergenerierten Daten als zusätzlichen Input 
für die Berechnung von Empfehlungen auch die semantische Textanalyse zu verwenden. 
Dies beinhaltet die kontextuelle inhaltliche Analyse der Informationsgrundlagen. Die in der 
folgenden Abbildung (vgl. Abb. 2) dargestellten Teilkomponenten gliedern sich also in die 
‚Analyse von Nutzerinteraktionen‘ in Geoportalen und in ‚Semantische Textvergleiche‘. 
B. Vockner und M. Mittlböck 
224
Abb. 2: 
Teilkomponenten der Berechnung von Empfehlungen (Quelle: eigene Darstel-
lung 2013) 
3 
Erweiterung von Recommender-Systemen mit 
Methoden semantischer Textanalyse 
Um auch eine Verknüpfung zwischen räumlichen und vorrangig nicht-räumlichen Daten-
grundlagen (z. B. Bescheide mit eindeutiger Ortsbezeichnung wie einer Grundstücksnum-
mer) in Geoportalen automatisiert erstellen zu können, werden Algorithmen zur Abbildung 
der semantischen Ähnlichkeit angewendet. Eine dieser Methoden ist Latent Semantic Ana-
lysis (LSA; D
UMAIS 
et al.
1988), welche zu den Vertretern der nicht-überwachten Doku-
mentanalyse gehört. Nicht-überwacht bedeutet in dem Zusammenhang, dass die Methode 
keiner direkten Eingriffe von Nutzern bedarf. LSA verwendet einen Algorithmus, der da-
rauf aufbaut, Hauptkomponenten in Dokumenten zu finden. Dazu wird mathematisch eine 
gewichtete Termfrequenz-Matrix aus einer großen Menge an Dokumenten erstellt. Zur 
Dimensionsreduzierung wird eine Singulärwertzerlegung durchgeführt. Dies dient dem 
Zweck, die Rechenzeit sowie die Komplexität der Berechnung zu reduzieren. Um die Ähn-
lichkeit zwischen zwei Textdokumenten feststellen zu können, wird in einem letzten Schritt 
der Kosinus des Winkels der Vektor-Repräsentationen der beiden Textdokumente berech-
net. Werte von 1 deuten auf eine exakte bzw. sehr hohe Übereinstimmung, 0 auf keinerlei 
Übereinstimmung hin. Dementsprechend sind sich zwei Dokumente umso ähnlicher, je 
höher der Kosinus-Wert ist. 
L
ANDAUER 
et al. (1997) haben dargestellt, dass LSA den Wissensstand von Studenten an-
hand der Analyse von Essays, die diese verfasst haben, schätzen kann. Die Resultate haben 
gezeigt, dass der Unterschied zwischen den Schätzungen der Probanden und LSA relativ 
gering ist (L
ANDAUER 
et al. 1997). Der entscheidende Vorteil von LSA im Vergleich zu 
anderen Textanalysemethoden ist, dass keine manuell erstellten Ressourcen wie Thesauri 
oder Dictionaries benötigt werden. Der Algorithmus basiert einzig und allein auf großen 
sprachabhängigen Textmengen (z. B. DBpedia), auf deren Basis die Bedeutung von Wör-
tern abgeleitet wird (D
UMAIS
2004). LSA geht davon aus, dass die Bedeutung von Texten 
als Summe der Einzelbedeutungen von Wörtern verstanden werden kann (W
ICIJOWSKI 
&
Z
IOLKO 
2011). 
Verbesserung der Geo-Discovery mit Recommender-Systemen 
225 
4 
Implementierung 
Zur Realisierung des Textanalysewerkzeugs haben wir die beiden Python Module gensim 
und simserver verwendet (R
EHUREK 
&
S
OJKA 
2010). Der stark vereinfachte Prozessablauf 
der semantischen Textvergleiche gliedert sich in die Erstellung einer Sammlung von Do-
kumenten (Korpus), die in Vektoren konvertiert werden. Dementsprechend werden die 
Texte in einzelne Wörter zerlegt und deren Auftretenshäufigkeit im Text berechnet. Häufig 
vorkommende Wörter wie Artikel oder Bindewörter werden dabei entfernt. Das Resultat ist 
eine Termfrequenzmatrix, welche n-Dimensionen umfasst. Die anschließende Singulär-
wertzerlegung dient der Dimsionsreduzierung – mit dem Ziel, die semantische Struktur der 
Dokumente zu ermitteln, indem die statistischen Kookkurrenzmuster von Wörtern mit dem 
Korpus von Trainingsdokumenten verglichen werden. Abschließend wird der Kosinus des 
Winkels zwischen den Vektoren berechnet, die Werte zwischen 0 und 1 liefern. Diese fun-
gieren wiederum als Basis für zusätzliche Regelsätze des Recommender-Systems basierend 
auf Textähnlichkeiten. 
Als Recommender-System haben wir das Open-Source-Produkt „easyrec“ (http://www. 
easyrec.org) verwendet. Dieses stellt ein Java Servlet dar und kann dementsprechend in 
ESRI Geoportal Server, welches als Grundlage für das Geoportal fungiert, integriert wer-
den. Easyrec basiert hauptsächlich auf zwei Algorithmen: dem Apriori Algorithmus R 
(A
GRAWAL 
&
S
RIKANT
1994) und SlopeOne (L
EMIRE 
&
M
ACLACHLAN
2005). Diese dienen 
dazu, Assoziationsregeln für Produkte, die Nutzer betrachtet, gekauft oder bewertet haben, 
zu erstellen. Neben diesen „klassischen“ Recommender-Regeln, ermöglicht es die Pro-
grammierschnittstellte (API) von easyrec, zusätzlich Regeln von Fremdprodukten zu inte-
grieren. Diese Schnittstelle wird verwendet, um Empfehlungen basierend auf semantischen 
Textähnlichkeiten in das Recommender-System zu integrieren. 
Wenn ein Nutzer auf ein Ergebnis in der Suchoberfläche des EnerGEO Geoportals klickt, 
so werden in einer separaten Ergebnisliste weiterführende Materialien in Form von Emp-
fehlungen präsentiert (Abb. 3). Diese Empfehlungen basieren einerseits darauf, was andere 
Nutzer für interessant befunden haben, andererseits auf den semantischen Übereinstim-
mungen von Textdokumenten bzw. Ressourcenbeschreibungen. 
Abb. 3: 
Recommender-Sucherergebnisliste im EnerGEO Geoportal (Quelle: eigene Dar-
stellung 2013) 
5 
Fazit und Ausblick 
Die prototypische Implementierung im EU FP7 EnerGEO Geoportal zeigt die Resultate der 
kombinierten Methode aus semantischen Übereinstimmungen von Texten basierend auf 
B. Vockner und M. Mittlböck 
226
LSA und Nutzerverhalten in Form von Empfehlungen. Basierend auf der Annahme, dass 
textlich ähnliche Dokumente auch inhaltlich etwas gemeinsam haben, sowie der Annahme, 
dass Nutzer eher daran interessiert sind, was andere Nutzer betrachteten und positiv bewer-
teten, können erweiterte Recommender-Systeme entscheidend bei der Präzisierung von 
Suchresultaten beitragen. Dieser neue Ansatz ermöglicht die automatisierte Erstellung von 
Verknüpfungen zwischen Ressourcen, die per se nicht bestanden haben. Die quantitativ 
berechneten Übereinstimmungen von Texten werden in Form von Empfehlungen präsen-
tiert. Die Implementierung im EnerGEO Geoportal zeigt, dass Suchergebnisse mit dem 
Kontext der Daten erweitert werden können, welche in Kombination mit den Erfahrungen 
anderer Nutzer weitere interessante Datensätze, Dienste oder Textdokumente zur Verfü-
gung stellen kann. 
Zukünftige Forschungsarbeiten konzentrieren sich primär auf spezifische Besonderheiten 
von Metadaten (wie die Problematik des Vergleiches von Texten stark unterschiedlicher 
Länge mit relativ kurz gehaltenen Abstracts) bzw. der Durchführung von Nutzeranalysen. 
Ein weiterer interessanter Aspekt ist die Durchführung von multilingualen Textvergleichen. 
Literatur 
A
GRAWAL
,
R.
&
S
RIKANT
,
R. (1994), Fast Algorithms for Mining Association Rules in 
Large Databases. In: VLDB 1994 Proceedings of the 20th International Conference on 
Very Large Data Bases, 487-499. 
C
ROISIER
, S. (2012), The Rise of Semantic-aware Applications. In: M
AASS
,
W.
&
K
O
-
WATSCH
,
T. (Eds.), Semantic Technologies in Content Management Systems. Springer-
Verlag, Berlin/Heidelberg, 23-33. 
D
UMAIS
,
S. (2004), Latent semantic analysis. Annual Review of Information Science and 
Technology, 38 (1), 188-230. 
D
UMAIS
,
S.
T.,
F
URNAS
,
G.
W.,
L
ANDAUER
,
T.
K.,
D
EERWESTER
,
S.
&
H
ARSHMAN
,
R. 
(1988), Using latent semantic analysis to improve access to textual information. In: Pro-
ceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM. 
Washington, D.C., USA, 281-285. 
L
ANDAUER
,
T.,
L
AHAM
,
D.,
R
EHDER
,
B.
&
S
CHREINER
,
M.
E. (1997), How well can passage 
meaning be derived without using word order. In: Proceedings of the 19th annual meet-
ing of the Cognitive Science Society. 
R
EHUREK
,
R.
&
S
OJKA
,
P.
(2010), Software Framework for Topic Modelling with Large 
Corpora. In Proceedings of the LREC 2010 Workshop on New Challenges for NLP 
Frameworks, Valletta, Malta, 45-50. 
T
ANG
,
W.
&
S
ELWOOD
,
J. (2005), Spatial portals. Gateways to Geographic Information. 
ESRI Press, Redlands, USA. 
W
ICIJOWSKI
,
J.
&
Z
IOLKO
,
B. (2011), Extracting semantic knowledge from Wikipedia. In: 
K
LOPOTEK
,
M.
A. (Ed.), Information Systems: new approaches. Publishing House of 
University of Podlasie, Podlasie, 91-98. 
