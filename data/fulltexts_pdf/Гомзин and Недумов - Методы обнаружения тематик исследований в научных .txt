Московский государственный университет имени М.В.Ломоносова
Факультет вычислительной математики и кибернетики
Кафедра системного программирования
Пархоменко Павел Андреевич
Методы обнаружения тематик
исследований в научных статьях
МАГИСТЕРСКАЯ ДИССЕРТАЦИЯ
Научный руководитель:
ассистент кафедры СП
Гомзин Андрей Геннадьевич
Научный консультант:
Недумов Ярослав Ростиславович
Москва, 2017
Аннотация
Магистерская диссертация посвящена разработке метода Article2vec построения век-
торного представления научных статей для решения задачи выявления тематик исследо-
вания во множестве научных статей.
Этот метод является обобщением метода Paper2vec (С.
Гангули,
2017) [1].
Article2vec
предоставляет возможность учитывать несколько источников информации, которые мож-
но использовать для построения векторного представления научных статей (тексты статей,
отношение цитирования между статьями, метаданные). Также Article2vec позволяет учи-
тывать важность разных источников информации.
В ходе экспериментальных исследований показывается,
что использование Article2vec
в методе выявления тематик исследования во множестве научных статей способно увели-
чить эффективность работы метода по сравнению с другими существующими способами
построения векторного представления научных статей.
2
Содержание
Введение
5
1
Постановка задачи
9
2
Обзор существующих решений
11
2.1
word2vec .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
12
2.2
Подходы, основанные на тексте статьи .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
13
2.2.1
TF-IDF .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
2.2.2
BM25
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
2.2.3
Paragraph2vec
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
2.3
Подходы, основанные на отношении цитирования статей .
.
.
.
.
.
.
.
.
.
.
.
16
2.3.1
DeepWalk .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
2.3.2
Node2vec
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
2.4
Комбинированные подходы .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
2.4.1
Конкатенация
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
21
2.4.2
Paper2vec
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
2.5
Выводы .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
3
Исследование и построение решения задачи
25
3.1
Общая структура метода выявления тематик исследования .
.
.
.
.
.
.
.
.
.
25
3.2
Построение векторного представления статьи .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
26
3.2.1
Добавление рёбер совместного цитирования статей .
.
.
.
.
.
.
.
.
.
.
26
3.2.2
Добавление рёбер, соответствующих авторам статей .
.
.
.
.
.
.
.
.
.
27
3.2.3
Изменение алгоритма построения векторного представления вершины
графа
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.2.4
Взвешивание ребер
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
28
3.2.5
Article2vec
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
29
3.3
Методология экспериментальных исследований .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
3.3.1
Наборы данных
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
30
3.3.2
Внешние меры эффективности .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
31
3.3.3
Внутренние меры эффективности .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
32
3.4
Результаты экспериментальных исследований .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
33
3.4.1
Максимальная эффективность .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
35
3.4.2
Эффективность полученная с помощью оптимизации внутренних мер
эффективности .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
3
3.4.3
Сравнение внешних мер эффективности .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
41
4
Описание практической части
42
4.1
Выбранный инструментарий .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
4.2
Article2vec .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
42
4.3
Метод выявления тематик исследования .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
4.3.1
Общая схема работы
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
4.3.2
Общая архитектура
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
43
4.4
Тестовая система .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
45
4.4.1
Общая схема работы
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
4.4.2
Общая архитектура системы .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
46
4.5
Производительность .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
48
Заключение
50
Список литературы
51
Приложение A. Внутренние меры эффективности
57
Приложение B. Внешние меры эффективности
59
4
Введение
Благодаря электронным библиотекам (CiteSeer
1
, КиберЛенинка
2
, eLIBRARY.ru
3
) и ар-
хивам (arXiv.org
4
) научных статей и их препринтов, исследователи и ученые со всего мира
имеют доступ к текстам научных публикаций. Это дает им возможность быть в курсе те-
кущих исследований и разработок; иметь представление о последних достижениях, пред-
ставленных на международных конференциях; получать быстрый доступ к интересующим
научным статьям.
Количество научных публикаций,
находящихся в открытом доступе,
очень велико.
Один только arXiv.org, специализирующийся на хранении препринтов научных статей все-
го лишь нескольких направлений (физика,
математика,
компьютерные науки,
биология,
статистика и финансы), содержит более 1 250 000 препринтов. И это число с каждым днем
все увеличивается.
Наличие такого большого количества доступных научных статей также является про-
блемой для исследователей и ученых. Они сталкиваются с необходимостью выявления из
этого огромного множества статей только тех работ, которые являются действительно по-
лезными для них.
Особенно это затруднительно для исследователей, только начинающих погружаться в
новую для себя предметную область и не имеющих представления о ее структуре, сильных
научных школах, последних достижениях, конференциях.
Примером таких исследователей могут служить студенты,
работающие над курсовой
или дипломной работой. Им необходимо с нуля разобраться в предметной области, понять
ее структуру,
выбрать наиболее актуальные публикации.
Так как у студентов зачастую
отсутствует опыт проведения исследований,
они могут столкнуться с трудностями при
поиске релевантных научных статей.
Еще одним примером служат специалисты в R&D отделах корпораций (исследователи-
разработчики).
Перед ними постоянно встает задача исследования новой предметной об-
ласти для разработки требуемого программного средства. Исследование новой предметной
области без использования вспомогательных средств может быть очень трудной задачей,
требующей большого количества времени.
Исследовательский поиск (разведочный поиск,
exploratory search) [2,
3,
4]
помогает
таким исследователями лучше разобраться в новой для них предметной области. Главной
1
http://citeseerx.ist.psu.edu/
2
http://cyberleninka.ru/
3
http://elibrary.ru/
4
https://arxiv.org/
5
задачей, решаемой исследовательским поиском, является создание представления исследо-
вателя о предметной области, путем ответа на сложные вопросы о ней [4]: «какова структу-
ра предметной области, из каких тем она состоит?», «какие основные достижения?», «как
она развивалась со временем?», «какие авторы компетентны по данной теме?»и так далее.
Один из существующих подходов исследовательского поиска — навигация на основе
кластеров (clustering based navigation)[5]. Этот подход предполагает разбиение множества
документов из одной предметной области (кластеризация) на близкие по смыслу подмно-
жества (кластеры), что позволяет понять структуру этой предметной области. При хоро-
шей кластеризации каждый кластер должен содержать статьи, посвященные одной и той
же тематике исследования, то есть содержать статьи, рассматривающие общую проблему,
описывающие схожие темы.
Исследователю было бы полезно иметь программное средство, разделяющее множество
статей на кластеры.
В этом случае он бы мог,
например,
прочитать статью из каждого
кластера (например,
какой-нибудь обзор либо самую цитируемую публикацию) и понять
структуру предметной области.
К примеру,
он бы мог понять что его задаче релевант-
ны статьи только из одного кластера и направить дальнейшие усилия на исследование
публикаций, которые были отнесены к этому кластеру.
Вообще говоря,
тематики исследования научных статей могут иметь довольно слож-
ную структуру.
Во-первых,
они могут иметь иерархическую структуру:
некоторые тема-
тики исследования (например, математика) могут состоять из других тематик (например,
математический анализ или линейная алгебра). Во-вторых, тематики исследования могут
пересекаться: статья может одновременно относиться к нескольким тематикам исследова-
ния.
Несмотря на это,
в некоторых работах [6,
7,
8]
делается упрощенное предположение
о неиерархичности и непересекаемости тематик исследования.
Возможным обоснованием
этого выбора можно считать желание выделить тематики исследования одного уровня
иерархии в заданном множестве статей. Также выявление непересекающихся тематик ис-
следования, возможно, упрощает навигацию по кластерам статей.
Задачу кластеризации научных статей можно решать разными способами.
Существу-
ющие подходы можно классифицировать по источнику информации,
на основе которого
производится кластеризация.
Некоторые методы решают задачу кластеризации на основе известной текстовой ин-
формации.
В качестве текстовой информации могут быть использованы как полные тек-
сты статей, так и их аннотации или даже названия. Например, некоторые из этих подходов
основаны на взаимной встречаемости слов в текстах статей [9, 10]; другие строят темати-
ческую модель текстов статей и на её основе производят кластеризацию [11, 12, 13]. Обзор
6
и экспериментальное исследование методов кластеризации текстов научных статей можно
найти в работе [14].
Еще одним важным источником данных при решении задачи кластеризации научных
статей является отношение цитирования между статьями. Одним из вариантов представ-
ления отношений цитирования является граф цитирования. Под графом цитирования по-
нимается ориентированный граф,
вершины которого соответствуют научным статьям,
а
рёбра — отношению цитирования. Ребро, исходящее из вершины, соответствующей статье
A, и входящее в вершину, соответствующую статье B, существует в том случае, если ста-
тья A цитирует статью B.
В ряде работ [15,
16,
17,
18]
описывается следующий подход
кластеризации научных статей:
на основе множества научных статей строится их граф
цитирования,
а затем применяется алгоритм кластеризации к вершинам этого графа.
В
этом случае статьи образуют те же кластеры, что и соответствующие им вершины графа
цитирования.
Некоторые другие подходы [19, 20] также используют отношения цитирования научных
статей для построения графа и его дальнейшей кластеризации, но построенные ими графы
имеют иную структуру. Примером такого графа является граф совместного цитирования
статей (co-citation graph).
Это неориентированный граф,
вершины которого соответству-
ют научным статьям,
а рёбра — отношению совместного цитирования соответствующих
статей. Говорят, что две статьи A и B связаны отношением совместного цитирования, если
существует другая статья C, цитирующая одновременно обе эти статьи.
Еще
одним примером такого
графа
является
граф библиографических
связей
(bibliographic coupling).
Вершины этого графа соответствуют научным статьям,
а рёбра
— библиографической связи между соответствующими статьями. Две статьи A и B связа-
ны библиографической связью, если существует статья C, которую статьи A и B цитируют.
Граф такого вида используется в работах [21, 22].
Один из возможных подходов решения задачи кластеризации заключается в нахожде-
нии векторного представления статьи (сопоставлению каждой статье вещественного векто-
ра фиксированной длины) и кластеризации этих векторов. Такой подход был использован
в работах [5, 7, 8, 10, 14]. В этом случае в один кластер попадают те статьи, чьи векторы
также попали в один кластер.
Некоторые современные методы [23,
24,
25],
используемые для построения векторно-
го представления научных статей,
основываются на методе word2vec [26,
27],
представ-
ленном Т.
Миколовым и др.
в 2013 году.
Метод word2vec строит векторное представле-
ние слова на основе большого набора текстов.
Два слова имеют близкие вектора в том
случае,
если они встречаются в текстах рядом с одними и теми же словами.
На основе
7
word2vec были разработаны методы,
как вычисляющие векторное представление текстов
(например, Paragraph2vec [23]), так и векторное представление вершин графа (например,
DeepWalk [24]).
В статье [14]
описывается экспериментальное исследование применимости различных
способов нахождения векторного представления текстов научных статей в задаче класте-
ризации научных статей.
В этой статье показано,
что самыми эффективными методами
определения векторного представления текстов статей для задачи кластеризации статей
являются Paragraph2vec,
TF-IDF,
BM25 [28]
(эти методы предпочтительнее в том числе
методов тематического моделирования).
В работе [6]
показывается,
что использование современных методов построения век-
торного представления вершин графа,
основанных на word2vec,
в задаче кластеризации,
является более эффективными,
чем использование классического алгоритма кластериза-
ции графа (алгоритм спектральной кластеризации).
Можно сделать предположение,
что кластеризация научных статей на основе вектор-
ного представления этих статей,
может быть эффективной.
Для этого необходимо иметь
эффективный метод построения векторного представления научной статьи.
Одним из возможных направлений для создания эффективного векторного представ-
ления научной статьи является одновременное использование разных источников инфор-
мации (тексты статьи, отношения цитирования, авторы, журнал и так далее).
Но необходимо учитывать, что не вся эта информация может быть доступна для каждой
статьи.
Поэтому необходимо,
чтобы несмотря на отсутствие некоторых данных о статье,
векторное представление все равно можно было построить. Например, если для некоторых
статей не известен их текст, но известны их отношения цитирования с другими статьями; а
для других статей известны тексты, но неизвестны отношения цитирования, то векторное
представление можно построить на основе имеющейся информации.
Также необходимо учитывать, что разные источники информации могут быть полезны
в разной степени.
Это тоже необходимо учитывать при построении векторного представ-
ления.
8
1
Постановка задачи
Целью магистерской диссертации является разработка метода построения векторного
представления научных статей. Этот метод должен принимать на вход множество научных
статей и для каждой статьи из этого множества возвращать ее векторное представление:
вещественный вектор фиксированной длины.
Так как при построении векторного представления научной статьи могут быть полезны
несколько источников информации (тексты статей, отношения цитирования, метаданные),
желательно, чтобы метод был способен учитывать несколько источников. Если метод учи-
тывает только один источник информации,
он не сможет построить векторное представ-
ление статьи, если для этой статьи такая информация отсутствует.
Также метод должен быть способен построить векторное представление статьи в слу-
чае, если какие-то источники информации, на основе которых происходит построение век-
торного представления, для данной статьи отсутствуют. Например, если у некоторых ста-
тей в наборе данных отсутствуют тексты, а у других — информация об отношении цити-
рования, метод должен уметь строить векторное представление на основе тех источников
информации, которые присутствуют у данной статьи.
Так как для разных наборов данных важность одних и тех же источников информа-
ции может отличаться (а некоторые источники могут только ухудшать эффективность
работы), метод построения векторного представления статьи должен учитывать важность
источников информации.
Разработанный метод необходимо экспериментально сравнить с существующими мето-
дами при решении задачи выявления тематик исследования во множестве научных статей.
Для выявления численного значения эффективности работы метода выявления тема-
тик исследования во множестве научных статей при использовании различных методов
построения векторного представления научных статей,
необходимо определить внешнюю
меру эффективности,
которая позволит получить численную оценку схожести двух раз-
биений статей по тематикам исследования: настоящим (полученным человеком) и предла-
гаемым (полученным методом). Так как исследуемые методы могут зависеть от значений
гиперпараметров, необходимо провести два вида экспериментальных исследований.
Во-первых, необходимо установить потенциально максимальную эффективность иссле-
дуемых методов. Этого можно добиться путем проведения нескольких экспериментальных
исследований для каждого метода с разными значениями гиперпараметров.
Потенциаль-
но максимальной эффективностью исследуемого метода является максимальное значение
внешней меры эффективности,
полученное в процессе экспериментальных исследований
для данного метода.
9
Во-вторых, так как эффективность исследуемых методов зависит от значений гиперпа-
раметров,
необходимо определить способ,
с помощью которого будет происходить подбор
значений гиперпараметров.
Этот способ может быть основан на предлагаемом (методом)
разбиении статей по тематикам исследования,
но без использования настоящего распре-
деления статей по тематикам исследования.
В итоге должны быть вычислены значения
внешней меры эффективности работы исследуемых методов при использовании способа
определения оптимальных значений гиперпараметров.
Для проведения экспериментальных исследований необходимо реализовать тестовую
систему,
позволяющую автоматизировать процесс экспериментальных исследований.
Те-
стовая система должна принимать на вход метод выявления тематик исследования во
множестве статей (с методом построения векторного представления статьи),
возможные
значения гиперпараметров метода, множество статей, настоящее распределение статей по
тематикам исследования. Система должна запускать исследуемый метод со всевозможны-
ми комбинациями значений гиперпараметров и для каждой комбинации выдавать инфор-
мацию о результатах экспериментальных исследований.
Метод выявления тематик исследования должен работать не более 1 часа для набора
данных, состоящего из 10000 статей.
10
2
Обзор существующих решений
Данная глава посвящена обзору существующих методов построения векторного пред-
ставления научной статьи. Для каждого из исследуемых методов необходимо выявить сле-
дующую информацию:
• используемые источники информации;
• способен ли метод строить векторное представление статьи,
у которой отсутствует
информация из некоторых используемых источников информации;
• учитывается ли важность различных источников информации;
• эффективность работы методов,
использующих данный способ векторного построе-
ния;
Последний пункт необходим для понимания эффективности векторного представления
при решении различных практических задач. Так как напрямую оценить эффективность
методов построения векторного представления чаще всего не представляется возможным
(из-за отсутствия ожидаемого векторного представления,
которое необходимо получить),
на практике для получения оценки эффективности работы построения векторного пред-
ставления различных объектов их используют как составную часть при решении какой-то
прикладной задачи.
Часто такими задачами являются задачи классификации [1,
24,
25],
кластеризации [6], визуализации в двухмерном пространстве [6], предсказания ребер в гра-
фе [1, 25].
В данной работе для проверки эффективности различных векторных представлений
используется задача кластеризации научных статей.
Как уже было сказано ранее,
ряд
работ [5, 7, 8, 10, 14], решающих данную задачу, основаны на следующей схеме:
1.
предварительная обработка данных;
2.
построение векторного представления научной статьи;
3.
кластеризация векторов, полученных на предыдущих этапах.
Предварительная обработка данных необходима для нормализации данных,
удаления
шума.
Методы,
применяемые на этом шаге,
зависят от структуры и природы данных.
При
построении алгоритмов,
работающих с научными статьями,
желательно проводить пред-
варительную обработку текстов этих статей.
Один из стандартных способов нормализации текстов,
написанных на естественном
языке, включает в себя:
• удаление знаков препинания;
• перевод слов в один регистр;
• удаление стоп-слов (слов, которые не оказывают влияния на семантику текстов);
11
• стемминг (перевод слов в нормальную форму путем удаления преффиксов и суф-
фиксов).
Для кластеризации векторов можно использовать один из существующих методов кла-
стеризации.
Одним из самых популярных методов,
использующихся при решении этой
задачи (например,
в работах [5,
7,
8,
10,
14]),
является алгоритм k-means
(метод k-
средних) [29].
Многие современные методы определения векторного представления объектов бази-
руются на идее метода word2vec,
разработанного Т.
Миколовом в 2013 году.
Этот метод
предназначен для построения векторного представления слов. Его описание можно найти
в разделе 2.1.
Разные методы построения векторного представления статьи могут быть классифици-
рованы по используемому источнику информации. В разделе 2.2 рассматриваются методы,
строящие векторное представление статей на основе их текстов; в разделе 2.3 рассматри-
ваются методы,
рассматривающие множество статей как граф,
вершины которого соот-
ветствуют статьям, а ребра — некоторому отношению близости между соответствующими
статьями (например,
отношению цитирования);
раздел 2.4 посвящен описанию методов,
использующих несколько источников информации.
2.1
word2vec
Word2vec [26, 27] базируется на дистрибутивной гипотезе: значение слова можно понять
по его контексту («You shall know the word by the company it keeps» [30]). В word2vec под
контекстом понимается N слов, находящихся в тексте перед словом, для которого строится
вектор,
и N слов,
находящихся после этого слова.
Параметр N принято называть окном
(window).
Существует 2 метода построения word2vec векторов: Continuous Skip-gram Model (Skip-
gram) [26]
и Continuous Bag-of-Words Model
(CBOW) [26].
Оба этих подхода основаны на
обучении неглубокой нейронной сети (с одним скрытым слоем), но архитектуры нейронных
сетей у этих подходов отличаются (на рисунке 1 изображены их архитектуры).
Нейронная сеть, обучаемая в CBOW, решает задачу предсказания слова по его контек-
сту.
Фиксируется некоторое слово из текста,
на вход нейронной сети поступают текущие
word2vec векторы слов из контекста фиксированного слова. Далее эти векторы суммиру-
ются и сеть пытается предсказать фиксированное слово. После этого она сравнивает пред-
сказанное слово с фиксированным словом и обновляет параметры (в том числе и word2vec
векторы).
Нейронная сеть, используемая в Skip-gram, решает обратную задачу: предсказания кон-
12
Рис. 1: Архитектуры нейронных сетей, используемых в двух подходах word2vec: CBOW и
Skip-gram. (Слева) Нейронная сеть в CBOW предсказывает слово по его контексту. (Спра-
ва) Обучаемая в Skip-gram нейронная сеть предсказывает контекст по слову. Рисунок взят
из статьи Т. Миколова, описывающей эти подходы [26].
текста по слову.
Обучение этого алгоритма устроено следующим образом.
Фиксируется
некоторое слово из текста, ему ставится в соответствие его текущий word2vec вектор. По
этому вектору нейронная сеть предсказывает контекст слова, сравнивает с реальным кон-
текстом и обновляет параметры алгоритма (в том числе и word2vec векторы слов).
Оба алгоритма применяются к каждому слову текста,
причем обычно это делают
несколько раз (проводится несколько итераций).
Итоговые векторы слов и считаются
word2vec векторами.
Более подробное описание этих двух методов можно найти в ра-
боте [26].
Статья [27]
посвящена описанию алгоритмов предсказания слова по word2vec
вектору (в модели CBOW) и предсказанию контекста по word2vec вектору (в Skip-gram).
2.2
Подходы, основанные на тексте статьи
Для нахождения векторного представления статьи можно использовать методы,
ос-
нованные на нахождении векторного представления текста.
Таким методам в качестве
входных данных можно передавать доступные текстовые данные статьи:
полный текст,
аннотацию, название и так далее.
Все методы данной группы используют только один источник информации — текст ста-
13
тьи (либо другую текстовую информацию о статье).
Если у какой-то статьи отсутствует
текстовая информация, для этой статьи будет невозможно построить векторное представ-
ление.
В обзоре [14] было проведено экспериментальное исследование методов построения век-
торного представления текстов научных статей для задачи кластеризации статей.
Экспериментальное
исследование
проводилось
на
четырех
наборах
данных:
20
Newsgroups (20 NG)
5
[31], Krapivin (KR) [32], аннотации из Krapivin (KRabs), TREC GEN
2007 (TG2007) [33]. Таблица 1 содержит результаты экспериментальных исследований. Для
каждого метода указано значение меры эффективности AMI [34]. Чем ее значение больше,
тем выше эффективность метода.
В данном обзоре были исследованы следующие методы построения векторного пред-
ставления статей:
BinaryBOW (встречаемость
каждого
слова
(n-граммы)
в
тексте),
CountBOW (количество раз, в которых каждое слово (n-грамма) встретилось в тексте), TF-
IDF,
BM25 [28],
NMF [35],
LDA [36],
WVAvgPool
[37]
(усреднение word2vec векторов слов
в тексте), PV-DM [23] ( Paragraph2vec Distributed memory), PV-DBOW [23] (Paragraph2vec
Distributed bag of words), WordClustering [38], WVClustering [39].
Таблица 1:
Максимальное значение AMI при использовании различных методов построе-
ния векторного представления статьи.
20NG
KR
KRabs
TG2007
BinaryBOW
0.2586
0.2402
0.2041
0.3581
CountBOW
0.2957
0.2453
0.1598
0.4018
TF-IDF
0.4911
0.2826
0.2705
0.5051
BM25
0.4261
0.3069
0.2824
0.5291
NMF
0.4438
0.2642
0.262
0.4882
LDA
0.3391
0.2831
0.2237
0.4155
WVAvgPool
0.141
0.174
0.1608
0.2847
PV-DM
0.5901
0.3014
0.2483
0.56
PV-DBOW
0.6735
0.2773
0.251
0.5026
WordClustering
0.2188
0.2296
0.2059
0.4193
WVClustering
0.1159
0.0875
0.0613
0.1636
Наилучшие результаты были получены при использовании методов TF-IDF,
BM25 и
Paragraph2vec.
5
http://qwone.com/~jason/20Newsgroups/
14
2.2.1
TF-IDF
Одним из самых распространенных подходов построения векторного представления
текстов является TF-IDF. Значение TF-IDF слова t
i
в документе d
j
можно рассматривать
как важность данного слова для документа.
Это значение определяется формулой 1 и
представляет собой произведение двух частей: TF и IDF.
T F − IDF (t
i
, d
j
, D) = tf (t
i
, d
j
) · log
|D|
|(d
j
⊃ t
i
)|
(1)
Значение TF равно количеству раз, которое слово t
i
встретилось в документе d
j
, а зна-
чение IDF обратно пропорционально количеству документов,
в которых это слово встре-
чается. В данной формуле D — множество рассматриваемых документов.
Таким образом, значение TF-IDF слова для документа тем больше, чем чаще оно встре-
чается в этом документе, и чем меньше документов его содержат.
При построении векторного представления текста с помощью TF-IDF обычно рассмат-
ривают N слов, которые чаще всего встречались во множестве текстов D. В этом случае
векторы текстов имеют размерность N ,
и каждая компонента вектора соответствует од-
ному из N слов.
2.2.2
BM25
Одной из модификаций TF-IDF является метод BM25 [28].
Отличие BM25 от TF-IDF
заключается в множителе,
отвечающем за частоту слова в тексте:
в BM25 его значение
ограничено числом k
1
+1. Значение BM25 для слова t
i
в тексте d
j
определяется формулой 2.
BM25(t
i
, d
j
, D) =
tf (t
i
, d
j
) · (k
1
+ 1)
k
1
· (1 − b + b ·
|d
j
|
|d
avg
|
) + tf (t
i
, d
j
)
· log
|D|
|(d
j
⊃ t
i
)|
(2)
Здесь D — множество рассматриваемых текстов; tf (t
i
, d
j
) — количество раз, которое слово
t
i
встретилось в тексте d
j
;
|d
avg
|
— средняя длина текстов в D;
b и k
1
— свободные пара-
метры. Обычно свободные параметры принимают следующие значения: b = 0.75, k
1
= 2.0;
Построение векторного представления текстов с использованием BM25 происходит ана-
логично TF-IDF.
2.2.3
Paragraph2vec
В 2014 году К.
Ли и Т.
Миколов представили обобщение word2vec для построения
векторного представления текста — Paragraph2vec (doc2vec) [23]. Схема его работы схожа
со схемой работы word2vec за тем лишь исключением,
что при обучении нейронной сети
15
используется еще один вид данных — векторы текстов,
которые и являются искомыми
Paragraph2vec векторами.
Как и в word2vec, в Paragraph2vec также существует два подхода: Distributed memory
(DM) и Distributed bag of words (DBOW). Они используют неглубокую нейронную сеть (с
одним скрытым слоем),
в каждом из подходов нейронная сеть имеет собственную архи-
тектуру (архитектуры нейронных сетей изображены на рисунке 2).
Рис. 2: Архитектуры нейронных сетей, используемых в двух подходах Paragraph2vec: DM
и DBOW. (Слева) Нейронная сеть в DM предсказывает слово по его контексту и по векто-
ру документа (параграфа).
(Справа) Обучаемая в DBOW нейронная сеть предсказывает
контекст по вектору документа (параграфа). Рисунок взят из статьи К. Ли и Т. Миколова,
описывающей эти подходы [23].
Нейронная сеть, используемая в DM, решает задачу предсказания слова по его контек-
сту и по вектору документа. Она принимает на вход word2vec вектора слов из контекста и
Paragraph2vec вектор документа. Далее эти векторы суммируются (или конкатенируются)
и по этому вектору предсказывается слово. После этого нейросеть сравнивает предсказан-
ное слово с реальным и обновляет параметры (в том числе Paragrap2vec вектор документа).
В DBOW подходе нейронная сеть принимает на вход Paragraph2vec вектор докумен-
та и по нему предсказывает слова из этого документа.
Далее эти слова сравниваются с
реальными словами документа и происходит обновление параметров.
Этот метод, как и word2vec, является итеративным. После завершения работы метода,
полученные Paragraph2vec вектора являются векторами документов.
2.3
Подходы, основанные на отношении цитирования статей
Множество научных статей можно рассматривать как граф, вершины которого соответ-
ствуют научным статьям, а ребра — отношению между соответствующими вершинами (на-
пример, отношению цитирования). В этом случае можно использовать методы, строящие
16
для каждой вершины ее векторное представление. В этом случае векторное представление
статьи совпадает с векторным представлением соответствующей вершины.
Такие методы основываются на одном источнике информации (отношении цитирова-
ния) и,
в случае,
если какая-то статья не связана этим отношением с какой-то другой
статьей, ей будет невозможно поставить в соответствие векторное представление.
К сожалению, исследования различных методов построения векторного представления
вершин графа в задаче кластеризации статей найти не удалось.
В работе [25]
было про-
ведено экспериментальное исследование некоторых методов построения векторного пред-
ставления вершины графа в задаче многоклассовой классификации.
Экспериментальное исследование проходило на трех наборах данных: BlogCatalog [40],
Protein-Protein Interactions (PPI) [41], Wikipedia [42]. Для оценки эффективности исследу-
емых методов использовалась F1-мера. Были исследованы следующие методы векторного
построения вершин графа:
спектральная кластеризация [43],
DeepWalk [24],
LINE [44],
Node2vec [25]. Результаты экспериментальных исследований можно найти в таблице 2.
Таблица 2: Значение F1-меры при решении мультиклассовой классификации при исполь-
зовании различных методов построения векторного представления вершины графа.
BlogCatalog
PPI
Wikipedia
Спектральная кластеризация
0.0405
0.0681
0.0395
DeepWalk
0.2110
0.1768
0.1274
LINE
0.0784
0.1447
0.1164
Node2vec
0.2581
0.1791
0.1552
В соответствии с результатами исследования,
наилучшими методами построения век-
торного представления вершин графа являются DeepWalk и Node2vec.
2.3.1
DeepWalk
В 2014 году Б.
Пероцци представил DeepWalk [24]
— метод,
использующий идею
word2vec для построения векторного представления вершин графа.
DeepWalk основан на
случайных блужданиях (random walks) [45] — построении случайных путей в графе, начи-
нающихся с фиксированной вершины.
DeepWalk зависит от следующих гиперпараметров:
размер окна w,
размер вектора d,
количество случайных блужданий из каждой вершины γ, длина случайных блужданий t.
Алгоритм состоит из двух основных этапов.
На первом этапе происходит генерация случайных блужданий.
Для каждой вершины
17
генерируются γ случайных блужданий,
начинающихся в этой вершине,
длина которых
равна t.
На следующем этапе используется модель word2vec Skip-gram для поиска векторно-
го представления вершин графа.
Так как word2vec работает с текстами,
полученные на
предыдущем этапе блуждания рассматриваются как тексты. Каждое блуждание считает-
ся предложением, а каждая посещенная в процессе блуждания вершина — словом. На этих
данных Skip-gram строит векторное представление для каждой вершины.
2.3.2
Node2vec
В 2016 году А. Гровер и Ю. Лесковец представили обобщение DeepWalk — Node2vec [25].
Ключевое отличие предложенного метода заключается в изменении стратегии выбора рё-
бер в процессе построения случайных блужданий.
Если в DeepWalk вероятность выбора
ребра в случайном блуждании одинакова для всех рёбер, инцидентных текущей вершине,
то в Node2vec она вычисляется по формуле 3:
P (c
i
= x|c
i−1
= v) =



α
pq
(t, x) · w(v, x)/Z,
если (v, x) ∈ E
0,
иначе.
(3)
С помощью этой формулы вычисляется вероятность перехода в вершину c
i
= x при
условии, что текущая вершина c
i−1
= v. Эта условная вероятность ненулевая в случае, если
существует соответствующее ребро (v, x)в графе E.
В этом случае вероятность перехода
вычисляется как произведение веса ребра (v, x):
w(x, v),
умноженного на коэффициент
α,
зависящего от вершины x (вершины,
вероятность перехода в которую вычисляется в
этой формуле) и вершины t — предыдущей вершины в случайном блуждании (вершина,
из которой был совершён переход в вершину v).
Полученное произведение делится на
константу Z для нормализации вероятности. Коэффициент α зависит от параметров p и q
и определяется следующим образом (формула 4):
α
pq
(t, x) =









1/p,
если d
tx
= 0
1,
если d
tx
= 1
1/q,
если d
tx
= 2
(4)
Величина d
tx
соответствует минимальному количеству рёбер, через которые необходи-
мо пройти,
чтобы добраться из вершины t в вершину x.
В частности,
значение d
tx
= 0
означает,
что t = x;
d
tx
= 1 соответствует смежным вершинам (вершинам,
соединённым
ребром). Необходимо отметить, что значение d
tx
не может превышать 2, так как в процессе
18
случайного блуждания был совершен переход из вершины t в вершину v, а затем в верши-
ну x. Таким образом, для рассматриваемых вершин t и x всегда существует путь длины 2
(через вершину v).
Для понимания семантики параметров p и q можно сравнить случайные блуждания,
получающиеся при использовании различных значений параметров, с обходами графа, ко-
торые можно получить при помощи алгоритмов обхода в глубину (Depth-First Search, DFS)
и в ширину (Breadth-First Search, BFS). При обходе графа в ширину сначала, по возмож-
ности, перебираются все смежные вершины одной фиксированной вершины, а уже потом
смежные вершины смежных вершин и так далее.
При обходе в глубину берется только
одна смежная вершина начальной вершины, далее выбирается смежная вершина смежной
вершины и так далее. Таким образом, если рассматривать первые n вершин обходов, они
могут значительно различаться:
в случае обхода в глубину вершина n может находиться
уже далеко от стартовой вершины, в отличие от обхода в ширину. На рисунке 3 приведен
пример обходов графа из 10 вершин.
Рис.
3:
Первые 3 вершины при совершении обхода графа из 10 вершин в ширину (BFS)
и в глубину (DFS). Обход начинается в вершине U. Рисунок взят из статьи, посвященной
Node2vec [25].
Случайные блуждания,
используемые в DeepWalk,
по своей природе схожи с обходом
графа в глубину: следующая вершина блуждания выбирается случайно из смежных вер-
шин текущей вершины. Такой алгоритм построения случайных блужданий может быть не
оптимальным при решении некоторых задач. К примеру, существует предположение, что
для графа цитирования научных статей больше подходят случайные блуждания, постро-
енные по принципу обхода в ширину:
статьи,
соответствующие вершинам,
находящимся
даже на не очень большом расстоянии друг от друга, могут быть посвящены совершенно
разным темам.
Основываясь на предположении,
что в разных задачах структура опти-
мальных случайных блужданий может отличаться, создатели Node2vec предложили доба-
вить параметры p и q для контроля структуры блужданий.
На основе описанных обходов графа и формулы 4 можно сделать вывод о структу-
19
ре случайных блужданий в зависимости от параметров p и q.
Пусть в ходе случайного
блуждания был совершен переход из вершины t в вершину x и вычисляется вероятность
перехода в вершину v.
Если v = t,
то вероятность перехода (возврата в вершину t) будет
включать в себя множитель α = 1/p. Возврат в предыдущую вершину больше свойственен
случайному блужданию,
сходному с обходом в ширину,
таким образом:
чем меньше зна-
чение p тем с большей вероятностью случайное блуждание будет состоять из небольшого
количества вершин, так как будет часто происходить возвращение к предыдущей вершине.
Аналогично может быть показано, что чем меньше значение параметра q, тем больше слу-
чайное блуждание будет напоминать обход в глубину:
обход будет состоять из большого
количества вершин, расстояние между первой и последней вершиной в обходе может быть
довольно большим.
Стоит отметить,
что при p = 1 и q
= 1,
Node2vec аналогичен DeepWalk в случае
обработки невзвешенного графа.
2.4
Комбинированные подходы
Недостатком описанных выше подходов является использование небольшого количе-
ства доступной информации. В данном разделе описаны методы, использующие одновре-
менно несколько источников информации.
В статье [1]
было проведено исследование некоторых методов построения векторного
представления научной статьи для решения задачи классификации научных статей.
Экспериментальное исследование проходило на двух наборах данных научных статей:
Cora
6
и DBLP
7
.
Экспериментальное исследование состояло в обучении классификатора SVM на N%
данных и вычислении эффективности работы на оставшейся части.
В качестве меры эф-
фективности использовалась доля правильных ответов (Accuracy).
Помимо методов TF-IDF,
Paragraph2vec,
DeepWalk и Line (которые уже упоминались
ранее) также были исследованы методы TADW [46], Paper2vec [1] и конкатенация векторов
(DeepWalk и Paragraph2vec).
Результаты экспериментальных исследований представлены в таблицах 3 и 4.
Метод
TADW не был экспериментально исследован на наборе данных DBLP, так как он, соглас-
но авторам статьи,
не способен обрабатывать наборы данных большого размера (DBLP
содержит 412806 статей).
6
https://people.cs.umass.edu/∼mccallum/data.html
7
https://aminer.org/citation
20
Таблица 3:
Эффективность классификации научных статей при использовании разных
методов построения векторного представления статей и объема обучающей выборки. Набор
данных Cora.
10%
20%
30%
40%
50%
LINE
76.98
79.35
80.46
81.34
81.82
Deepwalk
77.97
80.24
81.29
82.17
82.65
Paragraph2vec
75.46
78.34
79.54
80.40
80.87
TF-IDF
76.29
77.21
78.24
79.14
80.34
Конкатенация
80.16
81.72
82.68
83.37
83.88
TADW
77.51
79.69
80.68
81.17
81.36
Paper2vec
82.31
83.83
84.45
84.87
85.18
Таблица 4:
Эффективность классификации научных статей при использовании разных
методов построения векторного представления статей и объема обучающей выборки. Набор
данных DBLP.
10%
20%
30%
40%
50%
LINE
61.36
62.38
62.74
63.11
63.61
Deepwalk
60.27
61.56
62.29
63.00
63.43
Paragraph2vec
57.26
58.03
59.35
60.12
60.45
TF-IDF
57.57
58.59
58.87
59.5
60.09
Конкатенация
64.56
65.78
66.35
66.98
67.77
Paper2vec
65.45
66.46
67.61
68.21
69.94
На основе этих результатов можно сделать вывод, что на данный момент для построе-
ния векторного представления научной статьи лучше всего использовать Paper2vec.
2.4.1
Конкатенация
Наивным подходом,
объединяющим информацию из нескольких доступных источни-
ков, является конкатенация векторов, полученных на основе этих источников. В качестве
примера можно рассмотреть конкатенацию двух векторов,
один из которых получен на
основе текста статьи, а второй — на основе отношений цитирования статьи.
Если для статьи не будет информации из какого-то источника, на основе которого стро-
ится векторное представление, то для данной статьи невозможно будет построить вектор-
ное представление на основе этого источника и,
соответственно,
конкатенацию векторов
21
тоже. Это является недостатком конкатенации.
Для учета важности источника в конкатенации можно варьировать размерности стро-
ящихся векторов, основанных на разных источниках информации.
2.4.2
Paper2vec
С.
Гангули и В.
Пуди в
2017
году
опубликовали статью,
посвященную методу
Paper2vec [1],
решающему задачу построения векторного представления научных статей.
Метод использует информацию о текстах статей и о их отношениях цитирования. Он ос-
нован на ранее описанных методах нахождения векторного представления текстов статей
(Paragraph2vec) и вершин графа цитирования (DeepWalk).
Алгоритм Paper2vec состоит из трёх последовательных этапов:
1.
вычисление векторного представления текстов научных статей;
2.
добавление в граф цитирования ребер между вершинами,
соответствующие статьи
которых имеют близкие векторы текстов;
3.
нахождение векторного представления вершин графа (векторное представление ста-
тьи — векторное представление соответствующей вершины).
Для определения векторного представления текста статьи используется описанный в
разделе 2.2.3 метод Paragrah2vec.
По словам авторов статьи, их метод комбинирует тексты статей с отношениями цити-
рования двумя способами.
Первый из них заключается в добавлении в граф цитирования потенциальных рёбер —
рёбер между вершинами,
соответствующие статьи которых имеют близкие векторы тек-
стов. Для каждой статьи находятся N статей, имеющих наиболее близкие векторные пред-
ставления текстов с векторным представлению текста рассматриваемой статьи.
Между
рассматриваемой статьей и каждой из этих N статей добавляется ребро. Таким образом, в
исходный граф цитирования добавляется |E|∗N рёбер, где |E| — количество вершин в гра-
фе,
N — гиперпараметр метода,
обычно принимающий небольшое значение (значение по
умолчанию равно 3,
в экспериментальных исследованиях авторы использовали значения
от 0 до 19, причем наилучшие результаты были получены при N ∈ [2, 8]).
На второй способ комбинирования текстов статей с графом цитирования,
по словам
авторов, их вдохновила работа [47] в области компьютерного зрения. В этой работе иници-
ализация весов алгоритма машинного обучения происходит с помощью другого алгоритма,
обученного на большом наборе данных. Это помогает значительно сократить время на обу-
чение и повысить эффективность работы.
Аналогичным образом авторы Paper2vec предлагают использовать векторное представ-
22
ление текстов статей при построении векторного представления вершин графа: инициали-
зировать векторное представление вершины не случайным образом, а использовать вектор-
ное представление соответствующего текста.
Это,
во-первых,
является неплохим началь-
ным приближением, что способно улучшить результаты работы метода; а во-вторых, спо-
собно сократить время работы метода (количество итерация word2vec внутри DeepWalk),
так как метод может быстрее сходиться.
Таким образом,
последний этап метода заключается в нахождении векторного пред-
ставления вершин графа,
полученного на втором этапе,
с помощью алгоритма DeepWalk
с инициализацией векторов вершин векторами текстов соответствующих статей.
Paper2vec способен строить векторное представление статьи,
если про один из двух
используемых источников информации ничего не известно (отсутствует текст статьи или
отношения цитирования).
Но Paper2vec не способен учитывать важность источников информации.
2.5
Выводы
В ходе обзора существующих решений были исследованы методы построения вектор-
ного представления научных статей.
Были изучены работы,
описывающие эксперимен-
тальное сравнение различных методов построения векторного представления для решения
разных задач: классификации и кластеризации.
На основе этих исследований было выявлено (таблицы 3 и 4),
что лучшим существу-
ющим методом построения векторного представления научных статей является метод
Paper2vec. Но, учитывая результаты экспериментальных исследований, можно предполо-
жить, что существующие методы можно улучшить.
Помимо этого, были исследованы следующие аспекты рассматриваемых методов:
• используемые источники информации;
• способен ли метод строить векторное представление статьи,
у которой отсутствует
информация из некоторых используемых источников информации (устойчивость к
отсутствию некоторой информации);
• учитывается ли важность различных источников информации.
В таблице 5 содержится сгруппированная информация.
На основе этой таблицы можно сделать вывод,
что не существует метода,
удовлетво-
ряющего одновременно всем трем желаемым свойствам.
Существует предположение,
что
разработав метод, удовлетворяющий всем трем вышеперечисленным свойствам, можно по-
высить эффективность построения векторного представления научных статей.
Таким образом,
необходимо разработать метод построения векторного представления
23
Таблица 5: Сравнительная характеристика методов построения векторного представления
научных статей.
Источники информа-
ции
Устойчивость
к
от-
сутствию некоторой
информации
Учет важности раз-
ных источников ин-
формации
TF-IDF
Текст
Нет
Нет
BM25
(Робертсон, 1995)
Текст
Нет
Нет
Paragraph2vec
(Ли, 2014)
Текст
Нет
Нет
Deepwalk
(Пероцци, 2014)
Отношение
между
статьями
Нет
Нет
Node2vec
(Гровер, 2016)
Отношение
между
статьями
Нет
Нет
Конкатенация
Произвольные
ис-
точники
Нет
Да
Paper2vec
(Гангули, 2017)
Текст
и
отношение
цитирования
Да
Нет
научных статей,
удовлетворяющий трем вышеперечисленным свойствам,
и эксперимен-
тально сравнить его с существующими методами в задаче кластеризации научных статей.
24
3
Исследование и построение решения задачи
Как было отмечено выше, решение задачи выявления тематик исследований во множе-
стве научных статей может быть получено путём последовательного решения трёх подза-
дач: предварительной обработки данных, построения вещественного вектора статьи, кла-
стеризация полученных векторов.
Методы предварительной обработки данных и кластеризации вещественных векторов
хорошо изучены на данный момент, и при решении задачи выявления тематик исследова-
ния во множестве научных статей могут применяться стандартные подходы для их реше-
ния.
Для определения же векторного представления научной статьи необходимо разработать
новый способ,
так как существующие методы не позволяют использовать все доступные
источники информации и не учитывают важность источников информации. В разделе 3.2
содержится описание предлагаемых улучшений существующего метода Paper2vec.
На ос-
нове этих улучшений был разработан метод Article2vec,
описание которого можно найти
в 3.2.5.
Также в этой главе содержится информация о проведенных экспериментальных иссле-
дования. Раздел 3.3 посвящен методологии экспериментальных исследований: в нем описа-
ны наборы данных, внутренние и внешние меры эффективности. В разделе 3.4 содержатся
результаты исследований.
3.1
Общая структура метода выявления тематик исследования
Для выявления тематик исследования во множестве научных статей используется стан-
дартная структура [5, 7, 8, 10, 14], состоящая из следующих этапов:
• предварительная обработка данных;
• построение векторного представления научной статьи;
• кластеризация векторов.
В качестве предварительной обработки данных используется стандартная обработка
текстов, написанных на естественном языке. Она применяется для текстов статей и состоит
из следующих этапов:
1.
удаление знаков препинания;
2.
перевод слов в нижний регистр;
3.
удаление стоп-слов;
4.
стемминг Snowball (Porter2)
8
.
8
http://snowball.tartarus.org/algorithms/english/stemmer.html
25
Для построения векторного представления научной статьи предлагается использовать
разработанный в ходе работы над магистерской диссертацией метод Article2vec, описание
которого можно найти в разделе 3.2.5.
Кластеризация векторов может происходить одним из стандартных алгоритмов кла-
стеризации.
Для проведения экспериментальных исследований использовался алгоритм
k-means.
Для инициализации центров кластеров k-means
использовался алгоритм k-
means++ [48]. Запуск k-means производился 10 раз, из 10 полученных кластеризаций вы-
биралась наилучшая (минимизирующая суммарное расстояние всех кластеризуемых объ-
ектов до ближайших центров кластеров).
Это делалось для получения более устойчивых
результатов.
3.2
Построение векторного представления статьи
В соответствии с обзором существующих решений,
большинство методов построения
векторного представления статьи основываются только на одном источнике информации:
тексте (Paragraph2vec, TF-IDF, BM25) или отношении цитирования (DeepWalk, Node2vec).
Альтернативой этих подходов является метод Paper2vec,
который основывается как на
тексте статьи, так и на её отношениях цитирования с другими статьями.
Недостаток Paper2vec заключается в том, что он строит векторное представление ста-
тьи только на основе этих двух источников.
Также Paper2vec не учитывает важность
источников информации.
Данный раздел посвящен обобщению Paper2vec,
позволяюще-
му использовать больше источников информации и задавать их важность.
Далее описы-
ваются предлагаемые улучшения.
Раздел 3.2.5 содержит описание предлагаемого метода
Artcle2vec — обобщения Paper2vec.
3.2.1
Добавление рёбер совместного цитирования статей
В качестве представления отношений цитирования можно использовать не только граф
цитирования, но и граф совместного цитирования статей [19, 20]. Под графом совместного
цитирования статей [49] понимается неориентированный граф, вершины которого соответ-
ствуют статьям, а ребра — отношению совместного цитирования соответствующих статей.
Говорят, что статьи v и u связаны отношением совместного цитирования, если существует
статья w, цитирующая статьи v и u.
В некоторых случаях отношение совместного цитирования может лучше характери-
зовать близость научных статей, чем отношение цитирования. К примеру, использование
отношения совместного цитирования позволяет выявить семантическую близость двух ста-
тей,
опубликованных примерно в одно и то же время.
Авторы каждой из этих статей не
26
могли сослаться на другую статью (так как при написании своей статьи другая статья еще
не была опубликована), но более поздние публикации могут цитировать обе эти работы в
случае, если они посвящены одной теме.
Также между двумя близкими статьями может не существовать отношения цитирова-
ния из-за того,
что авторы более поздней статьи не знали о существовании более ранней
статьи. В этом случае отношение совместного цитирования может восстановить информа-
цию о близости статей,
если существует статья,
цитирующая обе эти статьи (что весьма
вероятно в случае, если эти две статьи действительно посвящены схожим темам).
Еще одним отличием графа совместного цитирования от графа цитирования заключа-
ется в возможности взвешивания рёбер.
Для вычисления веса ребра графа совместного
цитирования могут быть использованы различные формулы; в соответствии с ними чаще
всего значение веса ребра тем больше, чем больше статей процитировали статьи, соответ-
ствующие инцидентным данному ребру вершинам.
Веса ребер совместного цитирования могут быть использованы как минимум в двух слу-
чаях. Во-первых, вес ребра можно непосредственно использовать в методе построения век-
торного представления вершины графа (если используемый метод учитывает вес рёбер).
Во-вторых, вес рёбер можно учитывать при их фильтрации: удалении рёбер с маленьким
весом.
Удаление рёбер с маленьким весом,
во-первых,
может улучшить производитель-
ность метода (за счет уменьшения количества обрабатываемой информации). Во-вторых,
удаление ребра способно улучшить эффективность метода. Это может следовать из пред-
положения,
что статьи,
которые были совместно процитированы небольшое количество
раз,
на самом деле не являются семантически близкими (например,
если их совместно
процитировала только одна статья, то, вероятно, на них ссылались в различных разделах
этой статьи, и такое совместное цитирование можно считать случайным).
3.2.2
Добавление рёбер, соответствующих авторам статей
Авторы научных статей — ещё один возможный источник информации, на основе кото-
рого можно сделать вывод о семантической близости двух статей. Это может быть основано
на предположении,
согласно которому один и тот же автор пишет статьи,
посвященные
небольшому количеству тем.
Существуют даже целые подходы,
выявляющие тематики
исследования во множестве статей только на основе их авторов [50, 51].
Один из способов обработки информации об авторах статей заключается в построении
графа специального вида, в котором вершины соответствуют статьям, а рёбра — отноше-
нию близости авторов соответствующих статей.
В одних подходах авторы статей u и v считаются близкими, если их написали одни и те
27
же авторы, в других — если у этих статей совпадает хотя бы один автор. Также существует
подход основанный на графе совместного цитирования авторов [50].
В экспериментальных исследованиях использовался следующий подход:
ребро между
вершинами, соответствующими статьям u и v, существует только в том случае, если у этих
статей есть хотя бы один общий автор.
3.2.3
Изменение алгоритма построения векторного представления вершины
графа
Одним из
возможных улучшений Paper2vec
является замена
алгоритма
построе-
ния векторного представления вершины графа:
использование Node2vec (2.3.2)
вместо
DeepWalk (2.3.1).
Эти методы были описаны в обзоре существующих решений,
ниже пе-
речислены основные причины, почему использование Node2vec является более предпочти-
тельным.
Во-первых,
Node2vec
является
обобщением
DeepWalk
(Node2vec
эквивалентен
DeepWalk,
если его гиперпараметры имеют следующие значения:
p = 1 и q = 1).
Это
означает, что любое решение, полученное с помощью DeepWalk, можно получить с помо-
щью Node2vec.
Во-вторых, Node2vec позволяет контролировать структуру случайных блужданий, бла-
годаря чему можно настроить случайные блуждания таким образом,
чтобы их вершины
находились не очень далеко от стартовой вершины.
В-третьих,
Node2vec,
в отличие от DeepWalk,
поддерживает работу со взвешенными
рёбрами. В следующем разделе описана мотивация использования взвешенных рёбер.
3.2.4
Взвешивание ребер
В Paper2vec строится векторное представление вершин графа,
имеющего рёбра двух
типов: основанных на отношении цитирования и на близости текстов статей. Все рёбра в
этом графе имеют одинаковый вес (равный 1), таким образом, в Paper2vec не отличаются
рёбра, полученные из разных источников информации.
Существует гипотеза,
что ребра разных типов (основанных на близости текстов,
от-
ношении цитирования,
отношении совместного цитирования и так далее) могут быть ис-
пользованы с разной степенью полезности.
К примеру,
если для каждой статьи имеется
её полный текст,
то полученное на основе этого текста представление,
скорее всего,
луч-
ше представления,
которое может быть получено на основе аннотации статьи (как было
показано в работе [14]).
Или,
к примеру,
если известно,
что информация об отношени-
ях цитирования зашумлена (отсутствуют ребра,
соответствующие настоящим цитатам,
и
28
присутствуют ребра,
которые на самом деле не соответствуют цитате),
то использование
других типов ребер может быть более предпочтительным.
Взвешивание рёбер разного типа может решить эту проблему.
Поэтому предлагает-
ся для рёбер,
полученных из разных источников информации,
задавать веса в качестве
гиперпараметров алгоритма. Таким образом можно контролировать важность разных ис-
точников информациии.
3.2.5
Article2vec
Ниже представлено описание метода Article2vec — обобщения Paper2vec,
способного
учитывать информацию из различных источников для построения векторного представ-
ления научных статей. Также Article2vec способен учитывать важность разных источников
информации.
На вход методу подается множество научных статей (с метаданными) и информация о
цитировании.
Далее строится граф, вершины которого соответствуют научным статьям, а рёбра — от-
ношению близости между соответствующими статьями. Близость между статьями может
быть получена из различных источников: текстов статей, их авторов, отношений цитиро-
вания,
названий статей,
времени и месте публикации и так далее.
Ребра,
полученные на
основе одного источника, имеют одинаковые веса. Эти веса задаются в качестве гиперпа-
раметров алгоритма.
Далее для каждой вершины графа строится векторное представление с помощью одно-
го из существующих алгоритмов. Предлагается использовать метод Node2vec. В качестве
инициализации векторов вершин графа предлагается использовать вектора текстов статей,
соответствующих вершинам (как это делается в Paper2vec).
Научная статья будет иметь векторное представление равное векторному представле-
нию соответствующей вершины графа.
В ходе экспериментальных исследований предлагается добавить в граф следующие рёб-
ра:
• рёбра цитирования;
• рёбра совместного цитирования;
• рёбра, соответствующие статьям со схожим текстом.
Рёбра последнего типа получают так же, как и в методе Paper2vec: для каждой статьи
строится векторное представление её текста;
для каждой статьи находятся N (гиперпа-
раметр метода) статей,
имеющих наиболее схожие векторы текстов (под схожестью по-
нимается евклидово расстояние);
между вершиной,
соответствующей заданной статье,
и
29
вершинами, соответствующими этим N статьям, проводятся N рёбер.
Эти три типа рёбер не являются строго заданными, при возможности стоит добавлять
рёбра, полученные на основе других источников информации.
3.3
Методология экспериментальных исследований
Для оценки эффективности методов были проведены экспериментальные исследова-
ния на наборах данных научных статей (их описание можно найти в 3.3.1). Для получения
численной оценки эффективности использовались внешние меры эффективности, описан-
ные в 3.3.2.
Подбор значений гиперпараметров происходил с помощью внутренних мер
эффективности, описанных в 3.3.3.
3.3.1
Наборы данных
Экспериментальное исследование проводилось на двух наборах данных научных статей:
TREC GEN 2007 (TG2007) [33] и Cora Research Paper Classification (Cora)
9
.
Набор данных TREC GEN 2007 был составлен для проведения конкурса по извлечению
сущностей TREC 2007 Genomics Track
10
. Организаторами были отобраны 160 000 научных
публикаций, посвященных геномике, из 49 журналов. Для этих целей использовался кор-
пус научных статей Highwire Press
11
, из которых было выделено несколько тысяч статей.
Эти статьи были предоставлены экспертам в предметной области геномика для размет-
ки. Процесс разметки состоял в поиске ответа на фиксированные организаторами вопросы
(всего 36 вопросов) в текстах статей.
Типичный вопрос имел вид:
«Рассказывается ли в
статье о ...?»В процессе экспериментальных исследований в качестве истинной разметки
(gold labels,
ground truth) использовались ответы экспертов.
Предполагалось,
что статья
относится к одному из 36 классов,
если хотя бы один эксперт утвердительно ответил на
соответствующий вопрос на основе текста статьи.
Разные статьи размечало разное коли-
чество экспертов (чаще всего не очень большое:
1-2),
некоторые эксперты утвердительно
отвечали на несколько вопросов для одной статьи.
Для проведения экспериментальных
исследований были отобрали только те статьи, для которых утвердительные ответы были
получены только на один вопрос и именно этот класс (номер вопроса) считался в качестве
истинного.
Итоговый набор состоит из 2325 статей,
для каждой статьи известен ее пол-
ный текст,
название,
год публикации,
фамилии и инициалы авторов и некоторые другие
9
https://people.cs.umass.edu/∼mccallum/data.html
10
http://trec.nist.gov/data/t2007_genomics.html
11
http://home.highwire.org/
30
метаданные. Также для каждой статьи известны названия статей, которые она цитирует.
С помощью этой информации был построен граф цитирования статей.
Набор данных Cora состоит из 24504 научных статей, посвященных компьютерным нау-
кам (Computer science). Каждой научной статье сопоставлена одна тематика исследования,
которой посвящена работа.
Всего в этом наборе данных существует 10 тематик исследо-
вания.
Для каждой статьи известна следующая информация:
текст аннотации,
название,
цитируемые статьи и некоторые другие метаданные.
В таблице 6 содержится информация о наборах данных.
Таблица 6: Характеристики используемых наборов данных.
TrecGen2007
Cora
Предметная область
Геномика
Компьютерные науки
Количество
2325
24504
Текстовые данные
Полный текст статьи
Аннотация
Граф цитирования
В неявном виде (необходи-
мо сопоставлять названия
статей)
В явном виде
Истинная
разметка
(классы)
Ответы экспертов на во-
просы
Тематики исследования
Количество классов
36
10
Авторы
Фамилия и инициалы ав-
торов
Отсутствуют
для
боль-
шинства статей
Другие метаданные
Название,
год
публика-
ции, журнал
Название,
для некоторых
статей
известны
другие
метаданные
3.3.2
Внешние меры эффективности
Для определения наилучшего метода, решающего поставленную задачу, необходимо по-
лучить численное значение эффективности работы исследуемых методов. Для этих целей
в задаче кластеризации применяются функции (внешние меры эффективности),
прини-
мающие на вход разбиение объектов на кластеры,
полученное оцениваемым методом,
и
истинное разбиение объектов на классы.
В обзоре [52]
показано,
что не существует од-
ной общепринятой меры эффективности и для разных задач можно использовать раз-
31
ные меры.
В следствие чего было принято исследование вычислять значения несколь-
ких мер эффективности,
что также позволит сравнивать результаты других исследова-
ний с результатами исследований, приведенных в данной работе. В ходе эксперименталь-
ных исследований были вычислены значения следующих мер эффективности:
Adjusted
Mutual
Information(AMI)
[34],
Normalized Mutual
Information(NMI)
[53],
Adjusted Rand
Index (ARI) [54], V-measure [55].
Использование нескольких мер эффективности затрудняет сравнение результатов рабо-
ты разных методов. Основной мерой эффективности была выбрана AMI. Это было сделано
по двум причинам.
Во-первых, в мерах ARI и AMI вводится поправка на случайность (adjusted for chance),
в отличие от NMI и V-measure. Меры, не использующие поправку на случайность, склонны
к получению завышенных результатов в случае, когда количество классов велико. Эту за-
висимость можно наблюдать на рисунке 4. Здесь изображен график зависимости значений
четырех мер эффективности (AMI, MI(Mutual Information), ARI, V-measure) от количества
кластеров. Сравнивались два случайных разбиения 100 объектов на кластеры. Можно ви-
деть,
что меры MI (ненормализованная мера NMI) и V-measure имеют высокие значения
несмотря на то,
что сравниваемые разбиения случайны.
Значения же AMI и ARI близки
к нулю, что соответствует ожидаемому поведению.
Вторая причина выбора AMI является следствием работы Романо и др. [56], в которой
показано,
что в случае кластеров разных размеров (что соответствует тематикам иссле-
дований научных статей) предпочтительнее использовать AMI.
ARI лучше применять в
случае кластеров одинаковых размеров.
3.3.3
Внутренние меры эффективности
В отличие от внешних мер эффективности, внутренние меры вычисляются только на ос-
нове результатов работы алгоритмов кластеризации, не используя информацию об истин-
ном разбиении объектов на классы. Эти меры основаны на оценке внутренней структуры
полученных кластеров. Они могут быть полезны в случае отсутствия истинного разбиения,
с чем приходится часто сталкиваться при решении практических задач.
Один из возможных вариантов их использования заключается в подборе значений ги-
перпараметров методов. Эта стратегия заключается в проведении нескольких кластериза-
ций (используя различные значения гиперпараметров) и выборе в качестве финальной ту
кластеризацию, которая максимизирует внутреннюю меру эффективности.
В ходе
исследования
применялись
следующие
меры эффективности:
Silhouette
12
http://scikit-learn.org/stable/auto_examples/cluster/plot_adjusted_for_chance_measures.html
32
Рис. 4: Влияние поправки на случайность на значения мер эффективности. Для каждой из
4 мер эффективности (AMI,
MI,
ARI и V-measure) приводится значение при сравнении 2
случайных разбиений объектов на N кластеров. Ось X соответствует количеству кластеров,
ось Y — значению меры эффективности. Количество объектов равно 100. Меры эффектив-
ности,
не использующие поправку на случайность (MI и V-measure),
имеют завешенные
значения при увеличении количества кластеров. Меры AMI и ARI, использующие поправ-
ку на случайность,
имеют значения,
близкие к нулю,
при любом количестве кластеров,
что согласуется с ожидаемым поведением. Рисунок взят с сайта scikit-learn.org
12
.
Coefficient (Silhouette,
SC) [57];
Calinski-Harabaz Index (CHI) [58].
Выбор этих мер был
основан как на их популярности (применялись в других работах),
так и на том,
что они
хорошо оптимизируют гиперпараметры алгоритма кластеризации k-means, благодаря то-
му, что основаны на схожих предположениях [59].
3.4
Результаты экспериментальных исследований
В следующих разделах описываются результаты экспериментальных исследований. Со-
кращенные названия исследуемых методов построения векторного представления статей
перечислены в таблице 7.
Исследуемые методы можно условно разделить на несколько групп.
Часть методов
(TF-IDF,
BM25,
Paragraph2vec)
для построения векторного представления статьи ис-
33
Таблица 7: Исследуемые методы построения векторного представления статьи.
Метод
Описание
TF-IDF
Векторное представление текста статьи на основе TF-IDF
BM25
Векторное представление текста статьи на основе BM25
Paragraph2vec
Векторное представление текста статьи на основе Paragraph2vec
DeepWalk(C)
Векторное
представление
вершины графа
цитирования на
основе
DeepWalk
DeepWalk(Coc)
Векторное представление вершины графа совместного цитирования на
основе DeepWalk
Node2vec(C)
Векторное
представление
вершины графа
цитирования на
основе
Node2vec
Node2vec(Coc)
Векторное представление вершины графа совместного цитирования на
основе Node2vec
Concatenation(TC)
Конкатенация векторного представления текста (Paragraph2vec) и вер-
шины графа цитирования (Node2vec)
Concatenation(TCoc)
Конкатенация векторного представления текста (Paragraph2vec) и вер-
шины графа совместного цитирования (Node2vec)
Concatenation(TCCoc)
Конкатенация векторного представления текста (Paragraph2vec), вер-
шины графа цитирования (Node2vec) и вершины графа совместного
цитирования (Node2vec)
Paper2vec
Оригинальный Paper2vec
Article2vec(Node2vec)
Предлагаемое улучшение Paper2vec (использование Node2vec вместо
DeepWalk)
Article2vec(WE)
Предлагаемое улучшение Paper2vec (использование веса для рёбер
разного типа)
Article2vec(Coc)
Предлагаемое улучшение Paper2vec (добавление рёбер совместного ци-
тирования)
Article2vec(Auth)
Предлагаемое улучшение Paper2vec (добавлением рёбер, соответству-
ющих авторам)
Article2vec
Предлагаемый
метод
Article2vec,
объединяющий
Article2vec(Node2vec), Article2vec(WE), Article2vec(Coc)
пользуют только её текст,
другие методы (DeepWalk(C),
DeepWalk(Coc),
Node2vec(C),
Node2vec(Coc)) основываются только на структуре графа цитирования либо графа сов-
местного цитирования статей и строят векторное
представление
для каждой верши-
ны графа.
Остальные
методы учитывают данные
из
различных источников.
Методы
34
Concatenation(TC),
Concatenation(TCoc),
Concatenation(TCCoc)
конкатенируют вектор-
ные представления,
полученные из различных источников.
Paper2vec объединяет инфор-
мацию из различных источников с помощью построения графа с ребрами,
основанными
на различных источниках информации.
Методы Article2vec(Node2vec),
Article2vec(WE),
Article2vec(Coc),
Article2vec(Auth) являются предлагаемыми улучшениями исходного ме-
тода Paper2vec.
Метод Article2vec является предлагаемым методом,
включающим в себя
улучшения,
предложенные в Article2vec(Node2vec),
Article2vec(WE),
Article2vec(Coc).
В
Article2vec не был включён Article2vec(Auth),
так как в процессе экспериментальных ис-
следований было выяснено, что это улучшение требует много вычислительных ресурсов и
оптимизация этого метода является отдельной задачей.
Так как исследуемые методы зависят от значений гиперпараметров, в эксперименталь-
ных исследованиях использовался поиск по сетке возможных значений гиперпараметров
(Grid search).
Для каждого важного гиперпараметра каждого метода определялись его
некоторые возможные значения,
далее для всех возможных комбинаций определенных
значений гиперпараметров применялся исследуемый метод.
Для каждого такого запуска
метода (эксперимента) были подсчитаны значения мер эффективности (как внутренних,
так и внешних).
3.4.1
Максимальная эффективность
Таблица 8 содержит наибольшие значения AMI, полученные в ходе экспериментального
исследования. Эту величину можно рассматривать как потенциально наилучшее значение
AMI, которое можно получить при удачном выборе значений гиперпараметров.
На основе полученных результатов можно сделать следующие выводы. Значение AMI
сильно отличается для разных наборов данных. Максимальное значение AMI, полученное
на Cora, равно 0.3098; на TrecGen2007 — 0.553.
Методы, использующие только текст статьи, имеют значение AMI выше, чем методы,
основанные на графовой информации,
на наборе данных TrecGen2007.
На наборе дан-
ных Cora наблюдается противоположная ситуация.
Это может быть объяснено тем,
что
в TrecGen2007 для каждой статьи известен её полный текст,
а в Cora — только аннота-
ция.
Из-за малого размера текстов методы TF-IDF,
BM25 и Paragraph2vec имеют низкое
значение AMI на Cora.
Сравнивая методы, основанные на различных видах графов, можно отметить, что ис-
пользование векторного представления, полученного на основе графа цитирования, явля-
ется более предпочтительным, чем полученное на основе графа совместного цитирования.
Использование алгоритма Node2vec увеличивает AMI по сравнению с DeepWalk.
35
Таблица 8: Максимальное значение AMI, полученное при использовании различных мето-
дов построения векторного представления статьей.
Cora
TrecGen2007
TF-IDF
0.206
0.5008
BM25
0.2217
0.5139
Paragraph2vec
0.2183
0.4956
DeepWalk(C)
0.241
0.3564
DeepWalk(Coc)
0.1006
0.2156
Node2vec(C)
0.2594
0.3817
Node2vec(Coc)
0.1924
0.2247
Concatenation(TC)
0.2642
0.5056
Concatenation(TCoc)
0.2141
0.3939
Concatenation(TCCoc)
0.2129
0.3984
Paper2vec
0.2897
0.5294
Article2vec(Node2vec)
0.2969
0.5323
Article2vec(WE)
0.3098
0.5471
Article2vec(Coc)
0.2902
0.5338
Article2vec(Auth)
-
0.4718
Article2vec
0.3015
0.553
При конкатенации векторов лучший результат получается при использовании векто-
ра текста и вектора вершины графа цитирования.
Добавление вектора вершины графа
совместного цитирования обычно уменьшает значение AMI.
Алгоритм Paper2vec является наиболее предпочтительным (по сравнению с существу-
ющими методами).
Article2vec(Auth) — улучшение Paper2vec,
состоящее в добавлении ребра между вер-
шинами, соответствующими статьям, имеющим общего автора. В ходе экспериментальных
исследований было выявлено, что это улучшение требует больших вычислительных ресур-
сов,
в следствие чего было проведено небольшое количество экспериментов для данного
метода.
Это является одной из причин небольшого значения AMI.
Для набора данных
Cora не были проведены экспериментальные исследования метода Article2vec(Auth),
так
как этот набор не содержит информацию об авторах статьи.
Использование других улучшений Paper2vec (Article2vec(Node2vec),
Article2vec(WE),
Article2vec(Coc)) увеличивает значение по сравнению с оригинальным методом Paper2vec.
36
Среди трех исследуемых улучшений Paper2vec, добавление веса ребрам разных типов (ме-
тод Article2vec(WE)) дает наибольшие улучшение меры AMI.
Подход Article2vec,
предлагаемый в
этой работе,
объединяет
3
вышеперечислен-
ных улучшения (Article2vec(Node2vec), Article2vec(WE), Article2vec(Coc)). Можно видеть,
что на исследуемых наборах данных он превосходит исходный метод Paper2vec.
На
TrecGen2007 он имеет наибольшее значение AMI среди всех исследуемых методов, на Cora
уступает только модификации Article2vec(WE).
Возможная причина заключается в том,
что не были найдены оптимальные значения гиперпаарметров метода Article2vec.
Рис.
5:
Матрица ошибок на наборе данных Cora при использовании метода построения
векторного представления статьи Article2vec(WE). AMI=0.3098.
Для визуализации результатов кластеризации можно использовать матрицу ошибок
(confusion matrix). Благодаря этой матрицы можно понять, что подразумевается под неко-
торым значением меры эффективности.
Матрица ошибок — матрица,
каждая строка ко-
торой соответствует реальному классу, а столбец — полученному кластеру. Квадрат, нахо-
дящийся на пересечении i-й строки и j-го столбца, имеет тем более насыщенный цвет, чем
больше объектов, принадлежащих i-му классу, были отнесены в j-й кластер. Нормализация
происходит для каждой строки (каждого класса):
сумма каждой строки матрицы равна
1. Таким образом, эту матрицу можно рассматривать в качестве распределения объектов
класса по кластерам. В случае идеальной кластеризации (для каждого класса существует
37
кластер, содержащий все объекты этого класса и только их) матрица будет иметь следую-
щий вид: для каждой строки существует только один столбец, на пересечении с которым
квадрат является закрашенным; для каждого столбца существует единственная строка, на
пересечении с которой находится закрашенный квадрат.
На рисунке 5 изображена матрица ошибок для метода, показавшего лучший результат
на наборе данных Cora (Article2vec(WE);
AMI=0.3098).
Метод отнес объекты 10 классов
на 7 кластеров. Из-за этого объекты некоторых классов были объединены в один кластер.
К примеру, в кластер 0 было отнесено большое количество объектов класса 0 (статьи это-
го кластера принадлежат тематике исследования «Hardware_and_Architecture») и класса
8 («Operating_Systems»).
В 2 кластер входят много объектов класса 2 («Networking»)
и класса 5 («Encryption_and_Compression»).
Кластер 3 состоит из большого количества
объектов класса 3 («Information_Retrieval») и класса 7 («Databases»).
Рис. 6: Матрица ошибок на наборе данных TrecGen2007 при использовании метода постро-
ения векторного представления статьи Article2vec. AMI=0.553.
На рисунке 6 изображена матрица ошибок для набора данных TrecGen2007. Эта матри-
ца визуализирует результаты работы метода выявления тематик исследования во множе-
стве научных статей, использующего Article2vec в качестве метода построения векторного
38
представления научной статьи,
с AMI=0.553.
36 классов были распределены на 20 кла-
стеров. Возможная причина заключается в том, что некоторые вопросы, соответствующие
классам, имеют близкую семантику. В целом можно наблюдать, что в большинстве случаев
объекты каждого класса относятся в один кластер, что совпадает с желаемым поведением
алгоритма кластеризации.
3.4.2
Эффективность полученная с помощью оптимизации внутренних мер
эффективности
При решении задачи выявления тематик исследования во множестве научных статей
возникают трудности с подбором значений гиперпараметров методов.
Так как чаще все-
го настоящее распределение статей по тематикам исследования неизвестно,
необходимо
использовать подходы, позволяющие подбирать значения гиперпараметров.
Таблица 9: Значения AMI, полученные с помощью оптимизации внутренней меры эффек-
тивности Calinski-Harabaz Index.
Cora
TrecGen2007
TF-IDF
0.0053
0.1892
BM25
0.0807
0.3944
Paragraph2vec
0.168
0.4617
DeepWalk(C)
0.0108
0.2851
DeepWalk(Coc)
0.0012
-0.0001
Node2vec(C)
0.0165
0.3397
Node2vec(Coc)
0.1284
0.0188
Concatenation(TC)
0.235
0.4808
Concatenation(TCoc)
0.1233
0.3573
Concatenation(TCCoc)
0.1227
0.3481
Paper2vec
0.2398
0.5254
Article2vec(Node2vec)
0.2729
0.5189
Article2vec(WE)
0.2769
0.4709
Article2vec(Coc)
0.2533
0.5133
Article2vec(Auth)
-
0.4718
Article2vec
0.2733
0.5325
Одним из таких подходов является подбор значений гиперпараметров с помощью оп-
тимизации некоторой внутренней меры эффективности. Эта мера основывается не на на-
39
Таблица 10: Значения AMI, полученные с помощью оптимизации внутренней меры эффек-
тивности Silhouette Coefficient.
Cora
TrecGen2007
TF-IDF
0.0168
0.183
BM25
0.1156
0.4134
Paragraph2vec
0.2112
0.4608
DeepWalk(C)
0.0108
0.009
DeepWalk(Coc)
0.0019
-0.0001
Node2vec(C)
0.0498
0.3288
Node2vec(Coc)
0.1624
0.2089
Concatenation(TC)
0.2506
0.416
Concatenation(TCoc)
0.1413
0.2626
Concatenation(TCCoc)
0.1862
0.3743
Paper2vec
0.2166
0.4381
Article2vec(Node2vec)
0.2953
0.3935
Article2vec(WE)
0.2443
0.43
Article2vec(Coc)
0.2155
0.4583
Article2vec(Auth)
-
0.4372
Article2vec
0.2631
0.4612
стоящем распределении объектов по классам, а на внутренней структуре кластеров.
В таблице 9 содержатся значения AMI,
полученные при оптимизации внутренней ме-
ры Calinski-Harabaz Index (CHI);
в таблице 10 — при оптимизации Silhouette Coefficient
(Silhouette).
Можно видеть, что в случае оптимизации CHI, методы, имеющие максимальное значе-
ние AMI, не изменились. Стоит отметить, что у методов, основанных на одном источнике
информации (либо тексте,
либо вершине в графе),
значение AMI,
в целом,
уменьшилось
сильнее, чем у методов, использующих сразу несколько источников информации.
При оптимизации Silhouette метод Article2vec(Node2vec) имеет наибольшее значение
AMI на наборе данных Cora,
на TrecGen2007 — Article2vec.
Можно видеть,
что,
в сред-
нем, оптимизация CHI для Paper2vec, его улучшений и Article2vec предпочтительнее, чем
Silhouette.
Для оценки связи значений внутренних мер эффективности и значений AMI была вы-
числена ранговая корреляция Кендалла [60].
Была использована именно ранговая кор-
40
реляция, так как в данной задаче интересен именно относительный порядок методов для
исследуемых мер. В то же время была выбрана корреляция Кендалла, так как в работе [61]
было показано, что она предоставляет более надежную оценку, чем ранговая корреляция
Спирмена (в особенности для выборок небольшого размера).
Результаты можно найти в
приложении A данной работы.
Помимо этого в приложении можно найти максимальные
значения внутренних мер эффективности.
3.4.3
Сравнение внешних мер эффективности
В ходе экспериментальных исследований были вычислены значения не только AMI,
но и других внешних мер эффективности: NMI, ARI, V-measure. Помимо самих значений
внешних мер эффективности также была вычислена ранговая корреляция Кендалла меж-
ду их значениями и значениями меры эффективности AMI.
Результаты можно найти в
приложении B магистерской диссертации.
41
4
Описание практической части
В процессе работы над магистерской диссертацией были реализованы следующие ком-
поненты:
• метод построения векторного представления научной статьи (Article2vec);
• метод выявления тематик исследования во множестве научных статей (SciCluster);
• тестовая система.
4.1
Выбранный инструментарий
Программная реализация была написана на языке программирования Python (версия
2.7). Это выбор в первую очередь обоснован тем, что авторские реализации большинства
существующих методов реализованы на языке Python.
Это предоставляет возможность
использовать авторские реализации существующих методов во время проведения экспери-
ментальных исследований.
Предварительная обработка текстов,
написанных на естественном языке,
(токениза-
ция,
удаление стоп-слов и стемминг) производилась с помощью программного средства
NLTK (Natural Language Toolkit)
13
[62].
Для проведения кластеризации и вычисления значений мер эффективности использова-
лась библиотека машинного обучения Scikit-learn
14
[63]. Для исследования работы метода
TF-IDF была использована реализация Scikit-learn.
Также была использована библиотека gensim
15
[64], предоставляющая методы word2vec
и paragraph2vec.
Помимо этого использовались авторские реализации следующих методов: DeepWalk
16
,
Node2vec
17
и Paper2vec.
В ходе работы над магистерской диссертацией было написано около 2500 строк кода;
программная реализация включает в себя 48 классов (вместе со вспомогательными клас-
сами).
4.2
Article2vec
Реализация метода Article2vec представляет собой класс Article2vec. При создании эк-
земпляра класса необходимо указать название метода построения векторного представ-
13
http://www.nltk.org/
14
http://scikit-learn.org/
15
https://radimrehurek.com/gensim/
16
https://github.com/phanein/deepwalk
17
https://github.com/aditya-grover/node2vec
42
ления текстов (например, Paragraph2vec) и метода построения векторного представления
вершин графа (например, Node2vec). Помимо этого можно указать значения других пара-
метров,
таких как:
количество добавляемых ребер для каждой вершины,
основанных на
близости текстов статей; веса ребер разного типа; размер строящегося вектора; параметры
методов построения векторного представления текстов и вершин графа и так далее.
Так
как эти параметры имеют значения по-умолчанию,
передача значений этих параметров
является опциональной.
Класс Article2vec содержит метод fit_transform, принимающий на вход граф цитирова-
ния научных статей, их тексты и другие метаданные. Этот метод строит граф, вершины ко-
торого соответствуют научным статьям, а рёбра — отношению близости соответствующих
научных статей на основе какого-либо источника информации (текст, отношение цитирова-
ния и так далее). Ребро каждого типа имеет свой вес. Далее построенный граф передается
методу,
строящему векторное представление его вершин.
После чего метод fit_transform
возвращает векторное представление статей:
оно совпадает с векторным представлением
соответствующих вершин графа.
4.3
Метод выявления тематик исследования
Для выявления тематик исследования во множестве статей был реализован метод
SciCluster.
4.3.1
Общая схема работы
Общая схема работы метода выявления тематик исследования во множестве научных
статей изображена на рисунке 7.
4.3.2
Общая архитектура
Метод выявления тематик исследования во множестве научных статей представляет
собой класс SciCluster.
Для создания экземпляра класса SciCluster необходимо передать
названия трех классов,
каждый из которых реализует один из трех этапов (предвари-
тельная обработка данных,
построение векторного представления статьи,
кластеризация
векторов) и их параметры.
Для
запуска
выявления
тематик
исследования,
необходимо
вызвать
метод
fit_predict(documents_with_graph).
На
вход этому методу передается граф цитирова-
ния научных статей,
их тексты и другие
метаданные.
На выходе
метод возвращает
распределение статей по кластерам.
43
Рис. 7: Общая схема работы метода выявления тематик исследования во множестве науч-
ных статей.
В
этом
методе
по-очереди
происходит
вызов
методов
make_preprocessing,
make_embeddings, make_clustering.
Метод make_preprocessing принимает на вход множество научных статей и возвраща-
ет множество нормализованных научных статей (к которым была применена функция
предварительной обработки). Этот метод создает экземпляр класса Preprocessing, который
и выполняет предварительную обработку. Класс BasicPreprocessing является обобщением
класса Preprocessing. Он нормализует тексты статей.
Метод make_embeddings принимает на вход множество научных статей,
их метадан-
ные,
граф цитирования и возвращает векторное представление научных статей.
Метод
создает экземпляр класса DocumentEmbeddingsMethod,
который и отвечает за постро-
ение векторного представления статей.
Были реализованы следующие обобщения это-
го класса:
TextEmbeddingsMethod (определение векторного представления на основе тек-
ста), Article2vec, Paper2vec, Concatenation, CitationGraphEmbeddings (построение векторно-
го представления на основе графа цитирования),
CocitationGraphEmbeddings (построение
векторного представления на основе графа совместного цитирования).
Метод make_clustering принимает на вход векторное представление научных статей
и возвращает распределение статей по кластерам.
Для этих целей был создан класс
Clustering.
В экспериментальных исследованиях использовался алгоритм кластеризации
44
Рис. 8: Диаграмма классов метода выявления тематик исследования.
k-means из библиотеки Scikit-learn.
4.4
Тестовая система
Для проведения экспериментальных исследований была реализована тестовая система,
позволяющая вычислить численное значение эффективности работы исследуемых мето-
45
дов.
4.4.1
Общая схема работы
Общая схема работы тестовой системы изображена на рисунке 9.
Рис. 9: Общая схема работы тестовой системы.
4.4.2
Общая архитектура системы
На рисунке 10 представлена диаграмма классов,
показывающая общую архитектуру
системы.
Запуск
тестовой
системы
производится
путём
создания
экземпляра
класса
EvaluationSystem (с
передачей всех необходимых параметров
для проведения экспе-
риментов) и вызова метода run_experiments() этого экземпляра.
Данный класс создает
и инициализирует объекты вспомогательных классов (GitLogger,
ExperimentsResultSaver
и так далее).
При вызове
метода run_experiments(),
создается набор экспериментов
(объекты класса Experiment) и объект класса ExperimentRunner.
46
Рис. 10: Диаграмма классов тестовой системы.
Класс ExperimentRunner отвечает за проведение экспериментов.
Проведение экспери-
мента происходит при вызове метода run_experiment(experiment) этого класса.
Под про-
ведением эксперимента понимается запуск метода с заданными значениями параметров и
вычисление внутренних и внешних мер эффективности.
Класс Experiment
содержит информацию об эксперименте: используемые методы и их
параметры.
Класс GitLogger предназначен для сохранения информации о текущем состоянии репо-
зитория.
Класс ExperimentsResultSaver
предназначен для сохранения результатов эксперимен-
тов.
Результаты экспериментов хранятся в CSV файле,
каждая строка которого соответ-
ствует одному эксперименту.
Для каждого эксперимента сохраняется информация об ис-
пользуемых методах,
значений их параметров,
значений внутренних и внешних мер эф-
фективности, времени работы эксперимента и другая вспомогательная информация.
Класс SciCluster решает задачу выявления тематик исследования в наборе статей. При
вызове метода fit_predict(documents_with_graph), он возвращает разбиение входных статей
по кластерам (тематикам исследования).
Класс Serializer предназначен для сохранения промежуточных вычислений,
которые
47
могут быть переиспользованы в других экспериментах.
Это позволяет ускорить процесс
проведения экспериментальных исследований.
Класс QualityMeasurer вычисляет значения внутренних и внешних мер эффективности.
Для этих целей он использует Metrics из библиотеки Scikit-learn.
Класс DatasetLoader загружает наборы данных.
Для
хранения
наборов
данных
используется
класс
Dataset.
Он
содержит
класс
DocumentsWithGraph и список, состоящий из объектов класса Label.
Класс Label
содержит настоящую тематику исследования для заданной статьи.
Класс DocumentsWithGraph содержит набор данных, используемый методом SciCluster.
Он содержит следующие элементы:
список объектов класса Reference,
соответствующих
ребру в графе и список объектов класса Document, соответствующих статье.
Класс Document
предназначен для хранения информации о статье:
идентификацион-
ный номер, аннотацию, полный текст, предобработанный текст и метаданные. Для хране-
ния метаданных используется класс Metadata.
4.5
Производительность
Экспериментальные исследования происходили на компьютере со следующими харак-
теристиками: Intel Xeon E312xx (8 CPU), 2GHz, 64GB RAM.
Таблица 11 содержит среднее время работы метода выявления тематик исследования во
множестве научных статей в зависимости от используемого метода построения векторного
представления статьи и набора данных. В таблице приведены значения времени работы ме-
тодов с теми значениями гиперпараметров, при которых достигается наибольшее значение
меры эффективности AMI.
Необходимо учитывать, что это время является приблизительным, так как оно сильно
зависит от значений гиперпараметров.
48
Таблица 11: Время работы (в секундах) метода выявления тематик исследования при ис-
пользовании разных способов построения векторного представления статьи.
Cora
TrecGen2007
TF-IDF
389
50
BM25
688
313
Paragraph2vec
185
259
DeepWalk(C)
480
1410
DeepWalk(Coc)
180
1025
Node2vec(C)
1012
3820
Node2vec(Coc)
2138
4661
Concatenation(TC)
322
2202
Concatenation(TCoc)
680
2963
Concatenation(TCCoc)
822
3569
Paper2vec
560
1722
Article2vec(Node2vec)
709
3460
Article2vec(WE)
978
6928
Article2vec(Coc)
264
964
Article2vec(Auth)
-
19121
Article2vec
364
857
49
Заключение
В рамках магистерской диссертации был разработан метод Article2vec векторного пред-
ставления научных статей. Метод способен учитывать несколько источников информации;
строить векторное представление в случае,
если некоторая необходимая информация о
статье отсутствует;
учитывать важность различных источников информации.
Article2vec
основывается на методе Paper2vec,
предложенным С.
Гангули и В.
Пуди в 2017 году,
и
улучшает его.
Экспериментальное исследование проводилось на двух наборах данных научных статей:
Cora (компьютерные науки) и TrecGen2007 (геномика). В качестве внешней меры эффек-
тивности была использвана Adjusted Mutual Information, также были посчитаны значения
Normalized Mutual Information, Adjusted Rand Index и V-measure.
Для подбора оптимальных гиперпараметров были использованы внутренние меры эф-
фективности Silhouette Coefficient и Calinski-Harabaz Index.
В ходе работы были проведены экспериментальные исследования,
подтверждающие
увеличение эффективности работы Article2vec по сравнению с оригинальным методом
Paper2vec при решении задачи выявления тематик исследования во множестве научных
статей. Также в ходе экспериментальных исследований было произведено сравнение с дру-
гими существующими методами: основанными на текстах (TF-IDF, BM25, Paragraph2vec);
на отношениях цитирования и совместного цитирования (DeepWalk и Node2vec) и на кон-
катенации векторных представлений данных разных источников.
Было показано,
что использование Article2vec предпочтительнее,
чем существующие
исследуемые методы. На наборе данных Cora использование модификации Article2vec вме-
сто Paper2vec способно повысить эффективность выявления тематик исследования во мно-
жестве статей (AMI) с 0.2897 до 0.3098; на набое данных TrecGen2007 — с 0.5294 до 0.553.
Для автоматизации проведения экспериментальных исследований было разработано
программное средство. Оно состоит из метода построения векторного представления ста-
тей Article2vec, метода выявления тематик исследования во множестве научных статей и
тестовой системы.
Время работы метода выявления тематик исследования во множестве научных ста-
тей, использующего Article2vec с оптимальными значениями гиперпараметров, на наборе
данных Cora составляет 364 секунды, на наборе данных TrecGen2007 — 857 секунд.
В процессе работы над магистерской диссертацией был написана научная статья «Об-
зор и экспериментальное сравнение методов кластеризации текстов в приложении к науч-
ным статьям» [14].
50
Список литературы
[1]
Ganguly S.,
Pudi
V.
Paper2vec:
Combining Graph and Text Information for Scientific
Paper Representation // European Conference on Information Retrieval / Springer.
2017.
P. 383–395.
[2]
Marchionini G. Exploratory search: from finding to understanding // Communications of
the ACM.
2006.
Vol. 49, no. 4.
P. 41–46.
[3]
White R.
W.,
Roth R.
A.
Exploratory search:
Beyond the query-response paradigm //
Synthesis Lectures on Information Concepts, Retrieval, and Services.
2009.
Vol. 1, no. 1.
P. 1–98.
[4]
Янина А. О. , Воронцов К. В.
Мультимодальные тематические модели для разведоч-
ного поиска в коллективном блоге // Машинное обучение и анализ данных. 2016. Т. 2,
№ 2.
С. 173–186.
[5]
Aljaber B., Stokes N., Bailey J., Pei J. Document clustering of scientific texts using citation
contexts // Information Retrieval.
2010.
Vol. 13, no. 2.
P. 101–131.
[6]
Cao S.,
Lu W.,
Xu Q.
Grarep:
Learning graph representations
with global
structural
information // Proceedings of the 24th ACM International on Conference on Information
and Knowledge Management / ACM.
2015.
P. 891–900.
[7]
Huang A.
Similarity measures for text document clustering // Proceedings of
the sixth
new zealand computer science research student conference (NZCSRSC2008), Christchurch,
New Zealand.
2008.
P. 49–56.
[8]
Angelova R.,
Siersdorfer
S.
A neighborhood-based approach for
clustering of
linked
document
collections
//
Proceedings
of
the
15th ACM international
conference
on
Information and knowledge management / ACM.
2006.
P. 778–779.
[9]
Boyack K. W., Newman D., Duhon R. J. et al. Clustering more than two million biomedical
publications:
Comparing the accuracies of
nine text-based similarity approaches // PloS
one.
2011.
Vol. 6, no. 3.
P. e18029.
[10]
Janssens F.,
Leta J.,
Gl¨anzel
W.,
De Moor B.
Towards mapping library and information
science // Information processing & management.
2006.
Vol. 42, no. 6.
P. 1614–1642.
[11]
Xie P.,
Xing E.
P.
Integrating document clustering and topic modeling // arXiv preprint
arXiv:1309.6874.
2013.
51
[12]
Yau C.-K., Porter A., Newman N., Suominen A. Clustering scientific documents with topic
modeling // Scientometrics.
2014.
Vol. 100, no. 3.
P. 767–786.
[13]
Mei
Q.,
Cai
D.,
Zhang D.,
Zhai
C.
Topic
modeling with network regularization //
Proceedings of the 17th international conference on World Wide Web / ACM. 2008. P. 101–
110.
[14]
Пархоменко П. А. , Григорьев А. А. , Астраханцев Н. А.
Обзор и экспериментальное
сравнение методов кластеризации текстов в приложении к научным статьям // Труды
Института системного программирования РАН. 2017. (статья принята к публикации).
[15]
ˇ
Subelj L.,
van Eck N.
J.,
Waltman L.
Clustering scientific publications based on citation
relations: A systematic comparison of different methods // PloS one.
2016.
Vol. 11, no. 4.
P. e0154404.
[16]
Karypis G., Kumar V. A fast and high quality multilevel scheme for partitioning irregular
graphs // SIAM Journal on scientific Computing.
1998.
Vol. 20, no. 1.
P. 359–392.
[17]
Dhillon I.
S.,
Guan Y.,
Kulis B.
Weighted graph cuts without eigenvectors a multilevel
approach // IEEE transactions on pattern analysis and machine intelligence. 2007. Vol. 29,
no. 11.
[18]
Yang J.,
Leskovec J.
Overlapping community detection at scale:
a nonnegative matrix
factorization approach // Proceedings of the sixth ACM international conference on Web
search and data mining / ACM.
2013.
P. 587–596.
[19]
Boyack K. W., Klavans R. Co-citation analysis, bibliographic coupling, and direct citation:
Which citation approach represents the research front most accurately? // Journal of the
American Society for Information Science and Technology.
2010.
Vol. 61, no. 12.
P. 2389–
2404.
[20]
Chen C., Ibekwe-SanJuan F., Hou J. The structure and dynamics of cocitation clusters: A
multiple-perspective cocitation analysis // Journal of the American Society for Information
Science and Technology.
2010.
Vol. 61, no. 7.
P. 1386–1409.
[21]
Janssens
F.,
Gl¨
anzel
W.,
De
Moor
B.
A hybrid mapping of
information science
//
Scientometrics.
2008.
Vol. 75, no. 3.
P. 607–631.
[22]
Waltman L.,
van Eck N.
J.,
Noyons E.
C.
A unified approach to mapping and clustering
of bibliometric networks // Journal of Informetrics.
2010.
Vol. 4, no. 4.
P. 629–635.
52
[23]
Le Q. V., Mikolov T. Distributed Representations of Sentences and Documents. // ICML.
Vol. 14.
2014.
P. 1188–1196.
[24]
Perozzi
B.,
Al-Rfou R.,
Skiena S.
Deepwalk:
Online learning of
social
representations //
Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery
and data mining / ACM.
2014.
P. 701–710.
[25]
Grover A.,
Leskovec J.
node2vec:
Scalable feature learning for networks // Proceedings
of
the 22nd ACM SIGKDD International
Conference on Knowledge Discovery and Data
Mining / ACM.
2016.
P. 855–864.
[26]
Mikolov T., Chen K., Corrado G., Dean J. Efficient estimation of word representations in
vector space // arXiv preprint arXiv:1301.3781.
2013.
[27]
Mikolov T., Sutskever I., Chen K. et al. Distributed representations of words and phrases
and their compositionality // Advances in neural
information processing systems.
2013.
P. 3111–3119.
[28]
Robertson S. E., Walker S., Jones S. et al. Okapi at TREC-3 // Nist Special Publication
Sp.
1995.
Vol. 109.
P. 109.
[29]
MacQueen
J.
et
al.
Some
methods
for
classification
and
analysis
of
multivariate
observations // Proceedings of
the fifth Berkeley symposium on mathematical
statistics
and probability / Oakland, CA, USA.
Vol. 1.
1967.
P. 281–297.
[30]
Firth J. R. A synopsis of linguistic theory, 1930-1955.
1957.
[31]
Lang K. Newsweeder: Learning to filter netnews // Proceedings of the 12th international
conference on machine learning.
1995.
P. 331–339.
[32]
Krapivin M., Autaeu A., Marchese M. Large dataset for keyphrases extraction. 2009. URL:
http://eprints.biblio.unitn.it/1671/1/disi09055-krapivin-autayeu-marchese.
pdf (дата обращения: 2014-11-30).
[33]
Hersh W., Cohen A., Ruslen L., Roberts P. TREC 2007 Genomics Track Overview.
2007.
[34]
Vinh N. X., Epps J., Bailey J. Information theoretic measures for clusterings comparison:
is a correction for chance necessary? // Proceedings of
the 26th Annual
International
Conference on Machine Learning / ACM.
2009.
P. 1073–1080.
[35]
Lee D.
D.,
Seung H.
S.
Algorithms for non-negative matrix factorization // Advances in
neural information processing systems.
2001.
P. 556–562.
53
[36]
Blei
D.
M.,
Ng A.
Y.,
Jordan M.
I.
Latent dirichlet allocation // Journal
of
machine
Learning research.
2003.
Vol. 3, no. Jan.
P. 993–1022.
[37]
Xing C.,
Wang D.,
Zhang X.,
Liu C.
Document
classification with distributions
of
word vectors // Asia-Pacific Signal and Information Processing Association, 2014 Annual
Summit and Conference (APSIPA) / IEEE.
2014.
P. 1–5.
[38]
Slonim N.,
Tishby N.
Document
clustering using word clusters
via the
information
bottleneck method // Proceedings of the 23rd annual international ACM SIGIR conference
on Research and development in information retrieval / ACM.
2000.
P. 208–215.
[39]
Qimin C.,
Qiao G.,
Yongliang W.,
Xianghua W.
Text clustering using VSM with feature
clusters // Neural Computing and Applications.
2015.
Vol. 26, no. 4.
P. 995–1003.
[40]
Zafarani R., Liu H.
Social computing data repository at ASU.
2009.
[41]
Breitkreutz B.-J., Stark C., Reguly T. et al. The BioGRID interaction database // Nucleic
acids research.
2008.
Vol. 36, no. suppl 1.
P. D637–D640.
[42]
Mahoney
M.
Large
text
compression
benchmark
//
URL:
www.mattmahoney.net/dc/textdata.
2011.
[43]
Tang L.,
Liu H.
Leveraging social
media networks for classification // Data Mining and
Knowledge Discovery.
2011.
Vol. 23, no. 3.
P. 447–478.
[44]
Tang J.,
Qu M.,
Wang M.
et al.
Line:
Large-scale information network embedding //
Proceedings of
the 24th International
Conference on World Wide Web / ACM.
2015.
P. 1067–1077.
[45]
Spitzer F. Principles of random walk.
Springer Science & Business Media, 1964.
Vol. 34.
[46]
Yang C.,
Liu Z.,
Zhao D.
et
al.
Network Representation Learning with Rich Text
Information. // IJCAI.
2015.
P. 2111–2117.
[47]
Sharif
Razavian A.,
Azizpour H.,
Sullivan J.,
Carlsson S.
CNN features off-the-shelf:
an
astounding baseline for recognition // Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition Workshops.
2014.
P. 806–813.
[48]
Arthur D., Vassilvitskii S. k-means++: The advantages of careful seeding // Proceedings
of
the eighteenth annual
ACM-SIAM symposium on Discrete algorithms / Society for
Industrial and Applied Mathematics.
2007.
P. 1027–1035.
54
[49]
Small H. Co-citation in the scientific literature: A new measure of the relationship between
two documents // Journal of the American Society for information Science.
1973.
Vol. 24,
no. 4.
P. 265–269.
[50]
White
H.
D.,
Griffith B.
C.
Author
cocitation:
A literature
measure
of
intellectual
structure // Journal
of
the Association for Information Science and Technology.
1981.
Vol. 32, no. 3.
P. 163–171.
[51]
Zhao D.,
Strotmann A.
Evolution of
research activities
and intellectual
influences
in
information science
1996–2005:
Introducing author
bibliographic-coupling analysis
//
Journal
of the American Society for Information Science and Technology.
2008.
Vol.
59,
no. 13.
P. 2070–2086.
[52]
Amig´
o E., Gonzalo J., Artiles J., Verdejo F. A comparison of extrinsic clustering evaluation
metrics based on formal constraints // Information retrieval.
2009.
Vol. 12, no. 4.
P. 461–
486.
[53]
Strehl A., Ghosh J. Cluster ensembles—a knowledge reuse framework for combining multiple
partitions // Journal of machine learning research.
2002.
Vol. 3, no. Dec.
P. 583–617.
[54]
Hubert L., Arabie P. Comparing partitions // Journal of classification.
1985.
Vol. 2, no. 1.
P. 193–218.
[55]
Rosenberg A.,
Hirschberg J.
V-Measure:
A Conditional
Entropy-Based External
Cluster
Evaluation Measure. // EMNLP-CoNLL.
Vol. 7.
2007.
P. 410–420.
[56]
Romano S., Vinh N. X., Bailey J., Verspoor K. Adjusting for chance clustering comparison
measures // Journal of Machine Learning Research.
2016.
Vol. 17, no. 134.
P. 1–32.
[57]
Rousseeuw P. J. Silhouettes: a graphical aid to the interpretation and validation of cluster
analysis // Journal of computational and applied mathematics.
1987.
Vol. 20.
P. 53–65.
[58]
Cali´
nski
T.,
Harabasz J.
A dendrite method for cluster analysis // Communications in
Statistics-theory and Methods.
1974.
Vol. 3, no. 1.
P. 1–27.
[59]
Van Craenendonck T., Blockeel H. Using internal validity measures to compare clustering
algorithms // Benelearn 2015 Poster presentations (online).
2015.
P. 1–8.
[60]
Kendall
M.
G.
A new measure of rank correlation // Biometrika.
1938.
Vol.
30,
no.
1/2.
P. 81–93.
55
[61]
Field A. Discovering statistics using IBM SPSS statistics.
Sage, 2013.
[62]
Bird S.
NLTK:
the natural
language toolkit
// Proceedings
of
the COLING/ACL on
Interactive presentation sessions / Association for Computational Linguistics.
2006.
P. 69–
72.
[63]
Pedregosa F., Varoquaux G., Gramfort A. et al. Scikit-learn: Machine learning in Python //
Journal of Machine Learning Research.
2011.
Vol. 12, no. Oct.
P. 2825–2830.
[64]
Rehurek R.,
Sojka P.
Software framework for topic modelling with large corpora // In
Proceedings
of
the LREC 2010 Workshop on New Challenges
for
NLP Frameworks
/
Citeseer.
2010.
56
Приложение A. Внутренние меры эффективности
Таблица 12: Максимальное значение Calinski-Harabaz Index.
Cora
TrecGen2007
TF-IDF
381.0154
49.7169
BM25
264.1749
28.9352
Paragraph2vec
6627.9239
79.7363
DeepWalk(C)
91646.1915
62.0859
DeepWalk(Coc)
20244.2624
2.7e+27
Node2vec(C)
110129.7
52.9833
Node2vec(Coc)
27205.6
10273.5
Concatenation(TC)
2927.2715
48.6216
Concatenation(TCoc)
5355.5379
81.2592
Concatenation(TCCoc)
5416.3287
80.727
Paper2vec
7078.7304
59.9924
Article2vec(Node2vec)
8405.6104
57.0783
Article2vec(WE)
8739.7887
61.6265
Article2vec(Coc)
7176.084
60.9287
Article2vec(Auth)
-
37.737
Article2vec
8246.1809
56.8845
Таблица 13: Корреляция Calinski-Harabaz Index и AMI.
Cora
TrecGen2007
TF-IDF
0.4574
0.0458
BM25
0.6327
-0.0133
Paragraph2vec
-0.1665
-0.1691
DeepWalk(C)
0.1673
0.054
DeepWalk(Coc)
0.5278
0.5871
Node2vec(C)
0.1167
-0.1371
Node2vec(Coc)
0.6202
0.3437
Concatenation(TC)
-0.0185
-0.2641
Concatenation(TCoc)
0.6803
-0.1518
Concatenation(TCCoc)
0.6851
-0.1619
Paper2vec
0.1541
-0.5763
Article2vec(Node2vec)
-0.0543
-0.4903
Article2vec(WE)
0.0472
-0.3466
Article2vec(Coc)
0.1772
-0.5247
Article2vec(Auth)
-
-1.0
Article2vec
0.0285
-0.3312
57
Таблица 14: Максимальное значение Silhouette Coefficient.
Cora
TrecGen2007
TF-IDF
0.4396
0.1047
BM25
0.0165
0.0358
Paragraph2vec
0.2514
0.1185
DeepWalk(C)
0.7646
0.1947
DeepWalk(Coc)
0.9978
0.9994
Node2vec(C)
0.4568
0.0984
Node2vec(Coc)
0.6289
0.4706
Concatenation(TC)
0.1654
0.0885
Concatenation(TCoc)
0.3349
0.1789
Concatenation(TCCoc)
0.278
0.0873
Paper2vec
0.2634
0.1432
Article2vec(Node2vec)
0.2665
0.1801
Article2vec(WE)
0.2724
0.1701
Article2vec(Coc)
0.266
0.1486
Article2vec(Auth)
-
0.0903
Article2vec
0.2657
0.1402
Таблица 15: Корреляция Silhouette Coefficient и AMI.
Cora
TrecGen2007
TF-IDF
-0.6479
0.0621
BM25
-0.3352
0.4979
Paragraph2vec
0.2686
0.1751
DeepWalk(C)
0.3939
-0.3065
DeepWalk(Coc)
-0.741
-0.6476
Node2vec(C)
0.2177
-0.256
Node2vec(Coc)
0.2833
0.1883
Concatenation(TC)
0.0925
-0.0993
Concatenation(TCoc)
-0.3462
0.2857
Concatenation(TCCoc)
-0.3783
0.2596
Paper2vec
-0.2317
-0.2363
Article2vec(Node2vec)
0.0435
0.0569
Article2vec(WE)
-0.0602
-0.1989
Article2vec(Coc)
-0.2933
-0.257
Article2vec(Auth)
-
-1.0
Article2vec
0.0221
-0.0841
58
Приложение B. Внешние меры эффективности
Таблица 16: Максимальное значение NMI.
Cora
TrecGen2007
TF-IDF
0.2501
0.5562
BM25
0.2651
0.5778
Paragraph2vec
0.2642
0.5771
DeepWalk(C)
0.2827
0.4346
DeepWalk(Coc)
0.1164
0.3115
Node2vec(C)
0.3
0.4464
Node2vec(Coc)
0.203
0.3178
Concatenation(TC)
0.3131
0.5711
Concatenation(TCoc)
0.2598
0.5016
Concatenation(TCCoc)
0.2582
0.497
Paper2vec
0.3418
0.5811
Article2vec(Node2vec)
0.3462
0.5843
Article2vec(WE)
0.3604
0.5896
Article2vec(Coc)
0.3479
0.5925
Article2vec(Auth)
-
0.5283
Article2vec
0.3596
0.5899
Таблица 17: Корреляция NMI и AMI.
Cora
TrecGen2007
TF-IDF
0.8945
0.7923
BM25
0.8475
0.7799
Paragraph2vec
0.7368
0.2783
DeepWalk(C)
0.7373
0.259
DeepWalk(Coc)
0.831
0.721
Node2vec(C)
0.4286
0.069
Node2vec(Coc)
0.8649
0.7864
Concatenation(TC)
0.072
-0.0017
Concatenation(TCoc)
0.9048
0.2611
Concatenation(TCCoc)
0.9045
0.2202
Paper2vec
0.3296
0.0236
Article2vec(Node2vec)
0.5249
0.5677
Article2vec(WE)
0.3708
0.1363
Article2vec(Coc)
0.3224
-0.045
Article2vec(Auth)
-
-1.0
Article2vec
0.2211
0.1247
59
Таблица 18: Максимальное значение ARI.
Cora
TrecGen2007
TF-IDF
0.1523
0.2826
BM25
0.1838
0.3243
Paragraph2vec
0.1748
0.2723
DeepWalk(C)
0.2485
0.1878
DeepWalk(Coc)
0.0172
0.043
Node2vec(C)
0.3141
0.183
Node2vec(Coc)
0.0893
0.0422
Concatenation(TC)
0.2757
0.2933
Concatenation(TCoc)
0.1673
0.1878
Concatenation(TCCoc)
0.1663
0.189
Paper2vec
0.2653
0.3219
Article2vec(Node2vec)
0.2671
0.3349
Article2vec(WE)
0.2689
0.3272
Article2vec(Coc)
0.2757
0.3502
Article2vec(Auth)
-
0.2592
Article2vec
0.2695
0.3529
Таблица 19: Корреляция ARI и AMI.
Cora
TrecGen2007
TF-IDF
0.451
0.8474
BM25
0.009
0.8535
Paragraph2vec
0.5509
0.8238
DeepWalk(C)
0.1223
0.4942
DeepWalk(Coc)
0.7924
0.8609
Node2vec(C)
0.1248
0.6138
Node2vec(Coc)
-0.5589
-0.1476
Concatenation(TC)
0.1433
0.7968
Concatenation(TCoc)
0.1192
0.5197
Concatenation(TCCoc)
0.1352
0.5214
Paper2vec
0.3113
0.7852
Article2vec(Node2vec)
0.4318
0.8748
Article2vec(WE)
0.4252
0.8017
Article2vec(Coc)
0.334
0.8116
Article2vec(Auth)
-
1.0
Article2vec
0.268
0.8163
60
Таблица 20: Максимальное значение V-measure.
Cora
TrecGen2007
TF-IDF
0.2457
0.554
BM25
0.2611
0.5759
Paragraph2vec
0.2582
0.575
DeepWalk(C)
0.2772
0.4322
DeepWalk(Coc)
0.1154
0.3115
Node2vec(C)
0.297
0.4439
Node2vec(Coc)
0.2027
0.3178
Concatenation(TC)
0.3068
0.5675
Concatenation(TCoc)
0.2552
0.4985
Concatenation(TCCoc)
0.2537
0.4941
Paper2vec
0.3339
0.5777
Article2vec(Node2vec)
0.3381
0.5813
Article2vec(WE)
0.352
0.5858
Article2vec(Coc)
0.3398
0.5888
Article2vec(Auth)
-
0.5267
Article2vec
0.3514
0.5896
Таблица 21: Корреляция V-measure и AMI.
Cora
TrecGen2007
TF-IDF
0.9265
0.798
BM25
0.8612
0.7862
Paragraph2vec
0.7589
0.2964
DeepWalk(C)
0.7552
0.2768
DeepWalk(Coc)
0.9519
0.726
Node2vec(C)
0.46
0.0886
Node2vec(Coc)
0.8732
0.7849
Concatenation(TC)
0.0992
0.0388
Concatenation(TCoc)
0.909
0.2728
Concatenation(TCCoc)
0.9086
0.2324
Paper2vec
0.3931
0.0742
Article2vec(Node2vec)
0.5889
0.5958
Article2vec(WE)
0.4374
0.1908
Article2vec(Coc)
0.3988
0.0221
Article2vec(Auth)
-
-1.0
Article2vec
0.2813
0.2043
61
