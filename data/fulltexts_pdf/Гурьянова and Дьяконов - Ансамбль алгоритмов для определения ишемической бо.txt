Московский государственный университет имени М.В. Ломоносова
Факультет Вычислительной Математики и Кибернетики
Магистерская программа
«Логические и комбинаторные методы анализа данных»
Магистерская диссертация
«Ансамбль алгоритмов для определения ишемической
болезни сердца по электрокардиограмме»
Работу выполнила:
Гурьянова Валерия Николаевна
Научный руководитель:
профессор, д.ф.-м.н.
Дьяконов Александр Геннадьевич
Москва
2017
Содержание
1
Введение
4
2
Постановка задачи и описание данных
5
3
Предобработка данных
5
4
Алгоритмы, входящие в состав ансамбля
6
4.1
Алгоритм, основанный на признаках, полученных из HRV-сигнала .
.
.
.
7
4.2
Алгоритм, основанный на 3-х различных группах признаков
.
.
.
.
.
.
.
12
4.3
Алгоритм, основанный на вейвлет-преобразовании сигнала
.
.
.
.
.
.
.
.
14
4.4
Алгоритм, основанный на анализе сегментов сигнала вокруг его R-пиков
17
4.5
Алгоритм, основанный на биспектральном разложении сигнала .
.
.
.
.
.
18
5
Методы построения ансамблей алгоритмов
21
5.1
Голосование по большинству .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
21
5.2
EM-алгоритм .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
21
6
Метрики качества,
используемые для сравнения реализованных алго-
ритмов
22
6.1
Качество по пациентам .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
6.2
F-мера .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
22
6.3
Roc-Auc .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
7
Результаты экспериментального исследования
23
7.1
Характеристики программной реализации .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
7.2
Метод оценки алгоритмов и подбора параметров
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
7.3
Полученные результаты .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
24
8
Заключение
28
2
Аннотация
Ишемическая болезнь сердца является ведущей причиной смерти в мире. Дан-
ная болезнь может протекать долгое время бессимптно и с течением времени про-
грессировать и закончится смертью.
В современных условиях с помощью специ-
ального оборудования стало возможно снять кардиограмму в домашних услови-
ях. В данной работе ставилась задача определения ишемической болезни по элек-
трокардиограммам,
полученных с помощью данного оборудования.
Проводилось
исследование различных подходов для классификации электрокардиограмм.
Бы-
ли предложены новые подходы и модификации существующих.
Кроме того были
предложены способы ансамблирования реализованных алгоритмов. Наилучшее ка-
чество показал ансамбль, реализованный с помощью EM-алгоритма.
3
1
Введение
Ишемическая болезнь сердца (ИБС) − это такое состояние, при котором нарушается
кровообращение мышцы сердца,
когда к некоторым его участкам переодически и при
определенных обстоятельствах поступает недостаточное количество крови. Проявлени-
ями ИБС могут быть стенокардия, острая коронарная недостаточность со смертельным
исходом, инфаркт миокарда и нарушение сердечного ритма. [1] По данным Всемирной
организации здравоохранения [2]
ишемическая болезнь сердца является ведущей при-
чиной смертей в мире.
На начальных стадиях заболевания у большинства людей не проявляется никаких
симптомов данного заболевания. Однако со временем болезнь чаще всего прогрессирует
и может закончится смертью [1]. Очень важно своевременно выявить заболевание, чтобы
замедлить ход развития болезни и не допустить смерти.
Традиционно ишемическая болезнь сердца определяется при помощи специалистов
и ряда исследований.
Исследования включают в себя стресс-тесты (если больной не в
состоянии выполнить стресс-тест,
то применяется ввод лекарственных препаратов,
ко-
торые увеличивают нагрузку на сердце),
анализы крови,
мониторинг артериального
давления, электрокардиограмму, эхокардиограмму и прочее [1]. Следует отметить, что
эти исследования занимают существенное время пациента,
а также требуют высокой
квалификации специалиста, который будет их проводить. Так как специалистов крайне
мало, а число потенциальных больных растет с каждым годом, то задача автоматическо-
го определения ишемической болезни сердца является крайне актуальной в настоящее
время. На сегодняшний день крайне актуальной является задача создания устройства,
которое поможет определять заболевание или его вероятность в домашних условиях.
Такие устройства позволят направить человека к врачу, в случае высокой вероятности
наличия у него ИБС.
Электрокардиограмма (ЭКГ) − это сигнал,
отображающий электрическую актив-
ность сердца.
Он может быть измерен при помощи электродов,
прикрепленных к ко-
нечностям или грудной клетке [3]. ЭКГ является одним из наиболее доступных средств
диагностики сердечных заболеваний в настоящее время из-за ее неинвазивности и низ-
кой стоимости. В настоящее время существует множество различных исследований, ко-
торые показывают,
что ЭКГ может быть использована для определения ишемической
болезни сердца [4] [5]. Компания CardioQvark создала устройство, которое представляет
собой насадку на смартфон, позволяющую делать замеры ЭКГ в бытовых условиях. За-
меры отправляются в облако и анализируются там,
а затем результаты отправляются
пациенту и лечащему врачу.
4
В данной работе исследовались различные методы,
которые позволяют выявлять
болезни сердца на основе ЭКГ,
и их применимость для определения ишемической бо-
лезни сердца по ЭКГ,
полученном от устройства созданным компанией CardioQvark.
Были предложены модификации этих методов, которые позволяют улучшить качество
классификации для данной задачи. Также было проведено исследование применимости
нового метода для автоматического определения ишемической болезни сердца. С целью
улучшить качество классификации был построен ансамбль из реализованных алгорит-
мов.
Данная работа состоит из следующих разделов: постановка задачи и описание дан-
ных, предобработка данных, описание алгоритмов, входящих в состав ансамбля, описа-
ние методов построения ансамблей алгоритмов, описание метрик качества, по которым
сравниваются алгоритмы, результаты экспериментальных исследований и заключение.
2
Постановка задачи и описание данных
Целью данной работы является построение алгоритма, который показывает наилуч-
шее качество при определении ишемической болезни сердца по электрокардиограмме,
полученной с помощью устройства от компании CardioQvark.
При решении данной задачи использовались две выборки. Выборка, по которой про-
водилась кросс-валидация и обучение алгоритма и выборка,
которая использовалась
для тестирования.
Выборка, которая использовалась для обучения алгоритмов состоит из 1798 кардио-
грамм.
При этом она содержит 1055 кардиограмм здоровых пациентов и 743 кардио-
граммы больных пациента. Частота дискретизации 1000 Гц.
Выборка, которая использовалась для тестирования алгоритмов состоит из 1567 кар-
диограмм.
При этом она содержит 973 кардиограммы здоровых пациентов и 594 кар-
диограммы больных пациентов. Частота дискретизации 1000 Гц.
3
Предобработка данных
Данные, полученные от электрокардиографа, часто подвержены шуму, поэтому необ-
ходима предобработка данных. Для избавления данных от шума используются различ-
ные фильтры.
Фильтр − это обрабатывающая система,
алгоритм или метод,
реализо-
ванный программно или аппаратно,
который используется,
чтобы изменить заданный
сигнал специальным образом [3].
5
Фильтр нижних (верхних) частот − это фильтр, который используется, чтобы уда-
лить высоко-частотный (низко-частотный) шум с минимальными потерями компонент
сигнала в указанной полосе пропускания [3].
Каждый фильтр характеризуется величиной, которая называется амплитудно-частотная
характеристика.
Амплитудно-частотная характеристика показывает зависимость ам-
плитуды выходного сигнала от частоты входного сигнала [3].
Фильтр Баттерворта (нижних и верхних частот) является одним из наиболее часто
используемых фильтров по причине простоты его реализации,
а также из-за макси-
мально гладкой амплитудно-частотной характеристики, которая позволяет не слишком
сильно изменять вид исходного сигнала [3] .
Медианный фильтр часто используется для извлечения тренда, который был полу-
чен из-за помех в приборе. Медианный фильтр определяется следующим образом.
Пусть 𝑤 − заданный размер окна (нечетное число), 𝑥 − исходный сигнал, 𝑖 − индекс
элемента сигнала, [ : ] − индексация массива. median - статистика, такая что половина
элементов выборки меньше ее, и половина элементов выборки больше ее. Тогда выход-
ной сигнал 𝑦 определяется как :
𝑦
𝑖
= median(𝑥[𝑖 − 𝑤/2 : 𝑖 + 𝑤/2]).
Проведенная предобработка данных включает в себя следующие шаги:
∙ Применение фильтра Баттерворта второго порядка верхних частот с частотой по-
давления сигнала 0.3 Гц.
∙ Применение фильтра Баттерворта второго порядка верхних частот с частотой по-
давления сигнала 0.3 Гц.
∙ Извлечение тренда при помощи медианного фильтра.
∙ Вычитание тренда из полученного сигнала.
В данной работе использовались реализации указанных выше фильтров из модуля
signal библиотеки scipy [6].
На Рис. 1 изображен пример ЭКГ-сигнала до и после предобработки.
4
Алгоритмы, входящие в состав ансамбля
Ниже приведены описания алгоритмов, которые были использованы для построения
ансамбля.
6
0
250
500
750
1000
1250
1500
1750
2000
0.000
0.025
0.050
0.075
0.100
0.125
0.150
0.175
0.200
Сигнал до предобработки
0
250
500
750
1000
1250
1500
1750
2000
0.001
0.000
0.001
0.002
0.003
0.004
0.005
0.006
Сигнал после предобработки
Рис. 1: Вид сигнала до и после предобработки.
4.1
Алгоритм,
основанный на признаках,
полученных из HRV-
сигнала
Данный алгоритм был описан в статье [4] и был использован для обнаружения ише-
мической болезни сердца.
В ЭКГ-сигнале можно выделить R-пики, которые соответствуют пульсу человека [3].
Пример того, как выглядят R-пики в ЭКГ-сигнале можно увидеть на Рис. 2.
0
500
1000
1500
2000
2500
0.001
0.000
0.001
0.002
0.003
0.004
0.005
R-peak
R-peak
R-peak
Рис. 2: R-пики в ЭКГ сигнале.
Алгоритм обнаружения R-пиков подробно описан в [7] и его общий принцип состоит
в следующем.
∙ Выделяем только те пики, в окрестности 200 мс которых нет пиков больше данного.
∙ Если такие пики нашлись, то проверяем, содержит ли ЭКГ-сигнал положительный
и отрицательный наклон.
∙ Если пик больше чем, некоторый заданный порог, то считаем его R-пиком.
7
Для вычисления R-пиков использовалась реализация указанного выше алгоритма из
библиотеки BioSPPy [8].
По ЭКГ-сигналу может быть построен сигнал, который называется вариабельность
сердечного ритма (HRV-сигнал). Он вычисляется следующим образом.
∙ Вычисляются R-пики.
∙ Измеряются интервалы между двумя R-пиками (RR-интервалы).
∙ Каждая величина RR-интервала преобразуется как 60/RR.
На Рис. 3 изображен ЭКГ-сигнал и соответствующий ему HRV-сигнал.
0
20000
40000
60000
80000
100000
120000
140000
0.002
0.000
0.002
0.004
0.006
0.008
ЭКГ-сигнал
0
100
200
300
400
0.0750
0.0775
0.0800
0.0825
0.0850
0.0875
0.0900
0.0925
HRV-сигнал
Рис. 3: ЭКГ и HRV-сигнал.
На основе HRV-сигнала строятся различные группы признаков.
В первую группу признаков входят различные энтропийные признаки, которые по-
казывают меру непредсказуемости в сигнале. Используются следующие виды энтропий:
приближенная энтропия, выборочная энтропия и энтропия Шеннона. Про каждый вид
энтропии подробно описано ниже.
Приближенная энтропия вычисляется следующим образом. Здесь 𝑥 − HRV-сигнал.
∙ Необходимо зафиксировать целое 𝑚 и действительное 𝑟
∙ На основе сигнала составим вектора следующего вида: 𝑥
𝑖
= (𝑥
𝑖
, 𝑥
𝑖+1
, ..., 𝑥
𝑖+𝑚−1
)
8
∙ Определим величины 𝐶
𝑚
𝑖
(𝑟) следующим образом:
𝐶
𝑚
𝑖
(𝑟) =
|𝑥 : 𝑑(𝑥
𝑖
, 𝑥) ≤ 𝑟|
𝑁 − 𝑚 + 1
,
𝑑(𝑥
𝑖
, 𝑥) = 𝑚𝑎𝑥
𝑎
|𝑥
𝑖
(𝑎) − 𝑥(𝑎)|,
(1)
где 𝑁 -размер HRV-сигнала, 𝑥
𝑖
(𝑎) − компонента 𝑎 вектора 𝑥
𝑖
∙ Определим величины Φ
𝑚
(𝑟) как:
Φ
𝑚
(𝑟) = (𝑁 − 𝑀 + 1)
−1
𝑁−𝑚+1
∑︁
𝑖=1
log(𝐶
𝑚
𝑖
(𝑟))
∙ Приближенная энтропия (ApEn) определяется как
ApEn = Φ
𝑚
(𝑟) − Φ
𝑚+1
(𝑟)
В данной работе приближенная энтропия реализовывались для 𝑚 = 10 и 𝑟 = 0.2std(𝑥),
где std(𝑥) − стандартное отклонение сигнала.
std(𝑥) =
⎯
⎸
⎸
⎷
1
𝑁
𝑁
∑︁
𝑖=1
(𝑥
𝑖
− 𝜇),
(2)
где 𝑥
𝑖
− 𝑖-ая компонента сигнала, 𝑁 -число элементов в сигнале, 𝜇 − среднее сигнала и
определяется по формуле
𝜇 =
1
𝑁
𝑁
∑︁
𝑖=1
𝑥
𝑖
.
(3)
Выборочная энтропия вычисляется следующим образом.
∙ Формируются векторы длины 𝑚 𝑥
𝑖
𝑚
аналогичные тем,
которые были сформиро-
ваны в приближенной энтропии.
∙ Вычисляются величины 𝐴 и 𝐵 следующим образом
𝐴 = |𝑥 : 𝑑(𝑥
𝑖
𝑚+1
, 𝑥
𝑚+1
) ≤ 𝑟|,
𝐵 = |𝑥 : 𝑑(𝑥
𝑖
𝑚
, 𝑥
𝑚
) ≤ 𝑟|,
где d определяется согласно формуле (1).
9
∙ Выборочная энтропия (SampEn) определяется как
SampEn = − log
𝐴
𝐵
.
В данной работе выборочная энтропия определялась при 𝑚 = 10, 𝑟 = 0.2std(x).
Энтропия Шеннона (ShanEn), вычисляется как
ShanEn =
𝑘
∑︁
𝑓=1
𝑝
𝑓
log 𝑝
𝑓
,
где k −число различных элементов в сигнале 𝑥, 𝑝
𝑓
− частота элемента 𝑓 в сигнале 𝑥.
Следующая группа признаков основана на графике повторений.
Данный график
показывает частоту и продолжительность повторений в сигнале. Элемент (𝑖, 𝑗) данного
графика определяется следующим образом
𝑅(𝑖, 𝑗) =
⎧
⎨
⎩
1,
если ||𝑥
𝑖
− 𝑥
𝑗
|| < 𝜀
0,
иначе
,
где 𝑥 − HRV-сигнал.
На основе данного графика вычисляются следующие признаки, 𝑁 − число элементов
в HRV-сигнале:
∙ Плотность точек на графике (REC)
REC =
1
𝑁
2
𝑁
∑︁
𝑖,𝑗=0
𝑅(𝑖, 𝑗).
∙ Процент точек,
которые формируют диагональные линии минимальной длины
(DET)
DET =
∑︀
𝑁
𝑙=𝑙
min
𝑙𝑃 (𝑙)
∑︀
𝑁
𝑖,𝑗
𝑅(𝑖, 𝑗)
,
𝑙
min
− минимальная длина диагонали, 𝑃 (𝑙) − число диагоналей длины 𝑙.
∙ Средняя длина диагоналей (𝐿
mean
)
𝐿
mean
=
∑︀
𝑁
𝑙=𝑙
min
𝑙𝑃 (𝑙)
∑︀
𝑙=𝑙
min
𝑃 (𝑙)
.
∙ Энтропия диагональных линий (EN
𝑑
)
EN
𝑑
= −
𝑁
∑︁
𝑙=𝑙
min
𝑝
𝑙
log 𝑝
𝑙
,
где 𝑝
𝑙
− частота диагональных линий длины 𝑙.
10
∙ Энтропия вертикальных линий (EN
𝑣
)
EN
𝑣
= −
𝑁
∑︁
𝑙=𝑙
𝑣 min
𝑝
𝑣𝑙
log 𝑝
𝑣𝑙
,
где 𝑝
𝑣𝑙
− частота вертикальных линий длины 𝑙,
𝑙
𝑣 min
− минимальная длина вер-
тикальной линии.
Для вычисления указанных признаков в данной работе использовалась библиотека
PyRQA [9].
Еще одна группа признаков, которая используется при данном подходе, − это груп-
па признаков, основанных на графике Пуанкаре. График Пуанкаре строится следующим
образом: для сигнала 𝑥 = (𝑥
1
, 𝑥
2
, ..., 𝑥
𝑁
) на графике отображаются точки (𝑥
1
, 𝑥
2
), (𝑥
2
, 𝑥
3
, ), ..., (𝑥
𝑖
, 𝑥
𝑖+1
)
и так далее.
В данном случае в качестве сигнала берется сигнал,
который состоит из
RR-интервалов.
Используются следующие признаки:
∙ Стандартное отклонение (формула (2)) расстояний точек графика до прямой 𝑦 =
𝑥. Данный признак описывает локальную вариативность RR-интервалов.
∙ Стандартное отклонение (формула (2)) расстояний точек графика до прямой 𝑦 =
−𝑥 − 2𝑅𝑅
𝑚𝑒𝑎𝑛
. 𝑅𝑅
mean
− среднее значение RR-интервалов. Данный признак опи-
сывает долговременную вариативность RR-интервалов.
Признаки, основанные на детрентном флуктуационном анализе. Данный метод поз-
воляет определить самозависимость сигнала.
Определим следующую кумулятивную
сумму:
𝑥(𝑡) =
𝑡
∑︁
𝑖=1
(𝑥(𝑖) − 𝜇),
𝑥 - сигнал, состоящий из RR-интервалов, 𝜇 − среднее значение сигнала 𝑥 (определяется
по формуле (3))
Данные сегментируются с окном размера ∆𝑛. На каждом сегменте для данных нахо-
дится полином, который наиболее точно их представляет(обычно линейный) и находится
следующая функция
𝐹 (∆𝑛) =
⎯
⎸
⎸
⎷
1
𝑁
𝑁
∑︁
𝑡=1
[𝑥(𝑡) − 𝑥
Δ𝑛
(𝑡)]
2
,
где 𝑁 -длина сигнала, состоящего из RR-интервалов.
11
Признаком будет являться угол наклона линии log 𝐹 (∆𝑛) к log(∆𝑛). Подробнее про
данный подход написано в [10].
В данной работе для вычисления данного признака
использовалась реализация из библиотеки nolds [11].
Следующим признаком, который используется при данном подходе является корре-
ляция размерностей.
Данный признак является количественной характеристикой тра-
ектории сигнала и определяется следующим образом.
∙ Формируются векторы длины 𝑚 𝑥
𝑖
𝑚
аналогичные тем,
которые были сформиро-
ваны в приближенной энтропии.
∙ Величина 𝑔 определяется как 𝑔(𝑟) = |𝑥 : 𝑑(𝑥
𝑖
𝑚+1
, 𝑥
𝑗
𝑚+1
) ≤ 𝑟|. 𝑔 − это число векто-
ров, расстояние между которым меньше либо равно 𝑟.
∙ Величина 𝐶(𝑟) определяется как
𝐶(𝑟) =
𝑔(𝑟)
𝑁
2
,
где 𝑁 − это длина сигнала 𝑥.
∙ Корреляция размерностей (𝐷2) определяется как
𝐷2 = lim
𝑟→0
log 𝐶(𝑟)
log(𝑟)
.
В данной работе использовалась реализация данного признака из библиотеки nolds
[11].
В качестве классификатора при данном подходе использовалась логистическая ре-
грессия из пакета scikit-learn [12] и градиентный бустинг из библиотеки xgboost [13].
4.2
Алгоритм, основанный на 3-х различных группах признаков
Данный алгоритм представляет собой смесь 3-х различных признаковых пространств,
которые ранее были использованы в задачах классификации биомедицинских сигналов.
Первая группа признаков состоит из параметров Йорта [14]. Данные параметры из-
начально использовались как характеристики электроэнцефалограмм. Электроэнцефа-
лограмма (ЭЭГ) − это сигнал,
который показывает биоэлектрическую активность го-
ловного мозга [3].
Однако позже стали применяться во многих работах,
в том числе и
для классификации ЭКГ-сигналов [15].
Данные параметры определяются следующим
образом. 𝑥(𝑡) − заданный сигнал, var(x) − дисперсия сигнала 𝑥 и определяется следу-
ющим образом:
var(𝑥) =
1
𝑁
𝑁
∑︁
𝑖=1
(𝑥
𝑖
− 𝜇)
2
.
(4)
12
∙ Активность (Activity) отображает дисперсию сигнала
Activity = 𝑣𝑎𝑟(𝑥(𝑡)).
∙ Мобильность (Mobility) представляет собой среднюю частоту
Mobility =
√︃
𝑣𝑎𝑟(
𝑑𝑥(𝑡)
𝑑𝑡
)
𝑣𝑎𝑟(𝑥(𝑡))
.
∙ Сложность (Complexity) показывает на изменения в частоте сигнала
Complexity =
Mobility(
𝑑𝑥(𝑡)
𝑑𝑡
)
Mobility(𝑥(𝑡))
.
Следующая группа признаков представляет собой статистические характеристики
сигнала и состоит из следующих признаков.
∙ Среднее (формула (3)).
∙ Cтандартное отклонение (формула (2)).
∙ Минимум и максимум значений сигнала
∙ Пусть задана выборка 𝑥 = (𝑥
1
, 𝑥
2
, ..., 𝑥
𝑁
),
ей соответствует вариационный ряд
𝑥
(1)
≤ 𝑥
(2)
≤ ...𝑥
(𝑁)
.
Квантилью порядка 𝛼 называется число равное элементу,
которому соответствует номер 𝑁 𝛼 + 1 в вариационном ряду. В качестве признаков
берутся выборочные квантили сигнала порядка 0.1, 0.25, 0.5, 0.75, 0.9.
∙ Суммы и суммы квадратов значений сигнала, которые находятся выше/ниже опре-
деленных значений квантилей 0.1, 0.25, 0.5, 0.75, 0.9.
∙ Коэффициент асимметрии:
1
𝑛
∑︀
𝑛
𝑖=1
(𝑥
𝑖
− ¯
𝑥)
3
(
1
𝑛
∑︀
𝑛
𝑖=1
(𝑥
𝑖
− ¯
𝑥)
2
)
3/2
∙ Коэффициент эксцесса:
1
𝑛
∑︀
𝑛
𝑖=1
(𝑥
𝑖
− ¯
𝑥)
4
(
1
𝑛
∑︀
𝑛
𝑖=1
(𝑥
𝑖
− ¯
𝑥)
2
)
2
− 3
Следующая группа признаков была предложена В.
М.
Успенским для определения
заболевания по ЭКГ пациента [16]. Для вычисления данных признаков необходимо вы-
числить амплитуды R-пиков (𝐴(𝑛)), расстояния между R-пиками (𝑇 (𝑛)), а также арк-
тангенс их отношения
𝛼(𝑛) = acrtg
𝐴(𝑛)
𝑇 (𝑛)
.
13
Рис. 4: Величины, используемые при формировании признаков Успенского.
Изображение данных величин представлено на Рис. 4.
Предполагается,
что имеют значения не сами величины A(n),
T(n),
а лишь знаки
их приращений.
Способ кодирования сигнала,
основанный на всех возможных знаках
приращений указанных величин представлен в Таблице 1.
A
B
C
D
E
F
𝐴(𝑛 + 1) − 𝐴(𝑛)
+
−
+
−
+
−
𝑇 (𝑛 + 1) − 𝑇 (𝑛)
+
−
−
+
+
−
𝛼(𝑛 + 1) − 𝛼(𝑛)
+
+
+
−
−
−
Таблица 1: Кодовое преобразование сигнала
После того как получено кодовое представление сигнала,
осуществляется выделе-
ние три-грамм.
Признаковым пространством является количество вхождений каждой
из возможных три-грамм в заданную кодовую последовательность, полученную из сиг-
нала.
В качестве классификатора при данном подходе использовалась логистическая ре-
грессия из пакета scikit-learn [12] и градиентный бустинг из библиотеки xgboost [13].
4.3
Алгоритм, основанный на вейвлет-преобразовании сигнала
Данный алгоритм, использовался авторами статьи [17] для обнаружения эпилепсии
по ЭЭГ-сигналу, а также для идентификации человека по ЭКГ-cигналу.
Вейвлет-преобразование сигнала − это свертка функций Ψ(𝑡),
называемых вейвле-
тами, с сигналом. Данные вейвлет-функции должны иметь следующие свойства:
14
∫︁
+∞
−∞
Ψ(𝑡)𝑑𝑡 = 0
∫︁
+∞
−∞
|Ψ(𝑡)|
2
𝑑𝑡 < inf .
Вейвлет-преобразование позволяет получить сжатие сигнала,
которое обладает хо-
рошим качеством восстановленного сигнала [3].
Все вейвлет-функции, используемые в вейвлет-преобразовании могут быть представ-
лены на основе функции-прототипа 𝜓(𝑡),
путем масштабирования и переноса.
Так в
случае дискретного вейвлет-преобразования все вейвлет-функции могут быть записаны
как:
𝜓
𝑚,𝑛
(𝑡) =
1
√
2
𝑚
𝜓
(︀
2
−𝑚
𝑡 − 𝑛
)︀
.
Параметр сдвига 𝑛 показывает, где во временной оси размещен соотвествующий вей-
влет, а параметр масштабирования 𝑚 связан с частотой для заданного вейвлета.
Тогда вейвлет-преобразование может быть записано как:
𝑋(𝑚, 𝑛) =
∫︁
+∞
−∞
𝑥(𝑡)𝜓
*
𝑚,𝑛
(𝑡)𝑑𝑡,
где 𝜓
*
− это функция комплексно сопряженная к 𝜓.
В дискретном вейвлет-преобразовании функции 𝜓
*
𝑚,𝑛
могут быть разбиты на 2 со-
ставляющие.
Это функции,
которые отвечают коэффициентам аппроксимации и ко-
эффициентам детализации. В данной работе для представления сигнала используются
коэффициенты аппроксимации для нового представления сигнала, а в качестве вейвлет-
функций используются Daubechies вейвлеты [18].
Программная реализация используется из библиотеки PyWavelets [19].
После того как были получены коэффициенты вейвлет-преобразования,
из сигнала
выделяются локальные сегменты. Для этого вдоль сигнала необходимо пройти «окном»
некоторой длины 𝑤, с шагом 𝑠. Все элементы, которые попадают в пределы одного окна,
записываются в отдельный сегмент. Таким образом, каждый сигнал представляет собой
набор локальных сегментов.
Все локальные сегменты,
которые входят в обучающую выборку кластеризуются
на 𝑘 кластеров методом k-средних.
После этого каждый сегмент заменяется номером
кластера,
которому он принадлежит.
Таким образом каждый сигнал представляется в
виде текста, состоящего из кодовых слов, соответствующих выделенным кластерам.
При реализации заданного подхода использовалась 𝑤 = 100, 𝑠 = 30, 𝑘 = 200. Реали-
зация метода k-средних использовалась из библиотеки scikit-learn.
В обучающий выборке каждый локальный сегмент заменяется на тот кластер, ближе
всего к которому он расположен. То есть для локального сегмента 𝑥
𝑖
в тестовой выборке
15
кластер 𝑐, которому он принадлежит, определяется формулой:
𝑐 = argmin
𝑗
𝑑(𝑏
𝑗
, 𝑥
𝑖
)
𝑑(𝑏, 𝑥) =
⎯
⎸
⎸
⎷
𝑁
∑︁
𝑘=1
(𝑥
𝑘
− 𝑏
𝑘
)
2
,
где 𝑏
𝑗
− центр кластера 𝑗.
Таким образом, получив вместо сигнала текст, можем использовать подходы, приме-
нимые для текстов. Авторы статьи, которые предложили данное кодирование сигнала,
использовали в качестве признакового пространства «мешок слов». Признаковым опи-
санием является число вхождений каждого кодового слова в данный сигнал.
Кроме того, с целью выделения зависимостей между локальными сегментами в сиг-
нале использовались признаки на основе word2vec. Данный подход был предложен ком-
панией Google и он позволяет учитывать контекст слов при обработке текстов, в то же
время сокращая размер данных [20].
Word2Vec представляет собой на самом деле два
разных метода:
Continuous Bag of
Words (CBOW) и Skip-gram.
В CBOW методе,
це-
лью алгоритма является предсказать слово,
на основе слов,
которые его окружают.
В
методе Skip-gram целью является предсказать слова, которые окружают данное слово.
Оба метода используют нейронную сеть в качестве алгоритма для обучения.
В начале
обучения каждое слово – это случайный n-размерный вектор.
Во время обучения ал-
горитм изучает оптимальный вектор для каждого слова,
используя метод CBOW или
Skip-gram.
w(t-2)
w(t+1)
w(t-1)
w(t+2)
w(t)
SUM
INPUT PROJECTION OUTPUT
w(t)
INPUT PROJECTION OUTPUT
w(t-2)
w(t-1)
w(t+1)
w(t+2)
CBOW Skip-gram
Figure 1: New model architectures. The CBOW architecture predicts the current word based on the
context, and the Skip-gram predicts surrounding words given the current word.
R
words from the future of the current word as correct labels.
This will require us to do
R ⇥ 2
word classifications, with the current word as input, and each of the
R + R
words as output.
In the
following experiments, we use
C = 10
.
4
Results
To compare the quality of different versions of word vectors, previous papers typically use a table
showing example words and their most similar words,
and understand them intuitively.
Although
it is easy to show that word France is similar to Italy and perhaps some other countries, it is much
more challenging when subjecting those vectors in a more complex similarity task, as follows.
We
follow previous observation that there can be many different types of similarities between words, for
example, word big is similar to bigger in the same sense that small is similar to smaller.
Example
of another type of relationship can be word pairs big - biggest and small - smallest [20].
We further
denote two pairs of words with the same relationship as a question,
as we can ask:
”What is the
word that is similar to small in the same sense as biggest is similar to big?”
Somewhat surprisingly, these questions can be answered by performing simple algebraic operations
with the vector representation of words.
To find a word that is similar to small in the same sense as
biggest is similar to big, we can simply compute vector
X = vector(”biggest”)
vector(”big”) +
vector(”small”)
. Then, we search in the vector space for the word closest to
X
measured by cosine
distance, and use it as the answer to the question (we discard the input question words during this
search).
When the word vectors are well trained,
it is possible to find the correct answer (word
smallest
) using this method.
Finally, we found that when we train high dimensional word vectors on a large amount of data, the
resulting vectors can be used to answer very subtle semantic relationships between words, such as
a city and the country it belongs to, e.g.
France is to Paris as Germany is to Berlin.
Word vectors
with such semantic relationships could be used to improve many existing NLP applications,
such
as machine translation, information retrieval and question answering systems, and may enable other
future applications yet to be invented.
5
Рис. 5: Основной принцип работы методов Word2Vec [20]
Модель word2vec строилась по обучающей выборке с длиной вектора 80. В качестве
16
признаков использовался вектор,
являющийся средним всех векторов,
которые входят
в "текст"сигнала.
Модель строилась с помощью библиотеки gensim [21].
В качестве алгоритма классификации использовалась логистическая регрессия из
библиотеки scikit-learn [12].
4.4
Алгоритм, основанный на анализе сегментов сигнала вокруг
его R-пиков
Данный алгоритм был предложен авторами статьи [22]
для определения состояния
сердца, при котором возникает необходимость в госпитализации.
Построение признакового пространства для данного подхода осуществляется следу-
ющим образом.
∙ Выделяются окрестности R-пиков сигнала: 200 мс до R-пика и 500 мс после.
∙ В качестве признакового пространства используется усредненная окрестность.
В качестве классификатора использовалась искусственная нейронная сеть.
Искус-
ственная нейронная сеть − это модель,
построенная по аналогии с принципом функ-
ционирования биологических нейронных сетей.
Основной принцип построения искус-
ственного нейрона состоит в следующем: каждый нейрон получает входные сигналы по
каналам связи, соответствующим каналам от предыдущего нейрона. Для каждого кана-
ла связи установлен его вес, а также функция активации. Выход нейрона определяется
как:
𝑦(𝑥, 𝑤) = 𝑓 (
𝑁
∑︁
𝑖=1
𝑤
𝑖
𝑥
𝑖
),
где 𝑤
𝑖
− заданные веса для 𝑖-го канала связи,
𝑥
𝑖
− входные данные для i-го канала
связи,
𝑓 − функция активации.
Совокупность таких нейронов вместе с выделенными
входными и выходными нейронами может служить как универсальная аппроксимация
произвольной функции [23].
Обучение нейронных сетей происходит с помощью методов стохастической оптими-
зации, используя технику обратного распространения ошибки.
В нейронных сетях выделяют группу сетей прямого распространения,
нейроны и
связи между которыми образуют направленный граф без циклов.
Большинство таких
сетей можно представить как последовательность наборов нейронов,
в котором связи
могут идти только из нейронов предыдущего набора в нейроны последующего набора.
Такие наборы называются слоями.
17
Одним из типов слоев,
которые часто используются в нейронных сетях,
является
полносвязный слой.
В таком слое канал связи идет из каждого нейрона предыдущего
слоя в каждый нейрон текущего слоя.
В данной работе рассматривалась следующая архитектура нейронной сети, которая
описана в Таблице 2, где 𝑓
𝑠
− сигмоидная функция активации, которая задается как:
𝑓
𝑠
(𝑥) =
1
1 + 𝑒
−𝑥
.
Слои
Входной слой
Полносвязный слой
Полносвязный слой
Параметры
число нейронов=700
число нейронов=90
число нейронов=1
функция активации: 𝑓
𝑠
функция активации: 𝑓
𝑠
Таблица 2: Структура нейронной сети
В данной работе нейронная сеть была реализована с помощью библиотек Theano [24]
и Lasagne [25], в качестве метода оптимизации использовался алгоритм Adam [23].
4.5
Алгоритм, основанный на биспектральном разложении сиг-
нала
Преобразование Фурье [3] − это операция, сопоставляющая одной функции 𝑥(𝑡) дру-
гую функцию 𝑋(𝑓) согласно следующей формуле:
𝑋(𝑓) =
1
√
2𝜋
∫︁
∞
−∞
𝑥(𝑡)𝑒
−𝑖𝑡𝑓
𝑑𝑡
.
Биспектр сигнала − это функция от двух переменных 𝑓
1
и 𝑓
2
,
задающих частоты,
выражающаяся следующей формулой [26]:
𝐵(𝑓
1
, 𝑓
2
) = 𝑋(𝑓
1
)𝑋(𝑓
2
)𝑋
*
(𝑓
1
+ 𝑓
2
),
где 𝑋(𝑓 ) − преобразование Фурье сигнала,
а 𝑋
*
(𝑓 ) − комплексное сопряженное к
нему. Биспектр сигнала как правило рассчитывается с помощью быстрого преобразова-
ния Фурье.
Подробное описание алгоритма для нахождения биспектра сигнала можно
найти в [27].
При вычислении биспектра сигнала получается двумерная матрица,
эле-
ментами которой являются комплексные числа.
18
На основе полученной матрицы,
элементы которой можно обозначить как 𝑎(𝑖, 𝑗),
можно сопоставить каждому сигналу некоторое изображение, которое вычисляется сле-
дующим образом. Вычисляется новая матрица 𝐵 = ||𝑏
𝑖,𝑗
||, элементы которой равны
𝑏(𝑖, 𝑗) =
√︁
Re
2
𝑎(𝑖, 𝑗) + Im
2
𝑎(𝑖, 𝑗),
где Re − обозначает действительную часть комплексного числа,
а Im обозначает мни-
мую часть комплексного числа.
В качестве изображения используется график линий
уровня матрицы B. Линия уровня − это линия, во всех точках которой значения функ-
ции равны.
Авторами статьи [28]
было показано,
что ишемическая болезнь сердца может быть
обнаружена,
при анализе изображений,
полученных на основе биспектра сигнала.
Ме-
тод описанный в вышеуказанной статье состоял в выделении площади региона внутри
линий уровня,
при оценке которой можно было сделать вывод о наличии у пациента
ишемической болезни сердца. Результаты, которые были получены авторами, позволя-
ют сделать вывод, что изображения биспектра могут использоваться для обнаружения
у пациента ишемической болезни сердца.
На Рис.
6 представлен пример изображений,
соответствующих спектральному раз-
ложению сигнала для больного ИБС и здорового человека.
Больной ИБС пациент
Здоровый пациент
Рис. 6: Изображение, соотвествующее биспектральному разложению больного и здорового человека
Однако следует отметить,
что подход,
который был реализован в вышеуказанной
статье,
не учитывает никаких особенностей изображения,
кроме как площадь внутри
линий уровня. Поэтому можно сделать предположение, что проанализировав изображе-
ние более сложными методами удастся получить лучшее качество.
19
В качестве метода анализа данных изображений предлагается использовать нейрон-
ные сети,
которые на сегодняшний день успешно решают многие задачи,
связанные с
анализом изображений.
Одним из самых популярных слоев для обработки изображений на сегодняшний
день являются сети,
содержащие сверточные слои,
которые является слоями прямо-
го распространения.
В сверточном слое каждый нейрон зависит не от всех нейронов
предыдущего слоя,
а только некоторого набора нейронов,
которые находятся в общей
окрестности [23].
Такие слои позволяют ускорить процесс обучения и при этом сохра-
нить пространственную информацию. Данный сверточный слой получил свое название
из-за использовании операции свертки.
Суть данной операции заключается в том,
что
каждый элемент выходного слоя вычисляется как сумма всех элементов поэлементного
произведения матрицы ядра свертки и фрагмента изображения, при этом ядро свертки
может перемещаться по входному изображению с некоторым заданным смещением по
осям.
В данной работе для вычисления биспектра сигнала использовался пакет HOSA [29].
Для классификации полученных изображений, использовалась нейронная сеть с ар-
хитектурой, которая описана в таблице 3. Функция активации 𝑓
𝑙𝑟
− Relu «с утечкой» и
она определяется по следующей формуле.
𝑓
𝑙𝑟
(𝑥) =
⎧
⎨
⎩
𝛼𝑥,
𝑥 < 0
𝑥,
𝑥 ≥ 0
,
где 𝛼 − малая константа.
Входной слой
размер слоя=3x80x80
Сверточный слой
размер фильтра=32x5x5
смещение = (2,2)
Полносвязный слой
число нейронов=30
функция активации = 𝑓
𝑙𝑟
Полносвязный слой
число нейронов=1
функция активации = 𝑓
𝑠
Таблица 3: Структура нейронной сети
20
В данной работе нейронная сеть была реализована с помощью библиотек Theano [24]
и Lasagne [25], в качестве метода оптимизации использовался алгоритм Adam [23].
5
Методы построения ансамблей алгоритмов
Для того, чтобы улучшить качество классификации для решаемой в данной работе
задаче было предложено использовать ансамбли из реализованных алгоритмов.
Ниже
описаны методы ансамблирования, которые были использованы в данной работе.
5.1
Голосование по большинству
Пусть набор алгоритмов 𝐴 = (𝐴
1
, 𝐴
2
, ..., 𝐴
𝑛
) выдает вектор ответов 𝑎 = (𝑎
1
, 𝑎
2
, ..., 𝑎
𝑛
)
для классификации случая 𝑖, тогда результирующий ответ 𝑎 будет равен
𝑎 = mode(𝑎
1
, 𝑎
2
, ..., 𝑎
𝑛
),
где mode − статистика, равная наиболее часто встречающемуся элементу в выборке. В
случае если таких элементов несколько, то выбирается один из них случайным образом.
5.2
EM-алгоритм
Данный алгоритм был предложен авторами статьи [30]
для агрегации данных,
по-
лученных от разных людей об одном и том же событии с целью получить истинный
результат.
Так как целью построения ансамбля алгоритмов является агрегация отве-
тов различных алгоритмов для получения истинного результата,
то данный алгоритм
можно использовать для построения ансамбля.
Ниже представлено описание алгоритма для двухклассовой классификации.
𝑁 − размер доступных данных,
𝑛
𝑘
𝑖𝑙
− поставил ли k-ый алгоритм ответ 𝑙 (𝑙 ∈ {1, 2}) на данные 𝑖 ( 𝑖 = 1...𝑁 ),
𝜋
𝑘
𝑗𝑙
(𝑗 ∈ {1, 2}) − вероятность, что 𝑘-ый алгоритм поставит ответ 𝑗, когда истинным
ответом является 𝑙.
𝑇
𝑖𝑗
= 1,
если истинным ответом для данных 𝑖 является 𝑗,
в противном случае,
он
равняется 0.
𝑝
𝑗
− вероятность класса 𝑗 в выборке.
∙ Шаг 1:
Инициализируем матрицы 𝜋 идеальным случаем.
T инициализируем зна-
чением голосования по большинству.
21
∙ Шаг 2: Пересчитываем значения матриц 𝜋 и 𝑝
𝑗
как
𝜋
𝑘
𝑗𝑙
=
∑︀
𝑖
𝑇
𝑖𝑗
𝑛
𝑘
𝑖𝑙
∑︀
𝑙
∑︀
𝑖
𝑇
𝑖𝑗
𝑛
𝑘
𝑖𝑙
𝑝
𝑗
=
∑︀
𝑖
𝑇
𝑖𝑗
𝐼
∙ Шаг 3. Пересчитываем 𝑇
𝑖𝑗
𝑇
𝑖𝑗
=
𝑝
𝑗
∏︀
𝐾
𝑘=1
∏︀
2
𝑙=1
(𝜋
𝑘
𝑗𝑙
)
𝑛
𝑘
𝑖𝑙
∑︀
2
𝑞=1
𝑝
𝑞
∏︀
𝐾
𝑘=1
∏︀
2
𝑙=1
(𝜋
𝑘
𝑞𝑙
)
𝑛
𝑘
𝑖𝑙
Повторяем шаги 2 и 3 до тех пор, пока матрицы 𝜋 не перестанут изменяться.
В конце работы данного алгоритма получим в матрице 𝑇 вероятности принадлеж-
ности данных каждому классу.
В качестве ответа берется тот класс,
вероятность при-
надлежности которому наибольшая.
6
Метрики качества, используемые для сравнения ре-
ализованных алгоритмов
6.1
Качество по пациентам
Данная метрика позволяет оценить то, на сколько хорошо алгоритм определяет бо-
лезнь человека по любой из его кардиограмм. Кроме того, данная метрика не зависит от
числа кардиограмм для каждого пациента.
Данная метрика определяется следующим
образом.
𝑁
∑︁
𝑗=1
∑︀
𝑛
𝑗
𝑖=1
[𝑡
𝑖𝑗
==𝑝
𝑖𝑗
]
𝑛
𝑗
𝑁
,
где 𝑡
𝑖𝑗
− истинное значение целевой переменной для кардиограммы 𝑗 пациента 𝑖,
𝑝
𝑖𝑗
− предсказанное значение целевой переменной для кардиограммы 𝑗 пациента 𝑖,
𝑛
𝑗
−
число кардиограмм у пациента 𝑗, 𝑁 − число пациентов.
6.2
F-мера
F-мера − это мера, не зависящая от несбалансированности выборки и позволяющая
оценить качество модели.
Однако следует отметить,
что данная метрика имеет суще-
ственный недостаток, так как не учитывает, что разные пациенты могут иметь различ-
ное число кардиограмм. Если алгоритм правильно(неправильно) определяет результат
22
для пациентов с большим числом кардиограмм, то это может исказить результат в боль-
шую (меньшую) сторону. Для определения F-меры введем следующие величины.
𝑇
𝑝
– число истинных ответов, принадлежащих классу 1, определенных моделью.
𝑇
𝑛
– число истинных ответов, принадлежащих классу 0, определенных моделью.
𝐹
𝑝
– число ложных ответов, принадлежащих классу 1, определенных моделью.
𝐹
𝑛
– число ложных ответов, принадлежащих классу 0, определенных моделью.
𝑃 = 𝑇
𝑝
+ 𝐹
𝑛
.
Полнота (recall) =
𝑇
𝑝
𝑃
Точность (precision) =
𝑇
𝑝
𝑇
𝑝
+ 𝐹
𝑝
F-мера =
2 * precision * recall
precision + recall
6.3
Roc-Auc
Метрики, описанные выше, имеют недостаток, заключающийся в том, что их значе-
ния зависят от порога, который выбирается при преобразовании вероятностей принад-
лежности классам в метки. Метрикой, которая позволяет оценить возможность такого
преобразования без непосредственно его выполнения, является метрика Roc-Auc.
Roc-Auc равна вероятности того, что для случайно выбранных 𝑥
1
∈ 𝐶
1
и 𝑥
2
∈ 𝐶
0
бу-
дет выполнено: 𝑝(𝑥
1
) > 𝑝(𝑥
0
). Где 𝐶
1
и 𝐶
0
– единичный и нулевые классы соответственно,
а 𝑝(𝑥) – вероятность принадлежности классу 𝐶
1
, присвоенная классификатором.
7
Результаты экспериментального исследования
7.1
Характеристики программной реализации
Программная реализация
1
выполнена на языке Python 2.7.9, с использованием биб-
лиотек: pandas [31], numpy [32], а также библиотек, которые были указаны в описаниях
алгоритмов.
7.2
Метод оценки алгоритмов и подбора параметров
Качество модели 𝜇 оценивалось на кроссвалидации по 12 фолдам,
которая заклю-
чается в следующем:
выборка 𝑋 длины 𝐿 разбивается на 12 непересекающихся бло-
1
https://github.com/ValeryKi/ECG_repository
23
ков одинаковой (или почти одинаковой) длины,
таким образом,
чтобы в каждом бло-
ке находились разные пациенты и блоки были почти одинаковой длины 𝑘
1
, . . . , 𝑘
12
:
𝑋
𝐿
= 𝑋
𝑘
1
1
∪ · · · ∪ 𝑋
𝑘
12
12
, 𝑘
1
+ · · · + 𝑘
12
= 𝐿. Каждый блок по очереди становится контроль-
ной подвыборкой,
при этом обучение производится по остальным 11 блокам.
Качество
определяется в результате объединения ответов на контрольных подвыборках в единый
вектор:
𝐶𝑉 (𝜇, 𝑋
𝐿
) = 𝑄
(︀
12
⋃︁
𝑛=1
𝜇(𝑋
𝐿
∖ 𝑋
𝑘
𝑛
𝑛
, 𝑋
𝑘
𝑛
𝑛
), 𝑋
𝐿
)︀
.
Кроме оценки модели при помощи кросс-валидации также использовалось оценива-
ние модели на отложенной выборке. Оценивание модели на отложенной выборке позво-
ляет оценивать качество предложенных подходов при уже настроенных параметрах.
При обучении моделей настраивались следующие параметры:
LogisticRegression −
C (коэффициент регуляризации),
XGBClassifier − learning_rate (скорость обучения),
n_estimators (число деревьев),
нейронные сети − learning_rate (скорость обучения).
Остальные параметры были настроены по умолчанию. Параметры подбирались по сет-
кам. В качестве итоговых параметров выбирались те, при которых качество модели на
кросс-валидации является наилучшим, или перестает существенно улучшаться относи-
тельно критерия качества по пациентам.
В качестве итоговой модели выбиралась та,
которая дает наилучшее качество по пациентам.
7.3
Полученные результаты
Обозначим реализованные методы следующим образом.
BISPECTRUM − алгоритм, основанный на биспектральном разложении сигнала.
WORDS − алгоритм,
основанный на вейвлет-преобразовании сигнала (без исполь-
зования word2vec признаков).
WORDS_W2V − алгоритм,
основанный на вейвлет-преобразовании сигнала (с ис-
пользованием word2vec признаков).
R_WINDOW − алгоритм, основанный на анализе сегментов сигнала вокруг его R-
пиков.
MIX − алгоритм, основанный на 3-х различных группах признаков.
HRV − алгоритм, основанный на признаках, полученных из HRV сигнала.
MAJORITY − ансамбль алгоритмов, выполненный по методу голосование по боль-
шинству.
EM − ансамбль алгоритмов, выполненный по EM-методу.
24
Обозначим алгоритмы классификации как:
xgb − xgboost,
lr − логистическая ре-
грессия, 𝑛𝑛 - нейронная сеть.
CV обозначает качество модели на кросс-валидации, а T обозначает качество модели
на отложенной тестовой выборке.
Полученные результаты приведены в таблицах 4, 5 и 6.
Метод
Алгоритм
Качество
Качество
Классификации
по пациентам (CV)
по пациентам (T)
BISPECTRUM
nn
0.7207
0.7432
WORDS
lr
0.741
0.7699
WORDS_W2V
lr
0.7501
0.7856
R_WINDOW
nn
0.7602
0.7896
MIX
lr
0.744
0.733
MIX
xgb
0.7632
0.7878
HRV
lr
0.7632
0.744
HRV
xgb
0.7693
0.8029
MAJORITY
0.806
0.7605
EM
0.8108
0.8419
Таблица 4: Результаты экспериментальных исследований
Метод
Алгоритм Классификации
Roc-Auc (CV)
Roc-Auc (T)
BISPECTRUM
nn
0.7418
0.724
WORDS
lr
0.8
0.9075
WORDS_W2V
lr
0.8
0.9087
R_WINDOW
nn
0.7988
0.9444
MIX
lr
0.8228
0.9234
MIX
xgb
0.8042
0.9479
HRV
lr
0.6319
0.7506
HRV
xgb
0.744
0.877
MAJORITY
EM
0.8738
0.9737
Таблица 5: Результаты экспериментальных исследований
25
Метод
Алгоритм Классификации
F-мера (CV)
F-мера (T)
BISPECTRUM
nn
0.7244
0.7979
WORDS
lr
0.6967
0.7708
WORDS_W2V
lr
0.6990
0.7776
R_WINDOW
nn
0.703
0.789
MIX
lr
0.7057
0.7811
MIX
xgb
0.70256
0.7878
HRV
lr
0.592
0.7490
HRV
xgb
0.6620
0.8029
MAJORITY
0.7784
0.8807
EM
0.7784
0.9024
Таблица 6: Результаты экспериментальных исследований.
Из таблиц 4, 5 и 6 следует, что качество на кросс-валидации по всем метрикам как
правило ниже,
чем качество на отложенной тестовой выборке.
Данное явление может
быть объяснено следующими причинами.
Во-первых,
на кросс-валидации использова-
лось меньше данных для обучения,
а обучение на полной выборке позволяет добиться
лучшего качества. Во-вторых, известно, что первая и вторая выборка содержат разные
кардиограммы, однако существует вероятность, что некоторые пациенты из обучающей
выборки встречались и в тестовой,
а следовательно содержат похожие кардиограммы,
в то время как на кросс-валидации одни и те же пациенты не попадали одновременно
в обучение и в контроль. Учитывая последний факт, следует отметить, что важно оце-
нивать качество не только на отложенной тестовой выборке, но и на кросс-валидации.
Как видно из Таблицы 4, алгоритм, который основан на биспектральном разложении
сигнала, показывает худшее качество по пациентам на кросс-валидации. На отложенной
тестовой выборке качество не является худшим,
и сопоставимо с качеством по осталь-
ным алгоритмам.
Заниженное качество по пациентам может быть связано с тем,
что
обучающая выборка слишком мала для нейронной сети и для того, чтобы получить бо-
лее высокое качество необходима выборка большего размера. Однако, следует заметить,
что качество не слишком низкое,
что позволяет сделать вывод,
что анализ изображе-
ний, полученных на основе биспектрального разложения сигнала может использоваться
для определения заболеваний по ЭКГ. В будущем этот метод может быть исследован на
предмет повышения качества классификации. Стоит отметить, что этот метод показал
лучшее качество по F-мере среди одиночных алгоритмов на кросс-валидации, и одно из
лучших на тестовой выборке.
Данный факт дает повод предположить,
что этот метод
26
верно идентифицирует пациентов с большим количеством кардиограмм.
Из полученных результатов следует, что при добавлении word2vec признаков модель
работает лучше практически по всем выбранным критериям качества (на отложенной
тестовой выборке модель по критерию Roc-Auc работает также).
Однако прирост не
слишком существенен. Cледует заметить, что методу word2vec как привило необходимо
много данных для того,
чтобы получить высокое качество.
Поэтому,
возможно,
что
если бы объем выборки был больше,
то удалось бы получить более высокое качество
при добавлении этих признаков.
Модель,
основанная на 3-х различных группах признаков показывает лучшее ка-
чество по метрике Roc-Auc на кросс-валидации.
На отложенной тестовой выборке она
также является лучшей. Это может быть связано с тем, что она может правильно опре-
делять пациентов у которых много кардиограмм,
и при подборе правильного порога
может увеличиться значение F-меры.
Наилучшее качество по пациентам на кросс-валидации показывает модель основан-
ная на HRV-сигнале. Однако на отложенной тестовой выборке ее качество сильно зави-
сит от используемого алгоритма классификации. По F-мере данная модель показывает
худшее качество на кросс-валидации и худшее качество на отложенной тестовой вы-
борке в случае использования логистической регрессии.
Стоит отметить,
что данный
алгоритм показывает лучшее качество в случае использования градиентного бустинга
как на кросс-валидации, так и на отложенной тестовой выборке. Данный факт позволяет
сделать вывод, что зависимость между целевой переменной и признаками, входящими в
эту модель не является линейной. Можно сказать, что в случае использования градиент-
ного бустинга данный алгоритм дает лучшее качество по пациентам среди одиночных
алгоритмов.
Проанализировав результаты в таблице для разных метрик можно сделать вывод,
что алгоритмы работают по-разному и правильно классифицируют разных пациентов.
Данный результат позволяет сделать вывод, что применив ансамбль алгоритмов удаст-
ся улучшить качество классификации,
что и доказывают результаты для ансамблей
алгоритмов как и на кросс-валидации, так и на отложенной выборке. С помощью EM-
алгоритма качество удалось существенно увеличить по всем исследуемым метрикам,
как на кросс-валидации так и на отложенной выборке,
что позволяет сделать вывод о
том, что ансамбль алгоритмов при использовании EM-алгоритма работает значительно
лучше отдельных. Однако, при помощи голосования по большинству не удалось повы-
сить качество по пациентам на отложенной тестовой выборке, но повысилась F-мера. На
кросс-валидации голосование по большинству увеличило значения обоих метрик, поэто-
му однозначного решения о его неприменимости в данной задаче принимать не следует.
27
Следует также отметить, что EM-алгоритм позволяет существенно улучшить качество
по Roc-Auc по сравнению с индивидуальными алгоритмами.
8
Заключение
В ходе данной работы была проделано следующее.
∙ Реализовано 5 различных методов обнаружения ишемической болезни сердца по
ЭКГ.
∙ Предложена модификация одного из существующих методов,
улучшающая каче-
ство классификации.
∙ Предложен новый метод для классификации ишемической болезни сердца.
∙ Проведено экспериментальное сравнительное исследование реализованных мето-
дов.
∙ Предложены способы ансамблирования реализованных алгоритмов.
∙ Исследована применимость EM-алгоритма как метода ансамблирования.
Основными результатами данной работы являются следующие выводы.
∙ word2vec позволяет увеличить качество классификации метода основанного на
вейвлет-преобразовании.
∙ Биспектральное разложение может быть использовано для классификации ише-
мической болезни сердца.
∙ Наилучшее качество по Roc-Auc среди одиночных алгоритмов показывает алго-
ритм, основанный на 3-х различных признаковых пространствах.
∙ Наилучшее качество по F-мере показывает алгоритм, основанный на биспектраль-
ном разложении.
∙ Наилучшее качество по пациентам показывает алгоритм,
основанный на HRV-
сигнале, при использовании в качестве классификатора градиентного бустинга.
∙ EM-алгоритм применим для ансамблирования и в данном случае показывает наи-
лучшее качество классификации по всем выбранным метрикам.
28
∙ При использовании оборудования CardioQvark возможно определить ишемиче-
скую болезнь сердца с точностью свыше 0.8 по качеству по пациентам, с точностью
свыше 0.77 по F-мере и с точностью cвыше 0.87 по Roc-Auc.
Работа была представлена на международной XXIV научной конференции «Ломоносов
- 2017» [33].
29
Список литературы
[1]
В.В.
Горбачев Ишемическая Болезнь Сердца.
- Минск:
Выш.
шк.,
2008.
- 479 с.
-
ISBN 978-985-06-1433-9
[2]
Всемирная организация здравоохранения. Центр СМИ. 10 ведущих причин смерти
в мире.
[Электронный ресурс]
// Всемирная организация здравоохранения.
URL:
http://www.who.int/mediacentre/factsheets/fs310/ru/ (дата обращения: 01.05.2017).
[3]
Rangayyan R. M. Biomedical signal analysis. – John Wiley & Sons, 2015. – Т. 33.
[4]
Dua S. et al. Novel classification of coronary artery disease using heart rate variability
analysis //Journal of Mechanics in Medicine and Biology. – 2012. – Т. 12. – №. 04. – С.
1240017.
[5]
Giri
D.
et al.
Automated diagnosis of
coronary artery disease affected patients using
LDA,
PCA,
ICA and discrete wavelet transform //Knowledge-Based Systems.
– 2013.
– Т. 37. – С. 274-282.
[6]
Jones E., Oliphant T., Peterson P. SciPy: open source scientific tools for Python. – 2014.
[7]
Hamilton P. Open source ECG analysis //Computers in Cardiology, 2002. – IEEE, 2002.
– С. 101-104.
[8]
Carlos
Carreiras.
BioSPPy − Biosignal
Processing in Python.
[Электронный ре-
сурс] //BioSPPy’s documentation.
URL: http://biosppy.readthedocs.io/en/stable/ (да-
та обращения: 01.05.2017).
[9]
Rawald T., Sips M., Marwan N. PyRQA—Conducting recurrence quantification analysis
on very long time series efficiently //Computers & Geosciences. – 2016.
[10]
Kantelhardt J.
W.
et al.
Detecting long-range correlations with detrended fluctuation
analysis //Physica A: Statistical Mechanics and its Applications. – 2001. – Т. 295. – №.
3. – С. 441-454.
[11]
Christopher Sch¨
olzel.
Nolds.
[Электронный ресурс]
//
Nolds’
documentation.
URL:
https://cschoel.github.io/nolds/ (дата обращения: 01.05.2017).
[12]
Pedregosa F.
et
al.
Scikit-learn:
Machine learning in Python //Journal
of
Machine
Learning Research. – 2011. – Т. 12. – №. Oct. – С. 2825-2830.
30
[13]
Chen T., Guestrin C. XGBoost: Reliable large-scale tree boosting system //Proceedings
of
the 22nd SIGKDD Conference on Knowledge Discovery and Data Mining,
San
Francisco, CA, USA. – 2016. – С. 13-17.
[14]
Hjorth B. EEG analysis based on time domain properties //Electroencephalography and
clinical neurophysiology. – 1970. – Т. 29. – №. 3. – С. 306-310.
[15]
De Cooman T. et al. Online seizure detection in adults with temporal lobe epilepsy using
single-lead ECG //Signal
Processing Conference (EUSIPCO),
2014 Proceedings of the
22nd European. – IEEE, 2014. – С. 1532-1536.
[16]
Успенский В. М. Информационная функция сердца. Теория и практика диагности-
ки заболеваний внутренних органов методом информационного анализа электро-
кардиосигналов. М.: Экономика и информатика, 2008. 116 с.
[17]
Wang J.
et
al.
Bag-of-words
representation for
biomedical
time series
classification
//Biomedical Signal Processing and Control. – 2013. – Т. 8. – №. 6. – С. 634-644.
[18]
Liu C. L. A tutorial of the wavelet transform //NTUEE, Taiwan. – 2010.
[19]
Wasilewski
F.
Pywavelets:
Discrete
wavelet
transform in
python
//Available:
http://www.pybytes.com/pywavelets. – 2010.
[20]
Mikolov T.
et al.
Efficient estimation of
word representations in vector space //arXiv
preprint arXiv:1301.3781. – 2013.
[21]
Rehurek R.,
Sojka P.
Software framework for topic modelling with large corpora //In
Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks.
–
2010.
[22]
Ripoll
V.
J.
R.
et
al.
ECG assessment
based on neural
networks
with pretraining
//Applied Soft Computing. – 2016. – Т. 49. – С. 399-406.
[23]
Goodfellow I., Bengio Y., Courville A. Deep learning. Book in preparation for MIT Press
//URL< http://www. deeplearningbook. org. – 2016.
[24]
Team T. T. D. et al. Theano: A Python framework for fast computation of mathematical
expressions //arXiv preprint arXiv:1605.02688. – 2016.
[25]
Dieleman S. et al. Lasagne: First release //Zenodo: Geneva, Switzerland. – 2015.
[26]
Civera M., Zanotti Fragonara L., Surace C. Using bispectral analysis and neural networks
to localise cracks in beam-like structures. – 2016.
31
[27]
Nikias
C.
L.,
Raghuveer
M.
R.
Bispectrum estimation:
A digital
signal
processing
framework //Proceedings of the IEEE. – 1987. – Т. 75. – №. 7. – С. 869-891.
[28]
Al-Fahoum A.,
Al-Fraihat
A.,
Al-Araida A.
Detection of
cardiac
ischaemia using
bispectral
analysis approach //Journal
of
medical
engineering & technology.
− 2014.
− Т. 38. − №. 6. − С. 311-316.
[29]
Swami A., Mendel J., Nikias C. L. HOSA toolbox of Matlab 5.1 //MathWorks, Natick,
USA. – 1993.
[30]
Dawid A. P., Skene A. M. Maximum likelihood estimation of observer error-rates using
the EM algorithm //Applied statistics, 1979, С. 20-28.
[31]
McKinney W. et al. Data structures for statistical computing in python //Proceedings
of the 9th Python in Science Conference. – van der Voort S, Millman J, 2010. – Т. 445.
– С. 51-56.
[32]
Walt
S.,
Colbert
S.
C.,
Varoquaux G.
The NumPy array:
a structure for
efficient
numerical computation //Computing in Science & Engineering. – 2011. – Т. 13. – №. 2.
– С. 22-30.
[33]
Кибитова В.Н. Ансамбль алгоритмов для определения ишемической болезни сердца
// Сборник тезисов XXVI международной научной конференции Ломоносов−2017.
Издательский отдел факультета вычислительной математики и кибернетики МГУ
имени М.В. Ломоносова, 2017. С. 15-17.
32
