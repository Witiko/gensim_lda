САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ
ФАКУЛЬТЕТ ПРИКЛАДНОЙ МАТЕМАТИКИ – ПРОЦЕССОВ УПРАВЛЕНИЯ
КАФЕДРА ТЕХНОЛОГИИ ПРОГРАММИРОВАНИЯ
Чуриков Никита Сергеевич
Выпускная квалификационная работа бакалавра
Предсказание атрибутов документов
в системе документооборота
Направление 010400
Прикладная математика и информатика
Заведующий кафедрой,
кандидат технических наук,
доцент
Блеканов И. С.
Научный руководитель,
кандидат физ.-мат. наук,
доцент
Добрынин В. Ю.
Рецензент,
руководитель научной лаборатории Digital Design
Ашихмин И. А.
Санкт-Петербург
2017
Содержание
Введение
4
Обзор литературы .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
4
Постановка задачи
6
Глава 1. Обзор Docsvision
6
Глава 2. Загрузка данных
8
§2.1. Данные из document.json
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
9
§2.2. Данные из resolution.json
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
10
Глава 3.
Описание алгоритмов машинного обучения используе-
мых в работе
14
§3.1. Random forest .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
14
§3.1.1 Выделение важных атрибутов .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
14
§3.2. Stochastic gradient descent
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
15
§3.3. Линейная регрессия
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16
§3.3. Word2vec
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
16
§3.4. LabelEncoding .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
§3.5. One Hot Encoding .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
17
§3.6. Алгоритмы понижения размерности .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
§3.6.1 PCA .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
18
§3.6.2 MDS
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
§3.6.3 TSNE .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
19
§3.7 Random oversampling .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
20
Глава 4. Метрики
20
Глава 5. Решения задач
22
§5.1. Подготовка категориальных переменных
.
.
.
.
.
.
.
.
.
.
.
.
.
22
2
§5.1.1 Понижение размерности
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
23
§5.2. Рекомендация исполнителя .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
25
§5.3. Прогнозирование времени исполнения документа
.
.
.
.
.
.
.
.
26
Глава 6. Эксперименты
26
§6.1. Прогнозирование времени исполнения документа
.
.
.
.
.
.
.
.
26
§6.2. Рекомендация исполнителя .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
29
§6.2.1 Первый уровень исполнения .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
31
§6.2.2. Второй уровень исполнения .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
34
§6.2.3. Третий уровень исполнения .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
39
Выводы
42
Заключение
42
Список литературы
42
3
Введение
Система электронного документооборота (СЭД) [1]
– это система ав-
томатизации процессов работы с документами,
поддерживающая основные
функции документооборота, такие как: хранение, создание, поиск.
Первые продукты такого рода появились в 80-х годах прошлого века, в
виде запасного хранилища бумажных документов.
Позже, была добавлена функциональность для работы с электронными
документами,
такими как:
электронная почта,
поручения,
документы,
изоб-
ражения и т.д.
И сегодня современные СЭД стараются идти в ногу со временем,
до-
бавляя такую функциональность,
как извлечение текста из изображений [2]
и автоматическая классификация текстовых документов [3].
В представленной дипломной работе предлагается два новых подхода к
расширению функциональности СЭД Digital Design [4] Docsvision [5]:
1.
Рекомендация исполнителя для задания;
2.
Прогнозирование времени, которое потребуется на обработку документа.
Для решения этих задач компания Digital
Design предоставила набор
документов правительства Мурманской области за два года.
На их основе
был построен прототип системы обработки документов.
Обзор литературы
Для повышения теоретических знаний в области машинного обучения
и информационного поиска, использовалась работа �Введение в информаци-
онный поиск� К.
Маннинга [6],
и в первую очередь глава 14 �Классифика-
ция в векторном пространстве� и глава 18 �Разложение матриц и латентно-
семантическое индексирование�. Для развития практических навыков в обла-
сти машинного обучения и анализа данных использовалась книга В. Маккини
4
�Python для анализа данных� [7]. В ней последовательно проиллюстрирова-
ны подходы для манипулирования и визуализации данных в python. Богатая
коллекция решений классических задач представлена на сайте kagge [8].
В
частности, для построения модели регрессии, полезен разбор задачи по про-
гнозированию цен за дома [9]. Для ознакомления с алгоритмом Random forest,
очень помогла классическая работа Breiman L. �Random forests� [10], а также
для понимания того,
как считается информативность атрибутов в алгорит-
ме использовалась статья Louppe,
G.
�Understanding variable importances in
forests of randomized trees� [11]. В этой статье приводится достаточно подроб-
ное описание того,
как в случайных лесах выделяются важные атрибуты.
В
понимании задачи и структуры данных,
в предоставленном датасете,
значи-
тельную роль сыграла документация API Docsvision и интерактивная демон-
страция создания документа в системе Docsvision [12].
О борьбе с несбалан-
сированностью данных подробно и практично описано в статье �8 методов
борьбы с несбалансированностью данных� [13]: в этой статье приводится ме-
тодики по уменьшению несбалансированности данных, такие как oversampling
(генерирование атрибутов малых классов) и разбиение выборки на сбаланси-
рованные подвыборки.
5
Постановка задачи
В контексте данной работы,
под документом будем понимать следую-
щее:
Документ – это история обработки некоторого официального доку-
мента или поручения.
В системе электронного документооборота Docvision
он описывается двумя обязательными файлами содержащими метаданные:
document.json и resolution.json,
и одним или несколькими дополнительными
файлами,
которые могут быть изображением,
текстовым файлом,
презента-
цией и т.п.
Рассмотрим задачи, которые стоят перед нами:
1.
С помощью методов машинного обучения необходимо построить модель,
которая будет рекомендовать сотрудника-исполнителя задачи исходя из
данных документа;
2.
Построить модель, для прогнозирования длительности исполнения доку-
мента.
Специфика обеих задач в том, что для их решения в качестве атрибутов
используются категориальные переменные.
Поскольку стандартные методы,
вроде One hot encoding подходят при небольшом количестве значений, необ-
ходимо найти иной способ представления переменных такого рода.
Глава 1. Обзор Docsvision
Перед тем,
как перейти к данным,
для наглядности,
обсудим то,
как
выглядит и работает система документооборота компании Digital Design
Docsvision.
Схема работы с документом представлена на Рис.
1.
При созда-
нии документа, есть возможность указать его тип (письмо, документ, и т.д.),
краткое описание, от кого пришел файл, кому, автор документа, подразделе-
ние, в котором будет зарегистрирован документ и его категория. Это данные,
6
которые хранятся в файле document.json.
Созданное задание представлено на Рис.
2.
В созданном задании,
есть
такие параметры как время начала и окончания, кто будет работать над зада-
нием и описание поручения. Эти данные хранятся в файле resolution.json.
В следующей секции будет рассмотрена структура этих файлов, как они
выглядят, какие переменные будут извлекаться.
Рис. 1. Созданный документ
7
Рис. 2. Создание задания
Глава 2. Загрузка данных
Каждый документ в СЭД Docsvision описывается с помощью метадан-
ных,
хранящихся в файлах document.json и resolution.json.
Эти файлы
имеют фиксированную структуру и каждый объект в файле имеет свой фик-
сированный набор атрибутов.
В основном,
это категориальные переменные,
но среди них имеются значения,
уникальные для организации и значения
фиксированные в системе.
8
Категориальные переменные задаются в виде UUID [14]
– universally
unique identifier, которое является уникальным значением, принимающим сле-
дующий вид:
xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx,
где M и N задают вер-
сию идентификатора,
а x является случайной латинской буквой или циф-
рой ([a
z0
9]). Вероятность повторения этих идентификаторов очень низкая
и поэтому их используют для кодирования различных объектов в промышлен-
ном программировании.
Т.е.
у каждого объекта,
вроде категории,
человека,
документа, файла и т.д. имеется свое уникальное значение.
Значения, фиксированные в системе, кодируются целочисленными зна-
чениями и едины для всех организаций.
§2.1. Данные из document.json
В файле document.json хранятся метаданные описывающие документ
заданные при его регистрации в системе:
категория,
регистратор,
краткое
описание и т.д.
Представленные в файле document.json метаданные рассматриваются в
данной работе как категориальные переменные.
Рассмотрим статистику переменных из document.json представленную
в Таблице 1.
Краткое описание каждой из переменных приведено в столбце
Описание. Со структурой можно ознакомиться в Приложении A.
По данным Таблицы 1 видно, что у нас имеется восемь переменных, семь
из которых – категориальные,
одна переменная является строкой,
а также
Categories представляет из себя список.
9
Название
Тип
Количество
Описание
Content
string
7193 words
Краткое описание документа
Urgency
UUID
4
Устанавливает срочность
документа:
Обычная, Срочно,
В.срочно, Оперативно
AccessType
UUID
3
Уровень доступа документа:
Общий, Конфиденциально, ДСП
Categories
List of UUIDs
157
К какой категории
относится документ
RegistratorDepartment
UUID
66
Департамент, в котором был
зарегистрирован документ
Registrator
UUID
159
Тот, кто зарегистрировал
документ
Operator
UUID
145
Тот, кто создал документ
Addressee.Reference
UUID
5007
Ссылка на человека или отдел
Таблица 1. Статистика переменных
§2.2. Данные из resolution.json
Файл resolution.json содержит в себе сведения о прохождении докумен-
том цепочки заданий на исполнение в организации.
Задания в файле resolution.json имеют рекурсивную структуру,
при-
мер которой представлен в листинге 1.
"Tasks": [{
"Parts": [{
"Executors": [
"Tasks": [...],
}]]
"Executes": {,
"Name": "sample string 12",
"Id": "200e825a-796b-4580-bb3d-417e7676d2fa"
},
"Appointed": {
"Name": "sample string 12",
"Id": "200e825a-796b-4580-bb3d-417e7676d2fa"
},
]
Listing 1. Рекурсивная структура заданий
Имеется два вида исполнителя: Appointed и Executes. Первый обознача-
ет человека, на которого было назначено задание, а второй – непосредствен-
ного исполнителя задания. Исполнители могут отличаться в том случае, если
10
начальник, на которого назначено задание, передал его своему подчиненному
для непосредственного исполнения.
Рассмотрим распределение количества выполненных заданий для этих
двух переменных на Рис. 3.
Видно, что в данном датасете всего в 43 случаях задание выполнил не
тот, кто был назначен. В семи случаях это обращение граждан, в тридцати –
письмо и пяти – поручение. Эти результаты подтверждают, что обычно, если
человек,
которому назначено задание и тот кто непосредственно выполнил,
отличаются, то в подавляющем большинстве случаев это начальник передал
задание подчиненному.
Не трудно заметить, что распределения очень похожи, но это не значит,
что эти значения всегда одинаковые,
потому что из
370000 заданий,
в 43
случаях Appointed и Executes разные.
Рис. 3. По оси X интервалы с количеством выполненных заданий, а по Y сколько заданий в каждой корзине
11
Вспомним теперь,
что задания имеют рекурсивный характер и могут иметь
много уровней вложенности.
Посмотрим,
сколько всего может быть уровней
назначения:
Уровень
Количество заданий на уровне
1
115772
2
154495
3
69980
4
24802
5
5365
6
706
7
51
8
8
Таблица 2. Количество уровней исполнения в резолюции
Как можно увидеть в таблице 2 всего имеется 8 уровней в представлен-
ном датасете.
На Рис.
29,
в Приложении С,
представлено,
сколько заданий
выполнено для соответствующих уровней.
Нами будут рассмотрены только первые 3 уровня,
представленные на
Рис. 4, 5, 6.
На графиках, интервалы по оси y определяют количество заданий вы-
полненных исполнителями, а по оси x – количество исполнителей, попавших
в этот интервал.
Рис. 4.
12
Рис. 5.
Рис. 6.
13
Глава 3.
Описание алгоритмов машинного обучения ис-
пользуемых в работе
§3.1. Random forest
Алгоритм Random forest [15,
16,
10]
является сегодня универсальным
средством для решения задач связанных с машинным обучением.
Основан-
ный на ансамбле решающих деревьях,
его можно использовать как для за-
дач классификации, так и для регрессии. Он довольно прост для понимания,
устойчив к переобучению и реализован на многих языках программирования.
Однако,
несмотря на то,
что в теории,
он способен работать с любыми
категориальными переменными,
на практике,
если передавать ему классы
закодированные через Label
Encoder,
то он будет считать,
что классы 1 и
2 близки, а 9 и 10 далеки от них. Поэтому, как правило, используют One hot
encoding.
Данный метод был выбран, потому что он не зависит от масштаба дан-
ных.
Воспользуемся реализацией данного алгоритма для регрессии и класси-
фикации из библиотеки sklearn [17]. Из параметров, для классификации, уста-
новим class_weight=’balanced’, остальные параметры оставим по умолча-
нию.
§3.1.1. Выделение важных атрибутов
В моделях, основанных на решающих деревьях, можно выделить атри-
буты, которые привносят наибольшее количество информации [11].
Imp(X
m
) = 1/N
T
X
T
X
t2T :v(s
t
)=X
m
p(t)
i(s
t
, t)
где N
T
– количество узлов в дереве T , t – узел в дереве, p(t) =
N
t
N
– количество
переменных,
достигающих узел t,
v(s
t
) – переменная,
определяющая разби-
14
ение в узле t.
i(s
t
, t) определяет величину изменения неопределенности в
узле t:
i(s
t
, t) = i(t)
p
L
i(t
L
)
p
R
i(t
R
)
где i(t) определяет коэффициент неопределенности (коэффициент Gini,
эн-
тропию или дисперсию целевой переменной Y ), p
L
=
N
t
L
N
t
и p
R
=
N
t
R
N
t
опреде-
ляют пропорции: сколько переменных идут в левый или правый узел соответ-
ственно.
В качестве коэффициента неопределенности i(t) был выбран коэффи-
циент Gini.
i(t) = 1
X
c2C
p
2
c
, где p
c
– вероятность класса c.
Реализация этой меры есть в классе RandomForest, в библиотеке sklearn.
§3.2. Stochastic gradient descent
Стохастический градиентный спуск [18, 19] простой и эффективный под-
ход к обучению линейных классификаторов.
Математическая формулировка: имея набор тренировочных данных:
{(x
i
, y
i
)}
N
i=1
,
где x
i
2 R
n
и y
i
2 {0, 1}
необходимо построить линейную функцию f (x) = w
T
x + b с весами w 2 R
m
и порогом b 2 R. Типичный способ нахождения весов – минимизация целевой
функции при помощи градиентного спуска на тренировочном множестве.
E (w, b) =
1
n
n
X
i=1
L (y
i
, f (x
i
)) + ↵R (w)
где L – это функция потерь, которая обучает модель, а R – это параметр регу-
ляризации (поправка),
которая штрафует модель,
↵ > 0 – неотрицательный
гиперпараметр.
15
Разные L соответствуют разным классификаторам. Мы будем брать L,
которая соответствует логарифму от функции правдоподобия
L =
n
X
i=1
log
✓
1
exp (
y
i
f (x
i
)) + 1
◆
Данный метод хорошо подходит для данных, которые находятся в одном
масштабе,
поэтому будем использовать его для значений X,
полученных с
помощью One hot encoding.
Реализацию этого метода возьмем из библиотеки sklearn.
Из парамет-
ров, установим class_weight=’balanced’, остальные параметры оставим по
умолчанию.
§3.3. Линейная регрессия
Линейная регрессия [20] – это классический алгоритм для прогнозирова-
ния данных. Ее задача – построить прямую (гиперплоскость в случае многих
переменных) через точки из тренировочного множества по заданным наблю-
дениям.
Реализация данного алгоритма была взята из библиотеки sklearn со
стандартными параметрами.
§3.3. Word2vec
Word2Vec [21, 22, 23] – технология от Google, которая нацелена на стати-
стическую обработку больших массивов текстовой информации. W2V собира-
ет статистику совместного появления слов в предложениях,
а затем обучает
нейронную сеть по алгоритму skip-gramm, описанному в оригинальной статье.
W2V предлагает подход к представлению слов, который учитывает их поло-
жение в предложении,
в отличии от классического подхода – мешка слов.
В
результате получаются вектора слов в N -мерном пространстве.
Мы попробуем обучить модель на имеющихся текстовых данных
(Content) и на выгруженных документах с сайта правительства [24, 25].
16
Реализация этого метода была взята из библиотеки gensim со стандарт-
ными параметрами.
§3.4. LabelEncoding
Данный подход интерпретирует категориальные переменные,
как упо-
рядоченный целочисленный список. Как правило, это не так и кодируя таким
образом переменные, привносится лишняя информация.
Данный подход имеет серьезные недостатки такие как:
1.
В данные привносится не существующая информация;
2.
Нет возможности работать со списочными категориальными переменны-
ми.
Однако у метода есть серьезный плюс по причине которого он все таки
рассматривается в данной работе: данный метод хранит данные относящиеся
к одной переменной в одном столбце.
Метод проиллюстрирован в листинге 2.
In
[17]: cats = [’Москва’, ’Санкт-Петербург’, ’Нижний-Новгород’, ’Москва’]
In
[18]: from sklearn.preprocessing import LabelEncoder
In
[19]: le = LabelEncoder()
In
[20]: le_cats = le.fit_transform(cats)
In
[21]: le_cats
Out [21]: array([0, 2, 1, 0])
Listing 2. Использование LabelEncoder из библиотеки sklearn
§3.5. One Hot Encoding
One Hot Encoding преобразовывает переменные в бинарные (или так на-
зываемые, dummy values). Т.е. каждое значение категориальных переменных
будет иметь свой столбец,
где каждая строка обозначает наличие значения
переменной в документе (значение 1) или отсутствие (значение 0). Метод про-
иллюстрирован в листинге 3.
17
Данный метод также обладает недостатками:
1.
в ходе его работы теряется связь между переменными;
2.
при большом количестве значений значительно повышается размерность.
In
[22]: cats = [’Москва’, ’Санкт-Петербург’, ’Нижний-Новгород’, ’Москва’]
In
[23]: import pandas as pd
In
[24]: pd.get_dummies(cats)
Out [24]:
’Москва’
’Нижний-Новгород’
’Санкт-Петербург’
0
1.0
0.0
0.0
1
0.0
0.0
1.0
2
0.0
1.0
0.0
3
1.0
0.0
0.0
Listing 3. One Hot Encoding используя pandas
Однако указанные минусы в нашем случае можно компенсировать:
в
разделе ниже будут рассмотрены варианты, как измерить дистанцию между
людьми и другими категориальными переменными.
§3.6. Алгоритмы понижения размерности
Рассмотрим методы,
которые позволят нам сохранить информацию о
категориальных переменных и при этом получить одномерное представле-
ние.
Для работы этих методов,
необходимо ввести меру расстояния между
значениями. Нам необходимо построить матрицу расстояний для переменных
и понизить ее размерность описанными ниже методами.
Так, например, с городами, в качестве меры расстояния можно было бы
взять дистанцию двух городов или среднее время на дорогу,
в зависимости
от задачи.
§3.6.1. PCA
Метод главных компонент (PCA) [26,
27]
является линейным методом
и его основная идея,
в том,
чтобы спроецировать данные на гиперплоскость
с наименьшей ошибкой проектирования или,
иначе с сохранением большей
части дисперсии данных.
18
Данный метод находить только линейные подпространства исходного
пространства,
которые �объясняют� данные с высокой точностью.
Но,
как
правило, данные имеют нелинейную структуру, поэтому также будут исполь-
зованы нелинейные методы понижения размерности.
Имплементация этого метода была взята из библиотеки sklearn, с уста-
новленным параметром количества компонент n_components=1,
остальные
параметры по умолчанию.
§3.6.2. MDS
Многоразмерное масштабирование (MDS) проецирует точки в простран-
ство малой размерности, так чтобы минимизировать несходство между попар-
ными расстояниями в исходном пространстве и пространстве малой размер-
ности.
Данный метод был выбран, потому что он сохраняет глобальную струк-
туру данных.
Реализация данного метода была взята из библиотеки sklearn, с установ-
ленным параметром количества компонент n_components=1 и не сходством
(dissimilarity),
для структур,
которые представляют из себя матрицу ди-
станций равным ’precomputed’,
а для матриц,
где матрица дистанций не
была построена ’euclidean’.
§3.6.3. TSNE
Основная идея t-SNE [28]
конвертировать близость каждой пары то-
чек в исходном пространстве R
D
большой размерности в вероятность того,
что одна точка данных связана с другой точкой так,
как с ее соседом.
T в
названии алгоритма означает,
что при вычислении градиента используется
t-распределение Стьюдента.
Было принято решение использовать этот метод, потому что он сохра-
няет локальную структуру данных.
19
Реализация данного метода была взята из библиотеки sklearn,
с уста-
новленным параметром количества компонент n_components=1 и мерой похо-
жести metric, для структур, которые представляют из себя матрицу дистан-
ций равным ’precomputed’,
а для матриц,
где матрица дистанций не была
построена ’euclidean’, также, предварительно, вычисляется понижение раз-
мерности с помощью метода главных компонент (init=’pca’).
§3.7. Random oversampling
Random oversampling применяется для задач классификации с несбалан-
сированными классами.
Его назначение в том,
чтобы повысить количество
наблюдаемых значений для редких классов,
т.е.
редкие наблюдения классов
он случайным образов повторяет.
Однако, применение данного метода может вести к переобучению, если
классы слишком несбалансированы.
Реализация данного метода была взята из библиотеки imblearn.
Глава 4. Метрики
Рассмотрим метрики для определения точности классификаторов и ре-
грессии.
Для классификации будем использовать точность(P ), полноту(R) и F
1
метрики:
P =
tp
tp + f p
(1)
R =
tp
tp + f n
(2)
F 1 =
2P R
P + R
(3)
Где (1) определяет долю релевантных документов среди найденных, (2)
20
– доля релевантных документов среди всех релевантных,
(3) – среднее гар-
моническое между двумя величинами.
Эти величины получаются для бинарной классификации.
При много-
классовой, для каждого класса будет посчитана своя точность, полнота и F
1
меры, а затем будет взято среднее значение для каждой из метрик, т.е.:
P
muticlass
=
P
i2C
P
i
N
C
(4)
Где C – классы в представленной выборке, N
C
– количество классов.
Так как нам необходимо рекомендовать людей, то посмотрим, в сколь-
ки случаев релевантный исполнитель встречается в списке первых n испол-
нителей.
Выбранные нами классификаторы (Random forest и логистическая
регрессия с градиентным спуском) дают в качестве результата прогнозиро-
вания вектор вероятностей по всем классам.
Поэтому можно отсортировать
этот список и брать первые n интересующих значений.
Обозначим отсорти-
рованный список классов по вероятностям как C
sorted
, релевантный класс как
c
r
, матрицу вероятностей Y
pred
размерности [N
test
⇥N
C
], где N
test
– количество
примеров в тестовой выборке, C
1:n
обозначим с первого по n-ый элементы из
вектора C.
score
n
(C
sorted
) =
8
<
:
1,
если c
r
2С
sorted
1:n
0,
иначе
(5)
S
n
=
P
i2N
test
score
n
(sort
desc
(Y
pred
i.
)
N
test
Для задачи регрессии воспользуемся коэффициентом детерминации (6)
и среднеквадратическим отклонением (7).
Пусть ˆ
y
i
– спрогнозированные значения i-го наблюдения, y
i
обозначает
правильное значение, тогда R
2
определяется следующим образом для n
samples
.
R
2
(y, ˆ
y) = 1
P
n
samples
1
i=1
(y
i
ˆ
y
i
)
2
P
n
samples
1
i=1
(y
i
¯
y)
2
(6)
где ¯
y =
1
n
samples
P
n
samples
1
i=1
y
i
.
21
Коэффициент R
2
определяет,
насколько хорошо модель прогнозирует
примеры,
которых не было в тренировочной выборке.
Наилучшее значение
коэффициента 1.
В случае 0-го значения,
модель всегда дает один и тот же
результат, независимо от входных данных.
MSE(y, ˆ
y) =
1
n
samples
n
samples
1
X
i=1
(y
i
ˆ
y
i
)
2
(7)
(7) Определяет ошибку регрессии. Чем меньше эта величина, тем выше
точность прогнозирования.
Глава 5. Решения задач
Перед нами стоят серьезные задачи по подготовке данных и построению
рекомендательной системы. Еще раз обсудим их:
1.
Необходимо найти способ представить категориальные переменные в чис-
ленном формате, при этом постараться не потерять информацию, связан-
ную с ними;
2.
Научиться рекомендовать исполнителей по категориальным переменным;
3.
Прогнозировать количество дней, которое потребуется на задание.
§5.1. Подготовка категориальных переменных
Как видно из Таблицы 1 данные, в основном, представляют из себя кате-
гориальные переменные и нам необходимо выбрать метод представления их в
виде чисел. В главе 3 рассмотрены два стандартных подхода: Label Encoding
и One Hot Encoding.
Мы предлагаем представлять категориальные переменные в виде векто-
ров через понижение размерности матрицы дистанции между переменными.
Обычно методы понижения размерности используют для того,
чтобы
графически представить данные высокой размерности в трехмерном или дву-
22
мерном пространстве.
Мы же собираемся отобразить данные на одномерное
пространство,
чтобы получить возможность передать данные методам ма-
шинного обучения, при этом не теряя и не внося новой информации.
Для таких переменных,
как тип доступа (AccessType) или срочность
(Urgency) можно применить Label Encoder, потому что для данных этого типа
существует порядок подходящий для использования LabelEncoding, что видно
из Таблицы 1.
§5.1.1. Понижение размерности
В наших данных значительную роль играют люди, поэтому логично най-
ти какой-то способ измерить расстояние между ними. Построим матрицу свя-
зей D размерности [k ⇥ k], где k – количество людей(отделов):
D
i,j
=
8
<
:
1/d
i,j
, если d
i,j
6
= 0
1, иначе
где значение d
i,j
равно количеству раз,
i-ый сотрудник(отдел) встречается
вместе с j-ым сотрудником(отделом). Например, если два человека работают
в одном отделе и работали над одним документом,
тогда d
i,j
= 2 для этих
двух людей.
Получается, чем больше два человека работали вместе, тем ближе зна-
чение D
i,j
к 0,
а соответственно,
если два человека работали вместе менее
двух раз, то D
i,j
= 1.
Такую матрицу D можно построить для следующих переменных:
Operator, Registrator, RegistratorDepartment, Addressee.
С переменными, у которых нельзя построить матрицу расстояний опи-
санным выше способом(Categories и Kind ) поступим следующим образом:
• Измерим расстояние между категориями через людей,
работавших над
категориями.
Построим матрицу категорий - людей M,
размерности [n ⇥ k],
где n –
23
количество категорий,
а k – количество людей,
m
i,j
обозначает,
сколько
раз i-я категория, встретилась с j-ым человеком.
Вычисляем каждый элемент матрицы по следующему правилу:
M
i,j
=
8
<
:
1/m
i,j
,
если m
i,j
6
= 0
1, иначе
• Построим Word2Vec модель по кратким описаниям документов (Content)
или по какому-нибудь датасету (в данном случае использовались, государ-
ственные документы с сайта правительства РФ [24].
Также в открытом
доступе есть документы на лето 2016 года и обученная W2V модель [25]).
В результате для каждого слова получим k-мерное представление в ви-
де вектора. Обозначим обученную Word2Vec модель как w2v, некоторое
слово как w, словарь известных слов V. Построим матрицу M следующим
образом:
M матрицанулей[n ⇥ k];
for c 2 Categories do
sentences выбратьContentдокументов,скатегориейc;
s нулевойвекторразмерностиk;
for sentence 2 sentences do
for w 2 sentence do
if w 2 V then
s s+w2v[w];
end
end
end
M
.c
s;
end
Algorithm 1: Алгоритм вычисления матрицы M для Categories и Kind
24
Затем строим матрицу D для Categories и Kind следующим образом:
D
i,j
=
v
u
u
t
k
1
X
l=0
(M
i,l
M
j,l
)
2
Имея матрицу расстояний D можно понизить ее размерность и сопоставить
каждой переменной число. Сделав это, получаем для каждой категориальной
переменной некоторое число.
Это значение,
в дальнейшем,
можно использо-
вать как значения категориальных переменных в матрице X.
§5.2. Рекомендация исполнителя
Дана матрица X размера [N ⇥ K], где N – это количество заданий, а K
– количество переменных, полученных либо понижением размерности, либо с
помощью One hot encoding и вектор Y размерности N .
Если обратиться к Рис.
4,
5,
6 то видно,
что представленные классы
несбалансированы.
Есть сотни людей,
кто был назначен что-то выполнять
один раз,
а есть те,
у кого в истории по тысяче выполненных заданий.
По-
этому применение алгоритмов классификации без предварительной борьбы с
несбалансированностью – наивно и некорректно.
Во-первых разобьем весь датасет на уровни от 1-го до 3-го, во-вторых,
на каждом уровне разобьем данные таким образом,
чтобы частоты выпол-
ненных заданий исполнителями были как можно более сбалансированными,
в-третьих,
будем применим oversampling для исполнителей с малым коли-
чеством заданий.
В-четвертых,
при классификации будем используем фла-
ги для весов классов Classification(class_wight=’balanced’). Установка
этого флага вносит следующий коэффициент для весов классов:
n
f eatures
n
classes
⇤ np.bincount(Y )
Также исключим из рассмотрения атрибут Addressee, поскольку в дан-
ном датасете,
более чем в 70% случаев он совпадает с Appointed – целевой
переменной.
25
Для решения задачи рекомендации исполнителя,
воспользуемся алго-
ритмами Random forest и стохастическим градиентным спуском с логистиче-
ской функцией потерь.
§5.3. Прогнозирование времени исполнения документа
В системах, связанных с документами, имеются определенные сроки на
обработку документа. Например, обращение гражданина должно рассматри-
ваться не дольше тридцати дней. Поэтому важно выяснить, что, что больше
всего влияет на длительность обработки документа, и возможно ли построить
модель, которая определяла бы это время.
В файлах resolution.json у каждого задания есть следующие сроки:
CreationDateTime:
– время создания,
ActualTerm:
– время завершения зада-
ния. Для того, чтобы получить время исполнения документа, посчитаем сред-
нее время затраченное на каждое из заданий.
В результате, для каждого документа, получим величину, соответству-
ющую времени, которое потребуется на обработку документа.
Эти значения будем считать наблюдаемыми Y . А X возьмем как преж-
де, но добавим Addressee в атрибуты.
Для решения задачи прогнозирования времени выполнения документа
воспользуемся алгоритмами Random forest и линейной регрессией.
Глава 6. Эксперименты
§6.1. Прогнозирование времени исполнения документа
Рассмотрим задачу прогнозирования длительности обработки докумен-
та.
Пусть X – матрица с атрибутами, полученная, либо с помощью One hot
encoding, либо с помощью понижения размерности, а Y – вектор с со средним
временем выполнения заданий в каждом документе.
26
На Рис. 7 представлено распределение количества дней, затраченных на
обработку каждого документа.
Рис. 7. Распределение количества дней
Регрессия дает лучше результаты, когда целевая переменная имеет ма-
лую дисперсию.
Стандартный метод для нормализации – функция y
0
= log (y + 1). При-
меняя ее, получается получается распределение, представленное на Рис. 8.
Рис. 8. Нормализованное распределение количества дней
Построим регрессию по атрибутам,
полученным с помощью One hot
encoding и понижения размерности. Матрица X
dim_red
с атрибутами получен-
ными в результате понижения размерности будет иметь размер [115730 ⇥ 23],
27
а матрица X
ohe
полученная в результате One hot encoding, размерность
[115730 ⇥ 357]. Воспользуемся следующими категориальными переменными:
Operator, Registrator, RegistratorDepartment, Urgency, AccessType, Kind.
В матрице X
dim_red
воспользуемся всеми повышениями размерностей:
(MDS,
PCA,
TSNE),
а Urgency,
AccessType преобразуем в численный вид с
помощью Label encoding.
Для обучения модели возьмем 75% от всего набора данных. Результаты
прогнозирования на тестовой выборке размера 25% от всего набора данных,
представлены на Рис. 9.
Метрики были вычисленные на данных,
преобразованных в исходный
вид с помощью формулы y = exp(y
0
)
1. На графике с результатами 9 введены
следующие обозначения:
• RFR – random forest regressor;
• LinearRegression – линейная регрессия;
• _ohe – Использованы данные, полученные с помощью one hot encoding;
• _dim_red – Использованы данные,
полученные с помощью понижения
размерности.
• R
2
– мера R2 (6), чем больше, тем лучше.
• error – среднеквадратическое отклонение (7): чем меньше, тем лучше.
В результате видим,
что данные,
полученные с помощью понижения
размерности, можно применять не только для нелинейных моделей, но также
к линейным. Атрибуты, полученные с помощью one hot encoding при исполь-
зовании в линейной регрессии дают R
2
=
3.23338968469e + 20 и средне-
квадратическое отклонение равное 58488029338.625488. Это показывает, что
нельзя применять линейную модель для категориальных переменных,
полу-
ченных с помощью One hot encoding.
28
Рис. 9. Результаты применения регрессий.
§6.2. Рекомендация исполнителя
Решать задачу рекомендации исполнителя будем следующим образом:
пусть X – матрица с атрибутами, полученная, либо с помощью one hot encoding,
либо с помощью понижения размерности, а Y – вектор с исполнителями, ко-
торые являются категориями в данной задаче. Предварительно, если у доку-
мента было несколько исполнителей, то продублируем строки из матрицы X
столько раз, сколько исполнителей для соответствующего документа.
Затем, выберем из этой матрицы первые три уровня исполнения (Рис. 4,
5, 6). Для второго уровня добавим в атрибуты исполнителей, которые были на
первом уровне, а для третьего, соответственно, с первого и второго уровней.
Алгоритмы классификации будем обучать, как на данных полученных
с помощью one hot encoding, так и с переменными, полученными в результате
понижения размерности. Причем, учитывая тот факт, что этот метод способен
выделять важные атрибуты, будем передавать ему все переменные получен-
ные в результате понижения размерности (MDS, PCA, TSNE). В таблицах с
результатами введем следующие обозначения:
29
• subset – выбранные исполнители, с количеством заданий из промежутка;
• subset_train_size – размер тренировочной выборки матрицы наблюда-
емых значений для данных исполнителей;
• subset_train_size – размер тестовой выборки;
• n_classes – количество исполнителей, попавших в подвыборку subset;
• method – выбранный метод классификации и понижения размерности,
где
– RFC – random forest classifier;
– SGD – stochastic gradient descent;
– _ohe – one hot encoding;
– _dim_red – понижение размерности;
– w или w/o oversampling – с или без повторения наблюдаемых значений.
• precision – точность (4);
• recall – полнота (2);
• f1_score – F1 мера (3) top_3 и top_5 – меры определяющие вхождение
релевантного исполнителя в топ 3 или 5 (5)
Также, если применяется oversampling, то разбиение на тренировочную и те-
стовую выборки происходит следующим образом:
разбиваем исходное мно-
жество на тренировочное и тестовое,
применяем oversampling для трениро-
вочного множества и обучаем на нем классификатор,
а тестовое множество
оставляем неизменным.
На графиках с результатами классификации, используются следующие
обозначения:
• по оси y следующая структура:
используемый метод (соответствует обо-
значениям из таблицы), выбранные исполнители с количеством заданий,
размер тренировочной выборки,размер тестовой выборки;
30
• По оси x – значение метрики (чем больше, тем лучше).
§6.2.1. Первый уровень исполнения
Разобьем первый уровень исполнения на три подвыборки: в первой будут
люди, с количеством выполненных заданий от 10 до 100. Во второй от 100 до
1000. В третьей от 1000 до 6000. В Таблице 3 из Приложения D, и на
Рис. 10 - 12 представлены результаты классификации.
Рис. 10. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 10 до 100.
Количество исполнителей: 64
Рис. 11. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 100 до 1000.
Количество исполнителей: 57
31
Рис. 12. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 1000 до 6000.
Количество исполнителей: 31
По результатам классификации видно,
что метод стохастического гра-
диентного спуска не применим к данным полученным с помощью понижения
размерности. Также, на первом уровне исполнения, атрибуты, полученные с
помощью понижения размерности, повышают точность классификации.
Рассмотрим теперь, какие атрибуты больше всего влияют на результаты
классификации.
Рис. 13. Важность атрибутов на первом уровне исполнения, с количеством выполненных заданий от 10 до 100
32
Рис. 14. Важность атрибутов на первом уровне исполнения, с количеством выполненных заданий от 100 до 1000
Рис. 15. Важность атрибутов на первом уровне исполнения, с количеством выполненных заданий от 1000 до 6000
На Рис.
13,
14,
15 видно,
что oversampling снижает значимость атрибутов,
имевших большое значение информативности без oversampling и повышает
значимость менее информативных. Также, можно судить, о том, что чем мень-
ше выполнил заданий человек, тем больше оказывают влияние такие атрибу-
ты как Categories и Kind. Переменные, вроде, AccessType и Urgency оказались
малоинформативными. Зато самое большое влияние оказывают люди, связан-
ные с созданием документа (Operator, Registrator ).
О людях,
с низким количеством выполненных заданий,
можно судить,
33
что их еще мало знают и поэтому назначают задания,
соответствующие их
компетенции. А людям с большим числом заданий, дают более разнообразные
задания.
Также можно судить о том, что люди (Operator, Registrator ) в простран-
стве большей размерности, имеют линейную структуру, поскольку лучшие ре-
зультаты дает понижение размерности с помощью метода главных компонент
(PCA). А отделы (RegistratorDepartment), соответственно, имеют нелинейную
структуру.
§6.2.2. Второй уровень исполнения
Для рекомендации исполнителя на втором уровне добавим в атрибуты
исполнителя,
назначенного на предыдущем уровне.
Этот подход можно экс-
траполировать также и на следующие уровни исполнения,
однако в итоге,
матрица, полученная с помощью, One hot encoding будет иметь сотни атрибу-
тов. Помимо того, матрица такого размера замедляет вычисления, ее высокая
размерность может вести к переобучению.
Разобьем второй уровень исполнения на четыре подвыборки по количе-
ству выполненных заданий: от 10 выполненных заданий до 100, от 100 до 1000,
от 100 до 500 и от 1000 до 6000. Для второй подвыборки применим повыше-
ние количества примеров, поскольку на этом участке имеется много классов
и мало примеров. Тогда получим результаты, представленные в Таблице 4 в
Приложении E и на Рис. 16 – 19.
На графиках видно, что как минимум в 60% случаев в лучших 5 испол-
нителях будет релевантный сотрудник. Также, как и на первом уровне, SGC
плохо обрабатывает данные полученные с помощью понижения размерности.
Низкая точность рекомендации обусловлена тем фактом,
что необхо-
димо классифицировать по большому числу классов с малым количеством
примеров. Однако, несмотря на это, использование атрибутов, полученных с
помощью понижения размерности повышает точность рекомендаций.
34
Рис. 16. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 10 до 100.
Количество исполнителей: 493
Рис. 17. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 100 до 500.
Количество исполнителей: 233
35
Рис. 18. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 100 до 1000.
Количество исполнителей: 285
Рис. 19. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 1000 до 6000.
Количество исполнителей: 29
36
Рассмотрим теперь, какие атрибуты оказывают наибольшее влияние на
решение алгоритма. На Рис. 20, 21 видно, что наибольшее влияние оказыва-
ет тот человек,
который был назначен уровнем выше,
тогда как по Рис.
22
переменные,
описывающие документ (Categories, Kind ),
оказывают большее
влияние.
Рис. 20. Важность атрибутов на втором уровне исполнения, с количеством выполненных заданий от 10 до 100
Рис. 21. Важность атрибутов на втором уровне исполнения, с количеством выполненных заданий от 100 до 1000
37
Рис. 22. Важность атрибутов на втором уровне исполнения, с количеством выполненных заданий от 1000 до 6000 с
Oversampling
Oversampling, для исполнителей с малым количеством заданий не вно-
сит значительных изменений в значимости атрибутов, при этом точность ре-
комендаций в некоторых случаях даже падает.
По получившимся важностям атрибутов можно судить о следующем:
исполнитель на втором уровне очень сильно зависит от того, кто был назначен
на первом уровне, чем меньше выполнено заданий исполнителем, тем важнее
атрибут first_level_appointed. Чем больше заданий выполнено, тем больше на
равных становятся атрибуты документа и исполнитель первого уровня.
Из атрибутов документа,
переменная тип доступа (AccessType) не ока-
зывает влияния на решение классификатора. Переменные тип документа
(Kind ) и срочность (Urgency) вносят одинаковое количество информации, при
этом их важность падает с повышением числа выполненных заданий исполни-
телем. Operator, Registrator и RegistratorDepartment
также несут тем больше
информации, чем больше заданий выполнил исполнитель.
Из этого можно сделать вывод, что чем больше исполнитель выполнил
заданий на втором уровне, тем больше он похож на исполнителя первого уров-
ня.
38
§6.2.3. Третий уровень исполнения
На третьем уровне исполнения добавим в атрибуты исполнителей перво-
го и второго уровней. Разобьем этот уровень, по частоте выполнения заданий
исполнителями на три подвыборки:
от 10 до 100 выполненных заданий,
от
100 до 500 и от 100 до 1000.
Получим результаты классификации,
представленные на Таблице 5 в
Приложении F и графиках 23, 24, 25.
Рис. 23. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 1000 до 6000.
Количество исполнителей: 656
Рис. 24. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 100 до 500.
Количество исполнителей: 157
39
Рис. 25. Результаты классификации на выборке исполнителей с количеством выполненных заданий от 100 до 1000.
Количество исполнителей: 174
На представленных результатах классификации,
еще раз убеждаемся,
что нельзя использовать данные, полученные с помощью понижения размер-
ности,
для классификации с помощью SGC.
Также,
получаем неплохие ре-
зультаты классификации для исполнителей с большим количеством выпол-
ненных заданий.
Для исполнителей с малым количеством заданий получаются не впе-
чатляющие результаты,
однако это также связано с их малым количеством.
Обучение классификатора на данных полученных с помощью oversampling
незначительно повышает точность рекомендаций, а в некоторых случаях, сни-
жает ее.
Рассмотрим теперь, какие атрибуты оказывают влияние на решение ал-
горитма. На всех трех графиках 26, 27, 28 видно, что значительную роль иг-
рают исполнители первого и второго уровней, а категории документа уходят
на второй план.
По графику 26 можно судить, что так как про исполнителя еще известно
достаточно мало,
то его выбирают в соответствии с документом,
при этом,
чем больше он выполняет заданий, тем больше исполнители второго уровня
выбирают его на задания разного типа.
40
Рис. 26. Важность атрибутов на третьем уровне исполнения, с количеством выполненных заданий от 10 до 100
Рис. 27. Важность атрибутов на третьем уровне исполнения, с количеством выполненных заданий от 100 до 500
Рис. 28. Важность атрибутов на третьем уровне исполнения, с количеством выполненных заданий от 100 до 1000
41
Выводы
Экспериментально было доказано, что хоть One hot encoding и является
универсальным средством для работы с категориальными переменными,
ис-
пользовать его можно только если необходимо получить результаты быстро,
пренебрегая качеством результатов.
Если есть время поработать с данными,
разобраться в их структуре,
то лучше попробовать сохранить их структу-
ру применив подходы представленные в работе.
На представленных данных
сохранение информации о структуре данных не только давало значительно
ниже размерность матрицы X,
но также повышало точность прогнозирова-
ний.
Заключение
Цель данной работы была в том, чтобы показать, что введение метрик
между категориальными переменными и понижение размерности матриц до
векторов работает не хуже стандартного подхода One hot encoding.
Данная
цель была достигнута и более того,
данные полученные данные полученные
при использовании рассмотренного подхода не только не ухудшают точность,
а повышают ее.
Данная система уже реализована в качестве прототипа в компании
Digital Design в коммерческой системе документооборота Docsvision. В каче-
стве дальнейшего развития прототипа рассматривается использование метода
построения полного дерева резолюций и расширение системы рекомендаций
исполнителей на любых уровнях исполнения. В конечном итоге, стоит задача
перевода прототипа в режим коммерческой эксплуатации в качестве допол-
нительного API системы Docsvision.
Реализация поставленных задач может стать объектом магистерской
диссертации.
42
Список литературы
1.
DMS Document management system [Интернет ресурс]: URL:en.wikipedia.
org/wiki/Document_management_system (date: 18.03.17)
2.
Alkhalaf
K. S.,
Almishal
A. I.,
Almahmoud A. O.,
Alotaibi
M. S.
OCR-Based
Electronic Documentation Management
System // International
Journal
of
Innovation, Management and Technology 2014. Vol. 5, No 5. P. 465–469.
3.
Floriana Esposito and Stefano F.,
Teresa M.,
Nicola D.
Machine Learning for
Digital Document Processing: from Layout Analysis to Metadata Extraction //
Machine Learning in Document Analysis and Recognition 2008.
4.
DigitalDesign [Интернет ресурс]: URL:http://digdes.ru/about (дата обра-
щения: 18.03.17)
5.
Docsvision [Интренет ресурс]:
http://www.docsvision.com (дата обраще-
ния: 03.05.2017).
6.
Manning C. D.,
Raghavan P.
and Schutze
H.
Introduction to Information
Retrieval // Cambridge University Press 2008.
7.
Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython
(01 November 2012) by Wes McKinney
8.
kaggle – Сайт с задачами по машинному обучению [Интернет ресурс]: URL:
https://www.kaggle.com
9.
– Решение задачи по прогнизированию цен за дома [Интернет ресурс]:
https://www.kaggle.com/apapiu/regularized-linear-models
10.
Breiman L.
Random forests // Machine Learning.� 2001.� Vol.
45,
no.
1.�
Pp. 5Џ32.
11.
Louppe,
G.,
Wehenkel,
L.,
Sutera,
A.,
Geurts,
P Understanding variable
importances in forests of randomized trees // Advances in Neural Information
Processing Systems 26. 2013. С. 431–439.
43
12.
Интерактивное демо создания документа в Docsvision [Интренет ресурс]:
URL:https://marvelapp.com/35d1ihe/screen/13200295
13.
8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset
[Интернет ресурс]: URL:goo.gl/IddLHg
14.
UUID description on wiki [Интернет ресурс]: URL:https://en.wikipedia.
org/wiki/Universally_unique_identifier (дата обращения: 15.05.2017).
15.
Random forest
на
wikipedia
[Интернет
ресурс]:
URL:https://en.
wikipedia.org/wiki/Random_forest (дата обращения: 18.03.17).
16.
Композиции
алгоритмов,
основанные
на
случайном
лесе
//
http://www.machinelearning.ru
URL:http://www.machinelearning.
ru/wiki/images/d/d8/2015_517_RyzhkovAM.pdf
(дата
обращения:
03.05.2017).
17.
Sklearn [Интернет ресурс]:
URL:http://scikit-learn.org (дата обраще-
ния: 15.05.2017).
18.
Stochastic
Gradient
Descent
//
http://scikit-learn.org/
URL:http:
//scikit-learn.org/stable/modules/sgd.html
(дата
обращения:
15.05.2017).
19.
Large-Scale
Machine
Learning
with
Stochastic
Gradient
Descent
In
Proceedings of the 19th International
Conference on Computational Statistics
(COMPSTAT’2010) (August 2010), pp. 177-187 by Luon Bottou edited by Yves
Lechevallier, Gilbert Saporta
20.
Tranmer M., Elliot M. Multiple linear regression //The Cathie Marsh Centre
for Census and Survey Research (CCSR). Џ 2008.
21.
Radim R.,
Sojka P.
Software Framework for
Topic Modelling with Large
Corpora // Proceedings of the LREC 2010 Workshop on New Challenges for
NLP Frameworks. Valletta, Malta: ELRA, 2010. С. 45–50.
44
22.
Word2Vec
в
примерах [Интернет
ресурс]
URL:https://habrahabr.ru/
post/249215/ (дата обращения: 15.05.2017).
23.
Mikolov,
T.,
Sutskever,
I.,
Chen,
K.,
Greg S.
C.,
Dean,
J.
Distributed
Representations of Words and
24.
Правительство
Российской
федерации
[Итернет
ресурс]:
http:
//government.ru (дата обращения: 15.05.2017).
25.
Обученная word2vec модель и документы с сайта правительства на ле-
то 2016 года [Интернет ресурс]:
URL:https://yadi.sk/d/dOGUKF9R3Hs9WT
(дата обращения: 15.05.2017).
26.
Лекция 13. Уменьшение размерности в данных. Метод главных компонент.
[Интернет ресурс]: URL:http://www.machinelearning.ru/wiki/images/4/
45/SMAIS2009-13.pdf (дата обращения: 15.05.2017).
27.
Pearson K.,
On lines and planes of
closest fit to systems of
points in space,
Philosophical Magazine, (1901) 2, 559�572
28.
L.J.P.
van der Maaten and G.E.
Hinton.
Visualizing High-Dimensional
Data
Using t-SNE. Journal of Machine Learning Research 9(Nov):2579-2605, 2008.
29.
Классификация
секретной
информации
в
РФ [Интернет
ресурс]:
URL:https://ru.wikipedia.org/wiki/Классификация_секретной_
информации_в_России (дата обращения: 15.05.2017).
45
Приложение
Приложение A. Пример document.json файла
1
{
2
"Type" :
0 ,
3
" Content " :
" sample
s t r i n g
1 " ,
4
" R e g i s t r a t i o n D a t e " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
5
" CompletionDate " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
6
"Kind" :
{
7
"Name" :
" sample
s t r i n g
3 " ,
8
" I d " :
"55 e8453b - 9 cb8 - 4 6 7 9 - b56a - f 3 9 d 4 f 5 3 4 d 5 2 "
9
} ,
10
" AccessType " :
{
11
"Name" :
" sample
s t r i n g
3 " ,
12
" I d " :
" e578eb30 - 3 2 cb - 4 a78 - 9 a0e - a 4 7 3 d a 3 f 7 1 4 a "
13
} ,
14
" Urgency " :
{
15
"Name" :
" sample
s t r i n g
1 " ,
16
" I d " :
"612 d1a9b - 8 e45 - 4 b9a - 8 cbc - d b c e f 4 5 3 0 c b 9 "
17
} ,
18
" O p er a t o r " :
{
19
"Type" :
0 ,
20
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
21
" P o s i t i o n I m p o r t a n c e " :
1 ,
22
" S t a t u s " :
0 ,
23
"Manager" :
{
24
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
25
} ,
26
" Importance " :
1 ,
27
" Unit " :
{
28
"Type" :
1 ,
29
" UnitType " :
6 ,
30
"Name" :
" sample
s t r i n g
7 " ,
31
" I d " :
"1 d f 5 9 2 e a - 6 6 9 5 - 4 1 b0 - 8 9 3 e - 7 b 3 d 2 c f 2 a 3 0 3 "
32
} ,
33
" Gender " :
0 ,
34
"Name" :
" sample
s t r i n g
1 2 " ,
35
" I d " :
" f 0 2 b e 8 2 1 - f 5 5 e - 4 de6 - b15f - ad2ae25135d5 "
36
} ,
37
" R e g i s t r a t o r D e p a r t m e n t " :
{
38
"Type" :
1 ,
39
"Manager" :
{
40
"Type" :
0 ,
41
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
42
" P o s i t i o n I m p o r t a n c e " :
1 ,
43
" S t a t u s " :
0 ,
44
"Manager " :
{
45
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
46
} ,
47
" Importance " :
1 ,
46
48
" Gender " :
0 ,
49
"Name" :
" sample
s t r i n g
1 2 " ,
50
" I d " :
" f 0 2 b e 8 2 1 - f 5 5 e - 4 de6 - b15f - ad2ae25135d5 "
51
} ,
52
" UnitType " :
6 ,
53
"Name" :
" sample
s t r i n g
7 " ,
54
" I d " :
"1 d f 5 9 2 e a - 6 6 9 5 - 4 1 b0 - 8 9 3 e - 7 b 3 d 2 c f 2 a 3 0 3 "
55
} ,
56
" R e g i s t r a t o r " :
{
57
"Type" :
0 ,
58
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
59
" P o s i t i o n I m p o r t a n c e " :
1 ,
60
" S t a t u s " :
0 ,
61
"Manager" :
{
62
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
63
} ,
64
" Importance " :
1 ,
65
" Unit " :
{
66
"Type" :
1 ,
67
" UnitType " :
6 ,
68
"Name" :
" sample
s t r i n g
7 " ,
69
" I d " :
"1 d f 5 9 2 e a - 6 6 9 5 - 4 1 b0 - 8 9 3 e - 7 b 3 d 2 c f 2 a 3 0 3 "
70
} ,
71
" Gender " :
0 ,
72
"Name" :
" sample
s t r i n g
1 2 " ,
73
" I d " :
" f 0 2 b e 8 2 1 - f 5 5 e - 4 de6 - b15f - ad2ae25135d5 "
74
} ,
75
" E x t e r n a l C o n t r o l " :
t r u e ,
76
" TemplateId " :
" f f 3 5 9 5 2 c - e21d - 4 9 0 5 - b7b8 - 1 0 e f d 3 5 4 3 0 4 e " ,
77
" P e r f o r m e r " :
{
78
"Type" :
0 ,
79
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
80
" P o s i t i o n I m p o r t a n c e " :
1 ,
81
" S t a t u s " :
0 ,
82
"Manager" :
{
83
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
84
} ,
85
" Importance " :
1 ,
86
" Unit " :
{
87
"Type" :
1 ,
88
" UnitType " :
6 ,
89
"Name" :
" sample
s t r i n g
7 " ,
90
" I d " :
"1 d f 5 9 2 e a - 6 6 9 5 - 4 1 b0 - 8 9 3 e - 7 b 3 d 2 c f 2 a 3 0 3 "
91
} ,
92
" Gender " :
0 ,
93
"Name" :
" sample
s t r i n g
1 2 " ,
94
" I d " :
" f 0 2 b e 8 2 1 - f 5 5 e - 4 de6 - b15f - ad2ae25135d5 "
95
} ,
96
" F i l e s " :
[
97
{
98
" C reate d " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
99
"Changed" :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
100
" E x t e n s i o n " :
" sample
s t r i n g
3 " ,
101
" S i z e " :
4 ,
102
"Name" :
" sample
s t r i n g
6 " ,
47
103
"OwnerId" :
" e54e87b4 - 5 7 6 2 - 4 3 e0 - 8 1 a4 - e 7 2 e 4 5 d 1 e 1 1 f " ,
104
" Importance " :
8 , ,
105
" P a r e n t I d " :
"692 f 7 f f 5 - 8 bbd - 4 b2c - 9 c80 - 3 6 0 3 7 4 0 9 7 4 bd " ,
106
" I d " :
" e185baa1 - dfdb - 4 2 e f - b324 - 6 8 1 2 4 f c 0 3 a 2 e "
107
} ] ,
108
" P a r e n t I d " :
"692 f 7 f f 5 - 8 bbd - 4 b2c - 9 c80 - 3 6 0 3 7 4 0 9 7 4 bd " ,
109
" I d " :
" e185baa1 - dfdb - 4 2 e f - b324 - 6 8 1 2 4 f c 0 3 a 2 e "
110
}
111
] ,
112
" A d d r e s s e e s " :
[
113
{
114
"OrderNumber" :
1 ,
115
" R e f e r e n c e " :
{
116
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
117
} ,
118
"Type" :
0 ,
119
" AddresseeType " :
0 ,
120
" OutgoingNumber" :
" sample
s t r i n g
1 " ,
121
"OutRegDate" :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
122
" OutSignedBy " :
{
123
" Address " :
" sample
s t r i n g
8 " ,
124
"Name" :
" sample
s t r i n g
9 " ,
125
" I d " :
" c a f 2 9 f f 2 - e6e7 - 4 bb7 - 9 baf - 7 1 d 2 1 f a 5 f f 5 d "
126
} ,
127
"SendTo" :
{
128
" Address " :
" sample
s t r i n g
8 " ,
129
"Name" :
" sample
s t r i n g
9 " ,
130
" I d " :
" c a f 2 9 f f 2 - e6e7 - 4 bb7 - 9 baf - 7 1 d 2 1 f a 5 f f 5 d "
131
} ,
132
" NumberOfCopies " :
" sample
s t r i n g
4 " ,
133
" PageCount " :
" sample
s t r i n g
5 " ,
134
" TaskId " :
{
135
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
136
} ,
137
" I d " :
"3 b a 5 6 f f e - e e f b - 4 9 2 d - 8 d6c - 8 2 0 9 d108321c "
138
} ] ,
139
" E x e c u t o r s " :
[
140
{
141
" Order " :
1 ,
142
" Employee " :
{
143
"Type" :
0 ,
144
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
145
" P o s i t i o n I m p o r t a n c e " :
1 ,
146
" S t a t u s " :
0 ,
147
"Manager" :
{
148
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
149
} ,
150
" Importance " :
1 ,
151
" Unit " :
{
152
"Type" :
1 ,
153
" UnitType " :
6 ,
154
"Name" :
" sample
s t r i n g
7 " ,
155
" I d " :
"1 d f 5 9 2 e a - 6 6 9 5 - 4 1 b0 - 8 9 3 e - 7 b 3 d 2 c f 2 a 3 0 3 "
156
} ,
157
" Gender " :
0 ,
48
158
"Name" :
" sample
s t r i n g
1 2 " ,
159
" I d " :
" f 0 2 b e 8 2 1 - f 5 5 e - 4 de6 - b15f - ad2ae25135d5 "
160
} ,
161
" I d " :
"96 ead854 - 9 ae6 - 4 3 ad - be79 - 6 3 6 a49e75d70 "
162
} ] ,
163
" Approvers " :
[
164
{
165
" Approver " :
{
166
"Type" :
0 ,
167
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
168
" P o s i t i o n I m p o r t a n c e " :
1 ,
169
" S t a t u s " :
0 ,
170
"Manager" :
{
171
" I d " :
" f f d 4 0 9 5 5 - ad37 - 4 a02 - 8 e88 - d d 4 5 5 f e d 3 f 5 b "
172
} ,
173
" Importance " :
1 ,
174
" Unit " :
{
175
"Type" :
1 ,
176
" UnitType " :
6 ,
177
"Name" :
" sample
s t r i n g
7 " ,
178
" I d " :
"1 d f 5 9 2 e a - 6 6 9 5 - 4 1 b0 - 8 9 3 e - 7 b 3 d 2 c f 2 a 3 0 3 "
179
} ,
180
" Gender " :
0 ,
181
"Name" :
" sample
s t r i n g
1 2 " ,
182
" I d " :
" f 0 2 b e 8 2 1 - f 5 5 e - 4 de6 - b15f - ad2ae25135d5 "
183
} ,
184
" ApprovalDate " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
185
" IsApproved " :
t r u e ,
186
" A p p r o v a l S t a t u s " :
0 ,
187
" I d " :
"6 b52896e - 1 5 a f - 4 5 5 b - 9 e04 - 6 d20b2cd5bdf "
188
}
189
] ,
190
" NumberOfCopies " :
" sample
s t r i n g
5 " ,
191
"NumberOfPages" :
" sample
s t r i n g
6 " ,
192
" C a t e g o r i e s " :
[
193
{
194
"Name" :
" sample
s t r i n g
1 " ,
195
" I d " :
"612 d1a9b - 8 e45 - 4 b9a - 8 cbc - d b c e f 4 5 3 0 c b 9 "
196
}
197
] ,
198
" D e s c r i p t i o n " :
" sample
s t r i n g
7 " ,
199
" S t a t e " :
{
200
"Name" :
" sample
s t r i n g
1 " ,
201
" I d " :
"4007 f 3 6 e - a4a0 - 4 7 1 5 - b714 - 9 4 3 d 0 c 0 6 c 8 a f "
202
} ,
203
" I s T e m p l a t e " :
t r u e ,
204
" C r e a t i o n D a t e " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
205
" ChangeDate " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 2 8 : 3 7 . 6 1 1 3 1 6 5 + 0 3 : 0 0 " ,
206
" U r l " :
" sample
s t r i n g
1 1 " ,
207
" I d " :
" f a 9 f b e 3 e - 2 d75 - 4 a91 - b9ed - e 3 4 8 2 a 2 0 7 8 3 2 "
208
}
Приложение B. Пример resolution.json файла
49
1
{
2
" Tasks " :
[
3
{
4
" P a r t s " :
[
5
{
6
" E x e c u t o r s " :
[
7
{
8
" I d " :
"64 bdca00 - 1 6 a0 - 4 9 ca - 8 2 5 d - a 3 f 6 5 0 1 b 2 2 0 1 " ,
9
" P a r t I d " :
"86 f 6 9 6 7 4 - e474 - 4 5 fd - b048 - 9 1 c 6 a 5 f 3 0 a 1 d " ,
10
" ExecutorNumber " :
3 ,
11
" ExecutorType " :
0 ,
12
" E x e c u t o r " :
{
13
"Name" :
" sample
s t r i n g
1 " ,
14
" I d " :
"0481194 f - 3 de2 - 4 5 bc - 8 9 3 0 - f 8 8 b f 0 b f 1 e 1 f "
15
} ,
16
" ExecutorKind " :
0 ,
17
" Tasks " :
[ ]
,
18
" R e p o r t R e q u i r e " :
t r u e ,
19
" AutoPerform " :
t r u e ,
20
" P u r s u a n c e R e q u i r e " :
t r u e ,
21
" F i r s t R e s p o n s i b l e " :
t r u e ,
22
" A p p r o v a l S t a t u s " :
0
23
}
24
] ,
25
" I d " :
" db5c83a2 - 0 0 ac - 4 7 5 0 - 8 f 1 4 - 8 4 f 6 e 3 5 f a f 6 a " ,
26
" TaskId " :
" a f 4 6 8 4 4 6 - 7 5 2 d - 4 0 7 a - 8 c f 0 - 4 f 4 b 8 e 4 2 5 c 9 b " ,
27
" C a n c e l l e d " :
t r u e ,
28
" ControlTerm " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 0 2 7 6 4 3 + 0 3 : 0 0 " ,
29
" PartText " :
" sample
s t r i n g
7 " ,
30
" Urgency " :
{
31
"Name" :
" sample
s t r i n g
1 " ,
32
" I d " :
"0481194 f - 3 de2 - 4 5 bc - 8 9 3 0 - f 8 8 b f 0 b f 1 e 1 f "
33
} ,
34
" C a t e g o r i e s " :
[
35
{
36
"Name" :
" sample
s t r i n g
1 " ,
37
" I d " :
"0481194 f - 3 de2 - 4 5 bc - 8 9 3 0 - f 8 8 b f 0 b f 1 e 1 f "
38
}
39
] ,
40
] ,
41
" D e s c r i p t i o n " :
" sample
s t r i n g
1 " ,
42
" I d " :
" c65ade91 - 6 4 2 4 - 4 0 6 a - a f 6 e - 2 e d b 2 6 f f 9 f 8 8 " ,
43
" A p p r o v a l S t a t u s " :
0 ,
44
"Kind" :
{
45
"Name" :
" sample
s t r i n g
3 " ,
46
" I d " :
"3 d5e9360 - 9 2 e4 - 4 f c 3 - 9 6 3 8 - a a d e 1 0 7 9 5 d c e "
47
} ,
48
" S t a t e " :
{
49
"Name" :
" sample
s t r i n g
1 " ,
50
" I d " :
" bd67965e - 5 b17 - 4 8 ed - 8 8 9 5 - 1 1 6 d3ed696ee "
51
} ,
52
" AppointedType " :
0 ,
53
" ExecutesDisplayName " :
" sample
s t r i n g
4 " ,
54
" AuthorDisplayName " :
" sample
s t r i n g
5 " ,
55
" AppointedDisplayName " :
" sample
s t r i n g
6 " ,
50
56
" CreationDateTime " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 1 8 3 8 9 + 0 3 : 0 0 " ,
57
" FinishworkTerm " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 1 8 3 8 9 + 0 3 : 0 0 " ,
58
" ControlTerm " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 1 8 3 8 9 + 0 3 : 0 0 " ,
59
" ActualTerm " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 1 8 3 8 9 + 0 3 : 0 0 " ,
60
" ApprovalDate " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 1 8 3 8 9 + 0 3 : 0 0 " ,
61
" E x e c u t e s " :
{
62
"Type" :
0 ,
63
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
64
" P o s i t i o n I m p o r t a n c e " :
1 ,
65
" S t a t u s " :
0 ,
66
"Manager" :
{
67
" I d " :
"246 f38bb - 8 be9 - 4 d4d - aa03 - 9 0 1 1 f a 3 b f 2 3 f "
68
} ,
69
" Importance " :
1 ,
70
" Unit " :
{
71
"Type" :
1 ,
72
" UnitType " :
6 ,
73
"Name" :
" sample
s t r i n g
7 " ,
74
" I d " :
" f 6 6 1 b 4 0 c - 4 8 6 7 - 4 8 aa - 9 bb6 - 1 9 d 5 7 6 f 3 8 f 5 2 "
75
} ,
76
" Gender " :
0 ,
77
"Name" :
" sample
s t r i n g
1 2 " ,
78
" I d " :
"200 e825a - 7 9 6 b - 4 5 8 0 - bb3d - 4 1 7 e 7 6 7 6 d 2 f a "
79
} ,
80
" Appointed " :
{
81
"Type" :
0 ,
82
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
83
" P o s i t i o n I m p o r t a n c e " :
1 ,
84
" S t a t u s " :
0 ,
85
"Manager" :
{
86
" I d " :
"246 f38bb - 8 be9 - 4 d4d - aa03 - 9 0 1 1 f a 3 b f 2 3 f "
87
} ,
88
" Importance " :
1 ,
89
" Unit " :
{
90
"Type" :
1 ,
91
" UnitType " :
6 ,
92
"Name" :
" sample
s t r i n g
7 " ,
93
" I d " :
" f 6 6 1 b 4 0 c - 4 8 6 7 - 4 8 aa - 9 bb6 - 1 9 d 5 7 6 f 3 8 f 5 2 "
94
} ,
95
" Gender " :
0 ,
96
"Name" :
" sample
s t r i n g
1 2 " ,
97
" I d " :
"200 e825a - 7 9 6 b - 4 5 8 0 - bb3d - 4 1 7 e 7 6 7 6 d 2 f a "
98
} ,
99
" Author " :
{
100
"Type" :
0 ,
101
" P o s i t i o n " :
" sample
s t r i n g
5 " ,
102
" P o s i t i o n I m p o r t a n c e " :
1 ,
103
" S t a t u s " :
0 ,
104
"Manager" :
{
105
" I d " :
"246 f38bb - 8 be9 - 4 d4d - aa03 - 9 0 1 1 f a 3 b f 2 3 f "
106
} ,
107
" Importance " :
1 ,
108
" Unit " :
{
109
"Type" :
1 ,
110
" UnitType " :
6 ,
51
111
"Name" :
" sample
s t r i n g
7 " ,
112
" I d " :
" f 6 6 1 b 4 0 c - 4 8 6 7 - 4 8 aa - 9 bb6 - 1 9 d 5 7 6 f 3 8 f 5 2 "
113
} ,
114
" Gender " :
0 ,
115
"Name" :
" sample
s t r i n g
1 2 " ,
116
" I d " :
"200 e825a - 7 9 6 b - 4 5 8 0 - bb3d - 4 1 7 e 7 6 7 6 d 2 f a "
117
} ,
118
" P e r f o r m i n g R e p o r t " :
t r u e ,
119
" H a s F i l e s " :
t r u e ,
120
" ApproverOrder " :
19
121
}
122
] ,
123
" I d " :
" cc6cbb6a - 7 1 4 2 - 4 6 2 2 - 9 d9a - a 1 4 c 2 0 e 1 1 1 a a " ,
124
" D e s c r i p t i o n " :
" sample
s t r i n g
2 " ,
125
" CreationDateTime " :
" 2 0 1 7 - 0 4 - 2 0 T15 : 4 2 : 4 6 . 5 1 8 3 8 9 + 0 3 : 0 0 " ,
126
}
52
Приложение C. Восемь уровней исполнения
Рис. 29. По оси Y интервалы с количеством выполненных заданий, а по X сколько исполнителей заданий (Appointed) в
каждой корзине
53
Приложение D.
Результаты классификации на перовм уровне ис-
полнения
subset
train_size
test_size
method
precision
recall
f1
top_3
top_5
n_classes
(10, 100)
(3712, 23)
(1085, 23)
RFC_dim_red
w oversampling
0.81
0.68
0.67
0.92
0.95
64
(10, 100)
(1084, 23)
(1085, 23)
RFC_dim_red
w/o oversampling
0.80
0.69
0.68
0.95
0.96
64
(10, 100)
(3712, 23)
(1085, 23)
SGD_dim_red
w oversampling
0.00
0.00
0.00
0.00
0.00
64
(10, 100)
(1084, 23)
(1085, 23)
SGD_dim_red
w/o oversampling
0.0
0.01
0.0
0.01
0.01
64
(10, 100)
(3538, 200)
(1057, 200)
RFC_ohe
w oversampling
0.74
0.63
0.61
0.90
0.94
64
(10, 100)
(1057, 200)
(1057, 200)
RFC_ohe
w/o oversampling
0.75
0.63
0.61
0.91
0.94
64
(10, 100)
(3538, 200)
(1057, 200)
SGD_ohe
w oversampling
0.69
0.65
0.61
0.90
0.93
64
(10, 100)
(1057, 200)
(1057, 200)
SGD_ohe
w/o oversampling
0.66
0.59
0.55
0.80
0.83
64
(100, 500)
(7844, 23)
(4077, 23)
RFC_dim_red
w oversampling
0.74
0.73
0.70
0.95
0.99
37
(100, 500)
(4077, 23)
(4077, 23)
RFC_dim_red
w/o oversampling
0.72
0.73
0.70
0.95
0.99
37
(100, 500)
(7844, 23)
(4077, 23)
SGD_dim_red
w oversampling
0.04
0.05
0.03
0.06
0.13
37
(100, 500)
(4077, 23)
(4077, 23)
SGD_dim_red
w/o oversampling
0.00
0.01
0.00
0.01
0.02
37
(100, 500)
(8103, 171)
(4031, 171)
RFC_ohe
w oversampling
0.64
0.67
0.62
0.92
0.99
37
(100, 500)
(4031, 171)
(4031, 171)
RFC_ohe
w/o oversampling
0.65
0.67
0.62
0.92
0.99
37
(100, 500)
(8103, 171)
(4031, 171)
SGD_ohe
w oversampling
0.63
0.65
0.61
0.92
0.99
37
(100, 500)
(4031, 171)
(4031, 171)
SGD_ohe
w/o oversampling
0.54
0.62
0.54
0.88
0.96
37
(100, 1000)
(25365, 23)
(10709, 23)
RFC_dim_red
w oversampling
0.66
0.63
0.59
0.94
0.98
57
(100, 1000)
(25365, 23)
(10709, 23)
SGD_dim_red
w oversampling
0.02
0.06
0.01
0.03
0.05
57
(100, 1000)
(10708, 23)
(10709, 23)
SGD_dim_red
w/o oversampling
0.00
0.01
0.00
0.07
0.10
57
(100, 1000)
(27075, 229)
(10606, 229)
RFC_ohe
w oversampling
0.62
0.55
0.50
0.92
0.99
57
(100, 1000)
(10605, 229)
(10606, 229)
RFC_ohe
w/o oversampling
0.64
0.55
0.50
0.92
0.99
57
(100, 1000)
(27075, 229)
(10606, 229)
SGD_ohe
w oversampling
0.62
0.56
0.51
0.91
0.98
57
(100, 1000)
(10605, 229)
(10606, 229)
SGD_ohe
w/o oversampling
0.63
0.56
0.51
0.91
0.98
57
(1000, 6000)
(39449, 23)
(39449, 23)
RFC_dim_red
w/o oversampling
0.70
0.67
0.66
0.89
0.96
31
(1000, 6000)
(39449, 23)
(39449, 23)
SGD_dim_red
w/o oversampling
0.02
0.05
0.02
0.08
0.09
31
(1000, 6000)
(38954, 184)
(38954, 184)
RFC_ohe
w/o oversampling
0.69
0.63
0.61
0.87
0.96
31
(1000, 6000)
(38954, 184)
(38954, 184)
SGD_ohe
w/o oversampling
0.64
0.66
0.63
0.88
0.96
31
Таблица 3. Результаты классификации на первом уровне исполнения. test_size=0.5.
54
Приложение E.
Результаты классификации на Втором уровне ис-
полнения
subset
train_size
test_size
method
precision
recall
f1
top_3
top_5
n_classes
(10, 100)
(27608, 513)
(9635, 513)
RFC_ohe
w oversampling
0.22
0.20
0.16
0.47
0.63
493
(10, 100)
(9635, 513)
(9635, 513)
RFC_ohe
w/o oversampling
0.23
0.21
0.16
0.47
0.63
493
(10, 100)
(27608, 513)
(9635, 513)
RFC_ohe
w oversampling
0.19
0.19
0.14
0.45
0.61
493
(10, 100)
(9635, 513)
(9635, 513)
SGD_ohe
w/o oversampling
0.18
0.20
0.14
0.44
0.60
493
(10, 100)
(27608, 26)
(9635, 26)
RFC_dim_red
w oversampling
0.27
0.23
0.19
0.49
0.63
493
(10, 100)
(9635, 26)
(9635, 26)
RFC_dim_red
w/o oversampling
0.28
0.23
0.20
0.49
0.64
493
(10, 100)
(27608, 26)
(9635, 26)
SGD_ohe
w oversampling
0.00
0.00
0.00
0.00
0.00
493
(10, 100)
(9635, 26)
(9635, 26)
SGD_ohe
w/o oversampling
0.00
0.00
0.00
0.00
0.00
493
(100, 500)
(57551, 393)
(26273, 393)
RFC_ohe
w oversampling
0.26
0.23
0.18
0.53
0.70
233
(100, 500)
(26273, 393)
(26273, 393)
RFC_ohe
w/o oversampling
0.26
0.23
0.18
0.52
0.71
233
(100, 500)
(57551, 393)
(26273, 393)
RFC_ohe
w oversampling
0.24
0.22
0.17
0.50
0.69
233
(100, 500)
(26273, 393)
(26273, 393)
SGD_ohe
w/o oversampling
0.24
0.23
0.17
0.51
0.70
233
(100, 500)
(57551, 26)
(26273, 26)
RFC_dim_red
w oversampling
0.31
0.27
0.23
0.55
0.72
233
(100, 500)
(26273, 26)
(26273, 26)
RFC_dim_red
w/o oversampling
0.31
0.27
0.23
0.56
0.72
233
(100, 500)
(57551, 26)
(26273, 26)
SGD_dim_red
w oversampling
0.00
0.01
0.00
0.02
0.03
233
(100, 500)
(26273, 26)
(26273, 26)
SGD_dim_red
w/o oversampling
0.00
0.01
0.00
0.02
0.03
233
(100, 1000)
(145065, 437)
(44210, 437)
RFC_ohe
w oversampling
0.21
0.18
0.14
0.44
0.60
285
(100, 1000)
(44209, 437)
(44210, 437)
RFC_ohe
w/o oversampling
0.21
0.19
0.15
0.44
0.61
285
(100, 1000)
(145065, 437)
(44210, 437)
RFC_ohe
w oversampling
0.17
0.18
0.13
0.42
0.60
285
(100, 1000)
(44209, 437)
(44210, 437)
SGD_ohe
w/o oversampling
0.18
0.20
0.14
0.44
0.60
285
(100, 1000)
(145065, 26)
(44210, 26)
RFC_dim_red
w oversampling
0.29
0.23
0.20
0.49
0.64
285
(100, 1000)
(44209, 26)
(44210, 26)
RFC_dim_red
w/o oversampling
0.28
0.23
0.20
0.49
0.65
285
(100, 1000)
(145065, 26)
(44210, 26)
SGD_dim_red
w oversampling
0.00
0.01
0.00
0.01
0.01
285
(100, 1000)
(44209, 26)
(44210, 26)
SGD_dim_red
w/o oversampling
0.00
0.01
0.00
0.01
0.01
285
(1000, 6000)
(37642, 186)
(22277, 186)
RFC_ohe
w oversampling
0.49
0.47
0.44
0.76
0.85
29
(1000, 6000)
(22277, 186)
(22277, 186)
RFC_ohe
w/o oversampling
0.49
0.47
0.44
0.76
0.84
29
(1000, 6000)
(37642, 186)
(22277, 186)
RFC_ohe
w oversampling
0.50
0.45
0.41
0.73
0.83
29
(1000, 6000)
(22277, 186)
(22277, 186)
SGD_ohe
w/o oversampling
0.52
0.46
0.41
0.73
0.84
29
(1000, 6000)
(37642, 26)
(22277, 26)
RFC_dim_red
w oversampling
0.57
0.54
0.53
0.79
0.86
29
(1000, 6000)
(22277, 26)
(22277, 26)
RFC_dim_red
w/o oversampling
0.56
0.54
0.53
0.79
0.86
29
(1000, 6000)
(37642, 26)
(22277, 26)
SGD_dim_red
w oversampling
0.01
0.04
0.01
0.10
0.20
29
(1000, 6000)
(22277, 26)
(22277, 26)
SGD_dim_red
w/o oversampling
0.02
0.05
0.02
0.05
0.10
29
Таблица 4. Результаты классификации на втором уровне исполнения. test_size=0.5.
55
Приложение F.
Результаты классификации на третьем уровне ис-
полнения
subset
train_size
test_size
method
precision
recall
f1
top_3
top_5
n_classes
(10, 100)
(36736, 651)
(12190, 651)
RFC_ohe
w oversampling
0.28
0.25
0.23
0.51
0.63
656
(10, 100)
(12190, 651)
(12190, 651)
RFC_ohe
w/o oversampling
0.27
0.25
0.23
0.52
0.64
656
(10, 100)
(36736, 651)
(12190, 651)
SGD_ohe
w oversampling
0.26
0.25
0.22
0.52
0.67
656
(10, 100)
(12190, 651)
(12190, 651)
SGD_ohe
w/o oversampling
0.25
0.25
0.21
0.52
0.66
656
(10, 100)
(36736, 29)
(12190, 29)
RFC_dim_red
w oversampling
0.31
0.27
0.26
0.51
0.60
656
(10, 100)
(12190, 29)
(12190, 29)
RFC_dim_red
w/o oversampling
0.30
0.28
0.27
0.53
0.62
656
(10, 100)
(36736, 29)
(12190, 29)
SGD_dim_red
w oversampling
0.00
0.00
0.00
0.00
0.00
656
(10, 100)
(12190, 29)
(12190, 29)
SGD_dim_red
w/o oversampling
0.00
0.00
0.00
0.00
0.00
656
(100, 500)
(40192, 422)
(15603, 422)
RFC_ohe
w oversampling
0.47
0.44
0.42
0.76
0.84
157
(100, 500)
(15603, 422)
(15603, 422)
RFC_ohe
w/o oversampling
0.47
0.46
0.44
0.77
0.86
157
(100, 500)
(40192, 422)
(15603, 422)
SGD_ohe
w oversampling
0.48
0.45
0.41
0.78
0.89
157
(100, 500)
(15603, 422)
(15603, 422)
SGD_ohe
w/o oversampling
0.50
0.46
0.42
0.77
0.88
157
(100, 500)
(40192, 29)
(15603, 29)
RFC_dim_red
w oversampling
0.50
0.48
0.47
0.73
0.80
157
(100, 500)
(15603, 29)
(15603, 29)
RFC_dim_red
w/o oversampling
0.49
0.48
0.47
0.75
0.82
157
(100, 500)
(40192, 29)
(15603, 29)
SGD_dim_red
w oversampling
0.00
0.01
0.00
0.01
0.01
157
(100, 500)
(15603, 29)
(15603, 29)
SGD_dim_red
w/o oversampling
0.00
0.02
0.00
0.02
0.03
157
(100, 1000)
(79344, 430)
(20842, 430)
RFC_ohe
w oversampling
0.43
0.39
0.37
0.71
0.81
174
(100, 1000)
(20841, 430)
(20842, 430)
RFC_ohe
w/o oversampling
0.43
0.40
0.38
0.72
0.82
174
(100, 1000)
(79344, 430)
(20842, 430)
SGD_ohe
w oversampling
0.44
0.40
0.37
0.73
0.86
174
(100, 1000)
(20841, 430)
(20842, 430)
SGD_ohe
w/o oversampling
0.46
0.42
0.39
0.73
0.85
174
(100, 1000)
(79344, 29)
(20842, 29)
RFC_dim_red
w oversampling
0.44
0.41
0.41
0.69
0.77
174
(100, 1000)
(20841, 29)
(20842, 29)
RFC_dim_red
w/o oversampling
0.45
0.42
0.41
0.72
0.80
174
(100, 1000)
(79344, 29)
(20842, 29)
SGD_dim_red
w oversampling
0.00
0.00
0.00
0.01
0.01
174
(100, 1000)
(20841, 29)
(20842, 29)
SGD_dim_red
w/o oversampling
0.00
0.00
0.00
0.01
0.02
174
Таблица 5. Результаты классификации на третьем уровне исполнения. test_size=0.5.
56
